{"Magnetic_field": "A magnetic field is a vector field that describes the magnetic influence on moving electric charges, electric currents,:\u200ach1\u200a and magnetic materials. A moving charge in a magnetic field experiences a force perpendicular to its own velocity and to the magnetic field.:\u200ach13\u200a:\u200a278\u200a A permanent magnet's magnetic field pulls on ferromagnetic materials such as iron, and attracts or repels other magnets.   In addition, a nonuniform magnetic field exerts minuscule forces on \"nonmagnetic\" materials by three other magnetic effects:  paramagnetism, diamagnetism, and antiferromagnetism, although these forces are usually so small they can only be detected by laboratory equipment.  Magnetic fields surround magnetized materials, and are created by electric currents such as those used in electromagnets, and by electric fields varying in time. Since both strength and direction of a magnetic field may vary with location, it is described mathematically by a function assigning a vector to each point of space, called a vector field.\nIn electromagnetics, the term \"magnetic field\" is used for two distinct but closely related vector fields denoted by the symbols B and H. In the International System of Units, the unit of H, magnetic field strength, is the ampere per meter (A/m).:\u200a22\u200a The unit of B, the magnetic flux density, is the tesla (in SI base units: kilogram per second2 per ampere),:\u200a21\u200a which is equivalent to newton per meter per ampere. H and B differ in how they account for magnetization. In vacuum, the two fields are related through the vacuum permeability, \n  \n    \n      \n        \n          B\n        \n        \n          /\n        \n        \n          \u03bc\n          \n            0\n          \n        \n        =\n        \n          H\n        \n      \n    \n    {\\displaystyle \\mathbf {B} /\\mu _{0}=\\mathbf {H} }\n  ; but in a magnetized material, the quantities on each side of this equation differ by the magnetization field of the material.\nMagnetic fields are produced by moving electric charges and the intrinsic magnetic moments of elementary particles associated with a fundamental quantum property, their spin.:\u200ach1\u200a Magnetic fields and electric fields are interrelated and are both components of the electromagnetic force, one of the four fundamental forces of nature.\nMagnetic fields are used throughout modern technology, particularly in electrical engineering and electromechanics. Rotating magnetic fields are used in both electric motors and generators. The interaction of magnetic fields in electric devices such as transformers is conceptualized and investigated as magnetic circuits. Magnetic forces give information about the charge carriers in a material through the Hall effect. The Earth produces its own magnetic field, which shields the Earth's ozone layer from the solar wind and is important in navigation using a compass.\n\n\n== Description ==\nThe force on an electric charge depends on its location, speed, and direction; two vector fields are used to describe this force.:\u200ach1\u200a The first is the electric field, which describes the force acting on a stationary charge and gives the component of the force that is independent of motion. The magnetic field, in contrast, describes the component of the force that is proportional to both the speed and direction of charged particles.:\u200ach13\u200a The field is defined by the Lorentz force law and is, at each instant, perpendicular to both the motion of the charge and the force it experiences.\nThere are two different, but closely related vector fields which are both sometimes called the \"magnetic field\" written B and H. While both the best names for these fields and exact interpretation of what these fields represent has been the subject of long running debate, there is wide agreement about how the underlying physics work. Historically, the term \"magnetic field\" was reserved for H while using other terms for B, but many recent textbooks use the term \"magnetic field\" to describe B as well as or in place of H.\nThere are many alternative names for both (see sidebar).\n\n\n=== The B-field ===\n\nThe magnetic field vector B at any point can be defined as the vector that, when used in the Lorentz force law, correctly predicts the force on a charged particle at that point::\u200a204\u200a\n\nHere F is the force on the particle, q is the particle's electric charge, v, is the particle's velocity, and \u00d7 denotes the cross product. The direction of force on the charge can be determined by a mnemonic known as the right-hand rule (see the figure). Using the right hand, pointing the thumb in the direction of the current, and the fingers in the direction of the magnetic field, the resulting force on the charge points outwards from the palm. The force on a negatively charged particle is in the opposite direction. If both the speed and the charge are reversed then the direction of the force remains the same. For that reason a magnetic field measurement (by itself) cannot distinguish whether there is a positive charge moving to the right or a negative charge moving to the left. (Both of these cases produce the same current.) On the other hand, a magnetic field combined with an electric field can distinguish between these, see Hall effect below.\nThe first term in the Lorentz equation is from the theory of electrostatics, and says that a particle of charge q in an electric field E experiences an electric force:\n\nThe second term is the magnetic force:\nUsing the definition of the cross product, the magnetic force can also be written as a scalar equation::\u200a357\u200a\nwhere Fmagnetic, v, and B are the scalar magnitude of their respective vectors, and \u03b8 is the angle between the velocity of the particle and the magnetic field. The vector B is defined as the vector field necessary to make the Lorentz force law correctly describe the motion of a charged particle. In other words,:\u200a173\u20134\u200a\n[T]he command, \"Measure the direction and magnitude of the vector B at such and such a place,\" calls for the following operations: Take a particle of known charge q. Measure the force on q at rest, to determine E. Then measure the force on the particle when its velocity is v; repeat with v in some other direction. Now find a B that makes the Lorentz force law fit all these results\u2014that is the magnetic field at the place in question.\nThe B field can also be defined by the torque on a magnetic dipole, m.:\u200a174\u200a\n\nThe SI unit of B is tesla (symbol: T). The Gaussian-cgs unit of B is the gauss (symbol: G). (The conversion is 1 T \u2258 10000 G.) One nanotesla corresponds to 1 gamma (symbol: \u03b3).\n\n\n=== The H-field ===\nThe magnetic H field is defined::\u200a269\u200a:\u200a192\u200a:\u200ach36\u200a\n\nWhere \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the vacuum permeability, and M is the magnetization vector. In a vacuum, B and H are proportional to each other. Inside a material they are different (see H and B inside and outside magnetic materials). The SI unit of the H-field is the ampere per metre (A/m), and the CGS unit is the oersted (Oe).:\u200a286\u200a\n\n\n=== Measurement ===\n\nAn instrument used to measure the local magnetic field is known as a magnetometer. Important classes of magnetometers include using induction magnetometers (or search-coil magnetometers) which measure only varying magnetic fields, rotating coil magnetometers, Hall effect magnetometers, NMR magnetometers, SQUID magnetometers, and fluxgate magnetometers. The magnetic fields of distant astronomical objects are measured through their effects on local charged particles. For instance, electrons spiraling around a field line produce synchrotron radiation that is detectable in radio waves. The finest precision for a magnetic field measurement was attained by Gravity Probe B at 5 aT (5\u00d710\u221218 T).\n\n\n=== Visualization ===\n\nThe field can be visualized by a set of magnetic field lines, that follow the direction of the field at each point. The lines can be constructed by measuring the strength and direction of the magnetic field at a large number of points (or at every point in space). Then, mark each location with an arrow (called a vector) pointing in the direction of the local magnetic field with its magnitude proportional to the strength of the magnetic field. Connecting these arrows then forms a set of magnetic field lines. The direction of the magnetic field at any point is parallel to the direction of nearby field lines, and the local density of field lines can be made proportional to its strength. Magnetic field lines are like streamlines in fluid flow, in that they represent a continuous distribution, and a different resolution would show more or fewer lines.\nAn advantage of using magnetic field lines as a representation is that many laws of magnetism (and electromagnetism) can be stated completely and concisely using simple concepts such as the \"number\" of field lines through a surface. These concepts can be quickly \"translated\" to their mathematical form. For example, the number of field lines through a given surface is the surface integral of the magnetic field.:\u200a237\u200aVarious phenomena \"display\" magnetic field lines as though the field lines were physical phenomena. For example, iron filings placed in a magnetic field form lines that correspond to \"field lines\". Magnetic field \"lines\" are also visually displayed in polar auroras, in which plasma particle dipole interactions create visible streaks of light that line up with the local direction of Earth's magnetic field.\nField lines can be used as a qualitative tool to visualize magnetic forces. In ferromagnetic substances like iron and in plasmas, magnetic forces can be understood by imagining that the field lines exert a tension, (like a rubber band) along their length, and a pressure perpendicular to their length on neighboring field lines. \"Unlike\" poles of magnets attract because they are linked by many field lines; \"like\" poles repel because their field lines do not meet, but run parallel, pushing on each other.\n\n\n== Magnetic field of permanent magnets ==\n\nPermanent magnets are objects that produce their own persistent magnetic fields. They are made of ferromagnetic materials, such as iron and nickel, that have been magnetized, and they have both a north and a south pole.\nThe magnetic field of permanent magnets can be quite complicated, especially near the magnet. The magnetic field of a small straight magnet is proportional to the magnet's strength (called its magnetic dipole moment m). The equations are non-trivial and also depend on the distance from the magnet and the orientation of the magnet. For simple magnets, m points in the direction of a line drawn from the south to the north pole of the magnet. Flipping a bar magnet is equivalent to rotating its m by 180 degrees.\nThe magnetic field of larger magnets can be obtained by modeling them as a collection of a large number of small magnets called dipoles each having their own m. The magnetic field produced by the magnet then is the net magnetic field of these dipoles; any net force on the magnet is a result of adding up the forces on the individual dipoles.\nThere were two simplified models for the nature of these dipoles. These two models produce two different magnetic fields, H and B. Outside a material, though, the two are identical (to a multiplicative constant) so that in many cases the distinction can be ignored. This is particularly true for magnetic fields, such as those due to electric currents, that are not generated by magnetic materials.\nA realistic model of magnetism is more complicated than either of these models; neither model fully explains why materials are magnetic. The monopole model has no experimental support. Ampere's model explains some, but not all of a material's magnetic moment. Like Ampere's model predicts, the motion of electrons within an atom are connected to those electrons' orbital magnetic dipole moment, and these orbital moments do contribute to the magnetism seen at the macroscopic level. However, the motion of electrons is not classical, and the spin magnetic moment of electrons (which is not explained by either model) is also a significant contribution to the total moment of magnets.\n\n\n=== Magnetic pole model ===\n\nHistorically, early physics textbooks would model the force and torques between two magnets as due to magnetic poles repelling or attracting each other in the same manner as the Coulomb force between electric charges. At the microscopic level, this model contradicts the experimental evidence, and the pole model of magnetism is no longer the typical way to introduce the concept.:\u200a204\u200a However, it is still sometimes used as a macroscopic model for ferromagnetism due to its mathematical simplicity.In this model, a magnetic H-field is produced by fictitious magnetic charges that are spread over the surface of each pole. These magnetic charges are in fact related to the magnetization field M. The H-field, therefore, is analogous to the electric field E, which starts at a positive electric charge and ends at a negative electric charge. Near the north pole, therefore, all H-field lines point away from the north pole (whether inside the magnet or out) while near the south pole all H-field lines point toward the south pole (whether inside the magnet or out). Too, a north pole feels a force in the direction of the H-field while the force on the south pole is opposite to the H-field.\nIn the magnetic pole model, the elementary magnetic dipole m is formed by two opposite magnetic poles of pole strength qm separated by a small distance vector d, such that m = qm\u2009d. The magnetic pole model predicts correctly the field H both inside and outside magnetic materials, in particular the fact that H is opposite to the magnetization field M inside a permanent magnet.\nSince it is based on the fictitious idea of a magnetic charge density, the pole model has limitations. Magnetic poles cannot exist apart from each other as electric charges can, but always come in north\u2013south pairs. If a magnetized object is divided in half, a new pole appears on the surface of each piece, so each has a pair of complementary poles. The magnetic pole model does not account for magnetism that is produced by electric currents, nor the inherent connection between angular momentum and magnetism.\nThe pole model usually treats magnetic charge as a mathematical abstraction, rather than a physical property of particles. However, a magnetic monopole is a hypothetical particle (or class of particles) that physically has only one magnetic pole (either a north pole or a south pole). In other words, it would possess a \"magnetic charge\" analogous to an electric charge. Magnetic field lines would start or end on magnetic monopoles, so if they exist, they would give exceptions to the rule that magnetic field lines neither start nor end. Some theories (such as Grand Unified Theories) have predicted the existence of magnetic monopoles, but so far, none have been observed.\n\n\n=== Amperian loop model ===\n\nIn the model developed by Ampere, the elementary magnetic dipole that makes up all magnets is a sufficiently small Amperian loop with current I and loop area A. The dipole moment of this loop is m = IA.\nThese magnetic dipoles produce a magnetic B-field.\nThe magnetic field of a magnetic dipole is depicted in the figure. From outside, the ideal magnetic dipole is identical to that of an ideal electric dipole of the same strength. Unlike the electric dipole, a magnetic dipole is properly modeled as a current loop having a current I and an area a. Such a current loop has a magnetic moment of\n\nwhere the direction of m is perpendicular to the area of the loop and depends on the direction of the current using the right-hand rule. An ideal magnetic dipole is modeled as a real magnetic dipole whose area a has been reduced to zero and its current I increased to infinity such that the product m = Ia is finite. This model clarifies the connection between angular momentum and magnetic moment, which is the basis of the Einstein\u2013de Haas effect rotation by magnetization and its inverse, the Barnett effect or magnetization by rotation. Rotating the loop faster (in the same direction) increases the current and therefore the magnetic moment, for example.\n\n\n== Interactions with magnets ==\n\n\n=== Force between magnets ===\n\nSpecifying the force between two small magnets is quite complicated because it depends on the strength and orientation of both magnets and their distance and direction relative to each other. The force is particularly sensitive to rotations of the magnets due to magnetic torque. The force on each magnet depends on its magnetic moment and the magnetic field of the other.\nTo understand the force between magnets, it is useful to examine the magnetic pole model given above. In this model, the H-field of one magnet pushes and pulls on both poles of a second magnet. If this H-field is the same at both poles of the second magnet then there is no net force on that magnet since the force is opposite for opposite poles. If, however, the magnetic field of the first magnet is nonuniform (such as the H near one of its poles), each pole of the second magnet sees a different field and is subject to a different force. This difference in the two forces moves the magnet in the direction of increasing magnetic field and may also cause a net torque.\nThis is a specific example of a general rule that magnets are attracted (or repulsed depending on the orientation of the magnet) into regions of higher magnetic field. Any non-uniform magnetic field, whether caused by permanent magnets or electric currents, exerts a force on a small magnet in this way.\nThe details of the Amperian loop model are different and more complicated but yield the same result: that magnetic dipoles are attracted/repelled into regions of higher magnetic field. Mathematically, the force on a small magnet having a magnetic moment m due to a magnetic field B is::\u200aEq. 11.42\u200a\nwhere the gradient \u2207 is the change of the quantity m \u00b7 B per unit distance and the direction is that of maximum increase of m \u00b7 B. The dot product m \u00b7 B = mBcos(\u03b8), where m and B represent the magnitude of the m and B vectors and \u03b8 is the angle between them. If m is in the same direction as B then the dot product is positive and the gradient points \"uphill\" pulling the magnet into regions of higher B-field (more strictly larger m \u00b7 B). This equation is strictly only valid for magnets of zero size, but is often a good approximation for not too large magnets. The magnetic force on larger magnets is determined by dividing them into smaller regions each having their own m then summing up the forces on each of these very small regions.\n\n\n=== Magnetic torque on permanent magnets ===\n\nIf two like poles of two separate magnets are brought near each other, and one of the magnets is allowed to turn, it promptly rotates to align itself with the first. In this example, the magnetic field of the stationary magnet creates a magnetic torque on the magnet that is free to rotate. This magnetic torque \u03c4 tends to align a magnet's poles with the magnetic field lines. A compass, therefore, turns to align itself with Earth's magnetic field.\n\n In terms of the pole model, two equal and opposite magnetic charges experiencing the same H also experience equal and opposite forces. Since these equal and opposite forces are in different locations, this produces a torque proportional to the distance (perpendicular to the force) between them. With the definition of m as the pole strength times the distance between the poles, this leads to \u03c4 = \u03bc0 m H sin\u2009\u03b8, where \u03bc0 is a constant called the vacuum permeability, measuring 4\u03c0\u00d710\u22127 V\u00b7s/(A\u00b7m) and \u03b8 is the angle between H and m.\nMathematically, the torque \u03c4 on a small magnet is proportional both to the applied magnetic field and to the magnetic moment m of the magnet:\n\nwhere \u00d7 represents the vector cross product. This equation includes all of the qualitative information included above. There is no torque on a magnet if m is in the same direction as the magnetic field, since the cross product is zero for two vectors that are in the same direction. Further, all other orientations feel a torque that twists them toward the direction of magnetic field.\n\n\n== Interactions with electric currents ==\nCurrents of electric charges both generate a magnetic field and feel a force due to magnetic B-fields.\n\n\n=== Magnetic field due to moving charges and electric currents ===\n\nAll moving charged particles produce magnetic fields. Moving point charges, such as electrons, produce complicated but well known magnetic fields that depend on the charge, velocity, and acceleration of the particles.Magnetic field lines form in concentric circles around a cylindrical current-carrying conductor, such as a length of wire. The direction of such a magnetic field can be determined by using the \"right-hand grip rule\" (see figure at right). The strength of the magnetic field decreases with distance from the wire. (For an infinite length wire the strength is inversely proportional to the distance.)\n\nBending a current-carrying wire into a loop concentrates the magnetic field inside the loop while weakening it outside. Bending a wire into multiple closely spaced loops to form a coil or \"solenoid\" enhances this effect. A device so formed around an iron core may act as an electromagnet, generating a strong, well-controlled magnetic field. An infinitely long cylindrical electromagnet has a uniform magnetic field inside, and no magnetic field outside. A finite length electromagnet produces a magnetic field that looks similar to that produced by a uniform permanent magnet, with its strength and polarity determined by the current flowing through the coil.\nThe magnetic field generated by a steady current I (a constant flow of electric charges, in which charge neither accumulates nor is depleted at any point) is described by the Biot\u2013Savart law::\u200a224\u200a\nwhere the integral sums over the wire length where vector d\u2113 is the vector line element with direction in the same sense as the current I, \u03bc0 is the magnetic constant, r is the distance between the location of d\u2113 and the location where the magnetic field is calculated, and r\u0302 is a unit vector in the direction of r. For example, in the case of a sufficiently long, straight wire, this becomes:\n\nwhere r = |r|. The direction is tangent to a circle perpendicular to the wire according to the right hand rule.:\u200a225\u200aA slightly more general way of relating the current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   to the B-field is through Amp\u00e8re's law:\n\nwhere the line integral is over any arbitrary loop and \n  \n    \n      \n        \n          I\n          \n            enc\n          \n        \n      \n    \n    {\\displaystyle I_{\\text{enc}}}\n   is the current enclosed by that loop. Amp\u00e8re's law is always valid for steady currents and can be used to calculate the B-field for certain highly symmetric situations such as an infinite wire or an infinite solenoid.\nIn a modified form that accounts for time varying electric fields, Amp\u00e8re's law is one of four Maxwell's equations that describe electricity and magnetism.\n\n\n=== Force on moving charges and current ===\n\n\n==== Force on a charged particle ====\n\nA charged particle moving in a B-field experiences a sideways force that is proportional to the strength of the magnetic field, the component of the velocity that is perpendicular to the magnetic field and the charge of the particle. This force is known as the Lorentz force, and is given by\n\nwhere F is the force, q is the electric charge of the particle, v is the instantaneous velocity of the particle, and B is the magnetic field (in teslas).\nThe Lorentz force is always perpendicular to both the velocity of the particle and the magnetic field that created it. When a charged particle moves in a static magnetic field, it traces a helical path in which the helix axis is parallel to the magnetic field, and in which the speed of the particle remains constant. Because the magnetic force is always perpendicular to the motion, the magnetic field can do no work on an isolated charge. It can only do work indirectly, via the electric field generated by a changing magnetic field. It is often claimed that the magnetic force can do work to a non-elementary magnetic dipole, or to charged particles whose motion is constrained by other forces, but this is incorrect because the work in those cases is performed by the electric forces of the charges deflected by the magnetic field.\n\n\n==== Force on current-carrying wire ====\n\nThe force on a current carrying wire is similar to that of a moving charge as expected since a current carrying wire is a collection of moving charges. A current-carrying wire feels a force in the presence of a magnetic field. The Lorentz force on a macroscopic current is often referred to as the Laplace force.\nConsider a conductor of length \u2113, cross section A, and charge q due to electric current i. If this conductor is placed in a magnetic field of magnitude B that makes an angle \u03b8 with the velocity of charges in the conductor, the force exerted on a single charge q is\n\nso, for N charges where\n\nthe force exerted on the conductor is\n\nwhere i = nqvA.\n\n\n== Relation between H and B ==\nThe formulas derived for the magnetic field above are correct when dealing with the entire current. A magnetic material placed inside a magnetic field, though, generates its own bound current, which can be a challenge to calculate. (This bound current is due to the sum of atomic sized current loops and the spin of the subatomic particles such as electrons that make up the material.) The H-field as defined above helps factor out this bound current; but to see how, it helps to introduce the concept of magnetization first.\n\n\n=== Magnetization ===\n\nThe magnetization vector field M represents how strongly a region of material is magnetized. It is defined as the net magnetic dipole moment per unit volume of that region. The magnetization of a uniform magnet is therefore a material constant, equal to the magnetic moment m of the magnet divided by its volume. Since the SI unit of magnetic moment is A\u22c5m2, the SI unit of magnetization M is ampere per meter, identical to that of the H-field.\nThe magnetization M field of a region points in the direction of the average magnetic dipole moment in that region. Magnetization field lines, therefore, begin near the magnetic south pole and ends near the magnetic north pole. (Magnetization does not exist outside the magnet.)\nIn the Amperian loop model, the magnetization is due to combining many tiny Amperian loops to form a resultant current called bound current. This bound current, then, is the source of the magnetic B field due to the magnet. Given the definition of the magnetic dipole, the magnetization field follows a similar law to that of Ampere's law:\nwhere the integral is a line integral over any closed loop and Ib is the bound current enclosed by that closed loop.\nIn the magnetic pole model, magnetization begins at and ends at magnetic poles. If a given region, therefore, has a net positive \"magnetic pole strength\" (corresponding to a north pole) then it has more magnetization field lines entering it than leaving it. Mathematically this is equivalent to:\n\nwhere the integral is a closed surface integral over the closed surface S and qM is the \"magnetic charge\" (in units of magnetic flux) enclosed by S. (A closed surface completely surrounds a region with no holes to let any field lines escape.) The negative sign occurs because the magnetization field moves from south to north.\n\n\n=== H-field and magnetic materials ===\n\nIn SI units, the H-field is related to the B-field by\n\nIn terms of the H-field, Ampere's law is\n\nwhere If represents the 'free current' enclosed by the loop so that the line integral of H does not depend at all on the bound currents.For the differential equivalent of this equation see Maxwell's equations. Ampere's law leads to the boundary condition\n\nwhere Kf is the surface free current density and the unit normal \n  \n    \n      \n        \n          \n            \n              \n                n\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {n} }}}\n   points in the direction from medium 2 to medium 1.Similarly, a surface integral of H over any closed surface is independent of the free currents and picks out the \"magnetic charges\" within that closed surface:\n\nwhich does not depend on the free currents.\nThe H-field, therefore, can be separated into two independent parts:\n\nwhere H0 is the applied magnetic field due only to the free currents and Hd is the demagnetizing field due only to the bound currents.\nThe magnetic H-field, therefore, re-factors the bound current in terms of \"magnetic charges\". The H field lines loop only around \"free current\" and, unlike the magnetic B field, begins and ends near magnetic poles as well.\n\n\n=== Magnetism ===\n\nMost materials respond to an applied B-field by producing their own magnetization M and therefore their own B-fields. Typically, the response is weak and exists only when the magnetic field is applied. The term magnetism describes how materials respond on the microscopic level to an applied magnetic field and is used to categorize the magnetic phase of a material. Materials are divided into groups based upon their magnetic behavior:\n\nDiamagnetic materials produce a magnetization that opposes the magnetic field.\nParamagnetic materials produce a magnetization in the same direction as the applied magnetic field.\nFerromagnetic materials and the closely related ferrimagnetic materials and antiferromagnetic materials can have a magnetization independent of an applied B-field with a complex relationship between the two fields.\nSuperconductors (and ferromagnetic superconductors) are materials that are characterized by perfect conductivity below a critical temperature and magnetic field. They also are highly magnetic and can be perfect diamagnets below a lower critical magnetic field. Superconductors often have a broad range of temperatures and magnetic fields (the so-named mixed state) under which they exhibit a complex hysteretic dependence of M on B.In the case of paramagnetism and diamagnetism, the magnetization M is often proportional to the applied magnetic field such that:\n\nwhere \u03bc is a material dependent parameter called the permeability. In some cases the permeability may be a second rank tensor so that H may not point in the same direction as B. These relations between B and H are examples of constitutive equations. However, superconductors and ferromagnets have a more complex B-to-H relation; see magnetic hysteresis.\n\n\n== Stored energy ==\n\nEnergy is needed to generate a magnetic field both to work against the electric field that a changing magnetic field creates and to change the magnetization of any material within the magnetic field. For non-dispersive materials, this same energy is released when the magnetic field is destroyed so that the energy can be modeled as being stored in the magnetic field.\nFor linear, non-dispersive, materials (such that B = \u03bcH where \u03bc is frequency-independent), the energy density is:\n\nIf there are no magnetic materials around then \u03bc can be replaced by \u03bc0. The above equation cannot be used for nonlinear materials, though; a more general expression given below must be used.\nIn general, the incremental amount of work per unit volume \u03b4W needed to cause a small change of magnetic field \u03b4B is:\n\nOnce the relationship between H and B is known this equation is used to determine the work needed to reach a given magnetic state. For hysteretic materials such as ferromagnets and superconductors, the work needed also depends on how the magnetic field is created. For linear non-dispersive materials, though, the general equation leads directly to the simpler energy density equation given above.\n\n\n== Appearance in Maxwell's equations ==\n\nLike all vector fields, a magnetic field has two important mathematical properties that relates it to its sources. (For B the sources are currents and changing electric fields.) These two properties, along with the two corresponding properties of the electric field, make up Maxwell's Equations. Maxwell's Equations together with the Lorentz force law form a complete description of classical electrodynamics including both electricity and magnetism.\nThe first property is the divergence of a vector field A, \u2207 \u00b7 A, which represents how A \"flows\" outward from a given point. As discussed above, a B-field line never starts or ends at a point but instead forms a complete loop. This is mathematically equivalent to saying that the divergence of B is zero. (Such vector fields are called solenoidal vector fields.) This property is called Gauss's law for magnetism and is equivalent to the statement that there are no isolated magnetic poles or magnetic monopoles.\nThe second mathematical property is called the curl, such that \u2207 \u00d7 A represents how A curls or \"circulates\" around a given point. The result of the curl is called a \"circulation source\". The equations for the curl of B and of E are called the Amp\u00e8re\u2013Maxwell equation and Faraday's law respectively.\n\n\n=== Gauss' law for magnetism ===\n\nOne important property of the B-field produced this way is that magnetic B-field lines neither start nor end (mathematically, B is a solenoidal vector field); a field line may only extend to infinity, or wrap around to form a closed curve, or follow a never-ending (possibly chaotic) path. Magnetic field lines exit a magnet near its north pole and enter near its south pole, but inside the magnet B-field lines continue through the magnet from the south pole back to the north. If a B-field line enters a magnet somewhere it has to leave somewhere else; it is not allowed to have an end point.\nMore formally, since all the magnetic field lines that enter any given region must also leave that region, subtracting the \"number\" of field lines that enter the region from the number that exit gives identically zero. Mathematically this is equivalent to Gauss's law for magnetism:\n\nwhere the integral is a surface integral over the closed surface S (a closed surface is one that completely surrounds a region with no holes to let any field lines escape). Since dA points outward, the dot product in the integral is positive for B-field pointing out and negative for B-field pointing in.\n\n\n=== Faraday's Law ===\n\nA changing magnetic field, such as a magnet moving through a conducting coil, generates an electric field (and therefore tends to drive a current in such a coil). This is known as Faraday's law and forms the basis of many electrical generators and electric motors. Mathematically, Faraday's law is:\n\nwhere \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   is the electromotive force (or EMF, the voltage generated around a closed loop) and \u03a6 is the magnetic flux\u2014the product of the area times the magnetic field normal to that area. (This definition of magnetic flux is why B is often referred to as magnetic flux density.):\u200a210\u200a The negative sign represents the fact that any current generated by a changing magnetic field in a coil produces a magnetic field that opposes the change in the magnetic field that induced it. This phenomenon is known as Lenz's law. This integral formulation of Faraday's law can be converted into a differential form, which applies under slightly different conditions.\n\n\n=== Amp\u00e8re's Law and Maxwell's correction ===\n\nSimilar to the way that a changing magnetic field generates an electric field, a changing electric field generates a magnetic field. This fact is known as Maxwell's correction to Amp\u00e8re's law and is applied as an additive term to Ampere's law as given above. This additional term is proportional to the time rate of change of the electric flux and is similar to Faraday's law above but with a different and positive constant out front. (The electric flux through an area is proportional to the area times the perpendicular part of the electric field.)\nThe full law including the correction term is known as the Maxwell\u2013Amp\u00e8re equation. It is not commonly given in integral form because the effect is so small that it can typically be ignored in most cases where the integral form is used.\nThe Maxwell term is critically important in the creation and propagation of electromagnetic waves. Maxwell's correction to Amp\u00e8re's Law together with Faraday's law of induction describes how mutually changing electric and magnetic fields interact to sustain each other and thus to form electromagnetic waves, such as light: a changing electric field generates a changing magnetic field, which generates a changing electric field again. These, though, are usually described using the differential form of this equation given below.\n\nwhere J is the complete microscopic current density.\nAs discussed above, materials respond to an applied electric E field and an applied magnetic B field by producing their own internal \"bound\" charge and current distributions that contribute to E and B but are difficult to calculate. To circumvent this problem, H and D fields are used to re-factor Maxwell's equations in terms of the free current density Jf:\n\nThese equations are not any more general than the original equations (if the \"bound\" charges and currents in the material are known). They also must be supplemented by the relationship between B and H as well as that between E and D. On the other hand, for simple relationships between these quantities this form of Maxwell's equations can circumvent the need to calculate the bound charges and currents.\n\n\n== Formulation in special relativity and quantum electrodynamics ==\n\n\n=== Relativistic Electrodynamics ===\n\n\n==== As different aspects of the same phenomenon ====\nAccording to the special theory of relativity, the partition of the electromagnetic force into separate electric and magnetic components is not fundamental, but varies with the observational frame of reference: An electric force perceived by one observer may be perceived by another (in a different frame of reference) as a magnetic force, or a mixture of electric and magnetic forces. \nThe magnetic field existing as electric field in other frames can be shown by consistency of equations obtained from Lorentz transformation of four force from Coulomb's Law in particle's rest frame with Maxwell's laws considering definition of fields from Lorentz force and for non accelerating condition. The form of magnetic field hence obtained by Lorentz transformation of four-force from the form of Coulomb's law in source's initial frame is given by:where \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the charge of the point source, \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is the position vector from the point source to the point in space, \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   is the velocity vector of the charged particle, \n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is the ratio of speed of the charged particle divided by the speed of light and \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   and \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n  . This form of magnetic field can be shown to satisfy maxwell's laws within the constraint of particle being non accelerating. Note that the above reduces to Biot-Savart law for non relativistic stream of current (\n  \n    \n      \n        \u03b2\n        \u226a\n        1\n      \n    \n    {\\displaystyle \\beta \\ll 1}\n  ).\nFormally, special relativity combines the electric and magnetic fields into a rank-2 tensor, called the electromagnetic tensor. Changing reference frames mixes these components. This is analogous to the way that special relativity mixes space and time into spacetime, and mass, momentum, and energy into four-momentum. Similarly, the energy stored in a magnetic field is mixed with the energy stored in an electric field in the electromagnetic stress\u2013energy tensor.\n\n\n==== Magnetic vector potential ====\n\nIn advanced topics such as quantum mechanics and relativity it is often easier to work with a potential formulation of electrodynamics rather than in terms of the electric and magnetic fields. In this representation, the magnetic vector potential A, and the electric scalar potential \u03c6, are defined using gauge fixing such that:\n.\nThe vector potential, A given by this form may be interpreted as a generalized potential momentum per unit charge  just as \u03c6 is interpreted as a generalized potential energy per unit charge. There are multiple choices one can make for the potential fields that satisfy the above condition. However, the choice of potentials is represented by its respective gauge condition.\nMaxwell's equations when expressed in terms of the potentials in Lorentz gauge can be cast into a form that agrees with special relativity. In relativity, A together with \u03c6 forms a four-potential regardless of the gauge condition, analogous to the four-momentum that combines the momentum and energy of a particle. Using the four potential instead of the electromagnetic tensor has the advantage of being much simpler\u2014and it can be easily modified to work with quantum mechanics.\n\n\n==== Propagation of Electric and Magnetic fields ====\nSpecial theory of relativity imposes the condition for events related by cause and effect to be time-like separated, that is that causal efficacy propagates no faster than light. Maxwell's equations for electromagnetism are found to be in favor of this as electric and magnetic disturbances are found to travel at the speed of light in space. Electric and magnetic fields from classical electrodynamics obey the principle of locality in physics and are expressed in terms of retarded time or the time at which the cause of a measured field originated given that the influence of field travelled at speed of light. The retarded time for a point particle is given as solution of:\n\n  \n    \n      \n        \n          t\n          \n            r\n          \n        \n        =\n        \n          t\n        \n        \u2212\n        \n          \n            \n              \n                |\n              \n              \n                r\n              \n              \u2212\n              \n                \n                  r\n                \n                \n                  s\n                \n              \n              (\n              \n                t\n                \n                  r\n                \n              \n              )\n              \n                |\n              \n            \n            c\n          \n        \n      \n    \n    {\\displaystyle t_{r}=\\mathbf {t} -{\\frac {|\\mathbf {r} -\\mathbf {r} _{s}(t_{r})|}{c}}}\n  \nwhere \n  \n    \n      \n        \n          \n            t\n            \n              r\n            \n          \n        \n      \n    \n    {\\textstyle {t_{r}}}\n   is retarded time or the time at which the source's contribution of the field originated, \n  \n    \n      \n        \n          \n            r\n          \n          \n            s\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\textstyle {r}_{s}(t)}\n   is the position vector of the particle as function of time, \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\textstyle \\mathbf {r} }\n   is the point in space, \n  \n    \n      \n        \n          t\n        \n      \n    \n    {\\textstyle \\mathbf {t} }\n   is the time at which fields are measured and \n  \n    \n      \n        c\n      \n    \n    {\\textstyle c}\n   is the speed of light. The equation subtracts the time taken for light to travel from particle to the point in space from the time of measurement to find time of origin of the fields. The uniqueness of solution for \n  \n    \n      \n        \n          \n            t\n            \n              r\n            \n          \n        \n      \n    \n    {\\textstyle {t_{r}}}\n   for given \n  \n    \n      \n        \n          t\n        \n      \n    \n    {\\displaystyle \\mathbf {t} }\n  , \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   and \n  \n    \n      \n        \n          r\n          \n            s\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle r_{s}(t)}\n   is valid for charged particles moving slower than speed of light.\n\n\n==== Magnetic field of arbitrary moving point charge ====\n\nThe solution of maxwell's equations for electric and magnetic field of a point charge is expressed in terms of retarded time or the time at which the particle in the past causes the field at the point, given that the influence travels across space at the speed of light.\nAny arbitrary motion of point charge causes electric and magnetic fields found by solving maxwell's equations using green's function for retarded potentials and hence finding the fields to be as follows:\n\n  \n    \n      \n        \n          A\n        \n        (\n        \n          r\n        \n        ,\n        \n          t\n        \n        )\n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              c\n            \n            \n              4\n              \u03c0\n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  q\n                  \n                    \n                      \u03b2\n                    \n                    \n                      s\n                    \n                  \n                \n                \n                  (\n                  1\n                  \u2212\n                  \n                    \n                      n\n                    \n                    \n                      s\n                    \n                  \n                  \u22c5\n                  \n                    \n                      \u03b2\n                    \n                    \n                      s\n                    \n                  \n                  )\n                  \n                    |\n                  \n                  \n                    r\n                  \n                  \u2212\n                  \n                    \n                      r\n                    \n                    \n                      s\n                    \n                  \n                  \n                    |\n                  \n                \n              \n            \n            )\n          \n          \n            t\n            =\n            \n              t\n              \n                r\n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \u03b2\n                \n                \n                  s\n                \n              \n              (\n              \n                t\n                \n                  r\n                \n              \n              )\n            \n            c\n          \n        \n        \u03c6\n        (\n        \n          r\n        \n        ,\n        \n          t\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {A} (\\mathbf {r} ,\\mathbf {t} )={\\frac {\\mu _{0}c}{4\\pi }}\\left({\\frac {q{\\boldsymbol {\\beta }}_{s}}{(1-\\mathbf {n} _{s}\\cdot {\\boldsymbol {\\beta }}_{s})|\\mathbf {r} -\\mathbf {r} _{s}|}}\\right)_{t=t_{r}}={\\frac {{\\boldsymbol {\\beta }}_{s}(t_{r})}{c}}\\varphi (\\mathbf {r} ,\\mathbf {t} )}\n  \n\n  \n    \n      \n        \n          B\n        \n        (\n        \n          r\n        \n        ,\n        \n          t\n        \n        )\n        =\n        \n          \n            \n              \u03bc\n              \n                0\n              \n            \n            \n              4\n              \u03c0\n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    q\n                    c\n                    (\n                    \n                      \n                        \u03b2\n                      \n                      \n                        s\n                      \n                    \n                    \u00d7\n                    \n                      \n                        n\n                      \n                      \n                        s\n                      \n                    \n                    )\n                  \n                  \n                    \n                      \u03b3\n                      \n                        2\n                      \n                    \n                    (\n                    1\n                    \u2212\n                    \n                      \n                        n\n                      \n                      \n                        s\n                      \n                    \n                    \u22c5\n                    \n                      \n                        \u03b2\n                      \n                      \n                        s\n                      \n                    \n                    \n                      )\n                      \n                        3\n                      \n                    \n                    \n                      |\n                    \n                    \n                      r\n                    \n                    \u2212\n                    \n                      \n                        r\n                      \n                      \n                        s\n                      \n                    \n                    \n                      \n                        |\n                      \n                      \n                        2\n                      \n                    \n                  \n                \n              \n              +\n              \n                \n                  \n                    q\n                    \n                      \n                        n\n                      \n                      \n                        s\n                      \n                    \n                    \u00d7\n                    \n                      \n                        (\n                      \n                    \n                    \n                      \n                        n\n                      \n                      \n                        s\n                      \n                    \n                    \u00d7\n                    \n                      \n                        (\n                      \n                    \n                    (\n                    \n                      \n                        n\n                      \n                      \n                        s\n                      \n                    \n                    \u2212\n                    \n                      \n                        \u03b2\n                      \n                      \n                        s\n                      \n                    \n                    )\n                    \u00d7\n                    \n                      \n                        \n                          \n                            \n                              \u03b2\n                            \n                            \n                              s\n                            \n                          \n                          \u02d9\n                        \n                      \n                    \n                    \n                      \n                        )\n                      \n                    \n                    \n                      \n                        )\n                      \n                    \n                  \n                  \n                    (\n                    1\n                    \u2212\n                    \n                      \n                        n\n                      \n                      \n                        s\n                      \n                    \n                    \u22c5\n                    \n                      \n                        \u03b2\n                      \n                      \n                        s\n                      \n                    \n                    \n                      )\n                      \n                        3\n                      \n                    \n                    \n                      |\n                    \n                    \n                      r\n                    \n                    \u2212\n                    \n                      \n                        r\n                      \n                      \n                        s\n                      \n                    \n                    \n                      |\n                    \n                  \n                \n              \n            \n            )\n          \n          \n            t\n            =\n            \n              t\n              \n                r\n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  n\n                \n                \n                  s\n                \n              \n              (\n              \n                t\n                \n                  r\n                \n              \n              )\n            \n            c\n          \n        \n        \u00d7\n        \n          E\n        \n        (\n        \n          r\n        \n        ,\n        \n          t\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {B} (\\mathbf {r} ,\\mathbf {t} )={\\frac {\\mu _{0}}{4\\pi }}\\left({\\frac {qc({\\boldsymbol {\\beta }}_{s}\\times \\mathbf {n} _{s})}{\\gamma ^{2}(1-\\mathbf {n} _{s}\\cdot {\\boldsymbol {\\beta }}_{s})^{3}|\\mathbf {r} -\\mathbf {r} _{s}|^{2}}}+{\\frac {q\\mathbf {n} _{s}\\times {\\Big (}\\mathbf {n} _{s}\\times {\\big (}(\\mathbf {n} _{s}-{\\boldsymbol {\\beta }}_{s})\\times {\\dot {{\\boldsymbol {\\beta }}_{s}}}{\\big )}{\\Big )}}{(1-\\mathbf {n} _{s}\\cdot {\\boldsymbol {\\beta }}_{s})^{3}|\\mathbf {r} -\\mathbf {r} _{s}|}}\\right)_{t=t_{r}}={\\frac {\\mathbf {n} _{s}(t_{r})}{c}}\\times \\mathbf {E} (\\mathbf {r} ,\\mathbf {t} )}\n  \nwhere \n  \n    \n      \n        \u03c6\n        (\n        \n          r\n        \n        ,\n        \n          t\n        \n        )\n      \n    \n    {\\textstyle \\varphi (\\mathbf {r} ,\\mathbf {t} )}\n  and \n  \n    \n      \n        \n          A\n        \n        (\n        \n          r\n        \n        ,\n        \n          t\n        \n        )\n      \n    \n    {\\textstyle \\mathbf {A} (\\mathbf {r} ,\\mathbf {t} )}\n   are electric scalar potential and magnetic vector potential in Lorentz gauge, \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the charge of the point source, \n  \n    \n      \n        \n          \n            n\n          \n          \n            s\n          \n        \n        (\n        \n          r\n        \n        ,\n        t\n        )\n      \n    \n    {\\textstyle {n}_{s}(\\mathbf {r} ,t)}\n   is a unit vector pointing from charged particle to the point in space, \n  \n    \n      \n        \n          \n            \u03b2\n          \n          \n            s\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\textstyle {\\boldsymbol {\\beta }}_{s}(t)}\n   is the velocity of the particle divided by the speed of light and \n  \n    \n      \n        \u03b3\n        (\n        t\n        )\n      \n    \n    {\\textstyle \\gamma (t)}\n   is the corresponding Lorentz factor. Hence by the principle of superposition, the fields of a system of charges also obey principle of locality.\n\n\n=== Quantum electrodynamics ===\n\nIn modern physics, the electromagnetic field is understood to be not a classical field, but rather a quantum field; it is represented not as a vector of three numbers at each point, but as a vector of three quantum operators at each point. The most accurate modern description of the electromagnetic interaction (and much else) is quantum electrodynamics (QED), which is incorporated into a more complete theory known as the Standard Model of particle physics.\nIn QED, the magnitude of the electromagnetic interactions between charged particles (and their antiparticles) is computed using perturbation theory. These rather complex formulas produce a remarkable pictorial representation as Feynman diagrams in which virtual photons are exchanged.\nPredictions of QED agree with experiments to an extremely high degree of accuracy: currently about 10\u221212 (and limited by experimental errors); for details see precision tests of QED. This makes QED one of the most accurate physical theories constructed thus far.\nAll equations in this article are in the classical approximation, which is less accurate than the quantum description mentioned here. However, under most everyday circumstances, the difference between the two theories is negligible.\n\n\n== Uses and examples ==\n\n\n=== Earth's magnetic field ===\n\nThe Earth's magnetic field is produced by convection of a liquid iron alloy in the outer core. In a dynamo process, the movements drive a feedback process in which electric currents create electric and magnetic fields that in turn act on the currents.The field at the surface of the Earth is approximately the same as if a giant bar magnet were positioned at the center of the Earth and tilted at an angle of about 11\u00b0 off the rotational axis of the Earth (see the figure). The north pole of a magnetic compass needle points roughly north, toward the North Magnetic Pole. However, because a magnetic pole is attracted to its opposite, the North Magnetic Pole is actually the south pole of the geomagnetic field. This confusion in terminology arises because the pole of a magnet is defined by the geographical direction it points.Earth's magnetic field is not constant\u2014the strength of the field and the location of its poles vary. Moreover, the poles periodically reverse their orientation in a process called geomagnetic reversal. The most recent reversal occurred 780,000 years ago.\n\n\n=== Rotating magnetic fields ===\n\nThe rotating magnetic field is a key principle in the operation of alternating-current motors. A permanent magnet in such a field rotates so as to maintain its alignment with the external field. This effect was conceptualized by Nikola Tesla, and later utilized in his and others' early AC (alternating current) electric motors.\nMagnetic torque is used to drive electric motors. In one simple motor design, a magnet is fixed to a freely rotating shaft and subjected to a magnetic field from an array of electromagnets. By continuously switching the electric current through each of the electromagnets, thereby flipping the polarity of their magnetic fields, like poles are kept next to the rotor; the resultant torque is transferred to the shaft.\nA rotating magnetic field can be constructed using two orthogonal coils with 90 degrees phase difference in their AC currents. However, in practice such a system would be supplied through a three-wire arrangement with unequal currents.\nThis inequality would cause serious problems in standardization of the conductor size and so, to overcome it, three-phase systems are used where the three currents are equal in magnitude and have 120 degrees phase difference. Three similar coils having mutual geometrical angles of 120 degrees create the rotating magnetic field in this case. The ability of the three-phase system to create a rotating field, utilized in electric motors, is one of the main reasons why three-phase systems dominate the world's electrical power supply systems.\nSynchronous motors use DC-voltage-fed rotor windings, which lets the excitation of the machine be controlled\u2014and induction motors use short-circuited rotors (instead of a magnet) following the rotating magnetic field of a multicoiled stator. The short-circuited turns of the rotor develop eddy currents in the rotating field of the stator, and these currents in turn move the rotor by the Lorentz force.\nIn 1882, Nikola Tesla identified the concept of the rotating magnetic field. In 1885, Galileo Ferraris independently researched the concept. In 1888, Tesla gained U.S. Patent 381,968 for his work. Also in 1888, Ferraris published his research in a paper to the Royal Academy of Sciences in Turin.\n\n\n=== Hall effect ===\n\nThe charge carriers of a current-carrying conductor placed in a transverse magnetic field experience a sideways Lorentz force; this results in a charge separation in a direction perpendicular to the current and to the magnetic field. The resultant voltage in that direction is proportional to the applied magnetic field. This is known as the Hall effect.\nThe Hall effect is often used to measure the magnitude of a magnetic field. It is used as well to find the sign of the dominant charge carriers in materials such as semiconductors (negative electrons or positive holes).\n\n\n=== Magnetic circuits ===\n\nAn important use of H is in magnetic circuits where B = \u03bcH inside a linear material. Here, \u03bc is the magnetic permeability of the material. This result is similar in form to Ohm's law J = \u03c3E, where J is the current density, \u03c3 is the conductance and E is the electric field. Extending this analogy, the counterpart to the macroscopic Ohm's law (I = V\u2044R) is:\n\nwhere \n  \n    \n      \n        \u03a6\n        =\n        \u222b\n        \n          B\n        \n        \u22c5\n        \n          d\n        \n        \n          A\n        \n      \n    \n    {\\textstyle \\Phi =\\int \\mathbf {B} \\cdot \\mathrm {d} \\mathbf {A} }\n   is the magnetic flux in the circuit, \n  \n    \n      \n        F\n        =\n        \u222b\n        \n          H\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\textstyle F=\\int \\mathbf {H} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n   is the magnetomotive force applied to the circuit, and Rm is the reluctance of the circuit. Here the reluctance Rm is a quantity similar in nature to resistance for the flux. Using this analogy it is straightforward to calculate the magnetic flux of complicated magnetic field geometries, by using all the available techniques of circuit theory.\n\n\n=== Largest magnetic fields ===\nAs of October 2018, the largest magnetic field produced over a macroscopic volume outside a lab setting is 2.8 kT (VNIIEF in Sarov, Russia, 1998). As of October 2018, the largest magnetic field produced in a laboratory over a macroscopic volume was 1.2 kT by researchers at the University of Tokyo in 2018.\nThe largest magnetic fields produced in a laboratory occur in particle accelerators, such as RHIC, inside the collisions of heavy ions, where microscopic fields reach 1014 T. Magnetars have the strongest known magnetic fields of any naturally occurring object, ranging from 0.1 to 100 GT (108 to 1011 T).\n\n\n== History ==\n\n\n=== Early developments ===\nWhile magnets and some properties of magnetism were known to ancient societies, the research of magnetic fields began in 1269 when French scholar Petrus Peregrinus de Maricourt mapped out the magnetic field on the surface of a spherical magnet using iron needles. Noting the resulting field lines crossed at two points he named those points \"poles\" in analogy to Earth's poles. He also articulated the principle that magnets always have both a north and south pole, no matter how finely one slices them.Almost three centuries later, William Gilbert of Colchester replicated Petrus Peregrinus's work and was the first to state explicitly that Earth is a magnet.:\u200a34\u200a Published in 1600, Gilbert's work, De Magnete, helped to establish magnetism as a science.\n\n\n=== Mathematical development ===\n\nIn 1750, John Michell stated that magnetic poles attract and repel in accordance with an inverse square law:\u200a56\u200a Charles-Augustin de Coulomb experimentally verified this in 1785 and stated explicitly that north and south poles cannot be separated.:\u200a59\u200a Building on this force between poles, Sim\u00e9on Denis Poisson (1781\u20131840) created the first successful model of the magnetic field, which he presented in 1824.:\u200a64\u200a In this model, a magnetic H-field is produced by magnetic poles and magnetism is due to small pairs of north\u2013south magnetic poles.\nThree discoveries in 1820 challenged this foundation of magnetism. Hans Christian \u00d8rsted demonstrated that a current-carrying wire is surrounded by a circular magnetic field. Then Andr\u00e9-Marie Amp\u00e8re showed that parallel wires with currents attract one another if the currents are in the same direction and repel if they are in opposite directions.:\u200a87\u200a Finally, Jean-Baptiste Biot and F\u00e9lix Savart announced empirical results about the forces that a current-carrying long, straight wire exerted on a small magnet, determining the forces were inversely proportional to the perpendicular distance from the wire to the magnet.:\u200a86\u200a Laplace later deduced a law of force based on the differential action of a differential section of the wire, which became known as the Biot\u2013Savart law, as Laplace did not publish his findings.Extending these experiments, Amp\u00e8re published his own successful model of magnetism in 1825. In it, he showed the equivalence of electrical currents to magnets:\u200a88\u200a and proposed that magnetism is due to perpetually flowing loops of current instead of the dipoles of magnetic charge in Poisson's model. Further, Amp\u00e8re derived both Amp\u00e8re's force law describing the force between two currents and Amp\u00e8re's law, which, like the Biot\u2013Savart law, correctly described the magnetic field generated by a steady current. Also in this work, Amp\u00e8re introduced the term electrodynamics to describe the relationship between electricity and magnetism.:\u200a88\u201392\u200aIn 1831, Michael Faraday discovered electromagnetic induction when he found that a changing magnetic field generates an encircling electric field, formulating what is now known as Faraday's law of induction.:\u200a189\u2013192\u200a Later, Franz Ernst Neumann proved that, for a moving conductor in a magnetic field, induction is a consequence of Amp\u00e8re's force law.:\u200a222\u200a In the process, he introduced the magnetic vector potential, which was later shown to be equivalent to the underlying mechanism proposed by Faraday.:\u200a225\u200aIn 1850, Lord Kelvin, then known as William Thomson, distinguished between two magnetic fields now denoted H and B. The former applied to Poisson's model and the latter to Amp\u00e8re's model and induction.:\u200a224\u200a Further, he derived how H and B relate to each other and coined the term permeability.:\u200a245\u200aBetween 1861 and 1865, James Clerk Maxwell developed and published Maxwell's equations, which explained and united all of classical electricity and magnetism. The first set of these equations was published in a paper entitled On Physical Lines of Force in 1861. These equations were valid but incomplete. Maxwell completed his set of equations in his later 1865 paper A Dynamical Theory of the Electromagnetic Field and demonstrated the fact that light is an electromagnetic wave. Heinrich Hertz published papers in 1887 and 1888 experimentally confirming this fact.\n\n\n=== Modern developments ===\nIn 1887, Tesla developed an induction motor that ran on alternating current. The motor used polyphase current, which generated a rotating magnetic field to turn the motor (a principle that Tesla claimed to have conceived in 1882). Tesla received a patent for his electric motor in May 1888. In 1885, Galileo Ferraris independently researched rotating magnetic fields and subsequently published his research in a paper to the Royal Academy of Sciences in Turin, just two months before Tesla was awarded his patent, in March 1888.The twentieth century showed that classical electrodynamics is already consistent with special relativity, and extended classical electrodynamics to work with quantum mechanics. Albert Einstein, in his paper of 1905 that established relativity, showed that both the electric and magnetic fields are part of the same phenomena viewed from different reference frames. Finally, the emergent field of quantum mechanics was merged with electrodynamics to form quantum electrodynamics, which first formalized the notion that electromagnetic field energy is quantized in the form of photons.\n\n\n== See also ==\n\n\n=== General ===\nMagnetohydrodynamics \u2013 the study of the dynamics of electrically conducting fluids\nMagnetic hysteresis \u2013 application to ferromagnetism\nMagnetic nanoparticles \u2013 extremely small magnetic particles that are tens of atoms wide\nMagnetic reconnection \u2013 an effect that causes solar flares and auroras\nMagnetic scalar potential\nSI electromagnetism units \u2013 common units used in electromagnetism\nOrders of magnitude (magnetic field) \u2013 list of magnetic field sources and measurement devices from smallest magnetic fields to largest detected\nUpward continuation\nMoses Effect\n\n\n=== Mathematics ===\nMagnetic helicity \u2013 extent to which a magnetic field wraps around itself\n\n\n=== Applications ===\nDynamo theory \u2013 a proposed mechanism for the creation of the Earth's magnetic field\nHelmholtz coil \u2013 a device for producing a region of nearly uniform magnetic field\nMagnetic field viewing film \u2013 Film used to view the magnetic field of an area\nMagnetic pistol \u2013 a device on torpedoes or naval mines that detect the magnetic field of their target\nMaxwell coil \u2013 a device for producing a large volume of an almost constant magnetic field\nStellar magnetic field \u2013 a discussion of the magnetic field of stars\nTeltron tube \u2013 device used to display an electron beam and demonstrates effect of electric and magnetic fields on moving charges\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n Media related to Magnetic fields at Wikimedia Commons\nCrowell, B., \"Electromagnetism\".\nNave, R., \"Magnetic Field\". HyperPhysics.\n\"Magnetism\", The Magnetic Field (archived 9 July 2006). theory.uwinnipeg.ca.\nHoadley, Rick, \"What do magnetic fields look like?\" 17 July 2005.", "Gravitational_acceleration": "In physics, gravitational acceleration is the acceleration of an object in free fall within a vacuum (and thus without experiencing drag). This is the steady gain in speed caused exclusively by the force of gravitational attraction. All bodies accelerate in vacuum at the same rate, regardless of the masses or compositions of the bodies; the measurement and analysis of these rates is known as gravimetry.\nAt a fixed point on the surface, the magnitude of Earth's gravity results from combined effect of gravitation and the centrifugal force from Earth's rotation. At different points on Earth's surface, the free fall acceleration ranges from 9.764 to 9.834 m/s2 (32.03 to 32.26 ft/s2), depending on altitude, latitude, and longitude. A conventional standard value is defined exactly as 9.80665 m/s2 (32.1740 ft/s2). Locations of significant variation from this value are known as gravity anomalies. This does not take into account other effects, such as buoyancy or drag.\n\n\n== Relation to the Universal Law ==\nNewton's law of universal gravitation states that there is a gravitational force between any two masses that is equal in magnitude for each mass, and is aligned to draw the two masses toward each other.  The formula is:\n\n  \n    \n      \n        F\n        =\n        G\n        \n          \n            \n              \n                m\n                \n                  1\n                \n              \n              \n                m\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n         \n      \n    \n    {\\displaystyle F=G{\\frac {m_{1}m_{2}}{r^{2}}}\\ }\n  where \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle m_{1}}\n   and \n  \n    \n      \n        \n          m\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{2}}\n   are any two masses, \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is the gravitational constant, and \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the distance between the two point-like masses.\n\nUsing the integral form of Gauss's Law, this formula can be extended to any pair of objects of which one is far more massive than the other \u2014 like a planet relative to any man-scale artifact.  The distances between planets and between the planets and the Sun are (by many orders of magnitude) larger than the sizes of the sun and the planets.  In consequence both the sun and the planets can be considered as point masses and the same formula applied to planetary motions.  (As planets and natural satellites form pairs of comparable mass, the distance 'r' is measured from the common centers of mass of each pair rather than the direct total distance between planet centers.)\nIf one mass is much larger than the other, it is convenient to take it as observational reference and define it as source of a gravitational field of magnitude and orientation given by:\n\n  \n    \n      \n        \n          g\n        \n        =\n        \u2212\n        \n          \n            \n              G\n              M\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {g} =-{GM \\over r^{2}}\\mathbf {\\hat {r}} }\n  where \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is the mass of the field source (larger), and \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} }\n   is a unit vector directed from the field source to the sample (smaller) mass. The negative sign indicates that the force is attractive (points backward, toward the source).\nThen the attraction force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n   vector onto a sample mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   can be expressed as:\n\n  \n    \n      \n        \n          F\n        \n        =\n        m\n        \n          g\n        \n      \n    \n    {\\displaystyle \\mathbf {F} =m\\mathbf {g} }\n  Here \n  \n    \n      \n        \n          g\n        \n      \n    \n    {\\displaystyle \\mathbf {g} }\n   is the frictionless, free-fall acceleration sustained by the sampling mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   under the attraction of the gravitational source.\nIt is a vector oriented toward the field source, of magnitude measured in acceleration units. The gravitational acceleration vector depends only on how massive the field source \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is and on the distance 'r' to the sample mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  .  It does not depend on the magnitude of the small sample mass.\nThis model represents the \"far-field\" gravitational acceleration associated with a massive body.  When the dimensions of a body are not trivial compared to the distances of interest, the principle of superposition can be used for differential masses for an assumed density distribution throughout the body in order to get a more detailed model of the \"near-field\" gravitational acceleration.  For satellites in orbit, the far-field model is sufficient for rough calculations of altitude versus period, but not for precision estimation of future location after multiple orbits.\nThe more detailed models include (among other things) the bulging at the equator for the Earth, and irregular mass concentrations (due to meteor impacts) for the Moon. The Gravity Recovery and Climate Experiment (GRACE) mission launched in 2002 consists of two probes, nicknamed \"Tom\" and \"Jerry\", in polar orbit around the Earth measuring differences in the distance between the two probes in order to more precisely determine the gravitational field around the Earth, and to track changes that occur over time.  Similarly, the Gravity Recovery and Interior Laboratory mission from 2011-2012 consisted of two probes (\"Ebb\" and \"Flow\") in polar orbit around the Moon to more precisely determine the gravitational field for future navigational purposes, and to infer information about the Moon's physical makeup.\n\n\n== Comparative gravities of the Earth, Sun, Moon, and planets ==\nThe table below shows comparative gravitational accelerations at the surface of the Sun, the Earth's moon, each of the planets in the Solar System and their major moons, Ceres, Pluto, and Eris. For gaseous bodies, the \"surface\" is taken to mean visible surface: the cloud tops of the gas giants (Jupiter, Saturn, Uranus and Neptune), and the Sun's photosphere. The values in the table have not been de-rated for the centrifugal force effect of planet rotation (and cloud-top wind speeds for the gas giants) and therefore, generally speaking, are similar to the actual gravity that would be experienced near the poles. For reference the time it would take an object to fall 100 meters, the height of a skyscraper, is shown, along with the maximum speed reached. Air resistance is neglected.\n\n\n== General relativity ==\n\nIn Einstein's theory of general relativity, gravitation is an attribute of curved spacetime instead of being due to a force propagated between bodies. In Einstein's theory, masses distort spacetime in their vicinity, and other particles move in trajectories determined by the geometry of spacetime. The gravitational force is a fictitious force.  There is no gravitational acceleration, in that the proper acceleration and hence four-acceleration of objects in free fall are zero. Rather than undergoing an acceleration, objects in free fall travel along straight lines (geodesics) on the curved spacetime.\n\n\n== See also ==\nAir track\nGravimetry\nGravity of Earth\nGravitation of the Moon\nGravity of Mars\nNewton's law of universal gravitation\nStandard gravity\n\n\n== Notes ==\n\n\n== References ==", "Energy": "In physics, energy (from Ancient Greek  \u1f10\u03bd\u03ad\u03c1\u03b3\u03b5\u03b9\u03b1 (en\u00e9rgeia) 'activity') is the quantitative property that is transferred to a body or to a physical system, recognizable in the performance of work and in the form of heat and light. Energy is a conserved quantity\u2014the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The unit of measurement for energy in the International System of Units (SI) is the joule (J).\nCommon forms of energy include the kinetic energy of a moving object, the potential energy stored by an object (for instance due to its position in a field), the elastic energy stored in a solid object, chemical energy associated with chemical reactions, the radiant energy carried by electromagnetic radiation, and the internal energy contained within a thermodynamic system. All living organisms constantly take in and release energy.\nDue to mass\u2013energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. \nHuman civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The Earth's climate and ecosystems processes are driven by the energy the planet receives from the Sun (although a small amount is also contributed by geothermal energy).\n\n\n== Forms ==\n\nThe total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object \u2013 or the composite motion of the components of an object \u2013 and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may be stored in the field itself.\nWhile these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, the sum of translational and rotational kinetic and potential energy within a system is referred to as mechanical energy, whereas nuclear energy refers to the combined potentials within an atomic nucleus from either the nuclear force or the weak force, among other examples.\n\n\n== History ==\n\nThe word energy derives from the Ancient Greek: \u1f10\u03bd\u03ad\u03c1\u03b3\u03b5\u03b9\u03b1, romanized: energeia, lit.\u2009'activity, operation', which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.\nIn the late 17th century, Gottfried Leibniz proposed the idea of the Latin: vis viva, or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total vis viva was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the motions of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from vis viva only by a factor of two. Writing in the early 18th century, \u00c9milie du Ch\u00e2telet proposed the concept of conservation of energy in the marginalia of her French language translation of Newton's Principia Mathematica, which represented the first formulation of a conserved measurable quantity that was distinct from momentum, and which would later be called \"energy\".\nIn 1807, Thomas Young was possibly the first to use the term \"energy\" instead of vis viva, in its modern sense. Gustave-Gaspard Coriolis described \"kinetic energy\" in 1829 in its modern sense, and in 1853, William Rankine coined the term \"potential energy\". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.\nThese developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jo\u017eef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.\n\n\n== Units of measure ==\n\nIn 1843, James Prescott Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the \"Joule apparatus\": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.\nIn the International System of Units (SI), the unit of energy is the joule, named after Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British thermal units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.\nThe SI unit of energy rate (energy per unit time) is the watt, which is a joule per second. Thus, one joule is one watt-second, and 3600 joules equal one watt-hour. The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.\n\n\n== Scientific use ==\n\n\n=== Classical mechanics ===\n\nIn classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.\nWork, a function of energy, is force times distance.\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            C\n          \n        \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle W=\\int _{C}\\mathbf {F} \\cdot \\mathrm {d} \\mathbf {s} }\n  This says that the work (\n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  ) is equal to the line integral of the force F along a path C; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.\nThe total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy minus the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).\nNoether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.\n\n\n=== Chemistry ===\nIn the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular, or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is usually accompanied by a decrease, and sometimes an increase, of the total energy of the substances involved. Some energy may be transferred between the surroundings and the reactants in the form of heat or light; thus the products of a reaction have sometimes more but usually less energy than the reactants. A reaction is said to be exothermic or exergonic if the final state is lower on the energy scale than the initial state; in the less common case of endothermic reactions the situation is the reverse. Chemical reactions are usually not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at a given temperature T) is related to the activation energy E by the Boltzmann's population factor e\u2212E/kT; that is, the probability of a molecule to have energy greater than or equal to E at a given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction can be provided in the form of thermal energy.\n\n\n=== Biology ===\n\nIn biology, energy is an attribute of all biological systems, from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or organelle of a biological organism. Energy used in respiration is stored in substances such as carbohydrates (including sugars), lipids, and proteins stored by cells. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, using as a standard an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 \u00f7 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a \"feel\" for the use of a given amount of energy.Sunlight's radiant energy is also captured by plants as chemical potential energy in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into carbohydrates, lipids, proteins and oxygen. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark in a forest fire, or it may be made available more slowly for animal or human metabolism when organic molecules are ingested and catabolism is triggered by enzyme action.\nAll living creatures rely on an external source of energy to be able to grow and reproduce \u2013 radiant energy from the Sun in the case of green plants and chemical energy (in some form) in the case of animals. The daily 1500\u20132000 Calories (6\u20138 MJ) recommended for a human adult are taken as food molecules, mostly carbohydrates and fats, of which glucose (C6H12O6) and stearin (C57H110O6) are convenient examples. The food molecules are oxidized to carbon dioxide and water in the mitochondria\n\nand some of the energy is used to convert ADP into ATP:\n\nThe rest of the chemical energy of the carbohydrate or fat are converted into heat: the ATP is used as a sort of \"energy currency\", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:\ngain in kinetic energy of a sprinter during a 100 m race: 4 kJ\ngain in gravitational potential energy of a 150 kg weight lifted through 2 metres: 3 kJ\nDaily food intake of a normal adult: 6\u20138 MJIt would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy); most machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe (\"the surroundings\"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology. As an example, to take just the first step in the food chain: of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.\n\n\n=== Earth sciences ===\nIn geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations in our atmosphere brought about by solar energy.\nSunlight is the main input to Earth's energy budget which accounts for its temperature and climate stability. Sunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example when) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives most weather phenomena, save a few exceptions, like those generated by volcanic events for example. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, suddenly give up some of their thermal energy to power a few days of violent air movement.\nIn a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may later be transformed into active kinetic energy during landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars (which created these atoms).\n\n\n=== Cosmology ===\nIn cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.\n\n\n=== Quantum mechanics ===\n\nIn quantum mechanics, energy is defined in terms of the energy operator\n(Hamiltonian) as a time derivative of the wave function. The Schr\u00f6dinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schr\u00f6dinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schr\u00f6dinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: \n  \n    \n      \n        E\n        =\n        h\n        \u03bd\n      \n    \n    {\\displaystyle E=h\\nu }\n   (where \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is the Planck constant and \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.\n\n\n=== Relativity ===\nWhen calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically \u2013 using Lorentz transformations instead of Newtonian mechanics \u2013 Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:\n\nwhere\n\nm0 is the rest mass of the body,\nc is the speed of light in vacuum,\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}}\n   is the rest energy.For example, consider electron\u2013positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles. This is a reversible process \u2013 the inverse process is called pair creation \u2013 in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.\nIn general relativity, the stress\u2013energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.Energy and mass are manifestations of one and the same underlying physical property of a system. This property is responsible for the inertia and strength of gravitational interaction of the system (\"mass manifestations\"), and is also responsible for the potential ability of the system to perform work or heating (\"energy manifestations\"), subject to the limitations of other physical laws.\nIn classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy\u2013momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of spacetime (= boosts).\n\n\n== Transformation ==\n\nEnergy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery (from chemical energy to electric energy), a dam (from gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator), and a heat engine (from heat to work).\nExamples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. The Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that itself (since it still contains the same total energy even in different forms) but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.\nThere are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.\nEnergy transformations in the universe over time are characterized by various kinds of potential energy, that has been available since the Big Bang, being \"released\" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae to \"store\" energy in the creation of heavy isotopes (such as uranium and thorium), and nuclear decay, a process in which energy is released that was originally stored in these heavy elements, before they were incorporated into the Solar System and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic and thermal energy in a very short time.\nYet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at its maximum. At its lowest point the kinetic energy is at its maximum and is equal to the decrease in potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.\nEnergy is also transferred from potential energy (\n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle E_{p}}\n  ) to kinetic energy (\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n  ) and then back to potential energy constantly. This is referred to as conservation of energy. In this isolated system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:\n\nThe equation can then be simplified further since \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        =\n        m\n        g\n        h\n      \n    \n    {\\displaystyle E_{p}=mgh}\n   (mass times acceleration due to gravity times the height) and \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\textstyle E_{k}={\\frac {1}{2}}mv^{2}}\n   (half mass times velocity squared). Then the total amount of energy can be found by adding \n  \n    \n      \n        \n          E\n          \n            p\n          \n        \n        +\n        \n          E\n          \n            k\n          \n        \n        =\n        \n          E\n          \n            total\n          \n        \n      \n    \n    {\\displaystyle E_{p}+E_{k}=E_{\\text{total}}}\n  .\n\n\n=== Conservation of energy and mass in transformation ===\nEnergy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula E = mc\u00b2, derived by Albert Einstein (1905) quantifies the relationship between relativistic mass and energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J.J. Thomson (1881), Henri Poincar\u00e9 (1900), Friedrich Hasen\u00f6hrl (1904) and others (see Mass-energy equivalence#History for further information).\nPart of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since \n  \n    \n      \n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle c^{2}}\n   is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~\n  \n    \n      \n        9\n        \u00d7\n        \n          10\n          \n            16\n          \n        \n      \n    \n    {\\displaystyle 9\\times 10^{16}}\n   joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics. Often, however, the complete conversion of matter (such as atoms) to non-matter (such as photons) is forbidden by conservation laws.\n\n\n=== Reversible and non-reversible transformations ===\nThermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as thermal energy and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomization in a crystal).\nAs the universe evolves with time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or as other kinds of increases in disorder). This has led to the hypothesis of the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), continues to decrease.\n\n\n== Conservation of energy ==\n\nThe fact that energy can be neither created nor destroyed is called the law of conservation of energy. In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out as work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.\nRichard Feynman said during a 1961 lecture:\nThere is a fact, or if you wish, a law, governing all natural phenomena that are known to date. There is no known exception to this law \u2013 it is exact so far as we know. The law is called the conservation of energy. It states that there is a certain quantity, which we call energy, that does not change in manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same.\nMost kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle \u2013 it is impossible to define the exact amount of energy during any definite time interval (though this is practically significant only for very short time intervals). The uncertainty principle should not be confused with energy conservation \u2013 rather it provides mathematical limits to which energy can in principle be defined and measured.\nEach of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appear as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.\nIn quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by\n\n  \n    \n      \n        \u0394\n        E\n        \u0394\n        t\n        \u2265\n        \n          \n            \u210f\n            2\n          \n        \n      \n    \n    {\\displaystyle \\Delta E\\Delta t\\geq {\\frac {\\hbar }{2}}}\n  which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since H and t are not dynamically conjugate variables, neither in classical nor in quantum mechanics).\nIn particle physics, this inequality permits a qualitative understanding of virtual particles, which carry momentum. The exchange of virtual particles with real particles is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons are also responsible for the electrostatic interaction between electric charges (which results in Coulomb's law), for spontaneous radiative decay of excited atomic and nuclear states, for the Casimir force, for the Van der Waals force and some other observable phenomena.\n\n\n== Energy transfer ==\n\n\n=== Closed systems ===\nEnergy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, tidal interactions, and the conductive transfer of thermal energy.\nEnergy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:\n\nwhere \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is the amount of energy transferred, \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n    represents the work done on or by the system, and \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   represents the heat flow into or out of the system. As a simplification, the heat term, \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  , can sometimes be ignored, especially for fast processes involving gases, which are poor conductors of heat, or when the thermal efficiency of the transfer is high. For such adiabatic processes,\n\nThis simplified equation is the one used to define the joule, for example.\n\n\n=== Open systems ===\nBeyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (this process is illustrated by injection of an air-fuel mixture into a car engine, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by \n  \n    \n      \n        \n          E\n          \n            matter\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{matter}}}\n  , one may write\n\n\n== Thermodynamics ==\n\n\n=== Internal energy ===\nInternal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.\n\n\n=== First law of thermodynamics ===\nThe first law of thermodynamics asserts that the total energy of a system and its surroundings (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a gain in energy signified by a positive quantity) is given as\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        T\n        \n          d\n        \n        S\n        \u2212\n        P\n        \n          d\n        \n        V\n        \n      \n    \n    {\\displaystyle \\mathrm {d} E=T\\mathrm {d} S-P\\mathrm {d} V\\,}\n  ,where the first term on the right is the heat transferred into the system, expressed in terms of temperature T and entropy S (in which entropy increases and its change dS is positive when heat is added to the system), and the last term on the right hand side is identified as work done on the system, where pressure is P and volume V (the negative sign results since compression of the system requires work to be done on it and so the volume change, dV, is negative when work is done on the system).\nThis equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and PV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a closed system is expressed in a general form by\n\n  \n    \n      \n        \n          d\n        \n        E\n        =\n        \u03b4\n        Q\n        +\n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\mathrm {d} E=\\delta Q+\\delta W}\n  where \n  \n    \n      \n        \u03b4\n        Q\n      \n    \n    {\\displaystyle \\delta Q}\n   is the heat supplied to the system and \n  \n    \n      \n        \u03b4\n        W\n      \n    \n    {\\displaystyle \\delta W}\n   is the work applied to the system.\n\n\n=== Equipartition of energy ===\nThe energy of a mechanical harmonic oscillator (a mass on a spring) is alternately kinetic and potential energy. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over a whole cycle, or over many cycles, average energy is equally split between kinetic and potential. This is an example of the equipartition principle: the total energy of a system with many degrees of freedom is equally split among all available degrees of freedom, on average.\nThis principle is vitally important to understanding the behavior of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is part of the second law of thermodynamics. The second law of thermodynamics is simple only for systems which are near or in a physical equilibrium state. For non-equilibrium systems, the laws governing the systems' behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way as to maximize their entropy production.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n=== Journals ===\nThe Journal of Energy History / Revue d'histoire de l'\u00e9nergie (JEHRHE), 2018\u2013 \n\n\n== External links ==\n\nEnergy at Curlie\nDifferences between Heat and Thermal energy Archived 2016-08-27 at the Wayback Machine \u2013 BioCab", "Mechanical_energy": "In  physical sciences, mechanical energy is the sum of potential energy and kinetic energy. The principle of conservation of mechanical energy states that if an isolated system is subject only to conservative forces, then the mechanical energy is constant. If an object moves in the opposite direction of a conservative net force, the potential energy will increase; and if the speed (not the velocity) of the object changes, the kinetic energy of the object also changes. In all real systems, however, nonconservative forces, such as frictional forces, will be present, but if they are of negligible magnitude, the mechanical energy changes little and its conservation is a useful approximation. In elastic collisions, the kinetic energy is conserved, but in inelastic collisions some mechanical energy may be converted into thermal energy. The equivalence between lost mechanical energy  and an increase in temperature was discovered by James Prescott Joule.\nMany devices are used to convert mechanical energy to or from other forms of energy, e.g. an electric motor converts electrical energy to mechanical energy, an electric generator converts mechanical energy into electrical energy and a heat engine converts heat to mechanical energy.\n\n\n== General ==\nEnergy is a scalar quantity and the mechanical energy of a system is the sum of the potential energy (which is measured by the position of the parts of the system) and the kinetic energy (which is also called the energy of motion):\nThe potential energy, U, depends on the position of an object subjected to gravity or some other conservative force. The gravitational potential energy of an object is equal to the weight W of the object multiplied by the height h of the object's center of gravity relative to an arbitrary datum:\n\nThe potential energy of an object can be defined as the object's ability to do work and is increased as the object is moved in the opposite direction of the direction of the force. If F represents the conservative force and x the position, the potential energy of the force between the two positions x1 and x2 is defined as the negative integral of F from x1 to x2:\nThe kinetic energy, K, depends on the speed of an object and is the ability of a moving object to do work on other objects when it collides with them. It is defined as one half the product of the object's mass with the square of its speed, and the total kinetic energy of a system of objects is the sum of the kinetic energies of the respective objects:\nThe principle of conservation of mechanical energy states that if a body or system is subjected only to conservative forces, the mechanical energy of that body or system remains constant. The difference between a conservative and a non-conservative force is that when a conservative force moves an object from one point to another, the work done by the conservative force is independent of the path. On the contrary, when a non-conservative force acts upon an object, the work done by the non-conservative force is dependent of the path.\n\n\n== Conservation of mechanical energy ==\n\nAccording to the principle of conservation of mechanical energy, the mechanical energy of an isolated system remains constant in time, as long as the system is free of friction and other non-conservative forces. In any real situation, frictional forces and other non-conservative forces are present, but in many cases their effects on the system are so small that the principle of conservation of mechanical energy can be used as a fair approximation. Though energy cannot be created or destroyed, it can be converted to another form of energy.\n\n\n=== Swinging pendulum ===\n\nIn a mechanical system like a swinging pendulum subjected to the conservative gravitational force where frictional forces like air drag and friction at the pivot are negligible, energy passes back and forth between kinetic and potential energy but never leaves the system. The pendulum reaches greatest kinetic energy and least potential energy when in the vertical position, because it will have the greatest speed and be nearest the Earth at this point. On the other hand, it will have its least kinetic energy and greatest potential energy at the extreme positions of its swing, because it has zero speed and is farthest from Earth at these points. However, when taking the frictional forces into account, the system loses mechanical energy with each swing because of the negative work done on the pendulum by these non-conservative forces.\n\n\n=== Irreversibilities ===\n\nThat the loss of mechanical energy in a system always resulted in an increase of the system's temperature has been known for a long time, but it was the amateur physicist James Prescott Joule who first experimentally demonstrated how a certain amount of work done against friction resulted in a definite quantity of heat which should be conceived as the random motions of the particles that comprise matter. This equivalence between mechanical energy and heat is especially important when considering colliding objects. In an elastic collision, mechanical energy is conserved \u2013 the sum of the mechanical energies of the colliding objects is the same before and after the collision. After an inelastic collision, however, the mechanical energy of the system will have changed. Usually, the mechanical energy before the collision is greater than the mechanical energy after the collision. In inelastic collisions, some of the mechanical energy of the colliding objects is transformed into kinetic energy of the constituent particles. This increase in kinetic energy of the constituent particles is perceived as an increase in temperature. The collision can be described by saying some of the mechanical energy of the colliding objects has been converted into an equal amount of heat. Thus, the total energy of the system remains unchanged though the mechanical energy of the system has reduced.\n\n\n=== Satellite ===\n\nA satellite of mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   at a distance \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   from the centre of Earth possesses both kinetic energy, \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  , (by virtue of its motion) and gravitational potential energy, \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  , (by virtue of its position within the Earth's gravitational field; Earth's mass is \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  ).\nHence, mechanical energy \n  \n    \n      \n        \n          E\n          \n            mechanical\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{mechanical}}}\n   of the satellite-Earth system is given by\n\nIf the satellite is in circular orbit, the energy conservation equation can be further simplified into\n\nsince in circular motion, Newton's 2nd Law of motion can be taken to be\n\n\n== Conversion ==\nToday, many technological devices convert mechanical energy into other forms of energy or vice versa. These devices can be placed in these categories:\n\nAn electric motor converts electrical energy into mechanical energy.\nA generator converts mechanical energy into electrical energy.\nA hydroelectric powerplant converts the mechanical energy of water in a storage dam into electrical energy.\nAn internal combustion engine is a heat engine that obtains mechanical energy from chemical energy by burning fuel. From this mechanical energy, the internal combustion engine often generates electricity.\nA steam engine converts the heat energy of steam into mechanical energy.\nA turbine converts the kinetic energy of a stream of gas or liquid into mechanical energy.\n\n\n== Distinction from other types ==\nThe classification of energy into different types often follows the boundaries of the fields of study in the natural sciences.\n\nChemical energy is the kind of potential energy \"stored\" in chemical bonds and is studied in chemistry.\nNuclear energy is energy stored in interactions between the particles in the atomic nucleus and is studied in nuclear physics.\nElectromagnetic energy is in the form of electric charges, magnetic fields, and photons. It is studied in electromagnetism.\nVarious forms of energy in quantum mechanics; e.g., the energy levels of electrons in an atom.\n\n\n== References ==\nNotes\n\nCitations\n\nBibliography\n\nBrodie, David; Brown, Wendy; Heslop, Nigel; Ireson, Gren; Williams, Peter (1998).  Terry Parkin (ed.). Physics. Addison Wesley Longman Limited. ISBN 978-0-582-28736-5.\nJain, Mahesh C. (2009). Textbook of Engineering Physics, Part I. New Delhi: PHI Learning Pvt. Ltd. ISBN 978-81-203-3862-3. Retrieved 2011-08-25.\nNewton, Isaac (1999).  I. Bernard Cohen; Anne Miller Whitman (eds.). The Principia: mathematical principles of natural philosophy. United States of America: University of California Press. ISBN 978-0-520-08816-0.", "Physics": "Physics is the natural science of matter, involving the study of matter, its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force. Physics is one of the most fundamental scientific disciplines, with its main goal being to understand how the universe behaves. A scientist who specializes in the field of physics is called a physicist.\nPhysics is one of the oldest academic disciplines and, through its inclusion of astronomy, perhaps the oldest. Over much of the past two millennia, physics, chemistry, biology, and certain branches of mathematics were a part of natural philosophy, but during the Scientific Revolution in the 17th century these natural sciences emerged as unique research endeavors in their own right. Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms studied by other sciences and suggest new avenues of research in these and other academic disciplines such as mathematics and philosophy.\nAdvances in physics often enable advances in new technologies. For example, advances in the understanding of electromagnetism, solid-state physics, and nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons; advances in thermodynamics led to the development of industrialization; and advances in mechanics inspired the development of calculus.\n\n\n== History ==\n\nThe word \"physics\" originates from Ancient Greek: \u03c6\u03c5\u03c3\u03b9\u03ba\u03ae (\u1f10\u03c0\u03b9\u03c3\u03c4\u03ae\u03bc\u03b7), romanized: physik\u1e17 (epist\u1e17m\u0113), meaning \"knowledge of nature\".\n\n\n=== Ancient astronomy ===\n\nAstronomy is one of the oldest natural sciences. Early civilizations dating back before 3000 BCE, such as the Sumerians, ancient Egyptians, and the Indus Valley Civilisation, had a predictive knowledge and a basic awareness of the motions of the Sun, Moon, and stars. The stars and planets, believed to represent gods, were often worshipped. While the explanations for the observed positions of the stars were often unscientific and lacking in evidence, these early observations laid the foundation for later astronomy, as the stars were found to traverse great circles across the sky, which could not explain the positions of the planets.\nAccording to Asger Aaboe, the origins of Western astronomy can be found in Mesopotamia, and all Western efforts in the exact sciences are descended from late Babylonian astronomy. Egyptian astronomers left monuments showing knowledge of the constellations and the motions of the celestial bodies, while Greek poet Homer wrote of various celestial objects in his Iliad and Odyssey; later Greek astronomers provided names, which are still used today, for most constellations visible from the Northern Hemisphere.\n\n\n=== Natural philosophy ===\n\nNatural philosophy has its origins in Greece during the Archaic period (650 BCE \u2013 480 BCE), when pre-Socratic philosophers like Thales rejected non-naturalistic explanations for natural phenomena and proclaimed that every event had a natural cause. They proposed ideas verified by reason and observation, and many of their hypotheses proved successful in experiment; for example, atomism was found to be correct approximately 2000 years after it was proposed by Leucippus and his pupil Democritus.\n\n\n=== Medieval European and Islamic ===\n\nThe Western Roman Empire fell in the fifth century, and this resulted in a decline in intellectual pursuits in the western part of Europe. By contrast, the Eastern Roman Empire (also known as the Byzantine Empire) resisted the attacks from the barbarians, and continued to advance various fields of learning, including physics.In the sixth century, Isidore of Miletus created an important compilation of Archimedes' works that are copied in the Archimedes Palimpsest.\n\nIn sixth-century Europe John Philoponus, a Byzantine scholar, questioned Aristotle's teaching of physics and noted its flaws. He introduced the theory of impetus. Aristotle's physics was not scrutinized until Philoponus appeared; unlike Aristotle, who based his physics on verbal argument, Philoponus relied on observation. On Aristotle's physics Philoponus wrote:But this is completely erroneous, and our view may be corroborated by actual observation more effectively than by any sort of verbal argument. For if you let fall from the same height two weights of which one is many times as heavy as the other, you will see that the ratio of the times required for the motion does not depend on the ratio of the weights, but that the difference in time is a very small one. And so, if the difference in the weights is not considerable, that is, of one is, let us say, double the other, there will be no difference, or else an imperceptible difference, in time, though the difference in weight is by no means negligible, with one body weighing twice as much as the otherPhiloponus' criticism of Aristotelian principles of physics served as an inspiration for Galileo Galilei ten centuries later, during the Scientific Revolution. Galileo cited Philoponus substantially in his works when arguing that Aristotelian physics was flawed. In the 1300s Jean Buridan, a teacher in the faculty of arts at the University of Paris, developed the concept of impetus. It was a step toward the modern ideas of inertia and momentum.Islamic scholarship inherited Aristotelian physics from the Greeks and during the Islamic Golden Age developed it further, especially placing emphasis on observation and a priori reasoning, developing early forms of the scientific method.\nAlthough Aristotle\u2019s principles of physics was criticized, it is important to identify his the evidence he based his views off of.  When thinking of the history of science and math, it is notable to acknowledge the contributions made by older scientists. Aristotle\u2019s science was the backbone of the science we learn in schools today. Aristotle published many biological works including The Parts of Animals, in which he discusses both biological science and natural science as well. It is also integral to mention the role Aristotle had in the progression of physics and metaphysics and how his beliefs and findings are still being taught in science classes to this day. The explanations that Aristotle gives for his findings are also very simple. When thinking of the elements, Aristotle believed that each element (earth, fire, water, air) had its own natural place. Meaning that because of the density of these elements, they will revert back to their own specific place in the atmosphere. So, because of their weights, fire would be at the very top, air right underneath fire, then water, then lastly earth. He also stated that when a small amount of one element enters the natural place of another, the less abundant element will automatically go into its own natural place. For example, if there is a fire on the ground, if you pay attention, the flames go straight up into the air as an attempt to go back into its natural place where it belongs. Aristotle called his metaphysics \"first philosophy\" and characterized it as the study of \"being as being\". Aristotle defined the paradigm of motion as a being or entity encompassing different areas in the same body. Meaning that if a person is at a certain location (A) they can move to a new location (B) and still take up the same amount of space. This is involved with Aristotle\u2019s belief that motion is a continuum. In terms of matter, Aristotle believed that the change in category (ex. place) and quality (ex. color) of an object is defined as \"alteration\". But, a change in substance is a change in matter. This is also very close to our idea of matter today. \n\nHe also devised his own laws of motion that include 1) heavier objects will fall faster, the speed being proportional to the weight and 2) the speed of the object that is falling depends inversely on the density object it is falling through (ex. density of air). He also stated that, when it comes to violent motion (motion of an object when a force is applied to it by a second object) that the speed that object moves, will only be as fast or strong as the measure of force applied to it. This is also seen in the rules of velocity and force that is taught in physics classes today. These rules are not necessarily what we see in our physics today but, they are very similar. It is evident that these rules were the backbone for other scientists to come revise and edit his beliefs.\nThe most notable innovations were in the field of optics and vision, which came from the works of many scientists like Ibn Sahl, Al-Kindi, Ibn al-Haytham, Al-Farisi and Avicenna. The most notable work was The Book of Optics (also known as Kit\u0101b al-Man\u0101\u1e93ir), written by Ibn al-Haytham, in which he conclusively disproved the ancient Greek idea about vision and came up with a new theory. In the book, he presented a study of the phenomenon of the camera obscura (his thousand-year-old version of the pinhole camera) and delved further into the way the eye itself works. Using dissections and the knowledge of previous scholars, he was able to begin to explain how light enters the eye. He asserted that the light ray is focused, but the actual explanation of how light projected to the back of the eye had to wait until 1604. His Treatise on Light explained the camera obscura, hundreds of years before the modern development of photography.The seven-volume Book of Optics (Kitab al-Manathir) hugely influenced thinking across disciplines from the theory of visual perception to the nature of perspective in medieval art, in both the East and the West, for more than 600 years. Many later European scholars and fellow polymaths, from Robert Grosseteste and Leonardo da Vinci to Ren\u00e9 Descartes, Johannes Kepler and Isaac Newton, were in his debt. Indeed, the influence of Ibn al-Haytham's Optics ranks alongside that of Newton's work of the same title, published 700 years later.\nThe translation of The Book of Optics had a huge impact on Europe. From it, later European scholars were able to build devices that replicated those Ibn al-Haytham had built and understand the way light works. From this, important inventions such as eyeglasses, magnifying glasses, telescopes, and cameras were developed.\n\n\n=== Classical ===\n\nPhysics became a separate science when early modern Europeans used experimental and quantitative methods to discover what are now considered to be the laws of physics.Major developments in this period include the replacement of the geocentric model of the Solar System with the heliocentric Copernican model, the laws governing the motion of planetary bodies (determined by Kepler between 1609 and 1619), Galileo's pioneering work on telescopes and observational astronomy in the 16th and 17th Centuries, and Isaac Newton's discovery and unification of the laws of motion and universal gravitation (that would come to bear his name). Newton also developed calculus, the mathematical study of continuous change, which provided new mathematical methods for solving physical problems.The discovery of new laws in thermodynamics, chemistry, and electromagnetics resulted from research efforts during the Industrial Revolution as energy needs increased. The laws comprising classical physics remain very widely used for objects on everyday scales travelling at non-relativistic speeds, since they provide a very close approximation in such situations, and theories such as quantum mechanics and the theory of relativity simplify to their classical equivalents at such scales. Inaccuracies in classical mechanics for very small objects and very high velocities led to the development of modern physics in the 20th century.\n\n\n=== Modern ===\n\nModern physics began in the early 20th century with the work of Max Planck in quantum theory and Albert Einstein's theory of relativity. Both of these theories came about due to inaccuracies in classical mechanics in certain situations. Classical mechanics predicted that the speed of light depends on the motion of the observer, which could not be resolved with the constant speed predicted by Maxwell's equations of electromagnetism. This discrepancy was corrected by Einstein's theory of special relativity, which replaced classical mechanics for fast-moving bodies and allowed for a constant speed of light. Black-body radiation provided another problem for classical physics, which was corrected when Planck proposed that the excitation of material oscillators is possible only in discrete steps proportional to their frequency. This, along with the photoelectric effect and a complete theory predicting discrete energy levels of electron orbitals, led to the theory of quantum mechanics improving on classical physics at very small scales.Quantum mechanics would come to be pioneered by Werner Heisenberg, Erwin Schr\u00f6dinger and Paul Dirac. From this early work, and work in related fields, the Standard Model of particle physics was derived. Following the discovery of a particle with properties consistent with the Higgs boson at CERN in 2012, all fundamental particles predicted by the standard model, and no others, appear to exist; however, physics beyond the Standard Model, with theories such as supersymmetry, is an active area of research. Areas of mathematics in general are important to this field, such as the study of probabilities and groups.\n\n\n== Philosophy ==\n\nIn many ways, physics stems from ancient Greek philosophy. From Thales' first attempt to characterize matter, to Democritus' deduction that matter ought to reduce to an invariant state the Ptolemaic astronomy of a crystalline firmament, and Aristotle's book Physics (an early book on physics, which attempted to analyze and define motion from a philosophical point of view), various Greek philosophers advanced their own theories of nature. Physics was known as natural philosophy until the late 18th century.By the 19th century, physics was realized as a discipline distinct from philosophy and the other sciences. Physics, as with the rest of science, relies on philosophy of science and its \"scientific method\" to advance our knowledge of the physical world. The scientific method employs a priori reasoning as well as a posteriori reasoning and the use of Bayesian inference to measure the validity of a given theory.The development of physics has answered many questions of early philosophers but has also raised new questions. Study of the philosophical issues surrounding physics, the philosophy of physics, involves issues such as the nature of space and time, determinism, and metaphysical outlooks such as empiricism, naturalism and realism.Many physicists have written about the philosophical implications of their work, for instance Laplace, who championed causal determinism, and Erwin Schr\u00f6dinger, who wrote on quantum mechanics. The mathematical physicist Roger Penrose has been called a Platonist by Stephen Hawking, a view Penrose discusses in his book, The Road to Reality. Hawking referred to himself as an \"unashamed reductionist\" and took issue with Penrose's views.\n\n\n== Core theories ==\n\nPhysics deals with a wide variety of systems, although certain theories are used by all physicists. Each of these theories was experimentally tested numerous times and found to be an adequate approximation of nature. For instance, the theory of classical mechanics accurately describes the motion of objects, provided they are much larger than atoms and moving at a speed much less than the speed of light. These theories continue to be areas of active research today. Chaos theory, a remarkable aspect of classical mechanics, was discovered in the 20th century, three centuries after the original formulation of classical mechanics by Newton (1642\u20131727).\nThese central theories are important tools for research into more specialized topics, and any physicist, regardless of their specialization, is expected to be literate in them. These include classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, and special relativity.\n\n\n=== Classical ===\n\nClassical physics includes the traditional branches and topics that were recognized and well-developed before the beginning of the 20th century\u2014classical mechanics, acoustics, optics, thermodynamics, and electromagnetism. Classical mechanics is concerned with bodies acted on by forces and bodies in motion and may be divided into statics (study of the forces on a body or bodies not subject to an acceleration), kinematics (study of motion without regard to its causes), and dynamics (study of motion and the forces that affect it); mechanics may also be divided into solid mechanics and fluid mechanics (known together as continuum mechanics), the latter include such branches as hydrostatics, hydrodynamics, aerodynamics, and pneumatics. Acoustics is the study of how sound is produced, controlled, transmitted and received. Important modern branches of acoustics include ultrasonics, the study of sound waves of very high frequency beyond the range of human hearing; bioacoustics, the physics of animal calls and hearing, and electroacoustics, the manipulation of audible sound waves using electronics.Optics, the study of light, is concerned not only with visible light but also with infrared and ultraviolet radiation, which exhibit all of the phenomena of visible light except visibility, e.g., reflection, refraction, interference, diffraction, dispersion, and polarization of light. Heat is a form of energy, the internal energy possessed by the particles of which a substance is composed; thermodynamics deals with the relationships between heat and other forms of energy. Electricity and magnetism have been studied as a single branch of physics since the intimate connection between them was discovered in the early 19th century; an electric current gives rise to a magnetic field, and a changing magnetic field induces an electric current. Electrostatics deals with electric charges at rest, electrodynamics with moving charges, and magnetostatics with magnetic poles at rest.\n\n\n=== Modern ===\n\nClassical physics is generally concerned with matter and energy on the normal scale of observation, while much of modern physics is concerned with the behavior of matter and energy under extreme conditions or on a very large or very small scale. For example, atomic and nuclear physics study matter on the smallest scale at which chemical elements can be identified. The physics of elementary particles is on an even smaller scale since it is concerned with the most basic units of matter; this branch of physics is also known as high-energy physics because of the extremely high energies necessary to produce many types of particles in particle accelerators. On this scale, ordinary, commonsensical notions of space, time, matter, and energy are no longer valid.The two chief theories of modern physics present a different picture of the concepts of space, time, and matter from that presented by classical physics. Classical mechanics approximates nature as continuous, while quantum theory is concerned with the discrete nature of many phenomena at the atomic and subatomic level and with the complementary aspects of particles and waves in the description of such phenomena. The theory of relativity is concerned with the description of phenomena that take place in a frame of reference that is in motion with respect to an observer; the special theory of relativity is concerned with motion in the absence of gravitational fields and the general theory of relativity with motion and its connection with gravitation. Both quantum theory and the theory of relativity find applications in many areas of modern physics.\n\n\n==== Fundamental concepts in modern physics ====\nCausality\nCovariance\nAction\nPhysical field\nSymmetry\nPhysical interaction\nStatistical ensemble\nQuantum\nWave\nParticle\n\n\n=== Difference ===\n\nWhile physics itself aims to discover universal laws, its theories lie in explicit domains of applicability.\n\nLoosely speaking, the laws of classical physics accurately describe systems whose important length scales are greater than the atomic scale and whose motions are much slower than the speed of light. Outside of this domain, observations do not match predictions provided by classical mechanics. Einstein contributed the framework of special relativity, which replaced notions of absolute time and space with spacetime and allowed an accurate description of systems whose components have speeds approaching the speed of light. Planck, Schr\u00f6dinger, and others introduced quantum mechanics, a probabilistic notion of particles and interactions that allowed an accurate description of atomic and subatomic scales. Later, quantum field theory unified quantum mechanics and special relativity. General relativity allowed for a dynamical, curved spacetime, with which highly massive systems and the large-scale structure of the universe can be well-described. General relativity has not yet been unified with the other fundamental descriptions; several candidate theories of quantum gravity are being developed.\n\n\n== Relation to other fields ==\n\n\n=== Prerequisites ===\nMathematics provides a compact and exact language used to describe the order in nature. This was noted and advocated by Pythagoras, Plato, Galileo, and Newton.\nPhysics uses mathematics to organise and formulate experimental results. From those results, precise or estimated solutions are obtained, or quantitative results, from which new predictions can be made and experimentally confirmed or negated. The results from physics experiments are numerical data, with their units of measure and estimates of the errors in the measurements. Technologies based on mathematics, like computation have made computational physics an active area of research.\n\nOntology is a prerequisite for physics, but not for mathematics. It means physics is ultimately concerned with descriptions of the real world, while mathematics is concerned with abstract patterns, even beyond the real world. Thus physics statements are synthetic, while mathematical statements are analytic. Mathematics contains hypotheses, while physics contains theories. Mathematics statements have to be only logically true, while predictions of physics statements must match observed and experimental data.\nThe distinction is clear-cut, but not always obvious. For example, mathematical physics is the application of mathematics in physics. Its methods are mathematical, but its subject is physical. The problems in this field start with a \"mathematical model of a physical situation\" (system) and a \"mathematical description of a physical law\" that will be applied to that system. Every mathematical statement used for solving has a hard-to-find physical meaning. The final mathematical solution has an easier-to-find meaning, because it is what the solver is looking for.Pure physics is a branch of fundamental science (also called basic science). Physics is also called \"the fundamental science\" because all branches of natural science like chemistry, astronomy, geology, and biology are constrained by laws of physics. Similarly, chemistry is often called the central science because of its role in linking the physical sciences. For example, chemistry studies properties, structures, and reactions of matter (chemistry's focus on the molecular and atomic scale distinguishes it from physics). Structures are formed because particles exert electrical forces on each other, properties include physical characteristics of given substances, and reactions are bound by laws of physics, like conservation of energy, mass, and charge. Physics is applied in industries like engineering and medicine.\n\n\n=== Application and influence ===\n\nApplied physics is a general term for physics research, which is intended for a particular use. An applied physics curriculum usually contains a few classes in an applied discipline, like geology or electrical engineering. It usually differs from engineering in that an applied physicist may not be designing something in particular, but rather is using physics or conducting physics research with the aim of developing new technologies or solving a problem.\nThe approach is similar to that of applied mathematics. Applied physicists use physics in scientific research. For instance, people working on accelerator physics might seek to build better particle detectors for research in theoretical physics.\nPhysics is used heavily in engineering. For example, statics, a subfield of mechanics, is used in the building of bridges and other static structures. The understanding and use of acoustics results in sound control and better concert halls; similarly, the use of optics creates better optical devices. An understanding of physics makes for more realistic flight simulators, video games, and movies, and is often critical in forensic investigations.\nWith the standard consensus that the laws of physics are universal and do not change with time, physics can be used to study things that would ordinarily be mired in uncertainty. For example, in the study of the origin of the earth, one can reasonably model earth's mass, temperature, and rate of rotation, as a function of time allowing one to extrapolate forward or backward in time and so predict future or prior events. It also allows for simulations in engineering that drastically speed up the development of a new technology.\nBut there is also considerable interdisciplinarity, so many other important fields are influenced by physics (e.g., the fields of econophysics and sociophysics).\n\n\n== Research ==\n\n\n=== Scientific method ===\nPhysicists use the scientific method to test the validity of a physical theory. By using a methodical approach to compare the implications of a theory with the conclusions drawn from its related experiments and observations, physicists are better able to test the validity of a theory in a logical, unbiased, and repeatable way. To that end, experiments are performed and observations are made in order to determine the validity or invalidity of the theory.A scientific law is a concise verbal or mathematical statement of a relation that expresses a fundamental principle of some theory, such as Newton's law of universal gravitation.\n\n\n=== Theory and experiment ===\n\nTheorists seek to develop mathematical models that both agree with existing experiments and successfully predict future experimental results, while experimentalists devise and perform experiments to test theoretical predictions and explore new phenomena. Although theory and experiment are developed separately, they strongly affect and depend upon each other. Progress in physics frequently comes about when experimental results defy explanation by existing theories, prompting intense focus on applicable modelling, and when new theories generate experimentally testable predictions, which inspire the development of new experiments (and often related equipment).Physicists who work at the interplay of theory and experiment are called phenomenologists, who study complex phenomena observed in experiment and work to relate them to a fundamental theory.Theoretical physics has historically taken inspiration from philosophy; electromagnetism was unified this way. Beyond the known universe, the field of theoretical physics also deals with hypothetical issues, such as parallel universes, a multiverse, and higher dimensions. Theorists invoke these ideas in hopes of solving particular problems with existing theories; they then explore the consequences of these ideas and work toward making testable predictions.\nExperimental physics expands, and is expanded by, engineering and technology. Experimental physicists who are involved in basic research design and perform experiments with equipment such as particle accelerators and lasers, whereas those involved in applied research often work in industry, developing technologies such as magnetic resonance imaging (MRI) and transistors. Feynman has noted that experimentalists may seek areas that have not been explored well by theorists.\n\n\n=== Scope and aims ===\n\nPhysics covers a wide range of phenomena, from elementary particles (such as quarks, neutrinos, and electrons) to the largest superclusters of galaxies. Included in these phenomena are the most basic objects composing all other things. Therefore, physics is sometimes called the \"fundamental science\". Physics aims to describe the various phenomena that occur in nature in terms of simpler phenomena. Thus, physics aims to both connect the things observable to humans to root causes, and then connect these causes together.\nFor example, the ancient Chinese observed that certain rocks (lodestone and magnetite) were attracted to one another by an invisible force. This effect was later called magnetism, which was first rigorously studied in the 17th century. But even before the Chinese discovered magnetism, the ancient Greeks knew of other objects such as amber, that when rubbed with fur would cause a similar invisible attraction between the two. This was also first studied rigorously in the 17th century and came to be called electricity. Thus, physics had come to understand two observations of nature in terms of some root cause (electricity and magnetism). However, further work in the 19th century revealed that these two forces were just two different aspects of one force\u2014electromagnetism. This process of \"unifying\" forces continues today, and electromagnetism and the weak nuclear force are now considered to be two aspects of the electroweak interaction. Physics hopes to find an ultimate reason (theory of everything) for why nature is as it is (see section Current research below for more information).\n\n\n=== Research fields ===\nContemporary research in physics can be broadly divided into nuclear and particle physics; condensed matter physics; atomic, molecular, and optical physics; astrophysics; and applied physics. Some physics departments also support physics education research and physics outreach.Since the 20th century, the individual fields of physics have become increasingly specialised, and today most physicists work in a single field for their entire careers. \"Universalists\" such as Einstein (1879\u20131955) and Lev Landau (1908\u20131968), who worked in multiple fields of physics, are now very rare.The major fields of physics, along with their subfields and the theories and concepts they employ, are shown in the following table.\n\n\n==== Nuclear and particle ====\n\nParticle physics is the study of the elementary constituents of matter and energy and the interactions between them. In addition, particle physicists design and develop the high-energy accelerators, detectors, and computer programs necessary for this research. The field is also called \"high-energy physics\" because many elementary particles do not occur naturally but are created only during high-energy collisions of other particles.Currently, the interactions of elementary particles and fields are described by the Standard Model. The model accounts for the 12 known particles of matter (quarks and leptons) that interact via the strong, weak, and electromagnetic fundamental forces. Dynamics are described in terms of matter particles exchanging gauge bosons (gluons, W and Z bosons, and photons, respectively). The Standard Model also predicts a particle known as the Higgs boson. In July 2012 CERN, the European laboratory for particle physics, announced the detection of a particle consistent with the Higgs boson, an integral part of the Higgs mechanism.\nNuclear physics is the field of physics that studies the constituents and interactions of atomic nuclei. The most commonly known applications of nuclear physics are nuclear power generation and nuclear weapons technology, but the research has provided application in many fields, including those in nuclear medicine and magnetic resonance imaging, ion implantation in materials engineering, and radiocarbon dating in geology and archaeology.\n\n\n==== Atomic, molecular, and optical ====\n\nAtomic, molecular, and optical physics (AMO) is the study of matter\u2013matter and light\u2013matter interactions on the scale of single atoms and molecules. The three areas are grouped together because of their interrelationships, the similarity of methods used, and the commonality of their relevant energy scales. All three areas include both classical, semi-classical and quantum treatments; they can treat their subject from a microscopic view (in contrast to a macroscopic view).\nAtomic physics studies the electron shells of atoms. Current research focuses on activities in quantum control, cooling and trapping of atoms and ions, low-temperature collision dynamics and the effects of electron correlation on structure and dynamics. Atomic physics is influenced by the nucleus (see hyperfine splitting), but intra-nuclear phenomena such as fission and fusion are considered part of nuclear physics.\nMolecular physics focuses on multi-atomic structures and their internal and external interactions with matter and light. Optical physics is distinct from optics in that it tends to focus not on the control of classical light fields by macroscopic objects but on the fundamental properties of optical fields and their interactions with matter in the microscopic realm.\n\n\n==== Condensed matter ====\n\nCondensed matter physics is the field of physics that deals with the macroscopic physical properties of matter. In particular, it is concerned with the \"condensed\" phases that appear whenever the number of particles in a system is extremely large and the interactions between them are strong.The most familiar examples of condensed phases are solids and liquids, which arise from the bonding by way of the electromagnetic force between atoms. More exotic condensed phases include the superfluid and the Bose\u2013Einstein condensate found in certain atomic systems at very low temperature, the superconducting phase exhibited by conduction electrons in certain materials, and the ferromagnetic and antiferromagnetic phases of spins on atomic lattices.Condensed matter physics is the largest field of contemporary physics. Historically, condensed matter physics grew out of solid-state physics, which is now considered one of its main subfields. The term condensed matter physics was apparently coined by Philip Anderson when he renamed his research group\u2014previously solid-state theory\u2014in 1967. In 1978, the Division of Solid State Physics of the American Physical Society was renamed as the Division of Condensed Matter Physics. Condensed matter physics has a large overlap with chemistry, materials science, nanotechnology and engineering.\n\n\n==== Astrophysics ====\n\nAstrophysics and astronomy are the application of the theories and methods of physics to the study of stellar structure, stellar evolution, the origin of the Solar System, and related problems of cosmology. Because astrophysics is a broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.The discovery by Karl Jansky in 1931 that radio signals were emitted by celestial bodies initiated the science of radio astronomy. Most recently, the frontiers of astronomy have been expanded by space exploration. Perturbations and interference from the earth's atmosphere make space-based observations necessary for infrared, ultraviolet, gamma-ray, and X-ray astronomy.\nPhysical cosmology is the study of the formation and evolution of the universe on its largest scales. Albert Einstein's theory of relativity plays a central role in all modern cosmological theories. In the early 20th century, Hubble's discovery that the universe is expanding, as shown by the Hubble diagram, prompted rival explanations known as the steady state universe and the Big Bang.\nThe Big Bang was confirmed by the success of Big Bang nucleosynthesis and the discovery of the cosmic microwave background in 1964. The Big Bang model rests on two theoretical pillars: Albert Einstein's general relativity and the cosmological principle. Cosmologists have recently established the \u039bCDM model of the evolution of the universe, which includes cosmic inflation, dark energy, and dark matter.\nNumerous possibilities and discoveries are anticipated to emerge from new data from the Fermi Gamma-ray Space Telescope over the upcoming decade and vastly revise or clarify existing models of the universe. In particular, the potential for a tremendous discovery surrounding dark matter is possible over the next several years. Fermi will search for evidence that dark matter is composed of weakly interacting massive particles, complementing similar experiments with the Large Hadron Collider and other underground detectors.\nIBEX is already yielding new astrophysical discoveries: \"No one knows what is creating the ENA (energetic neutral atoms) ribbon\" along the termination shock of the solar wind, \"but everyone agrees that it means the textbook picture of the heliosphere\u2014in which the Solar System's enveloping pocket filled with the solar wind's charged particles is plowing through the onrushing 'galactic wind' of the interstellar medium in the shape of a comet\u2014is wrong.\"\n\n\n=== Current research ===\n\nResearch in physics is continually progressing on a large number of fronts.\nIn condensed matter physics, an important unsolved theoretical problem is that of high-temperature superconductivity. Many condensed matter experiments are aiming to fabricate workable spintronics and quantum computers.In particle physics, the first pieces of experimental evidence for physics beyond the Standard Model have begun to appear. Foremost among these are indications that neutrinos have non-zero mass. These experimental results appear to have solved the long-standing solar neutrino problem, and the physics of massive neutrinos remains an area of active theoretical and experimental research. The Large Hadron Collider has already found the Higgs boson, but future research aims to prove or disprove the supersymmetry, which extends the Standard Model of particle physics. Research on the nature of the major mysteries of dark matter and dark energy is also currently ongoing.Although much progress has been made in high-energy, quantum, and astronomical physics, many everyday phenomena involving complexity, chaos, or turbulence are still poorly understood. Complex problems that seem like they could be solved by a clever application of dynamics and mechanics remain unsolved; examples include the formation of sandpiles, nodes in trickling water, the shape of water droplets, mechanisms of surface tension catastrophes, and self-sorting in shaken heterogeneous collections.These complex phenomena have received growing attention since the 1970s for several reasons, including the availability of modern mathematical methods and computers, which enabled complex systems to be modeled in new ways. Complex physics has become part of increasingly interdisciplinary research, as exemplified by the study of turbulence in aerodynamics and the observation of pattern formation in biological systems. In the 1932 Annual Review of Fluid Mechanics, Horace Lamb said:\nI am an old man now, and when I die and go to heaven there are two matters on which I hope for enlightenment. One is quantum electrodynamics, and the other is the turbulent motion of fluids. And about the former I am rather optimistic.\n\n\n== Education ==\n\n\n== Career ==\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Sources ==\n\n\n== External links ==\n\nPhysics at Quanta Magazine\nUsenet Physics FAQ \u2013 FAQ compiled by sci.physics and other physics newsgroups\nWebsite of the Nobel Prize in physics \u2013 Award for outstanding contributions to the subject\nWorld of Physics \u2013 Online encyclopedic dictionary of physics\nNature Physics \u2013 Academic journal\nPhysics \u2013 Online magazine by the American Physical Society\nPhysics/Publications at Curlie \u2013 Directory of physics related media\nThe Vega Science Trust \u2013 Science videos, including physics\nHyperPhysics website \u2013 Physics and astronomy mind-map from Georgia State University\nPhysics at MIT OpenCourseWare \u2013 Online course material from Massachusetts Institute of Technology\nThe Feynman Lectures on Physics", "Newton's_laws_of_motion": "Newton's laws of motion are three basic laws of classical mechanics that describe the relationship between the motion of an object and the forces acting on it. These laws can be paraphrased as follows:\n\nA body remains at rest, or in motion at a constant speed in a straight line, unless acted upon by a force.\nWhen a body is acted upon by a force, the time rate of change of its momentum equals the force.\nIf two bodies exert forces on each other, these forces have the same magnitude but opposite directions.The three laws of motion were first stated by Isaac Newton in his Philosophi\u00e6 Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), originally published in 1687. Newton used them to investigate and explain the motion of many physical objects and systems, which laid the foundation for classical mechanics. In the time since Newton, the conceptual content of classical physics has been reformulated in alternative ways, involving different mathematical approaches that have yielded insights which were obscured in the original, Newtonian formulation. Limitations to Newton's laws have also been discovered; new theories are necessary when objects move at very high speeds (special relativity), are very massive (general relativity), or are very small (quantum mechanics).\n\n\n== Prerequisites ==\nNewton's laws are often stated in terms of point or particle masses, that is, bodies whose volume is negligible. This is a reasonable approximation for real bodies when the motion of internal parts can be neglected, and when the separation between bodies is much larger than the size of each. For instance, the Earth and the Sun can both be approximated as pointlike when considering the orbit of the former around the latter, but the Earth is not pointlike when considering activities on its surface.The mathematical description of motion, or kinematics, is based on the idea of specifying positions using numerical coordinates. Movement is represented by these numbers changing over time: a body's trajectory is represented by a function that assigns to each value of a time variable the values of all the position coordinates. The simplest case is one-dimensional, that is, when a body is constrained to move only along a straight line. Its position can then be given by a single number, indicating where it is relative to some chosen reference point. For example, a body might be free to slide along a track that runs left to right, and so its location can be specified by its distance from a convenient zero point, or origin, with negative numbers indicating positions to the left and positive numbers indicating positions to the right. If the body's location as a function of time is \n  \n    \n      \n        s\n        (\n        t\n        )\n      \n    \n    {\\displaystyle s(t)}\n  , then its average velocity over the time interval from \n  \n    \n      \n        \n          t\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle t_{0}}\n   to \n  \n    \n      \n        \n          t\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle t_{1}}\n   is Here, the Greek letter \n  \n    \n      \n        \u0394\n      \n    \n    {\\displaystyle \\Delta }\n   (delta) is used, per tradition, to mean \"change in\". A positive average velocity means that the position coordinate \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   increases over the interval in question, a negative average velocity indicates a net decrease over that interval, and an average velocity of zero means that the body ends the time interval in the same place as it began. Calculus gives the means to define an instantaneous velocity, a measure of a body's speed and direction of movement at a single moment of time, rather than over an interval. One notation for the instantaneous velocity is to replace \n  \n    \n      \n        \u0394\n      \n    \n    {\\displaystyle \\Delta }\n   with the symbol \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  , for example,This denotes that the instantaneous velocity is the derivative of the position with respect to time. It can roughly be thought of as the ratio between an infinitesimally small change in position \n  \n    \n      \n        d\n        s\n      \n    \n    {\\displaystyle ds}\n   to the infinitesimally small time interval \n  \n    \n      \n        d\n        t\n      \n    \n    {\\displaystyle dt}\n   over which it occurs. More carefully, the velocity and all other derivatives can be defined using the concept of a limit. A function \n  \n    \n      \n        f\n        (\n        t\n        )\n      \n    \n    {\\displaystyle f(t)}\n   has a limit of \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   at a given input value \n  \n    \n      \n        \n          t\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle t_{0}}\n   if the difference between \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   and \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   can be made arbitrarily small by choosing an input sufficiently close to \n  \n    \n      \n        \n          t\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle t_{0}}\n  . One writes, Instantaneous velocity can be defined as the limit of the average velocity as the time interval shrinks to zero: Acceleration is to velocity as velocity is to position: it is the derivative of the velocity with respect to time. Acceleration can likewise be defined as a limit:Consequently, the acceleration is the second derivative of position, often written \n  \n    \n      \n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              s\n            \n            \n              d\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {d^{2}s}{dt^{2}}}}\n  .\nPosition, when thought of as a displacement from an origin point, is a vector: a quantity with both magnitude and direction.:\u200a1\u200a Velocity and acceleration are vector quantities as well. The mathematical tools of vector algebra provide the means to describe motion in two, three or more dimensions. Vectors are often denoted with an arrow, as in \n  \n    \n      \n        \n          \n            \n              s\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {s}}}\n  , or in bold typeface, such as \n  \n    \n      \n        \n          \n            s\n          \n        \n      \n    \n    {\\displaystyle {\\bf {s}}}\n  . Often, vectors are represented visually as arrows, with the direction of the vector being the direction of the arrow, and the magnitude of the vector indicated by the length of the arrow. Numerically, a vector can be represented as a list; for example, a body's velocity vector might be \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n        =\n        (\n        \n          3\n           \n          m\n          \n            /\n          \n          s\n        \n        ,\n        \n          4\n           \n          m\n          \n            /\n          \n          s\n        \n        )\n      \n    \n    {\\displaystyle {\\vec {v}}=(\\mathrm {3~m/s} ,\\mathrm {4~m/s} )}\n  , indicating that it is moving at 3 metres per second along a horizontal axis and 4 metres per second along the vertical axis. The same motion described in a different coordinate system will be represented by different numbers, and vector algebra can be used to translate between these alternatives.:\u200a4\u200aThe physics concept of force makes quantitative the everyday idea of a push or a pull. Forces in Newtonian mechanics are often due to strings and ropes, friction, muscle effort, gravity, and so forth. Like displacement, velocity, and acceleration, force is a vector quantity.\n\n\n== Laws ==\n\n\n=== First ===\n\nTranslated from the Latin, Newton's first law reads,\n\nEvery body continues in its state of rest, or of uniform motion in a straight line, unless it is compelled to change that state by forces impressed upon it.:\u200a114\u200aNewton's first law expresses the principle of inertia: the natural behavior of a body is to move in a straight line at constant speed. In the absence of outside influences, a body's motion preserves the status quo.\nThe modern understanding of Newton's first law is that no inertial observer is privileged over any other. The concept of an inertial observer makes quantitative the everyday idea of feeling no effects of motion. For example, a person standing on the ground watching a train go past is an inertial observer. If the observer on the ground sees the train moving smoothly in a straight line at a constant speed, then a passenger sitting on the train will also be an inertial observer: the train passenger feels no motion. The principle expressed by Newton's first law is that there is no way to say which inertial observer is \"really\" moving and which is \"really\" standing still. One observer's state of rest is another observer's state of uniform motion in a straight line, and no experiment can deem either point of view to be correct or incorrect. There is no absolute standard of rest.\n\n\n=== Second ===\nThe change of motion of an object is proportional to the force impressed; and is made in the direction of the straight line in which the force is impressed.:\u200a114\u200aBy \"motion\", Newton meant the quantity now called momentum, which depends upon the amount of matter contained in a body, the speed at which that body is moving, and the direction in which it is moving. In modern notation, the momentum of a body is the product of its mass and its velocity:\n\nNewton's second law, in modern form, states that the time derivative of the momentum is the force:\n\nIf the mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   does not change with time, then the derivative acts only upon the velocity, and so the force equals the product of the mass and the time derivative of the velocity, which is the acceleration:\n\nAs the acceleration is the second derivative of position with respect to time, this can also be written\n\n The forces acting on a body add as vectors, and so the total force on a body depends upon both the magnitudes and the directions of the individual forces. When the net force on a body is equal to zero, then by Newton's second law, the body does not accelerate, and it is said to be in mechanical equilibrium. A state of mechanical equilibrium is stable if, when the position of the body is changed slightly, the body remains near that equilibrium. Otherwise, the equilibrium is unstable.\nA common visual representation of forces acting in concert is the free body diagram, which schematically portrays a body of interest and the forces applied to it by outside influences. For example, a free body diagram of a block sitting upon an inclined plane can illustrate the combination of gravitational force, \"normal\" force, friction, and string tension.Newton's second law is sometimes presented as a definition of force, i.e., a force is that which exists when an inertial observer sees a body accelerating. In order for this to be more than a tautology \u2014 acceleration implies force, force implies acceleration \u2014 some other statement about force must also be made. For example, an equation detailing the force might be specified, like Newton's law of universal gravitation. By inserting such an expression for \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   into Newton's second law, an equation with predictive power can be written. Newton's second law has also been regarded as setting out a research program for physics, establishing that important goals of the subject are to identify the forces present in nature and to catalogue the constituents of matter.\n\n\n=== Third ===\nTo every action, there is always opposed an equal reaction; or, the mutual actions of two bodies upon each other are always equal, and directed to contrary parts.:\u200a116\u200a\nOverly brief paraphrases of the third law, like \"action equals reaction\" might have caused confusion among generations of students: the \"action\" and \"reaction\" apply to different bodies. For example, consider a book at rest on a table. The Earth's gravity pulls down upon the book. The \"reaction\" to that \"action\" is not the support force from the table holding up the book, but the gravitational pull of the book acting on the Earth.Newton's third law relates to a more fundamental principle, the conservation of momentum. The latter remains true even in cases where Newton's statement does not, for instance when force fields as well as material bodies carry momentum, and when momentum is defined properly, in quantum mechanics as well. In Newtonian mechanics, if two bodies have momenta \n  \n    \n      \n        \n          \n            \n              \n                p\n                \u2192\n              \n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}_{1}}\n   and \n  \n    \n      \n        \n          \n            \n              \n                p\n                \u2192\n              \n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}_{2}}\n   respectively, then the total momentum of the pair is \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              \n                p\n                \u2192\n              \n            \n          \n          \n            1\n          \n        \n        +\n        \n          \n            \n              \n                p\n                \u2192\n              \n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}={\\vec {p}}_{1}+{\\vec {p}}_{2}}\n  , and the rate of change of \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}}\n   is  By Newton's second law, the first term is the total force upon the first body, and the second term is the total force upon the second body. If the two bodies are isolated from outside influences, the only force upon the first body can be that from the second, and vice versa. By Newton's third law, these forces have equal magnitude but opposite direction, so they cancel when added, and \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}}\n   is constant. Alternatively, if \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}}\n   is known to be constant, it follows that the forces have equal magnitude and opposite direction.\n\n\n=== Candidates for additional laws ===\nVarious sources have proposed elevating other ideas used in classical mechanics to the status of Newton's laws. For example, in Newtonian mechanics, the total mass of a body made by bringing together two smaller bodies is the sum of their individual masses. Frank Wilczek has suggested calling attention to this assumption by designating it \"Newton's Zeroth Law\". Another candidate for a \"zeroth law\" is the fact that at any instant, a body reacts to the forces applied to it at that instant. Likewise, the idea that forces add like vectors (or in other words obey the superposition principle), and the idea that forces change the energy of a body, have both been described as a \"fourth law\".\n\n\n== Work and energy ==\nPhysicists developed the concept of energy after Newton's time, but it has become an inseparable part of what is considered \"Newtonian\" physics. Energy can broadly be classified into kinetic, due to a body's motion, and potential, due to a body's position relative to others. Thermal energy, the energy carried by heat flow, is a type of kinetic energy not associated with the macroscopic motion of objects but instead with the movements of the atoms and molecules of which they are made. According to the work-energy theorem, when a force acts upon a body while that body moves along the line of the force, the force does work upon the body, and the amount of work done is equal to the change in the body's kinetic energy. In many cases of interest, the net work done by a force when a body moves in a closed loop \u2014 starting at a point, moving along some trajectory, and returning to the initial point \u2014 is zero. If this is the case, then the force can be written in terms of the gradient of a function called a scalar potential::\u200a303\u200a\nThis is true for many forces including that of gravity, but not for friction; indeed, almost any problem in a mechanics textbook that does not involve friction can be expressed in this way.:\u200a19\u200a The fact that the force can be written in this way can be understood from the conservation of energy. Without friction to dissipate a body's energy into heat, the body's energy will trade between potential and (non-thermal) kinetic forms while the total amount remains constant. Any gain of kinetic energy, which occurs when the net force on the body accelerates it to a higher speed, must be accompanied by a loss of potential energy. So, the net force upon the body is determined by the manner in which the potential energy decreases.\n\n\n== Examples ==\n\n\n=== Uniformly accelerated motion ===\n\nIf a body falls from rest near the surface of the Earth, then in the absence of air resistance, it will accelerate at a constant rate. This is known as free fall. The speed attained during free fall is proportional to the elapsed time, and the distance traveled is proportional to the square of the elapsed time. Importantly, the acceleration is the same for all bodies, independently of their mass. This follows from combining Newton's second law of motion with his law of universal gravitation. The latter states that the magnitude of the gravitational force from the Earth upon the body is\n\nwhere \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the mass of the falling body, \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is the mass of the Earth, \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is Newton's constant, and \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the distance from the center of the Earth to the body's location, which is very nearly the radius of the Earth. Setting this equal to \n  \n    \n      \n        m\n        a\n      \n    \n    {\\displaystyle ma}\n  , the body's mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   cancels from both sides of the equation, leaving an acceleration that depends upon \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  , \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  , and \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  , and \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   can be taken to be constant. This particular value of acceleration is typically denoted \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  :\n\nIf the body is not released from rest but instead launched upwards and/or horizontally with nonzero velocity, then free fall becomes projectile motion. When air resistance can be neglected, projectiles follow parabola-shaped trajectories, because gravity affects the body's vertical motion and not its horizontal. At the peak of the projectile's trajectory, its vertical velocity is zero, but its acceleration is \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   downwards, as it is at all times. Setting the wrong vector equal to zero is a common confusion among physics students.\n\n\n=== Uniform circular motion ===\n\nWhen a body is in uniform circular motion, the force on it changes the direction of its motion but not its speed. For a body moving in a circle of radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   at a constant speed \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  , its acceleration has a magnitudeand is directed toward the center of the circle. The force required to sustain this acceleration, called the centripetal force, is therefore also directed toward the center of the circle and has magnitude \n  \n    \n      \n        m\n        \n          v\n          \n            2\n          \n        \n        \n          /\n        \n        r\n      \n    \n    {\\displaystyle mv^{2}/r}\n  . Many orbits, such as that of the Moon around the Earth, can be approximated by uniform circular motion. In such cases, the centripetal force is gravity, and by Newton's law of universal gravitation has magnitude \n  \n    \n      \n        G\n        M\n        m\n        \n          /\n        \n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle GMm/r^{2}}\n  , where \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is the mass of the larger body being orbited. Therefore, the mass of a body can be calculated from observations of another body orbiting around it.:\u200a130\u200aNewton's cannonball is a thought experiment that interpolates between projectile motion and uniform circular motion. A cannonball that is lobbed weakly off the edge of a tall cliff will hit the ground in the same amount of time as if it were dropped from rest, because the force of gravity only affects the cannonball's momentum in the downward direction, and its effect is not diminished by horizontal movement. If the cannonball is launched with a greater initial horizontal velocity, then it will travel farther before it hits the ground, but it will still hit the ground in the same amount of time. However, if the cannonball is launched with an even larger initial velocity, then the curvature of the Earth becomes significant: the ground itself will curve away from the falling cannonball. A very fast cannonball will fall away from the inertial straight-line trajectory at the same rate that the Earth curves away beneath it; in other words, it will be in orbit (imagining that it is not slowed by air resistance or obstacles).\n\n\n=== Harmonic motion ===\n\nConsider a body of mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   able to move along the \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   axis, and suppose an equilibrium point exists at the position \n  \n    \n      \n        x\n        =\n        0\n      \n    \n    {\\displaystyle x=0}\n  . That is, at \n  \n    \n      \n        x\n        =\n        0\n      \n    \n    {\\displaystyle x=0}\n  , the net force upon the body is the zero vector, and by Newton's second law, the body will not accelerate. If the force upon the body is proportional to the displacement from the equilibrium point, and directed to the equilibrium point, then the body will perform simple harmonic motion. Writing the force as \n  \n    \n      \n        F\n        =\n        \u2212\n        k\n        x\n      \n    \n    {\\displaystyle F=-kx}\n  , Newton's second law becomes\n\nThis differential equation has the solution\n\nwhere the frequency \n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   is equal to \n  \n    \n      \n        \n          \n            k\n            \n              /\n            \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {k/m}}}\n  , and the constants \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n   can be calculated knowing, for example, the position and velocity the body has at a given time, like \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n  .\nOne reason that the harmonic oscillator is a conceptually important example is that it is good approximation for many systems near a stable mechanical equilibrium. For example, a pendulum has a stable equilibrium in the vertical position: if motionless there, it will remain there, and if pushed slightly, it will swing back and forth. Neglecting air resistance and friction in the pivot, the force upon the pendulum is gravity, and Newton's second law becomes where \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   is the length of the pendulum and \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is its angle from the vertical. When the angle \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is small, the sine of \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is nearly equal to \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   (see Taylor series), and so this expression simplifies to the equation for a simple harmonic oscillator with frequency \n  \n    \n      \n        \u03c9\n        =\n        \n          \n            g\n            \n              /\n            \n            L\n          \n        \n      \n    \n    {\\displaystyle \\omega ={\\sqrt {g/L}}}\n  .\nA harmonic oscillator can be damped, often by friction or viscous drag, in which case energy bleeds out of the oscillator and the amplitude of the oscillations decreases over time. Also, a harmonic oscillator can be driven by an applied force, which can lead to the phenomenon of resonance.\n\n\n=== Objects with variable mass ===\n\nNewtonian physics treats matter as being neither created nor destroyed, though it may be rearranged. It can be the case that an object of interest gains or loses mass because matter is added to or removed from it. In such a situation, Newton's laws can be applied to the individual pieces of matter, keeping track of which pieces belong to the object of interest over time. For instance, if a rocket of mass \n  \n    \n      \n        M\n        (\n        t\n        )\n      \n    \n    {\\displaystyle M(t)}\n  , moving at velocity \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle {\\vec {v}}(t)}\n  , ejects matter at a velocity \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {u}}}\n   relative to the rocket, then\n\nwhere \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   is the net external force (e.g., a planet's gravitational pull).:\u200a139\u200a\n\n\n== Rigid-body motion and rotation ==\nA rigid body is an object whose size is too large to neglect and which maintains the same shape over time. In Newtonian mechanics, the motion of a rigid body is often understood by separating it into movement of the body's center of mass and movement around the center of mass.\n\n\n=== Center of mass ===\n\nSignificant aspects of the motion of an extended body can be understood by imagining the mass of that body concentrated to a single point, known as the center of mass. The location of a body's center of mass depends upon how that body's material is distributed. For a collection of pointlike objects with masses \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          m\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle m_{1},\\ldots ,m_{N}}\n   at positions \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            N\n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}_{1},\\ldots ,{\\vec {r}}_{N}}\n  , the center of mass is located at  where \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is the total mass of the collection. In the absence of a net external force, the center of mass moves at a constant speed in a straight line. This applies, for example, to a collision between two bodies. If the total external force is not zero, then the center of mass changes velocity as though it were a point body of mass \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  . This follows from the fact that the internal forces within the collection, the forces that the objects exert upon each other, occur in balanced pairs by Newton's third law. In a system of two bodies with one much more massive than the other, the center of mass will approximately coincide with the location of the more massive body.:\u200a22\u201324\u200a\n\n\n=== Rotational analogues of Newton's laws ===\nWhen Newton's laws are applied to rotating extended bodies, they lead to new quantities that are analogous to those invoked in the original laws. The analogue of mass is the moment of inertia, the counterpart of momentum is angular momentum, and the counterpart of force is torque.\nAngular momentum is calculated with respect to a reference point. If the displacement vector from a reference point to a body is \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   and the body has momentum \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}}\n  , then the body's angular momentum with respect to that point is, using the vector cross product,  Taking the time derivative of the angular momentum gives  The first term vanishes because \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}}\n   and \n  \n    \n      \n        m\n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle m{\\vec {v}}}\n   point in the same direction. The remaining term is the torque,  When the torque is zero, the angular momentum is constant, just as when the force is zero, the momentum is constant.:\u200a14\u201315\u200a The torque can vanish even when the force is non-zero, if the body is located at the reference point (\n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle {\\vec {r}}=0}\n  ) or if the force \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   and the displacement vector \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   are directed along the same line.\nThe angular momentum of a collection of point masses, and thus of an extended body, is found by adding the contributions from each of the points. This provides a means to characterize a body's rotation about an axis, by adding up the angular momenta of its individual pieces. The result depends on the chosen axis, the shape of the body, and the rate of rotation.:\u200a28\u200a\n\n\n=== Multi-body gravitational system ===\n\nNewton's law of universal gravitation states that any body attracts any other body along the straight line connecting them. The size of the attracting force is proportional to the product of their masses, and inversely proportional to the square of the distance between them. Finding the shape of the orbits that an inverse-square force law will produce is known as the Kepler problem. The Kepler problem can be solved in multiple ways, including by demonstrating that the Laplace\u2013Runge\u2013Lenz vector is constant, or by applying a duality transformation to a 2-dimensional harmonic oscillator. However it is solved, the result is that orbits will be conic sections, that is, ellipses (including circles), parabolas, or hyperbolas. The eccentricity of the orbit, and thus the type of conic section, is determined by the energy and the angular momentum of the orbiting body. Planets do not have sufficient energy to escape the Sun, and so their orbits are ellipses, to a good approximation; because the planets pull on one another, actual orbits are not exactly conic sections.\nIf a third mass is added, the Kepler problem becomes the three-body problem, which in general has no exact solution in closed form. That is, there is no way to start from the differential equations implied by Newton's laws and, after a finite sequence of standard mathematical operations, obtain equations that express the three bodies' motions over time. Numerical methods can be applied to obtain useful, albeit approximate, results for the three-body problem. The positions and velocities of the bodies can be stored in variables within a computer's memory; Newton's laws are used to calculate how the velocities will change over a short interval of time, and knowing the velocities, the changes of position over that time interval can be computed. This process is looped to calculate, approximately, the bodies' trajectories. Generally speaking, the shorter the time interval, the more accurate the approximation.\n\n\n== Chaos and unpredictability ==\n\n\n=== Nonlinear dynamics ===\n\nNewton's laws of motion allow the possibility of chaos. That is, qualitatively speaking, physical systems obeying Newton's laws can exhibit sensitive dependence upon their initial conditions: a slight change of the position or velocity of one part of a system can lead to the whole system behaving in a radically different way within a short time. Noteworthy examples include the three-body problem, the double pendulum, dynamical billiards, and the Fermi\u2013Pasta\u2013Ulam\u2013Tsingou problem.\nNewton's laws can be applied to fluids by considering a fluid as composed of infinitesimal pieces, each exerting forces upon neighboring pieces. The Euler momentum equation is an expression of Newton's second law adapted to fluid dynamics. A fluid is described by a velocity field, i.e., a function \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n        (\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle {\\vec {v}}({\\vec {x}},t)}\n   that assigns a velocity vector to each point in space and time. A small object being carried along by the fluid flow can change velocity for two reasons: first, because the velocity field at its position is changing over time, and second, because it moves to a new location where the velocity field has a different value. Consequently, when Newton's second law is applied to an infinitesimal portion of fluid, the acceleration \n  \n    \n      \n        \n          \n            \n              a\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {a}}}\n   has two terms, a combination known as a total or material derivative. The mass of an infinitesimal portion depends upon the fluid density, and there is a net force upon it if the fluid pressure varies from one side of it to another. Accordingly, \n  \n    \n      \n        \n          \n            \n              a\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \n          /\n        \n        m\n      \n    \n    {\\displaystyle {\\vec {a}}={\\vec {F}}/m}\n   becomes\n\nwhere \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is the density, \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   is the pressure, and \n  \n    \n      \n        \n          \n            \n              f\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {f}}}\n   stands for an external influence like a gravitational pull. Incorporating the effect of viscosity turns the Euler equation into a Navier\u2013Stokes equation:\n\nwhere \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   is the kinematic viscosity.\n\n\n=== Singularities ===\nIt is mathematically possible for a collection of point masses, moving in accord with Newton's laws, to launch some of themselves away so forcefully that they fly off to infinity in a finite time. This unphysical behavior, known as a \"noncollision singularity\", depends upon the masses being pointlike and able to approach one another arbitrarily closely, as well as the lack of a relativistic speed limit in Newtonian physics.It is not yet known whether or not the Euler and Navier\u2013Stokes equations exhibit the analogous behavior of initially smooth solutions \"blowing up\" in finite time. The question of existence and smoothness of Navier\u2013Stokes solutions is one of the Millennium Prize Problems.\n\n\n== Relation to other formulations of classical physics ==\nClassical mechanics can be mathematically formulated in multiple different ways, other than the \"Newtonian\" description (which itself, of course, incorporates contributions from others both before and after Newton). The physical content of these different formulations is the same as the Newtonian, but they provide different insights and facilitate different types of calculations. For example, Lagrangian mechanics helps make apparent the connection between symmetries and conservation laws, and it is useful when calculating the motion of constrained bodies, like a mass restricted to move along a curving track or on the surface of a sphere.:\u200a48\u200a Hamiltonian mechanics is convenient for statistical physics,:\u200a57\u200a leads to further insight about symmetry,:\u200a251\u200a and can be developed into sophisticated techniques for perturbation theory.:\u200a284\u200a Due to the breadth of these topics, the discussion here will be confined to concise treatments of how they reformulate Newton's laws of motion.\n\n\n=== Lagrangian ===\nLagrangian mechanics differs from the Newtonian formulation by considering entire trajectories at once rather than predicting a body's motion at a single instant.:\u200a109\u200a It is traditional in Lagrangian mechanics to denote position with \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   and velocity with \n  \n    \n      \n        \n          \n            \n              q\n              \u02d9\n            \n          \n        \n      \n    \n    {\\displaystyle {\\dot {q}}}\n  . The simplest example is a massive point particle, the Lagrangian for which can be written as the difference between its kinetic and potential energies:\n\nwhere the kinetic energy is\n\nand the potential energy is some function of the position, \n  \n    \n      \n        V\n        (\n        q\n        )\n      \n    \n    {\\displaystyle V(q)}\n  . The physical path that the particle will take between an initial point \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n   and a final point \n  \n    \n      \n        \n          q\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle q_{f}}\n   is the path for which the integral of the Lagrangian is \"stationary\". That is, the physical path has the property that small perturbations of it will, to a first approximation, not change the integral of the Lagrangian. Calculus of variations provides the mathematical tools for finding this path.:\u200a485\u200a Applying the calculus of variations to the task of finding the path yields the Euler\u2013Lagrange equation for the particle,\n\nEvaluating the partial derivatives of the Lagrangian gives\n\nwhich is a restatement of Newton's second law. The left-hand side is the time derivative of the momentum, and the right-hand side is the force, represented in terms of the potential energy.:\u200a737\u200aLandau and Lifshitz argue that the Lagrangian formulation makes the conceptual content of classical mechanics more clear than starting with Newton's laws. Lagrangian mechanics provides a convenient framework in which to prove Noether's theorem, which relates symmetries and conservation laws. The conservation of momentum can be derived by applying Noether's theorem to a Lagrangian for a multi-particle system, and so, Newton's third law is a theorem rather than an assumption.:\u200a124\u200a\n\n\n=== Hamiltonian ===\n\nIn Hamiltonian mechanics, the dynamics of a system are represented by a function called the Hamiltonian, which in many cases of interest is equal to the total energy of the system.:\u200a742\u200a The Hamiltonian is a function of the positions and the momenta of all the bodies making up the system, and it may also depend explicitly upon time. The time derivatives of the position and momentum variables are given by partial derivatives of the Hamiltonian, via Hamilton's equations.:\u200a203\u200a The simplest example is a point mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   constrained to move in a straight line, under the effect of a potential. Writing \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   for the position coordinate and \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   for the body's momentum, the Hamiltonian is\n\nIn this example, Hamilton's equations are\n\nand\n\nEvaluating these partial derivatives, the former equation becomes\n\nwhich reproduces the familiar statement that a body's momentum is the product of its mass and velocity. The time derivative of the momentum is\n\nwhich, upon identifying the negative derivative of the potential with the force, is just Newton's second law once again.:\u200a742\u200aAs in the Lagrangian formulation, in Hamiltonian mechanics the conservation of momentum can be derived using Noether's theorem, making Newton's third law an idea that is deduced rather than assumed.:\u200a251\u200aAmong the proposals to reform the standard introductory-physics curriculum is one that teaches the concept of energy before that of force, essentially \"introductory Hamiltonian mechanics\".\n\n\n=== Hamilton\u2013Jacobi ===\nThe Hamilton\u2013Jacobi equation provides yet another formulation of classical mechanics, one which makes it mathematically analogous to wave optics.:\u200a284\u200a This formulation also uses Hamiltonian functions, but in a different way than the formulation described above. The paths taken by bodies or collections of bodies are deduced from a function \n  \n    \n      \n        S\n        (\n        \n          \n            \n              \n                q\n                \u2192\n              \n            \n          \n          \n            1\n          \n        \n        ,\n        \n          \n            \n              \n                q\n                \u2192\n              \n            \n          \n          \n            2\n          \n        \n        ,\n        \u2026\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle S({\\vec {q}}_{1},{\\vec {q}}_{2},\\ldots ,t)}\n   of positions \n  \n    \n      \n        \n          \n            \n              \n                q\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle {\\vec {q}}_{i}}\n   and time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  . The Hamiltonian is incorporated into the Hamilton\u2013Jacobi equation, a differential equation for \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  . Bodies move over time in such a way that their trajectories are perpendicular to the surfaces of constant \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  , analogously to how a light ray propagates in the direction perpendicular to its wavefront. This is simplest to express for the case of a single point mass, in which \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is a function \n  \n    \n      \n        S\n        (\n        \n          \n            \n              q\n              \u2192\n            \n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle S({\\vec {q}},t)}\n  , and the point mass moves in the direction along which \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   changes most steeply. In other words, the momentum of the point mass is the gradient of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  :\n\nThe Hamilton\u2013Jacobi equation for a point mass is\n\nThe relation to Newton's laws can be seen by considering a point mass moving in a time-independent potential \n  \n    \n      \n        V\n        (\n        \n          \n            \n              q\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle V({\\vec {q}})}\n  , in which case the Hamilton\u2013Jacobi equation becomes\n\nTaking the gradient of both sides, this becomes\n\nInterchanging the order of the partial derivatives on the left-hand side, and using the power and chain rules on the first term on the right-hand side,\n\nGathering together the terms that depend upon the gradient of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  ,\n\nThis is another re-expression of Newton's second law. The expression in brackets is a total or material derivative as mentioned above, in which the first term indicates how the function being differentiated changes over time at a fixed location, and the second term captures how a moving particle will see different values of that function as it travels from place to place:\n\n\n== Relation to other physical theories ==\n\n\n=== Thermodynamics and statistical physics ===\n\nIn statistical physics, the kinetic theory of gases applies Newton's laws of motion to large numbers (typically on the order of the Avogadro number) of particles. Kinetic theory can explain, for example, the pressure that a gas exerts upon the container holding it as the aggregate of many impacts of atoms, each imparting a tiny amount of momentum.:\u200a62\u200aThe Langevin equation is a special case of Newton's second law, adapted for the case of describing a small object bombarded stochastically by even smaller ones.:\u200a235\u200a It can be writtenwhere \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is a drag coefficient and \n  \n    \n      \n        \n          \n            \n              \u03be\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {\\xi }}}\n   is a force that varies randomly from instant to instant, representing the net effect of collisions with the surrounding particles. This is used to model Brownian motion.\n\n\n=== Electromagnetism ===\nNewton's three laws can be applied to phenomena involving electricity and magnetism, though subtleties and caveats exist.\nCoulomb's law for the electric force between two stationary, electrically charged bodies has much the same mathematical form as Newton's law of universal gravitation: the force is proportional to the product of the charges, inversely proportional to the square of the distance between them, and directed along the straight line between them. The Coulomb force that a charge \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n   exerts upon a charge \n  \n    \n      \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{2}}\n   is equal in magnitude to the force that \n  \n    \n      \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{2}}\n   exerts upon \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n  , and it points in the exact opposite direction. Coulomb's law is thus consistent with Newton's third law.Electromagnetism treats forces as produced by fields acting upon charges. The Lorentz force law provides an expression for the force upon a charged body that can be plugged into Newton's second law in order to calculate its acceleration.:\u200a85\u200a According to the Lorentz force law, a charged body in an electric field experiences a force in the direction of that field, a force proportional to its charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   and to the strength of the electric field. In addition, a moving charged body in a magnetic field experiences a force that is also proportional to its charge, in a direction perpendicular to both the field and the body's direction of motion. Using the vector cross product,\n\nIf the electric field vanishes (\n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle {\\vec {E}}=0}\n  ), then the force will be perpendicular to the charge's motion, just as in the case of uniform circular motion studied above, and the charge will circle (or more generally move in a helix) around the magnetic field lines at the cyclotron frequency \n  \n    \n      \n        \u03c9\n        =\n        q\n        B\n        \n          /\n        \n        m\n      \n    \n    {\\displaystyle \\omega =qB/m}\n  .:\u200a222\u200a Mass spectrometry works by applying electric and/or magnetic fields to moving charges and measuring the resulting acceleration, which by the Lorentz force law yields the mass-to-charge ratio.Collections of charged bodies do not always obey Newton's third law: there can be a change of one body's momentum without a compensatory change in the momentum of another. The discrepancy is accounted for by momentum carried by the electromagnetic field itself. The momentum per unit volume of the electromagnetic field is proportional to the Poynting vector.:\u200a184\u200aThere is subtle conceptual conflict between electromagnetism and Newton's first law: Maxwell's theory of electromagnetism predicts that electromagnetic waves will travel through empty space at a constant, definite speed. Thus, some inertial observers seemingly have a privileged status over the others, namely those who measure the speed of light and find it to be the value predicted by the Maxwell equations. In other words, light provides an absolute standard for speed, yet the principle of inertia holds that there should be no such standard. This tension is resolved in the theory of special relativity, which revises the notions of space and time in such a way that all inertial observers will agree upon the speed of light in vacuum.\n\n\n=== Special relativity ===\nIn special relativity, the rule that Wilczek called \"Newton's Zeroth Law\" breaks down: the mass of a composite object is not merely the sum of the masses of the individual pieces.:\u200a33\u200a Newton's first law, inertial motion, remains true. A form of Newton's second law, that force is the rate of change of momentum, also holds, as does the conservation of momentum. However, the definition of momentum is modified. Among the consequences of this is the fact that the more quickly a body moves, the harder it is to accelerate, and so, no matter how much force is applied, a body cannot be accelerated to the speed of light. Depending on the problem at hand, momentum in special relativity can be represented as a three-dimensional vector, \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n        =\n        m\n        \u03b3\n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}=m\\gamma {\\vec {v}}}\n  , where \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the body's rest mass and \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is the Lorentz factor, which depends upon the body's speed. Alternatively, momentum and force can be represented as four-vectors.:\u200a107\u200aNewtonian mechanics is a good approximation to special relativity when the speeds involved are small compared to that of light.:\u200a131\u200a\n\n\n=== General relativity ===\nGeneral relativity is theory of gravity that advances beyond that of Newton. In general relativity, gravitational force is reimagined as curvature of spacetime. A curved path like an orbit is not the result of a force deflecting a body from an ideal straight-line path, but rather the body's attempt to fall freely through a background that is itself curved by the presence of other masses. A remark by John Archibald Wheeler that has become proverbial among physicists summarizes the theory: \"Spacetime tells matter how to move; matter tells spacetime how to curve.\" Wheeler himself thought of this reciprocal relationship as a modern, generalized form of Newton's third law. The relation between matter distribution and spacetime curvature is given by the Einstein field equations, which require tensor calculus to express.:\u200a43\u200aThe Newtonian theory of gravity is a good approximation to the predictions of general relativity when gravitational effects are weak and objects are moving slowly compared to the speed of light.:\u200a327\u200a\n\n\n=== Quantum mechanics ===\nQuantum mechanics is a theory of physics originally developed in order to understand microscopic phenomena: behavior at the scale of molecules, atoms or subatomic particles. Generally and loosely speaking, the smaller a system is, the more an adequate mathematical model will require understanding quantum effects. The conceptual underpinning of quantum physics is very different from that of classical physics. Instead of thinking about quantities like position, momentum, and energy as properties that an object has, one considers what result might appear when a measurement of a chosen type is performed. Quantum mechanics allows the physicist to calculate the probability that a chosen measurement will elicit a particular result. The expectation value for a measurement is the average of the possible results it might yield, weighted by their probabilities of occurrence.The Ehrenfest theorem provides a connection between quantum expectation values and Newton's second law, a connection that is necessarily inexact, as quantum physics is fundamentally different from classical. In quantum physics, position and momentum are represented by mathematical entities known as Hermitian operators, and the Born rule is used to calculate the expectation values of a position measurement or a momentum measurement. These expectation values will generally change over time; that is, depending on the time at which (for example) a position measurement is performed, the probabilities for its different possible outcomes will vary. The Ehrenfest theorem says, roughly speaking, that the equations describing how these expectation values change over time have a form reminiscent of Newton's second law. However, the more pronounced quantum effects are in a given situation, the more difficult it is to derive meaningful conclusions from this resemblance.\n\n\n== History ==\n\nThe concepts invoked in Newton's laws of motion \u2014 mass, velocity, momentum, force \u2014 have predecessors in earlier work, and the content of Newtonian physics was further developed after Newton's time. Newton combined knowledge of celestial motions with the study of events on Earth and showed that one theory of mechanics could encompass both.\n\n\n=== Antiquity and medieval background ===\nThe subject of physics is often traced back to Aristotle; however, the history of the concepts involved is obscured by multiple factors. An exact correspondence between Aristotelian and modern concepts is not simple to establish: Aristotle did not clearly distinguish what we would call speed and force, and he used the same term for density and viscosity; he conceived of motion as always through a medium, rather than through space. In addition, some concepts often termed \"Aristotelian\" might better be attributed to his followers and commentators upon him. These commentators found that Aristotelian physics had difficulty explaining projectile motion. Aristotle divided motion into two types: \"natural\" and \"violent\". The \"natural\" motion of terrestrial solid matter was to fall downwards, whereas a \"violent\" motion could push a body sideways. Moreover, in Aristotelian physics, a \"violent\" motion requires an immediate cause; separated from the cause of its \"violent\" motion, a body would revert to its \"natural\" behavior. Yet a javelin continues moving after it leaves the hand of its thrower. Aristotle concluded that the air around the javelin must be imparted with the ability to move the javelin forward. John Philoponus, a Byzantine Greek thinker active during the sixth century, found this absurd: the same medium, air, was somehow responsible both for sustaining motion and for impeding it. If Aristotle's idea were true, Philoponus said, armies would launch weapons by blowing upon them with bellows. Philoponus argued that setting a body into motion imparted a quality, impetus, that would be contained within the body itself. As long as its impetus was sustained, the body would continue to move.:\u200a47\u200a In the following centuries, versions of impetus theory were advanced by individuals including Nur ad-Din al-Bitruji, Avicenna, Abu'l-Barak\u0101t al-Baghd\u0101d\u012b, John Buridan, and Albert of Saxony. In retrospect, the idea of impetus can be seen as a forerunner of the modern concept of momentum. (The intuition that objects move according to some kind of impetus persists in many students of introductory physics.)\n\n\n=== Inertia and the first law ===\nThe modern concept of inertia is credited to Galileo. Based on his experiments, Galileo concluded that the \"natural\" behavior of a moving body was to keep moving, until something else interfered with it. Galileo recognized that in projectile motion, the Earth's gravity affects vertical but not horizontal motion. However, Galileo's idea of inertia was not exactly the one that would be codified into Newton's first law. Galileo thought that a body moving a long distance inertially would follow the curve of the Earth. This idea was corrected by Isaac Beeckman, Ren\u00e9 Descartes, and Pierre Gassendi, who recognized that inertial motion should be motion in a straight line.\n\n\n=== Force and the second law ===\nChristiaan Huygens, in his Horologium Oscillatorium (1673), put forth the hypothesis that \"By the action of gravity, whatever its sources, it happens that bodies are moved by a motion composed both of a uniform motion in one direction or another and of a motion downward due to gravity.\" Newton's second law generalized this hypothesis from gravity to all forces.One important characteristic of Newtonian physics is that forces can act at a distance without requiring physical contact. For example, the Sun and the Earth pull on each other gravitationally, despite being separated by millions of kilometres. This contrasts with the idea, championed by Descartes among others, that the Sun's gravity held planets in orbit by swirling them in a vortex of transparent matter, aether. Newton considered aetherial explanations of force but ultimately rejected them. The study of magnetism by William Gilbert and others created a precedent for thinking of immaterial forces, and unable to find a quantitatively satisfactory explanation of his law of gravity in terms of an aetherial model, Newton eventually declared, \"I feign no hypotheses\": whether or not a model like Descartes's vortices could be found to underlie the Principia's theories of motion and gravity, the first grounds for judging them must be the successful predictions they made. And indeed, since Newton's time every attempt at such a model has failed.\n\n\n=== Momentum conservation and the third law ===\nJohannes Kepler suggested that gravitational attractions were reciprocal \u2014 that, for example, the Moon pulls on the Earth while the Earth pulls on the Moon \u2014 but he did not argue that such pairs are equal and opposite. In his Principles of Philosophy (1644), Descartes introduced the idea that during a collision between bodies, a \"quantity of motion\" remains unchanged. Descartes defined this quantity somewhat imprecisely by adding up the products of the speed and \"size\" of each body, where \"size\" for him incorporated both volume and surface area. Moreover, Descartes thought of the universe as a plenum, that is, filled with matter, so all motion required a body to displace a medium as it moved. During the 1650s, Huygens studied collisions between hard spheres and deduced a principle that is now identified as the conservation of momentum. Christopher Wren would later deduce the same rules for elastic collisions that Huygens had, and John Wallis would apply momentum conservation to study inelastic collisions. Newton cited the work of Huygens, Wren, and Wallis to support the validity of his third law.Newton arrived at his set of three laws incrementally. In a 1684 manuscript written to Huygens, he listed four laws: the principle of inertia, the change of motion by force, a statement about relative motion that would today be called Galilean invariance, and the rule that interactions between bodies do not change the motion of their center of mass. In a later manuscript, Newton added a law of action and reaction, while saying that this law and the law regarding the center of mass implied one another. Newton probably settled on the presentation in the Principia, with three primary laws and then other statements reduced to corollaries, during 1685.\n\n\n=== After the Principia ===\n\nNewton expressed his second law by saying that the force on a body is proportional to its change of motion, or momentum. By the time he wrote the Principia, he had already developed calculus (which he called \"the science of fluxions\"), but in the Principia he made no explicit use of it, perhaps because he believed geometrical arguments in the tradition of Euclid to be more rigorous.:\u200a15\u200a Consequently, the Principia does not express acceleration as the second derivative of position, and so it does not give the second law as \n  \n    \n      \n        F\n        =\n        m\n        a\n      \n    \n    {\\displaystyle F=ma}\n  . This form of the second law was written (for the special case of constant force) at least as early as 1716, by Jakob Hermann; Leonhard Euler would employ it as a basic premise in the 1740s. Euler pioneered the study of rigid bodies and established the basic theory of fluid dynamics. Pierre-Simon Laplace's five-volume Trait\u00e9 de m\u00e9canique c\u00e9leste (1798\u20131825) forsook geometry and developed mechanics purely through algebraic expressions, while resolving questions that the Principia had left open, like a full theory of the tides.The concept of energy became a key part of Newtonian mechanics in the post-Newton period. Huygens' solution of the collision of hard spheres showed that in that case, not only is momentum conserved, but kinetic energy is as well (or, rather, a quantity that in retrospect we can identify as one-half the total kinetic energy). The question of what is conserved during all other processes, like inelastic collisions and motion slowed by friction, was not resolved until the 19th century. Debates on this topic overlapped with philosophical disputes between the metaphysical views of Newton and Leibniz, and variants of the term \"force\" were sometimes used to denote what we would call types of energy. For example, in 1742, \u00c9milie du Ch\u00e2telet wrote, \"Dead force consists of a simple tendency to motion: such is that of a spring ready to relax; living force is that which a body has when it is in actual motion.\" In modern terminology, \"dead force\" and \"living force\" correspond to potential energy and kinetic energy respectively. Conservation of energy was not established as a universal principle until it was understood that the energy of mechanical work can be dissipated into heat. With the concept of energy given a solid grounding, Newton's laws could then be derived within formulations of classical mechanics that put energy first, as in the Lagrangian and Hamiltonian formulations described above.\nModern presentations of Newton's laws use the mathematics of vectors, a topic that was not developed until the late 19th and early 20th centuries. Vector algebra, pioneered by Josiah Willard Gibbs and Oliver Heaviside, stemmed from and largely supplanted the earlier system of quaternions invented by William Rowan Hamilton.\n\n\n== See also ==\nHistory of classical mechanics\nList of eponymous laws\nList of equations in classical mechanics\nList of scientific laws named after people\nList of textbooks on classical mechanics and quantum mechanics\nNorton's dome\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nChakrabarty, Deepto; Dourmashkin, Peter; Tomasik, Michelle; Frebel, Anna; Vuletic, Vladan (2016). \"Classical Mechanics\". MIT OpenCourseWare. Retrieved 17 January 2022.\nThomson, W.; Tait, P. G. (1867). \"242, Newton's laws of motion\". Treatise on natural philosophy. Vol. 1.", "Motion_graphs_and_derivatives": "In mechanics, the derivative of the position vs. time graph of an object is equal to the velocity of the object. In the International System of Units, the position of the moving object is measured in meters relative to the origin, while the time is measured in seconds. Placing position on the y-axis and time on the x-axis, the slope of the curve is given by:\n\n  \n    \n      \n        v\n        =\n        \n          \n            \n              \u0394\n              y\n            \n            \n              \u0394\n              x\n            \n          \n        \n        =\n        \n          \n            \n              \u0394\n              s\n            \n            \n              \u0394\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle v={\\frac {\\Delta y}{\\Delta x}}={\\frac {\\Delta s}{\\Delta t}}.}\n  Here \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is the position of the object, and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is the time. Therefore, the slope of the curve gives the change in position divided by the change in time, which is the definition of the average velocity for that interval of time on the graph. If this interval is made to be infinitesimally small, such that \n  \n    \n      \n        \n          \u0394\n          s\n        \n      \n    \n    {\\displaystyle {\\Delta s}}\n   becomes \n  \n    \n      \n        \n          d\n          s\n        \n      \n    \n    {\\displaystyle {ds}}\n   and \n  \n    \n      \n        \n          \u0394\n          t\n        \n      \n    \n    {\\displaystyle {\\Delta t}}\n   becomes \n  \n    \n      \n        \n          d\n          t\n        \n      \n    \n    {\\displaystyle {dt}}\n  , the result is the instantaneous velocity at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , or the derivative of the position with respect to time.\nA similar fact also holds true for the velocity vs. time graph. The slope of a velocity vs. time graph is acceleration, this time, placing velocity on the y-axis and time on the x-axis. Again the slope of a line is change in \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n   over change in \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  :\n\n  \n    \n      \n        a\n        =\n        \n          \n            \n              \u0394\n              y\n            \n            \n              \u0394\n              x\n            \n          \n        \n        =\n        \n          \n            \n              \u0394\n              v\n            \n            \n              \u0394\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle a={\\frac {\\Delta y}{\\Delta x}}={\\frac {\\Delta v}{\\Delta t}}}\n  where \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the velocity, and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is the time. This slope therefore defines the average acceleration over the interval, and reducing the interval infinitesimally gives \n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      d\n                      v\n                    \n                    \n                      d\n                      t\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{matrix}{\\frac {dv}{dt}}\\end{matrix}}}\n  , the instantaneous acceleration at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , or the derivative of the velocity with respect to time (or the second derivative of the position with respect to time). In SI, this slope or derivative is expressed in the units of meters per second per second (\n  \n    \n      \n        \n          m\n          \n            /\n          \n          \n            s\n            \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {m/s^{2}} }\n  , usually termed \"meters per second-squared\").\nSince the velocity of the object is the derivative of the position graph, the area under the line in the velocity vs. time graph is the displacement of the object. (Velocity is on the y-axis and time on the x-axis. Multiplying the velocity by the time, the time cancels out, and only displacement remains.)\nThe same multiplication rule holds true for acceleration vs. time graphs. When acceleration is multiplied\n\n\n== Variable rates of change ==\n\nThe expressions given above apply only when the rate of change is constant or when only the average (mean) rate of change is required. If the velocity or positions change non-linearly over time, such as in the example shown in the figure, then differentiation provides the correct solution. Differentiation reduces the time-spans used above to be extremely small (infinitesimal) and gives a velocity or acceleration at each point on the graph rather than between a start and end point. The derivative forms of the above equations are\n\n  \n    \n      \n        v\n        =\n        \n          \n            \n              d\n              s\n            \n            \n              d\n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle v={\\frac {ds}{dt}},}\n  \n  \n    \n      \n        a\n        =\n        \n          \n            \n              d\n              v\n            \n            \n              d\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle a={\\frac {dv}{dt}}.}\n  Since acceleration differentiates the expression involving position, it can be rewritten as a second derivative with respect to time:\n\n  \n    \n      \n        a\n        =\n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              s\n            \n            \n              d\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle a={\\frac {d^{2}s}{dt^{2}}}.}\n  Since, for the purposes of mechanics such as this, integration is the opposite of differentiation, it is also possible to express position as a function of velocity and velocity as a function of acceleration. The process of determining the area under the curve, as described above, can give the displacement and change in velocity over particular time intervals by using definite integrals:\n\n  \n    \n      \n        s\n        (\n        \n          t\n          \n            2\n          \n        \n        )\n        \u2212\n        s\n        (\n        \n          t\n          \n            1\n          \n        \n        )\n        =\n        \n          \u222b\n          \n            \n              t\n              \n                1\n              \n            \n          \n          \n            \n              t\n              \n                2\n              \n            \n          \n        \n        \n          v\n        \n        \n        d\n        t\n        ,\n      \n    \n    {\\displaystyle s(t_{2})-s(t_{1})=\\int _{t_{1}}^{t_{2}}{v}\\,dt,}\n  \n  \n    \n      \n        v\n        (\n        \n          t\n          \n            2\n          \n        \n        )\n        \u2212\n        v\n        (\n        \n          t\n          \n            1\n          \n        \n        )\n        =\n        \n          \u222b\n          \n            \n              t\n              \n                1\n              \n            \n          \n          \n            \n              t\n              \n                2\n              \n            \n          \n        \n        \n          a\n        \n        \n        d\n        t\n        .\n      \n    \n    {\\displaystyle v(t_{2})-v(t_{1})=\\int _{t_{1}}^{t_{2}}{a}\\,dt.}\n  \n\n\n== See also ==\nDisplacement (vector)\nVelocity\nAcceleration\nKinematics\n\n\n== References ==\nWolfson, Richard; Jay M. Pasachoff (1999). Physics for Scientists and Engineers (3rd ed.). Reading, Massachusetts: Addison-Wesley. pp. 23\u201338. ISBN 0-321-03571-2.", "Speed": "In everyday use and in kinematics, the speed (commonly referred to as v) of an object is the magnitude of the change of its position over time or the magnitude of the change of its position per unit of time; it is thus a scalar quantity. The average speed of an object in an interval of time is the distance travelled by the object divided by the duration of the interval; the instantaneous speed is the limit of the average speed as the duration of the time interval approaches zero. Speed is not the same as velocity.\nSpeed has the dimensions of distance divided by time. The SI unit of speed is the metre per second (m/s), but the most common unit of speed in everyday usage is the kilometre per hour (km/h) or, in the US and the UK, miles per hour (mph). For air and marine travel, the knot is commonly used.\nThe fastest possible speed at which energy or information can travel, according to special relativity, is the speed of light in vacuum c = 299792458 metres per second (approximately 1079000000 km/h or 671000000 mph). Matter cannot quite reach the speed of light, as this would require an infinite amount of energy. In relativity physics, the concept of rapidity replaces the classical idea of speed.\n\n\n== Definition ==\n\n\n=== Historical definition ===\nItalian physicist Galileo Galilei is usually credited with being the first to measure speed by considering the distance covered and the time it takes. Galileo defined speed as the distance covered per unit of time. In equation form, that is\n\n  \n    \n      \n        v\n        =\n        \n          \n            d\n            t\n          \n        \n        ,\n      \n    \n    {\\displaystyle v={\\frac {d}{t}},}\n  where \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is speed, \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   is distance, and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is time. A cyclist who covers 30 metres in a time of 2 seconds, for example, has a speed of 15 metres per second. Objects in motion often have variations in speed (a car might travel along a street at 50 km/h, slow to 0 km/h, and then reach 30 km/h).\n\n\n=== Instantaneous speed ===\nSpeed at some instant, or assumed constant during a very short period of time, is called instantaneous speed. By looking at a speedometer, one can read the instantaneous speed of a car at any instant. A car travelling at 50 km/h generally goes for less than one hour at a constant speed, but if it did go at that speed for a full hour, it would travel 50 km. If the vehicle continued at that speed for half an hour, it would cover half that distance (25 km). If it continued for only one minute, it would cover about 833 m.\nIn mathematical terms, the instantaneous speed \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is defined as the magnitude of the instantaneous velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}}\n  , that is, the derivative of the position \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {r}}}\n   with respect to time:\n\n  \n    \n      \n        v\n        =\n        \n          |\n          \n            v\n          \n          |\n        \n        =\n        \n          |\n          \n            \n              \n                r\n                \u02d9\n              \n            \n          \n          |\n        \n        =\n        \n          |\n          \n            \n              \n                d\n                \n                  r\n                \n              \n              \n                d\n                t\n              \n            \n          \n          |\n        \n        \n        .\n      \n    \n    {\\displaystyle v=\\left|{\\boldsymbol {v}}\\right|=\\left|{\\dot {\\boldsymbol {r}}}\\right|=\\left|{\\frac {d{\\boldsymbol {r}}}{dt}}\\right|\\,.}\n  If \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is the length of the path (also known as the distance) travelled until time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , the speed equals the time derivative of \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  :\n\n  \n    \n      \n        v\n        =\n        \n          \n            \n              d\n              s\n            \n            \n              d\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle v={\\frac {ds}{dt}}.}\n  In the special case where the velocity is constant (that is, constant speed in a straight line), this can be simplified to \n  \n    \n      \n        v\n        =\n        s\n        \n          /\n        \n        t\n      \n    \n    {\\displaystyle v=s/t}\n  .  The average speed over a finite time interval is the total distance travelled divided by the time duration.\n\n\n=== Average speed ===\nDifferent from instantaneous speed, average speed is defined as the total distance covered divided by the time interval. For example, if a distance of 80 kilometres is driven in 1 hour, the average speed is 80 kilometres per hour. Likewise, if 320 kilometres are travelled in 4 hours, the average speed is also 80 kilometres per hour. When a distance in kilometres (km) is divided by a time in hours (h), the result is in kilometres per hour (km/h).\nAverage speed does not describe the speed variations that may have taken place during shorter time intervals (as it is the entire distance covered divided by the total time of travel), and so average speed is often quite different from a value of instantaneous speed. If the average speed and the time of travel are known, the distance travelled can be calculated by rearranging the definition to\n\n  \n    \n      \n        d\n        =\n        \n          \n            \n              v\n              \u00af\n            \n          \n        \n        t\n        \n        .\n      \n    \n    {\\displaystyle d={\\boldsymbol {\\bar {v}}}t\\,.}\n  Using this equation for an average speed of 80 kilometres per hour on a 4-hour trip, the distance covered is found to be 320 kilometres.\nExpressed in graphical language, the slope of a tangent line at any point of a distance-time graph is the instantaneous speed at this point, while the slope of a chord line of the same graph is the average speed during the time interval covered by the chord. Average speed of an object is\nVav = s\u00f7t\n\n\n=== Difference between speed and velocity ===\nSpeed denotes only how fast an object is moving, whereas velocity describes both how fast and in which direction the object is moving. If a car is said to travel at 60 km/h, its speed has been specified. However, if the car is said to move at 60 km/h to the north, its velocity has now been specified.\nThe big difference can be discerned when considering movement around a circle. When something moves in a circular path and returns to its starting point, its average velocity is zero, but its average speed is found by dividing the circumference of the circle by the time taken to move around the circle. This is because the average velocity is calculated by considering only the displacement between the starting and end points, whereas the average speed considers only the total distance travelled.\n\n\n=== Tangential speed ===\nLinear speed is the distance travelled per unit of time, while tangential speed (or tangential velocity) is the linear speed of something moving along a circular path. A point on the outside edge of a merry-go-round or turntable travels a greater distance in one complete rotation than a point nearer the center. Travelling a greater distance in the same time means a greater speed, and so linear speed is greater on the outer edge of a rotating object than it is closer to the axis. This speed along a circular path is known as tangential speed because the direction of motion is tangent to the circumference of the circle. For circular motion, the terms linear speed and tangential speed are used interchangeably, and both use units of m/s, km/h, and others.\nRotational speed (or angular speed) involves the number of revolutions per unit of time. All parts of a rigid merry-go-round or turntable turn about the axis of rotation in the same amount of time. Thus, all parts share the same rate of rotation, or the same number of rotations or revolutions per unit of time. It is common to express rotational rates in revolutions per minute (RPM) or in terms of the number of \"radians\" turned in a unit of time. There are little more than 6 radians in a full rotation (2\u03c0 radians exactly). When a direction is assigned to rotational speed, it is known as rotational velocity or angular velocity. Rotational velocity is a vector whose magnitude is the rotational speed.\nTangential speed and rotational speed are related: the greater the RPMs, the larger the speed in metres per second. Tangential speed is directly proportional to rotational speed at any fixed distance from the axis of rotation. However, tangential speed, unlike rotational speed, depends on radial distance (the distance from the axis). For a platform rotating with a fixed rotational speed, the tangential speed in the centre is zero. Towards the edge of the platform the tangential speed increases proportional to the distance from the axis. In equation form:\n\n  \n    \n      \n        v\n        \u221d\n        \n        \n        r\n        \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle v\\propto \\!\\,r\\omega \\,,}\n  where v is tangential speed and \u03c9 (Greek letter omega) is rotational speed. One moves faster if the rate of rotation increases (a larger value for \u03c9), and one also moves faster if movement farther from the axis occurs (a larger value for r). Move twice as far from the rotational axis at the centre and you move twice as fast. Move out three times as far, and you have three times as much tangential speed. In any kind of rotating system, tangential speed depends on how far you are from the axis of rotation.\nWhen proper units are used for tangential speed v, rotational speed \u03c9, and radial distance r, the direct proportion of v to both r and \u03c9 becomes the exact equation\n\n  \n    \n      \n        v\n        =\n        r\n        \u03c9\n        \n        .\n      \n    \n    {\\displaystyle v=r\\omega \\,.}\n  Thus, tangential speed will be directly proportional to r when all parts of a system simultaneously have the same \u03c9, as for a wheel, disk, or rigid wand.\n\n\n== Units ==\n\nUnits of speed include:\n\nmetres per second (symbol m s\u22121 or m/s), the SI derived unit;\nkilometres per hour (symbol km/h);\nmiles per hour (symbol mi/h or mph);\nknots (nautical miles per hour, symbol kn or kt);\nfeet per second (symbol fps or ft/s);\nMach number (dimensionless), speed divided by the speed of sound;\nin natural units (dimensionless), speed divided by the speed of light in vacuum (symbol c = 299792458 m/s). (* = approximate values)\n\n\n== Examples of different speeds ==\n\n\n== Psychology ==\nAccording to Jean Piaget, the intuition for the notion of speed in humans precedes that of duration, and is based on the notion of outdistancing. Piaget studied this subject inspired by a question asked to him in 1928 by Albert Einstein: \"In what order do children acquire the concepts of time and speed?\" Children's early concept of speed is based on \"overtaking\", taking only temporal and spatial orders into consideration, specifically: \"A moving object is judged to be more rapid than another when at a given moment the first object is behind and a moment or so later ahead of the other object.\"\n\n\n== See also ==\n\n\n== References ==\n\nRichard P. Feynman, Robert B. Leighton, Matthew Sands. The Feynman Lectures on Physics, Volume I, Section 8\u20132. Addison-Wesley, Reading, Massachusetts (1963). ISBN 0-201-02116-1.", "Snell's_law": "Snell's law (also known as Snell\u2013Descartes law  and ibn-Sahl law and the law of refraction) is a formula used to describe the relationship between the angles of incidence and refraction, when referring to light or other waves passing through a boundary between two different isotropic media, such as water, glass, or air.\nIn optics, the law is used in ray tracing to compute the angles of incidence or refraction, and in experimental optics to find the refractive index of a material. The law is also satisfied in meta-materials, which allow light to be bent \"backward\" at a negative angle of refraction with a negative refractive index.\nSnell's law states that, for a given pair of media, the ratio of the sines of angle of incidence (\n  \n    \n      \n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\theta _{1}}\n  ) and angle of refraction (\n  \n    \n      \n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta _{2}}\n  ) is equal to the refractive index of the second medium w.r.t the first (n21) which is equal to the ratio of the refractive indices (n2/n1) of the two media, or equivalently, to the ratio of the phase velocities (v1/v2) in the two media.\n\n  \n    \n      \n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          n\n          \n            21\n          \n        \n        =\n        \n          \n            \n              n\n              \n                2\n              \n            \n            \n              n\n              \n                1\n              \n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                1\n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sin \\theta _{1}}{\\sin \\theta _{2}}}=n_{21}={\\frac {n_{2}}{n_{1}}}={\\frac {v_{1}}{v_{2}}}}\n  The law follows from Fermat's principle of least time, which in turn follows from the propagation of light as waves.\n\n\n== History ==\n\nPtolemy, in Alexandria, Egypt, had found a relationship regarding refraction angles, but it was inaccurate for angles that were not small. Ptolemy was confident he had found an accurate empirical law, partially as a result of slightly altering his data to fit theory (see: confirmation bias).\n\nThe law was eventually named after Snell, although it was first discovered by the Persian scientist Ibn Sahl, at the Baghdad court in 984. In the manuscript On Burning Mirrors and Lenses, Sahl used the law to derive lens shapes that focus light with no geometric aberration.Alhazen, in his Book of Optics (1021), came close to rediscovering the law of refraction, but he did not take this step.The law was rediscovered by Thomas Harriot in 1602, who however did not publish his results although he had corresponded with Kepler on this very subject. In 1621, the Dutch astronomer Willebrord Snellius (1580\u20131626)\u2014Snell\u2014derived a mathematically equivalent form, that remained unpublished during his lifetime. Ren\u00e9 Descartes independently derived the law using heuristic momentum conservation arguments in terms of sines in his 1637 essay Dioptrique, and used it to solve a range of optical problems. Rejecting Descartes' solution, Pierre de Fermat arrived at the same solution based solely on his principle of least time. Descartes assumed the speed of light was infinite, yet in his derivation of Snell's law he also assumed the denser the medium, the greater the speed of light. Fermat supported the opposing assumptions, i.e., the speed of light is finite, and his derivation depended upon the speed of light being slower in a denser medium. Fermat's derivation also utilized his invention of adequality, a mathematical procedure equivalent to differential calculus, for finding maxima, minima, and tangents.In his influential mathematics book Geometry, Descartes solves a problem that was worked on by Apollonius of Perga and Pappus of Alexandria. Given n lines L and a point P(L) on each line, find the locus of points Q such that the lengths of the line segments QP(L) satisfy certain conditions.  For example, when n = 4, given the lines a, b, c, and d and a point A on a, B on b, and so on, find the locus of points Q such that the product QA*QB equals the product QC*QD. When the lines are not all parallel, Pappus showed that the loci are conics, but when Descartes considered larger n, he obtained cubic and higher degree curves. To show that the cubic curves were interesting, he showed that they arose naturally in optics from Snell's law.According to Dijksterhuis, \"In De natura lucis et proprietate (1662) Isaac Vossius said that Descartes had seen Snell's paper and concocted his own proof.  We now know this charge to be undeserved but it has been adopted many times since.\"  Both Fermat and Huygens repeated this accusation that Descartes had copied Snell. In French, Snell's Law is called \"la loi de Descartes\" or \"loi de Snell-Descartes.\"\n\nIn his 1678 Trait\u00e9 de la Lumi\u00e8re, Christiaan Huygens showed how Snell's law of sines could be explained by, or derived from, the wave nature of light, using what we have come to call the Huygens\u2013Fresnel principle.\nWith the development of modern optical and electromagnetic theory, the ancient Snell's law was brought into a new stage.  In 1962, Bloembergen showed that at the boundary of nonlinear medium, the Snell's law should be written in a general form. In 2008 and 2011, plasmonic metasurfaces were also demonstrated to change the reflection and refraction directions of light beam.\n\n\n== Explanation ==\n\nSnell's law is used to determine the direction of light rays through refractive media with varying indices of refraction. The indices of refraction of the media, labeled \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle n_{1}}\n  , \n  \n    \n      \n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle n_{2}}\n   and so on, are used to represent the factor by which a light ray's speed decreases when traveling through a refractive medium, such as glass or water, as opposed to its velocity in a vacuum.\nAs light passes the border between media, depending upon the relative refractive indices of the two media, the light will either be refracted to a lesser angle, or a greater one. These angles are measured with respect to the normal line, represented perpendicular to the boundary. In the case of light traveling from air into water, light would be refracted towards the normal line, because the light is slowed down in water; light traveling from water to air would refract away from the normal line.\nRefraction between two surfaces is also referred to as reversible because if all conditions were identical, the angles would be the same for light propagating in the opposite direction.\nSnell's law is generally true only for isotropic or specular media (such as glass). In anisotropic media such as some crystals, birefringence may split the refracted ray into two rays, the ordinary or o-ray which follows Snell's law, and the other extraordinary or e-ray which may not be co-planar with the incident ray.\nWhen the light or other wave involved is monochromatic, that is, of a single frequency, Snell's law can also be expressed in terms of a ratio of wavelengths in the two media, \n  \n    \n      \n        \n          \u03bb\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{1}}\n   and \n  \n    \n      \n        \n          \u03bb\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{2}}\n  :\n\n  \n    \n      \n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                1\n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n        =\n        \n          \n            \n              \u03bb\n              \n                1\n              \n            \n            \n              \u03bb\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sin \\theta _{1}}{\\sin \\theta _{2}}}={\\frac {v_{1}}{v_{2}}}={\\frac {\\lambda _{1}}{\\lambda _{2}}}}\n  \n\n\n== Derivations and formula ==\n\nSnell's law can be derived in various ways.\n\n\n=== Derivation from Fermat's principle ===\nSnell's law can be derived from Fermat's principle, which states that the light travels the path which takes the least time. By taking the derivative of the optical path length, the stationary point is found giving the path taken by the light. (There are situations of light violating Fermat's principle by not taking the least time path, as in reflection in a (spherical) mirror.) In a classic analogy, the area of lower refractive index is replaced by a beach, the area of higher refractive index by the sea, and the fastest way for a rescuer on the beach to get to a drowning person in the sea is to run along a path that follows Snell's law.\n\nAs shown in the figure to the right, assume the refractive index of medium 1 and medium 2 are \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle n_{1}}\n   and \n  \n    \n      \n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle n_{2}}\n   respectively. Light  enters medium 2 from medium 1 via point O.\n\n  \n    \n      \n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\theta _{1}}\n   is the angle of incidence, \n  \n    \n      \n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta _{2}}\n   is the angle of refraction with respect to the normal.\nThe phase velocities of light in medium 1 and medium 2 are\n\n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        =\n        c\n        \n          /\n        \n        \n          n\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}=c/n_{1}}\n   and\n\n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        c\n        \n          /\n        \n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{2}=c/n_{2}}\n   respectively.\n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n    is the speed of light in vacuum.\nLet T be the time required for the light to travel from point Q through point O to point P. \n\n  \n    \n      \n        T\n        =\n        \n          \n            \n              \n                x\n                \n                  2\n                \n              \n              +\n              \n                a\n                \n                  2\n                \n              \n            \n            \n              v\n              \n                1\n              \n            \n          \n        \n        +\n        \n          \n            \n              \n                b\n                \n                  2\n                \n              \n              +\n              (\n              l\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                x\n                \n                  2\n                \n              \n              +\n              \n                a\n                \n                  2\n                \n              \n            \n            \n              v\n              \n                1\n              \n            \n          \n        \n        +\n        \n          \n            \n              \n                b\n                \n                  2\n                \n              \n              +\n              \n                l\n                \n                  2\n                \n              \n              \u2212\n              2\n              l\n              x\n              +\n              \n                x\n                \n                  2\n                \n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle T={\\frac {\\sqrt {x^{2}+a^{2}}}{v_{1}}}+{\\frac {\\sqrt {b^{2}+(l-x)^{2}}}{v_{2}}}={\\frac {\\sqrt {x^{2}+a^{2}}}{v_{1}}}+{\\frac {\\sqrt {b^{2}+l^{2}-2lx+x^{2}}}{v_{2}}}}\n  where a, b, l and x are as denoted in the right-hand figure, x being the varying parameter.\nTo minimize it, one can differentiate :\n\n  \n    \n      \n        \n          \n            \n              d\n              T\n            \n            \n              d\n              x\n            \n          \n        \n        =\n        \n          \n            x\n            \n              \n                v\n                \n                  1\n                \n              \n              \n                \n                  \n                    x\n                    \n                      2\n                    \n                  \n                  +\n                  \n                    a\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              \u2212\n              (\n              l\n              \u2212\n              x\n              )\n            \n            \n              \n                v\n                \n                  2\n                \n              \n              \n                \n                  (\n                  l\n                  \u2212\n                  x\n                  \n                    )\n                    \n                      2\n                    \n                  \n                  +\n                  \n                    b\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle {\\frac {dT}{dx}}={\\frac {x}{v_{1}{\\sqrt {x^{2}+a^{2}}}}}+{\\frac {-(l-x)}{v_{2}{\\sqrt {(l-x)^{2}+b^{2}}}}}=0}\n   (stationary point)Note that\n\n  \n    \n      \n        \n          \n            x\n            \n              \n                x\n                \n                  2\n                \n              \n              +\n              \n                a\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\frac {x}{\\sqrt {x^{2}+a^{2}}}}=\\sin \\theta _{1}}\n  \nand \n  \n    \n      \n        \n          \n            \n              l\n              \u2212\n              x\n            \n            \n              (\n              l\n              \u2212\n              x\n              \n                )\n                \n                  2\n                \n              \n              +\n              \n                b\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {l-x}{\\sqrt {(l-x)^{2}+b^{2}}}}=\\sin \\theta _{2}}\n  \nTherefore, \n\n  \n    \n      \n        \n          \n            \n              d\n              T\n            \n            \n              d\n              x\n            \n          \n        \n        =\n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            \n              v\n              \n                1\n              \n            \n          \n        \n        \u2212\n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle {\\frac {dT}{dx}}={\\frac {\\sin \\theta _{1}}{v_{1}}}-{\\frac {\\sin \\theta _{2}}{v_{2}}}=0}\n  \n  \n    \n      \n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            \n              v\n              \n                1\n              \n            \n          \n        \n        =\n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sin \\theta _{1}}{v_{1}}}={\\frac {\\sin \\theta _{2}}{v_{2}}}}\n  \n  \n    \n      \n        \n          \n            \n              \n                n\n                \n                  1\n                \n              \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            c\n          \n        \n        =\n        \n          \n            \n              \n                n\n                \n                  2\n                \n              \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n            c\n          \n        \n      \n    \n    {\\displaystyle {\\frac {n_{1}\\sin \\theta _{1}}{c}}={\\frac {n_{2}\\sin \\theta _{2}}{c}}}\n  \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle n_{1}\\sin \\theta _{1}=n_{2}\\sin \\theta _{2}}\n  \n\n\n=== Derivation from Huygens's principle ===\n\nAlternatively, Snell's law can be derived using interference of all possible paths of light wave from source to observer\u2014it results in destructive interference everywhere except extrema of phase (where interference is constructive)\u2014which become actual paths.\n\n\n=== Derivation from Maxwell's equations ===\n\nAnother way to derive Snell's Law involves an application of the general boundary conditions of Maxwell equations for electromagnetic radiation and induction.\n\n\n=== Derivation from conservation of energy and momentum ===\nYet another way to derive Snell's law is based on translation symmetry considerations. For example, a homogeneous surface perpendicular to the z direction cannot change the transverse momentum. Since the propagation vector \n  \n    \n      \n        \n          \n            \n              k\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {k}}}\n   is proportional to the photon's momentum, the transverse propagation direction \n  \n    \n      \n        (\n        \n          k\n          \n            x\n          \n        \n        ,\n        \n          k\n          \n            y\n          \n        \n        ,\n        0\n        )\n      \n    \n    {\\displaystyle (k_{x},k_{y},0)}\n   must remain the same in both regions. Assume without loss of generality a plane of incidence in the \n  \n    \n      \n        z\n        ,\n        x\n      \n    \n    {\\displaystyle z,x}\n   plane \n  \n    \n      \n        \n          k\n          \n            x\n            \n              \n                Region\n              \n              \n                1\n              \n            \n          \n        \n        =\n        \n          k\n          \n            x\n            \n              \n                Region\n              \n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle k_{x{\\text{Region}}_{1}}=k_{x{\\text{Region}}_{2}}}\n  . Using the well known dependence of the wavenumber on the refractive index of the medium, we derive Snell's law immediately.\n\n  \n    \n      \n        \n          k\n          \n            x\n            \n              \n                Region\n              \n              \n                1\n              \n            \n          \n        \n        =\n        \n          k\n          \n            x\n            \n              \n                Region\n              \n              \n                2\n              \n            \n          \n        \n        \n      \n    \n    {\\displaystyle k_{x{\\text{Region}}_{1}}=k_{x{\\text{Region}}_{2}}\\,}\n  \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        \n          k\n          \n            0\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        \n          k\n          \n            0\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        \n      \n    \n    {\\displaystyle n_{1}k_{0}\\sin \\theta _{1}=n_{2}k_{0}\\sin \\theta _{2}\\,}\n  \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        \n      \n    \n    {\\displaystyle n_{1}\\sin \\theta _{1}=n_{2}\\sin \\theta _{2}\\,}\n  where \n  \n    \n      \n        \n          k\n          \n            0\n          \n        \n        =\n        \n          \n            \n              2\n              \u03c0\n            \n            \n              \u03bb\n              \n                0\n              \n            \n          \n        \n        =\n        \n          \n            \u03c9\n            c\n          \n        \n      \n    \n    {\\displaystyle k_{0}={\\frac {2\\pi }{\\lambda _{0}}}={\\frac {\\omega }{c}}}\n   is the wavenumber in vacuum. Although no surface is truly homogeneous at the atomic scale, full translational symmetry is an excellent approximation whenever the region is homogeneous on the scale of the light wavelength.\n\n\n=== Vector form ===\n\nGiven a normalized light vector \n  \n    \n      \n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {l}}}\n   (pointing from the light source toward the surface) and a normalized plane normal vector \n  \n    \n      \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {n}}}\n  , one can work out the normalized reflected and refracted rays, via the cosines of the angle of incidence \n  \n    \n      \n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\theta _{1}}\n   and angle of refraction \n  \n    \n      \n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta _{2}}\n  , without explicitly using the sine values or any trigonometric functions or angles:\n\n  \n    \n      \n        cos\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \u2212\n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\cos \\theta _{1}=-{\\vec {n}}\\cdot {\\vec {l}}}\n  Note: \n  \n    \n      \n        cos\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\cos \\theta _{1}}\n   must be positive, which it will be if \n  \n    \n      \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {n}}}\n   is the normal vector that points from the surface toward the side where the light is coming from, the region with index \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle n_{1}}\n  . If \n  \n    \n      \n        cos\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\cos \\theta _{1}}\n   is negative, then \n  \n    \n      \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {n}}}\n   points to the side without the light, so start over with \n  \n    \n      \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {n}}}\n   replaced by its negative.\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              r\n              e\n              f\n              l\n              e\n              c\n              t\n            \n          \n        \n        =\n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n        +\n        2\n        cos\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {reflect} }={\\vec {l}}+2\\cos \\theta _{1}{\\vec {n}}}\n  This reflected direction vector points back toward the side of the surface where the light came from.\nNow apply Snell's law to the ratio of sines to derive the formula for the refracted ray's direction vector:\n\n  \n    \n      \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        =\n        \n          (\n          \n            \n              \n                n\n                \n                  1\n                \n              \n              \n                n\n                \n                  2\n                \n              \n            \n          \n          )\n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          (\n          \n            \n              \n                n\n                \n                  1\n                \n              \n              \n                n\n                \n                  2\n                \n              \n            \n          \n          )\n        \n        \n          \n            1\n            \u2212\n            \n              \n                (\n                \n                  cos\n                  \u2061\n                  \n                    \u03b8\n                    \n                      1\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sin \\theta _{2}=\\left({\\frac {n_{1}}{n_{2}}}\\right)\\sin \\theta _{1}=\\left({\\frac {n_{1}}{n_{2}}}\\right){\\sqrt {1-\\left(\\cos \\theta _{1}\\right)^{2}}}}\n  \n\n  \n    \n      \n        cos\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        =\n        \n          \n            1\n            \u2212\n            (\n            sin\n            \u2061\n            \n              \u03b8\n              \n                2\n              \n            \n            \n              )\n              \n                2\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \u2212\n            \n              \n                (\n                \n                  \n                    \n                      n\n                      \n                        1\n                      \n                    \n                    \n                      n\n                      \n                        2\n                      \n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            \n              (\n              \n                1\n                \u2212\n                \n                  \n                    (\n                    \n                      cos\n                      \u2061\n                      \n                        \u03b8\n                        \n                          1\n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle \\cos \\theta _{2}={\\sqrt {1-(\\sin \\theta _{2})^{2}}}={\\sqrt {1-\\left({\\frac {n_{1}}{n_{2}}}\\right)^{2}\\left(1-\\left(\\cos \\theta _{1}\\right)^{2}\\right)}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              r\n              e\n              f\n              r\n              a\n              c\n              t\n            \n          \n        \n        =\n        \n          (\n          \n            \n              \n                n\n                \n                  1\n                \n              \n              \n                n\n                \n                  2\n                \n              \n            \n          \n          )\n        \n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n        +\n        \n          (\n          \n            \n              \n                \n                  n\n                  \n                    1\n                  \n                \n                \n                  n\n                  \n                    2\n                  \n                \n              \n            \n            cos\n            \u2061\n            \n              \u03b8\n              \n                1\n              \n            \n            \u2212\n            cos\n            \u2061\n            \n              \u03b8\n              \n                2\n              \n            \n          \n          )\n        \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {refract} }=\\left({\\frac {n_{1}}{n_{2}}}\\right){\\vec {l}}+\\left({\\frac {n_{1}}{n_{2}}}\\cos \\theta _{1}-\\cos \\theta _{2}\\right){\\vec {n}}}\n  The formula may appear simpler in terms of renamed simple values \n  \n    \n      \n        r\n        =\n        \n          n\n          \n            1\n          \n        \n        \n          /\n        \n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle r=n_{1}/n_{2}}\n   and \n  \n    \n      \n        c\n        =\n        \u2212\n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle c=-{\\vec {n}}\\cdot {\\vec {l}}}\n  , avoiding any appearance of trig function  names or angle names:\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              r\n              e\n              f\n              r\n              a\n              c\n              t\n            \n          \n        \n        =\n        r\n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n        +\n        \n          (\n          \n            r\n            c\n            \u2212\n            \n              \n                1\n                \u2212\n                \n                  r\n                  \n                    2\n                  \n                \n                \n                  (\n                  \n                    1\n                    \u2212\n                    \n                      c\n                      \n                        2\n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n          )\n        \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {refract} }=r{\\vec {l}}+\\left(rc-{\\sqrt {1-r^{2}\\left(1-c^{2}\\right)}}\\right){\\vec {n}}}\n  Example:\n\n  \n    \n      \n        \n          \n            \n              l\n              \u2192\n            \n          \n        \n        =\n        {\n        0.707107\n        ,\n        \u2212\n        0.707107\n        }\n        ,\n         \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n        =\n        {\n        0\n        ,\n        1\n        }\n        ,\n         \n        r\n        =\n        \n          \n            \n              n\n              \n                1\n              \n            \n            \n              n\n              \n                2\n              \n            \n          \n        \n        =\n        0.9\n      \n    \n    {\\displaystyle {\\vec {l}}=\\{0.707107,-0.707107\\},~{\\vec {n}}=\\{0,1\\},~r={\\frac {n_{1}}{n_{2}}}=0.9}\n  \n\n  \n    \n      \n        c\n        =\n        cos\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        0.707107\n        ,\n         \n        \n          \n            1\n            \u2212\n            \n              r\n              \n                2\n              \n            \n            \n              (\n              \n                1\n                \u2212\n                \n                  c\n                  \n                    2\n                  \n                \n              \n              )\n            \n          \n        \n        =\n        cos\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        =\n        0.771362\n      \n    \n    {\\displaystyle c=\\cos \\theta _{1}=0.707107,~{\\sqrt {1-r^{2}\\left(1-c^{2}\\right)}}=\\cos \\theta _{2}=0.771362}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              r\n              e\n              f\n              l\n              e\n              c\n              t\n            \n          \n        \n        =\n        {\n        0.707107\n        ,\n        0.707107\n        }\n        ,\n         \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              r\n              e\n              f\n              r\n              a\n              c\n              t\n            \n          \n        \n        =\n        {\n        0.636396\n        ,\n        \u2212\n        0.771362\n        }\n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {reflect} }=\\{0.707107,0.707107\\},~{\\vec {v}}_{\\mathrm {refract} }=\\{0.636396,-0.771362\\}}\n  The cosine values may be saved and used in the Fresnel equations for working out the intensity of the resulting rays.\nTotal internal reflection is indicated by a negative radicand in the equation for \n  \n    \n      \n        cos\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\cos \\theta _{2}}\n  , which can only happen for rays crossing into a less-dense medium (\n  \n    \n      \n        \n          n\n          \n            2\n          \n        \n        <\n        \n          n\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle n_{2}<n_{1}}\n  ).\n\n\n== Total internal reflection and critical angle ==\n\nWhen light travels from a medium with a higher refractive index to one with a lower refractive index, Snell's law seems to require in some cases (whenever the angle of incidence is large enough) that the sine of the angle of refraction be greater than one. This of course is impossible, and the light in such cases is completely reflected by the boundary, a phenomenon known as total internal reflection. The largest possible angle of incidence which still results in a refracted ray is called the critical angle; in this case the refracted ray travels along the boundary between the two media.\n\nFor example, consider a ray of light moving from water to air with an angle of incidence of 50\u00b0. The refractive indices of water and air are approximately 1.333 and 1, respectively, so Snell's law gives us the relation\n\n  \n    \n      \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        =\n        \n          \n            \n              n\n              \n                1\n              \n            \n            \n              n\n              \n                2\n              \n            \n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          \n            1.333\n            1\n          \n        \n        \u22c5\n        sin\n        \u2061\n        \n          (\n          \n            50\n            \n              \u2218\n            \n          \n          )\n        \n        =\n        1.333\n        \u22c5\n        0.766\n        =\n        1.021\n        ,\n      \n    \n    {\\displaystyle \\sin \\theta _{2}={\\frac {n_{1}}{n_{2}}}\\sin \\theta _{1}={\\frac {1.333}{1}}\\cdot \\sin \\left(50^{\\circ }\\right)=1.333\\cdot 0.766=1.021,}\n  which is impossible to satisfy. The critical angle \u03b8crit is the value of \u03b81 for which \u03b82 equals 90\u00b0:\n\n  \n    \n      \n        \n          \u03b8\n          \n            crit\n          \n        \n        =\n        arcsin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  n\n                  \n                    2\n                  \n                \n                \n                  n\n                  \n                    1\n                  \n                \n              \n            \n            sin\n            \u2061\n            \n              \u03b8\n              \n                2\n              \n            \n          \n          )\n        \n        =\n        arcsin\n        \u2061\n        \n          \n            \n              n\n              \n                2\n              \n            \n            \n              n\n              \n                1\n              \n            \n          \n        \n        =\n        \n          48.6\n          \n            \u2218\n          \n        \n        .\n      \n    \n    {\\displaystyle \\theta _{\\text{crit}}=\\arcsin \\left({\\frac {n_{2}}{n_{1}}}\\sin \\theta _{2}\\right)=\\arcsin {\\frac {n_{2}}{n_{1}}}=48.6^{\\circ }.}\n  \n\n\n== Dispersion ==\n\nIn many wave-propagation media, wave velocity changes with frequency or wavelength of the waves; this is true of light propagation in most transparent substances other than a vacuum.  These media are called dispersive.  The result is that the angles determined by Snell's law also depend on frequency or wavelength, so that a ray of mixed wavelengths, such as white light, will spread or disperse.  Such dispersion of light in glass or water underlies the origin of rainbows and other optical phenomena, in which different wavelengths appear as different colors.\nIn optical instruments, dispersion leads to chromatic aberration; a color-dependent blurring that sometimes is the resolution-limiting effect.  This was especially true in refracting telescopes, before the invention of achromatic objective lenses.\n\n\n== Lossy, absorbing, or conducting media ==\n\nIn a conducting medium, permittivity and index of refraction are complex-valued. Consequently, so are the angle of refraction and the wave-vector. This implies that, while the surfaces of constant real phase are planes whose normals make an angle equal to the angle of refraction with the interface normal, the surfaces of constant amplitude, in contrast, are planes parallel to the interface itself. Since these two planes do not in general coincide with each other, the wave is said to be inhomogeneous. The refracted wave is exponentially attenuated, with exponent proportional to the imaginary component of the index of refraction.\n\n\n== See also ==\nList of refractive indices\nThe refractive index vs wavelength of light \u2013 Empirical relationship between refractive index and wavelength\nEvanescent wave \u2013 Type of field where the net flow of electromagnetic energy is zeroPages displaying short descriptions of redirect targets\nReflection (physics) \u2013 \"Bouncing back\" of waves at an interface\nSnell's window \u2013 Underwater phenomenon due to Snell's Law\nCalculus of variations \u2013 Differential calculus on function spaces\nBrachistochrone curve \u2013 Fastest curve descent without friction for a simple proof by Jacob Bernoulli\nHamiltonian optics\nComputation of radiowave attenuation in the atmosphere\nN-slit interferometric equation\n\n\n== References ==\n\n\n== External links ==\nIbn Sahl and Snell's Law\nDiscovery of the law of refraction\nSnell's Law of Refraction (Wave Fronts) by Todd Rowland, Wolfram Demonstrations Project\nSnell's law on a wall in downtown Leiden Archived 2018-04-27 at the Wayback Machine\nShore line effect", "Hooke's_law": "In physics, Hooke's law is an empirical law which states that the force (F) needed to extend or compress a spring by some distance (x) scales linearly with respect to that distance\u2014that is, Fs = kx, where k is a constant factor characteristic of the spring (i.e., its stiffness), and x is small compared to the total possible deformation of the spring. The law is named after 17th-century British physicist Robert Hooke. He first stated the law in 1676 as a Latin anagram. He published the solution of his anagram in 1678 as: ut tensio, sic vis (\"as the extension, so the force\" or \"the extension is proportional to the force\"). Hooke states in the 1678 work that he was aware of the law since 1660.\nHooke's equation holds (to some extent) in many other situations where an elastic body is deformed, such as wind blowing on a tall building, and a musician plucking a string of a guitar. An elastic body or material for which this equation can be assumed is said to be linear-elastic or Hookean.\nHooke's law is only a first-order linear approximation to the real response of springs and other elastic bodies to applied forces. It must eventually fail once the forces exceed some limit, since no material can be compressed beyond a certain minimum size, or stretched beyond a maximum size, without some permanent deformation or change of state. Many materials will noticeably deviate from Hooke's law well before those elastic limits are reached.\nOn the other hand, Hooke's law is an accurate approximation for most solid bodies, as long as the forces and deformations are small enough. For this reason, Hooke's law is extensively used in all branches of science and engineering, and is the foundation of many disciplines such as seismology, molecular mechanics and acoustics. It is also the fundamental principle behind the spring scale, the manometer, the galvanometer, and the balance wheel of the mechanical clock.\nThe modern theory of elasticity generalizes Hooke's law to say that the strain (deformation) of an elastic object or material is proportional to the stress applied to it. However, since general stresses and strains may have multiple independent components, the \"proportionality factor\" may no longer be just a single real number, but rather a linear map (a tensor) that can be represented by a matrix of real numbers.\nIn this general form, Hooke's law makes it possible to deduce the relation between strain and stress for complex objects in terms of intrinsic properties of the materials they are made of. For example, one can deduce that a homogeneous rod with uniform cross section will behave like a simple spring when stretched, with a stiffness k directly proportional to its cross-section area and inversely proportional to its length.\n\n\n== Formal definition ==\n\n\n=== For linear springs ===\nConsider a simple helical spring that has one end attached to some fixed object, while the free end is being pulled by a force whose magnitude is Fs. Suppose that the spring has reached a state of equilibrium, where its length is not changing anymore. Let x be the amount by which the free end of the spring was displaced from its \"relaxed\" position (when it is not being stretched). Hooke's law states that  or, equivalently,  where k is a positive real number, characteristic of the spring. Moreover, the same formula holds when the spring is compressed, with Fs and x both negative in that case. According to this formula, the graph of the applied force Fs as a function of the displacement x will be a straight line passing through the origin, whose slope is k.\nHooke's law for a spring is sometimes, but rarely, stated under the convention that Fs is the restoring force exerted by the spring on whatever is pulling its free end. In that case, the equation becomes  since the direction of the restoring force is opposite to that of the displacement.\n\n\n=== General \"scalar\" springs ===\nHooke's spring law usually applies to any elastic object, of arbitrary complexity, as long as both the deformation and the stress can be expressed by a single number that can be both positive and negative.\nFor example, when a block of rubber attached to two parallel plates is deformed by shearing, rather than stretching or compression, the shearing force Fs and the sideways displacement of the plates x obey Hooke's law (for small enough deformations).\nHooke's law also applies when a straight steel bar or concrete beam (like the one used in buildings), supported at both ends, is bent by a weight F placed at some intermediate point. The displacement x in this case is the deviation of the beam, measured in the transversal direction, relative to its unloaded shape.\nThe law also applies when a stretched steel wire is twisted by pulling on a lever attached to one end. In this case the stress Fs can be taken as the force applied to the lever, and x as the distance traveled by it along its circular path. Or, equivalently, one can let Fs be the torque applied by the lever to the end of the wire, and x be the angle by which that end turns. In either case Fs is proportional to x (although the constant k is different in each case.)\n\n\n=== Vector formulation ===\nIn the case of a helical spring that is stretched or compressed along its axis, the applied (or restoring) force and the resulting elongation or compression have the same direction (which is the direction of said axis). Therefore, if Fs and x are defined as vectors, Hooke's equation still holds and says that the force vector is the elongation vector multiplied by a fixed scalar.\n\n\n=== General tensor form ===\nSome elastic bodies will deform in one direction when subjected to a force with a different direction. One example is a horizontal wood beam with non-square rectangular cross section that is bent by a transverse load that is neither vertical nor horizontal. In such cases, the magnitude of the displacement x will be proportional to the magnitude of the force Fs, as long as the direction of the latter remains the same (and its value is not too large); so the scalar version of Hooke's law Fs = \u2212kx will hold. However, the force and displacement vectors will not be scalar multiples of each other, since they have different directions. Moreover, the ratio k between their magnitudes will depend on the direction of the vector Fs.\nYet, in such cases there is often a fixed linear relation between the force and deformation vectors, as long as they are small enough. Namely, there is a function \u03ba from vectors to vectors, such that F = \u03ba(X), and \u03ba(\u03b1X1 + \u03b2X2) = \u03b1\u03ba(X1) + \u03b2\u03ba(X2) for any real numbers \u03b1, \u03b2 and any displacement vectors X1, X2. Such a function is called a (second-order) tensor.\nWith respect to an arbitrary Cartesian coordinate system, the force and displacement vectors can be represented by 3 \u00d7 1 matrices of real numbers. Then the tensor \u03ba connecting them can be represented by a 3 \u00d7 3 matrix \u03ba of real coefficients, that, when multiplied by the displacement vector, gives the force vector:\n\nThat is,  for i = 1, 2, 3. Therefore, Hooke's law F = \u03baX can be said to hold also when X and F are vectors with variable directions, except that the stiffness of the object is a tensor \u03ba, rather than a single real number k.\n\n\n=== Hooke's law for continuous media ===\n\nThe stresses and strains of the material inside a continuous elastic material (such as a block of rubber, the wall of a boiler, or a steel bar) are connected by a linear relationship that is mathematically similar to Hooke's spring law, and is often referred to by that name.\nHowever, the strain state in a solid medium around some point cannot be described by a single vector. The same parcel of material, no matter how small, can be compressed, stretched, and sheared at the same time, along different directions. Likewise, the stresses in that parcel can be at once pushing, pulling, and shearing.\nIn order to capture this complexity, the relevant state of the medium around a point must be represented by two-second-order tensors, the strain tensor \u03b5 (in lieu of the displacement X) and the stress tensor \u03c3 (replacing the restoring force F). The analogue of Hooke's spring law for continuous media is then  where c is a fourth-order tensor (that is, a linear map between second-order tensors) usually called the stiffness tensor or elasticity tensor. One may also write it as  where the tensor s, called the compliance tensor, represents the inverse of said linear map.\nIn a Cartesian coordinate system, the stress and strain tensors can be represented by 3 \u00d7 3 matrices\n\nBeing a linear mapping between the nine numbers \u03c3ij and the nine numbers \u03b5kl, the stiffness tensor c is represented by a matrix of 3 \u00d7 3 \u00d7 3 \u00d7 3 = 81 real numbers cijkl. Hooke's law then says that\n\nwhere i,j = 1,2,3.\nAll three tensors generally vary from point to point inside the medium, and may vary with time as well. The strain tensor \u03b5 merely specifies the displacement of the medium particles in the neighborhood of the point, while the stress tensor \u03c3 specifies the forces that neighboring parcels of the medium are exerting on each other. Therefore, they are independent of the composition and physical state of the material. The stiffness tensor c, on the other hand, is a property of the material, and often depends on physical state variables such as temperature, pressure, and microstructure.\nDue to the inherent symmetries of \u03c3, \u03b5, and c, only 21 elastic coefficients of the latter are independent.  This number can be further reduced by the symmetry of the material: 9 for an orthorhombic crystal, 5 for an hexagonal structure, and 3 for a cubic symmetry. For isotropic media (which have the same physical properties in any direction), c can be reduced to only two independent numbers, the bulk modulus K and the shear modulus G, that quantify the material's resistance to changes in volume and to shearing deformations, respectively.\n\n\n== Analogous laws ==\nSince Hooke's law is a simple proportionality between two quantities, its formulas and consequences are mathematically similar to those of many other physical laws, such as those describing the motion of fluids, or the polarization of a dielectric by an electric field.\nIn particular, the tensor equation \u03c3 = c\u03b5 relating elastic stresses to strains is entirely similar to the equation \u03c4 = \u03bc\u03b5\u0307 relating the viscous stress tensor \u03c4 and the strain rate tensor \u03b5\u0307 in flows of viscous fluids; although the former pertains to static stresses (related to amount of deformation) while the latter pertains to dynamical stresses (related to the rate of deformation).\n\n\n== Units of measurement ==\nIn SI units, displacements are measured in meters (m), and forces in newtons (N or kg\u00b7m/s2). Therefore, the spring constant k, and each element of the tensor \u03ba, is measured in newtons per meter (N/m), or kilograms per second squared (kg/s2).\nFor continuous media, each element of the stress tensor \u03c3 is a force divided by an area; it is therefore measured in units of pressure, namely pascals (Pa, or N/m2, or kg/(m\u00b7s2). The elements of the strain tensor \u03b5 are dimensionless (displacements divided by distances). Therefore, the entries of cijkl are also expressed in units of pressure.\n\n\n== General application to elastic materials ==\n\nObjects that quickly regain their original shape after being deformed by a force, with the molecules or atoms of their material returning to the initial state of stable equilibrium, often obey Hooke's law.\nHooke's law only holds for some materials under certain loading conditions. Steel exhibits linear-elastic behavior in most engineering applications; Hooke's law is valid for it throughout its elastic range (i.e., for stresses below the yield strength). For some other materials, such as aluminium, Hooke's law is only valid for a portion of the elastic range. For these materials a proportional limit stress is defined, below which the errors associated with the linear approximation are negligible.\nRubber is generally regarded as a \"non-Hookean\" material because its elasticity is stress dependent and sensitive to temperature and loading rate.\nGeneralizations of Hooke's law for the case of large deformations is provided by models of neo-Hookean solids and Mooney\u2013Rivlin solids.\n\n\n== Derived formulae ==\n\n\n=== Tensional stress of a uniform bar ===\nA rod of any elastic material may be viewed as a linear spring. The rod has length L and cross-sectional area A. Its tensile stress \u03c3 is linearly proportional to its fractional extension or strain \u03b5 by the modulus of elasticity E:\n\nThe modulus of elasticity may often be considered constant. In turn,\n\n(that is, the fractional change in length), and since\n\nit follows that:\n\nThe change in length may be expressed as\n\n\n=== Spring energy ===\nThe potential energy Uel(x) stored in a spring is given by  which comes from adding up the energy it takes to incrementally compress the spring. That is, the integral of force over displacement. Since the external force has the same general direction as the displacement, the potential energy of a spring is always non-negative.\nThis potential Uel can be visualized as a parabola on the Ux-plane such that Uel(x) = 1/2kx2. As the spring is stretched in the positive x-direction, the potential energy increases parabolically (the same thing happens as the spring is compressed). Since the change in potential energy changes at a constant rate:\n\nNote that the change in the change in U is constant even when the displacement and acceleration are zero.\n\n\n=== Relaxed force constants (generalized compliance constants) ===\nRelaxed force constants (the inverse of generalized compliance constants) are uniquely defined for molecular systems, in contradistinction to the usual \"rigid\" force constants, and thus their use allows meaningful correlations to be made between force fields calculated for reactants, transition states, and products of a chemical reaction. Just as the potential energy can be written as a quadratic form in the internal coordinates, so it can also be written in terms of generalized forces. The resulting coefficients are termed compliance constants. A direct method exists for calculating the compliance constant for any internal coordinate of a molecule, without the need to do the normal mode analysis. The suitability of relaxed force constants (inverse compliance constants) as covalent bond strength descriptors was demonstrated as early as 1980. Recently, the suitability as non-covalent bond strength descriptors was demonstrated too.\n\n\n=== Harmonic oscillator ===\n\nA mass m attached to the end of a spring is a classic example of a harmonic oscillator. By pulling slightly on the mass and then releasing it, the system will be set in sinusoidal oscillating motion about the equilibrium position. To the extent that the spring obeys Hooke's law, and that one can neglect friction and the mass of the spring, the amplitude of the oscillation will remain constant; and its frequency f will be independent of its amplitude, determined only by the mass and the stiffness of the spring:\n\nThis phenomenon made possible the construction of accurate mechanical clocks and watches that could be carried on ships and people's pockets.\n\n\n=== Rotation in gravity-free space ===\nIf the mass m were attached to a spring with force constant k and rotating in free space, the spring tension (Ft) would supply the required centripetal force (Fc):\n\nSince Ft = Fc and x = r, then:\n\nGiven that \u03c9 = 2\u03c0f, this leads to the same frequency equation as above:\n\n\n== Linear elasticity theory for continuous media ==\n\nNote: the Einstein summation convention of summing on repeated indices is used below.\n\n\n=== Isotropic materials ===\n\nIsotropic materials are characterized by properties which are independent of direction in space. Physical equations involving isotropic materials must therefore be independent of the coordinate system chosen to represent them. The strain tensor is a symmetric tensor. Since the trace of any tensor is independent of any coordinate system, the most complete coordinate-free decomposition of a symmetric tensor is to represent it as the sum of a constant tensor and a traceless symmetric tensor. Thus in index notation:\n\nwhere \u03b4ij is the Kronecker delta. In direct tensor notation:\n\nwhere I is the second-order identity tensor.\nThe first term on the right is the constant tensor, also known as the volumetric strain tensor, and the second term is the traceless symmetric tensor, also known as the deviatoric strain tensor or shear tensor.\nThe most general form of Hooke's law for isotropic materials may now be written as a linear combination of these two tensors:\n\nwhere K is the bulk modulus and G is the shear modulus.\nUsing the relationships between the elastic moduli, these equations may also be expressed in various other ways. A common form of Hooke's law for isotropic materials, expressed in direct tensor notation, is\n\n  \n    \n      \n        \n          \u03c3\n        \n        =\n        \u03bb\n        tr\n        \u2061\n        (\n        \n          \u03b5\n        \n        )\n        \n          I\n        \n        +\n        2\n        \u03bc\n        \n          \u03b5\n        \n        =\n        \n          \n            c\n          \n        \n        :\n        \n          \u03b5\n        \n        \n        ;\n        \n        \n          \n            c\n          \n        \n        =\n        \u03bb\n        \n          I\n        \n        \u2297\n        \n          I\n        \n        +\n        2\n        \u03bc\n        \n          \n            I\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\sigma }}=\\lambda \\operatorname {tr} ({\\boldsymbol {\\varepsilon }})\\mathbf {I} +2\\mu {\\boldsymbol {\\varepsilon }}={\\mathsf {c}}:{\\boldsymbol {\\varepsilon }}\\,;\\qquad {\\mathsf {c}}=\\lambda \\mathbf {I} \\otimes \\mathbf {I} +2\\mu {\\mathsf {I}}}\n  \nwhere \u03bb = K \u2212 2/3G = c1111 \u2212 2c1212 and \u03bc = G = c1212 are the Lam\u00e9 constants, I is the second-rank identity tensor, and I is the symmetric part of the fourth-rank identity tensor. In index notation:\n\nThe inverse relationship is\nTherefore, the compliance tensor in the relation \u03b5 = s : \u03c3 is\n\nIn terms of Young's modulus and Poisson's ratio, Hooke's law for isotropic materials can then be expressed as\n\nThis is the form in which the strain is expressed in terms of the stress tensor in engineering. The expression in expanded form is\n\nwhere E is Young's modulus and \u03bd is Poisson's ratio. (See 3-D elasticity).\n\nIn matrix form, Hooke's law for isotropic materials can be written as\n\nwhere \u03b3ij = 2\u03b5ij is the engineering shear strain. The inverse relation may be written as\n\nwhich can be simplified thanks to the Lam\u00e9 constants:\n\nIn vector notation this becomes\n\nwhere I is the identity tensor.\n\n\n==== Plane stress ====\nUnder plane stress conditions, \u03c331 = \u03c313 = \u03c332 = \u03c323 = \u03c333 = 0. In that case Hooke's law takes the form\n\nIn vector notation this becomes\n\nThe inverse relation is usually written in the reduced form\n\n\n==== Plane strain ====\nUnder plane strain conditions, \u03b531 = \u03b513 = \u03b532 = \u03b523 = \u03b533 = 0. In this case Hooke's law takes the form\n\n\n=== Anisotropic materials ===\nThe symmetry of the Cauchy stress tensor (\u03c3ij = \u03c3ji) and the generalized Hooke's laws (\u03c3ij = cijkl\u03b5kl) implies that cijkl = cjikl. Similarly, the symmetry of the infinitesimal strain tensor implies that cijkl = cijlk. These symmetries are called the minor symmetries of the stiffness tensor c. This reduces the number of elastic constants from 81 to 36.\nIf in addition, since the displacement gradient and the Cauchy stress are work conjugate, the stress\u2013strain relation can be derived from a strain energy density functional (U), then\n\nThe arbitrariness of the order of differentiation implies that cijkl = cklij. These are called the major symmetries of the stiffness tensor. This reduces the number of elastic constants from 36 to 21. The major and minor symmetries indicate that the stiffness tensor has only 21 independent components.\n\n\n==== Matrix representation (stiffness tensor) ====\nIt is often useful to express the anisotropic form of Hooke's law in matrix notation, also called Voigt notation. To do this we take advantage of the symmetry of the stress and strain tensors and express them as six-dimensional vectors in an orthonormal coordinate system (e1,e2,e3) as\n\nThen the stiffness tensor (c) can be expressed as\n\nand Hooke's law is written as\n\nSimilarly the compliance tensor (s) can be written as\n\n\n==== Change of coordinate system ====\nIf a linear elastic material is rotated from a reference configuration to another, then the material is symmetric with respect to the rotation if the components of the stiffness tensor in the rotated configuration are related to the components in the reference configuration by the relation\nwhere lab are the components of an orthogonal rotation matrix [L]. The same relation also holds for inversions.\nIn matrix notation, if the transformed basis (rotated or inverted) is related to the reference basis by\n\nthen\n\nIn addition, if the material is symmetric with respect to the transformation [L] then\n\n\n==== Orthotropic materials ====\n\nOrthotropic materials have three orthogonal planes of symmetry. If the basis vectors (e1,e2,e3) are normals to the planes of symmetry then the coordinate transformation relations imply that\n\nThe inverse of this relation is commonly written as\nwhere\n\nEi is the Young's modulus along axis i\nGij is the shear modulus in direction j on the plane whose normal is in direction i\n\u03bdij is the Poisson's ratio that corresponds to a contraction in direction j when an extension is applied in direction i.Under plane stress conditions, \u03c3zz = \u03c3zx = \u03c3yz = 0, Hooke's law for an orthotropic material takes the form\n\nThe inverse relation is\n\nThe transposed form of the above stiffness matrix is also often used.\n\n\n==== Transversely isotropic materials ====\nA transversely isotropic material is symmetric with respect to a rotation about an axis of symmetry. For such a material, if e3 is the axis of symmetry, Hooke's law can be expressed as\n\nMore frequently, the x \u2261 e1 axis is taken to be the axis of symmetry and the inverse Hooke's law is written as\n\n\n==== Universal elastic anisotropy index ====\nTo grasp the degree of anisotropy of any class, a universal elastic anisotropy index (AU) was formulated. It replaces the Zener ratio, which is suited for cubic crystals.\n\n\n== Thermodynamic basis ==\nLinear deformations of elastic materials can be approximated as adiabatic. Under these conditions and for quasistatic processes the first law of thermodynamics for a deformed body can be expressed as\n\nwhere \u03b4U is the increase in internal energy and \u03b4W is the work done by external forces. The work can be split into two terms\n\nwhere \u03b4Ws is the work done by surface forces while \u03b4Wb is the work done by body forces. If \u03b4u is a variation of the displacement field u in the body, then the two external work terms can be expressed as\n\nwhere t is the surface traction vector, b is the body force vector, \u03a9 represents the body and \u2202\u03a9 represents its surface. Using the relation between the Cauchy stress and the surface traction, t = n \u00b7 \u03c3 (where n is the unit outward normal to \u2202\u03a9), we have\n\nConverting the surface integral into a volume integral via the divergence theorem gives\n\nUsing the symmetry of the Cauchy stress and the identity\n\nwe have the following\n\nFrom the definition of strain and from the equations of equilibrium we have\n\nHence we can write\n\nand therefore the variation in the internal energy density is given by\n\nAn elastic material is defined as one in which the total internal energy is equal to the potential energy of the internal forces (also called the elastic strain energy). Therefore, the internal energy density is a function of the strains, U0 = U0(\u03b5) and the variation of the internal energy can be expressed as\n\nSince the variation of strain is arbitrary, the stress\u2013strain relation of an elastic material is given by\n\nFor a linear elastic material, the quantity \u2202U0/\u2202\u03b5 is a linear function of \u03b5, and can therefore be expressed as\n\nwhere c is a fourth-rank tensor of material constants, also called the stiffness tensor. We can see why c must be a fourth-rank tensor by noting that, for a linear elastic material,\n\nIn index notation\n\nThe right-hand side constant requires four indices and is a fourth-rank quantity. We can also see that this quantity must be a tensor because it is a linear transformation that takes the strain tensor to the stress tensor. We can also show that the constant obeys the tensor transformation rules for fourth-rank tensors.\n\n\n== See also ==\nAcoustoelastic effect\nElastic potential energy\nLaws of science\nList of scientific laws named after people\nQuadratic form\nSeries and parallel springs\nSpring system\nSimple harmonic motion of a mass on a spring\nSine wave\nSolid mechanics\nSpring pendulum\n\n\n== Notes ==\n\n\n== References ==\nHooke\u2019s law - The Feynman Lectures on Physics\nHooke's Law - Classical Mechanics - Physics - MIT OpenCourseWare\n\n\n== External links ==\nJavaScript Applet demonstrating Springs and Hooke's law\nJavaScript Applet demonstrating Spring Force", "Acceleration": "In mechanics, acceleration is the rate of change of the velocity of an object with respect to time. Accelerations are vector quantities (in that they have magnitude and direction). The orientation of an object's acceleration is given by the orientation of the net force acting on that object. The magnitude of an object's acceleration, as described by Newton's Second Law, is the combined effect of two causes:\n\nthe net balance of all external forces acting onto that object \u2014 magnitude is directly proportional to this net resulting force;\nthat object's mass, depending on the materials out of which it is made \u2014 magnitude is inversely proportional to the object's mass.The SI unit for acceleration is metre per second squared (m\u22c5s\u22122, \n  \n    \n      \n        \n          \n            \n              m\n              \n                s\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathrm {\\tfrac {m}{s^{2}}} }\n  ).\nFor example, when a vehicle starts from a standstill (zero velocity, in an inertial frame of reference) and travels in a straight line at increasing speeds, it is accelerating in the direction of travel. If the vehicle turns, an acceleration occurs toward the new direction and changes its motion vector.  The acceleration of the vehicle in its current direction of motion is called a linear (or tangential during circular motions) acceleration, the reaction to which the passengers on board experience as a force pushing them back into their seats. When changing direction, the effecting acceleration is called radial (or centripetal during circular motions) acceleration, the reaction to which the passengers experience as a centrifugal force. If the speed of the vehicle decreases, this is an acceleration in the opposite direction and mathematically a negative, sometimes called deceleration or retardation, and passengers experience the reaction to deceleration as an inertial force pushing them forward.  Such negative accelerations are often achieved by retrorocket burning in spacecraft. Both acceleration and deceleration are treated the same, as they are both changes in velocity. Each of these accelerations (tangential, radial, deceleration) is felt by passengers until their relative (differential) velocity are neutralized in reference to the acceleration due to change in speed.\n\n\n== Definition and properties ==\n\n\n=== Average acceleration ===\n\nAn object's average acceleration over a period of time is its change in velocity, \n  \n    \n      \n        \u0394\n        \n          v\n        \n      \n    \n    {\\displaystyle \\Delta \\mathbf {v} }\n  , divided by the duration of the period, \n  \n    \n      \n        \u0394\n        t\n      \n    \n    {\\displaystyle \\Delta t}\n  . Mathematically,\n\n\n=== Instantaneous acceleration ===\n\nInstantaneous acceleration, meanwhile, is the limit of the average acceleration over an infinitesimal interval of time. In the terms of calculus, instantaneous acceleration is the derivative of the velocity vector with respect to time:\n\nAs acceleration is defined as the derivative of velocity, v, with respect to time t and velocity is defined as the derivative of position, x, with respect to time, acceleration can be thought of as the second derivative of x with respect to t:\n\n(Here and elsewhere, if motion is in a straight line, vector quantities can be substituted by scalars in the equations.)\nBy the fundamental theorem of calculus, it can be seen that the integral of the acceleration function a(t) is the velocity function v(t); that is, the area under the curve of an acceleration vs. time (a vs. t) graph corresponds to the change of velocity.\n\nLikewise, the integral of the jerk function j(t), the derivative of the acceleration function, can be used to find  the change of acceleration at a certain time:\n\n\n=== Units ===\nAcceleration has the dimensions of velocity (L/T) divided by time, i.e. L T\u22122. The SI unit of acceleration is the metre per second squared (m s\u22122); or \"metre per second per second\", as the velocity in metres per second changes by the acceleration value, every second.\n\n\n=== Other forms ===\nAn object moving in a circular motion\u2014such as a satellite orbiting the Earth\u2014is accelerating due to the change of direction of motion, although its speed may be constant. In this case it is said to be undergoing centripetal (directed towards the center) acceleration.\nProper acceleration, the acceleration of a body relative to a free-fall condition, is measured by an instrument called an accelerometer.\nIn classical mechanics, for a body with constant mass, the (vector) acceleration of the body's center of mass is proportional to the net force vector (i.e. sum of all forces) acting on it (Newton's second law):\n\nwhere F is the net force acting on the body, m is  the mass of the body, and a is the center-of-mass acceleration. As speeds approach the speed of light, relativistic effects become increasingly large.\n\n\n== Tangential and centripetal acceleration ==\n\nThe velocity of a particle moving on a curved path as a function of time can be written as:\n\nwith v(t) equal to the speed of travel along the path, and\n\na unit vector tangent to the path pointing in the direction of motion at the chosen moment in time. Taking into account both the changing speed v(t) and the changing direction of ut, the acceleration of a particle moving on a curved path can be written using the chain rule of differentiation for the product of two functions of time as:\n\nwhere un is the  unit (inward) normal vector to the particle's trajectory (also called the principal normal), and r is its instantaneous radius of curvature based upon the osculating circle at time t. These components are called the tangential acceleration and the normal or radial acceleration (or centripetal acceleration in circular motion, see also circular motion and centripetal force).\nGeometrical analysis of three-dimensional space curves, which explains tangent, (principal) normal and binormal, is described by the Frenet\u2013Serret formulas.\n\n\n== Special cases ==\n\n\n=== Uniform acceleration ===\n\nUniform or constant acceleration is a type of motion in which the velocity of an object changes by an equal amount in every equal time period.\nA frequently cited example of uniform acceleration is that of an object in free fall in a uniform gravitational field. The acceleration of a falling body in the absence of resistances to motion is dependent only on the gravitational field strength g (also called acceleration due to gravity). By Newton's Second Law the force \n  \n    \n      \n        \n          \n            F\n            \n              g\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F_{g}} }\n   acting on a body is given by:\n\nBecause of the simple analytic properties of the case of constant acceleration, there are simple formulas relating the displacement, initial and time-dependent velocities, and acceleration to the time elapsed:\nwhere\n\n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is the elapsed time,\n\n  \n    \n      \n        \n          \n            s\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {s} _{0}}\n   is the initial displacement from the origin,\n\n  \n    \n      \n        \n          s\n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle \\mathbf {s} (t)}\n   is the displacement from the origin at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  ,\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{0}}\n   is the initial velocity,\n\n  \n    \n      \n        \n          v\n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle \\mathbf {v} (t)}\n   is the velocity at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , and\n\n  \n    \n      \n        \n          a\n        \n      \n    \n    {\\displaystyle \\mathbf {a} }\n   is the uniform rate of acceleration.In particular, the motion can be resolved into two orthogonal parts, one of constant velocity and the other according to the above equations.  As Galileo showed, the net result is parabolic motion, which describes, e.g., the trajectory of a projectile in vacuum near the surface of Earth.\n\n\n=== Circular motion ===\n\nIn uniform circular motion, that is moving with constant speed along a circular path, a particle experiences an acceleration resulting from the change of the direction of the velocity vector, while its magnitude remains constant. The derivative of the location of a point on a curve with respect to time, i.e. its velocity, turns out to be always exactly tangential to the curve, respectively orthogonal to the radius in this point. Since in uniform motion the velocity in the tangential direction does not change, the acceleration must be in radial direction, pointing to the center of the circle. This acceleration constantly changes the direction of the velocity to be tangent in the neighboring point, thereby rotating the velocity vector along the circle.\n\nFor a given speed \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  , the magnitude of this geometrically caused acceleration (centripetal acceleration) is inversely proportional to the radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   of the circle, and increases as the square of this speed: \nNote that, for a given angular velocity \n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n  , the centripetal acceleration is directly proportional to radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  . This is due to the dependence of velocity \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   on the radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  . Expressing centripetal acceleration vector in polar components, where \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is a vector from the centre of the circle to the particle with magnitude equal to this distance, and considering the orientation of the acceleration towards the center, yields\n\nAs usual in rotations, the speed \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   of a particle may be expressed as an angular speed with respect to a point at the distance \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   as\n\nThus \n  \n    \n      \n        \n          \n            a\n            \n              c\n            \n          \n        \n        =\n        \u2212\n        \n          \u03c9\n          \n            2\n          \n        \n        \n          r\n        \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {a_{c}} =-\\omega ^{2}\\mathbf {r} \\,.}\n  \nThis acceleration and the mass of the particle determine the necessary centripetal force, directed toward the centre of the circle, as the net force acting on this particle to keep it in this uniform circular motion. The so-called 'centrifugal force', appearing to act outward on the body, is a so-called pseudo force experienced in the frame of reference of the body in circular motion, due to the body's linear momentum, a vector tangent to the circle of motion.\nIn a nonuniform circular motion, i.e., the speed along the curved path is changing, the acceleration has a non-zero component tangential to the curve, and is not confined to the principal normal, which directs to the center of the osculating circle, that determines the radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   for the centripetal acceleration. The tangential component is given by the angular acceleration \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  , i.e., the rate of change \n  \n    \n      \n        \u03b1\n        =\n        \n          \n            \n              \u03c9\n              \u02d9\n            \n          \n        \n      \n    \n    {\\displaystyle \\alpha ={\\dot {\\omega }}}\n   of the angular speed \n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   times the radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  . That is,\n\nThe sign of the tangential component of the acceleration is determined by the sign of the angular acceleration (\n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  ), and the tangent is always directed at right angles to the radius vector.\n\n\n== Relation to relativity ==\n\n\n=== Special relativity ===\n\nThe special theory of relativity describes the behavior of objects traveling relative to other objects at speeds approaching that of light in vacuum. Newtonian mechanics is exactly revealed to be an approximation to reality, valid to great accuracy at lower speeds. As the relevant speeds increase toward the speed of light, acceleration no longer follows classical equations.\nAs speeds approach that of light, the acceleration produced by a given force decreases, becoming infinitesimally small as light speed is approached; an object with mass can approach this speed asymptotically, but never reach it.\n\n\n=== General relativity ===\n\nUnless the state of motion of an object is known, it is impossible to distinguish whether an observed force is due to gravity or to acceleration\u2014gravity and inertial acceleration have identical effects. Albert Einstein called this the equivalence principle, and said that only observers who feel no force at all\u2014including the force of gravity\u2014are justified in concluding that they are not accelerating.\n\n\n== Conversions ==\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nAcceleration Calculator Simple acceleration unit converter\nAcceleration Calculator Acceleration Conversion calculator converts units form meter per second square, kilometer per second square, millimeter per second square & more with metric conversion.", "Electron": "The electron (e\u2212 or \u03b2\u2212) is a subatomic particle with a negative one elementary electric charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron's mass is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value, expressed in units of the reduced Planck constant, \u0127. Being fermions, no two electrons can occupy the same quantum state, per the Pauli exclusion principle. Like all elementary particles, electrons exhibit properties of both particles and waves: They can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy.\nElectrons play an essential role in numerous physical phenomena, such as electricity, magnetism, chemistry, and thermal conductivity; they also participate in gravitational, electromagnetic, and weak interactions. Since an electron has charge, it has a surrounding electric field; if that electron is moving relative to an observer, the observer will observe it to generate a magnetic field. Electromagnetic fields produced from other sources will affect the motion of an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when they are accelerated.\nLaboratory instruments are capable of trapping individual electrons as well as electron plasma by the use of electromagnetic fields. Special telescopes can detect electron plasma in outer space. Electrons are involved in many applications, such as tribology or frictional charging, electrolysis, electrochemistry, battery technologies, electronics, welding, cathode-ray tubes, photoelectricity, photovoltaic solar panels, electron microscopes, radiation therapy, lasers, gaseous ionization detectors, and particle accelerators.\nInteractions involving electrons with other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between the positive protons within atomic nuclei and the negative electrons without allows the composition of the two known as atoms. Ionization or differences in the proportions of negative electrons versus positive nuclei changes the binding energy of an atomic system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. In 1838, British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms. Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897 during the cathode-ray tube experiment.  Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons can be created through beta decay of radioactive isotopes and in high-energy collisions, for instance, when cosmic rays enter the atmosphere.  The antiparticle of the electron is called the positron; it is identical to the electron, except that it carries electrical charge of the opposite sign. When an electron collides with a positron, both particles can be annihilated, producing gamma ray photons.\n\n\n== History ==\n\n\n=== Discovery of effect of electric force ===\nThe ancient Greeks noticed that amber attracted small objects when rubbed with fur. Along with lightning, this phenomenon is one of humanity's earliest recorded experiences with electricity. In his 1600 treatise De Magnete, the English scientist William Gilbert coined the New Latin term electrica, to refer to those substances with property similar to that of amber which attract smaller objects after being rubbed. Both electric and electricity are derived from the Latin \u0113lectrum (also the root of the alloy of the same name), which came from the Greek word for amber, \u1f24\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd (\u0113lektron).\n\n\n=== Discovery of two kinds of charges ===\nIn the early 1700s, French chemist Charles Fran\u00e7ois du Fay found that if a charged gold-leaf is repulsed by glass rubbed with silk, then the same charged gold-leaf is attracted by amber rubbed with wool. From this and other results of similar types of experiments, du Fay concluded that electricity consists of two electrical fluids, vitreous fluid from glass rubbed with silk and resinous fluid from amber rubbed with wool.  These two fluids can neutralize each other when combined. American scientist Ebenezer Kinnersley later also independently reached the same conclusion.:\u200a118\u200a A decade later Benjamin Franklin proposed that electricity was not from different types of electrical fluid, but a single electrical fluid showing an excess (+) or deficit (\u2212). He gave them the modern charge nomenclature of positive and negative respectively. Franklin thought of the charge carrier as being positive, but he did not correctly identify which situation was a surplus of the charge carrier, and which situation was a deficit.Between 1838 and 1851, British natural philosopher Richard Laming developed the idea that an atom is composed of a core of matter surrounded by subatomic particles that had unit electric charges. Beginning in 1846, German physicist Wilhelm Eduard Weber theorized that electricity was composed of positively and negatively charged fluids, and their interaction was governed by the inverse square law. After studying the phenomenon of electrolysis in 1874, Irish physicist George Johnstone Stoney suggested that there existed a \"single definite quantity of electricity\", the charge of a monovalent ion. He was able to estimate the value of this elementary charge e by means of Faraday's laws of electrolysis. However, Stoney believed these charges were permanently attached to atoms and could not be removed. In 1881, German physicist Hermann von Helmholtz argued that both positive and negative charges were divided into elementary parts, each of which \"behaves like atoms of electricity\".Stoney initially coined the term electrolion in 1881. Ten years later, he switched to electron to describe these elementary charges, writing in 1894: \"... an estimate was made of the actual amount of this most remarkable fundamental unit of electricity, for which I have since ventured to suggest the name electron\". A 1906 proposal to change to electrion failed because Hendrik Lorentz preferred to keep electron. The word electron is a combination of the words electric and ion. The suffix -on which is now used to designate other subatomic particles, such as a proton or neutron, is in turn derived from electron.\n\n\n=== Discovery of free electrons outside matter ===\n\nWhile studying electrical conductivity in rarefied gases in 1859, the German physicist Julius Pl\u00fccker observed the radiation emitted from the cathode caused phosphorescent light to appear on the tube wall near the cathode; and the region of the phosphorescent light could be moved by application of a magnetic field.  In 1869, Pl\u00fccker's student Johann Wilhelm Hittorf found that a solid body placed in between the cathode and the phosphorescence would cast a shadow upon the phosphorescent region of the tube.  Hittorf inferred that there are straight rays emitted from the cathode and that the phosphorescence was caused by the rays striking the tube walls. In 1876, the German physicist Eugen Goldstein showed that the rays were emitted perpendicular to the cathode surface, which distinguished between the rays that were emitted from the cathode and the incandescent light.  Goldstein dubbed the rays cathode rays.:\u200a393\u200a Decades of experimental and theoretical research involving cathode rays were important in J. J. Thomson's eventual discovery of electrons.During the 1870s, the English chemist and physicist Sir William Crookes developed the first cathode-ray tube to have a high vacuum inside. He then showed in 1874 that the cathode rays can turn a small paddle wheel when placed in their path.  Therefore, he concluded that the rays carried momentum. Furthermore, by applying a magnetic field, he was able to deflect the rays, thereby demonstrating that the beam behaved as though it were negatively charged. In 1879, he proposed that these properties could be explained by regarding cathode rays as composed of negatively charged gaseous molecules in a fourth state of matter in which the mean free path of the particles is so long that collisions may be ignored.:\u200a394\u2013395\u200aThe German-born British physicist Arthur Schuster expanded upon Crookes's experiments by placing metal plates parallel to the cathode rays and applying an electric potential between the plates. The field deflected the rays toward the positively charged plate, providing further evidence that the rays carried negative charge. By measuring the amount of deflection for a given electric and magnetic field, in 1890 Schuster was able to estimate the charge-to-mass ratio of the ray components. However, this produced a value that was more than a thousand times greater than what was expected, so little credence was given to his calculations at the time. This is because it was assumed that the charge carriers were much heavier hydrogen or nitrogen atoms. Schuster's estimates would subsequently turn out to be largely correct.\nIn 1892 Hendrik Lorentz suggested that the mass of these particles (electrons) could be a consequence of their electric charge.\n\nWhile studying naturally fluorescing minerals in 1896, the French physicist Henri Becquerel discovered that they emitted radiation without any exposure to an external energy source. These radioactive materials became the subject of much interest by scientists, including the New Zealand physicist Ernest Rutherford who discovered they emitted particles. He designated these particles alpha and beta, on the basis of their ability to penetrate matter. In 1900, Becquerel showed that the beta rays emitted by radium could be deflected by an electric field, and that their mass-to-charge ratio was the same as for cathode rays. This evidence strengthened the view that electrons existed as components of atoms.In 1897, the British physicist J. J. Thomson, with his colleagues John S. Townsend and H. A. Wilson, performed experiments indicating that cathode rays really were unique particles, rather than waves, atoms or molecules as was believed earlier. Thomson made good estimates of both the charge e and the mass m, finding that cathode ray particles, which he called \"corpuscles\", had perhaps one thousandth of the mass of the least massive ion known: hydrogen. He showed that their charge-to-mass ratio, e/m, was independent of cathode material. He further showed that the negatively charged particles produced by radioactive materials, by heated materials and by illuminated materials were universal. The name electron was adopted for these particles by the scientific community, mainly due to the advocation by G. F. FitzGerald, J. Larmor, and H. A. Lorentz.:\u200a273\u200a In the same year Emil Wiechert and Walter Kaufmann also calculated the e/m ratio but they failed short of interpreting their results while J. J. Thomson would subsequently in 1899 give estimates for the electron charge and mass as well: e~6.8\u00d710\u221210 esu and m~3\u00d710\u221226 g\n\nThe electron's charge was more carefully measured by the American physicists Robert Millikan and Harvey Fletcher in their oil-drop experiment of 1909, the results of which were published in 1911. This experiment used an electric field to prevent a charged droplet of oil from falling as a result of gravity. This device could measure the electric charge from as few as 1\u2013150 ions with an error margin of less than 0.3%. Comparable experiments had been done earlier by Thomson's team, using clouds of charged water droplets generated by electrolysis, and in 1911 by Abram Ioffe, who independently obtained the same result as Millikan using charged microparticles of metals, then published his results in 1913. However, oil drops were more stable than water drops because of their slower evaporation rate, and thus more suited to precise experimentation over longer periods of time.Around the beginning of the twentieth century, it was found that under certain conditions a fast-moving charged particle caused a condensation of supersaturated water vapor along its path. In 1911, Charles Wilson used this principle to devise his cloud chamber so he could photograph the tracks of charged particles, such as fast-moving electrons.\n\n\n=== Atomic theory ===\n\nBy 1914, experiments by physicists Ernest Rutherford, Henry Moseley, James Franck and Gustav Hertz had largely established the structure of an atom as a dense nucleus of positive charge surrounded by lower-mass electrons. In 1913, Danish physicist Niels Bohr postulated that electrons resided in quantized energy states, with their energies determined by the angular momentum of the electron's orbit about the nucleus. The electrons could move between those states, or orbits, by the emission or absorption of photons of specific frequencies. By means of these quantized orbits, he accurately explained the spectral lines of the hydrogen atom. However, Bohr's model failed to account for the relative intensities of the spectral lines and it was unsuccessful in explaining the spectra of more complex atoms.Chemical bonds between atoms were explained by Gilbert Newton Lewis, who in 1916 proposed that a covalent bond between two atoms is maintained by a pair of electrons shared between them. Later, in 1927, Walter Heitler and Fritz London gave the full explanation of the electron-pair formation and chemical bonding in terms of quantum mechanics. In 1919, the American chemist Irving Langmuir elaborated on the Lewis's static model of the atom and suggested that all electrons were distributed in successive \"concentric (nearly) spherical shells, all of equal thickness\". In turn, he divided the shells into a number of cells each of which contained one pair of electrons. With this model Langmuir was able to qualitatively explain the chemical properties of all elements in the periodic table, which were known to largely repeat themselves according to the periodic law.In 1924, Austrian physicist Wolfgang Pauli observed that the shell-like structure of the atom could be explained by a set of four parameters that defined every quantum energy state, as long as each state was occupied by no more than a single electron. This prohibition against more than one electron occupying the same quantum energy state became known as the Pauli exclusion principle. The physical mechanism to explain the fourth parameter, which had two distinct possible values, was provided by the Dutch physicists Samuel Goudsmit and George Uhlenbeck.  In 1925, they suggested that an electron, in addition to the angular momentum of its orbit, possesses an intrinsic angular momentum and magnetic dipole moment. This is analogous to the rotation of the Earth on its axis as it orbits the Sun. The intrinsic angular momentum became known as spin, and explained the previously mysterious splitting of spectral lines observed with a high-resolution spectrograph; this phenomenon is known as fine structure splitting.\n\n\n=== Quantum mechanics ===\n\nIn his 1924 dissertation Recherches sur la th\u00e9orie des quanta (Research on Quantum Theory), French physicist Louis de Broglie hypothesized that all matter can be represented as a de Broglie wave in the manner of light. That is, under the appropriate conditions, electrons and other matter would show properties of either particles or waves. The corpuscular properties of a particle are demonstrated when it is shown to have a localized position in space along its trajectory at any given moment. The wave-like nature of light is displayed, for example, when a beam of light is passed through parallel slits thereby creating interference patterns. In 1927, George Paget Thomson discovered the interference effect was produced when a beam of electrons was passed through thin metal foils and by American physicists Clinton Davisson and Lester Germer by the reflection of electrons from a crystal of nickel.\n\nDe Broglie's prediction of a wave nature for electrons led Erwin Schr\u00f6dinger to postulate a wave equation for electrons moving under the influence of the nucleus in the atom. In 1926, this equation, the Schr\u00f6dinger equation, successfully described how electron waves propagated. Rather than yielding a solution that determined the location of an electron over time, this wave equation also could be used to predict the probability of finding an electron near a position, especially a position near where the electron was bound in space, for which the electron wave equations did not change in time. This approach led to a second formulation of quantum mechanics (the first by Heisenberg in 1925), and solutions of Schr\u00f6dinger's equation, like Heisenberg's, provided derivations of the energy states of an electron in a hydrogen atom that were equivalent to those that had been derived first by Bohr in 1913, and that were known to reproduce the hydrogen spectrum. Once spin and the interaction between multiple electrons were describable, quantum mechanics made it possible to predict the configuration of electrons in atoms with atomic numbers greater than hydrogen.In 1928, building on Wolfgang Pauli's work, Paul Dirac produced a model of the electron \u2013 the Dirac equation, consistent with relativity theory, by applying relativistic and symmetry considerations to the hamiltonian formulation of the quantum mechanics of the electro-magnetic field. In order to resolve some problems within his relativistic equation, Dirac developed in 1930 a model of the vacuum as an infinite sea of particles with negative energy, later dubbed the Dirac sea. This led him to predict the existence of a positron, the antimatter counterpart of the electron. This particle was discovered in 1932 by Carl Anderson, who proposed calling standard electrons negatrons and using electron as a generic term to describe both the positively and negatively charged variants.In 1947, Willis Lamb, working in collaboration with graduate student Robert Retherford, found that certain quantum states of the hydrogen atom, which should have the same energy, were shifted in relation to each other; the difference came to be called the Lamb shift. About the same time, Polykarp Kusch, working with Henry M. Foley, discovered the magnetic moment of the electron is slightly larger than predicted by Dirac's theory. This small difference was later called anomalous magnetic dipole moment of the electron. This difference was later explained by the theory of quantum electrodynamics, developed by Sin-Itiro Tomonaga, Julian Schwinger and\nRichard Feynman in the late 1940s.\n\n\n=== Particle accelerators ===\nWith the development of the particle accelerator during the first half of the twentieth century, physicists began to delve deeper into the properties of subatomic particles. The first successful attempt to accelerate electrons using electromagnetic induction was made in 1942 by Donald Kerst. His initial betatron reached energies of 2.3 MeV, while subsequent betatrons achieved 300 MeV. In 1947, synchrotron radiation was discovered with a 70 MeV electron synchrotron at General Electric. This radiation was caused by the acceleration of electrons through a magnetic field as they moved near the speed of light.With a beam energy of 1.5 GeV, the first high-energy\nparticle collider was ADONE, which began operations in 1968. This device accelerated electrons and positrons in opposite directions, effectively doubling the energy of their collision when compared to striking a static target with an electron. The Large Electron\u2013Positron Collider (LEP) at CERN, which was operational from 1989 to 2000, achieved collision energies of 209 GeV and made important measurements for the Standard Model of particle physics.\n\n\n=== Confinement of individual electrons ===\nIndividual electrons can now be easily confined in ultra small (L = 20 nm, W = 20 nm) CMOS transistors operated at cryogenic temperature over a range of \u2212269 \u00b0C (4 K) to about \u2212258 \u00b0C (15 K). The electron wavefunction spreads in a semiconductor lattice and negligibly interacts with the valence band electrons, so it can be treated in the single particle formalism, by replacing its mass with the effective mass tensor.\n\n\n== Characteristics ==\n\n\n=== Classification ===\n\nIn the Standard Model of particle physics, electrons belong to the group of subatomic particles called leptons, which are believed to be fundamental or elementary particles. Electrons have the lowest mass of any charged lepton (or electrically charged particle of any type) and belong to the first-generation of fundamental particles. The second and third generation contain charged leptons, the muon and the tau, which are identical to the electron in charge, spin and interactions, but are more massive. Leptons differ from the other basic constituent of matter, the quarks, by their lack of strong interaction. All members of the lepton group are fermions, because they all have half-odd integer spin; the electron has spin 1/2.\n\n\n=== Fundamental properties ===\nThe invariant mass of an electron is approximately 9.109\u00d710\u221231 kilograms, or 5.489\u00d710\u22124 atomic mass units. Due to mass\u2013energy equivalence, this corresponds to a rest energy of 0.511 MeV (8.19\u00d710\u221214 J). The ratio between the mass of a proton and that of an electron is about 1836. Astronomical measurements show that the proton-to-electron mass ratio has held the same value, as is predicted by the Standard Model, for at least half the age of the universe.Electrons have an electric charge of \u22121.602176634\u00d710\u221219 coulombs, which is used as a standard unit of charge for subatomic particles, and is also called the elementary charge. Within the limits of experimental accuracy, the electron charge is identical to the charge of a proton, but with the opposite sign. The electron is commonly symbolized by e\u2212, and the positron is symbolized by e+.The electron has an intrinsic angular momentum or spin of \u0127/2. This property is usually stated by referring to the electron as a spin-1/2 particle. For such particles the spin magnitude is \u0127/2, while the result of the measurement of a projection of the spin on any axis can only be \u00b1\u0127/2. In addition to spin, the electron has an intrinsic magnetic moment along its spin axis. It is approximately equal to one Bohr magneton, which is a physical constant equal to 9.27400915(23)\u00d710\u221224 joules per tesla. The orientation of the spin with respect to the momentum of the electron defines the property of elementary particles known as helicity.The electron has no known substructure. Nevertheless, in condensed matter physics, spin\u2013charge separation can occur in some materials. In such cases, electrons 'split' into three independent particles, the spinon, the orbiton and the holon (or chargon). The electron can always be theoretically considered as a bound state of the three, with the spinon carrying the spin of the electron, the orbiton carrying the orbital degree of freedom and the chargon carrying the charge, but in certain conditions they can behave as independent quasiparticles.The issue of the radius of the electron is a challenging problem of modern theoretical physics. The admission of the hypothesis of a finite radius of the electron is incompatible to the premises of the theory of relativity. On the other hand, a point-like electron (zero radius) generates serious mathematical difficulties due to the self-energy of the electron tending to infinity. Observation of a single electron in a Penning trap suggests the upper limit of the particle's radius to be 10\u221222 meters.\nThe upper bound of the electron radius of 10\u221218 meters can be derived using the uncertainty relation in energy. There is also a physical constant called the \"classical electron radius\", with the much larger value of 2.8179\u00d710\u221215 m, greater than the radius of the proton. However, the terminology comes from a simplistic calculation that ignores the effects of quantum mechanics; in reality, the so-called classical electron radius has little to do with the true fundamental structure of the electron.There are elementary particles that spontaneously decay into less massive particles. An example is the muon, with a mean lifetime of 2.2\u00d710\u22126 seconds, which decays into an electron, a muon neutrino and an electron antineutrino. The electron, on the other hand, is thought to be stable on theoretical grounds: the electron is the least massive particle with non-zero electric charge, so its decay would violate charge conservation. The experimental lower bound for the electron's mean lifetime is 6.6\u00d71028 years, at a 90% confidence level.\n\n\n=== Quantum properties ===\nAs with all particles, electrons can act as waves. This is called the wave\u2013particle duality and can be demonstrated using the double-slit experiment.\nThe wave-like nature of the electron allows it to pass through two parallel slits simultaneously, rather than just one slit as would be the case for a classical particle. In quantum mechanics, the wave-like property of one particle can be described mathematically as a complex-valued function, the wave function, commonly denoted by the Greek letter psi (\u03c8). When the absolute value of this function is squared, it gives the probability that a particle will be observed near a location\u2014a probability density.:\u200a162\u2013218\u200a\n\nElectrons are identical particles because they cannot be distinguished from each other by their intrinsic physical properties. In quantum mechanics, this means that a pair of interacting electrons must be able to swap positions without an observable change to the state of the system. The wave function of fermions, including electrons, is antisymmetric, meaning that it changes sign when two electrons are swapped; that is, \u03c8(r1, r2) = \u2212\u03c8(r2, r1), where the variables r1 and r2 correspond to the first and second electrons, respectively. Since the absolute value is not changed by a sign swap, this corresponds to equal probabilities. Bosons, such as the photon, have symmetric wave functions instead.:\u200a162\u2013218\u200aIn the case of antisymmetry, solutions of the wave equation for interacting electrons result in a zero probability that each pair will occupy the same location or state. This is responsible for the Pauli exclusion principle, which precludes any two electrons from occupying the same quantum state. This principle explains many of the properties of electrons. For example, it causes groups of bound electrons to occupy different orbitals in an atom, rather than all overlapping each other in the same orbit.:\u200a162\u2013218\u200a\n\n\n=== Virtual particles ===\n\nIn a simplified picture, which often tends to give the wrong idea but may serve to illustrate some aspects, every photon spends some time as a combination of a virtual electron plus its antiparticle, the virtual positron, which rapidly annihilate each other shortly thereafter. The combination of the energy variation needed to create these particles, and the time during which they exist, fall under the threshold of detectability expressed by the Heisenberg uncertainty relation, \u0394E \u00b7 \u0394t \u2265 \u0127. In effect, the energy needed to create these virtual particles, \u0394E, can be \"borrowed\" from the vacuum for a period of time, \u0394t, so that their product is no more than the reduced Planck constant, \u0127 \u2248 6.6\u00d710\u221216 eV\u00b7s. Thus, for a virtual electron, \u0394t is at most 1.3\u00d710\u221221 s.\n\nWhile an electron\u2013positron virtual pair is in existence, the Coulomb force from the ambient electric field surrounding an electron causes a created positron to be attracted to the original electron, while a created electron experiences a repulsion. This causes what is called vacuum polarization. In effect, the vacuum behaves like a medium having a dielectric permittivity more than unity. Thus the effective charge of an electron is actually smaller than its true value, and the charge decreases with increasing distance from the electron. This polarization was confirmed experimentally in 1997 using the Japanese TRISTAN particle accelerator. Virtual particles cause a comparable shielding effect for the mass of the electron.The interaction with virtual particles also explains the small (about 0.1%) deviation of the intrinsic magnetic moment of the electron from the Bohr magneton (the anomalous magnetic moment). The extraordinarily precise agreement of this predicted difference with the experimentally determined value is viewed as one of the great achievements of quantum electrodynamics.The apparent paradox in classical physics of a point particle electron having intrinsic angular momentum and magnetic moment can be explained by the formation of virtual photons in the electric field generated by the electron. These photons can heuristically be thought of as causing the electron to shift about in a jittery fashion (known as zitterbewegung), which results in a net circular motion with precession. This motion produces both the spin and the magnetic moment of the electron. In atoms, this creation of virtual photons explains the Lamb shift observed in spectral lines. The Compton Wavelength shows that near elementary particles such as the electron, the uncertainty of the energy allows for the creation of virtual particles near the electron. This wavelength explains the \"static\" of virtual particles around elementary particles at a close distance.\n\n\n=== Interaction ===\nAn electron generates an electric field that exerts an attractive force on a particle with a positive charge, such as the proton, and a repulsive force on a particle with a negative charge. The strength of this force in nonrelativistic approximation is determined by Coulomb's inverse square law.:\u200a58\u201361\u200a When an electron is in motion, it generates a magnetic field.:\u200a140\u200a The Amp\u00e8re\u2013Maxwell law relates the magnetic field to the mass motion of electrons (the current) with respect to an observer. This property of induction supplies the magnetic field that drives an electric motor. The electromagnetic field of an arbitrary moving charged particle is expressed by the Li\u00e9nard\u2013Wiechert potentials, which are valid even when the particle's speed is close to that of light (relativistic).:\u200a429\u2013434\u200a\n\nWhen an electron is moving through a magnetic field, it is subject to the Lorentz force that acts perpendicularly to the plane defined by the magnetic field and the electron velocity. This centripetal force causes the electron to follow a helical trajectory through the field at a radius called the gyroradius. The acceleration from this curving motion induces the electron to radiate energy in the form of synchrotron radiation.:\u200a160\u200a The energy emission in turn causes a recoil of the electron, known as the Abraham\u2013Lorentz\u2013Dirac Force, which creates a friction that slows the electron. This force is caused by a back-reaction of the electron's own field upon itself.\n\nPhotons mediate electromagnetic interactions between particles in quantum electrodynamics. An isolated electron at a constant velocity cannot emit or absorb a real photon; doing so would violate conservation of energy and momentum. Instead, virtual photons can transfer momentum between two charged particles. This exchange of virtual photons, for example, generates the Coulomb force. Energy emission can occur when a moving electron is deflected by a charged particle, such as a proton. The deceleration of the electron results in the emission of Bremsstrahlung radiation.An inelastic collision between a photon (light) and a solitary (free) electron is called Compton scattering. This collision results in a transfer of momentum and energy between the particles, which modifies the wavelength of the photon by an amount called the Compton shift. The maximum magnitude of this wavelength shift is h/mec, which is known as the Compton wavelength. For an electron, it has a value of 2.43\u00d710\u221212 m. When the wavelength of the light is long (for instance, the wavelength of the visible light is 0.4\u20130.7 \u03bcm) the wavelength shift becomes negligible. Such interaction between the light and free electrons is called Thomson scattering or linear Thomson scattering.The relative strength of the electromagnetic interaction between two charged particles, such as an electron and a proton, is given by the fine-structure constant. This value is a dimensionless quantity formed by the ratio of two energies: the electrostatic energy of attraction (or repulsion) at a separation of one Compton wavelength, and the rest energy of the charge. It is given by \u03b1 \u2248 7.297353\u00d710\u22123, which is approximately equal to 1/137.When electrons and positrons collide, they annihilate each other, giving rise to two or more gamma ray photons. If the electron and positron have negligible momentum, a positronium atom can form before annihilation results in two or three gamma ray photons totalling 1.022 MeV. On the other hand, a high-energy photon can transform into an electron and a positron by a process called pair production, but only in the presence of a nearby charged particle, such as a nucleus.In the theory of electroweak interaction, the left-handed component of electron's wavefunction forms a weak isospin doublet with the electron neutrino. This means that during weak interactions, electron neutrinos behave like electrons. Either member of this doublet can undergo a charged current interaction by emitting or absorbing a W and be converted into the other member. Charge is conserved during this reaction because the W boson also carries a charge, canceling out any net change during the transmutation. Charged current interactions are responsible for the phenomenon of beta decay in a radioactive atom. Both the electron and electron neutrino can undergo a neutral current interaction via a Z0 exchange, and this is responsible for neutrino-electron elastic scattering.\n\n\n=== Atoms and molecules ===\n\nAn electron can be bound to the nucleus of an atom by the attractive Coulomb force. A system of one or more electrons bound to a nucleus is called an atom. If the number of electrons is different from the nucleus's electrical charge, such an atom is called an ion. The wave-like behavior of a bound electron is described by a function called an atomic orbital. Each orbital has its own set of quantum numbers such as energy, angular momentum and projection of angular momentum, and only a discrete set of these orbitals exist around the nucleus. According to the Pauli exclusion principle each orbital can be occupied by up to two electrons, which must differ in their spin quantum number.\nElectrons can transfer between different orbitals by the emission or absorption of photons with an energy that matches the difference in potential.:\u200a159\u2013160\u200a Other methods of orbital transfer include collisions with particles, such as electrons, and the Auger effect. To escape the atom, the energy of the electron must be increased above its binding energy to the atom. This occurs, for example, with the photoelectric effect, where an incident photon exceeding the atom's ionization energy is absorbed by the electron.:\u200a127\u2013132\u200aThe orbital angular momentum of electrons is quantized. Because the electron is charged, it produces an orbital magnetic moment that is proportional to the angular momentum. The net magnetic moment of an atom is equal to the vector sum of orbital and spin magnetic moments of all electrons and the nucleus. The magnetic moment of the nucleus is negligible compared with that of the electrons. The magnetic moments of the electrons that occupy the same orbital (so called, paired electrons) cancel each other out.The chemical bond between atoms occurs as a result of electromagnetic interactions, as described by the laws of quantum mechanics. The strongest bonds are formed by the sharing or transfer of electrons between atoms, allowing the formation of molecules. Within a molecule, electrons move under the influence of several nuclei, and occupy molecular orbitals; much as they can occupy atomic orbitals in isolated atoms. A fundamental factor in these molecular structures is the existence of electron pairs. These are electrons with opposed spins, allowing them to occupy the same molecular orbital without violating the Pauli exclusion principle (much like in atoms). Different molecular orbitals have different spatial distribution of the electron density. For instance, in bonded pairs (i.e. in the pairs that actually bind atoms together) electrons can be found with the maximal probability in a relatively small volume between the nuclei. By contrast, in non-bonded pairs electrons are distributed in a large volume around nuclei.\n\n\n=== Conductivity ===\n\nIf a body has more or fewer electrons than are required to balance the positive charge of the nuclei, then that object has a net electric charge. When there is an excess of electrons, the object is said to be negatively charged. When there are fewer electrons than the number of protons in nuclei, the object is said to be positively charged. When the number of electrons and the number of protons are equal, their charges cancel each other and the object is said to be electrically neutral. A macroscopic body can develop an electric charge through rubbing, by the triboelectric effect.Independent electrons moving in vacuum are termed free electrons. Electrons in metals also behave as if they were free. In reality the particles that are commonly termed electrons in metals and other solids are quasi-electrons\u2014quasiparticles, which have the same electrical charge, spin, and magnetic moment as real electrons but might have a different mass. When free electrons\u2014both in vacuum and metals\u2014move, they produce a net flow of charge called an electric current, which generates a magnetic field. Likewise a current can be created by a changing magnetic field. These interactions are described mathematically by Maxwell's equations.At a given temperature, each material has an electrical conductivity that determines the value of electric current when an electric potential is applied. Examples of good conductors include metals such as copper and gold, whereas glass and Teflon are poor conductors. In any dielectric material, the electrons remain bound to their respective atoms and the material behaves as an insulator. Most semiconductors have a variable level of conductivity that lies between the extremes of conduction and insulation. On the other hand, metals have an electronic band structure containing partially filled electronic bands. The presence of such bands allows electrons in metals to behave as if they were free or delocalized electrons. These electrons are not associated with specific atoms, so when an electric field is applied, they are free to move like a gas (called Fermi gas) through the material much like free electrons.\nBecause of collisions between electrons and atoms, the drift velocity of electrons in a conductor is on the order of millimeters per second. However, the speed at which a change of current at one point in the material causes changes in currents in other parts of the material, the velocity of propagation, is typically about 75% of light speed. This occurs because electrical signals propagate as a wave, with the velocity dependent on the dielectric constant of the material.Metals make relatively good conductors of heat, primarily because the delocalized electrons are free to transport thermal energy between atoms. However, unlike electrical conductivity, the thermal conductivity of a metal is nearly independent of temperature. This is expressed mathematically by the Wiedemann\u2013Franz law, which states that the ratio of thermal conductivity to the electrical conductivity is proportional to the temperature. The thermal disorder in the metallic lattice increases the electrical resistivity of the material, producing a temperature dependence for electric current.When cooled below a point called the critical temperature, materials can undergo a phase transition in which they lose all resistivity to electric current, in a process known as superconductivity. In BCS theory, pairs of electrons called Cooper pairs have their motion coupled to nearby matter via lattice vibrations called phonons, thereby avoiding the collisions with atoms that normally create electrical resistance. (Cooper pairs have a radius of roughly 100 nm, so they can overlap each other.) However, the mechanism by which higher temperature superconductors operate remains uncertain.\nElectrons inside conducting solids, which are quasi-particles themselves, when tightly confined at temperatures close to absolute zero, behave as though they had split into three other quasiparticles: spinons, orbitons and holons. The former carries spin and magnetic moment, the next carries its orbital location while the latter electrical charge.\n\n\n=== Motion and energy ===\nAccording to Einstein's theory of special relativity, as an electron's speed approaches the speed of light, from an observer's point of view its relativistic mass increases, thereby making it more and more difficult to accelerate it from within the observer's frame of reference. The speed of an electron can approach, but never reach, the speed of light in vacuum, c. However, when relativistic electrons\u2014that is, electrons moving at a speed close to c\u2014are injected into a dielectric medium such as water, where the local speed of light is significantly less than c, the electrons temporarily travel faster than light in the medium. As they interact with the medium, they generate a faint light called Cherenkov radiation.\n\nThe effects of special relativity are based on a quantity known as the Lorentz factor, defined as \n  \n    \n      \n        \n          \u03b3\n          =\n          1\n          \n            /\n          \n          \n            \n              1\n              \u2212\n              \n                \n                  v\n                  \n                    2\n                  \n                \n              \n              \n                /\n              \n              \n                \n                  c\n                  \n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle \\gamma =1/{\\sqrt {1-{v^{2}}/{c^{2}}}}}\n   where v is the speed of the particle. The kinetic energy Ke of an electron moving with velocity v is:\n\n  \n    \n      \n        \n          \n            K\n            \n              \n                e\n              \n            \n          \n          =\n          (\n          \u03b3\n          \u2212\n          1\n          )\n          \n            m\n            \n              \n                e\n              \n            \n          \n          \n            c\n            \n              2\n            \n          \n          ,\n        \n      \n    \n    {\\displaystyle \\displaystyle K_{\\mathrm {e} }=(\\gamma -1)m_{\\mathrm {e} }c^{2},}\n  where me is the mass of electron. For example, the Stanford linear accelerator can accelerate an electron to roughly 51 GeV.\nSince an electron behaves as a wave, at a given velocity it has a characteristic de Broglie wavelength. This is given by \u03bbe = h/p where h is the Planck constant and p is the momentum. For the 51 GeV electron above, the wavelength is about 2.4\u00d710\u221217 m, small enough to explore structures well below the size of an atomic nucleus.\n\n\n== Formation ==\n\nThe Big Bang theory is the most widely accepted scientific theory to explain the early stages in the evolution of the Universe. For the first millisecond of the Big Bang, the temperatures were over 10 billion kelvins and photons had mean energies over a million electronvolts. These photons were sufficiently energetic that they could react with each other to form pairs of electrons and positrons. Likewise, positron-electron pairs annihilated each other and emitted energetic photons:\n\n\u03b3 + \u03b3 \u2194 e+ + e\u2212An equilibrium between electrons, positrons and photons was maintained during this phase of the evolution of the Universe. After 15 seconds had passed, however, the temperature of the universe dropped below the threshold where electron-positron formation could occur. Most of the surviving electrons and positrons annihilated each other, releasing gamma radiation that briefly reheated the universe.For reasons that remain uncertain, during the annihilation process there was an excess in the number of particles over antiparticles. Hence, about one electron for every billion electron-positron pairs survived. This excess matched the excess of protons over antiprotons, in a condition known as baryon asymmetry, resulting in a net charge of zero for the universe. The surviving protons and neutrons began to participate in reactions with each other\u2014in the process known as nucleosynthesis, forming isotopes of hydrogen and helium, with trace amounts of lithium. This process peaked after about five minutes. Any leftover neutrons underwent negative beta decay with a half-life of about a thousand seconds, releasing a proton and electron in the process,\n\nn \u2192 p + e\u2212 + \u03bdeFor about the next 300000\u2013400000 years, the excess electrons remained too energetic to bind with atomic nuclei. What followed is a period known as recombination, when neutral atoms were formed and the expanding universe became transparent to radiation.Roughly one million years after the big bang, the first generation of stars began to form. Within a star, stellar nucleosynthesis results in the production of positrons from the fusion of atomic nuclei. These antimatter particles immediately annihilate with electrons, releasing gamma rays. The net result is a steady reduction in the number of electrons, and a matching increase in the number of neutrons. However, the process of stellar evolution can result in the synthesis of radioactive isotopes. Selected isotopes can subsequently undergo negative beta decay, emitting an electron and antineutrino from the nucleus. An example is the cobalt-60 (60Co) isotope, which decays to form nickel-60 (60Ni).\n\nAt the end of its lifetime, a star with more than about 20 solar masses can undergo gravitational collapse to form a black hole. According to classical physics, these massive stellar objects exert a gravitational attraction that is strong enough to prevent anything, even electromagnetic radiation, from escaping past the Schwarzschild radius. However, quantum mechanical effects are believed to potentially allow the emission of Hawking radiation at this distance. Electrons (and positrons) are thought to be created at the event horizon of these stellar remnants.\nWhen a pair of virtual particles (such as an electron and positron) is created in the vicinity of the event horizon, random spatial positioning might result in one of them to appear on the exterior; this process is called quantum tunnelling. The gravitational potential of the black hole can then supply the energy that transforms this virtual particle into a real particle, allowing it to radiate away into space. In exchange, the other member of the pair is given negative energy, which results in a net loss of mass-energy by the black hole. The rate of Hawking radiation increases with decreasing mass, eventually causing the black hole to evaporate away until, finally, it explodes.Cosmic rays are particles traveling through space with high energies. Energy events as high as 3.0\u00d71020 eV have been recorded. When these particles collide with nucleons in the Earth's atmosphere, a shower of particles is generated, including pions. More than half of the cosmic radiation observed from the Earth's surface consists of muons. The particle called a muon is a lepton produced in the upper atmosphere by the decay of a pion.\n\n\u03c0\u2212 \u2192 \u03bc\u2212 + \u03bd\u03bcA muon, in turn, can decay to form an electron or positron.\n\u03bc\u2212 \u2192 e\u2212 + \u03bde + \u03bd\u03bc\n\n\n== Observation ==\n\nRemote observation of electrons requires detection of their radiated energy. For example, in high-energy environments such as the corona of a star, free electrons form a plasma that radiates energy due to Bremsstrahlung radiation. Electron gas can undergo plasma oscillation, which is waves caused by synchronized variations in electron density, and these produce energy emissions that can be detected by using radio telescopes.The frequency of a photon is proportional to its energy. As a bound electron transitions between different energy levels of an atom, it absorbs or emits photons at characteristic frequencies. For instance, when atoms are irradiated by a source with a broad spectrum, distinct dark lines appear in the spectrum of transmitted radiation in places where the corresponding frequency is absorbed by the atom's electrons. Each element or molecule displays a characteristic set of spectral lines, such as the hydrogen spectral series. When detected, spectroscopic measurements of the strength and width of these lines allow the composition and physical properties of a substance to be determined.In laboratory conditions, the interactions of individual electrons can be observed by means of particle detectors, which allow measurement of specific properties such as energy, spin and charge. The development of the Paul trap and Penning trap allows charged particles to be contained within a small region for long durations. This enables precise measurements of the particle properties. For example, in one instance a Penning trap was used to contain a single electron for a period of 10 months. The magnetic moment of the electron was measured to a precision of eleven digits, which, in 1980, was a greater accuracy than for any other physical constant.The first video images of an electron's energy distribution were captured by a team at Lund University in Sweden, February 2008. The scientists used extremely short flashes of light, called attosecond pulses, which allowed an electron's motion to be observed for the first time.The distribution of the electrons in solid materials can be visualized by angle-resolved photoemission spectroscopy (ARPES). This technique employs the photoelectric effect to measure the reciprocal space\u2014a mathematical representation of periodic structures that is used to infer the original structure. ARPES can be used to determine the direction, speed and scattering of electrons within the material.\n\n\n== Plasma applications ==\n\n\n=== Particle beams ===\n\nElectron beams are used in welding. They allow energy densities up to 107 W\u00b7cm\u22122 across a narrow focus diameter of 0.1\u20131.3 mm and usually require no filler material. This welding technique must be performed in a vacuum to prevent the electrons from interacting with the gas before reaching their target, and it can be used to join conductive materials that would otherwise be considered unsuitable for welding.Electron-beam lithography (EBL) is a method of etching semiconductors at resolutions smaller than a micrometer. This technique is limited by high costs, slow performance, the need to operate the beam in the vacuum and the tendency of the electrons to scatter in solids. The last problem limits the resolution to about 10 nm. For this reason, EBL is primarily used for the production of small numbers of specialized integrated circuits.Electron beam processing is used to irradiate materials in order to change their physical properties or sterilize medical and food products. Electron beams fluidise or quasi-melt glasses without significant increase of temperature on intensive irradiation: e.g. intensive electron radiation causes a many orders of magnitude decrease of viscosity and stepwise decrease of its activation energy.Linear particle accelerators generate electron beams for treatment of superficial tumors in radiation therapy. Electron therapy can treat such skin lesions as basal-cell carcinomas because an electron beam only penetrates to a limited depth before being absorbed, typically up to 5 cm for electron energies in the range 5\u201320 MeV. An electron beam can be used to supplement the treatment of areas that have been irradiated by X-rays.Particle accelerators use electric fields to propel electrons and their antiparticles to high energies.  These particles emit synchrotron radiation as they pass through magnetic fields. The dependency of the intensity of this radiation upon spin polarizes the electron beam\u2014a process known as the Sokolov\u2013Ternov effect. Polarized electron beams can be useful for various experiments. Synchrotron radiation can also cool the electron beams to reduce the momentum spread of the particles.  Electron and positron beams are collided upon the particles' accelerating to the required energies; particle detectors observe the resulting energy emissions, which particle physics studies .\n\n\n=== Imaging ===\nLow-energy electron diffraction (LEED) is a method of bombarding a crystalline material with a collimated beam of electrons and then observing the resulting diffraction patterns to determine the structure of the material. The required energy of the electrons is typically in the range 20\u2013200 eV. The reflection high-energy electron diffraction (RHEED) technique uses the reflection of a beam of electrons fired at various low angles to characterize the surface of crystalline materials. The beam energy is typically in the range 8\u201320 keV and the angle of incidence is 1\u20134\u00b0.The electron microscope directs a focused beam of electrons at a specimen. Some electrons change their properties, such as movement direction, angle, and relative phase and energy as the beam interacts with the material. Microscopists can record these changes in the electron beam to produce atomically resolved images of the material. In blue light, conventional optical microscopes have a diffraction-limited resolution of about 200 nm. By comparison, electron microscopes are limited by the de Broglie wavelength of the electron. This wavelength, for example, is equal to 0.0037 nm for electrons accelerated across a 100,000-volt potential. The Transmission Electron Aberration-Corrected Microscope is capable of sub-0.05 nm resolution, which is more than enough to resolve individual atoms. This capability makes the electron microscope a useful laboratory instrument for high resolution imaging. However, electron microscopes are expensive instruments that are costly to maintain.\nTwo main types of electron microscopes exist: transmission and scanning. Transmission electron microscopes function like overhead projectors, with a beam of electrons passing through a slice of material then being projected by lenses on a photographic slide or a charge-coupled device.  Scanning electron microscopes rasteri a finely focused electron beam, as in a TV set, across the studied sample to produce the image. Magnifications range from 100\u00d7 to 1,000,000\u00d7 or higher for both microscope types. The scanning tunneling microscope uses quantum tunneling of electrons from a sharp metal tip into the studied material and can produce atomically resolved images of its surface.\n\n\n=== Other applications ===\nIn the free-electron laser (FEL), a relativistic electron beam passes through a pair of undulators that contain arrays of dipole magnets whose fields point in alternating directions. The electrons emit synchrotron radiation that coherently interacts with the same electrons to strongly amplify the radiation field at the resonance frequency. FEL can emit a coherent high-brilliance electromagnetic radiation with a wide range of frequencies, from microwaves to soft X-rays. These devices are used in manufacturing, communication, and in medical applications, such as soft tissue surgery.Electrons are important in cathode-ray tubes, which have been extensively used as display devices in laboratory instruments, computer monitors and television sets. In a photomultiplier tube, every photon striking the photocathode initiates an avalanche of electrons that produces a detectable current pulse. Vacuum tubes use the flow of electrons to manipulate electrical signals, and they played a critical role in the development of electronics technology. However, they have been largely supplanted by solid-state devices such as the transistor.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\n\"The Discovery of the Electron\". Center for History of Physics. American Institute of Physics.\"Particle Data Group\". University of California.Bock, R.K.; Vasilescu, A. (1998). The Particle Detector BriefBook (14th ed.). Springer. ISBN 978-3-540-64120-9.Copeland, Ed. \"Spherical Electron\". Sixty Symbols. Brady Haran for the University of Nottingham.", "Mass": "Mass is an intrinsic property of a body. It was traditionally believed to be related to the quantity of matter in a physical body, until the discovery of the atom and particle physics. It was found that different atoms and different elementary particles, theoretically with the same amount of matter, have nonetheless different masses. Mass in modern physics has multiple definitions which are conceptually distinct, but physically equivalent. Mass can be experimentally defined as a measure of the body's inertia, meaning the resistance to acceleration (change of velocity) when a net force is applied. The object's mass also determines the strength of its gravitational attraction to other bodies.\nThe SI base unit of mass is the kilogram (kg). In physics, mass is not the same as weight, even though mass is often determined by measuring the object's weight using a spring scale, rather than balance scale comparing it directly with known masses. An object on the Moon would weigh less than it does on Earth because of the lower gravity, but it would still have the same mass. This is because weight is a force, while mass is the property that (along with gravity) determines the strength of this force.\n\n\n== Phenomena ==\nThere are several distinct phenomena that can be used to measure mass. Although some theorists have speculated that some of these phenomena could be independent of each other, current experiments have found no difference in results regardless of how it is measured:\n\nInertial mass measures an object's resistance to being accelerated by a force (represented by the relationship F = ma).\nActive gravitational mass determines the strength of the gravitational field generated by an object.\nPassive gravitational mass measures the gravitational force exerted on an object in a known gravitational field.The mass of an object determines its acceleration in the presence of an applied force. The inertia and the inertial mass describe this property of physical bodies at the qualitative and quantitative level respectively.  According to Newton's second law of motion, if a body of fixed mass m is subjected to a single force F, its acceleration a is given by F/m. A body's mass also determines the degree to which it generates and is affected by a gravitational field. If a first body of mass mA is placed at a distance r (center of mass to center of mass) from a second body of mass mB, each body is subject to an attractive force Fg = GmAmB/r2, where G = 6.67\u00d710\u221211 N\u22c5kg\u22122\u22c5m2 is the \"universal gravitational constant\". This is sometimes referred to as gravitational mass. Repeated experiments since the 17th century have demonstrated that inertial and gravitational mass are identical; since 1915, this observation has been incorporated a priori in the equivalence principle of general relativity.\n\n\n== Units of mass ==\n\nThe International System of Units (SI) unit of mass is the kilogram (kg). The kilogram is 1000 grams (g), and was first defined in 1795 as the mass of one cubic decimetre of water at the melting point of ice. However, because precise measurement of a cubic decimetre of water at the specified temperature and pressure was difficult, in 1889 the kilogram was redefined as the mass of a metal object, and thus became independent of the metre and the properties of water, this being a copper prototype of the grave in 1793, the platinum Kilogramme des Archives in 1799, and the platinum-iridium International Prototype of the Kilogram (IPK) in 1889.\nHowever, the mass of the IPK and its national copies have been found to drift over time. The re-definition of the kilogram and several other units came into effect on 20 May 2019, following a final vote by the CGPM in November 2018. The new definition uses only invariant quantities of nature: the speed of light, the caesium hyperfine frequency, the Planck constant and the elementary charge.Non-SI units accepted for use with SI units include:\n\nthe tonne (t) (or \"metric ton\"), equal to 1000 kg\nthe electronvolt (eV), a unit of energy, used to express mass in units of eV/c2 through mass\u2013energy equivalence\nthe dalton (Da), equal to 1/12 of the mass of a free carbon-12 atom, approximately 1.66\u00d710\u221227 kg.Outside the SI system, other units of mass include:\n\nthe slug (sl), an Imperial unit of mass (about 14.6 kg)\nthe pound (lb), a unit of mass (about 0.45 kg), which is used alongside the similarly named pound (force) (about 4.5 N), a unit of force\nthe Planck mass (about 2.18\u00d710\u22128 kg), a quantity derived from fundamental constants\nthe solar mass (M\u2609), defined as the mass of the Sun, primarily used in astronomy to compare large masses such as stars or galaxies (\u2248 1.99\u00d71030 kg)\nthe mass of a particle, as identified with its inverse Compton wavelength (1 cm\u22121 \u2258 3.52\u00d710\u221241 kg)\nthe mass of a star or black hole, as identified with its Schwarzschild radius (1 cm \u2258 6.73\u00d71024 kg).\n\n\n== Definitions ==\nIn physical science, one may distinguish conceptually between at least seven different aspects of mass, or seven physical notions that involve the concept of mass. Every experiment to date has shown these seven values to be proportional, and in some cases equal, and this proportionality gives rise to the abstract concept of mass. There are a number of ways mass can be measured or operationally defined:\n\nInertial mass is a measure of an object's resistance to acceleration when a force is applied. It is determined by applying a force to an object and measuring the acceleration that results from that force. An object with small inertial mass will accelerate more than an object with large inertial mass when acted upon by the same force. One says the body of greater mass has greater inertia.\nActive gravitational mass is a measure of the strength of an object's gravitational flux (gravitational flux is equal to the surface integral of gravitational field over an enclosing surface). Gravitational field can be measured by allowing a small \"test object\" to fall freely and measuring its free-fall acceleration. For example, an object in free-fall near the Moon is subject to a smaller gravitational field, and hence accelerates more slowly, than the same object would if it were in free-fall near the Earth. The gravitational field near the Moon is weaker because the Moon has less active gravitational mass.\nPassive gravitational mass is a measure of the strength of an object's interaction with a gravitational field. Passive gravitational mass is determined by dividing an object's weight by its free-fall acceleration. Two objects within the same gravitational field will experience the same acceleration; however, the object with a smaller passive gravitational mass will experience a smaller force (less weight) than the object with a larger passive gravitational mass.\nAccording to relativity, mass is nothing else than the rest energy of a system of particles, meaning the energy of that system in a reference frame where it has zero momentum. Mass can be converted into other forms of energy according to the principle of mass\u2013energy equivalence. This equivalence is exemplified in a large number of physical processes including pair production, beta decay and nuclear fusion. Pair production and nuclear fusion are processes in which measurable amounts of mass are converted to kinetic energy or vice versa.\nCurvature of spacetime is a relativistic manifestation of the existence of mass. Such curvature is extremely weak and difficult to measure. For this reason, curvature was not discovered until after it was predicted by Einstein's theory of general relativity. Extremely precise atomic clocks on the surface of the Earth, for example, are found to measure less time (run slower) when compared to similar clocks in space. This difference in elapsed time is a form of curvature called gravitational time dilation. Other forms of curvature have been measured using the Gravity Probe B satellite.\nQuantum mass manifests itself as a difference between an object's quantum frequency and its wave number. The quantum mass of a particle is proportional to the inverse Compton wavelength and can be determined through various forms of spectroscopy.  In relativistic quantum mechanics, mass is one of the irreducible representation labels of the Poincar\u00e9 group.\n\n\n=== Weight vs. mass ===\n\nIn everyday usage, mass and \"weight\" are often used interchangeably. For instance, a person's weight may be stated as 75 kg. In a constant gravitational field, the weight of an object is proportional to its mass, and it is unproblematic to use the same unit for both concepts. But because of slight differences in the strength of the Earth's gravitational field at different places, the distinction becomes important for measurements with a precision better than a few percent, and for places far from the surface of the Earth, such as in space or on other planets. Conceptually, \"mass\" (measured in kilograms) refers to an intrinsic property of an object, whereas \"weight\" (measured in newtons) measures an object's resistance to deviating from its current course of free fall, which can be influenced by the nearby gravitational field. No matter how strong the gravitational field, objects in free fall are weightless, though they still have mass.The force known as \"weight\" is proportional to mass and acceleration in all situations where the mass is accelerated away from free fall. For example, when a body is at rest in a gravitational field (rather than in free fall), it must be accelerated by a force from a scale or the surface of a planetary body such as the Earth or the Moon. This force keeps the object from going into free fall. Weight is the opposing force in such circumstances and is thus determined by the acceleration of free fall. On the surface of the Earth, for example, an object with a mass of 50 kilograms weighs 491 newtons, which means that 491 newtons is being applied to keep the object from going into free fall. By contrast, on the surface of the Moon, the same object still has a mass of 50 kilograms but weighs only 81.5 newtons, because only 81.5 newtons is required to keep this object from going into a free fall on the moon. Restated in mathematical terms, on the surface of the Earth, the weight W of an object is related to its mass m by W = mg, where g = 9.80665 m/s2 is the acceleration due to Earth's gravitational field, (expressed as the acceleration experienced by a free-falling object).\nFor other situations, such as when objects are subjected to mechanical accelerations from forces other than the resistance of a planetary surface, the weight force is proportional to the mass of an object multiplied by the total acceleration away from free fall, which is called the proper acceleration. Through such mechanisms, objects in elevators, vehicles, centrifuges, and the like, may experience weight forces many times those caused by resistance to the effects of gravity on objects, resulting from planetary surfaces. In such cases, the generalized equation for weight W of an object is related to its mass m by the equation W = \u2013ma, where a is the proper acceleration of the object caused by all influences other than gravity. (Again, if gravity is the only influence, such as occurs when an object falls freely, its weight will be zero).\n\n\n=== Inertial vs. gravitational mass ===\nAlthough inertial mass, passive gravitational mass and active gravitational mass are conceptually distinct, no experiment has ever unambiguously demonstrated any difference between them. In classical mechanics, Newton's third law implies that active and passive gravitational mass must always be identical (or at least proportional), but the classical theory offers no compelling reason why the gravitational mass has to equal the inertial mass. That it does is merely an empirical fact.\nAlbert Einstein developed his general theory of relativity starting with the assumption that the inertial and passive gravitational masses are the same.  This is known as the equivalence principle.\nThe particular equivalence often referred to as the \"Galilean equivalence principle\" or the \"weak equivalence principle\" has the most important consequence for freely falling objects. Suppose an object has inertial and gravitational masses m and M, respectively. If the only force acting on the object comes from a gravitational field g, the force on the object is:\n\n  \n    \n      \n        F\n        =\n        M\n        g\n        .\n      \n    \n    {\\displaystyle F=Mg.}\n  Given this force, the acceleration of the object can be determined by Newton's second law:\n\n  \n    \n      \n        F\n        =\n        m\n        a\n        .\n      \n    \n    {\\displaystyle F=ma.}\n  Putting these together, the gravitational acceleration is given by:\n\n  \n    \n      \n        a\n        =\n        \n          \n            M\n            m\n          \n        \n        g\n        .\n      \n    \n    {\\displaystyle a={\\frac {M}{m}}g.}\n  This says that the ratio of gravitational to inertial mass of any object is equal to some constant K if and only if all objects fall at the same rate in a given gravitational field. This phenomenon is referred to as the \"universality of free-fall\". In addition, the constant K can be taken as 1 by defining our units appropriately.\nThe first experiments demonstrating the universality of free-fall were\u2014according to scientific 'folklore'\u2014conducted by Galileo obtained by dropping objects from the Leaning Tower of Pisa. This is most likely apocryphal: he is more likely to have performed his experiments with balls rolling down nearly frictionless inclined planes to slow the motion and increase the timing accuracy. Increasingly precise experiments have been performed, such as those performed by Lor\u00e1nd E\u00f6tv\u00f6s, using the torsion balance pendulum, in 1889. As of 2008, no deviation from universality, and thus from Galilean equivalence, has ever been found, at least to the precision 10\u22126. More precise experimental efforts are still being carried out.\n\nThe universality of free-fall only applies to systems in which gravity is the only acting force. All other forces, especially friction and air resistance, must be absent or at least negligible. For example, if a hammer and a feather are dropped from the same height through the air on Earth, the feather will take much longer to reach the ground; the feather is not really in free-fall because the force of air resistance upwards against the feather is comparable to the downward force of gravity. On the other hand, if the experiment is performed in a vacuum, in which there is no air resistance, the hammer and the feather should hit the ground at exactly the same time (assuming the acceleration of both objects towards each other, and of the ground towards both objects, for its own part, is negligible). This can easily be done in a high school laboratory by dropping the objects in transparent tubes that have the air removed with a vacuum pump. It is even more dramatic when done in an environment that naturally has a vacuum, as David Scott did on the surface of the Moon during Apollo 15.\nA stronger version of the equivalence principle, known as the Einstein equivalence principle or the strong equivalence principle, lies at the heart of the general theory of relativity. Einstein's equivalence principle states that within sufficiently small regions of space-time, it is impossible to distinguish between a uniform acceleration and a uniform gravitational field. Thus, the theory postulates that the force acting on a massive object caused by a gravitational field is a result of the object's tendency to move in a straight line (in other words its inertia) and should therefore be a function of its inertial mass and the strength of the gravitational field.\n\n\n=== Origin ===\n\nIn theoretical physics, a mass generation mechanism is a theory which attempts to explain the origin of mass from the most fundamental laws of physics. To date, a number of different models have been proposed which advocate different views of the origin of mass. The problem is complicated by the fact that the notion of mass is strongly related to the gravitational interaction but a theory of the latter has not been yet reconciled with the currently popular model of particle physics, known as the Standard Model.\n\n\n== Pre-Newtonian concepts ==\n\n\n=== Weight as an amount ===\n\nThe concept of amount is very old and predates recorded history.  Humans, at some early era, realized that the weight of a collection of similar objects was directly proportional to the number of objects in the collection:\n\n  \n    \n      \n        \n          W\n          \n            n\n          \n        \n        \u221d\n        n\n        ,\n      \n    \n    {\\displaystyle W_{n}\\propto n,}\n  where W is the weight of the collection of similar objects and n is the number of objects in the collection. Proportionality, by definition, implies that two values have a constant ratio:\n\n  \n    \n      \n        \n          \n            \n              W\n              \n                n\n              \n            \n            n\n          \n        \n        =\n        \n          \n            \n              W\n              \n                m\n              \n            \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\frac {W_{n}}{n}}={\\frac {W_{m}}{m}}}\n  , or equivalently \n  \n    \n      \n        \n          \n            \n              W\n              \n                n\n              \n            \n            \n              W\n              \n                m\n              \n            \n          \n        \n        =\n        \n          \n            n\n            m\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {W_{n}}{W_{m}}}={\\frac {n}{m}}.}\n  An early use of this relationship is a balance scale, which balances the force of one object's weight against the force of another object's weight. The two sides of a balance scale are close enough that the objects experience similar gravitational fields.  Hence, if they have similar masses then their weights will also be similar.  This allows the scale, by comparing weights, to also compare masses.\nConsequently, historical weight standards were often defined in terms of amounts.  The Romans, for example, used the carob seed (carat or siliqua) as a measurement standard.  If an object's weight was equivalent to 1728 carob seeds, then the object was said to weigh one Roman pound.  If, on the other hand, the object's weight was equivalent to 144 carob seeds then the object was said to weigh one Roman ounce (uncia).  The Roman pound and ounce were both defined in terms of different sized collections of the same common mass standard, the carob seed.  The ratio of a Roman ounce (144 carob seeds) to a Roman pound (1728 carob seeds) was:\n\n  \n    \n      \n        \n          \n            \n              o\n              u\n              n\n              c\n              e\n            \n            \n              p\n              o\n              u\n              n\n              d\n            \n          \n        \n        =\n        \n          \n            \n              W\n              \n                144\n              \n            \n            \n              W\n              \n                1728\n              \n            \n          \n        \n        =\n        \n          \n            144\n            1728\n          \n        \n        =\n        \n          \n            1\n            12\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {ounce} }{\\mathrm {pound} }}={\\frac {W_{144}}{W_{1728}}}={\\frac {144}{1728}}={\\frac {1}{12}}.}\n  \n\n\n=== Planetary motion ===\n\nIn 1600 AD, Johannes Kepler sought employment with Tycho Brahe, who had some of the most precise astronomical data available.  Using Brahe's precise observations of the planet Mars, Kepler spent the next five years developing his own method for characterizing planetary motion. In 1609, Johannes Kepler published his three laws of planetary motion, explaining how the planets orbit the Sun. In Kepler's final planetary model, he described planetary orbits as following elliptical paths with the Sun at a focal point of the ellipse. Kepler discovered that the square of the orbital period of each planet is directly proportional to the cube of the semi-major axis of its orbit, or equivalently, that the ratio of these two values is constant for all planets in the Solar System.On 25 August 1609, Galileo Galilei demonstrated his first telescope to a group of Venetian merchants, and in early January 1610, Galileo observed four dim objects near Jupiter, which he mistook for stars.  However, after a few days of observation, Galileo realized that these \"stars\" were in fact orbiting Jupiter.  These four objects (later named the Galilean moons in honor of their discoverer) were the first celestial bodies observed to orbit something other than the Earth or Sun.  Galileo continued to observe these moons over the next eighteen months, and by the middle of 1611, he had obtained remarkably accurate estimates for their periods.\n\n\n=== Galilean free fall ===\n\nSometime prior to 1638, Galileo turned his attention to the phenomenon of objects in free fall, attempting to characterize these motions. Galileo was not the first to investigate Earth's gravitational field, nor was he the first to accurately describe its fundamental characteristics.  However, Galileo's reliance on scientific experimentation to establish physical principles would have a profound effect on future generations of scientists. It is unclear if these were just hypothetical experiments used to illustrate a concept, or if they were real experiments performed by Galileo, but the results obtained from these experiments were both realistic and compelling.  A biography by Galileo's pupil Vincenzo Viviani stated that Galileo had dropped balls of the same material, but different masses, from the Leaning Tower of Pisa to demonstrate that their time of descent was independent of their mass. In support of this conclusion, Galileo had advanced the following theoretical argument: He asked if two bodies of different masses and different rates of fall are tied by a string, does the combined system fall faster because it is now more massive, or does the lighter body in its slower fall hold back the heavier body?  The only convincing resolution to this question is that all bodies must fall at the same rate.A later experiment was described in Galileo's Two New Sciences published in 1638.  One of Galileo's fictional characters, Salviati, describes an experiment using a bronze ball and a wooden ramp.  The wooden ramp was \"12 cubits long, half a cubit wide and three finger-breadths thick\" with a straight, smooth, polished groove.  The groove was lined with \"parchment, also smooth and polished as possible\".  And into this groove was placed \"a hard, smooth and very round bronze ball\".  The ramp was inclined at various angles to slow the acceleration enough so that the elapsed time could be measured.  The ball was allowed to roll a known distance down the ramp, and the time taken for the ball to move the known distance was measured.  The time was measured using a water clock described as follows:\n\na large vessel of water placed in an elevated position; to the bottom of this vessel was soldered a pipe of small diameter giving a thin jet of water, which we collected in a small glass during the time of each descent, whether for the whole length of the channel or for a part of its length; the water thus collected was weighed, after each descent, on a very accurate balance; the differences and ratios of these weights gave us the differences and ratios of the times, and this with such accuracy that although the operation was repeated many, many times, there was no appreciable discrepancy in the results.Galileo found that for an object in free fall, the distance that the object has fallen is always proportional to the square of the elapsed time:\n\n  \n    \n      \n        \n          Distance\n        \n        \u221d\n        \n          \n            \n              Time\n            \n            \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle {\\text{Distance}}\\propto {{\\text{Time}}^{2}}}\n  Galileo had shown that objects in free fall under the influence of the Earth's gravitational field have a constant acceleration, and Galileo's contemporary, Johannes Kepler, had shown that the planets follow elliptical paths under the influence of the Sun's gravitational mass.  However, Galileo's free fall motions and Kepler's planetary motions remained distinct during Galileo's lifetime.\n\n\n=== Mass as distinct from weight ===\nK. M. Browne very clearly explains the double meaning of \"weight\" in the past.What we now know as mass was until the time of Newton called \u201cweight.\u201d ... A goldsmith believed that an ounce of gold was a quantity of gold. ... But the ancients believed that a beam balance also measured \u201cheaviness\u201d which they recognized through their muscular senses. ... Mass and its associated downward force were believed to be the same thing. \nKepler formed a [distinct] concept of mass (\u201camount of matter\u201d (copia materiae)), but called it \u201cweight\u201d as did everyone at that time.In the first paragraph of Principia, Newton defined quantity of matter as \u201cdensity and bulk conjunctly\u201d, and mass as quantity of matter.The quantity of matter is the measure of the same, arising from its density and bulk conjunctly. ... It is this quantity that I mean hereafter everywhere under the name of body or mass. And the same is known by the weight of each body; for it is proportional to the weight.\n\n\n== Newtonian mass ==\n\nRobert Hooke had published his concept of gravitational forces in 1674, stating that all celestial bodies have an attraction or gravitating power towards their own centers, and also attract all the other celestial bodies that are within the sphere of their activity. He further stated that gravitational attraction increases by how much nearer the body wrought upon is to its own center. In correspondence with Isaac Newton from 1679 and 1680, Hooke conjectured that gravitational forces might decrease according to the double of the distance between the two bodies. Hooke urged Newton, who was a pioneer in the development of calculus, to work through the mathematical details of Keplerian orbits to determine if Hooke's hypothesis was correct.  Newton's own investigations verified that Hooke was correct, but due to personal differences between the two men, Newton chose not to reveal this to Hooke.  Isaac Newton kept quiet about his discoveries until 1684, at which time he told a friend, Edmond Halley, that he had solved the problem of gravitational orbits, but had misplaced the solution in his office. After being encouraged by Halley, Newton decided to develop his ideas about gravity and publish all of his findings.  In November 1684, Isaac Newton sent a document to Edmund Halley, now lost but presumed to have been titled De motu corporum in gyrum (Latin for \"On the motion of bodies in an orbit\"). Halley presented Newton's findings to the Royal Society of London, with a promise that a fuller presentation would follow.  Newton later recorded his ideas in a three-book set, entitled Philosophi\u00e6 Naturalis Principia Mathematica (Latin: Mathematical Principles of Natural Philosophy).  The first was received by the Royal Society on 28 April 1685\u201386; the second on 2 March 1686\u201387; and the third on 6 April 1686\u201387.  The Royal Society published Newton's entire collection at their own expense in May 1686\u201387.:\u200a31\u200aIsaac Newton had bridged the gap between Kepler's gravitational mass and Galileo's gravitational acceleration, resulting in the discovery of the following relationship which governed both of these:\n\n  \n    \n      \n        \n          g\n        \n        =\n        \u2212\n        \u03bc\n        \n          \n            \n              \n                \n                  R\n                \n                ^\n              \n            \n            \n              \n                |\n              \n              \n                R\n              \n              \n                \n                  |\n                \n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {g} =-\\mu {\\frac {\\hat {\\mathbf {R} }}{|\\mathbf {R} |^{2}}}}\n  where g is the apparent acceleration of a body as it passes through a region of space where gravitational fields exist, \u03bc is the gravitational mass (standard gravitational parameter) of the body causing gravitational fields, and R is the radial coordinate (the distance between the centers of the two bodies).\nBy finding the exact relationship between a body's gravitational mass and its gravitational field, Newton provided a second method for measuring gravitational mass.  The mass of the Earth can be determined using Kepler's method (from the orbit of Earth's Moon), or it can be determined by measuring the gravitational acceleration on the Earth's surface, and multiplying that by the square of the Earth's radius.  The mass of the Earth is approximately three-millionths of the mass of the Sun.  To date, no other accurate method for measuring gravitational mass has been discovered.\n\n\n=== Newton's cannonball ===\n\nNewton's cannonball was a thought experiment used to bridge the gap between Galileo's gravitational acceleration and Kepler's elliptical orbits.  It appeared in Newton's 1728 book A Treatise of the System of the World.  According to Galileo's concept of gravitation, a dropped stone falls with constant acceleration down towards the Earth.  However, Newton explains that when a stone is thrown horizontally (meaning sideways or perpendicular to Earth's gravity) it follows a curved path.  \"For a stone projected is by the pressure of its own weight forced out of the rectilinear path, which by the projection alone it should have pursued, and made to describe a curve line in the air; and through that crooked way is at last brought down to the ground.  And the greater the velocity is with which it is projected, the farther it goes before it falls to the Earth.\":\u200a513\u200a Newton further reasons that if an object were \"projected in an horizontal direction from the top of a high mountain\" with sufficient velocity, \"it would reach at last quite beyond the circumference of the Earth, and return to the mountain from which it was projected.\"\n\n\n=== Universal gravitational mass ===\n\nIn contrast to earlier theories (e.g. celestial spheres) which stated that the heavens were made of entirely different material, Newton's theory of mass was groundbreaking partly because it introduced universal gravitational mass: every object has gravitational mass, and therefore, every object generates a gravitational field.  Newton further assumed that the strength of each object's gravitational field would decrease according to the square of the distance to that object. If a large collection of small objects were formed into a giant spherical body such as the Earth or Sun, Newton calculated the collection would create a gravitational field proportional to the total mass of the body,:\u200a397\u200a and inversely proportional to the square of the distance to the body's center.:\u200a221\u200aFor example, according to Newton's theory of universal gravitation, each carob seed produces a gravitational field.  Therefore, if one were to gather an immense number of carob seeds and form them into an enormous sphere, then the gravitational field of the sphere would be proportional to the number of carob seeds in the sphere.  Hence, it should be theoretically possible to determine the exact number of carob seeds that would be required to produce a gravitational field similar to that of the Earth or Sun.  In fact, by unit conversion it is a simple matter of abstraction to realize that any traditional mass unit can theoretically be used to measure gravitational mass.\n\nMeasuring gravitational mass in terms of traditional mass units is simple in principle, but extremely difficult in practice.  According to Newton's theory, all objects produce gravitational fields and it is theoretically possible to collect an immense number of small objects and form them into an enormous gravitating sphere.  However, from a practical standpoint, the gravitational fields of small objects are extremely weak and difficult to measure. Newton's books on universal gravitation were published in the 1680s, but the first successful measurement of the Earth's mass in terms of traditional mass units, the Cavendish experiment, did not occur until 1797, over a hundred years later. Henry Cavendish found that the Earth's density was 5.448 \u00b1 0.033 times that of water.  As of 2009, the Earth's mass in kilograms is only known to around five digits of accuracy, whereas its gravitational mass is known to over nine significant figures.Given two objects A and B, of masses MA and MB, separated by a displacement RAB, Newton's law of gravitation states that each object exerts a gravitational force on the other, of magnitude\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            AB\n          \n        \n        =\n        \u2212\n        G\n        \n          M\n          \n            A\n          \n        \n        \n          M\n          \n            B\n          \n        \n        \n          \n            \n              \n                \n                  \n                    \n                      R\n                    \n                    ^\n                  \n                \n              \n              \n                AB\n              \n            \n            \n              \n                |\n              \n              \n                \n                  R\n                \n                \n                  AB\n                \n              \n              \n                \n                  |\n                \n                \n                  2\n                \n              \n            \n          \n        \n         \n      \n    \n    {\\displaystyle \\mathbf {F} _{\\text{AB}}=-GM_{\\text{A}}M_{\\text{B}}{\\frac {{\\hat {\\mathbf {R} }}_{\\text{AB}}}{|\\mathbf {R} _{\\text{AB}}|^{2}}}\\ }\n  ,where G is the universal gravitational constant. The above statement may be reformulated in the following way: if g is the magnitude at a given location in a gravitational field, then the gravitational force on an object with gravitational mass M is\n\n  \n    \n      \n        F\n        =\n        M\n        g\n      \n    \n    {\\displaystyle F=Mg}\n  .This is the basis by which masses are determined by weighing. In simple spring scales, for example, the force F is proportional to the displacement of the spring beneath the weighing pan, as per Hooke's law, and the scales are calibrated to take g into account, allowing the mass M to be read off. Assuming the gravitational field is equivalent on both sides of the balance, a balance measures relative weight, giving the relative gravitation mass of each object.\n\n\n=== Inertial mass ===\nMass was traditionally believed to be a measure of the quantity of matter in a physical body, equal to the \"amount of matter\" in an object. For example, Barre\u00b4 de Saint-Venant argued in 1851 that every object contains a number of \"points\" (basically, interchangeable elementary particles), and that mass is proportional to the number of points the object contains. (In practice, this \"amount of matter\" definition is adequate for most of classical mechanics, and sometimes remains in use in basic education, if the priority is to teach the difference between mass from weight.) This traditional \"amount of matter\" belief was contradicted by the fact that different atoms (and, later, different elementary particles) can have different masses, and was further contradicted by Einstein's theory of relativity (1905), which showed that the measurable mass of an object increases when energy is added to it (for example, by increasing its temperature or forcing it near an object that electrically repels it.) This motivates a search for a different definition of mass that is more accurate than the traditional definition of \"the amount of matter in an object\".\n\nInertial mass is the mass of an object measured by its resistance to acceleration. This definition has been championed by Ernst Mach and has since been developed into the notion of operationalism by Percy W. Bridgman. The simple classical mechanics definition of mass differs slightly from the definition in the theory of special relativity, but the essential meaning is the same.\nIn classical mechanics, according to Newton's second law, we say that a body has a mass m if, at any instant of time, it obeys the equation of motion\n\n  \n    \n      \n        \n          F\n        \n        =\n        m\n        \n          a\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =m\\mathbf {a} ,}\n  where F is the resultant force acting on the body and a is the acceleration of the body's centre of mass. For the moment, we will put aside the question of what \"force acting on the body\" actually means.\nThis equation illustrates how mass relates to the inertia of a body. Consider two objects with different masses. If we apply an identical force to each, the object with a bigger mass will experience a smaller acceleration, and the object with a smaller mass will experience a bigger acceleration. We might say that the larger mass exerts a greater \"resistance\" to changing its state of motion in response to the force.\nHowever, this notion of applying \"identical\" forces to different objects brings us back to the fact that we have not really defined what a force is. We can sidestep this difficulty with the help of Newton's third law, which states that if one object exerts a force on a second object, it will experience an equal and opposite force. To be precise, suppose we have two objects of constant inertial masses m1 and m2. We isolate the two objects from all other physical influences, so that the only forces present are the force exerted on m1 by m2, which we denote F12, and the force exerted on m2 by m1, which we denote F21. Newton's second law states that\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    F\n                    \n                      12\n                    \n                  \n                \n              \n              \n                \n                =\n                \n                  m\n                  \n                    1\n                  \n                \n                \n                  \n                    a\n                  \n                  \n                    1\n                  \n                \n                ,\n              \n            \n            \n              \n                \n                  \n                    F\n                    \n                      21\n                    \n                  \n                \n              \n              \n                \n                =\n                \n                  m\n                  \n                    2\n                  \n                \n                \n                  \n                    a\n                  \n                  \n                    2\n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {F_{12}} &=m_{1}\\mathbf {a} _{1},\\\\\\mathbf {F_{21}} &=m_{2}\\mathbf {a} _{2},\\end{aligned}}}\n  where a1 and a2 are the accelerations of m1 and m2, respectively. Suppose that these accelerations are non-zero, so that the forces between the two objects are non-zero. This occurs, for example, if the two objects are in the process of colliding with one another. Newton's third law then states that\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            12\n          \n        \n        =\n        \u2212\n        \n          \n            F\n          \n          \n            21\n          \n        \n        ;\n      \n    \n    {\\displaystyle \\mathbf {F} _{12}=-\\mathbf {F} _{21};}\n  and thus\n\n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        =\n        \n          m\n          \n            2\n          \n        \n        \n          \n            \n              \n                |\n              \n              \n                \n                  a\n                \n                \n                  2\n                \n              \n              \n                |\n              \n            \n            \n              \n                |\n              \n              \n                \n                  a\n                \n                \n                  1\n                \n              \n              \n                |\n              \n            \n          \n        \n        \n        .\n      \n    \n    {\\displaystyle m_{1}=m_{2}{\\frac {|\\mathbf {a} _{2}|}{|\\mathbf {a} _{1}|}}\\!.}\n  If |a1| is non-zero, the fraction is well-defined, which allows us to measure the inertial mass of m1. In this case, m2 is our \"reference\" object, and we can define its mass m as (say) 1 kilogram. Then we can measure the mass of any other object in the universe by colliding it with the reference object and measuring the accelerations.\nAdditionally, mass relates a body's momentum p to its linear velocity v:\n\n  \n    \n      \n        \n          p\n        \n        =\n        m\n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {p} =m\\mathbf {v} }\n  ,and the body's kinetic energy K to its velocity:\n\n  \n    \n      \n        K\n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        m\n        \n          |\n        \n        \n          v\n        \n        \n          \n            |\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle K={\\dfrac {1}{2}}m|\\mathbf {v} |^{2}}\n  .The primary difficulty with Mach's definition of mass is that it fails to take into account the potential energy (or binding energy) needed to bring two masses sufficiently close to one another to perform the measurement of mass. This is most vividly demonstrated by comparing the mass of the proton in the nucleus of deuterium, to the mass of the proton in free space (which is greater by about 0.239%\u2014this is due to the binding energy of deuterium). Thus, for example, if the reference weight m2 is taken to be the mass of the neutron in free space, and the relative accelerations for the proton and neutron in deuterium are computed, then the above formula over-estimates the mass m1 (by 0.239%) for the proton in deuterium.  At best, Mach's formula can only be used to obtain ratios of masses, that is, as m1 / m2 = |a2| / |a1|.  An additional difficulty was pointed out by Henri Poincar\u00e9, which is that the measurement of instantaneous acceleration is impossible: unlike the measurement of time or distance, there is no way to measure acceleration with a single measurement; one must make multiple measurements (of position, time, etc.) and perform a computation to obtain the acceleration.  Poincar\u00e9 termed this to be an \"insurmountable flaw\" in the Mach definition of mass.\n\n\n== Atomic masses ==\n\nTypically, the mass of objects is measured in terms of the kilogram, which since 2019 is defined in terms of fundamental constants of nature. The mass of an atom or other particle can be compared more precisely and more conveniently to that of another atom, and thus scientists developed the dalton (also known as the unified atomic mass unit). By definition, 1 Da (one dalton) is exactly one-twelfth of the mass of a carbon-12 atom, and thus, a carbon-12 atom has a mass of exactly 12 Da.\n\n\n== In relativity ==\n\n\n=== Special relativity ===\n\nIn some frameworks of special relativity, physicists have used different definitions of the term. In these frameworks, two kinds of mass are defined: rest mass (invariant mass), and relativistic mass (which increases with velocity). Rest mass is the Newtonian mass as measured by an observer moving along with the object.  Relativistic mass is the total quantity of energy in a body or system divided by c2. The two are related by the following equation:\n\n  \n    \n      \n        \n          m\n          \n            \n              r\n              e\n              l\n              a\n              t\n              i\n              v\n              e\n            \n          \n        \n        =\n        \u03b3\n        (\n        \n          m\n          \n            \n              r\n              e\n              s\n              t\n            \n          \n        \n        )\n        \n      \n    \n    {\\displaystyle m_{\\mathrm {relative} }=\\gamma (m_{\\mathrm {rest} })\\!}\n  where \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is the Lorentz factor:\n\n  \n    \n      \n        \u03b3\n        =\n        \n          \n            1\n            \n              1\n              \u2212\n              \n                v\n                \n                  2\n                \n              \n              \n                /\n              \n              \n                c\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\gamma ={\\frac {1}{\\sqrt {1-v^{2}/c^{2}}}}}\n  The invariant mass of systems is the same for observers in all inertial frames, while the relativistic mass depends on the observer's frame of reference. In order to formulate the equations of physics such that mass values do not change between observers, it is convenient to use rest mass. The rest mass of a body is also related to its energy E and the magnitude of its momentum p by the relativistic energy-momentum equation:\n\n  \n    \n      \n        (\n        \n          m\n          \n            \n              r\n              e\n              s\n              t\n            \n          \n        \n        )\n        \n          c\n          \n            2\n          \n        \n        =\n        \n          \n            \n              E\n              \n                \n                  t\n                  o\n                  t\n                  a\n                  l\n                \n              \n              \n                2\n              \n            \n            \u2212\n            (\n            \n              |\n            \n            \n              p\n            \n            \n              |\n            \n            c\n            \n              )\n              \n                2\n              \n            \n          \n        \n        .\n        \n      \n    \n    {\\displaystyle (m_{\\mathrm {rest} })c^{2}={\\sqrt {E_{\\mathrm {total} }^{2}-(|\\mathbf {p} |c)^{2}}}.\\!}\n  So long as the system is closed with respect to mass and energy, both kinds of mass are conserved in any given frame of reference. The conservation of mass holds even as some types of particles are converted to others. Matter particles (such as atoms) may be converted to non-matter particles (such as photons of light), but this does not affect the total amount of mass or energy. Although things like heat may not be matter, all types of energy still continue to exhibit mass. Thus, mass and energy do not change into one another in relativity; rather, both are names for the same thing, and neither mass nor energy appear without the other.\nBoth rest and relativistic mass can be expressed as an energy by applying the well-known relationship E = mc2, yielding rest energy and \"relativistic energy\" (total system energy) respectively:\n\n  \n    \n      \n        \n          E\n          \n            \n              r\n              e\n              s\n              t\n            \n          \n        \n        =\n        (\n        \n          m\n          \n            \n              r\n              e\n              s\n              t\n            \n          \n        \n        )\n        \n          c\n          \n            2\n          \n        \n        \n      \n    \n    {\\displaystyle E_{\\mathrm {rest} }=(m_{\\mathrm {rest} })c^{2}\\!}\n  \n\n  \n    \n      \n        \n          E\n          \n            \n              t\n              o\n              t\n              a\n              l\n            \n          \n        \n        =\n        (\n        \n          m\n          \n            \n              r\n              e\n              l\n              a\n              t\n              i\n              v\n              e\n            \n          \n        \n        )\n        \n          c\n          \n            2\n          \n        \n        \n      \n    \n    {\\displaystyle E_{\\mathrm {total} }=(m_{\\mathrm {relative} })c^{2}\\!}\n  The \"relativistic\" mass and energy concepts are related to their \"rest\" counterparts, but they do not have the same value as their rest counterparts in systems where there is a net momentum. Because the relativistic mass is proportional to the energy, it has gradually fallen into disuse among physicists. There is disagreement over whether the concept remains useful pedagogically.In bound systems, the binding energy must often be subtracted from the mass of the unbound system, because binding energy commonly leaves the system at the time it is bound. The mass of the system changes in this process merely because the system was not closed during the binding process, so the energy escaped. For example, the binding energy of atomic nuclei is often lost in the form of gamma rays when the nuclei are formed, leaving nuclides which have less mass than the free particles (nucleons) of which they are composed.\nMass\u2013energy equivalence also holds in macroscopic systems. For example, if one takes exactly one kilogram of ice, and applies heat, the mass of the resulting melt-water will be more than a kilogram: it will include the mass from the thermal energy (latent heat) used to melt the ice; this follows from the conservation of energy. This number is small but not negligible: about 3.7 nanograms. It is given by the latent heat of melting ice (334 kJ/kg) divided by the speed of light squared (c2 \u2248 9\u00d71016 m2/s2).\n\n\n=== General relativity ===\n\nIn general relativity, the equivalence principle is the equivalence of gravitational and inertial mass. At the core of this assertion is Albert Einstein's idea that the gravitational force as experienced locally while standing on a massive body (such as the Earth) is the same as the pseudo-force experienced by an observer in a non-inertial (i.e. accelerated) frame of reference.\nHowever, it turns out that it is impossible to find an objective general definition for the concept of invariant mass in general relativity. At the core of the problem is the non-linearity of the Einstein field equations, making it impossible to write the gravitational field energy as part of the stress\u2013energy tensor in a way that is invariant for all observers. For a given observer, this can be achieved by the stress\u2013energy\u2013momentum pseudotensor.\n\n\n== In quantum physics ==\nIn classical mechanics, the inert mass of a particle appears in the Euler\u2013Lagrange equation as a parameter m:\n\n  \n    \n      \n        \n          \n            \n              d\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n         \n        \n          (\n          \n            \n            \n              \n                \n                  \u2202\n                  L\n                \n                \n                  \u2202\n                  \n                    \n                      \n                        \n                          x\n                          \u02d9\n                        \n                      \n                    \n                    \n                      i\n                    \n                  \n                \n              \n            \n            \n          \n          )\n        \n         \n        =\n         \n        m\n        \n        \n          \n            \n              \n                x\n                \u00a8\n              \n            \n          \n          \n            i\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} }{\\mathrm {d} t}}\\ \\left(\\,{\\frac {\\partial L}{\\partial {\\dot {x}}_{i}}}\\,\\right)\\ =\\ m\\,{\\ddot {x}}_{i}.}\n  After quantization, replacing the position vector x with a wave function, the parameter m appears in the kinetic energy operator:\n\n  \n    \n      \n        i\n        \u210f\n        \n          \n            \u2202\n            \n              \u2202\n              t\n            \n          \n        \n        \u03a8\n        (\n        \n          r\n        \n        ,\n        \n        t\n        )\n        =\n        \n          (\n          \n            \u2212\n            \n              \n                \n                  \u210f\n                  \n                    2\n                  \n                \n                \n                  2\n                  m\n                \n              \n            \n            \n              \u2207\n              \n                2\n              \n            \n            +\n            V\n            (\n            \n              r\n            \n            )\n          \n          )\n        \n        \u03a8\n        (\n        \n          r\n        \n        ,\n        \n        t\n        )\n        .\n      \n    \n    {\\displaystyle i\\hbar {\\frac {\\partial }{\\partial t}}\\Psi (\\mathbf {r} ,\\,t)=\\left(-{\\frac {\\hbar ^{2}}{2m}}\\nabla ^{2}+V(\\mathbf {r} )\\right)\\Psi (\\mathbf {r} ,\\,t).}\n  In the ostensibly covariant (relativistically invariant) Dirac equation, and in natural units, this becomes:\n\n  \n    \n      \n        (\n        \u2212\n        i\n        \n          \u03b3\n          \n            \u03bc\n          \n        \n        \n          \u2202\n          \n            \u03bc\n          \n        \n        +\n        m\n        )\n        \u03c8\n        =\n        0\n      \n    \n    {\\displaystyle (-i\\gamma ^{\\mu }\\partial _{\\mu }+m)\\psi =0}\n  where the \"mass\" parameter m is now simply a constant associated with the quantum described by the wave function \u03c8.\nIn the Standard Model of particle physics as developed in the 1960s, this term arises from the coupling of the field \u03c8 to an additional field \u03a6, the Higgs field. In the case of fermions, the Higgs mechanism results in the replacement of the term m\u03c8 in the Lagrangian with \n  \n    \n      \n        \n          G\n          \n            \u03c8\n          \n        \n        \n          \n            \u03c8\n            \u00af\n          \n        \n        \u03d5\n        \u03c8\n      \n    \n    {\\displaystyle G_{\\psi }{\\overline {\\psi }}\\phi \\psi }\n  . This shifts the explanandum of the value for the mass of each elementary particle to the value of the unknown coupling constant G\u03c8.\n\n\n=== Tachyonic particles and imaginary (complex) mass ===\n\nA tachyonic field, or simply tachyon, is a quantum field with an imaginary mass. Although tachyons (particles that move faster than light) are a purely hypothetical concept not generally believed to exist, fields with imaginary mass have come to play an important role in modern physics and are discussed in popular books on physics. Under no circumstances do any excitations ever propagate faster than light in such theories\u2014the presence or absence of a tachyonic mass has no effect whatsoever on the maximum velocity of signals (there is no violation of causality). While the field may have imaginary mass, any physical particles do not; the \"imaginary mass\" shows that the system becomes unstable, and sheds the instability by undergoing a type of phase transition called tachyon condensation (closely related to second order phase transitions) that results in symmetry breaking in current models of particle physics.\nThe term \"tachyon\" was coined by Gerald Feinberg in a 1967 paper, but it was soon realized that Feinberg's model in fact did not allow for superluminal speeds. Instead, the imaginary mass creates an instability in the configuration:- any configuration in which one or more field excitations are tachyonic will spontaneously decay, and the resulting configuration contains no physical tachyons.  This process is known as tachyon condensation.  Well known examples include the condensation of the Higgs boson in particle physics, and ferromagnetism in condensed matter physics.\nAlthough the notion of a tachyonic imaginary mass might seem troubling because there is no classical interpretation of an imaginary mass, the mass is not quantized.  Rather, the scalar field is; even for tachyonic quantum fields, the field operators at spacelike separated points still commute (or anticommute), thus preserving causality. Therefore, information still does not propagate faster than light, and solutions grow exponentially, but not superluminally (there is no violation of causality). Tachyon condensation drives a physical system that has reached a local limit and might naively be expected to produce physical tachyons, to an alternate stable state where no physical tachyons exist. Once the tachyonic field reaches the minimum of the potential, its quanta are not tachyons any more but rather are ordinary particles with a positive mass-squared.This is a special case of the general rule, where unstable massive particles are formally described as having a complex mass, with the real part being their mass in the usual sense, and the imaginary part being the decay rate in natural units. However, in quantum field theory, a particle (a \"one-particle state\") is roughly defined as a state which is constant over time; i.e., an eigenvalue of the Hamiltonian. An unstable particle is a state which is only approximately constant over time; If it exists long enough to be measured, it can be formally described as having a complex mass, with the real part of the mass greater than its imaginary part. If both parts are of the same magnitude, this is interpreted as a resonance appearing in a scattering process rather than a particle, as it is considered not to exist long enough to be measured independently of the scattering process. In the case of a tachyon, the real part of the mass is zero, and hence no concept of a particle can be attributed to it.\nIn a Lorentz invariant theory, the same formulas that apply to ordinary slower-than-light particles (sometimes called \"bradyons\" in discussions of tachyons) must also apply to tachyons. In particular the energy\u2013momentum relation:\n\n  \n    \n      \n        \n          E\n          \n            2\n          \n        \n        =\n        \n          p\n          \n            2\n          \n        \n        \n          c\n          \n            2\n          \n        \n        +\n        \n          m\n          \n            2\n          \n        \n        \n          c\n          \n            4\n          \n        \n        \n      \n    \n    {\\displaystyle E^{2}=p^{2}c^{2}+m^{2}c^{4}\\;}\n  (where p is the relativistic momentum of the bradyon and m is its rest mass) should still apply, along with the formula for the total energy of a particle:\n\n  \n    \n      \n        E\n        =\n        \n          \n            \n              m\n              \n                c\n                \n                  2\n                \n              \n            \n            \n              1\n              \u2212\n              \n                \n                  \n                    v\n                    \n                      2\n                    \n                  \n                  \n                    c\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle E={\\frac {mc^{2}}{\\sqrt {1-{\\frac {v^{2}}{c^{2}}}}}}.}\n  This equation shows that the total energy of a particle (bradyon or tachyon) contains a contribution from its rest mass (the \"rest mass\u2013energy\") and a contribution from its motion, the kinetic energy.\nWhen v is larger than c, the denominator in the equation for the energy is \"imaginary\", as the value under the radical is negative. Because the total energy must be real, the numerator must also be imaginary:  i.e. the rest mass m must be imaginary, as a pure imaginary number divided by another pure imaginary number is a real number.\n\n\n== See also ==\nMass versus weight\nEffective mass (spring\u2013mass system)\nEffective mass (solid-state physics)\nExtension (metaphysics)\nInternational System of Quantities\n2019 redefinition of SI base units\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\nFrancisco Flores (6 February 2012). \"The Equivalence of Mass and Energy\". Stanford Encyclopedia of Philosophy.\nGordon Kane (27 June 2005). \"The Mysteries of Mass\". Scientific American. Archived from the original on 10 October 2007.\nL.B. Okun (2002). \"Photons, Clocks, Gravity and the Concept of Mass\". Nuclear Physics B: Proceedings Supplements. 110: 151\u2013155. arXiv:physics/0111134. Bibcode:2002NuPhS.110..151O. doi:10.1016/S0920-5632(02)01472-X. S2CID 16733517.\nFrank Wilczek (13 May 2001). \"The Origin of Mass and the Feebleness of Gravity\" (video). MIT Video.\nJohn Baez;  et al. (2012). \"Does mass change with velocity?\".\nJohn Baez;  et al. (2008). \"What is the mass of a photon?\".\nJim Baggott (27 September 2017). The Concept of Mass (video) published by the Royal Institution on YouTube.", "Potential_energy": "In physics, potential energy is the energy held by an object because of its position relative to other objects, stresses within itself, its electric charge, or other factors. The term potential energy was introduced by the 19th-century Scottish engineer and physicist William Rankine, although it has links to the ancient Greek philosopher Aristotle's concept of potentiality.\nCommon types of potential energy include the gravitational potential energy of an object, the elastic potential energy of an extended spring, and the electric potential energy of an electric charge in an electric field. The unit for energy in the International System of Units (SI) is the joule, which has the symbol J.\nPotential energy is associated with forces that act on a body in a way that the total work done by these forces on the body depends only on the initial and final positions of the body in space. These forces, whose total work is path independent, are called conservative forces. If the force acting on a body varies over space, then one has a force field; such a field is described by vectors at every point in space, which is in-turn called a vector field. A conservative vector field can be simply expressed as the gradient of a certain scalar function, called a scalar potential.\n\n\n== Overview ==\nThere are various types of potential energy, each associated with a particular type of force. For example, the work of an elastic force is called elastic potential energy; work of the gravitational force is called gravitational potential energy; work of the Coulomb force is called electric potential energy; work of the strong nuclear force or weak nuclear force acting on the baryon charge is called nuclear potential energy; work of intermolecular forces is called intermolecular potential energy. Chemical potential energy, such as the energy stored in fossil fuels, is the work of the Coulomb force during rearrangement of configurations of electrons and nuclei in atoms and molecules. Thermal energy usually has two components: the kinetic energy of random motions of particles and the potential energy of their configuration.\nForces derivable from a potential are also called conservative forces. The work done by a conservative force is\n\nwhere \n  \n    \n      \n        \u0394\n        U\n      \n    \n    {\\displaystyle \\Delta U}\n   is the change in the potential energy associated with the force. The negative sign provides the convention that work done against a force field increases potential energy, while work done by the force field decreases potential energy.  Common notations for potential energy are PE, U, V, and Ep.\nPotential energy is the energy by virtue of an object's position relative to other objects. Potential energy is often associated with restoring forces such as a spring or the force of gravity. The action of stretching a spring or lifting a mass is performed by an external force that works against the force field of the potential.  This work is stored in the force field, which is said to be stored as potential energy.  If the external force is removed the force field acts on the body to perform the work as it moves the body back to the initial position, reducing the stretch of the spring or causing a body to fall.\nConsider a ball whose mass is m and whose height is h. The acceleration g of free fall is approximately constant, so the weight force of the ball mg is constant. The product of force and displacement gives the work done, which is equal to the gravitational potential energy, thus\n\nThe more formal definition is that potential energy is the energy difference between the energy of an object in a given position and its energy at a reference position.\n\n\n== Work and potential energy ==\nPotential energy is closely linked with forces. If the work done by a force on a body that moves from A to B does not depend on the path between these points (if the work is done by a conservative force), then the work of this force measured from A assigns a scalar value to every other point in space and defines a scalar potential field. In this case, the force can be defined as the negative of the vector gradient of the potential field.\nIf the work for an applied force is independent of the path, then the work done by the force is evaluated from the start to the end of the trajectory of the point of application.  This means that there is a function U(x), called a \"potential\", that can be evaluated at the two points xA and xB to obtain the work over any trajectory between these two points.  It is tradition to define this function with a negative sign so that positive work is a reduction in the potential, that is \n\nwhere C is the trajectory taken from A to B. Because the work done is independent of the path taken, then this expression is true for any trajectory, C, from A to B.\nThe function U(x) is called the potential energy associated with the applied force.  Examples of forces that have potential energies are gravity and spring forces.\n\n\n=== Derivable from a potential ===\nIn this section the relationship between work and potential energy is presented in more detail. The line integral that defines work along curve C takes a special form if the force F is related to a scalar field U\u2032(x) so that\n\nThis means that the units of U\u2032 must be this case, work along the curve is given by\n\nwhich can be evaluated using the gradient theorem to obtain\n\nThis shows that when forces are derivable from a scalar field, the work of those forces along a curve C is computed by evaluating the scalar field at the start point A and the end point B of the curve.  This means the work integral does not depend on the path between A and B and is said to be independent of the path.\nPotential energy U = \u2212U\u2032(x) is traditionally defined as the negative of this scalar field so that work by the force field decreases potential energy, that is\n\nIn this case, the application of the del operator to the work function yields,\n\nand the force F is said to be \"derivable from a potential\". This also necessarily implies that F must be a conservative vector field. The potential U defines a force F at every point x in space, so the set of forces is called a force field.\n\n\n=== Computing potential energy ===\nGiven a force field F(x), evaluation of the work integral using the gradient theorem can be used to find the scalar function associated with potential energy. This is done by introducing a parameterized curve \u03b3(t) = r(t) from \u03b3(a) = A to \u03b3(b) = B, and computing,\n\nFor the force field F, let v = dr/dt, then the gradient theorem yields,\n\nThe power applied to a body by a force field is obtained from the gradient of the work, or potential, in the direction of the velocity v of the point of application, that is\n\nExamples of work that can be computed from potential functions are gravity and spring forces.\n\n\n== Potential energy for near Earth gravity ==\n\nFor small height changes, gravitational potential energy can be computed using\n\nwhere m is the mass in kg, g is the local gravitational field (9.8 metres per second squared on earth), h is the height above a reference level in metres, and U is the energy in joules.\nIn classical physics, gravity exerts a constant downward force F = (0, 0, Fz) on the center of mass of a body moving near the surface of the Earth.  The work of gravity on a body moving along a trajectory r(t) = (x(t), y(t), z(t)), such as the track of a roller coaster is calculated using its velocity, v = (vx, vy, vz), to obtain\n\nwhere the integral of the vertical component of velocity is the vertical distance. The work of gravity depends only on the vertical movement of the curve r(t).\n\n\n== Potential energy for a linear spring ==\n\nA horizontal spring exerts a force F = (\u2212kx, 0, 0) that is proportional to its deformation in the axial or x direction.  The work of this spring on a body moving along the space curve s(t) = (x(t), y(t), z(t)), is calculated using its velocity, v = (vx, vy, vz), to obtain\n\nFor convenience, consider contact with the spring occurs at t = 0, then the integral of the product of the distance x and the x-velocity, xvx, is x2/2.\nThe function \n\nis called the potential energy of a linear spring.\nElastic potential energy is the potential energy of an elastic object (for example a bow or a catapult) that is deformed under tension or compression (or stressed in formal terminology). It arises as a consequence of a force that tries to restore the object to its original shape, which is most often the electromagnetic force between the atoms and molecules that constitute the object. If the stretch is released, the energy is transformed into kinetic energy.\n\n\n== Potential energy for gravitational forces between two bodies ==\nThe gravitational potential function, also known as gravitational potential energy, is:\n\nThe negative sign follows the convention that work is gained from a loss of potential energy.\n\n\n=== Derivation ===\nThe gravitational force between two bodies of mass M and m separated by a distance r is given by Newton's law of universal gravitation\n\nwhere \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} }\n   is a vector of length 1 pointing from M to m and G is the gravitational constant.\nLet the mass m move at the velocity v then the work of gravity on this mass as it moves from position r(t1) to  r(t2) is given by\n\nThe position and velocity of the mass m are given by\n\nwhere er and et are the radial and tangential unit vectors directed relative to the vector from M to m. Use this to simplify the formula for work of gravity to,\n\nThis calculation uses the fact that\n\n\n== Potential energy for electrostatic forces between two bodies ==\nThe electrostatic force exerted by a charge Q on another charge q separated by a distance r is given by Coulomb's Law\n\nwhere \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} }\n   is a vector of length 1 pointing from Q to q and \u03b50 is the vacuum permittivity.\nThe work W required to move q from A to any point B in the electrostatic force field is given by the potential function\n\n\n== Reference level ==\nThe potential energy is a function of the state a system is in, and is defined relative to that for a particular state. This reference state is not always a real state; it may also be a limit, such as with the distances between all bodies tending to infinity, provided that the energy involved in tending to that limit is finite, such as in the case of inverse-square law forces. Any arbitrary reference state could be used; therefore it can be chosen based on convenience.\nTypically the potential energy of a system depends on the relative positions of its components only, so the reference state can also be expressed in terms of relative positions.\n\n\n== Gravitational potential energy ==\n\nGravitational energy is the potential energy associated with gravitational force, as work is required to elevate objects against Earth's gravity. The potential energy due to elevated positions is called gravitational potential energy, and is evidenced by water in an elevated reservoir or kept behind a dam. If an object falls from one point to another point inside a gravitational field, the force of gravity will do positive work on the object, and the gravitational potential energy will decrease by the same amount.\n\nConsider a book placed on top of a table. As the book is raised from the floor to the table, some external force works against the gravitational force. If the book falls back to the floor, the \"falling\" energy the book receives is provided by the gravitational force. Thus, if the book falls off the table, this potential energy goes to accelerate the mass of the book and is converted into kinetic energy. When the book hits the floor this kinetic energy is converted into heat, deformation, and sound by the impact.\nThe factors that affect an object's gravitational potential energy are its height relative to some reference point, its mass, and the strength of the gravitational field it is in. Thus, a book lying on a table has less gravitational potential energy than the same book on top of a taller cupboard and less gravitational potential energy than a heavier book lying on the same table. An object at a certain height above the Moon's surface has less gravitational potential energy than at the same height above the Earth's surface because the Moon's gravity is weaker. \"Height\" in the common sense of the term cannot be used for gravitational potential energy calculations when gravity is not assumed to be a constant. The following sections provide more detail.\n\n\n=== Local approximation ===\nThe strength of a gravitational field varies with location. However, when the change of distance is small in relation to the distances from the center of the source of the gravitational field, this variation in field strength is negligible and we can assume that the force of gravity on a particular object is constant. Near the surface of the Earth, for example, we assume that the acceleration due to gravity is a constant g = 9.8 m/s2 (standard gravity). In this case, a simple expression for gravitational potential energy can be derived using the W = Fd equation for work, and the equation\n\nThe amount of gravitational potential energy held by an elevated object is equal to the work done against gravity in lifting it. The work done equals the force required to move it upward multiplied with the vertical distance it is moved (remember W = Fd). The upward force required while moving at a constant velocity is equal to the weight, mg, of an object, so the work done in lifting it through a height h is the product mgh. Thus, when accounting only for mass, gravity, and altitude, the equation is:\nwhere U is the potential energy of the object relative to its being on the Earth's surface, m is the mass of the object, g is the acceleration due to gravity, and h is the altitude of the object.Hence, the potential difference is\n\n\n=== General formula ===\nHowever, over large variations in distance, the approximation that g is constant is no longer valid, and we have to use calculus and the general mathematical definition of work to determine gravitational potential energy. For the computation of the potential energy, we can integrate the gravitational force, whose magnitude is given by Newton's law of gravitation, with respect to the distance r between the two bodies. Using that definition, the gravitational potential energy of a system of masses m1 and M2 at a distance r using the Newtonian constant of gravitation G is\n\nwhere K is an arbitrary constant dependent on the choice of datum from which potential is measured. Choosing the convention that K = 0 (i.e. in relation to a point at infinity) makes calculations simpler, albeit at the cost of making U negative; for why this is physically reasonable, see below.\nGiven this formula for U, the total potential energy of a system of n bodies is found by summing, for all \n  \n    \n      \n        \n          \n            \n              n\n              (\n              n\n              \u2212\n              1\n              )\n            \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {n(n-1)}{2}}}\n   pairs of two bodies, the potential energy of the system of those two bodies.\n\nConsidering the system of bodies as the combined set of small particles the bodies consist of, and applying the previous on the particle level we get the negative gravitational binding energy. This potential energy is more strongly negative than the total potential energy of the system of bodies as such since it also includes the negative gravitational binding energy of each body. The potential energy of the system of bodies as such is the negative of the energy needed to separate the bodies from each other to infinity, while the gravitational binding energy is the energy needed to separate all particles from each other to infinity.\n\ntherefore,\n\n\n=== Negative gravitational energy ===\nAs with all potential energies, only differences in gravitational potential energy matter for most physical purposes, and the choice of zero point is arbitrary. Given that there is no reasonable criterion for preferring one particular finite r over another, there seem to be only two reasonable choices for the distance at which U becomes zero: \n  \n    \n      \n        r\n        =\n        0\n      \n    \n    {\\displaystyle r=0}\n   and \n  \n    \n      \n        r\n        =\n        \u221e\n      \n    \n    {\\displaystyle r=\\infty }\n  . The choice of \n  \n    \n      \n        U\n        =\n        0\n      \n    \n    {\\displaystyle U=0}\n   at infinity may seem peculiar, and the consequence that gravitational energy is always negative may seem counterintuitive, but this choice allows gravitational potential energy values to be finite, albeit negative.\nThe singularity at \n  \n    \n      \n        r\n        =\n        0\n      \n    \n    {\\displaystyle r=0}\n   in the formula for gravitational potential energy means that the only other apparently reasonable alternative choice of convention, with \n  \n    \n      \n        U\n        =\n        0\n      \n    \n    {\\displaystyle U=0}\n   for \n  \n    \n      \n        r\n        =\n        0\n      \n    \n    {\\displaystyle r=0}\n  , would result in potential energy being positive, but infinitely large for all nonzero values of r, and would make calculations involving sums or differences of potential energies beyond what is possible with the real number system. Since physicists abhor infinities in their calculations, and r is always non-zero in practice, the choice of \n  \n    \n      \n        U\n        =\n        0\n      \n    \n    {\\displaystyle U=0}\n   at infinity is by far the more preferable choice, even if the idea of negative energy in a gravity well appears to be peculiar at first.\nThe negative value for gravitational energy also has deeper implications that make it seem more reasonable in cosmological calculations where the total energy of the universe can meaningfully be considered; see inflation theory for more on this.\n\n\n=== Uses ===\n\nGravitational potential energy has a number of practical uses, notably the generation of pumped-storage hydroelectricity. For example, in Dinorwig, Wales, there are two lakes, one at a higher elevation than the other. At times when surplus electricity is not required (and so is comparatively cheap), water is pumped up to the higher lake, thus converting the electrical energy (running the pump) to gravitational potential energy. At times of peak demand for electricity, the water flows back down through electrical generator turbines, converting the potential energy into kinetic energy and then back into electricity. The process is not completely efficient and some of the original energy from the surplus electricity is in fact lost to friction.\nGravitational potential energy is also used to power clocks in which falling weights operate the mechanism.  It's also used by counterweights for lifting up an elevator, crane, or sash window.\nRoller coasters are an entertaining way to utilize potential energy \u2013 chains are used to move a car up an incline (building up gravitational potential energy), to then have that energy converted into kinetic energy as it falls.\nAnother practical use is utilizing gravitational potential energy to descend (perhaps coast) downhill in transportation such as the descent of an automobile, truck, railroad train, bicycle, airplane, or fluid in a pipeline.  In some cases the kinetic energy obtained from the potential energy of descent may be used to start ascending the next grade such as what happens when a road is undulating and has frequent dips. The commercialization of stored energy (in the form of rail cars raised to higher elevations) that is then converted to electrical energy when needed by an electrical grid, is being undertaken in the United States in a system called Advanced Rail Energy Storage (ARES).\n\n\n== Chemical potential energy ==\n\nChemical potential energy is a form of potential energy related to the structural arrangement of atoms or molecules. This arrangement may be the result of chemical bonds within a molecule or otherwise. Chemical energy of a chemical substance can be transformed to other forms of energy by a chemical reaction. As an example, when a fuel is burned the chemical energy is converted to heat, same is the case with digestion of food metabolized in a biological organism. Green plants transform solar energy to chemical energy through the process known as photosynthesis, and electrical energy can be converted to chemical energy through electrochemical reactions.\nThe similar term chemical potential is used to indicate the potential of a substance to undergo a change of configuration, be it in the form of a chemical reaction, spatial transport, particle exchange with a reservoir, etc.\n\n\n== Electric potential energy ==\n\nAn object can have potential energy by virtue of its electric charge and several forces related to their presence. There are two main types of this kind of potential energy: electrostatic potential energy, electrodynamic potential energy (also sometimes called magnetic potential energy).\n\n\n=== Electrostatic potential energy ===\nElectrostatic potential energy between two bodies in space is obtained from the force exerted by a charge Q on another charge q which is given by\n\nwhere \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} }\n   is a vector of length 1 pointing from Q to q and \u03b50 is the vacuum permittivity.\nIf the electric charge of an object can be assumed to be at rest, then it has potential energy due to its position relative to other charged objects.  The electrostatic potential energy is the energy of an electrically charged particle (at rest) in an electric field. It is defined as the work that must be done to move it from an infinite distance away to its present location, adjusted for non-electrical forces on the object. This energy will generally be non-zero if there is another electrically charged object nearby.\nThe work W required to move q from A to any point B in the electrostatic force field is given by\n\ntypically given in J for Joules. A related quantity called electric potential (commonly denoted with a V for voltage) is equal to the electric potential energy per unit charge.\n\n\n=== Magnetic potential energy ===\nThe energy of a magnetic moment \n  \n    \n      \n        \n          \u03bc\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\mu }}}\n   in an externally produced magnetic B-field B has potential energy\nThe magnetization M in a field is\n\nwhere the integral can be over all space or, equivalently, where M is nonzero.\nMagnetic potential energy is the form of energy related not only to the distance between magnetic materials, but also to the orientation, or alignment, of those materials within the field. For example, the needle of a compass has the lowest magnetic potential energy when it is aligned with the north and south poles of the Earth's magnetic field. If the needle is moved by an outside force, torque is exerted on the magnetic dipole of the needle by the Earth's magnetic field, causing it to move back into alignment. The magnetic potential energy of the needle is highest when its field is in the same direction as the Earth's magnetic field. Two magnets will have potential energy in relation to each other and the distance between them, but this also depends on their orientation. If the opposite poles are held apart, the potential energy will be higher the further they are apart and lower the closer they are. Conversely, like poles will have the highest potential energy when forced together, and the lowest when they spring apart.\n\n\n== Nuclear potential energy ==\nNuclear potential energy is the potential energy of the particles inside an atomic nucleus. The nuclear particles are bound together by the strong nuclear force. Weak nuclear forces provide the potential energy for certain kinds of radioactive decay, such as beta decay.\nNuclear particles like protons and neutrons are not destroyed in fission and fusion processes, but collections of them can have less mass than if they were individually free, in which case this mass difference can be liberated as heat and radiation in nuclear reactions (the heat and radiation have the missing mass, but it often escapes from the system, where it is not measured). The energy from the Sun is an example of this form of energy conversion. In the Sun, the process of hydrogen fusion converts about 4 million tonnes of solar matter per second into electromagnetic energy, which is radiated into space.\n\n\n== Forces and potential energy ==\nPotential energy is closely linked with forces. If the work done by a force on a body that moves from A to B does not depend on the path between these points, then the work of this force measured from A assigns a scalar value to every other point in space and defines a scalar potential field. In this case, the force can be defined as the negative of the vector gradient of the potential field.\nFor example, gravity is a conservative force. The associated potential is the gravitational potential, often denoted by \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   or \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  , corresponding to the energy per unit mass as a function of position. The gravitational potential energy of two particles of mass M and m separated by a distance r is\n\nThe gravitational potential (specific energy) of the two bodies is\n\nwhere \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the reduced mass.\nThe work done against gravity by moving an infinitesimal mass from point A with \n  \n    \n      \n        U\n        =\n        a\n      \n    \n    {\\displaystyle U=a}\n   to point B with \n  \n    \n      \n        U\n        =\n        b\n      \n    \n    {\\displaystyle U=b}\n   is \n  \n    \n      \n        (\n        b\n        \u2212\n        a\n        )\n      \n    \n    {\\displaystyle (b-a)}\n   and the work done going back the other way is \n  \n    \n      \n        (\n        a\n        \u2212\n        b\n        )\n      \n    \n    {\\displaystyle (a-b)}\n   so that the total work done in moving from A to B and returning to A is\n\nIf the potential is redefined at A to be \n  \n    \n      \n        a\n        +\n        c\n      \n    \n    {\\displaystyle a+c}\n   and the potential at B to be \n  \n    \n      \n        b\n        +\n        c\n      \n    \n    {\\displaystyle b+c}\n  , where \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is a constant (i.e. \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   can be any number, positive or negative, but it must be the same at A as it is at B) then the work done going from A to B is\n\nas before.\nIn practical terms, this means that one can set the zero of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n   and \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   anywhere one likes. One may set it to be zero at the surface of the Earth, or may find it more convenient to set zero at infinity (as in the expressions given earlier in this section).\nA conservative force can be expressed in the language of differential geometry as a closed form. As Euclidean space is contractible, its de Rham cohomology vanishes, so every closed form is also an exact form, and can be expressed as the gradient of a scalar field. This gives a mathematical justification of the fact that all conservative forces are gradients of a potential field.\n\n\n== Notes ==\n\n\n== References ==\nSerway, Raymond A.; Jewett, John W. (2010). Physics for Scientists and Engineers (8th ed.). Brooks/Cole cengage. ISBN 978-1-4390-4844-3.\nTipler, Paul (2004). Physics for Scientists and Engineers: Mechanics, Oscillations and Waves, Thermodynamics (5th ed.). W. H. Freeman. ISBN 0-7167-0809-4.\n\n\n== External links ==\nWhat is potential energy?", "Refractive_index": "In optics, the refractive index (or refraction index) of an optical medium is a dimensionless number that gives the indication of the light bending ability of that medium.\n\nThe refractive index determines how much the path of light is bent, or refracted, when entering a material. This is described by Snell's law of refraction, n1 sin \u03b81 = n2 sin \u03b82, where \u03b81 and \u03b82 are the angle of incidence and angle of refraction, respectively, of a ray crossing the interface between two media with refractive indices n1 and n2. The refractive indices also determine the amount of light that is reflected when reaching the interface, as well as the critical angle for total internal reflection, their intensity (Fresnel's equations) and Brewster's angle.The refractive index can be seen as the factor by which the speed and the wavelength of the radiation are reduced with respect to their vacuum values: the speed of light in a medium is v = c/n, and similarly the wavelength in that medium is \u03bb = \u03bb0/n, where \u03bb0 is the wavelength of that light in vacuum. This implies that vacuum has a refractive index of 1, and assumes that the frequency (f = v/\u03bb) of the wave is not affected by the refractive index.\nThe refractive index may vary with wavelength. This causes white light to split into constituent colors when refracted. This is called dispersion. This effect can be observed in prisms and rainbows, and as chromatic aberration in lenses. Light propagation in absorbing materials can be described using a complex-valued refractive index. The imaginary part then handles the attenuation, while the real part accounts for refraction. For most materials the refractive index changes with wavelength by several percent across the visible spectrum. Nevertheless, refractive indices for materials are commonly reported using a single value for n, typically measured at 633 nm.\nThe concept of refractive index applies across the full electromagnetic spectrum, from X-rays to radio waves. It can also be applied to wave phenomena such as sound. In this case, the speed of sound is used instead of that of light, and a reference medium other than vacuum must be chosen.For lenses (such as eye glasses), a lens made from a high refractive index material will be thinner, and hence lighter, than a conventional lens with a lower refractive index.  Such lenses are generally more expensive to manufacture than conventional ones.\n\n\n== Definition ==\nThe relative refractive index of an optical medium 2 with respect to another reference medium 1 (n21) is given by the ratio of speed of light in medium 1 to that in medium 2. This can be expressed as follows:\n\n  \n    \n      \n        \n          n\n          \n            21\n          \n        \n        =\n        \n          \n            \n              v\n              \n                1\n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle n_{21}={\\frac {v_{1}}{v_{2}}}.}\n  If the reference medium 1 is vacuum, then the refractive index of medium 2 is considered with respect to vacuum. It is simply represented as n2 and is called the absolute refractive index of medium 2.\nThe absolute refractive index n of an optical medium is defined as the ratio of the speed of light in vacuum, c = 299792458 m/s, and the phase velocity v of light in the medium,\n\n  \n    \n      \n        n\n        =\n        \n          \n            c\n            v\n          \n        \n        .\n      \n    \n    {\\displaystyle n={\\frac {c}{v}}.}\n  Since c is constant, n is inversely proportional to v :\n\n  \n    \n      \n        n\n        \u221d\n        \n          \n            1\n            v\n          \n        \n        .\n      \n    \n    {\\displaystyle n\\propto {\\frac {1}{v}}.}\n  The phase velocity is the speed at which the crests or the phase of the wave moves, which may be different from the group velocity, the speed at which the pulse of light or the envelope of the wave moves. Historically air at a standardized pressure and temperature has been common as a reference medium.\n\n\n== History ==\n\nThomas Young was presumably the person who first used, and invented, the name \"index of refraction\", in 1807.\nAt the same time he changed this value of refractive power into a single number, instead of the traditional ratio of two numbers. The ratio had the disadvantage of different appearances. Newton, who called it the \"proportion of the sines of incidence and refraction\", wrote it as a ratio of two numbers, like \"529 to 396\" (or \"nearly 4 to 3\"; for water).  Hauksbee, who called it the \"ratio of refraction\", wrote it as a ratio with a fixed numerator, like \"10000 to 7451.9\" (for urine).  Hutton wrote it as a ratio with a fixed denominator, like 1.3358 to 1 (water).Young did not use a symbol for the index of refraction, in 1807. In the later years, others started using different symbols:\nn, m, and \u00b5. The symbol n gradually prevailed.\n\n\n== Typical values ==\n\nRefractive index also varies with wavelength of the light as given by Cauchy's equation:\nThe most general form of Cauchy's equation is\n\nwhere n is the refractive index, \u03bb is the wavelength, A, B, C, etc.,  are coefficients that can be determined for a material by fitting the equation to measured refractive indices at known wavelengths. The coefficients are usually quoted for \u03bb as the vacuum wavelength in micrometres.\nUsually, it is sufficient to use a two-term form of the equation:\n\nwhere the coefficients A and B are determined specifically for this form of the equation.\n\nFor visible light most transparent media have refractive indices between 1 and 2. A few examples are given in the adjacent table. These values are measured at the yellow doublet D-line of sodium, with a wavelength of 589 nanometers, as is conventionally done. Gases at atmospheric pressure have refractive indices close to 1 because of their low density. Almost all solids and liquids have refractive indices above 1.3, with aerogel as the clear exception. Aerogel is a very low density solid that can be produced with refractive index in the range from 1.002 to 1.265. Moissanite lies at the other end of the range with a refractive index as high as 2.65. Most plastics have refractive indices in the range from 1.3 to 1.7, but some high-refractive-index polymers can have values as high as 1.76.For infrared light refractive indices can be considerably higher. Germanium is transparent in the wavelength region from 2 to 14 \u00b5m and has a refractive index of about 4. A type of new materials termed \"topological insulators\", was recently found which have high refractive index of up to 6 in the near to mid infrared frequency range. Moreover, topological insulators are transparent when they have nanoscale thickness. These properties are potentially important for applications in infrared optics.\n\n\n=== Refractive index below unity ===\nAccording to the theory of relativity, no information can travel faster than the speed of light in vacuum, but this does not mean that the refractive index cannot be less than 1. The refractive index measures the phase velocity of light, which does not carry information. The phase velocity is the speed at which the crests of the wave move and can be faster than the speed of light in vacuum, and thereby give a refractive index below 1. This can occur close to resonance frequencies, for absorbing media, in plasmas, and for X-rays. In the X-ray regime the refractive indices are lower than but very close to 1 (exceptions close to some resonance frequencies).\nAs an example, water has a refractive index of 0.99999974 = 1 \u2212 2.6\u00d710\u22127 for X-ray radiation at a photon energy of 30 keV (0.04 nm wavelength).An example of a plasma with an index of refraction less than unity is Earth's ionosphere.  Since the refractive index of the ionosphere (a plasma), is less than unity, electromagnetic waves propagating through the plasma are bent \"away from the normal\" (see Geometric optics) allowing the radio wave to be refracted back toward earth, thus enabling long-distance radio communications.  See also Radio Propagation and Skywave.\n\n\n=== Negative refractive index ===\n\nRecent research has also demonstrated the existence of materials with a negative refractive index, which can occur if permittivity and permeability have simultaneous negative values. This can be achieved with periodically constructed metamaterials. The resulting negative refraction (i.e., a reversal of Snell's law) offers the possibility of the superlens and other new phenomena to be actively developed by means of metamaterials.\n\n\n== Microscopic explanation ==\n\nAt the atomic scale, an electromagnetic wave's phase velocity is slowed in a material because the electric field creates a disturbance in the charges of each atom (primarily the electrons) proportional to the electric susceptibility of the medium. (Similarly, the magnetic field creates a disturbance proportional to the magnetic susceptibility.) As the electromagnetic fields oscillate in the wave, the charges in the material will be \"shaken\" back and forth at the same frequency.:\u200a67\u200a The charges thus radiate their own electromagnetic wave that is at the same frequency, but usually with a phase delay, as the charges may move out of phase with the force driving them (see sinusoidally driven harmonic oscillator). The light wave traveling in the medium is the macroscopic superposition (sum) of all such contributions in the material: the original wave plus the waves radiated by all the moving charges. This wave is typically a wave with the same frequency but shorter wavelength than the original, leading to a slowing of the wave's phase velocity. Most of the radiation from oscillating material charges will modify the incoming wave, changing its velocity. However, some net energy will be radiated in other directions or even at other frequencies (see scattering).\nDepending on the relative phase of the original driving wave and the waves radiated by the charge motion, there are several possibilities:\n\nIf the electrons emit a light wave which is 90\u00b0 out of phase with the light wave shaking them, it will cause the total light wave to travel slower. This is the normal refraction of transparent materials like glass or water, and corresponds to a refractive index which is real and greater than 1.\nIf the electrons emit a light wave which is 270\u00b0 out of phase with the light wave shaking them, it will cause the wave to travel faster. This is called \"anomalous refraction\", and is observed close to absorption lines (typically in infrared spectra), with X-rays in ordinary materials, and with radio waves in Earth's ionosphere. It corresponds to a permittivity less than 1, which causes the refractive index to be also less than unity and the phase velocity of light greater than the speed of light in vacuum c (note that the signal velocity is still less than c, as discussed above). If the response is sufficiently strong and out-of-phase, the result is a negative value of permittivity and imaginary index of refraction, as observed in metals or plasma.\nIf the electrons emit a light wave which is 180\u00b0 out of phase with the light wave shaking them, it will destructively interfere with the original light to reduce the total light intensity. This is light absorption in opaque materials and corresponds to an imaginary refractive index.\nIf the electrons emit a light wave which is in phase with the light wave shaking them, it will amplify the light wave. This is rare, but occurs in lasers due to stimulated emission. It corresponds to an imaginary index of refraction, with the opposite sign to that of absorption.For most materials at visible-light frequencies, the phase is somewhere between 90\u00b0 and 180\u00b0, corresponding to a combination of both refraction and absorption.\n\n\n== Dispersion ==\n\nThe refractive index of materials varies with the wavelength (and frequency) of light. This is called dispersion and causes prisms and rainbows to divide white light into its constituent spectral colors. As the refractive index varies with wavelength, so will the refraction angle as light goes from one material to another. Dispersion also causes the focal length of lenses to be wavelength dependent. This is a type of chromatic aberration, which often needs to be corrected for in imaging systems. In regions of the spectrum where the material does not absorb light, the refractive index tends to decrease with increasing wavelength, and thus increase with frequency. This is called \"normal dispersion\", in contrast to \"anomalous dispersion\", where the refractive index increases with wavelength. For visible light normal dispersion means that the refractive index is higher for blue light than for red.\nFor optics in the visual range, the amount of dispersion of a lens material is often quantified by the Abbe number:\n\n  \n    \n      \n        V\n        =\n        \n          \n            \n              \n                n\n                \n                  \n                    y\n                    e\n                    l\n                    l\n                    o\n                    w\n                  \n                \n              \n              \u2212\n              1\n            \n            \n              \n                n\n                \n                  \n                    b\n                    l\n                    u\n                    e\n                  \n                \n              \n              \u2212\n              \n                n\n                \n                  \n                    r\n                    e\n                    d\n                  \n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle V={\\frac {n_{\\mathrm {yellow} }-1}{n_{\\mathrm {blue} }-n_{\\mathrm {red} }}}.}\n  For a more accurate description of the wavelength dependence of the refractive index, the Sellmeier equation can be used. It is an empirical formula that works well in describing dispersion. Sellmeier coefficients are often quoted instead of the refractive index in tables.\n\n\n=== Principal refractive index wavelength ambiguity ===\nBecause of dispersion, it is usually important to specify the vacuum wavelength of light for which a refractive index is measured. Typically, measurements are done at various well-defined spectral emission lines.\nManufacturers of optical glass in general define principal index of refraction at yellow spectral line of helium (587.56 nm) and alternatively at a green spectral line of mercury (546.07 nm), called d and e lines respectively. Abbe number is defined for both and denoted Vd and Ve. The spectral data provided by glass manufacturers is also often more precise for these 2 wavelengths.Both, d and e spectral lines are singlets and thus are suitable to perform a very precise measurements, such as spectral goniometric method.In practical applications, measurements of refractive index are performed on various refractometers, such as Abbe refractometer. Measurement accuracy of such typical commercial devices is in the order of 0.0002. Refractometers usually measure refractive index nD, defined for sodium doublet D (589.29 nm), which is actually a midpoint between 2 adjacent yellow spectral lines of sodium. Yellow spectral lines of helium (d) and sodium (D) are 1.73 nm apart, which can be considered negligible for typical refractometers, but can cause confusion and lead to errors if accuracy is critical.\nAll 3 typical principle refractive indices definitions can be found depending on application and region, so a proper subscript should be used to avoid ambiguity.\n\n\n== Complex refractive index ==\n\nWhen light passes through a medium, some part of it will always be absorbed. This can be conveniently taken into account by defining a complex refractive index,\n\n  \n    \n      \n        \n          \n            n\n            _\n          \n        \n        =\n        n\n        +\n        i\n        \u03ba\n        .\n      \n    \n    {\\displaystyle {\\underline {n}}=n+i\\kappa .}\n  Here, the real part n is the refractive index and indicates the phase velocity, while the imaginary part \u03ba is called the optical extinction coefficient or absorption coefficient\u2014although \u03ba can also refer to the mass attenuation coefficient:\u200a3\u200a\u2014and indicates the amount of attenuation when the electromagnetic wave propagates through the material.:\u200a128\u200aThat \u03ba corresponds to absorption can be seen by inserting this refractive index into the expression for electric field of a plane electromagnetic wave traveling in the x-direction. This can be done by relating the complex wave number k to the complex refractive index n through k = 2\u03c0n/\u03bb0, with \u03bb0 being the vacuum wavelength; this can be inserted into the plane wave expression for a wave travelling in the x direction as:\n\n  \n    \n      \n        \n          E\n        \n        (\n        s\n        ,\n        t\n        )\n        =\n        Re\n        \n        \n          [\n          \n            \n              \n                E\n              \n              \n                0\n              \n            \n            \n              e\n              \n                i\n                (\n                \n                  \n                    k\n                    _\n                  \n                \n                x\n                \u2212\n                \u03c9\n                t\n                )\n              \n            \n          \n          ]\n        \n        =\n        Re\n        \n        \n          [\n          \n            \n              \n                E\n              \n              \n                0\n              \n            \n            \n              e\n              \n                i\n                (\n                2\n                \u03c0\n                (\n                n\n                +\n                i\n                \u03ba\n                )\n                x\n                \n                  /\n                \n                \n                  \u03bb\n                  \n                    0\n                  \n                \n                \u2212\n                \u03c9\n                t\n                )\n              \n            \n          \n          ]\n        \n        =\n        \n          e\n          \n            \u2212\n            2\n            \u03c0\n            \u03ba\n            x\n            \n              /\n            \n            \n              \u03bb\n              \n                0\n              \n            \n          \n        \n        Re\n        \n        \n          [\n          \n            \n              \n                E\n              \n              \n                0\n              \n            \n            \n              e\n              \n                i\n                (\n                k\n                x\n                \u2212\n                \u03c9\n                t\n                )\n              \n            \n          \n          ]\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {E} (s,t)=\\operatorname {Re} \\!\\left[\\mathbf {E} _{0}e^{i({\\underline {k}}x-\\omega t)}\\right]=\\operatorname {Re} \\!\\left[\\mathbf {E} _{0}e^{i(2\\pi (n+i\\kappa )x/\\lambda _{0}-\\omega t)}\\right]=e^{-2\\pi \\kappa x/\\lambda _{0}}\\operatorname {Re} \\!\\left[\\mathbf {E} _{0}e^{i(kx-\\omega t)}\\right].}\n  Here we see that \u03ba gives an exponential decay, as expected from the Beer\u2013Lambert law. Since intensity is proportional to the square of the electric field, intensity will depend on the depth into the material as\n\n  \n    \n      \n        I\n        (\n        x\n        )\n        =\n        \n          I\n          \n            0\n          \n        \n        \n          e\n          \n            \u2212\n            4\n            \u03c0\n            \u03ba\n            x\n            \n              /\n            \n            \n              \u03bb\n              \n                0\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle I(x)=I_{0}e^{-4\\pi \\kappa x/\\lambda _{0}}.}\n  and thus the absorption coefficient is \u03b1 = 4\u03c0\u03ba/\u03bb0,:\u200a128\u200a and the penetration depth (the distance after which the intensity is reduced by a factor of 1/e) is \u03b4p = 1/\u03b1 = \u03bb0/4\u03c0\u03ba.\nBoth n and \u03ba are dependent on the frequency. In most circumstances \u03ba > 0 (light is absorbed) or \u03ba = 0 (light travels forever without loss). In special situations, especially in the gain medium of lasers, it is also possible that \u03ba < 0, corresponding to an amplification of the light.\nAn alternative convention uses n = n + i\u03ba instead of n = n \u2212 i\u03ba, but where \u03ba > 0 still corresponds to loss. Therefore, these two conventions are inconsistent and should not be confused. The difference is related to defining sinusoidal time dependence as Re[exp(\u2212i\u03c9t)] versus Re[exp(+i\u03c9t)]. See Mathematical descriptions of opacity.\nDielectric loss and non-zero DC conductivity in materials cause absorption. Good dielectric materials such as glass have extremely low DC conductivity, and at low frequencies the dielectric loss is also negligible, resulting in almost no absorption. However, at higher frequencies (such as visible light), dielectric loss may increase absorption significantly, reducing the material's transparency to these frequencies.\nThe real, n, and imaginary, \u03ba, parts of the complex refractive index are related through the Kramers\u2013Kronig relations. In 1986 A.R. Forouhi and I. Bloomer deduced an equation describing \u03ba as a function of photon energy, E, applicable to amorphous materials. Forouhi and Bloomer then applied the Kramers\u2013Kronig relation to derive the corresponding equation for n as a function of E. The same formalism was applied to crystalline materials by Forouhi and Bloomer in 1988.\nThe refractive index and extinction coefficient, n and \u03ba, are typically measured from quantities that depend on them, such as reflectance, R, or transmittance, T, or ellipsometric parameters, \u03c8 and \u03b4. The determination of n and \u03ba from such measured quantities will involve developing a theoretical expression for R or T, or \u03c8 and \u03b4 in terms of a valid physical model for n and \u03ba. By fitting the theoretical model to the measured R or T, or \u03c8 and \u03b4 using regression analysis, n and \u03ba can be deduced.\n\n\n=== X-ray and extreme UV ===\nFor X-ray and extreme ultraviolet radiation the complex refractive index deviates only slightly from unity and usually has a real part smaller than 1. It is therefore normally written as n = 1 \u2212 \u03b4 + i\u03b2 (or n = 1 \u2212 \u03b4 \u2212 i\u03b2 with the alternative convention mentioned above). Far above the atomic resonance frequency delta can be given by\n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                r\n                \n                  0\n                \n              \n              \n                \u03bb\n                \n                  2\n                \n              \n              \n                n\n                \n                  e\n                \n              \n            \n            \n              2\n              \u03c0\n            \n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\frac {r_{0}\\lambda ^{2}n_{e}}{2\\pi }}}\n  where \n  \n    \n      \n        \n          r\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle r_{0}}\n   is the classical electron radius, \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is the X-ray wavelength, and \n  \n    \n      \n        \n          n\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle n_{e}}\n   is the electron density. One may assume the electron density is simply the number of electrons per atom Z multiplied by the atomic density, but more accurate calculation of the refractive index requires replacing Z with the complex atomic form factor \n  \n    \n      \n        f\n        =\n        Z\n        +\n        \n          f\n          \u2032\n        \n        +\n        i\n        \n          f\n          \u2033\n        \n      \n    \n    {\\displaystyle f=Z+f'+if''}\n  . It follows that\n\n  \n    \n      \n        \u03b4\n        =\n        \n          \n            \n              \n                r\n                \n                  0\n                \n              \n              \n                \u03bb\n                \n                  2\n                \n              \n            \n            \n              2\n              \u03c0\n            \n          \n        \n        (\n        Z\n        +\n        \n          f\n          \u2032\n        \n        )\n        \n          n\n          \n            atom\n          \n        \n      \n    \n    {\\displaystyle \\delta ={\\frac {r_{0}\\lambda ^{2}}{2\\pi }}(Z+f')n_{\\text{atom}}}\n  \n\n  \n    \n      \n        \u03b2\n        =\n        \n          \n            \n              \n                r\n                \n                  0\n                \n              \n              \n                \u03bb\n                \n                  2\n                \n              \n            \n            \n              2\n              \u03c0\n            \n          \n        \n        \n          f\n          \u2033\n        \n        \n          n\n          \n            atom\n          \n        \n      \n    \n    {\\displaystyle \\beta ={\\frac {r_{0}\\lambda ^{2}}{2\\pi }}f''n_{\\text{atom}}}\n  with \n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   and \n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   typically of the order of 10\u22125 and 10\u22126.\n\n\n== Relations to other quantities ==\n\n\n=== Optical path length ===\n\nOptical path length (OPL) is the product of the geometric length d of the path light follows through a system, and the index of refraction of the medium through which it propagates,\n\n  \n    \n      \n        \n          OPL\n        \n        =\n        n\n        d\n        .\n      \n    \n    {\\displaystyle {\\text{OPL}}=nd.}\n  This is an important concept in optics because it determines the phase of the light and governs interference and diffraction of light as it propagates. According to Fermat's principle, light rays can be characterized as those curves that optimize the optical path length.:\u200a68\u201369\u200a\n\n\n=== Refraction ===\n\nWhen light moves from one medium to another, it changes direction, i.e. it is refracted. If it moves from a medium with refractive index n1 to one with refractive index n2, with an incidence angle to the surface normal of \u03b81, the refraction angle \u03b82 can be calculated from Snell's law:\n\n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle n_{1}\\sin \\theta _{1}=n_{2}\\sin \\theta _{2}.}\n  When light enters a material with higher refractive index, the angle of refraction will be smaller than the angle of incidence and the light will be refracted towards the normal of the surface. The higher the refractive index, the closer to the normal direction the light will travel. When passing into a medium with lower refractive index, the light will instead be refracted away from the normal, towards the surface.\n\n\n=== Total internal reflection ===\n\nIf there is no angle \u03b82 fulfilling Snell's law, i.e.,\n\n  \n    \n      \n        \n          \n            \n              n\n              \n                1\n              \n            \n            \n              n\n              \n                2\n              \n            \n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        >\n        1\n        ,\n      \n    \n    {\\displaystyle {\\frac {n_{1}}{n_{2}}}\\sin \\theta _{1}>1,}\n  the light cannot be transmitted and will instead undergo total internal reflection.:\u200a49\u201350\u200a This occurs only when going to a less optically dense material, i.e., one with lower refractive index. To get total internal reflection the angles of incidence \u03b81 must be larger than the critical angle\n\n  \n    \n      \n        \n          \u03b8\n          \n            \n              c\n            \n          \n        \n        =\n        arcsin\n        \n        \n          (\n          \n            \n              \n                n\n                \n                  2\n                \n              \n              \n                n\n                \n                  1\n                \n              \n            \n          \n          )\n        \n        \n        .\n      \n    \n    {\\displaystyle \\theta _{\\mathrm {c} }=\\arcsin \\!\\left({\\frac {n_{2}}{n_{1}}}\\right)\\!.}\n  \n\n\n=== Reflectivity ===\nApart from the transmitted light there is also a reflected part. The reflection angle is equal to the incidence angle, and the amount of light that is reflected is determined by the reflectivity of the surface. The reflectivity can be calculated from the refractive index and the incidence angle with the Fresnel equations, which for normal incidence reduces to:\u200a44\u200a\n\n  \n    \n      \n        \n          R\n          \n            0\n          \n        \n        =\n        \n          \n            |\n            \n              \n                \n                  \n                    n\n                    \n                      1\n                    \n                  \n                  \u2212\n                  \n                    n\n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    n\n                    \n                      1\n                    \n                  \n                  +\n                  \n                    n\n                    \n                      2\n                    \n                  \n                \n              \n            \n            |\n          \n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle R_{0}=\\left|{\\frac {n_{1}-n_{2}}{n_{1}+n_{2}}}\\right|^{2}\\!.}\n  For common glass in air, n1 = 1 and n2 = 1.5, and thus about 4% of the incident power is reflected. At other incidence angles the reflectivity will also depend on the polarization of the incoming light. At a certain angle called Brewster's angle, p-polarized light (light with the electric field in the plane of incidence) will be totally transmitted. Brewster's angle can be calculated from the two refractive indices of the interface as :\u200a245\u200a\n\n  \n    \n      \n        \n          \u03b8\n          \n            \n              B\n            \n          \n        \n        =\n        arctan\n        \n        \n          (\n          \n            \n              \n                n\n                \n                  2\n                \n              \n              \n                n\n                \n                  1\n                \n              \n            \n          \n          )\n        \n        \n        .\n      \n    \n    {\\displaystyle \\theta _{\\mathrm {B} }=\\arctan \\!\\left({\\frac {n_{2}}{n_{1}}}\\right)\\!.}\n  \n\n\n=== Lenses ===\n\nThe focal length of a lens is determined by its refractive index n and the radii of curvature R1 and R2 of its surfaces. The power of a thin lens in air is given by the Lensmaker's formula:\n\n  \n    \n      \n        \n          \n            1\n            f\n          \n        \n        =\n        (\n        n\n        \u2212\n        1\n        )\n        \n        \n          (\n          \n            \n              \n                1\n                \n                  R\n                  \n                    1\n                  \n                \n              \n            \n            \u2212\n            \n              \n                1\n                \n                  R\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{f}}=(n-1)\\!\\left({\\frac {1}{R_{1}}}-{\\frac {1}{R_{2}}}\\right)\\!,}\n  where f is the focal length of the lens.\n\n\n=== Microscope resolution ===\nThe resolution of a good optical microscope is mainly determined by the numerical aperture (NA) of its objective lens. The numerical aperture in turn is determined by the refractive index n of the medium filling the space between the sample and the lens and the half collection angle of light \u03b8 according to:\u200a6\u200a\n\n  \n    \n      \n        \n          N\n          A\n        \n        =\n        n\n        sin\n        \u2061\n        \u03b8\n        .\n      \n    \n    {\\displaystyle \\mathrm {NA} =n\\sin \\theta .}\n  For this reason oil immersion is commonly used to obtain high resolution in microscopy. In this technique the objective is dipped into a drop of high refractive index immersion oil on the sample under study.:\u200a14\u200a\n\n\n=== Relative permittivity and permeability ===\nThe refractive index of electromagnetic radiation equals\n\n  \n    \n      \n        n\n        =\n        \n          \n            \n              \u03b5\n              \n                \n                  r\n                \n              \n            \n            \n              \u03bc\n              \n                \n                  r\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle n={\\sqrt {\\varepsilon _{\\mathrm {r} }\\mu _{\\mathrm {r} }}},}\n  where \u03b5r is the material's relative permittivity, and \u03bcr is its relative permeability.:\u200a229\u200a The refractive index is used for optics in Fresnel equations and Snell's law; while the relative permittivity and permeability are used in Maxwell's equations and electronics. Most naturally occurring materials are non-magnetic at optical frequencies, that is \u03bcr is very close to 1, therefore n is approximately \u221a\u03b5r. In this particular case, the complex relative permittivity \u03b5r, with real and imaginary parts \u03b5r and \u025b\u0303r, and the complex refractive index n, with real and imaginary parts n and \u03ba (the latter called the \"extinction coefficient\"), follow the relation\n\n  \n    \n      \n        \n          \n            \n              \u03b5\n              _\n            \n          \n          \n            \n              r\n            \n          \n        \n        =\n        \n          \u03b5\n          \n            \n              r\n            \n          \n        \n        +\n        i\n        \n          \n            \n              \n                \u03b5\n                ~\n              \n            \n          \n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            \n              n\n              _\n            \n          \n          \n            2\n          \n        \n        =\n        (\n        n\n        +\n        i\n        \u03ba\n        \n          )\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\underline {\\varepsilon }}_{\\mathrm {r} }=\\varepsilon _{\\mathrm {r} }+i{\\tilde {\\varepsilon }}_{\\mathrm {r} }={\\underline {n}}^{2}=(n+i\\kappa )^{2},}\n  and their components are related by:\n\n  \n    \n      \n        \n          \u03b5\n          \n            \n              r\n            \n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        \u2212\n        \n          \u03ba\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\varepsilon _{\\mathrm {r} }=n^{2}-\\kappa ^{2},}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \u03b5\n                ~\n              \n            \n          \n          \n            \n              r\n            \n          \n        \n        =\n        2\n        n\n        \u03ba\n        ,\n      \n    \n    {\\displaystyle {\\tilde {\\varepsilon }}_{\\mathrm {r} }=2n\\kappa ,}\n  and:\n\n  \n    \n      \n        n\n        =\n        \n          \n            \n              \n                \n                  |\n                \n                \n                  \n                    \n                      \u03b5\n                      _\n                    \n                  \n                  \n                    \n                      r\n                    \n                  \n                \n                \n                  |\n                \n                +\n                \n                  \u03b5\n                  \n                    \n                      r\n                    \n                  \n                \n              \n              2\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle n={\\sqrt {\\frac {|{\\underline {\\varepsilon }}_{\\mathrm {r} }|+\\varepsilon _{\\mathrm {r} }}{2}}},}\n  \n\n  \n    \n      \n        \u03ba\n        =\n        \n          \n            \n              \n                \n                  |\n                \n                \n                  \n                    \n                      \u03b5\n                      _\n                    \n                  \n                  \n                    \n                      r\n                    \n                  \n                \n                \n                  |\n                \n                \u2212\n                \n                  \u03b5\n                  \n                    \n                      r\n                    \n                  \n                \n              \n              2\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\kappa ={\\sqrt {\\frac {|{\\underline {\\varepsilon }}_{\\mathrm {r} }|-\\varepsilon _{\\mathrm {r} }}{2}}}.}\n  where \n  \n    \n      \n        \n          |\n        \n        \n          \n            \n              \u03b5\n              _\n            \n          \n          \n            \n              r\n            \n          \n        \n        \n          |\n        \n        =\n        \n          \n            \n              \u03b5\n              \n                \n                  r\n                \n              \n              \n                2\n              \n            \n            +\n            \n              \n                \n                  \n                    \u03b5\n                    ~\n                  \n                \n              \n              \n                \n                  r\n                \n              \n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle |{\\underline {\\varepsilon }}_{\\mathrm {r} }|={\\sqrt {\\varepsilon _{\\mathrm {r} }^{2}+{\\tilde {\\varepsilon }}_{\\mathrm {r} }^{2}}}}\n   is the complex modulus.\n\n\n=== Wave impedance ===\n\nThe wave impedance of a plane electromagnetic wave in a non-conductive medium is given by\n\n  \n    \n      \n        Z\n        =\n        \n          \n            \n              \u03bc\n              \u03b5\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \u03bc\n                  \n                    \n                      0\n                    \n                  \n                \n                \n                  \u03bc\n                  \n                    \n                      r\n                    \n                  \n                \n              \n              \n                \n                  \u03b5\n                  \n                    \n                      0\n                    \n                  \n                \n                \n                  \u03b5\n                  \n                    \n                      r\n                    \n                  \n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  \n                    0\n                  \n                \n              \n              \n                \u03b5\n                \n                  \n                    0\n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              \n                \u03bc\n                \n                  \n                    r\n                  \n                \n              \n              \n                \u03b5\n                \n                  \n                    r\n                  \n                \n              \n            \n          \n        \n        =\n        \n          Z\n          \n            0\n          \n        \n        \n          \n            \n              \n                \u03bc\n                \n                  \n                    r\n                  \n                \n              \n              \n                \u03b5\n                \n                  \n                    r\n                  \n                \n              \n            \n          \n        \n        =\n        \n          Z\n          \n            0\n          \n        \n        \n          \n            \n              \u03bc\n              \n                \n                  r\n                \n              \n            \n            n\n          \n        \n      \n    \n    {\\displaystyle Z={\\sqrt {\\frac {\\mu }{\\varepsilon }}}={\\sqrt {\\frac {\\mu _{\\mathrm {0} }\\mu _{\\mathrm {r} }}{\\varepsilon _{\\mathrm {0} }\\varepsilon _{\\mathrm {r} }}}}={\\sqrt {\\frac {\\mu _{\\mathrm {0} }}{\\varepsilon _{\\mathrm {0} }}}}{\\sqrt {\\frac {\\mu _{\\mathrm {r} }}{\\varepsilon _{\\mathrm {r} }}}}=Z_{0}{\\sqrt {\\frac {\\mu _{\\mathrm {r} }}{\\varepsilon _{\\mathrm {r} }}}}=Z_{0}{\\frac {\\mu _{\\mathrm {r} }}{n}}}\n  where \n  \n    \n      \n        \n          Z\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle Z_{0}}\n   is the vacuum wave impedance, \u03bc and \u03f5 are the absolute permeability and permittivity of the medium, \u03b5r is the material's relative permittivity, and \u03bcr is its relative permeability.\nIn non-magnetic media with \n  \n    \n      \n        \n          \u03bc\n          \n            \n              r\n            \n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle \\mu _{\\mathrm {r} }=1}\n  ,\n\n  \n    \n      \n        Z\n        =\n        \n          \n            \n              Z\n              \n                0\n              \n            \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle Z={\\frac {Z_{0}}{n}},}\n  \n  \n    \n      \n        n\n        =\n        \n          \n            \n              Z\n              \n                0\n              \n            \n            Z\n          \n        \n        .\n      \n    \n    {\\displaystyle n={\\frac {Z_{0}}{Z}}.}\n  Thus refractive index in a non-magnetic media is the ratio of the vacuum wave impedance to the wave impedance of the medium.\nThe reflectivity \n  \n    \n      \n        \n          R\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle R_{0}}\n   between two media can thus be expressed both by the wave impedances and the refractive indices as\n\n  \n    \n      \n        \n          R\n          \n            0\n          \n        \n        =\n        \n          \n            |\n            \n              \n                \n                  \n                    n\n                    \n                      1\n                    \n                  \n                  \u2212\n                  \n                    n\n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    n\n                    \n                      1\n                    \n                  \n                  +\n                  \n                    n\n                    \n                      2\n                    \n                  \n                \n              \n            \n            |\n          \n          \n            2\n          \n        \n        \n        =\n        \n          \n            |\n            \n              \n                \n                  \n                    Z\n                    \n                      2\n                    \n                  \n                  \u2212\n                  \n                    Z\n                    \n                      1\n                    \n                  \n                \n                \n                  \n                    Z\n                    \n                      2\n                    \n                  \n                  +\n                  \n                    Z\n                    \n                      1\n                    \n                  \n                \n              \n            \n            |\n          \n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle R_{0}=\\left|{\\frac {n_{1}-n_{2}}{n_{1}+n_{2}}}\\right|^{2}\\!=\\left|{\\frac {Z_{2}-Z_{1}}{Z_{2}+Z_{1}}}\\right|^{2}\\!.}\n  \n\n\n=== Density ===\n\nIn general, the refractive index of a glass increases with its density. However, there does not exist an overall linear relationship between the refractive index and the density for all silicate and borosilicate glasses. A relatively high refractive index and low density can be obtained with glasses containing light metal oxides such as Li2O and MgO, while the opposite trend is observed with glasses containing PbO and BaO as seen in the diagram at the right.\nMany oils (such as olive oil) and ethanol are examples of liquids that are more refractive, but less dense, than water, contrary to the general correlation between density and refractive index.\nFor air, n \u2212 1 is proportional to the density of the gas as long as the chemical composition does not change. This means that it is also proportional to the pressure and inversely proportional to the temperature for ideal gases.\n\n\n=== Group index ===\nSometimes, a \"group velocity refractive index\", usually called the group index is defined:\n\n  \n    \n      \n        \n          n\n          \n            \n              g\n            \n          \n        \n        =\n        \n          \n            \n              c\n            \n            \n              v\n              \n                \n                  g\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle n_{\\mathrm {g} }={\\frac {\\mathrm {c} }{v_{\\mathrm {g} }}},}\n  where vg is the group velocity. This value should not be confused with n, which is always defined with respect to the phase velocity. When the dispersion is small, the group velocity can be linked to the phase velocity by the relation:\u200a22\u200a\n\n  \n    \n      \n        \n          v\n          \n            \n              g\n            \n          \n        \n        =\n        v\n        \u2212\n        \u03bb\n        \n          \n            \n              \n                d\n              \n              v\n            \n            \n              \n                d\n              \n              \u03bb\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle v_{\\mathrm {g} }=v-\\lambda {\\frac {\\mathrm {d} v}{\\mathrm {d} \\lambda }},}\n  where \u03bb is the wavelength in the medium. In this case the group index can thus be written in terms of the wavelength dependence of the refractive index as\n\n  \n    \n      \n        \n          n\n          \n            \n              g\n            \n          \n        \n        =\n        \n          \n            n\n            \n              1\n              +\n              \n                \n                  \u03bb\n                  n\n                \n              \n              \n                \n                  \n                    \n                      d\n                    \n                    n\n                  \n                  \n                    \n                      d\n                    \n                    \u03bb\n                  \n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle n_{\\mathrm {g} }={\\frac {n}{1+{\\frac {\\lambda }{n}}{\\frac {\\mathrm {d} n}{\\mathrm {d} \\lambda }}}}.}\n  When the refractive index of a medium is known as a function of the vacuum wavelength (instead of the wavelength in the medium), the corresponding expressions for the group velocity and index are (for all values of dispersion)\n\n  \n    \n      \n        \n          v\n          \n            \n              g\n            \n          \n        \n        =\n        \n          c\n        \n        \n        \n          \n            (\n            \n              n\n              \u2212\n              \n                \u03bb\n                \n                  0\n                \n              \n              \n                \n                  \n                    \n                      d\n                    \n                    n\n                  \n                  \n                    \n                      d\n                    \n                    \n                      \u03bb\n                      \n                        0\n                      \n                    \n                  \n                \n              \n            \n            )\n          \n          \n            \u2212\n            1\n          \n        \n        \n        ,\n      \n    \n    {\\displaystyle v_{\\mathrm {g} }=\\mathrm {c} \\!\\left(n-\\lambda _{0}{\\frac {\\mathrm {d} n}{\\mathrm {d} \\lambda _{0}}}\\right)^{-1}\\!,}\n  \n\n  \n    \n      \n        \n          n\n          \n            \n              g\n            \n          \n        \n        =\n        n\n        \u2212\n        \n          \u03bb\n          \n            0\n          \n        \n        \n          \n            \n              \n                d\n              \n              n\n            \n            \n              \n                d\n              \n              \n                \u03bb\n                \n                  0\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle n_{\\mathrm {g} }=n-\\lambda _{0}{\\frac {\\mathrm {d} n}{\\mathrm {d} \\lambda _{0}}},}\n  where \u03bb0 is the wavelength in vacuum.\n\n\n=== Other relations ===\nAs shown in the Fizeau experiment, when light is transmitted through a moving medium, its speed relative to an observer traveling with speed v in the same direction as the light is:\n\n  \n    \n      \n        V\n        =\n        \n          \n            \n              c\n            \n            n\n          \n        \n        +\n        \n          \n            \n              v\n              \n                (\n                \n                  1\n                  \u2212\n                  \n                    \n                      1\n                      \n                        n\n                        \n                          2\n                        \n                      \n                    \n                  \n                \n                )\n              \n            \n            \n              1\n              +\n              \n                \n                  v\n                  \n                    c\n                    n\n                  \n                \n              \n            \n          \n        \n        \u2248\n        \n          \n            \n              c\n            \n            n\n          \n        \n        +\n        v\n        \n          (\n          \n            1\n            \u2212\n            \n              \n                1\n                \n                  n\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n         \n        .\n      \n    \n    {\\displaystyle V={\\frac {\\mathrm {c} }{n}}+{\\frac {v\\left(1-{\\frac {1}{n^{2}}}\\right)}{1+{\\frac {v}{cn}}}}\\approx {\\frac {\\mathrm {c} }{n}}+v\\left(1-{\\frac {1}{n^{2}}}\\right)\\ .}\n  The refractive index of a substance can be related to its polarizability with the Lorentz\u2013Lorenz equation or to the molar refractivities of its constituents by the Gladstone\u2013Dale relation.\n\n\n=== Refractivity ===\nIn atmospheric applications, refractivity is defined as N = n \u2013 1, often scaled as either N = 106(n \u2013 1) or N = 108(n \u2013 1); the multiplication factors are used because the refractive index for air, n deviates from unity by at most a few parts per ten thousand.\nMolar refractivity, on the other hand, is a measure of the total polarizability of a mole of a substance and can be calculated from the refractive index as\n\n  \n    \n      \n        A\n        =\n        \n          \n            M\n            \u03c1\n          \n        \n        \n          \n            \n              \n                n\n                \n                  2\n                \n              \n              \u2212\n              1\n            \n            \n              \n                n\n                \n                  2\n                \n              \n              +\n              2\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle A={\\frac {M}{\\rho }}{\\frac {n^{2}-1}{n^{2}+2}},}\n  where \u03c1 is the density, and M is the molar mass.:\u200a93\u200a\n\n\n== Nonscalar, nonlinear, or nonhomogeneous refraction ==\nSo far, we have assumed that refraction is given by linear equations involving a spatially constant, scalar refractive index. These assumptions can break down in different ways, to be described in the following subsections.\n\n\n=== Birefringence ===\n\nIn some materials, the refractive index depends on the polarization and propagation direction of the light. This is called birefringence or optical anisotropy.\nIn the simplest form, uniaxial birefringence, there is only one special direction in the material. This axis is known as the optical axis of the material.:\u200a230\u200a Light with linear polarization perpendicular to this axis will experience an ordinary refractive index no while light polarized in parallel will experience an extraordinary refractive index ne.:\u200a236\u200a The birefringence of the material is the difference between these indices of refraction, \u0394n = ne \u2212 no.:\u200a237\u200a Light propagating in the direction of the optical axis will not be affected by the birefringence since the refractive index will be no independent of polarization. For other propagation directions the light will split into two linearly polarized beams. For light traveling perpendicularly to the optical axis the beams will have the same direction.:\u200a233\u200a This can be used to change the polarization direction of linearly polarized light or to convert between linear, circular, and elliptical polarizations with waveplates.:\u200a237\u200aMany crystals are naturally birefringent, but isotropic materials such as plastics and glass can also often be made birefringent by introducing a preferred direction through, e.g., an external force or electric field. This effect is called photoelasticity, and can be used to reveal stresses in structures. The birefringent material is placed between crossed polarizers. A change in birefringence alters the polarization and thereby the fraction of light that is transmitted through the second polarizer.\nIn the more general case of trirefringent materials described by the field of crystal optics, the dielectric constant is a rank-2 tensor (a 3 by 3 matrix). In this case the propagation of light cannot simply be described by refractive indices except for polarizations along principal axes.\n\n\n=== Nonlinearity ===\n\nThe strong electric field of high intensity light (such as the output of a laser) may cause a medium's refractive index to vary as the light passes through it, giving rise to nonlinear optics.:\u200a502\u200a If the index varies quadratically with the field (linearly with the intensity), it is called the optical Kerr effect and causes phenomena such as self-focusing and self-phase modulation.:\u200a264\u200a If the index varies linearly with the field (a nontrivial linear coefficient is only possible in materials that do not possess inversion symmetry), it is known as the Pockels effect.:\u200a265\u200a\n\n\n=== Inhomogeneity ===\n\nIf the refractive index of a medium is not constant but varies gradually with the position, the material is known as a gradient-index or GRIN medium and is described by gradient index optics.:\u200a273\u200a Light traveling through such a medium can be bent or focused, and this effect can be exploited to produce lenses, some optical fibers, and other devices. Introducing GRIN elements in the design of an optical system can greatly simplify the system, reducing the number of elements by as much as a third while maintaining overall performance.:\u200a276\u200a The crystalline lens of the human eye is an example of a GRIN lens with a refractive index varying from about 1.406 in the inner core to approximately 1.386 at the less dense cortex.:\u200a203\u200a Some common mirages are caused by a spatially varying refractive index of air.\n\n\n== Refractive index measurement ==\n\n\n=== Homogeneous media ===\n\nThe refractive index of liquids or solids can be measured with refractometers. They typically measure some angle of refraction or the critical angle for total internal reflection. The first laboratory refractometers sold commercially were developed by Ernst Abbe in the late 19th century.\nThe same principles are still used today. In this instrument, a thin layer of the liquid to be measured is placed between two prisms. Light is shone through the liquid at incidence angles all the way up to 90\u00b0, i.e., light rays parallel to the surface. The second prism should have an index of refraction higher than that of the liquid, so that light only enters the prism at angles smaller than the critical angle for total reflection. This angle can then be measured either by looking through a telescope, or with a digital photodetector placed in the focal plane of a lens. The refractive index n of the liquid can then be calculated from the maximum transmission angle \u03b8 as n = nG sin \u03b8, where nG is the refractive index of the prism.\n\nThis type of device is commonly used in chemical laboratories for identification of substances and for quality control. Handheld variants are used in agriculture by, e.g., wine makers to determine sugar content in grape juice, and inline process refractometers are used in, e.g., chemical and pharmaceutical industry for process control.\nIn gemology, a different type of refractometer is used to measure the index of refraction and birefringence of gemstones. The gem is placed on a high refractive index prism and illuminated from below. A high refractive index contact liquid is used to achieve optical contact between the gem and the prism. At small incidence angles most of the light will be transmitted into the gem, but at high angles total internal reflection will occur in the prism. The critical angle is normally measured by looking through a telescope.\n\n\n=== Refractive index variations ===\n\nUnstained biological structures appear mostly transparent under Bright-field microscopy as most cellular structures do not attenuate appreciable quantities of light. Nevertheless, the variation in the materials that constitute these structures also corresponds to a variation in the refractive index.  The following techniques convert such variation into measurable amplitude differences:\nTo measure the spatial variation of the refractive index in a sample phase-contrast imaging methods are used. These methods measure the variations in phase of the light wave exiting the sample. The phase is proportional to the optical path length the light ray has traversed, and thus gives a measure of the integral of the refractive index along the ray path. The phase cannot be measured directly at optical or higher frequencies, and therefore needs to be converted into intensity by interference with a reference beam. In the visual spectrum this is done using Zernike phase-contrast microscopy, differential interference contrast microscopy (DIC), or interferometry.\nZernike phase-contrast microscopy introduces a phase shift to the low spatial frequency components of the image with a phase-shifting annulus in the Fourier plane of the sample, so that high-spatial-frequency parts of the image can interfere with the low-frequency reference beam. In DIC the illumination is split up into two beams that are given different polarizations, are phase shifted differently, and are shifted transversely with slightly different amounts. After the specimen, the two parts are made to interfere, giving an image of the derivative of the optical path length in the direction of the difference in the transverse shift. In interferometry the illumination is split up into two beams by a partially reflective mirror. One of the beams is let through the sample before they are combined to interfere and give a direct image of the phase shifts. If the optical path length variations are more than a wavelength the image will contain fringes.\nThere exist several phase-contrast X-ray imaging techniques to determine 2D or 3D spatial distribution of refractive index of samples in the X-ray regime.\n\n\n== Applications ==\nThe refractive index is an important property of the components of any optical instrument. It determines the focusing power of lenses, the dispersive power of prisms, the reflectivity of lens coatings, and the light-guiding nature of optical fiber. Since the refractive index is a fundamental physical property of a substance, it is often used to identify a particular substance, confirm its purity, or measure its concentration. The refractive index is used to measure solids, liquids, and gases. Most commonly it is used to measure the concentration of a solute in an aqueous solution. It can also be used as a useful tool to differentiate between different types of gemstone, due to the unique chatoyance each individual stone displays. A refractometer is the instrument used to measure the refractive index. For a solution of sugar, the refractive index can be used to determine the sugar content (see Brix).\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nNIST calculator for determining the refractive index of air\nDielectric materials\nScience World\nFilmetrics' online database Free database of refractive index and absorption coefficient information\nRefractiveIndex.INFO Refractive index database featuring online plotting and parameterisation of data\nLUXPOP Thin film and bulk index of refraction and photonics calculations\nThe Feynman Lectures on Physics Vol. II Ch. 32: Refractive Index of Dense Materials", "Hardness": "In materials science, hardness (antonym: softness) is a measure of the resistance to localized plastic deformation induced by either mechanical indentation or abrasion. In general, different materials differ in their hardness; for example hard metals such as titanium and beryllium are harder than soft metals such as sodium and metallic tin, or wood and common plastics. Macroscopic hardness is generally characterized by strong intermolecular bonds, but the behavior of solid materials under force is complex; therefore, hardness can be measured in different ways, such as scratch hardness, indentation hardness, and rebound hardness. Hardness is dependent on ductility, elastic stiffness, plasticity, strain, strength, toughness, viscoelasticity, and viscosity. Common examples of hard matter are ceramics, concrete, certain metals, and superhard materials, which can be contrasted with soft matter.\n\n\n== Measuring hardness ==\n\nThere are three main types of hardness measurements: scratch, indentation, and rebound. Within each of these classes of measurement there are individual measurement scales. For practical reasons conversion tables are used to convert between one scale and another.\n\n\n== Scratch hardness ==\n\nScratch hardness is the measure of how resistant a sample is to fracture or permanent plastic deformation due to friction from a sharp object. The principle is that an object made of a harder material will scratch an object made of a softer material. When testing coatings, scratch hardness refers to the force necessary to cut through the film to the substrate. The most common test is Mohs scale, which is used in mineralogy. One tool to make this measurement is the sclerometer.\nAnother tool used to make these tests is the pocket hardness tester. This tool consists of a scale arm with graduated markings attached to a four-wheeled carriage. A scratch tool with a sharp rim is mounted at a predetermined angle to the testing surface. In order to use it a weight of known mass is added to the scale arm at one of the graduated markings, the tool is then drawn across the test surface. The use of the weight and markings allows a known pressure to be applied without the need for complicated machinery.\n\n\n== Indentation hardness ==\n\nIndentation hardness measures the resistance of a sample to material deformation due to a constant compression load from a sharp object. Tests for indentation hardness are primarily used in engineering and metallurgy. The tests work on the basic premise of measuring the critical dimensions of an indentation left by a specifically dimensioned and loaded indenter. Common indentation hardness scales are Rockwell, Vickers, Shore, and Brinell, amongst others.\n\n\n== Rebound hardness ==\nRebound hardness, also known as dynamic hardness, measures the height of the \"bounce\" of a diamond-tipped hammer dropped from a fixed height onto a material. This type of hardness is related to elasticity. The device used to take this measurement is known as a scleroscope. Two scales that measures rebound hardness are the Leeb rebound hardness test and Bennett hardness scale. Ultrasonic Contact Impedance (UCI) method determines hardness by measuring the frequency of an oscillating rod. The rod consists of a metal shaft with vibrating element and a pyramid-shaped diamond mounted on one end.\n\n\n== Hardening ==\n\nThere are five hardening processes: Hall-Petch strengthening, work hardening, solid solution strengthening, precipitation hardening, and martensitic transformation.\n\n\n== Physics ==\n\nIn solid mechanics, solids generally have three responses to force, depending on the amount of force and the type of material:\n\nThey exhibit elasticity\u2014the ability to temporarily change shape, but return to the original shape when the pressure is removed. \"Hardness\" in the elastic range\u2014a small temporary change in shape for a given force\u2014is known as stiffness in the case of a given object, or a high elastic modulus in the case of a material.\nThey exhibit plasticity\u2014the ability to permanently change shape in response to the force, but remain in one piece. The yield strength is the point at which elastic deformation gives way to plastic deformation. Deformation in the plastic range is non-linear, and is described by the stress-strain curve. This response produces the observed properties of scratch and indentation hardness, as described and measured in materials science. Some materials exhibit both elasticity and viscosity when undergoing plastic deformation; this is called viscoelasticity.\nThey fracture\u2014split into two or more pieces.Strength is a measure of the extent of a material's elastic range, or elastic and plastic ranges together. This is quantified as compressive strength, shear strength, tensile strength depending on the direction of the forces involved. Ultimate strength is an engineering measure of the maximum load a part of a specific material and geometry can withstand.\nBrittleness, in technical usage, is the tendency of a material to fracture with very little or no detectable plastic deformation beforehand. Thus in technical terms, a material can be both brittle and strong. In everyday usage \"brittleness\" usually refers to the tendency to fracture under a small amount of force, which exhibits both brittleness and a lack of strength (in the technical sense). For perfectly brittle materials, yield strength and ultimate strength are the same, because they do not experience detectable plastic deformation. The opposite of brittleness is ductility.\nThe toughness of a material is the maximum amount of energy it can absorb before fracturing, which is different from the amount of force that can be applied. Toughness tends to be small for brittle materials, because elastic and plastic deformations allow materials to absorb large amounts of energy.\nHardness increases with decreasing particle size. This is known as the Hall-Petch relationship. However, below a critical grain-size, hardness decreases with decreasing grain size. This is known as the inverse Hall-Petch effect.\nHardness of a material to deformation is dependent on its microdurability or small-scale shear modulus in any direction, not to any rigidity or stiffness properties such as its bulk modulus or Young's modulus. Stiffness is often confused for hardness. Some materials are stiffer than diamond (e.g. osmium) but are not harder, and are prone to spalling and flaking in squamose or acicular habits.\n\n\n== Mechanisms and theory ==\n\nThe key to understanding the mechanism behind hardness is understanding the metallic microstructure, or the structure and arrangement of the atoms at the atomic level. In fact, most important metallic properties critical to the manufacturing of today\u2019s goods are determined by the microstructure of a material. At the atomic level, the atoms in a metal are arranged in an orderly three-dimensional array called a crystal lattice. In reality, however, a given specimen of a metal likely never contains a consistent single crystal lattice. A given sample of metal will contain many grains, with each grain having a fairly consistent array pattern. At an even smaller scale, each grain contains irregularities.\nThere are two types of irregularities at the grain level of the microstructure that are responsible for the hardness of the material. These irregularities are point defects and line defects. A point defect is an irregularity located at a single lattice site inside of the overall three-dimensional lattice of the grain. There are three main point defects. If there is an atom missing from the array, a vacancy defect is formed. If there is a different type of atom at the lattice site that should normally be occupied by a metal atom, a substitutional defect is formed. If there exists an atom in a site where there should normally not be, an interstitial defect is formed. This is possible because space exists between atoms in a crystal lattice. While point defects are irregularities at a single site in the crystal lattice, line defects are irregularities on a plane of atoms. Dislocations are a type of line defect involving the misalignment of these planes. In the case of an edge dislocation, a half plane of atoms is wedged between two planes of atoms. In the case of a screw dislocation two planes of atoms are offset with a helical array running between them.In glasses, hardness seems to depend linearly on the number of topological constraints acting between the atoms of the network. Hence, the rigidity theory has allowed predicting hardness values with respect to composition.\n\nDislocations provide a mechanism for planes of atoms to slip and thus a method for plastic or permanent deformation.  Planes of atoms can flip from one side of the dislocation to the other effectively allowing the dislocation to traverse through the material and the material to deform permanently. The movement allowed by these dislocations causes a decrease in the material's hardness.\nThe way to inhibit the movement of planes of atoms, and thus make them harder, involves the interaction of dislocations with each other and interstitial atoms. When a dislocation intersects with a second dislocation, it can no longer traverse through the crystal lattice. The intersection of dislocations creates an anchor point and does not allow the planes of atoms to continue to slip over one another A dislocation can also be anchored by the interaction with interstitial atoms. If a dislocation comes in contact with two or more interstitial atoms, the slip of the planes will again be disrupted. The interstitial atoms create anchor points, or pinning points, in the same manner as intersecting dislocations.\nBy varying the presence of interstitial atoms and the density of dislocations, a particular metal's hardness can be controlled. Although seemingly counter-intuitive, as the density of dislocations increases, there are more intersections created and consequently more anchor points. Similarly, as more interstitial atoms are added, more pinning points that impede the movements of dislocations are formed. As a result, the more anchor points added, the harder the material will become.\n\n\n== Relation between hardness number and stress-strain curve ==\nCareful note should be taken of the relationship between a hardness number and the stress-strain curve exhibited by the material.  The latter, which is conventionally obtained via tensile testing, captures the full plasticity response of the material (which is in most cases a metal).  It is in fact a dependence of the (true) von Mises plastic strain on the (true) von Mises stress, but this is readily obtained from a nominal stress \u2013 nominal strain curve (in the pre-necking regime), which is the immediate outcome of a tensile test.  This relationship can be used to describe how the material will respond to almost any loading situation, often by using the Finite Element Method (FEM).  This applies to the outcome of an indentation test (with a given size and shape of indenter, and a given applied load).\nHowever, while a hardness number thus depends on the stress-strain relationship, inferring the latter from the former is far from simple and is not attempted in any rigorous way during conventional hardness testing.  (In fact, the Indentation Plastometry technique, which involves iterative FEM modelling of an indentation test, does allow a stress-strain curve to be obtained via indentation, but this is outside the scope of conventional hardness testing.)  A hardness number is just a semi-quantitative indicator of the resistance to plastic deformation.  Although hardness is defined in a similar way for most types of test \u2013 usually as the load divided by the contact area \u2013 the numbers obtained for a particular material are different for different types of test, and even for the same test with different applied loads.  Attempts are sometimes made to identify simple analytical expressions that allow features of the stress-strain curve, particularly the yield stress and Ultimate Tensile Stress (UTS), to be obtained from a particular type of hardness number.  However, these are all based on empirical correlations, often specific to particular types of alloy:  even with such a limitation, the values obtained are often quite unreliable.  The underlying problem is that metals with a range of combinations of yield stress and work hardening characteristics can exhibit the same hardness number.  The use of hardness numbers for any quantitative purpose should, at best, be approached with considerable caution.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nChinn, R. L. (2009). \"Hardness, bearings, and the Rockwells\". Advanced Materials & Processes. 167 (10): 29\u201331.\nDavis, J. R. (Ed.). (2002). Surface hardening of steels: Understanding the basics. Materials Park, OH: ASM International.\nDieter, George E. (1989). Mechanical Metallurgy. SI Metric Adaptation. Maidenhead, UK: McGraw-Hill Education. ISBN 0-07-100406-8\nMalzbender, J (2003). \"Comment on hardness definitions\". Journal of the European Ceramic Society. 23 (9): 9. doi:10.1016/S0955-2219(02)00354-0.\nRevankar, G. (2003). \"Introduction to hardness testing.\" Mechanical testing and evaluation, ASM Online Vol. 8.\n\n\n== External links ==\n\nAn introduction to materials hardness\nGuidelines to hardness testing Archived 2021-02-25 at the Wayback Machine\nTesting the Hardness of Metals", "Photoelectric_effect": "The photoelectric effect is the emission of electrons when electromagnetic radiation, such as light, hits a material. Electrons emitted in this manner are called photoelectrons. The phenomenon is studied in condensed matter physics, and solid state and quantum chemistry to draw inferences about the properties of atoms, molecules and solids. The effect has found use in electronic devices specialized for light detection and precisely timed electron emission.\nThe experimental results disagree with classical electromagnetism, which predicts that continuous light waves transfer energy to electrons, which would then be emitted when they accumulate enough energy. An alteration in the intensity of light would theoretically change the kinetic energy of the emitted electrons, with sufficiently dim light resulting in a delayed emission. The experimental results instead show that electrons are dislodged only when the light exceeds a certain frequency\u2014regardless of the light's intensity or duration of exposure. Because a low-frequency beam at a high intensity does not build up the energy required to produce photoelectrons, as would be the case if light's energy accumulated over time from a continuous wave, Albert Einstein proposed that a beam of light is not a wave propagating through space, but a swarm of discrete energy packets, known as photons.\nEmission of conduction electrons from typical metals requires a few electron-volt (eV) light quanta, corresponding to short-wavelength visible or ultraviolet light. In extreme cases, emissions are induced with photons approaching zero energy, like in systems with negative electron affinity and the emission from excited states, or a few hundred keV photons for core electrons in elements with a high atomic number. Study of the photoelectric effect led to important steps in understanding the quantum nature of light and electrons and influenced the formation of the concept of wave\u2013particle duality. Other phenomena where light affects the movement of electric charges include the photoconductive effect, the photovoltaic effect, and the photoelectrochemical effect.\n\n\n== Emission mechanism ==\nThe photons of a light beam have a characteristic energy, called photon energy, which is proportional to the frequency of the light. In the photoemission process, when an electron within some material absorbs the energy of a photon and acquires more energy than its binding energy, it is likely to be ejected. If the photon energy is too low, the electron is unable to escape the material. Since an increase in the intensity of low-frequency light will only increase the number of low-energy photons, this change in intensity will not create any single photon with enough energy to dislodge an electron. Moreover, the energy of the emitted electrons will not depend on the intensity of the incoming light of a given frequency, but only on the energy of the individual photons.\nWhile free electrons can absorb any energy when irradiated as long as this is followed by an immediate re-emission, like in the Compton effect, in quantum systems all of the energy from one photon is absorbed\u2014if the process is allowed by quantum mechanics\u2014or none at all. Part of the acquired energy is used to liberate the electron from its atomic binding, and the rest contributes to the electron's kinetic energy as a free particle. Because electrons in a material occupy many different quantum states with different binding energies, and because they can sustain energy losses on their way out of the material, the emitted electrons will have a range of kinetic energies. The electrons from the highest occupied states will have the highest kinetic energy. In metals, those electrons will be emitted from the Fermi level.\nWhen the photoelectron is emitted into a solid rather than into a vacuum, the term internal photoemission is often used, and emission into a vacuum is distinguished as external photoemission.\n\n\n=== Experimental observation of photoelectric emission ===\nEven though photoemission can occur from any material, it is most readily observed from metals and other conductors. This is because the process produces a charge imbalance which, if not neutralized by current flow, results in the increasing potential barrier until the emission completely ceases. The energy barrier to photoemission is usually increased by nonconductive oxide layers on metal surfaces, so most practical experiments and devices based on the photoelectric effect use clean metal surfaces in evacuated tubes. Vacuum also helps observing the electrons since it prevents gases from impeding their flow between the electrodes.\nAs sunlight, due to atmosphere's absorption, does not provide much ultraviolet light, the light rich in ultraviolet rays used to be obtained by burning magnesium or from an arc lamp. At the present time, mercury-vapor lamps, noble-gas discharge UV lamps and radio-frequency plasma sources, ultraviolet lasers, and synchrotron insertion device light sources prevail.\n\nThe classical setup to observe the photoelectric effect includes a light source, a set of filters to monochromatize the light, a vacuum tube transparent to ultraviolet light, an emitting electrode (E) exposed to the light, and a collector (C) whose voltage VC can be externally controlled.\nA positive external voltage is used to direct the photoemitted electrons onto the collector. If the frequency and the intensity of the incident radiation are fixed, the photoelectric current I increases with an increase in the positive voltage, as more and more electrons are directed onto the electrode. When no additional photoelectrons can be collected, the photoelectric current attains a saturation value. This current can only increase with the increase of the intensity of light.\nAn increasing negative voltage prevents all but the highest-energy electrons from reaching the collector. When no current is observed through the tube, the negative voltage has reached the value that is high enough to slow down and stop the most energetic photoelectrons of kinetic energy Kmax. This value of the retarding voltage is called the stopping potential or cut off potential Vo. Since the work done by the retarding potential in stopping the electron of charge e is eVo, the following must hold eVo = Kmax.The current-voltage curve is sigmoidal, but its exact shape depends on the experimental geometry and the electrode material properties.\nFor a given metal surface, there exists a certain minimum frequency of incident radiation below which no photoelectrons are emitted. This frequency is called the threshold frequency. Increasing the frequency of the incident beam increases the maximum kinetic energy of the emitted photoelectrons, and the stopping voltage has to increase. The number of emitted electrons may also change because the probability that each photon results in an emitted electron is a function of photon energy.\nAn increase in the intensity of the same monochromatic light (so long as the intensity is not too high), which is proportional to the number of photons impinging on the surface in a given time, increases the rate at which electrons are ejected\u2014the photoelectric current I\u2014but the kinetic energy of the photoelectrons and the stopping voltage remain the same. For a given metal and frequency of incident radiation, the rate at which photoelectrons are ejected is directly proportional to the intensity of the incident light.\nThe time lag between the incidence of radiation and the emission of a photoelectron is very small, less than 10\u22129 second. Angular distribution of the photoelectrons is highly dependent on polarization (the direction of the electric field) of the incident light, as well as the emitting material's quantum properties such as atomic and molecular orbital symmetries and the electronic band structure of crystalline solids. In materials without macroscopic order, the distribution of electrons tends to peak in the direction of polarization of linearly polarized light. The experimental technique that can measure these distributions to infer the material's properties is angle-resolved photoemission spectroscopy.\n\n\n=== Theoretical explanation ===\n \nIn 1905, Einstein proposed a theory of the photoelectric effect using a concept that light consists of tiny packets of energy known as photons or light quanta. Each packet carries energy \n  \n    \n      \n        h\n        \u03bd\n      \n    \n    {\\displaystyle h\\nu }\n   that is proportional to the frequency \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   of the corresponding electromagnetic wave. The proportionality constant \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   has become known as the Planck constant. In the range of kinetic energies of the electrons that are removed from their varying atomic bindings by the absorption of a photon of energy \n  \n    \n      \n        h\n        \u03bd\n      \n    \n    {\\displaystyle h\\nu }\n  , the highest kinetic energy \n  \n    \n      \n        \n          K\n          \n            max\n          \n        \n      \n    \n    {\\displaystyle K_{\\max }}\n    is\n\nHere, \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n   is the minimum energy required to remove an electron from the surface of the material. It is called the work function of the surface and is sometimes denoted \n  \n    \n      \n        \u03a6\n      \n    \n    {\\displaystyle \\Phi }\n   or \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n  . If the work function is written as\n\nthe formula for the maximum kinetic energy of the ejected electrons becomes\n\nKinetic energy is positive, and \n  \n    \n      \n        \u03bd\n        >\n        \n          \u03bd\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle \\nu >\\nu _{o}}\n   is required for the photoelectric effect to occur. The frequency \n  \n    \n      \n        \n          \u03bd\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle \\nu _{o}}\n   is the threshold frequency for the given material. Above that frequency, the maximum kinetic energy of the photoelectrons as well as the stopping voltage in the experiment \n  \n    \n      \n        \n          V\n          \n            o\n          \n        \n        =\n        \n          \n            h\n            e\n          \n        \n        \n          (\n          \n            \u03bd\n            \u2212\n            \n              \u03bd\n              \n                o\n              \n            \n          \n          )\n        \n      \n    \n    {\\textstyle V_{o}={\\frac {h}{e}}\\left(\\nu -\\nu _{o}\\right)}\n   rise linearly with the frequency, and have no dependence on the number of photons and the intensity of the impinging monochromatic light. Einstein's formula, however simple, explained all the phenomenology of the photoelectric effect, and had far-reaching consequences in the development of quantum mechanics.\n\n\n=== Photoemission from atoms, molecules and solids ===\nElectrons that are bound in atoms, molecules and solids each occupy distinct states of well-defined binding energies. When light quanta deliver more than this amount of energy to an individual electron, the electron may be emitted into free space with excess (kinetic) energy that is \n  \n    \n      \n        h\n        \u03bd\n      \n    \n    {\\displaystyle h\\nu }\n   higher than the electron's binding energy. The distribution of kinetic energies thus reflects the distribution of the binding energies of the electrons in the atomic, molecular or crystalline system: an electron emitted from the state at binding energy \n  \n    \n      \n        \n          E\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle E_{B}}\n   is found at kinetic energy \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        h\n        \u03bd\n        \u2212\n        \n          E\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle E_{k}=h\\nu -E_{B}}\n  . This distribution is one of the main characteristics of the quantum system, and can be used for further studies in quantum chemistry and quantum physics.\n\n\n==== Models of photoemission from solids ====\nThe electronic properties of ordered, crystalline solids are determined by the distribution of the electronic states with respect to energy and momentum\u2014the electronic band structure of the solid. Theoretical models of photoemission from solids show that this distribution is, for the most part, preserved in the photoelectric effect. The phenomenological three-step model for ultraviolet and soft X-ray excitation decomposes the effect into these steps:\nInner photoelectric effect in the bulk of the material that is a direct optical transition between an occupied and an unoccupied electronic state. This effect is subject to quantum-mechanical selection rules for dipole transitions. The hole left behind the electron can give rise to secondary electron emission, or the so-called Auger effect, which may be visible even when the primary photoelectron does not leave the material. In molecular solids phonons are excited in this step and may be visible as satellite lines in the final electron energy.\nElectron propagation to the surface in which some electrons may be scattered because of interactions with other constituents of the solid. Electrons that originate deeper in the solid are much more likely to suffer collisions and emerge with altered energy and momentum. Their mean-free path is a universal curve dependent on electron's energy.\nElectron escape through the surface barrier into free-electron-like states of the vacuum. In this step the electron loses energy in the amount of the work function of the surface, and suffers from the momentum loss in the direction perpendicular to the surface. Because the binding energy of electrons in solids is conveniently expressed with respect to the highest occupied state at the Fermi energy \n  \n    \n      \n        \n          E\n          \n            F\n          \n        \n      \n    \n    {\\displaystyle E_{F}}\n  , and the difference to the free-space (vacuum) energy is the work function of the surface, the kinetic energy of the electrons emitted from solids is usually written as \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        h\n        \u03bd\n        \u2212\n        W\n        \u2212\n        \n          E\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle E_{k}=h\\nu -W-E_{B}}\n  .There are cases where the three-step model fails to explain peculiarities of the photoelectron intensity distributions. The more elaborate one-step model treats the effect as a coherent process of photoexcitation into the final state of a finite crystal for which the wave function is free-electron-like outside of the crystal, but has a decaying envelope inside.\n\n\n== History ==\n\n\n=== 19th century ===\nIn 1839, Alexandre Edmond Becquerel discovered the photovoltaic effect while studying the effect of light on electrolytic cells. Though not equivalent to the photoelectric effect, his work on photovoltaics was instrumental in showing a strong relationship between light and electronic properties of materials. In 1873, Willoughby Smith discovered photoconductivity in selenium while testing the metal for its high resistance properties in conjunction with his work involving submarine telegraph cables.Johann Elster (1854\u20131920) and Hans Geitel (1855\u20131923), students in Heidelberg, investigated the effects produced by light on electrified bodies and developed the first practical photoelectric cells that could be used to measure the intensity of light.:\u200a458\u200a They arranged metals with respect to their power of discharging negative electricity: rubidium, potassium, alloy of potassium and sodium, sodium, lithium, magnesium, thallium and zinc; for copper, platinum, lead, iron, cadmium, carbon, and mercury the effects with ordinary light were too small to be measurable. The order of the metals for this effect was the same as in Volta's series for contact-electricity, the most electropositive metals giving the largest photo-electric effect.\n\nIn 1887, Heinrich Hertz observed the photoelectric effect and reported on the production and reception of electromagnetic waves. The receiver in his apparatus consisted of a coil with a spark gap, where a spark would be seen upon detection of electromagnetic waves. He placed the apparatus in a darkened box to see the spark better. However, he noticed that the maximum spark length was reduced when inside the box. A glass panel placed between the source of electromagnetic waves and the receiver absorbed ultraviolet radiation that assisted the electrons in jumping across the gap. When removed, the spark length would increase. He observed no decrease in spark length when he replaced the glass with quartz, as quartz does not absorb UV radiation.\nThe discoveries by Hertz led to a series of investigations by Hallwachs, Hoor, Righi and Stoletov on the effect of light, and especially of ultraviolet light, on charged bodies. Hallwachs connected a zinc plate to an electroscope. He allowed ultraviolet light to fall on a freshly cleaned zinc plate and observed that the zinc plate became uncharged if initially negatively charged, positively charged if initially uncharged, and more positively charged if initially positively charged. From these observations he concluded that some negatively charged particles were emitted by the zinc plate when exposed to ultraviolet light. \nWith regard to the Hertz effect, the researchers from the start showed the complexity of the phenomenon of photoelectric fatigue\u2014the progressive diminution of the effect observed upon fresh metallic surfaces. According to Hallwachs, ozone played an important part in the phenomenon, and the emission was influenced by oxidation, humidity, and the degree of polishing of the surface. It was at the time unclear whether fatigue is absent in a vacuum.\nIn the period from 1888 until 1891, a detailed analysis of the photoeffect was performed by Aleksandr Stoletov with results reported in six publications. Stoletov invented a new experimental setup which was more suitable for a quantitative analysis of the photoeffect. He discovered a direct proportionality between the intensity of light and the induced photoelectric current (the first law of photoeffect or Stoletov's law). He measured the dependence of the intensity of the photo electric current on the gas pressure, where he found the existence of an optimal gas pressure corresponding to a maximum photocurrent; this property was used for the creation of solar cells.Many substances besides metals discharge negative electricity under the action of ultraviolet light. G. C. Schmidt and O. Knoblauch compiled a list of these substances.\nIn 1897, J. J. Thomson investigated ultraviolet light in Crookes tubes. Thomson deduced that the ejected particles, which he called corpuscles, were of the same nature as cathode rays. These particles later became known as the electrons. Thomson enclosed a metal plate (a cathode) in a vacuum tube, and exposed it to high-frequency radiation. It was thought that the oscillating electromagnetic fields caused the atoms' field to resonate and, after reaching a certain amplitude, caused subatomic corpuscles to be emitted, and current to be detected. The amount of this current varied with the intensity and color of the radiation. Larger radiation intensity or frequency would produce more current.During the years 1886\u20131902, Wilhelm Hallwachs and Philipp Lenard investigated the phenomenon of photoelectric emission in detail. Lenard observed that a current flows through an evacuated glass tube enclosing two electrodes when ultraviolet radiation falls on one of them. As soon as ultraviolet radiation is stopped, the current also stops. This initiated the concept of photoelectric emission. The discovery of the ionization of gases by ultraviolet light was made by Philipp Lenard in 1900. As the effect was produced across several centimeters of air and yielded a greater number of positive ions than negative, it was natural to interpret the phenomenon, as J. J. Thomson did, as a Hertz effect upon the particles present in the gas.\n\n\n=== 20th century ===\nIn 1902, Lenard observed that the energy of individual emitted electrons increased with the frequency (which is related to the color) of the light. This appeared to be at odds with Maxwell's wave theory of light, which predicted that the electron energy would be proportional to the intensity of the radiation.\nLenard observed the variation in electron energy with light frequency using a powerful electric arc lamp which enabled him to investigate large changes in intensity, and that had sufficient power to enable him to investigate the variation of the electrode's potential with light frequency. He found the electron energy by relating it to the maximum stopping potential (voltage) in a phototube. He found that the maximum electron kinetic energy is determined by the frequency of the light. For example, an increase in frequency results in an increase in the maximum kinetic energy calculated for an electron upon liberation \u2013 ultraviolet radiation would require a higher applied stopping potential to stop current in a phototube than blue light. However, Lenard's results were qualitative rather than quantitative because of the difficulty in performing the experiments: the experiments needed to be done on freshly cut metal so that the pure metal was observed, but it oxidized in a matter of minutes even in the partial vacuums he used. The current emitted by the surface was determined by the light's intensity, or brightness: doubling the intensity of the light doubled the number of electrons emitted from the surface.\nThe researches of Langevin and those of Eugene Bloch have shown that the greater part of the Lenard effect is certainly due to the Hertz effect. The Lenard effect upon the gas itself nevertheless does exist. Refound by J. J. Thomson and then more decisively by Frederic Palmer, Jr., the gas photoemission was studied and showed very different characteristics than those at first attributed to it by Lenard.In 1900, while studying black-body radiation, the German physicist Max Planck suggested in his \"On the Law of Distribution of Energy in the Normal Spectrum\" paper that the energy carried by electromagnetic waves could only be released in packets of energy. In 1905, Albert Einstein published a paper advancing the hypothesis that light energy is carried in discrete quantized packets to explain experimental data from the photoelectric effect. Einstein theorized that the energy in each quantum of light was equal to the frequency of light multiplied by a constant, later called the Planck constant. A photon above a threshold frequency has the required energy to eject a single electron, creating the observed effect. This was a key step in the development of quantum mechanics. In 1914, Robert A. Millikan's highly accurate measurements of the Planck constant from the photoelectric effect supported Einstein's model, even though a corpuscular theory of light was for Millikan, at the time, \"quite unthinkable\". Einstein was awarded the 1921 Nobel Prize in Physics for \"his discovery of the law of the photoelectric effect\", and Millikan was awarded the Nobel Prize in 1923 for \"his work on the elementary charge of electricity and on the photoelectric effect\". In quantum perturbation theory of atoms and solids acted upon by electromagnetic radiation, the photoelectric effect is still commonly analyzed in terms of waves; the two approaches are equivalent because photon or wave absorption can only happen between quantized energy levels whose energy difference is that of the energy of photon.Albert Einstein's mathematical description of how the photoelectric effect was caused by absorption of quanta of light was in one of his Annus Mirabilis papers, named \"On a Heuristic Viewpoint Concerning the Production and Transformation of Light\". The paper proposed a simple description of light quanta, or photons, and showed how they explained such phenomena as the photoelectric effect. His simple explanation in terms of absorption of discrete quanta of light agreed with experimental results. It explained why the energy of photoelectrons was dependent only on the frequency of the incident light and not on its intensity: at low-intensity, the high-frequency source could supply a few high energy photons, whereas at high-intensity, the low-frequency source would supply no photons of sufficient individual energy to dislodge any electrons. This was an enormous theoretical leap, but the concept was strongly resisted at first because it contradicted the wave theory of light that followed naturally from James Clerk Maxwell's equations of electromagnetism, and more generally, the assumption of infinite divisibility of energy in physical systems. Even after experiments showed that Einstein's equations for the photoelectric effect were accurate, resistance to the idea of photons continued.\nEinstein's work predicted that the energy of individual ejected electrons increases linearly with the frequency of the light. Perhaps surprisingly, the precise relationship had not at that time been tested. By 1905 it was known that the energy of photoelectrons increases with increasing frequency of incident light and is independent of the intensity of the light. However, the manner of the increase was not experimentally determined until 1914 when Millikan showed that Einstein's prediction was correct.The photoelectric effect helped to propel the then-emerging concept of wave\u2013particle duality in the nature of light. Light simultaneously possesses the characteristics of both waves and particles, each being manifested according to the circumstances. The effect was impossible to understand in terms of the classical wave description of light, as the energy of the emitted electrons did not depend on the intensity of the incident radiation. Classical theory predicted that the electrons would 'gather up' energy over a period of time, and then be emitted.\n\n\n== Uses and effects ==\n\n\n=== Photomultipliers ===\n\nThese are extremely light-sensitive vacuum tubes with a coated photocathode inside the envelope. The photo cathode contains combinations of materials such as cesium, rubidium, and antimony specially selected to provide a low work function, so when illuminated even by very low levels of light, the photocathode readily releases electrons. By means of a series of electrodes (dynodes) at ever-higher potentials, these electrons are accelerated and substantially increased in number through secondary emission to provide a readily detectable output current. Photomultipliers are still commonly used wherever low levels of light must be detected.\n\n\n=== Image sensors ===\nVideo camera tubes in the early days of television used the photoelectric effect, for example, Philo Farnsworth's \"Image dissector\" used a screen charged by the photoelectric effect to transform an optical image into a scanned electronic signal.\n\n\n=== Photoelectron spectroscopy ===\n\nBecause the kinetic energy of the emitted electrons is exactly the energy of the incident photon minus the energy of the electron's binding within an atom, molecule or solid, the binding energy can be determined by shining a monochromatic X-ray or UV light of a known energy and measuring the kinetic energies of the photoelectrons. The distribution of electron energies is valuable for studying quantum properties of these systems. It can also be used to determine the elemental composition of the samples. For solids, the kinetic energy and emission angle distribution of the photoelectrons is measured for the complete determination of the electronic band structure in terms of the allowed binding energies and momenta of the electrons. Modern instruments for angle-resolved photoemission spectroscopy are capable of measuring these quantities with a precision better than 1 meV and 0.1\u00b0.\nPhotoelectron spectroscopy measurements are usually performed in a high-vacuum environment, because the electrons would be scattered by gas molecules if they were present. However, some companies are now selling products that allow photoemission in air. The light source can be a laser, a discharge tube, or a synchrotron radiation source.The concentric hemispherical analyzer is a typical electron energy analyzer. It uses an electric field between two hemispheres to change (disperse) the trajectories of incident electrons depending on their kinetic energies.\n\n\n=== Night vision devices ===\nPhotons hitting a thin film of alkali metal or semiconductor material such as gallium arsenide in an image intensifier tube cause the ejection of photoelectrons due to the photoelectric effect. These are accelerated by an electrostatic field where they strike a phosphor coated screen, converting the electrons back into photons. Intensification of the signal is achieved either through acceleration of the electrons or by increasing the number of electrons through secondary emissions, such as with a micro-channel plate. Sometimes a combination of both methods is used. Additional kinetic energy is required to move an electron out of the conduction band and into the vacuum level. This is known as the electron affinity of the photocathode and is another barrier to photoemission other than the forbidden band, explained by the band gap model. Some materials such as gallium arsenide have an effective electron affinity that is below the level of the conduction band. In these materials, electrons that move to the conduction band all have sufficient energy to be emitted from the material, so the film that absorbs photons can be quite thick. These materials are known as negative electron affinity materials.\n\n\n=== Spacecraft ===\nThe photoelectric effect will cause spacecraft exposed to sunlight to develop a positive charge. This can be a major problem, as other parts of the spacecraft are in shadow which will result in the spacecraft developing a negative charge from nearby plasmas. The imbalance can discharge through delicate electrical components. The static charge created by the photoelectric effect is self-limiting, because a higher charged object doesn't give up its electrons as easily as a lower charged object does.\n\n\n=== Moon dust ===\nLight from the Sun hitting lunar dust causes it to become positively charged from the photoelectric effect. The charged dust then repels itself and lifts off the surface of the Moon by electrostatic levitation. This manifests itself almost like an \"atmosphere of dust\", visible as a thin haze and blurring of distant features, and visible as a dim glow after the sun has set. This was first photographed by the Surveyor program probes in the 1960s, and most recently the Chang'e 3 rover observed dust deposition on lunar rocks as high as about 28 cm. It is thought that the smallest particles are repelled kilometers from the surface and that the particles move in \"fountains\" as they charge and discharge.\n\n\n== Competing processes and photoemission cross section ==\nWhen photon energies are as high as the electron rest energy of 511 keV, yet another process, the Compton scattering, may take place. Above twice this energy, at 1.022 MeV pair production is also more likely. Compton scattering and pair production are examples of two other competing mechanisms.\nEven if the photoelectric effect is the favoured reaction for a particular interaction of a single photon with a bound electron, the result is also subject to quantum statistics and is not guaranteed. The probability of the photoelectric effect occurring is measured by the cross section of the interaction, \u03c3. This has been found to be a function of the atomic number of the target atom and photon energy. In a crude approximation, for photon energies above the highest atomic binding energy, the cross section is given by:\n\n  \n    \n      \n        \u03c3\n        =\n        \n          c\n          o\n          n\n          s\n          t\n          a\n          n\n          t\n        \n        \u22c5\n        \n          \n            \n              Z\n              \n                n\n              \n            \n            \n              E\n              \n                3\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma =\\mathrm {constant} \\cdot {\\frac {Z^{n}}{E^{3}}}}\n  Here Z is the atomic number and n is a number which varies between 4 and 5. The photoelectric effect rapidly decreases in significance in the gamma-ray region of the spectrum, with increasing photon energy. It is also more likely from elements with high atomic number. Consequently, high-Z materials make good gamma-ray shields, which is the principal reason why lead (Z = 82) is preferred and most widely used.\n\n\n== See also ==\nAnomalous photovoltaic effect\nCompton scattering\nDember effect\nPhoto\u2013Dember effect\nWave\u2013particle duality\nPhotomagnetic effect\nPhotochemistry\nTimeline of atomic and subatomic physics\n\n\n== References ==\n\n\n== External links ==\n\nAstronomy Cast \"http://www.astronomycast.com/2014/02/ep-335-photoelectric-effect/\". AstronomyCast.\nNave, R., \"Wave-Particle Duality\". HyperPhysics.\n\"Photoelectric effect\". Physics 2000. University of Colorado, Boulder, Colorado. (page not found)\nACEPT W3 Group, \"The Photoelectric Effect\". Department of Physics and Astronomy, Arizona State University, Tempe, AZ.\nHaberkern, Thomas, and N Deepak \"Grains of Mystique: Quantum Physics for the Layman\". Einstein Demystifies Photoelectric Effect, Chapter 3.\nDepartment of Physics, \"The Photoelectric effect Archived 2009-08-01 at the Wayback Machine\". Physics 320 Laboratory, Davidson College, Davidson.\nFowler, Michael, \"The Photoelectric Effect\". Physics 252, University of Virginia.\nGo to \"Concerning an Heuristic Point of View Toward the Emission and Transformation of Light\" to read an English translation of Einstein's 1905 paper. (Retrieved: 2014 Apr 11)\nhttp://www.chemistryexplained.com/Ru-Sp/Solar-Cells.html\nPhoto-electric transducers: http://sensorse.com/page4en.htmlApplets\n\n\"HTML 5 JavaScript simulator\" Open Source Physics project\n\"Photoelectric Effect\". The Physics Education Technology (PhET) project. (Java)\nFendt, Walter, \"The Photoelectric Effect\". (Java)\n\"Applet: Photo Effect Archived 2010-03-14 at the Wayback Machine\". Open Source Distributed Learning Content Management and Assessment System. (Java)", "Shock_wave": "In physics, a shock wave (also spelled shockwave), or shock, is a type of propagating disturbance that moves faster than the local speed of sound in the medium. Like an ordinary wave, a shock wave carries energy and can propagate through a medium but is characterized by an abrupt, nearly discontinuous, change in pressure, temperature, and density of the medium.For the purpose of comparison, in supersonic flows, additional increased expansion may be achieved through an expansion fan, also known as a Prandtl\u2013Meyer expansion fan. The accompanying expansion wave may approach and eventually collide and recombine with the shock wave, creating a process of destructive interference. The sonic boom associated with the passage of a supersonic aircraft is a type of sound wave produced by constructive interference.\nUnlike solitons (another kind of nonlinear wave), the energy and speed of a shock wave alone dissipates relatively quickly with distance. \nWhen a shock wave passes through matter, energy is preserved but entropy increases. This change in the matter's properties manifests itself as a decrease in the energy which can be extracted as work, and as a drag force on supersonic objects; shock waves are strongly irreversible processes.\n\n\n== Terminology ==\nShock waves can be:\n\nNormal\nAt 90\u00b0 (perpendicular) to the shock medium's flow direction.\nOblique\nAt an angle to the direction of flow.\nBow\nOccurs upstream of the front (bow) of a blunt object when the upstream flow velocity exceeds Mach 1.Some other terms:\n\nShock front: The boundary over which the physical conditions undergo an abrupt change because of a shock wave.\nContact front: In a shock wave caused by a driver gas (for example the \"impact\" of a high explosive on the surrounding air), the boundary between the driver (explosive products) and the driven (air) gases. The contact front trails the shock front.\n\n\n== In supersonic flows ==\n\nThe abruptness of change in the features of the medium, that characterize shock waves, can be viewed as a phase transition: the pressure-time diagram of a supersonic object propagating shows how the transition induced by a shock wave is analogous to a dynamic phase transition.\nWhen an object (or disturbance) moves faster than the information can propagate into the surrounding fluid, then the fluid near the disturbance cannot react or \"get out of the way\" before the disturbance arrives. In a shock wave the properties of the fluid (density, pressure, temperature, flow velocity, Mach number) change almost instantaneously. Measurements of the thickness of shock waves in air have resulted in values around 200 nm (about 10\u22125 in), which is on the same order of magnitude as the mean free path of gas molecules. In reference to the continuum, this implies the shock wave can be treated as either a line or a plane if the flow field is two-dimensional or three-dimensional, respectively.\nShock waves are formed when a pressure front moves at supersonic speeds and pushes on the surrounding air. At the region where this occurs, sound waves travelling against the flow reach a point where they cannot travel any further upstream and the pressure progressively builds in that region; a high pressure shock wave rapidly forms.\nShock waves are not conventional sound waves; a shock wave takes the form of a very sharp change in the gas properties. Shock waves in air are heard as a loud \"crack\" or \"snap\" noise. Over longer distances, a shock wave can change from a nonlinear wave into a linear wave, degenerating into a conventional sound wave as it heats the air and loses energy. The sound wave is heard as the familiar \"thud\" or \"thump\" of a sonic boom, commonly created by the supersonic flight of aircraft.\nThe shock wave is one of several different ways in which a gas in a supersonic flow can be compressed. Some other methods are isentropic compressions, including Prandtl\u2013Meyer compressions. The method of compression of a gas results in different temperatures and densities for a given pressure ratio which can be analytically calculated for a non-reacting gas. A shock wave compression results in a loss of total pressure, meaning that it is a less efficient method of compressing gases for some purposes, for instance in the intake of a scramjet. The appearance of pressure-drag on supersonic aircraft is mostly due to the effect of shock compression on the flow.\n\n\n== Normal shocks ==\nIn elementary fluid mechanics utilizing ideal gases, a shock wave is treated as a discontinuity where entropy increases abruptly as the shock passes. Since no fluid flow is discontinuous, a control volume is established around the shock wave, with the control surfaces that bound this volume parallel to the shock wave (with one surface on the pre-shock side of the fluid medium and one on the post-shock side). The two surfaces are separated by a very small depth such that the shock itself is entirely contained between them. At such control surfaces, momentum, mass flux and energy are constant; within combustion, detonations can be modelled as heat introduction across a shock wave. It is assumed the system is adiabatic (no heat exits or enters the system) and no work is being done. The Rankine\u2013Hugoniot conditions arise from these considerations.\nTaking into account the established assumptions, in a system where the downstream properties are becoming subsonic: the upstream and downstream flow properties of the fluid are considered isentropic. Since the total amount of energy within the system is constant, the stagnation enthalpy remains constant over both regions. Though, entropy is increasing; this must be accounted for by a drop in stagnation pressure of the downstream fluid.\n\n\n== Other shocks ==\n\n\n=== Oblique shocks ===\nWhen analyzing shock waves in a flow field, which are still attached to the body, the shock wave which is deviating at some arbitrary angle from the flow direction is termed oblique shock. These shocks require a component vector analysis of the flow; doing so allows for the treatment of the flow in an orthogonal direction to the oblique shock as a normal shock.\n\n\n=== Bow shocks ===\nWhen an oblique shock is likely to form at an angle which cannot remain on the surface, a nonlinear phenomenon arises where the shock wave will form a continuous pattern around the body. These are termed bow shocks. In these cases, the 1d flow model is not valid and further analysis is needed to predict the pressure forces which are exerted on the surface.\n\n\n== Shock waves due to nonlinear steepening ==\nShock waves can form due to steepening of ordinary waves. The best-known example of this phenomenon is ocean waves that form breakers on the shore. In shallow water, the speed of surface waves is dependent on the depth of the water. An incoming ocean wave has a slightly higher wave speed near the crest of each wave than near the troughs between waves, because the wave height is not infinitesimal compared to the depth of the water. The crests overtake the troughs until the leading edge of the wave forms a vertical face and spills over to form a turbulent shock (a breaker) that dissipates the wave's energy as sound and heat.\nSimilar phenomena affect strong sound waves in gas or plasma, due to the dependence of the sound speed on temperature and pressure. Strong waves heat the medium near each pressure front, due to adiabatic compression of the air itself, so that high pressure fronts outrun the corresponding pressure troughs. There is a theory that the sound pressure levels in brass instruments such as the trombone become high enough for steepening to occur, forming an essential part of the bright timbre of the instruments. While shock formation by this process does not normally happen to unenclosed sound waves in Earth's atmosphere, it is thought to be one mechanism by which the solar chromosphere and corona are heated, via waves that propagate up from the solar interior.\n\n\n== Analogies ==\nA shock wave may be described as the furthest point upstream of a moving object which \"knows\" about the approach of the object. In this description, the shock wave position is defined as the boundary between the zone having no information about the shock-driving event and the zone aware of the shock-driving event, analogous with the light cone described in the theory of special relativity.\nTo produce a shock wave, an object in a given medium (such as air or water) must travel faster than the local speed of sound. In the case of an aircraft travelling at high subsonic speed, regions of air around the aircraft may be travelling at exactly the speed of sound, so that the sound waves leaving the aircraft pile up on one another, similar to a traffic jam on a motorway. When a shock wave forms, the local air pressure increases and then spreads out sideways. Because of this amplification effect, a shock wave can be very intense, more like an explosion when heard at a distance (not coincidentally, since explosions create shock waves).\nAnalogous phenomena are known outside fluid mechanics. For example, charged particles accelerated beyond the speed of light in a refractive medium (where the speed of light is less than that in a vacuum, such as water) create visible shock effects, a phenomenon known as Cherenkov radiation.\n\n\n== Phenomenon types ==\nBelow are a number of examples of shock waves, broadly grouped with similar shock phenomena:\n\n\n=== Moving shock ===\nUsually consists of a shock wave propagating into a stationary medium\nIn this case, the gas ahead of the shock is stationary (in the laboratory frame) and the gas behind the shock can be supersonic in the laboratory frame. The shock propagates with a wavefront which is normal (at right angles) to the direction of flow. The speed of the shock is a function of the original pressure ratio between the two bodies of gas.\nMoving shocks are usually generated by the interaction of two bodies of gas at different pressure, with a shock wave propagating into the lower pressure gas and an expansion wave propagating into the higher pressure gas.\nExamples: Balloon bursting, Shock tube, shock wave from explosion.\n\n\n=== Detonation wave ===\n\nA detonation wave is essentially a shock supported by a trailing exothermic reaction. It involves a wave travelling through a highly combustible or chemically unstable medium, such as an oxygen-methane mixture or a high explosive. The chemical reaction of the medium occurs following the shock wave, and the chemical energy of the reaction drives the wave forward.\nA detonation wave follows slightly different rules from an ordinary shock since it is driven by the chemical reaction occurring behind the shock wavefront. In the simplest theory for detonations, an unsupported, self-propagating detonation wave proceeds at the Chapman-Jouguet flow velocity. A detonation will also cause a shock to propagate into the surrounding air due to the overpressure induced by the explosion.\nWhen a shock wave is created by high explosives such as TNT (which has a detonation velocity of 6,900 m/s), it will always travel at high, supersonic velocity from its point of origin.\n\n\n=== Bow shock (detached shock) ===\n\nThese shocks are curved and form a small distance in front of the body. Directly in front of the body, they stand at 90 degrees to the oncoming flow and then curve around the body. Detached shocks allow the same type of analytic calculations as for the attached shock, for the flow near the shock. They are a topic of continuing interest, because the rules governing the shock's distance ahead of the blunt body are complicated and are a function of the body's shape. Additionally, the shock standoff distance varies drastically with the temperature for a non-ideal gas, causing large differences in the heat transfer to the thermal protection system of the vehicle. See the extended discussion on this topic at Atmospheric reentry. These follow the \"strong-shock\" solutions of the analytic equations, meaning that for some oblique shocks very close to the deflection angle limit, the downstream Mach number is subsonic. See also bow shock or oblique shock\nSuch a shock occurs when the maximum deflection angle is exceeded. A detached shock is commonly seen on blunt bodies, but may also be seen on sharp bodies at low Mach numbers.\nExamples: Space return vehicles (Apollo, Space shuttle), bullets, the boundary (Bow shock) of a magnetosphere. The name \"bow shock\" comes from the example of a bow wave, the detached shock formed at the bow (front) of a ship or boat moving through water, whose slow surface wave speed is easily exceeded (see ocean surface wave).\n\n\n=== Attached shock ===\nThese shocks appear as attached to the tip of sharp bodies moving at supersonic speeds.\nExamples: Supersonic wedges and cones with small apex angles.\nThe attached shock wave is a classic structure in aerodynamics because, for a perfect gas and inviscid flow field, an analytic solution is available, such that the pressure ratio, temperature ratio, angle of the wedge and the downstream Mach number can all be calculated knowing the upstream Mach number and the shock angle. Smaller shock angles are associated with higher upstream Mach numbers, and the special case where the shock wave is at 90\u00b0 to the oncoming flow (Normal shock), is associated with a Mach number of one. These follow the \"weak-shock\" solutions of the analytic equations.\n\n\n=== In rapid granular flows ===\nShock waves can also occur in rapid flows of dense granular materials down inclined channels or slopes. Strong shocks in rapid dense granular flows can be studied theoretically and analyzed to compare with experimental data. Consider a configuration in which the rapidly moving material down the chute impinges on an obstruction wall erected perpendicular at the end of a long and steep channel. Impact leads to a sudden change in the flow regime from a fast moving supercritical thin layer to a stagnant thick heap. This flow configuration is particularly interesting because it is analogous to some hydraulic and aerodynamic situations associated with flow regime changes from supercritical to subcritical flows.\n\n\n=== In astrophysics ===\n\nAstrophysical environments feature many different types of shock waves. Some common examples are supernovae shock waves or blast waves travelling through the interstellar medium, the bow shock caused by the Earth's magnetic field colliding with the solar wind and shock waves caused by galaxies colliding with each other. Another interesting type of shock in astrophysics is the quasi-steady reverse shock or termination shock that terminates the ultra relativistic wind from young pulsars.\n\n\n==== Meteor entering events ====\n\nShock waves are generated by meteoroids when they enter the Earth's atmosphere. The Tunguska event and the 2013 Russian meteor event are the best documented evidence of the shock wave produced by a massive meteoroid.\nWhen the 2013 meteor entered into the Earth's atmosphere with an energy release equivalent to 100 or more kilotons of TNT, dozens of times more powerful than the atomic bomb dropped on Hiroshima, the meteor's shock wave produced damages as in a supersonic jet's flyby (directly underneath the meteor's path) and as a detonation wave, with the circular shock wave centred at the meteor explosion, causing multiple instances of broken glass in the city of Chelyabinsk and neighbouring areas (pictured).\n\n\n== Technological applications ==\nIn the examples below, the shock wave is controlled, produced by (ex. airfoil) or in the interior of a technological device, like a turbine.\n\n\n=== Recompression shock ===\n\nThese shocks appear when the flow over a transonic body is decelerated to subsonic speeds.\nExamples: Transonic wings, turbines\nWhere the flow over the suction side of a transonic wing is accelerated to a supersonic speed, the resulting re-compression can be by either Prandtl\u2013Meyer compression or by the formation of a normal shock. This shock is of particular interest to makers of transonic devices because it can cause separation of the boundary layer at the point where it touches the transonic profile. This can then lead to full separation and stall on the profile, higher drag, or shock-buffet, a condition where the separation and the shock interact in a resonance condition, causing resonating loads on the underlying structure.\n\n\n=== Pipe flow ===\nThis shock appears when supersonic flow in a pipe is decelerated.\nExamples:\nIn supersonic propulsion: ramjet, scramjet, unstart.\nIn flow control: needle valve, choked venturi.\nIn this case the gas ahead of the shock is supersonic (in the laboratory frame), and the gas behind the shock system is either supersonic (oblique shocks) or subsonic (a normal shock) (Although for some oblique shocks very close to the deflection angle limit, the downstream Mach number is subsonic.) The shock is the result of the deceleration of the gas by a converging duct, or by the growth of the boundary layer on the wall of a parallel duct.\n\n\n=== Combustion engines ===\nThe wave disk engine (also named \"Radial Internal Combustion Wave Rotor\") is a kind of pistonless rotary engine that utilizes shock waves to transfer energy between a high-energy fluid to a low-energy fluid, thereby increasing both temperature and pressure of the low-energy fluid.\n\n\n=== Memristors ===\nIn memristors, under externally-applied electric field, shock waves can be launched across the transition-metal oxides, creating fast and non-volatile resistivity changes.\n\n\n== Shock capturing and detection ==\n\nAdvanced techniques are needed to capture shock waves and to detect shock waves in both numerical computations and experimental observations.Computational fluid dynamics is commonly used to obtain the flow field with shock waves. Though shock waves are sharp discontinuities, in numerical solutions of fluid flow with discontinuities (shock wave, contact discontinuity or slip line), the shock wave can be smoothed out by low-order numerical method (due to numerical dissipation) or there are spurious oscillations near shock surface by high-order numerical method (due to Gibbs phenomena).\nThere exist some other discontinuities in fluid flow than the shock wave. The slip surface (3D) or slip line (2D) is a plane across which the tangent velocity is discontinuous, while pressure and normal velocity are continuous. Across the contact discontinuity, the pressure and velocity are continuous and the density is discontinuous. A strong expansion wave or shear layer may also contain high gradient regions which appear to be a discontinuity. Some common features of these flow structures and shock waves and the insufficient aspects of numerical and experimental tools lead to two important problems in practices:\n(1) some shock waves can not be detected or their positions are detected wrong, (2) some flow structures which are not shock waves are wrongly detected to be shock waves.\nIn fact, correct capturing and detection of shock waves are important since shock waves have the following influences: \n(1) causing loss of total pressure, which may be a concern related to scramjet engine performance, \n(2) providing lift for wave-rider configuration, as the oblique shock wave at lower surface of the vehicle can produce high pressure to generate lift, \n(3) leading to wave drag of high-speed vehicle which is harmful to vehicle performance,\n(4) inducing severe pressure load and heat flux, e.g. the Type IV shock\u2013shock interference could yield a 17 times heating increase at vehicle surface, (5) interacting with other structures, such as boundary layers, to produce new flow structures such as flow separation, transition, etc.\n\n\n== See also ==\n\n\n== References ==\n\nNikonov, V. A Semi-Lagrangian Godunov-Type Method without Numerical Viscosity for Shocks. Fluids 2022, 7, 16. https://doi.org/10.3390/fluids7010016\n\n\n== Further reading ==\nKrehl, Peter O. K. (2011), \"Shock wave physics and detonation physics \u2014 a stimulus for the emergence of numerous new branches in science and engineering\", European Physical Journal H, 36 (1): 85\u2013152, Bibcode:2011EPJH...36...85K, doi:10.1140/epjh/e2011-10037-x, S2CID 123074683.\n\n\n== External links ==\n\nNASA Glenn Research Center information on:\nOblique Shocks\nMultiple Crossed Shocks\nExpansion Fans\nSelkirk college: Aviation intranet: High speed (supersonic) flight\nEnergy loss in a shock wave, normal and oblique shock waves\nFormation of a normal shock wave\nFundamentals of compressible flow, 2007\nNASA 2015 Schlieren image shock wave T-38C", "Projectile_motion": "Projectile motion is a form of motion experienced by an object or particle (a projectile) that is projected in a gravitational field, such as from Earth's surface, and moves along a curved path under the action of gravity only. In the particular case of projectile motion of Earth, most calculations assume the effects of air resistance are passive and negligible. The curved path of objects in projectile motion was shown by Galileo to be a parabola, but may also be a straight line in the special case when it is thrown directly upwards. The study of such motions is called ballistics, and such a trajectory is a ballistic trajectory. The only force of mathematical significance that is actively exerted on the object is gravity, which acts downward, thus imparting to the object a downward acceleration towards the Earth\u2019s center of mass. Because of the object's inertia, no external force is needed to maintain the horizontal velocity component of the object's motion. Taking other forces into account, such as aerodynamic drag or internal propulsion (such as in a rocket), requires additional analysis. A ballistic missile is a missile only guided during the relatively brief initial powered phase of flight, and whose remaining course is governed by the laws of classical mechanics.\nBallistics (from Ancient Greek  \u03b2\u03ac\u03bb\u03bb\u03b5\u03b9\u03bd b\u00e1llein 'to throw') is the science of dynamics that deals with the flight, behavior and effects of projectiles, especially bullets, unguided bombs, rockets, or the like; the science or art of designing and accelerating projectiles so as to achieve a desired performance.\n\nThe elementary equation of ballistics neglect nearly every factor except for initial velocity and an assumed constant gravitational acceleration. Practical solutions of a ballistics problem often require considerations of air resistance, cross winds, target motion, varying acceleration due to gravity, and in such problems as launching a rocket from one point on the Earth to another, the rotation of the Earth. Detailed mathematical solutions of practical problems typically do not have closed-form solutions, and therefore require numerical methods to address.\n\n\n== Kinematic quantities ==\nIn projectile motion, the horizontal motion and the vertical motion are independent of each other; that is, neither motion affects the other. This is the principle of compound motion established by Galileo in 1638, and used by him to prove the parabolic form of projectile motion.\n\nA ballistic trajectory is a parabola with homogeneous acceleration, such as in a space ship with constant acceleration in absence of other forces. On Earth the acceleration changes magnitude with altitude and direction with latitude/longitude. This causes an elliptic trajectory, which is very close to a parabola on a small scale. However, if an object was thrown and the Earth was suddenly replaced with a black hole of equal mass, it would become obvious that the ballistic trajectory is part of an elliptic orbit around that black hole, and not a parabola that extends to infinity. At higher speeds the trajectory can also be circular, parabolic or hyperbolic (unless distorted by other objects like the Moon or the Sun). In this article a homogeneous acceleration is assumed.\n\n\n=== Acceleration ===\nSince there is acceleration only in the vertical direction, the velocity in the horizontal direction is constant, being equal to \n  \n    \n      \n        \n          \n            v\n          \n          \n            0\n          \n        \n        cos\n        \u2061\n        \u03b8\n      \n    \n    {\\displaystyle \\mathbf {v} _{0}\\cos \\theta }\n  . The vertical motion of the projectile is the motion of a particle during its free fall. Here the acceleration is constant, being equal to g. The components of the acceleration are: \n\n  \n    \n      \n        \n          a\n          \n            x\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle a_{x}=0}\n  ,\n\n  \n    \n      \n        \n          a\n          \n            y\n          \n        \n        =\n        \u2212\n        g\n      \n    \n    {\\displaystyle a_{y}=-g}\n  .\n\n\n=== Velocity ===\nLet the projectile be launched with an initial velocity \n  \n    \n      \n        \n          v\n        \n        (\n        0\n        )\n        \u2261\n        \n          \n            v\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} (0)\\equiv \\mathbf {v} _{0}}\n  , which can be expressed as the sum of horizontal and vertical components as follows:\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            0\n          \n        \n        =\n        \n          v\n          \n            0\n            x\n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n        +\n        \n          v\n          \n            0\n            y\n          \n        \n        \n          \n            \n              y\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{0}=v_{0x}\\mathbf {\\hat {x}} +v_{0y}\\mathbf {\\hat {y}} }\n  .The components \n  \n    \n      \n        \n          v\n          \n            0\n            x\n          \n        \n      \n    \n    {\\displaystyle v_{0x}}\n   and \n  \n    \n      \n        \n          v\n          \n            0\n            y\n          \n        \n      \n    \n    {\\displaystyle v_{0y}}\n   can be found if the initial launch angle, \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  , is known:\n\n  \n    \n      \n        \n          v\n          \n            0\n            x\n          \n        \n        =\n        \n          v\n          \n            0\n          \n        \n        cos\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle v_{0x}=v_{0}\\cos(\\theta )}\n  ,\n\n  \n    \n      \n        \n          v\n          \n            0\n            y\n          \n        \n        =\n        \n          v\n          \n            0\n          \n        \n        sin\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle v_{0y}=v_{0}\\sin(\\theta )}\n  The horizontal component of the velocity of the object remains unchanged throughout the motion. The vertical component of the velocity changes linearly, because the acceleration due to gravity is constant. The accelerations in the x and y directions can be integrated to solve for the components of velocity at any time t, as follows:\n\n  \n    \n      \n        \n          v\n          \n            x\n          \n        \n        =\n        \n          v\n          \n            0\n          \n        \n        cos\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle v_{x}=v_{0}\\cos(\\theta )}\n  ,\n\n  \n    \n      \n        \n          v\n          \n            y\n          \n        \n        =\n        \n          v\n          \n            0\n          \n        \n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        g\n        t\n      \n    \n    {\\displaystyle v_{y}=v_{0}\\sin(\\theta )-gt}\n  .The magnitude of the velocity (under the Pythagorean theorem, also known as the triangle law):\n\n  \n    \n      \n        v\n        =\n        \n          \n            \n              v\n              \n                x\n              \n              \n                2\n              \n            \n            +\n            \n              v\n              \n                y\n              \n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle v={\\sqrt {v_{x}^{2}+v_{y}^{2}}}}\n  .\n\n\n=== Displacement ===\n\nAt any time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , the projectile's horizontal and vertical displacement are:\n\n  \n    \n      \n        x\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        cos\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle x=v_{0}t\\cos(\\theta )}\n  ,\n\n  \n    \n      \n        y\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle y=v_{0}t\\sin(\\theta )-{\\frac {1}{2}}gt^{2}}\n  .The magnitude of the displacement is:\n\n  \n    \n      \n        \u0394\n        r\n        =\n        \n          \n            \n              x\n              \n                2\n              \n            \n            +\n            \n              y\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Delta r={\\sqrt {x^{2}+y^{2}}}}\n  .Consider the equations,\n\n  \n    \n      \n        x\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        cos\n        \u2061\n        (\n        \u03b8\n        )\n        ,\n        y\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x=v_{0}t\\cos(\\theta ),y=v_{0}t\\sin(\\theta )-{\\frac {1}{2}}gt^{2}}\n  .If t is eliminated between these two equations the following equation is obtained:\n\n  \n    \n      \n        y\n        =\n        tan\n        \u2061\n        (\n        \u03b8\n        )\n        \u22c5\n        x\n        \u2212\n        \n          \n            g\n            \n              2\n              \n                v\n                \n                  0\n                \n                \n                  2\n                \n              \n              \n                cos\n                \n                  2\n                \n              \n              \u2061\n              \u03b8\n            \n          \n        \n        \u22c5\n        \n          x\n          \n            2\n          \n        \n        =\n        tan\n        \u2061\n        \u03b8\n        .\n        x\n        \n          (\n          \n            1\n            \u2212\n            \n              \n                x\n                R\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle y=\\tan(\\theta )\\cdot x-{\\frac {g}{2v_{0}^{2}\\cos ^{2}\\theta }}\\cdot x^{2}=\\tan \\theta .x\\left(1-{\\frac {x}{R}}\\right).}\n  Here R is the Range of a projectile.\nSince g, \u03b8, and v0 are constants, the above equation is of the form \n\n  \n    \n      \n        y\n        =\n        a\n        x\n        +\n        b\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle y=ax+bx^{2}}\n  ,in which a and b are constants. This is the equation of a parabola, so the path is parabolic. The axis of the parabola is vertical.\nIf the projectile's position (x,y) and launch angle (\u03b8 or \u03b1) are known, the initial velocity can be found solving for  v0 in the aforementioned parabolic equation:\n\n  \n    \n      \n        \n          v\n          \n            0\n          \n        \n        =\n        \n          \n            \n              \n                \n                  x\n                  \n                    2\n                  \n                \n                g\n              \n              \n                x\n                sin\n                \u2061\n                2\n                \u03b8\n                \u2212\n                2\n                y\n                \n                  cos\n                  \n                    2\n                  \n                \n                \u2061\n                \u03b8\n              \n            \n          \n        \n      \n    \n    {\\displaystyle v_{0}={\\sqrt {{x^{2}g} \\over {x\\sin 2\\theta -2y\\cos ^{2}\\theta }}}}\n  .\n\n\n=== Displacement in polar coordinates ===\nThe parabolic trajectory of a projectile can also be expressed in polar coordinates instead of Cartesian coordinates. In this case, the position has the general formula\n\n  \n    \n      \n        r\n        (\n        \u03d5\n        )\n        =\n        \n          \n            \n              2\n              \n                v\n                \n                  0\n                \n                \n                  2\n                \n              \n              \n                cos\n                \n                  2\n                \n              \n              \u2061\n              \u03b8\n            \n            g\n          \n        \n        \n          (\n          \n            tan\n            \u2061\n            \u03b8\n            sec\n            \u2061\n            \u03d5\n            \u2212\n            tan\n            \u2061\n            \u03d5\n            sec\n            \u2061\n            \u03d5\n          \n          )\n        \n      \n    \n    {\\displaystyle r(\\phi )={\\frac {2v_{0}^{2}\\cos ^{2}\\theta }{g}}\\left(\\tan \\theta \\sec \\phi -\\tan \\phi \\sec \\phi \\right)}\n  .In this equation, the origin is the midpoint of the horizontal range of the projectile, and if the ground is flat, the parabolic arc is plotted in the range \n  \n    \n      \n        0\n        \u2264\n        \u03d5\n        \u2264\n        \u03c0\n      \n    \n    {\\displaystyle 0\\leq \\phi \\leq \\pi }\n  . This expression can be obtained by transforming the Cartesian equation as stated above by \n  \n    \n      \n        y\n        =\n        r\n        sin\n        \u2061\n        \u03d5\n      \n    \n    {\\displaystyle y=r\\sin \\phi }\n   and \n  \n    \n      \n        x\n        =\n        r\n        cos\n        \u2061\n        \u03d5\n      \n    \n    {\\displaystyle x=r\\cos \\phi }\n  .\n\n\n== Properties of the trajectory ==\n\n\n=== Time of flight or total time of the whole journey ===\nThe total time t for which the projectile remains in the air is called the time of flight.\n\n  \n    \n      \n        y\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle y=v_{0}t\\sin(\\theta )-{\\frac {1}{2}}gt^{2}}\n  After the flight, the projectile returns to the horizontal axis (x-axis), so \n  \n    \n      \n        y\n        =\n        0\n      \n    \n    {\\displaystyle y=0}\n  .\n\n  \n    \n      \n        0\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 0=v_{0}t\\sin(\\theta )-{\\frac {1}{2}}gt^{2}}\n  \n  \n    \n      \n        \n          v\n          \n            0\n          \n        \n        t\n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        =\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{0}t\\sin(\\theta )={\\frac {1}{2}}gt^{2}}\n  \n  \n    \n      \n        \n          v\n          \n            0\n          \n        \n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        =\n        \n          \n            1\n            2\n          \n        \n        g\n        t\n      \n    \n    {\\displaystyle v_{0}\\sin(\\theta )={\\frac {1}{2}}gt}\n  \n  \n    \n      \n        t\n        =\n        \n          \n            \n              2\n              \n                v\n                \n                  0\n                \n              \n              sin\n              \u2061\n              (\n              \u03b8\n              )\n            \n            g\n          \n        \n      \n    \n    {\\displaystyle t={\\frac {2v_{0}\\sin(\\theta )}{g}}}\n  Note that we have neglected air resistance on the projectile.\nIf the starting point is at height y0 with respect to the point of impact, the time of flight is:\n\n  \n    \n      \n        t\n        =\n        \n          \n            d\n            \n              v\n              cos\n              \u2061\n              \u03b8\n            \n          \n        \n        =\n        \n          \n            \n              v\n              sin\n              \u2061\n              \u03b8\n              +\n              \n                \n                  (\n                  v\n                  sin\n                  \u2061\n                  \u03b8\n                  \n                    )\n                    \n                      2\n                    \n                  \n                  +\n                  2\n                  g\n                  \n                    y\n                    \n                      0\n                    \n                  \n                \n              \n            \n            g\n          \n        \n      \n    \n    {\\displaystyle t={\\frac {d}{v\\cos \\theta }}={\\frac {v\\sin \\theta +{\\sqrt {(v\\sin \\theta )^{2}+2gy_{0}}}}{g}}}\n  As above, this expression can be reduced to\n\n  \n    \n      \n        t\n        =\n        \n          \n            \n              v\n              sin\n              \u2061\n              \n                \u03b8\n              \n              +\n              \n                \n                  (\n                  v\n                  sin\n                  \u2061\n                  \n                    \u03b8\n                  \n                  \n                    )\n                    \n                      2\n                    \n                  \n                \n              \n            \n            g\n          \n        \n        =\n        \n          \n            \n              v\n              sin\n              \u2061\n              \n                \u03b8\n              \n              +\n              v\n              sin\n              \u2061\n              \n                \u03b8\n              \n            \n            g\n          \n        \n        =\n        \n          \n            \n              2\n              v\n              sin\n              \u2061\n              \n                \u03b8\n              \n            \n            g\n          \n        \n        =\n        \n          \n            \n              2\n              v\n              sin\n              \u2061\n              \n                (\n                45\n                )\n              \n            \n            g\n          \n        \n        =\n        \n          \n            \n              2\n              v\n              \n                \n                  \n                    2\n                  \n                  2\n                \n              \n            \n            g\n          \n        \n        =\n        \n          \n            \n              \n                \n                  2\n                \n              \n              v\n            \n            g\n          \n        \n      \n    \n    {\\displaystyle t={\\frac {v\\sin {\\theta }+{\\sqrt {(v\\sin {\\theta })^{2}}}}{g}}={\\frac {v\\sin {\\theta }+v\\sin {\\theta }}{g}}={\\frac {2v\\sin {\\theta }}{g}}={\\frac {2v\\sin {(45)}}{g}}={\\frac {2v{\\frac {\\sqrt {2}}{2}}}{g}}={\\frac {{\\sqrt {2}}v}{g}}}\n  if \u03b8 is 45\u00b0 and y0 is 0.\n\n\n=== Time of flight to the target's position ===\nAs shown above in the Displacement section, the horizontal and vertical velocity of a projectile are independent of each other. \nBecause of this, we can find the time to reach a target using the displacement formula for the horizontal velocity:\n\n  \n    \n      \n        x\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        cos\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle x=v_{0}t\\cos(\\theta )}\n  \n\n  \n    \n      \n        \n          \n            x\n            t\n          \n        \n        =\n        \n          v\n          \n            0\n          \n        \n        cos\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle {\\frac {x}{t}}=v_{0}\\cos(\\theta )}\n  \n\n  \n    \n      \n        t\n        =\n        \n          \n            x\n            \n              \n                v\n                \n                  0\n                \n              \n              cos\n              \u2061\n              (\n              \u03b8\n              )\n            \n          \n        \n      \n    \n    {\\displaystyle t={\\frac {x}{v_{0}\\cos(\\theta )}}}\n  \nThis equation will give the total time t the projectile must travel for to reach the target's horizontal displacement, neglecting air resistance.\n\n\n=== Maximum height of projectile ===\n\nThe greatest height that the object will reach is known as the peak of the object's motion.\nThe increase in height will last until \n  \n    \n      \n        \n          v\n          \n            y\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle v_{y}=0}\n  , that is,\n\n  \n    \n      \n        0\n        =\n        \n          v\n          \n            0\n          \n        \n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        g\n        \n          t\n          \n            h\n          \n        \n      \n    \n    {\\displaystyle 0=v_{0}\\sin(\\theta )-gt_{h}}\n  .Time to reach the maximum height(h):\n\n  \n    \n      \n        \n          t\n          \n            h\n          \n        \n        =\n        \n          \n            \n              \n                v\n                \n                  0\n                \n              \n              sin\n              \u2061\n              (\n              \u03b8\n              )\n            \n            g\n          \n        \n      \n    \n    {\\displaystyle t_{h}={\\frac {v_{0}\\sin(\\theta )}{g}}}\n  .For the vertical displacement of the maximum height of projectile:\n\n  \n    \n      \n        h\n        =\n        \n          v\n          \n            0\n          \n        \n        \n          t\n          \n            h\n          \n        \n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            h\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle h=v_{0}t_{h}\\sin(\\theta )-{\\frac {1}{2}}gt_{h}^{2}}\n  \n\n  \n    \n      \n        h\n        =\n        \n          \n            \n              \n                v\n                \n                  0\n                \n                \n                  2\n                \n              \n              \n                sin\n                \n                  2\n                \n              \n              \u2061\n              (\n              \u03b8\n              )\n            \n            \n              2\n              g\n            \n          \n        \n      \n    \n    {\\displaystyle h={\\frac {v_{0}^{2}\\sin ^{2}(\\theta )}{2g}}}\n  The maximum reachable height is obtained for \u03b8=90\u00b0:\n\n  \n    \n      \n        \n          h\n          \n            \n              m\n              a\n              x\n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                0\n              \n              \n                2\n              \n            \n            \n              2\n              g\n            \n          \n        \n      \n    \n    {\\displaystyle h_{\\mathrm {max} }={\\frac {v_{0}^{2}}{2g}}}\n  If the projectile's position (x,y) and launch angle (\u03b8) are known, the maximum height can be found solving for h in the following equation:\n\n  \n    \n      \n        h\n        =\n        \n          \n            \n              (\n              x\n              tan\n              \u2061\n              \u03b8\n              \n                )\n                \n                  2\n                \n              \n            \n            \n              4\n              (\n              x\n              tan\n              \u2061\n              \u03b8\n              \u2212\n              y\n              )\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle h={\\frac {(x\\tan \\theta )^{2}}{4(x\\tan \\theta -y)}}.}\n  \n\n\n=== Relation between horizontal range and maximum height ===\nThe relation between the range d on the horizontal plane and the maximum height h reached at \n  \n    \n      \n        \n          \n            \n              t\n              \n                d\n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {t_{d}}{2}}}\n   is:\n\n  \n    \n      \n        h\n        =\n        \n          \n            \n              d\n              tan\n              \u2061\n              \u03b8\n            \n            4\n          \n        \n      \n    \n    {\\displaystyle h={\\frac {d\\tan \\theta }{4}}}\n  \n\n\n=== Maximum distance of projectile ===\n\nThe range and the maximum height of the projectile does not depend upon its mass. Hence range and maximum height are equal for all bodies that are thrown with the same velocity and direction.\nThe horizontal range d of the projectile is the horizontal distance it has traveled when it returns to its initial height (\n  \n    \n      \n        y\n        =\n        0\n      \n    \n    {\\displaystyle y=0}\n  ).\n\n  \n    \n      \n        0\n        =\n        \n          v\n          \n            0\n          \n        \n        \n          t\n          \n            d\n          \n        \n        sin\n        \u2061\n        (\n        \u03b8\n        )\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            d\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 0=v_{0}t_{d}\\sin(\\theta )-{\\frac {1}{2}}gt_{d}^{2}}\n  .Time to reach ground:\n\n  \n    \n      \n        \n          t\n          \n            d\n          \n        \n        =\n        \n          \n            \n              2\n              \n                v\n                \n                  0\n                \n              \n              sin\n              \u2061\n              (\n              \u03b8\n              )\n            \n            g\n          \n        \n      \n    \n    {\\displaystyle t_{d}={\\frac {2v_{0}\\sin(\\theta )}{g}}}\n  .From the horizontal displacement the maximum distance of projectile:\n\n  \n    \n      \n        d\n        =\n        \n          v\n          \n            0\n          \n        \n        \n          t\n          \n            d\n          \n        \n        cos\n        \u2061\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle d=v_{0}t_{d}\\cos(\\theta )}\n  ,so\n\n  \n    \n      \n        d\n        =\n        \n          \n            \n              v\n              \n                0\n              \n              \n                2\n              \n            \n            g\n          \n        \n        sin\n        \u2061\n        (\n        2\n        \u03b8\n        )\n      \n    \n    {\\displaystyle d={\\frac {v_{0}^{2}}{g}}\\sin(2\\theta )}\n  .Note that d has its maximum value when\n\n  \n    \n      \n        sin\n        \u2061\n        2\n        \u03b8\n        =\n        1\n      \n    \n    {\\displaystyle \\sin 2\\theta =1}\n  ,which necessarily corresponds to\n\n  \n    \n      \n        2\n        \u03b8\n        =\n        \n          90\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle 2\\theta =90^{\\circ }}\n  ,or\n\n  \n    \n      \n        \u03b8\n        =\n        \n          45\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle \\theta =45^{\\circ }}\n  .\nThe total horizontal distance (d) traveled.\n\n  \n    \n      \n        d\n        =\n        \n          \n            \n              v\n              cos\n              \u2061\n              \u03b8\n            \n            g\n          \n        \n        \n          (\n          \n            v\n            sin\n            \u2061\n            \u03b8\n            +\n            \n              \n                (\n                v\n                sin\n                \u2061\n                \u03b8\n                \n                  )\n                  \n                    2\n                  \n                \n                +\n                2\n                g\n                \n                  y\n                  \n                    0\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle d={\\frac {v\\cos \\theta }{g}}\\left(v\\sin \\theta +{\\sqrt {(v\\sin \\theta )^{2}+2gy_{0}}}\\right)}\n  When the surface is flat (initial height of the object is zero), the distance traveled:\n\n  \n    \n      \n        d\n        =\n        \n          \n            \n              \n                v\n                \n                  2\n                \n              \n              sin\n              \u2061\n              (\n              2\n              \u03b8\n              )\n            \n            g\n          \n        \n      \n    \n    {\\displaystyle d={\\frac {v^{2}\\sin(2\\theta )}{g}}}\n  Thus the maximum distance is obtained if \u03b8 is 45 degrees. This distance is:\n\n  \n    \n      \n        \n          d\n          \n            \n              m\n              a\n              x\n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                2\n              \n            \n            g\n          \n        \n      \n    \n    {\\displaystyle d_{\\mathrm {max} }={\\frac {v^{2}}{g}}}\n  \n\n\n=== Application of the work energy theorem ===\nAccording to the work-energy theorem the vertical component of velocity is:\n\n  \n    \n      \n        \n          v\n          \n            y\n          \n          \n            2\n          \n        \n        =\n        (\n        \n          v\n          \n            0\n          \n        \n        sin\n        \u2061\n        \u03b8\n        \n          )\n          \n            2\n          \n        \n        \u2212\n        2\n        g\n        y\n      \n    \n    {\\displaystyle v_{y}^{2}=(v_{0}\\sin \\theta )^{2}-2gy}\n  .\nThese formulae ignore aerodynamic drag and also assume that the landing area is at uniform height 0.\n\n\n=== Angle of reach ===\nThe \"angle of reach\" is the angle (\u03b8) at which a projectile must be launched in order to go a distance d, given the initial velocity v.\n\n  \n    \n      \n        sin\n        \u2061\n        (\n        2\n        \u03b8\n        )\n        =\n        \n          \n            \n              g\n              d\n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sin(2\\theta )={\\frac {gd}{v^{2}}}}\n  There are two solutions:\n\n  \n    \n      \n        \u03b8\n        =\n        \n          \n            1\n            2\n          \n        \n        arcsin\n        \u2061\n        \n          (\n          \n            \n              \n                g\n                d\n              \n              \n                v\n                \n                  2\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\theta ={\\frac {1}{2}}\\arcsin \\left({\\frac {gd}{v^{2}}}\\right)}\n   (shallow trajectory)and\n\n  \n    \n      \n        \u03b8\n        =\n        \n          \n            1\n            2\n          \n        \n        arccos\n        \u2061\n        \n          (\n          \n            \n              \n                g\n                d\n              \n              \n                v\n                \n                  2\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\theta ={\\frac {1}{2}}\\arccos \\left({\\frac {gd}{v^{2}}}\\right)}\n   (steep trajectory)\n\n\n=== Angle \u03b8 required to hit coordinate (x, y) ===\n\nTo hit a target at range x and altitude y when fired from (0,0) and with initial speed v the required angle(s) of launch \u03b8 are:\n\n  \n    \n      \n        \u03b8\n        =\n        arctan\n        \u2061\n        \n          \n            (\n            \n              \n                \n                  \n                    v\n                    \n                      2\n                    \n                  \n                  \u00b1\n                  \n                    \n                      \n                        v\n                        \n                          4\n                        \n                      \n                      \u2212\n                      g\n                      (\n                      g\n                      \n                        x\n                        \n                          2\n                        \n                      \n                      +\n                      2\n                      y\n                      \n                        v\n                        \n                          2\n                        \n                      \n                      )\n                    \n                  \n                \n                \n                  g\n                  x\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle \\theta =\\arctan {\\left({\\frac {v^{2}\\pm {\\sqrt {v^{4}-g(gx^{2}+2yv^{2})}}}{gx}}\\right)}}\n  The two roots of the equation correspond to the two possible launch angles, so long as they aren't imaginary, in which case the initial speed is not great enough to reach the point (x,y) selected. This formula allows one to find the angle of launch needed without the restriction of \n  \n    \n      \n        y\n        =\n        0\n      \n    \n    {\\displaystyle y=0}\n  .\nOne can also ask what launch angle allows the lowest possible launch velocity. This occurs when the two solutions above are equal, implying that the quantity under the square root sign is zero. This requires solving a quadratic equation for \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v^{2}}\n  , and we find\n\n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        \n          /\n        \n        g\n        =\n        y\n        +\n        \n          \n            \n              y\n              \n                2\n              \n            \n            +\n            \n              x\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle v^{2}/g=y+{\\sqrt {y^{2}+x^{2}}}.}\n  This gives\n\n  \n    \n      \n        \u03b8\n        =\n        arctan\n        \u2061\n        \n          (\n          \n            y\n            \n              /\n            \n            x\n            +\n            \n              \n                \n                  y\n                  \n                    2\n                  \n                \n                \n                  /\n                \n                \n                  x\n                  \n                    2\n                  \n                \n                +\n                1\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle \\theta =\\arctan \\left(y/x+{\\sqrt {y^{2}/x^{2}+1}}\\right).}\n  If we denote the angle whose tangent is y/x by \u03b1, then\n\n  \n    \n      \n        tan\n        \u2061\n        \u03b8\n        =\n        \n          \n            \n              sin\n              \u2061\n              \u03b1\n              +\n              1\n            \n            \n              cos\n              \u2061\n              \u03b1\n            \n          \n        \n      \n    \n    {\\displaystyle \\tan \\theta ={\\frac {\\sin \\alpha +1}{\\cos \\alpha }}}\n  \n\n  \n    \n      \n        tan\n        \u2061\n        (\n        \u03c0\n        \n          /\n        \n        2\n        \u2212\n        \u03b8\n        )\n        =\n        \n          \n            \n              cos\n              \u2061\n              \u03b1\n            \n            \n              sin\n              \u2061\n              \u03b1\n              +\n              1\n            \n          \n        \n      \n    \n    {\\displaystyle \\tan(\\pi /2-\\theta )={\\frac {\\cos \\alpha }{\\sin \\alpha +1}}}\n  \n\n  \n    \n      \n        \n          cos\n          \n            2\n          \n        \n        \u2061\n        (\n        \u03c0\n        \n          /\n        \n        2\n        \u2212\n        \u03b8\n        )\n        =\n        \n          \n            1\n            2\n          \n        \n        (\n        sin\n        \u2061\n        \u03b1\n        +\n        1\n        )\n      \n    \n    {\\displaystyle \\cos ^{2}(\\pi /2-\\theta )={\\frac {1}{2}}(\\sin \\alpha +1)}\n  \n\n  \n    \n      \n        2\n        \n          cos\n          \n            2\n          \n        \n        \u2061\n        (\n        \u03c0\n        \n          /\n        \n        2\n        \u2212\n        \u03b8\n        )\n        \u2212\n        1\n        =\n        cos\n        \u2061\n        (\n        \u03c0\n        \n          /\n        \n        2\n        \u2212\n        \u03b1\n        )\n      \n    \n    {\\displaystyle 2\\cos ^{2}(\\pi /2-\\theta )-1=\\cos(\\pi /2-\\alpha )}\n  This implies\n\n  \n    \n      \n        \u03b8\n        =\n        \u03c0\n        \n          /\n        \n        2\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        (\n        \u03c0\n        \n          /\n        \n        2\n        \u2212\n        \u03b1\n        )\n        .\n      \n    \n    {\\displaystyle \\theta =\\pi /2-{\\frac {1}{2}}(\\pi /2-\\alpha ).}\n  In other words, the launch should be at the angle halfway between the target and Zenith (vector opposite to Gravity)\n\n\n=== Total Path Length of the Trajectory ===\nThe length of the parabolic arc traced by a projectile L, given that the height of launch and landing is the same and that there is no air resistance, is given by the formula:\n\n  \n    \n      \n        L\n        =\n        \n          \n            \n              v\n              \n                0\n              \n              \n                2\n              \n            \n            \n              2\n              g\n            \n          \n        \n        \n          (\n          \n            2\n            sin\n            \u2061\n            \u03b8\n            +\n            \n              cos\n              \n                2\n              \n            \n            \u2061\n            \u03b8\n            \u22c5\n            ln\n            \u2061\n            \n              \n                \n                  1\n                  +\n                  sin\n                  \u2061\n                  \u03b8\n                \n                \n                  1\n                  \u2212\n                  sin\n                  \u2061\n                  \u03b8\n                \n              \n            \n          \n          )\n        \n        =\n        \n          \n            \n              v\n              \n                0\n              \n              \n                2\n              \n            \n            g\n          \n        \n        \n          (\n          \n            sin\n            \u2061\n            \u03b8\n            +\n            \n              cos\n              \n                2\n              \n            \n            \u2061\n            \u03b8\n            \u22c5\n            \n              tanh\n              \n                \u2212\n                1\n              \n            \n            \u2061\n            (\n            sin\n            \u2061\n            \u03b8\n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle L={\\frac {v_{0}^{2}}{2g}}\\left(2\\sin \\theta +\\cos ^{2}\\theta \\cdot \\ln {\\frac {1+\\sin \\theta }{1-\\sin \\theta }}\\right)={\\frac {v_{0}^{2}}{g}}\\left(\\sin \\theta +\\cos ^{2}\\theta \\cdot \\tanh ^{-1}(\\sin \\theta )\\right)}\n  where \n  \n    \n      \n        \n          v\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle v_{0}}\n   is the initial velocity, \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the launch angle and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   is the acceleration due to gravity as a positive value. The expression can be obtained by evaluating the arc length integral for the height-distance parabola between the bounds initial and final displacements (i.e. between 0 and the horizontal range of the projectile) such that:\n\n  \n    \n      \n        L\n        =\n        \n          \u222b\n          \n            0\n          \n          \n            \n              r\n              a\n              n\n              g\n              e\n            \n          \n        \n        \n          \n            1\n            +\n            \n              \n                (\n                \n                  \n                    \n                      \n                        d\n                      \n                      y\n                    \n                    \n                      \n                        d\n                      \n                      x\n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n          \n        \n        \n        \n          d\n        \n        x\n        =\n        \n          \u222b\n          \n            0\n          \n          \n            \n              v\n              \n                0\n              \n              \n                2\n              \n            \n            sin\n            \u2061\n            (\n            2\n            \u03b8\n            )\n            \n              /\n            \n            g\n          \n        \n        \n          \n            1\n            +\n            \n              \n                (\n                \n                  \u2212\n                  \n                    \n                      g\n                      \n                        \n                          v\n                          \n                            0\n                          \n                          \n                            2\n                          \n                        \n                        \n                          cos\n                          \n                            2\n                          \n                        \n                        \u2061\n                        \u03b8\n                      \n                    \n                  \n                  x\n                  +\n                  tan\n                  \u2061\n                  \u03b8\n                \n                )\n              \n              \n                2\n              \n            \n          \n        \n        \n        \n          d\n        \n        x\n      \n    \n    {\\displaystyle L=\\int _{0}^{\\mathrm {range} }{\\sqrt {1+\\left({\\frac {\\mathrm {d} y}{\\mathrm {d} x}}\\right)^{2}}}\\,\\mathrm {d} x=\\int _{0}^{v_{0}^{2}\\sin(2\\theta )/g}{\\sqrt {1+\\left(-{\\frac {g}{v_{0}^{2}\\cos ^{2}\\theta }}x+\\tan \\theta \\right)^{2}}}\\,\\mathrm {d} x}\n  .\n\n\n== Trajectory of a projectile with air resistance ==\n\nAir resistance creates a force that (for symmetric projectiles) is always directed against the direction of motion in the surrounding medium and has a magnitude that depends on the absolute speed: \n  \n    \n      \n        \n          \n            F\n            \n              a\n              i\n              r\n            \n          \n        \n        =\n        \u2212\n        f\n        (\n        v\n        )\n        \u22c5\n        \n          \n            \n              v\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F_{air}} =-f(v)\\cdot \\mathbf {\\hat {v}} }\n  . The speed-dependence of the friction force is linear (\n  \n    \n      \n        f\n        (\n        v\n        )\n        \u221d\n        v\n      \n    \n    {\\displaystyle f(v)\\propto v}\n  ) at very low speeds (Stokes drag) and quadratic (\n  \n    \n      \n        f\n        (\n        v\n        )\n        \u221d\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(v)\\propto v^{2}}\n  ) at larger speeds (Newton drag). The transition between these behaviours is determined by the Reynolds number, which depends on speed, object size and kinematic viscosity of the medium. For Reynolds numbers below about 1000, the dependence is linear, above it becomes quadratic. In air, which has a kinematic viscosity around \n  \n    \n      \n        0.15\n        \n        \n          c\n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle 0.15\\,\\mathrm {cm^{2}/s} }\n  , this means that the drag force becomes quadratic in v when the product of speed and diameter is more than about \n  \n    \n      \n        0.015\n        \n        \n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle 0.015\\,\\mathrm {m^{2}/s} }\n  , which is typically the case for projectiles.\n\nStokes drag: \n  \n    \n      \n        \n          \n            F\n            \n              a\n              i\n              r\n            \n          \n        \n        =\n        \u2212\n        \n          k\n          \n            \n              S\n              t\n              o\n              k\n              e\n              s\n            \n          \n        \n        \u22c5\n        \n          v\n        \n        \n      \n    \n    {\\displaystyle \\mathbf {F_{air}} =-k_{\\mathrm {Stokes} }\\cdot \\mathbf {v} \\qquad }\n   (for \n  \n    \n      \n        R\n        e\n        \u2272\n        1000\n      \n    \n    {\\displaystyle Re\\lesssim 1000}\n  )\nNewton drag: \n  \n    \n      \n        \n          \n            F\n            \n              a\n              i\n              r\n            \n          \n        \n        =\n        \u2212\n        k\n        \n        \n          |\n        \n        \n          v\n        \n        \n          |\n        \n        \u22c5\n        \n          v\n        \n        \n      \n    \n    {\\displaystyle \\mathbf {F_{air}} =-k\\,|\\mathbf {v} |\\cdot \\mathbf {v} \\qquad }\n   (for \n  \n    \n      \n        R\n        e\n        \u2273\n        1000\n      \n    \n    {\\displaystyle Re\\gtrsim 1000}\n  )\nThe free body diagram on the right is for a projectile that experiences air resistance and the effects of gravity. Here, air resistance is assumed to be in the direction opposite of the projectile's velocity: \n  \n    \n      \n        \n          \n            F\n            \n              \n                a\n                i\n                r\n              \n            \n          \n        \n        =\n        \u2212\n        f\n        (\n        v\n        )\n        \u22c5\n        \n          \n            \n              v\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F_{\\mathrm {air} }} =-f(v)\\cdot \\mathbf {\\hat {v}} }\n  \n\n\n=== Trajectory of a projectile with Stokes drag ===\nStokes drag, where \n  \n    \n      \n        \n          \n            F\n            \n              a\n              i\n              r\n            \n          \n        \n        \u221d\n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {F_{air}} \\propto \\mathbf {v} }\n  , only applies at very low speed in air, and is thus not the typical case for projectiles. However, the linear dependence of \n  \n    \n      \n        \n          F\n          \n            \n              a\n              i\n              r\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {air} }}\n   on \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   causes a very simple differential equation of motion\n\n  \n    \n      \n        \n          \n            \n              d\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    v\n                    \n                      x\n                    \n                  \n                \n              \n              \n                \n                  \n                    v\n                    \n                      y\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \u2212\n                  \u03bc\n                  \n                  \n                    v\n                    \n                      x\n                    \n                  \n                \n              \n              \n                \n                  \u2212\n                  g\n                  \u2212\n                  \u03bc\n                  \n                  \n                    v\n                    \n                      y\n                    \n                  \n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} }{\\mathrm {d} t}}{\\begin{pmatrix}v_{x}\\\\v_{y}\\end{pmatrix}}={\\begin{pmatrix}-\\mu \\,v_{x}\\\\-g-\\mu \\,v_{y}\\end{pmatrix}}}\n  in which the two cartesian components become completely independent, and thus easier to solve.\nHere, \n  \n    \n      \n        \n          v\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle v_{0}}\n  ,\n  \n    \n      \n        \n          v\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle v_{x}}\n   and \n  \n    \n      \n        \n          v\n          \n            y\n          \n        \n      \n    \n    {\\displaystyle v_{y}}\n   will be used to denote the initial velocity, the velocity along the direction of x and the velocity along the direction of y, respectively. The mass of the projectile will be denoted by m, and \n  \n    \n      \n        \u03bc\n        :=\n        k\n        \n          /\n        \n        m\n      \n    \n    {\\displaystyle \\mu :=k/m}\n  . For the derivation only the case where \n  \n    \n      \n        \n          0\n          \n            o\n          \n        \n        \u2264\n        \u03b8\n        \u2264\n        \n          180\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle 0^{o}\\leq \\theta \\leq 180^{o}}\n   is considered. Again, the projectile is fired from the origin (0,0).\n\n  \n    \n      \n        x\n        (\n        t\n        )\n        =\n        \n          \n            \n              v\n              \n                x\n                0\n              \n            \n            \u03bc\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bc\n                t\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle x(t)={\\frac {v_{x0}}{\\mu }}\\left(1-e^{-\\mu t}\\right)}\n   (1b)\n\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \u2212\n        \n          \n            g\n            \u03bc\n          \n        \n        t\n        +\n        \n          \n            1\n            \u03bc\n          \n        \n        \n          (\n          \n            \n              v\n              \n                y\n                0\n              \n            \n            +\n            \n              \n                g\n                \u03bc\n              \n            \n          \n          )\n        \n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                \u03bc\n                t\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle y(t)=-{\\frac {g}{\\mu }}t+{\\frac {1}{\\mu }}\\left(v_{y0}+{\\frac {g}{\\mu }}\\right)\\left(1-e^{-\\mu t}\\right)}\n   (3b)\n\n  \n    \n      \n        t\n        =\n        \n          \n            1\n            \u03bc\n          \n        \n        \n          (\n          \n            1\n            +\n            \n              \n                \u03bc\n                g\n              \n            \n            \n              v\n              \n                y\n                0\n              \n            \n            +\n            W\n            \n              (\n              \n                \u2212\n                \n                  (\n                  \n                    1\n                    +\n                    \n                      \n                        \u03bc\n                        g\n                      \n                    \n                    \n                      v\n                      \n                        y\n                        0\n                      \n                    \n                  \n                  )\n                \n                \n                  e\n                  \n                    \u2212\n                    \n                      (\n                      \n                        1\n                        +\n                        \n                          \n                            \u03bc\n                            g\n                          \n                        \n                        \n                          v\n                          \n                            y\n                            0\n                          \n                        \n                      \n                      )\n                    \n                  \n                \n              \n              )\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle t={\\frac {1}{\\mu }}\\left(1+{\\frac {\\mu }{g}}v_{y0}+W\\left(-\\left(1+{\\frac {\\mu }{g}}v_{y0}\\right)e^{-\\left(1+{\\frac {\\mu }{g}}v_{y0}\\right)}\\right)\\right)}\n  .\n\n\n=== Trajectory of a projectile with Newton drag ===\n\nThe most typical case of air resistance, for the case of Reynolds numbers above about 1000 is Newton drag with a drag force proportional to the speed squared, \n  \n    \n      \n        \n          F\n          \n            \n              a\n              i\n              r\n            \n          \n        \n        =\n        \u2212\n        k\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {air} }=-kv^{2}}\n  . In air, which has a kinematic viscosity around \n  \n    \n      \n        0.15\n        \n        \n          c\n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle 0.15\\,\\mathrm {cm^{2}/s} }\n  , this means that the product of speed and diameter must be more than about \n  \n    \n      \n        0.015\n        \n        \n          \n            m\n            \n              2\n            \n          \n          \n            /\n          \n          s\n        \n      \n    \n    {\\displaystyle 0.015\\,\\mathrm {m^{2}/s} }\n  .\nUnfortunately, the equations of motion can not be easily solved analytically for this case. Therefore, a numerical solution will be examined.\nThe following assumptions are made:\n\nConstant gravitational acceleration\nAir resistance is given by the following drag formula,\n  \n    \n      \n        \n          \n            F\n            \n              D\n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              1\n              2\n            \n          \n        \n        c\n        \u03c1\n        A\n        \n        v\n        \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {F_{D}} =-{\\tfrac {1}{2}}c\\rho A\\,v\\,\\mathbf {v} }\n  Where:FD is the drag force\nc is the drag coefficient\n\u03c1 is the air density\nA is the cross sectional area of the projectile\n\u03bc = k/m = c\u03c1A/(2m)\n\n\n==== Special cases ====\nEven though the general case of a projectile with Newton drag cannot be solved analytically, some special cases can. Here we denote the terminal velocity in free-fall as \n  \n    \n      \n        \n          v\n          \n            \u221e\n          \n        \n        =\n        \n          \n            g\n            \n              /\n            \n            \u03bc\n          \n        \n      \n    \n    {\\displaystyle v_{\\infty }={\\sqrt {g/\\mu }}}\n   and the characteristic settling time constant \n  \n    \n      \n        \n          t\n          \n            f\n          \n        \n        =\n        1\n        \n          /\n        \n        \n          \n            g\n            \u03bc\n          \n        \n      \n    \n    {\\displaystyle t_{f}=1/{\\sqrt {g\\mu }}}\n  .\n\nNear-horizontal motion: In case the motion is almost horizontal, \n  \n    \n      \n        \n          |\n        \n        \n          v\n          \n            x\n          \n        \n        \n          |\n        \n        \u226b\n        \n          |\n        \n        \n          v\n          \n            y\n          \n        \n        \n          |\n        \n      \n    \n    {\\displaystyle |v_{x}|\\gg |v_{y}|}\n  , such as a flying bullet, the vertical velocity component has very little influence on the horizontal motion. In this case:\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u02d9\n              \n            \n          \n          \n            x\n          \n        \n        (\n        t\n        )\n        =\n        \u2212\n        \u03bc\n        \n        \n          v\n          \n            x\n          \n          \n            2\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle {\\dot {v}}_{x}(t)=-\\mu \\,v_{x}^{2}(t)}\n  \n\n  \n    \n      \n        \n          v\n          \n            x\n          \n        \n        (\n        t\n        )\n        =\n        \n          \n            1\n            \n              1\n              \n                /\n              \n              \n                v\n                \n                  x\n                  ,\n                  0\n                \n              \n              +\n              \u03bc\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle v_{x}(t)={\\frac {1}{1/v_{x,0}+\\mu \\,t}}}\n  \n\n  \n    \n      \n        x\n        (\n        t\n        )\n        =\n        \n          \n            1\n            \u03bc\n          \n        \n        ln\n        \u2061\n        (\n        1\n        +\n        \u03bc\n        \n        \n          v\n          \n            x\n            ,\n            0\n          \n        \n        \u22c5\n        t\n        )\n      \n    \n    {\\displaystyle x(t)={\\frac {1}{\\mu }}\\ln(1+\\mu \\,v_{x,0}\\cdot t)}\n  \nThe same pattern applies for motion with friction along a line in any direction, when gravity is negligible. It also applies when vertical motion is prevented, such as for a moving car with its engine off.Vertical motion upward:\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u02d9\n              \n            \n          \n          \n            y\n          \n        \n        (\n        t\n        )\n        =\n        \u2212\n        g\n        \u2212\n        \u03bc\n        \n        \n          v\n          \n            y\n          \n          \n            2\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle {\\dot {v}}_{y}(t)=-g-\\mu \\,v_{y}^{2}(t)}\n  \n\n  \n    \n      \n        \n          v\n          \n            y\n          \n        \n        (\n        t\n        )\n        =\n        \n          v\n          \n            \u221e\n          \n        \n        tan\n        \u2061\n        \n          \n            \n              \n                t\n                \n                  \n                    p\n                    e\n                    a\n                    k\n                  \n                \n              \n              \u2212\n              t\n            \n            \n              t\n              \n                f\n              \n            \n          \n        \n      \n    \n    {\\displaystyle v_{y}(t)=v_{\\infty }\\tan {\\frac {t_{\\mathrm {peak} }-t}{t_{f}}}}\n  \n\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \n          y\n          \n            \n              p\n              e\n              a\n              k\n            \n          \n        \n        +\n        \n          \n            1\n            \u03bc\n          \n        \n        ln\n        \u2061\n        \n          (\n          \n            cos\n            \u2061\n            \n              \n                \n                  \n                    t\n                    \n                      \n                        p\n                        e\n                        a\n                        k\n                      \n                    \n                  \n                  \u2212\n                  t\n                \n                \n                  t\n                  \n                    f\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle y(t)=y_{\\mathrm {peak} }+{\\frac {1}{\\mu }}\\ln \\left(\\cos {\\frac {t_{\\mathrm {peak} }-t}{t_{f}}}\\right)}\n  \nHere\n\n  \n    \n      \n        \n          v\n          \n            \u221e\n          \n        \n        \u2261\n        \n          \n            \n              g\n              \u03bc\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle v_{\\infty }\\equiv {\\sqrt {\\frac {g}{\\mu }}},}\n  \n\n  \n    \n      \n        \n          t\n          \n            f\n          \n        \n        \u2261\n        \n          \n            1\n            \n              \u03bc\n              g\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle t_{f}\\equiv {\\frac {1}{\\sqrt {\\mu g}}},}\n  \n\n  \n    \n      \n        \n          t\n          \n            \n              p\n              e\n              a\n              k\n            \n          \n        \n        \u2261\n        \n          t\n          \n            f\n          \n        \n        arctan\n        \u2061\n        \n          \n            \n              v\n              \n                y\n                ,\n                0\n              \n            \n            \n              v\n              \n                \u221e\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              \u03bc\n              g\n            \n          \n        \n        arctan\n        \u2061\n        \n          \n            (\n            \n              \n                \n                  \n                    \u03bc\n                    g\n                  \n                \n              \n              \n                v\n                \n                  y\n                  ,\n                  0\n                \n              \n            \n            )\n          \n        \n        ,\n      \n    \n    {\\displaystyle t_{\\mathrm {peak} }\\equiv t_{f}\\arctan {\\frac {v_{y,0}}{v_{\\infty }}}={\\frac {1}{\\sqrt {\\mu g}}}\\arctan {\\left({\\sqrt {\\frac {\\mu }{g}}}v_{y,0}\\right)},}\n  \nand\n\n  \n    \n      \n        \n          y\n          \n            \n              p\n              e\n              a\n              k\n            \n          \n        \n        \u2261\n        \u2212\n        \n          \n            1\n            \u03bc\n          \n        \n        ln\n        \u2061\n        \n          cos\n          \u2061\n          \n            \n              \n                t\n                \n                  \n                    p\n                    e\n                    a\n                    k\n                  \n                \n              \n              \n                t\n                \n                  f\n                \n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              2\n              \u03bc\n            \n          \n        \n        ln\n        \u2061\n        \n          \n            (\n            \n              1\n              +\n              \n                \n                  \u03bc\n                  g\n                \n              \n              \n                v\n                \n                  y\n                  ,\n                  0\n                \n                \n                  2\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle y_{\\mathrm {peak} }\\equiv -{\\frac {1}{\\mu }}\\ln {\\cos {\\frac {t_{\\mathrm {peak} }}{t_{f}}}}={\\frac {1}{2\\mu }}\\ln {\\left(1+{\\frac {\\mu }{g}}v_{y,0}^{2}\\right)}}\n  \nwhere \n  \n    \n      \n        \n          v\n          \n            y\n            ,\n            0\n          \n        \n      \n    \n    {\\displaystyle v_{y,0}}\n   is the initial upward velocity at \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n   and the initial position is \n  \n    \n      \n        y\n        (\n        0\n        )\n        =\n        0\n      \n    \n    {\\displaystyle y(0)=0}\n  .\nA projectile can not rise longer than \n  \n    \n      \n        \n          t\n          \n            \n              r\n              i\n              s\n              e\n            \n          \n        \n        =\n        \n          \n            \u03c0\n            2\n          \n        \n        \n          t\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle t_{\\mathrm {rise} }={\\frac {\\pi }{2}}t_{f}}\n   vertically before it reaches the peak.Vertical motion downward:\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u02d9\n              \n            \n          \n          \n            y\n          \n        \n        (\n        t\n        )\n        =\n        \u2212\n        g\n        +\n        \u03bc\n        \n        \n          v\n          \n            y\n          \n          \n            2\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle {\\dot {v}}_{y}(t)=-g+\\mu \\,v_{y}^{2}(t)}\n  \n\n  \n    \n      \n        \n          v\n          \n            y\n          \n        \n        (\n        t\n        )\n        =\n        \u2212\n        \n          v\n          \n            \u221e\n          \n        \n        tanh\n        \u2061\n        \n          \n            \n              t\n              \u2212\n              \n                t\n                \n                  \n                    p\n                    e\n                    a\n                    k\n                  \n                \n              \n            \n            \n              t\n              \n                f\n              \n            \n          \n        \n      \n    \n    {\\displaystyle v_{y}(t)=-v_{\\infty }\\tanh {\\frac {t-t_{\\mathrm {peak} }}{t_{f}}}}\n  \n\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \n          y\n          \n            \n              p\n              e\n              a\n              k\n            \n          \n        \n        \u2212\n        \n          \n            1\n            \u03bc\n          \n        \n        ln\n        \u2061\n        \n          (\n          \n            cosh\n            \u2061\n            \n              \n                \n                  t\n                  \u2212\n                  \n                    t\n                    \n                      \n                        p\n                        e\n                        a\n                        k\n                      \n                    \n                  \n                \n                \n                  t\n                  \n                    f\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle y(t)=y_{\\mathrm {peak} }-{\\frac {1}{\\mu }}\\ln \\left(\\cosh {\\frac {t-t_{\\mathrm {peak} }}{t_{f}}}\\right)}\n  \nAfter a time \n  \n    \n      \n        \n          t\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle t_{f}}\n  , the projectile reaches almost terminal velocity \n  \n    \n      \n        \u2212\n        \n          v\n          \n            \u221e\n          \n        \n      \n    \n    {\\displaystyle -v_{\\infty }}\n  .\n\n\n==== Numerical solution ====\nA projectile motion with drag can be computed generically by numerical integration of the ordinary differential equation, for instance by applying a reduction to a first-order system. The equation to be solved is\n\n  \n    \n      \n        \n          \n            \n              d\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  x\n                \n              \n              \n                \n                  y\n                \n              \n              \n                \n                  \n                    v\n                    \n                      x\n                    \n                  \n                \n              \n              \n                \n                  \n                    v\n                    \n                      y\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    v\n                    \n                      x\n                    \n                  \n                \n              \n              \n                \n                  \n                    v\n                    \n                      y\n                    \n                  \n                \n              \n              \n                \n                  \u2212\n                  \u03bc\n                  \n                  \n                    v\n                    \n                      x\n                    \n                  \n                  \n                    \n                      \n                        v\n                        \n                          x\n                        \n                        \n                          2\n                        \n                      \n                      +\n                      \n                        v\n                        \n                          y\n                        \n                        \n                          2\n                        \n                      \n                    \n                  \n                \n              \n              \n                \n                  \u2212\n                  g\n                  \u2212\n                  \u03bc\n                  \n                  \n                    v\n                    \n                      y\n                    \n                  \n                  \n                    \n                      \n                        v\n                        \n                          x\n                        \n                        \n                          2\n                        \n                      \n                      +\n                      \n                        v\n                        \n                          y\n                        \n                        \n                          2\n                        \n                      \n                    \n                  \n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} }{\\mathrm {d} t}}{\\begin{pmatrix}x\\\\y\\\\v_{x}\\\\v_{y}\\end{pmatrix}}={\\begin{pmatrix}v_{x}\\\\v_{y}\\\\-\\mu \\,v_{x}{\\sqrt {v_{x}^{2}+v_{y}^{2}}}\\\\-g-\\mu \\,v_{y}{\\sqrt {v_{x}^{2}+v_{y}^{2}}}\\end{pmatrix}}}\n  .This approach also allows to add the effects of speed-dependent drag coefficient, altitude-dependent air density and position-dependent gravity field.\n\n\n== Lofted trajectory ==\n\nA special case of a ballistic trajectory for a rocket is a lofted trajectory, a trajectory with an apogee greater than the minimum-energy trajectory to the same range. In other words, the rocket travels higher and by doing so it uses more energy to get to the same landing point. This may be done for various reasons such as increasing distance to the horizon to give greater viewing/communication range or for changing the angle with which a missile will impact on landing. Lofted trajectories are sometimes used in both missile rocketry and in spaceflight.\n\n\n== Projectile motion on a planetary scale ==\n\nWhen a projectile without air resistance travels a range that is significant compared to the earth's radius (above \u2248100 km), the curvature of the earth and the non-uniform Earth's gravity have to be considered. This is for example the case with spacecraft or intercontinental projectiles. The trajectory then generalizes from a parabola to a Kepler-ellipse with one focus at the center of the earth. The projectile motion then follows Kepler's laws of planetary motion.\nThe trajectories' parameters have to be adapted from the values of a uniform gravity field stated above. The earth radius is taken as R, and g as the standard surface gravity. Let \n  \n    \n      \n        \n          \n            \n              v\n              ~\n            \n          \n        \n        :=\n        v\n        \n          /\n        \n        \n          \n            R\n            g\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {v}}:=v/{\\sqrt {Rg}}}\n   the launch velocity relative to the first cosmic velocity.\nTotal range d between launch and impact:\n\n  \n    \n      \n        d\n        =\n        \n          \n            \n              \n                v\n                \n                  2\n                \n              \n              sin\n              \u2061\n              (\n              2\n              \u03b8\n              )\n            \n            g\n          \n        \n        \n          \n            /\n          \n        \n        \n          \n            1\n            \u2212\n            \n              (\n              \n                2\n                \u2212\n                \n                  \n                    \n                      \n                        v\n                        ~\n                      \n                    \n                  \n                  \n                    2\n                  \n                \n              \n              )\n            \n            \n              \n                \n                  \n                    v\n                    ~\n                  \n                \n              \n              \n                2\n              \n            \n            \n              cos\n              \n                2\n              \n            \n            \u2061\n            \u03b8\n          \n        \n      \n    \n    {\\displaystyle d={\\frac {v^{2}\\sin(2\\theta )}{g}}{\\Big /}{\\sqrt {1-\\left(2-{\\tilde {v}}^{2}\\right){\\tilde {v}}^{2}\\cos ^{2}\\theta }}}\n  Maximum range of a projectile for optimum launch angle (\n  \n    \n      \n        \u03b8\n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        arccos\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  \n                    v\n                    ~\n                  \n                \n              \n              \n                2\n              \n            \n            \n              /\n            \n            (\n            2\n            \u2212\n            \n              \n                \n                  \n                    v\n                    ~\n                  \n                \n              \n              \n                2\n              \n            \n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle \\theta ={\\tfrac {1}{2}}\\arccos \\left({\\tilde {v}}^{2}/(2-{\\tilde {v}}^{2})\\right)}\n  ):\n\n  \n    \n      \n        \n          d\n          \n            \n              m\n              a\n              x\n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                2\n              \n            \n            g\n          \n        \n        \n          \n            /\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              \n                \n                  1\n                  2\n                \n              \n            \n            \n              \n                \n                  \n                    v\n                    ~\n                  \n                \n              \n              \n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle d_{\\mathrm {max} }={\\frac {v^{2}}{g}}{\\big /}\\left(1-{\\tfrac {1}{2}}{\\tilde {v}}^{2}\\right)}\n         with \n  \n    \n      \n        v\n        <\n        \n          \n            R\n            g\n          \n        \n      \n    \n    {\\displaystyle v<{\\sqrt {Rg}}}\n  , the first cosmic velocityMaximum height of a projectile above the planetary surface:\n\n  \n    \n      \n        h\n        =\n        \n          \n            \n              \n                v\n                \n                  2\n                \n              \n              \n                sin\n                \n                  2\n                \n              \n              \u2061\n              \u03b8\n            \n            g\n          \n        \n        \n          \n            /\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              \n                \n                  \n                    v\n                    ~\n                  \n                \n              \n              \n                2\n              \n            \n            +\n            \n              \n                1\n                \u2212\n                \n                  (\n                  \n                    2\n                    \u2212\n                    \n                      \n                        \n                          \n                            v\n                            ~\n                          \n                        \n                      \n                      \n                        2\n                      \n                    \n                  \n                  )\n                \n                \n                  \n                    \n                      \n                        v\n                        ~\n                      \n                    \n                  \n                  \n                    2\n                  \n                \n                \n                  cos\n                  \n                    2\n                  \n                \n                \u2061\n                \u03b8\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle h={\\frac {v^{2}\\sin ^{2}\\theta }{g}}{\\Big /}\\left(1-{\\tilde {v}}^{2}+{\\sqrt {1-\\left(2-{\\tilde {v}}^{2}\\right){\\tilde {v}}^{2}\\cos ^{2}\\theta }}\\right)}\n  Maximum height of a projectile for vertical launch (\n  \n    \n      \n        \u03b8\n        =\n        \n          90\n          \n            \u2218\n          \n        \n      \n    \n    {\\displaystyle \\theta =90^{\\circ }}\n  ):\n\n  \n    \n      \n        \n          h\n          \n            \n              m\n              a\n              x\n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                2\n              \n            \n            \n              2\n              g\n            \n          \n        \n        \n          \n            /\n          \n        \n        \n          (\n          \n            1\n            \u2212\n            \n              \n                \n                  1\n                  2\n                \n              \n            \n            \n              \n                \n                  \n                    v\n                    ~\n                  \n                \n              \n              \n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle h_{\\mathrm {max} }={\\frac {v^{2}}{2g}}{\\big /}\\left(1-{\\tfrac {1}{2}}{\\tilde {v}}^{2}\\right)}\n         with \n  \n    \n      \n        v\n        <\n        \n          \n            2\n            R\n            g\n          \n        \n      \n    \n    {\\displaystyle v<{\\sqrt {2Rg}}}\n  , the second cosmic velocityTime of flight:\n\n  \n    \n      \n        t\n        =\n        \n          \n            \n              2\n              v\n              sin\n              \u2061\n              \u03b8\n            \n            g\n          \n        \n        \u22c5\n        \n          \n            1\n            \n              2\n              \u2212\n              \n                \n                  \n                    \n                      v\n                      ~\n                    \n                  \n                \n                \n                  2\n                \n              \n            \n          \n        \n        \n          (\n          \n            1\n            +\n            \n              \n                1\n                \n                  \n                    \n                      2\n                      \u2212\n                      \n                        \n                          \n                            \n                              v\n                              ~\n                            \n                          \n                        \n                        \n                          2\n                        \n                      \n                    \n                  \n                  \n                  \n                    \n                      \n                        v\n                        ~\n                      \n                    \n                  \n                  sin\n                  \u2061\n                  \u03b8\n                \n              \n            \n            arcsin\n            \u2061\n            \n              \n                \n                  \n                    \n                      2\n                      \u2212\n                      \n                        \n                          \n                            \n                              v\n                              ~\n                            \n                          \n                        \n                        \n                          2\n                        \n                      \n                    \n                  \n                  \n                  \n                    \n                      \n                        v\n                        ~\n                      \n                    \n                  \n                  sin\n                  \u2061\n                  \u03b8\n                \n                \n                  1\n                  \u2212\n                  \n                    (\n                    \n                      2\n                      \u2212\n                      \n                        \n                          \n                            \n                              v\n                              ~\n                            \n                          \n                        \n                        \n                          2\n                        \n                      \n                    \n                    )\n                  \n                  \n                    \n                      \n                        \n                          v\n                          ~\n                        \n                      \n                    \n                    \n                      2\n                    \n                  \n                  \n                    cos\n                    \n                      2\n                    \n                  \n                  \u2061\n                  \u03b8\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle t={\\frac {2v\\sin \\theta }{g}}\\cdot {\\frac {1}{2-{\\tilde {v}}^{2}}}\\left(1+{\\frac {1}{{\\sqrt {2-{\\tilde {v}}^{2}}}\\,{\\tilde {v}}\\sin \\theta }}\\arcsin {\\frac {{\\sqrt {2-{\\tilde {v}}^{2}}}\\,{\\tilde {v}}\\sin \\theta }{\\sqrt {1-\\left(2-{\\tilde {v}}^{2}\\right){\\tilde {v}}^{2}\\cos ^{2}\\theta }}}\\right)}\n  \n\n\n== See also ==\nEquations of motion\n\n\n== Notes ==\n\n\n== References ==", "Non-inertial_reference_frame": "A non-inertial reference frame is a frame of reference that undergoes acceleration with respect to an inertial frame. An accelerometer at rest in a non-inertial frame will, in general, detect a non-zero acceleration. While the laws of motion are the same in all inertial frames, in non-inertial frames, they vary from frame to frame depending on the acceleration.In classical mechanics it is often possible to explain the motion of bodies in non-inertial reference frames by introducing additional fictitious forces (also called inertial forces, pseudo-forces and d'Alembert forces) to Newton's second law. Common examples of this include the Coriolis force and the centrifugal force. In general, the expression for any fictitious force can be derived from the acceleration of the non-inertial frame. As stated by Goodman and Warner, \"One might say that F = ma holds in any coordinate system provided the term 'force' is redefined to include the so-called 'reversed effective forces' or 'inertia forces'.\"In the theory of general relativity, the curvature of spacetime causes frames to be locally inertial, but globally non-inertial. Due to the non-Euclidean geometry of curved space-time, there are no global inertial reference frames in general relativity. More specifically, the fictitious force which appears in general relativity is the force of gravity.\n\n\n== Avoiding fictitious forces in calculations ==\n\nIn flat spacetime, the use of non-inertial frames can be avoided if desired.  Measurements with respect to non-inertial reference frames can always be transformed to an inertial frame, incorporating directly the acceleration of the non-inertial frame as that acceleration as seen from the inertial frame. This approach avoids use of fictitious forces (it is based on an inertial frame, where fictitious forces are absent, by definition) but it may be less convenient from an intuitive, observational, and even a calculational viewpoint. As pointed out by Ryder for the case of rotating frames as used in meteorology:\nA simple way of dealing with this problem is, of course, to transform all coordinates to an inertial system. This is, however, sometimes inconvenient. Suppose, for example, we wish to calculate the movement of air masses in the earth's atmosphere due to pressure gradients. We need the results relative to the rotating frame, the earth, so it is better to stay within this coordinate system if possible. This can be achieved by introducing fictitious (or \"non-existent\") forces which enable us to apply Newton's Laws of Motion in the same way as in an inertial frame.\n\n\n== Detection of a non-inertial frame: need for fictitious forces ==\nThat a given frame is non-inertial can be detected by its need for fictitious forces to explain observed motions. For example, the rotation of the Earth can be observed using a Foucault pendulum.  The rotation of the Earth seemingly causes the pendulum to change its plane of oscillation because the surroundings of the pendulum move with the Earth. As seen from an Earth-bound (non-inertial) frame of reference, the explanation of this apparent change in orientation  requires the introduction of the fictitious Coriolis force.\nAnother famous example is that of the tension in the string between two spheres rotating about each other. In that case, prediction of the measured tension in the string based upon the motion of the spheres as observed from a rotating reference frame requires the rotating observers to introduce a fictitious centrifugal force.\nIn this connection, it may be noted that a change in coordinate system, for example, from Cartesian to polar, if implemented without any change in relative motion, does not cause the appearance of fictitious forces, despite the fact that the form of the laws of motion varies from one type of curvilinear coordinate system to another.\n\n\n== Fictitious forces in curvilinear coordinates ==\n\nA different use of the term \"fictitious force\" often is used in curvilinear coordinates, particularly polar coordinates. To avoid confusion, this distracting ambiguity in terminologies is pointed out here. These so-called \"forces\" are non-zero in all frames of reference, inertial or non-inertial, and do not transform as vectors under rotations and translations of the coordinates (as all Newtonian forces do, fictitious or otherwise).\nThis incompatible use of the term \"fictitious force\" is unrelated to non-inertial frames. These so-called \"forces\" are defined by determining the acceleration of a particle within the curvilinear coordinate system, and then separating the simple double-time derivatives of coordinates from the remaining terms. These remaining terms then are called \"fictitious forces\". More careful usage calls these terms \"generalized fictitious forces\" to indicate their connection to the generalized coordinates of Lagrangian mechanics. The application of Lagrangian methods to polar coordinates can be found here.\n\n\n== Relativistic point of view ==\n\n\n=== Frames and flat spacetime ===\n\nIf a region of spacetime is declared to be Euclidean, and effectively free from obvious gravitational fields, then if an accelerated coordinate system is overlaid onto the same region, it can be said that a uniform fictitious field exists in the accelerated frame (we reserve the word gravitational for the case in which a mass is involved). An object accelerated to be stationary in the accelerated frame will \"feel\" the presence of the field, and they will also be able to see environmental matter with inertial states of motion (stars, galaxies, etc.) to be apparently falling \"downwards\" in the field along curved trajectories as if the field is real.\nIn frame-based descriptions, this supposed field can be made to appear or disappear by switching between \"accelerated\" and \"inertial\" coordinate systems.\n\n\n=== More advanced descriptions ===\nAs the situation is modeled in finer detail, using the general principle of relativity, the concept of a frame-dependent gravitational field becomes less realistic. In these Machian models, the accelerated body can agree that the apparent gravitational field is associated with the motion of the background matter, but can also claim that the motion of the material as if there is a gravitational field, causes the gravitational field - the accelerating background matter \"drags light\". Similarly, a background observer can argue that the forced acceleration of the mass causes an apparent gravitational field in the region between it and the environmental material (the accelerated mass also \"drags light\").\nThis \"mutual\" effect, and the ability of an accelerated mass to warp lightbeam geometry and lightbeam-based coordinate systems, is referred to as frame-dragging.\nFrame-dragging removes the usual distinction between accelerated frames (which show gravitational effects) and inertial frames (where the geometry is supposedly free from gravitational fields). When a forcibly-accelerated body physically \"drags\" a coordinate system, the problem becomes an exercise in warped spacetime for all observers.\n\n\n== See also ==\nRotating reference frame\nFictitious force\nCentrifugal force\nCoriolis effect\nInertial frame of reference\nFree motion equation\n\n\n== References and notes ==", "Diffraction": "Diffraction is defined as the interference or bending of waves around the corners of an obstacle or through an aperture into the region of geometrical shadow of the obstacle/aperture. The diffracting object or aperture effectively becomes a secondary source of the propagating wave. Italian scientist Francesco Maria Grimaldi coined the word diffraction and was the first to record accurate observations of the phenomenon in 1660.\n\nIn classical physics, the diffraction phenomenon is described by the Huygens\u2013Fresnel principle that treats each point in a propagating wavefront as a collection of individual spherical wavelets. The characteristic bending pattern is most pronounced when a wave from a coherent source (such as a laser) encounters a slit/aperture that is comparable in size to its wavelength, as shown in the inserted image. This is due to the addition, or interference, of different points on the wavefront (or, equivalently, each wavelet) that travel by paths of different lengths to the registering surface. If there are multiple, closely spaced openings (e.g., a diffraction grating), a complex pattern of varying intensity can result.\nThese effects also occur when a light wave travels through a medium with a varying refractive index, or when a sound wave travels through a medium with varying acoustic impedance \u2013 all waves diffract, including gravitational waves, water waves, and other electromagnetic waves such as X-rays and radio waves. Furthermore, quantum mechanics also demonstrates that matter possesses wave-like properties, and hence, undergoes diffraction (which is measurable at subatomic to molecular levels).The amount of diffraction depends on the size of the gap. Diffraction is greatest when the size of the gap is similar to the wavelength of the wave. In this case, when the waves pass through the gap they become semi-circular.\n\n\n== History ==\n\nThe effects of diffraction of light were first carefully observed and characterized by Francesco Maria Grimaldi, who also coined the term diffraction, from the Latin diffringere, 'to break into pieces', referring to light breaking up into different directions. The results of Grimaldi's observations were published posthumously in 1665. Isaac Newton studied these effects and attributed them to inflexion of light rays. James Gregory (1638\u20131675) observed the diffraction patterns caused by a bird feather, which was effectively the first diffraction grating to be discovered. Thomas Young performed a celebrated experiment in 1803 demonstrating interference from two closely spaced slits. Explaining his results by interference of the waves emanating from the two different slits, he deduced that light must propagate as waves. Augustin-Jean Fresnel did more definitive studies and calculations of diffraction, made public in 1816 and 1818, and thereby gave great support to the wave theory of light that had been advanced by Christiaan Huygens and reinvigorated by Young, against Newton's particle theory.\n\n\n== Mechanism ==\n\nIn classical physics diffraction arises because of the way in which waves propagate; this is described by the Huygens\u2013Fresnel principle and the principle of superposition of waves. The propagation of a wave can be visualized by considering every particle of the transmitted medium on a wavefront as a point source for a secondary spherical wave. The wave displacement at any subsequent point is the sum of these secondary waves. When waves are added together, their sum is determined by the relative phases as well as the amplitudes of the individual waves so that the summed amplitude of the waves can have any value between zero and the sum of the individual amplitudes.  Hence, diffraction patterns usually have a series of maxima and minima.\nIn the modern quantum mechanical understanding of light propagation through a slit (or slits) every photon has what is known as a wavefunction.  The wavefunction is determined by the physical surroundings such as slit geometry, screen distance and initial conditions when the photon is created.  In important experiments (A low-intensity double-slit experiment was first performed by G. I. Taylor in 1909, see double-slit experiment) the existence of the photon's wavefunction was demonstrated.  In the quantum approach the diffraction pattern is created by the probability distribution, the observation of light and dark bands is the presence or absence of photons in these areas, where these particles were more or less likely to be detected.  The quantum approach has some striking similarities to the Huygens-Fresnel principle; based on that principle, as light travels through slits and boundaries, secondary, point light sources are created near or along these obstacles, and the resulting diffraction pattern is going to be the intensity profile based on the collective interference of all these lights sources that have different optical paths. That is similar to considering the limited regions around the slits and boundaries where photons are more likely to originate from, in the quantum formalism, and calculating the probability distribution. This distribution is directly proportional to the intensity, in the classical formalism.\nThere are various analytical models which allow the diffracted field to be calculated, including the Kirchhoff-Fresnel diffraction equation which is derived from the wave equation, the Fraunhofer diffraction approximation of the Kirchhoff equation which applies to the far field, the Fresnel diffraction approximation  which applies to the near field and the Feynman path integral formulation.  Most configurations cannot be solved analytically, but can yield numerical solutions through finite element and boundary element methods.\nIt is possible to obtain a qualitative understanding of many diffraction phenomena by considering how the relative phases of the individual secondary wave sources vary, and in particular, the conditions in which the phase difference equals half a cycle in which case waves will cancel one another out.\nThe simplest descriptions of diffraction are those in which the situation can be reduced to a two-dimensional problem. For water waves, this is already the case; water waves propagate only on the surface of the water. For light, we can often neglect one direction if the diffracting object extends in that direction over a distance far greater than the wavelength. In the case of light shining through small circular holes we will have to take into account the full three-dimensional nature of the problem.\n\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n== Examples ==\n\nThe effects of diffraction are often seen in everyday life. The most striking examples of diffraction are those that involve light; for example, the closely spaced tracks on a CD or DVD act as a diffraction grating to form the familiar rainbow pattern seen when looking at a disc. This principle can be extended to engineer a grating with a structure such that it will produce any diffraction pattern desired; the hologram on a credit card is an example. Diffraction in the atmosphere by small particles can cause a bright ring to be visible around a bright light source  like the sun or the moon. A shadow of a solid object, using light from a compact source, shows small fringes near its edges. The speckle pattern which is observed when laser light falls on an optically rough surface is also a diffraction phenomenon.  When deli meat appears to be iridescent, that is diffraction off the meat fibers. All these effects are a consequence of the fact that light propagates as a wave.\nDiffraction can occur with any kind of wave. Ocean waves diffract around jetties and other obstacles. Sound waves can diffract around objects, which is why one can still hear someone calling even when hiding behind a tree.\nDiffraction can also be a concern in some technical applications; it sets a fundamental limit to the resolution of a camera, telescope, or microscope.\nOther examples of diffraction are considered below.\n\n\n=== Single-slit diffraction ===\n\n \n\nA long slit of infinitesimal width which is illuminated by light diffracts the light into a series of circular waves and the wavefront which emerges from the slit is a cylindrical wave of uniform intensity, in accordance with Huygens\u2013Fresnel principle.\nAn illuminated slit that is wider than a wavelength produces interference effects in the space downstream of the slit.  Assuming that the slit behaves as though it has a large number of point sources spaced evenly across the width of the slit interference effects can be calculated. The analysis of this system is simplified if we consider light of a single wavelength. If the incident light is coherent, these sources all have the same phase.  Light incident at a given point in the space downstream of the slit is made up of contributions from each of these point sources and if the relative phases of these contributions vary by \n  \n    \n      \n        2\n        \u03c0\n      \n    \n    {\\displaystyle 2\\pi }\n   or more, we may expect to find minima and maxima in the diffracted light. Such phase differences are caused by differences in the path lengths over which contributing rays reach the point from the slit.\nWe can find the angle at which a first minimum is obtained in the diffracted light by the following reasoning. The light from a source located at the top edge of the slit interferes destructively with a source located at the middle of the slit, when the path difference between them is equal to \u03bb/2. Similarly, the source just below the top of the slit will interfere destructively with the source located just below the middle of the slit at the same angle. We can continue this reasoning along the entire height of the slit to conclude that the condition for destructive interference for the entire slit is the same as the condition for destructive interference between two narrow slits a distance apart that is half the width of the slit. The path difference is approximately \n  \n    \n      \n        \n          \n            \n              d\n              sin\n              \u2061\n              (\n              \u03b8\n              )\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {d\\sin(\\theta )}{2}}}\n   so that the minimum intensity occurs at an angle \n  \n    \n      \n        \n          \u03b8\n          \n            m\n            i\n            n\n          \n        \n      \n    \n    {\\displaystyle \\theta _{min}}\n   given by\n\n  \n    \n      \n        d\n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            min\n          \n        \n        =\n        \u03bb\n      \n    \n    {\\displaystyle d\\,\\sin \\theta _{\\text{min}}=\\lambda }\n  where\n\n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   is the width of the slit,\n\n  \n    \n      \n        \n          \u03b8\n          \n            min\n          \n        \n      \n    \n    {\\displaystyle \\theta _{\\text{min}}}\n   is the angle of incidence at which the minimum intensity occurs, and\n\n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is the wavelength of the lightA similar argument can be used to show that if we imagine the slit to be divided into four, six, eight parts, etc., minima are obtained at angles \n  \n    \n      \n        \n          \u03b8\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\theta _{n}}\n   given by\n\n  \n    \n      \n        d\n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            n\n          \n        \n        =\n        n\n        \u03bb\n      \n    \n    {\\displaystyle d\\,\\sin \\theta _{n}=n\\lambda }\n  where\n\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is an integer other than zero.There is no such simple argument to enable us to find the maxima of the diffraction pattern. The intensity profile can be calculated using the Fraunhofer diffraction equation as\n\n  \n    \n      \n        I\n        (\n        \u03b8\n        )\n        =\n        \n          I\n          \n            0\n          \n        \n        \n        \n          sinc\n          \n            2\n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                \n                  d\n                  \u03c0\n                \n                \u03bb\n              \n            \n            sin\n            \u2061\n            \u03b8\n          \n          )\n        \n      \n    \n    {\\displaystyle I(\\theta )=I_{0}\\,\\operatorname {sinc} ^{2}\\left({\\frac {d\\pi }{\\lambda }}\\sin \\theta \\right)}\n  where\n\n  \n    \n      \n        I\n        (\n        \u03b8\n        )\n      \n    \n    {\\displaystyle I(\\theta )}\n   is the intensity at a given angle,\n\n  \n    \n      \n        \n          I\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle I_{0}}\n   is the intensity at the central maximum (\n  \n    \n      \n        \u03b8\n        =\n        0\n      \n    \n    {\\displaystyle \\theta =0}\n  ), which is also a normalization factor of the intensity profile that can be determined by an integration from \n  \n    \n      \n        \u03b8\n        =\n        \u2212\n        \n          \n            \u03c0\n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta =-{\\frac {\\pi }{2}}}\n   to \n  \n    \n      \n        \u03b8\n        =\n        \n          \n            \u03c0\n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta ={\\frac {\\pi }{2}}}\n   and conservation of energy.\n\n  \n    \n      \n        sinc\n        \u2061\n        (\n        x\n        )\n        =\n        \n          \n            {\n            \n              \n                \n                  \n                    \n                      \n                        sin\n                        \u2061\n                        x\n                      \n                      x\n                    \n                  \n                  ,\n                \n                \n                  x\n                  \u2260\n                  0\n                \n              \n              \n                \n                  1\n                  ,\n                \n                \n                  x\n                  =\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\operatorname {sinc} (x)={\\begin{cases}{\\frac {\\sin x}{x}},&x\\neq 0\\\\1,&x=0\\end{cases}}}\n   is the unnormalized sinc function.This analysis applies only to the far field (Fraunhofer diffraction), that is, at a distance much larger than the width of the slit.\nFrom the intensity profile above, if \n  \n    \n      \n        d\n        \u226a\n        \u03bb\n      \n    \n    {\\displaystyle d\\ll \\lambda }\n  , the intensity will have little dependency on \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n  , hence the wavefront emerging from the slit would resemble a cylindrical wave with azimuthal symmetry; If \n  \n    \n      \n        d\n        \u226b\n        \u03bb\n      \n    \n    {\\displaystyle d\\gg \\lambda }\n  , only \n  \n    \n      \n        \u03b8\n        \u2248\n        0\n      \n    \n    {\\displaystyle \\theta \\approx 0}\n   would have appreciable intensity, hence the wavefront emerging from the slit would resemble that of geometrical optics.\nWhen the incident angle \n  \n    \n      \n        \n          \u03b8\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\theta _{\\text{i}}}\n   of the light onto the slit is non-zero (which causes a change in the path length), the intensity profile in the Fraunhofer regime (i.e. far field) becomes:\n\n  \n    \n      \n        I\n        (\n        \u03b8\n        )\n        =\n        \n          I\n          \n            0\n          \n        \n        \n        \n          sinc\n          \n            2\n          \n        \n        \u2061\n        \n          [\n          \n            \n              \n                \n                  d\n                  \u03c0\n                \n                \u03bb\n              \n            \n            (\n            sin\n            \u2061\n            \u03b8\n            \u00b1\n            sin\n            \u2061\n            \n              \u03b8\n              \n                i\n              \n            \n            )\n          \n          ]\n        \n      \n    \n    {\\displaystyle I(\\theta )=I_{0}\\,\\operatorname {sinc} ^{2}\\left[{\\frac {d\\pi }{\\lambda }}(\\sin \\theta \\pm \\sin \\theta _{i})\\right]}\n  \nThe choice of plus/minus sign depends on the definition of the incident angle \n  \n    \n      \n        \n          \u03b8\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\theta _{\\text{i}}}\n  .\n\n\n=== Diffraction grating ===\n\nA diffraction grating is an optical component with a regular pattern. The form of the light diffracted by a grating depends on the structure of the elements and the number of elements present, but all gratings have intensity maxima at angles \u03b8m which are given by the grating equation\n\n  \n    \n      \n        d\n        \n          (\n          \n            sin\n            \u2061\n            \n              \n                \u03b8\n                \n                  m\n                \n              \n            \n            \u00b1\n            sin\n            \u2061\n            \n              \n                \u03b8\n                \n                  i\n                \n              \n            \n          \n          )\n        \n        =\n        m\n        \u03bb\n        .\n      \n    \n    {\\displaystyle d\\left(\\sin {\\theta _{m}}\\pm \\sin {\\theta _{i}}\\right)=m\\lambda .}\n  where\n\n  \n    \n      \n        \n          \u03b8\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\theta _{i}}\n   is the angle at which the light is incident,\n\n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   is the separation of grating elements, and\n\n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is an integer which can be positive or negative.The light diffracted by a grating is found by summing the light diffracted from each of the elements, and is essentially a convolution of diffraction and interference patterns.\nThe figure shows the light diffracted by 2-element and 5-element gratings where the grating spacings are the same; it can be seen that the maxima are in the same position, but the detailed structures of the intensities are different.\n\n\n=== Circular aperture ===\n\nThe far-field diffraction of a plane wave incident on a circular aperture is often referred to as the Airy Disk.  The variation in intensity with angle is given by\n\n  \n    \n      \n        I\n        (\n        \u03b8\n        )\n        =\n        \n          I\n          \n            0\n          \n        \n        \n          \n            (\n            \n              \n                \n                  2\n                  \n                    J\n                    \n                      1\n                    \n                  \n                  (\n                  k\n                  a\n                  sin\n                  \u2061\n                  \u03b8\n                  )\n                \n                \n                  k\n                  a\n                  sin\n                  \u2061\n                  \u03b8\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle I(\\theta )=I_{0}\\left({\\frac {2J_{1}(ka\\sin \\theta )}{ka\\sin \\theta }}\\right)^{2}}\n  ,where a is the radius of the circular aperture, k is equal to 2\u03c0/\u03bb and J1 is a Bessel function.  The smaller the aperture, the larger the spot size at a given distance, and the greater the divergence of the diffracted beams.\n\n\n=== General aperture ===\nThe wave that emerges from a point source has amplitude \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n   at location r that is given by the solution of the frequency domain wave equation for a point source (the Helmholtz equation),\n\n  \n    \n      \n        \n          \u2207\n          \n            2\n          \n        \n        \u03c8\n        +\n        \n          k\n          \n            2\n          \n        \n        \u03c8\n        =\n        \u03b4\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle \\nabla ^{2}\\psi +k^{2}\\psi =\\delta (\\mathbf {r} )}\n  where \n  \n    \n      \n        \u03b4\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle \\delta (\\mathbf {r} )}\n   is the 3-dimensional delta function.  The delta function has only radial dependence, so the Laplace operator (a.k.a. scalar Laplacian) in the spherical coordinate system simplifies to (see del in cylindrical and spherical coordinates)\n\n  \n    \n      \n        \n          \u2207\n          \n            2\n          \n        \n        \u03c8\n        =\n        \n          \n            1\n            r\n          \n        \n        \n          \n            \n              \u2202\n              \n                2\n              \n            \n            \n              \u2202\n              \n                r\n                \n                  2\n                \n              \n            \n          \n        \n        (\n        r\n        \u03c8\n        )\n      \n    \n    {\\displaystyle \\nabla ^{2}\\psi ={\\frac {1}{r}}{\\frac {\\partial ^{2}}{\\partial r^{2}}}(r\\psi )}\n  By direct substitution, the solution to this equation can be readily shown to be the scalar Green's function, which in the spherical coordinate system (and using the physics time convention \n  \n    \n      \n        \n          e\n          \n            \u2212\n            i\n            \u03c9\n            t\n          \n        \n      \n    \n    {\\displaystyle e^{-i\\omega t}}\n  ) is:\n\n  \n    \n      \n        \u03c8\n        (\n        r\n        )\n        =\n        \n          \n            \n              e\n              \n                i\n                k\n                r\n              \n            \n            \n              4\n              \u03c0\n              r\n            \n          \n        \n      \n    \n    {\\displaystyle \\psi (r)={\\frac {e^{ikr}}{4\\pi r}}}\n  This solution assumes that the delta function source is located at the origin.  If the source is located at an arbitrary source point, denoted by the vector \n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {r} '}\n   and the field point is located at the point \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n  , then we may represent the scalar Green's function (for arbitrary source location) as:\n\n  \n    \n      \n        \u03c8\n        (\n        \n          r\n        \n        \n          |\n        \n        \n          \n            r\n          \n          \u2032\n        \n        )\n        =\n        \n          \n            \n              e\n              \n                i\n                k\n                \n                  |\n                \n                \n                  r\n                \n                \u2212\n                \n                  \n                    r\n                  \n                  \u2032\n                \n                \n                  |\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                |\n              \n              \n                r\n              \n              \u2212\n              \n                \n                  r\n                \n                \u2032\n              \n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\psi (\\mathbf {r} |\\mathbf {r} ')={\\frac {e^{ik|\\mathbf {r} -\\mathbf {r} '|}}{4\\pi |\\mathbf {r} -\\mathbf {r} '|}}}\n  Therefore, if an electric field, Einc(x,y) is incident on the aperture, the field produced by this aperture distribution is given by the surface integral:\n\n  \n    \n      \n        \u03a8\n        (\n        r\n        )\n        \u221d\n        \n          \u222c\n          \n            \n              a\n              p\n              e\n              r\n              t\n              u\n              r\n              e\n            \n          \n        \n        \n          E\n          \n            \n              i\n              n\n              c\n            \n          \n        \n        (\n        \n          x\n          \u2032\n        \n        ,\n        \n          y\n          \u2032\n        \n        )\n         \n        \n          \n            \n              e\n              \n                i\n                k\n                \n                  |\n                \n                \n                  r\n                \n                \u2212\n                \n                  \n                    r\n                  \n                  \u2032\n                \n                \n                  |\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                |\n              \n              \n                r\n              \n              \u2212\n              \n                \n                  r\n                \n                \u2032\n              \n              \n                |\n              \n            \n          \n        \n        \n        d\n        \n          x\n          \u2032\n        \n        \n        d\n        \n          y\n          \u2032\n        \n        ,\n      \n    \n    {\\displaystyle \\Psi (r)\\propto \\iint \\limits _{\\mathrm {aperture} }E_{\\mathrm {inc} }(x',y')~{\\frac {e^{ik|\\mathbf {r} -\\mathbf {r} '|}}{4\\pi |\\mathbf {r} -\\mathbf {r} '|}}\\,dx'\\,dy',}\n  \nwhere the source point in the aperture is given by the vector\n\n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n        =\n        \n          x\n          \u2032\n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n        +\n        \n          y\n          \u2032\n        \n        \n          \n            \n              y\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} '=x'\\mathbf {\\hat {x}} +y'\\mathbf {\\hat {y}} }\n  In the far field, wherein the parallel rays approximation can be employed, the Green's function,\n\n  \n    \n      \n        \u03c8\n        (\n        \n          r\n        \n        \n          |\n        \n        \n          \n            r\n          \n          \u2032\n        \n        )\n        =\n        \n          \n            \n              e\n              \n                i\n                k\n                \n                  |\n                \n                \n                  r\n                \n                \u2212\n                \n                  \n                    r\n                  \n                  \u2032\n                \n                \n                  |\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                |\n              \n              \n                r\n              \n              \u2212\n              \n                \n                  r\n                \n                \u2032\n              \n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\psi (\\mathbf {r} |\\mathbf {r} ')={\\frac {e^{ik|\\mathbf {r} -\\mathbf {r} '|}}{4\\pi |\\mathbf {r} -\\mathbf {r} '|}}}\n  simplifies to\n\n  \n    \n      \n        \u03c8\n        (\n        \n          r\n        \n        \n          |\n        \n        \n          \n            r\n          \n          \u2032\n        \n        )\n        =\n        \n          \n            \n              e\n              \n                i\n                k\n                r\n              \n            \n            \n              4\n              \u03c0\n              r\n            \n          \n        \n        \n          e\n          \n            \u2212\n            i\n            k\n            (\n            \n              \n                r\n              \n              \u2032\n            \n            \u22c5\n            \n              \n                \n                  r\n                  ^\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle \\psi (\\mathbf {r} |\\mathbf {r} ')={\\frac {e^{ikr}}{4\\pi r}}e^{-ik(\\mathbf {r} '\\cdot \\mathbf {\\hat {r}} )}}\n  as can be seen in the figure to the right (click to enlarge).\nThe expression for the far-zone (Fraunhofer region) field becomes\n\n  \n    \n      \n        \u03a8\n        (\n        r\n        )\n        \u221d\n        \n          \n            \n              e\n              \n                i\n                k\n                r\n              \n            \n            \n              4\n              \u03c0\n              r\n            \n          \n        \n        \n          \u222c\n          \n            \n              a\n              p\n              e\n              r\n              t\n              u\n              r\n              e\n            \n          \n        \n        \n          E\n          \n            \n              i\n              n\n              c\n            \n          \n        \n        (\n        \n          x\n          \u2032\n        \n        ,\n        \n          y\n          \u2032\n        \n        )\n        \n          e\n          \n            \u2212\n            i\n            k\n            (\n            \n              \n                r\n              \n              \u2032\n            \n            \u22c5\n            \n              \n                \n                  r\n                  ^\n                \n              \n            \n            )\n          \n        \n        \n        d\n        \n          x\n          \u2032\n        \n        \n        d\n        \n          y\n          \u2032\n        \n        ,\n      \n    \n    {\\displaystyle \\Psi (r)\\propto {\\frac {e^{ikr}}{4\\pi r}}\\iint \\limits _{\\mathrm {aperture} }E_{\\mathrm {inc} }(x',y')e^{-ik(\\mathbf {r} '\\cdot \\mathbf {\\hat {r}} )}\\,dx'\\,dy',}\n  Now, since\n\n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n        =\n        \n          x\n          \u2032\n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n        +\n        \n          y\n          \u2032\n        \n        \n          \n            \n              y\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} '=x'\\mathbf {\\hat {x}} +y'\\mathbf {\\hat {y}} }\n  and\n\n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n        =\n        sin\n        \u2061\n        \u03b8\n        cos\n        \u2061\n        \u03d5\n        \n          \n            \n              x\n              ^\n            \n          \n        \n        +\n        sin\n        \u2061\n        \u03b8\n         \n        sin\n        \u2061\n        \u03d5\n         \n        \n          \n            \n              y\n              ^\n            \n          \n        \n        +\n        cos\n        \u2061\n        \u03b8\n        \n          \n            \n              z\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} =\\sin \\theta \\cos \\phi \\mathbf {\\hat {x}} +\\sin \\theta ~\\sin \\phi ~\\mathbf {\\hat {y}} +\\cos \\theta \\mathbf {\\hat {z}} }\n  the expression for the Fraunhofer region field from a planar aperture now becomes,\n\n  \n    \n      \n        \u03a8\n        (\n        r\n        )\n        \u221d\n        \n          \n            \n              e\n              \n                i\n                k\n                r\n              \n            \n            \n              4\n              \u03c0\n              r\n            \n          \n        \n        \n          \u222c\n          \n            \n              a\n              p\n              e\n              r\n              t\n              u\n              r\n              e\n            \n          \n        \n        \n          E\n          \n            \n              i\n              n\n              c\n            \n          \n        \n        (\n        \n          x\n          \u2032\n        \n        ,\n        \n          y\n          \u2032\n        \n        )\n        \n          e\n          \n            \u2212\n            i\n            k\n            sin\n            \u2061\n            \u03b8\n            (\n            cos\n            \u2061\n            \u03d5\n            \n              x\n              \u2032\n            \n            +\n            sin\n            \u2061\n            \u03d5\n            \n              y\n              \u2032\n            \n            )\n          \n        \n        \n        d\n        \n          x\n          \u2032\n        \n        \n        d\n        \n          y\n          \u2032\n        \n      \n    \n    {\\displaystyle \\Psi (r)\\propto {\\frac {e^{ikr}}{4\\pi r}}\\iint \\limits _{\\mathrm {aperture} }E_{\\mathrm {inc} }(x',y')e^{-ik\\sin \\theta (\\cos \\phi x'+\\sin \\phi y')}\\,dx'\\,dy'}\n  Letting,\n\n  \n    \n      \n        \n          k\n          \n            x\n          \n        \n        =\n        k\n        sin\n        \u2061\n        \u03b8\n        cos\n        \u2061\n        \u03d5\n        \n        \n      \n    \n    {\\displaystyle k_{x}=k\\sin \\theta \\cos \\phi \\,\\!}\n  and\n\n  \n    \n      \n        \n          k\n          \n            y\n          \n        \n        =\n        k\n        sin\n        \u2061\n        \u03b8\n        sin\n        \u2061\n        \u03d5\n        \n        \n      \n    \n    {\\displaystyle k_{y}=k\\sin \\theta \\sin \\phi \\,\\!}\n  the Fraunhofer region field of the planar aperture assumes the form of a Fourier transform\n\n  \n    \n      \n        \u03a8\n        (\n        r\n        )\n        \u221d\n        \n          \n            \n              e\n              \n                i\n                k\n                r\n              \n            \n            \n              4\n              \u03c0\n              r\n            \n          \n        \n        \n          \u222c\n          \n            \n              a\n              p\n              e\n              r\n              t\n              u\n              r\n              e\n            \n          \n        \n        \n          E\n          \n            \n              i\n              n\n              c\n            \n          \n        \n        (\n        \n          x\n          \u2032\n        \n        ,\n        \n          y\n          \u2032\n        \n        )\n        \n          e\n          \n            \u2212\n            i\n            (\n            \n              k\n              \n                x\n              \n            \n            \n              x\n              \u2032\n            \n            +\n            \n              k\n              \n                y\n              \n            \n            \n              y\n              \u2032\n            \n            )\n          \n        \n        \n        d\n        \n          x\n          \u2032\n        \n        \n        d\n        \n          y\n          \u2032\n        \n        ,\n      \n    \n    {\\displaystyle \\Psi (r)\\propto {\\frac {e^{ikr}}{4\\pi r}}\\iint \\limits _{\\mathrm {aperture} }E_{\\mathrm {inc} }(x',y')e^{-i(k_{x}x'+k_{y}y')}\\,dx'\\,dy',}\n  In the far-field / Fraunhofer region, this becomes the spatial Fourier transform of the aperture distribution.  Huygens' principle when applied to an aperture simply says that the far-field diffraction pattern is the spatial Fourier transform of the aperture shape, and this is a direct by-product of using the parallel-rays approximation, which is identical to doing a plane wave decomposition of the aperture plane fields (see Fourier optics).\n\n\n=== Propagation of a laser beam ===\nThe way in which the beam profile of a laser beam changes as it propagates is determined by diffraction. When the entire emitted beam has a planar, spatially coherent wave front, it approximates Gaussian beam profile and has the lowest divergence for a given diameter. The smaller the output beam, the quicker it diverges. It is possible to reduce the divergence of a laser beam by first expanding it with one convex lens, and then collimating it with a second convex lens whose focal point is coincident with that of the first lens. The resulting beam has a larger diameter, and hence a lower divergence. Divergence of a laser beam may be reduced below the diffraction of a Gaussian beam or even reversed to convergence if the refractive index of the propagation media increases with the light intensity. This may result in a self-focusing effect.\nWhen the wave front of the emitted beam has perturbations, only the transverse coherence length (where the wave front perturbation is less than 1/4 of the wavelength) should be considered as a Gaussian beam diameter when determining the divergence of the laser beam. If the transverse coherence length in the vertical direction is higher than in horizontal, the laser beam divergence will be lower in the vertical direction than in the horizontal.\n\n\n=== Diffraction-limited imaging ===\n\nThe ability of an imaging system to resolve detail is ultimately limited by diffraction.  This is because a plane wave incident on a circular lens or mirror is diffracted as described above. The light is not focused to a point but forms an Airy disk having a central spot in the focal plane whose radius (as measured to the first null) is\n\n  \n    \n      \n        \u0394\n        x\n        =\n        1.22\n        \u03bb\n        N\n      \n    \n    {\\displaystyle \\Delta x=1.22\\lambda N}\n  where \u03bb is the wavelength of the light and N is the f-number (focal length f divided by aperture diameter D) of the imaging optics; this is strictly accurate for N\u226b1 (paraxial case).  In object space, the corresponding angular resolution is\n\n  \n    \n      \n        \u03b8\n        \u2248\n        sin\n        \u2061\n        \u03b8\n        =\n        1.22\n        \n          \n            \u03bb\n            D\n          \n        \n        ,\n        \n      \n    \n    {\\displaystyle \\theta \\approx \\sin \\theta =1.22{\\frac {\\lambda }{D}},\\,}\n  where D is the diameter of the entrance pupil of the imaging lens (e.g., of a telescope's main mirror).\nTwo point sources will each produce an Airy pattern \u2013 see the photo of a binary star.  As the point sources move closer together, the patterns will start to overlap, and ultimately they will merge to form a single pattern, in which case the two point sources cannot be resolved in the image.  The Rayleigh criterion specifies that two point sources are considered \"resolved\" if the separation of the two images is at least the radius of the Airy disk, i.e. if the first minimum of one coincides with the maximum of the other.\nThus, the larger the aperture of the lens compared to the wavelength, the finer the resolution of an imaging system. This is one reason astronomical telescopes require large objectives, and why microscope objectives require a large numerical aperture (large aperture diameter compared to working distance) in order to obtain the highest possible resolution.\n\n\n=== Speckle patterns ===\n\nThe speckle pattern seen when using a laser pointer is another diffraction phenomenon. It is a result of the superposition of many waves with different phases, which are produced when a laser beam illuminates a rough surface. They add together to give a resultant wave whose amplitude, and therefore intensity, varies randomly.\n\n\n=== Babinet's principle ===\n\nBabinet's principle is a useful theorem stating that the diffraction pattern from an opaque body is identical to that from a hole of the same size and shape, but with differing intensities. This means that the interference conditions of a single obstruction would be the same as that of a single slit.\n\n\n=== \"Knife edge\" ===\nThe knife-edge effect or knife-edge diffraction is a truncation of a portion of the incident radiation that strikes a sharp well-defined obstacle, such as a mountain range or the wall of a building.\nThe knife-edge effect is explained by Huygens\u2013Fresnel principle, which states that a well-defined obstruction to an electromagnetic wave acts as a secondary source, and creates a new wavefront. This new wavefront propagates into the geometric shadow area of the obstacle.\nKnife-edge diffraction is an outgrowth of the \"half-plane problem\", originally solved by Arnold Sommerfeld using a plane wave spectrum formulation.  A generalization of the half-plane problem is the \"wedge problem\", solvable as a boundary value problem in cylindrical coordinates. The solution in cylindrical coordinates was then extended to the optical regime by Joseph B. Keller, who introduced the notion of diffraction coefficients through his geometrical theory of diffraction (GTD).  Pathak and Kouyoumjian extended the (singular) Keller coefficients via the uniform theory of diffraction (UTD).\n\n\t\t\n\n\n== Patterns ==\n\nSeveral qualitative observations can be made of diffraction in general:\n\nThe angular spacing of the features in the diffraction pattern is inversely proportional to the dimensions of the object causing the diffraction. In other words: The smaller the diffracting object, the 'wider' the resulting diffraction pattern, and vice versa. (More precisely, this is true of the sines of the angles.)\nThe diffraction angles are invariant under scaling; that is, they depend only on the ratio of the wavelength to the size of the diffracting object.\nWhen the diffracting object has a periodic structure, for example in a diffraction grating, the features generally become sharper. The third figure, for example, shows a comparison of a double-slit pattern with a pattern formed by five slits, both sets of slits having the same spacing, between the center of one slit and the next.\n\n\n== Particle diffraction ==\n\nAccording to quantum theory every particle exhibits wave properties. In particular, massive particles can interfere with themselves and therefore diffract. Diffraction of electrons and neutrons stood as one of the powerful arguments in favor of quantum mechanics. The wavelength associated with a particle is the de Broglie wavelength\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            h\n            p\n          \n        \n        \n      \n    \n    {\\displaystyle \\lambda ={\\frac {h}{p}}\\,}\n  where h is Planck's constant and p is the momentum of the particle (mass \u00d7 velocity for slow-moving particles).\nFor most macroscopic objects, this wavelength is so short that it is not meaningful to assign a wavelength to them.  A sodium atom traveling at about 300 m/s would have a De Broglie wavelength of about 50 picometres.\nBecause the wavelength for even the smallest of macroscopic objects is extremely small, diffraction of matter waves is only visible for small particles, like electrons, neutrons, atoms and small molecules. The short wavelength of these matter waves makes them ideally suited to study the atomic crystal structure of solids and large molecules like proteins.\nRelatively larger molecules like buckyballs were also shown to diffract.\n\n\n== Bragg diffraction ==\n\nDiffraction from a large three-dimensional periodic structure such as many thousands of atoms in a crystal is called Bragg diffraction.\nIt is similar to what occurs when waves are scattered from a diffraction grating. Bragg diffraction is a consequence of interference between waves reflecting from many different crystal planes.\nThe condition of constructive interference is given by Bragg's law:\n\n  \n    \n      \n        m\n        \u03bb\n        =\n        2\n        d\n        sin\n        \u2061\n        \u03b8\n      \n    \n    {\\displaystyle m\\lambda =2d\\sin \\theta }\n  where\n\n\u03bb is the wavelength,\nd is the distance between crystal planes,\n\u03b8 is the angle of the diffracted wave.\nand m is an integer known as the order of the diffracted beam.Bragg diffraction may be carried out using either electromagnetic radiation of very short wavelength like X-rays or matter waves like neutrons (and electrons) whose wavelength is on the order of (or much smaller than) the atomic spacing. The pattern produced gives information of the separations of crystallographic planes d, allowing one to deduce the crystal structure.  Diffraction contrast, in electron microscopes and x-topography devices are powerful tool for examining individual defects and local strain fields in crystals.\nFor completeness, Bragg diffraction is a limit for a large number of atoms with X-rays or neutrons, and is rarely valid for electron diffraction or with solid particles in the size range of less than 50 nanometers.\n\n\n== Coherence ==\n\nThe description of diffraction relies on the interference of waves emanating from the same source taking different paths to the same point on a screen. In this description, the difference in phase between waves that took different paths is only dependent on the effective path length. This does not take into account the fact that waves that arrive at the screen at the same time were emitted by the source at different times. The initial phase with which the source emits waves can change over time in an unpredictable way. This means that waves emitted by the source at times that are too far apart can no longer form a constant interference pattern since the relation between their phases is no longer time independent.:\u200a919\u200aThe length over which the phase in a beam of light is correlated, is called the coherence length. In order for interference to occur, the path length difference must be smaller than the coherence length. This is sometimes referred to as spectral coherence, as it is related to the presence of different frequency components in the wave. In the case of light emitted by an atomic transition, the coherence length is related to the lifetime of the excited state from which the atom made its transition.:\u200a71\u201374\u200a:\u200a314\u2013316\u200aIf waves are emitted from an extended source, this can lead to incoherence in the transversal direction. When looking at a cross section of a beam of light, the length over which the phase is correlated is called the transverse coherence length. In the case of Young's double slit experiment, this would mean that if the transverse coherence length is smaller than the spacing between the two slits, the resulting pattern on a screen would look like two single slit diffraction patterns.:\u200a74\u201379\u200aIn the case of particles like electrons, neutrons, and atoms, the coherence length is related to the spatial extent of the wave function that describes the particle.:\u200a107\u200a\n\n\n== Applications ==\n\n\n=== Diffraction before destruction ===\nA new way to image single biological particles has emerged since the 2010s, utilising the bright X-rays generated by X-ray free electron lasers. These femtosecond-duration pulses will allow for the (potential) imaging of single biological macromolecules. Due to these short pulses, radiation damage can be outrun, and diffraction patterns of single biological macromolecules will be able to be obtained.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nThe Feynman Lectures on Physics Vol. I Ch. 30: Diffraction\n\"Scattering and diffraction\". Crystallography. International Union of Crystallography.", "Intensity_(physics)": "In physics, the intensity or flux of radiant energy is the power transferred per unit area, where the area is measured on the plane perpendicular to the direction of propagation of the energy. In the SI system, it has units watts per square metre (W/m2), or kg\u22c5s\u22123 in base units. Intensity is used most frequently with waves such as acoustic waves (sound) or electromagnetic waves such as light or radio waves, in which case the average power transfer over one period of the wave is used. Intensity can be applied to other circumstances where energy is transferred. For example, one could calculate the intensity of the kinetic energy carried by drops of water from a garden sprinkler.\nThe word \"intensity\" as used here is not synonymous with \"strength\", \"amplitude\", \"magnitude\", or \"level\", as it sometimes is in colloquial speech.\nIntensity can be found by taking the energy density (energy per unit volume) at a point in space and multiplying it by the velocity at which the energy is moving. The resulting vector has the units of power divided by area (i.e., surface power density). The intensity of a wave is proportional to the square of its amplitude. For example, the intensity of an electromagnetic wave is proportional to the square of the wave's electric field amplitude.\n\n\n== Mathematical description ==\nIf a point source is radiating energy in all directions (producing a spherical wave), and no energy is absorbed or scattered by the medium, then the intensity decreases in proportion to the distance from the object squared. This is an example of the inverse-square law.\nApplying the law of conservation of energy, if the net power emanating is constant,\n\nwhere P is the net power radiated, I is the intensity vector as a function of position, the magnitude |I| is the intensity as a function of position, and dA is a differential element of a closed surface that contains the source.\nIf one integrates a uniform intensity, |I| = constant, over a surface that is perpendicular to the intensity vector, for instance over a sphere centered around the point source, the equation becomes\n\nwhere |I| is the intensity at the surface of the sphere, r is the radius of the sphere, and \n  \n    \n      \n        \n          A\n          \n            \n              s\n              u\n              r\n              f\n            \n          \n        \n        =\n        4\n        \u03c0\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle A_{\\mathrm {surf} }=4\\pi r^{2}}\n   is the expression for the surface area of a sphere.\nSolving for |I| gives\n\nIf the medium is damped, then the intensity drops off more quickly than the above equation suggests.\nAnything that can transmit energy can have an intensity associated with it. For a monochromatic propagating electromagnetic wave, such as a plane wave or a Gaussian beam, if E is the complex amplitude of the electric field, then the time-averaged energy density of the wave, travelling in a non-magnetic material, is given by:\n\nand the local intensity is obtained by multiplying this expression by the wave velocity, c/n:\n\nwhere n is the refractive index, c is the speed of light in vacuum and \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   is the vacuum permittivity.\nFor non-monochromatic waves, the intensity contributions of different spectral components can simply be added. The treatment above does not hold for arbitrary electromagnetic fields. For example, an evanescent wave may have a finite electrical amplitude while not transferring any power. The intensity should then be defined as the magnitude of the Poynting vector.\n\n\n== Alternative definitions ==\nIn photometry and radiometry intensity has a different meaning: it is the luminous or radiant power per unit solid angle. This can cause confusion in optics, where intensity can mean any of radiant intensity, luminous intensity or irradiance, depending on the background of the person using the term. Radiance is also sometimes called intensity, especially by astronomers and astrophysicists, and in heat transfer.\n\n\n== See also ==\nField strength\nSound intensity\nMagnitude (astronomy)\n\n\n== References ==", "Electrical_conductor": "In physics and electrical engineering, a conductor is an object or type of material that allows the flow of charge (electric current) in one or more directions. Materials made of metal are common electrical conductors. Electric current is generated by the flow of negatively charged electrons, positively charged holes, and positive or negative ions in some cases. \nIn order for current to flow within a closed electrical circuit, it is not necessary for one charged particle to travel from the component producing the current (the current source) to those consuming it (the loads). Instead, the charged particle simply needs to nudge its neighbor a finite amount, who will nudge its neighbor, and on and on until a particle is nudged into the consumer, thus powering it. Essentially what is occurring is a long chain of momentum transfer between mobile charge carriers; the Drude model of conduction describes this process more rigorously. This momentum transfer model makes metal an ideal choice for a conductor; metals, characteristically, possess a delocalized sea of electrons which gives the electrons enough mobility to collide and thus affect a momentum transfer. \nAs discussed above, electrons are the primary mover in metals; however, other devices such as the cationic electrolyte(s) of a battery, or the mobile protons of the proton conductor of a fuel cell rely on positive charge carriers. Insulators are non-conducting materials with few mobile charges that support only insignificant electric currents.\n\n\n== Resistance and conductance ==\n\nThe resistance of a given conductor depends on the material it is made of, and on its dimensions. For a given material, the resistance is inversely proportional to the cross-sectional area. For example, a thick copper wire has lower resistance than an otherwise-identical thin copper wire. Also, for a given material, the resistance is proportional to the length; for example, a long copper wire has higher resistance than an otherwise-identical short copper wire. The resistance R and conductance G of a conductor of uniform cross section, therefore, can be computed as\n\n  \n    \n      \n        \n          \n            \n              \n                R\n              \n              \n                \n                =\n                \u03c1\n                \n                  \n                    \u2113\n                    A\n                  \n                \n                ,\n              \n            \n            \n              \n                G\n              \n              \n                \n                =\n                \u03c3\n                \n                  \n                    A\n                    \u2113\n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}R&=\\rho {\\frac {\\ell }{A}},\\\\[6pt]G&=\\sigma {\\frac {A}{\\ell }}.\\end{aligned}}}\n  where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of the conductor, measured in metres [m], A is the cross-section area of the conductor measured in square metres [m2], \u03c3 (sigma) is the electrical conductivity measured in siemens per meter (S\u00b7m\u22121), and \u03c1 (rho) is the electrical resistivity (also called specific electrical resistance) of the material, measured in ohm-metres (\u03a9\u00b7m). The resistivity and conductivity are proportionality constants, and therefore depend only on the material the wire is made of, not the geometry of the wire. Resistivity and conductivity are reciprocals: \n  \n    \n      \n        \u03c1\n        =\n        1\n        \n          /\n        \n        \u03c3\n      \n    \n    {\\displaystyle \\rho =1/\\sigma }\n  . Resistivity is a measure of the material's ability to oppose electric current.\nThis formula is not exact: It assumes the current density is totally uniform in the conductor, which is not always true in practical situation. However, this formula still provides a good approximation for long thin conductors such as wires.\nAnother situation this formula is not exact for is with alternating current (AC), because the skin effect inhibits current flow near the center of the conductor. Then, the geometrical cross-section is different from the effective cross-section in which current actually flows, so the resistance is higher than expected. Similarly, if two conductors are near each other carrying AC current, their resistances increase due to the proximity effect. At commercial power frequency, these  effects are significant for large conductors carrying large currents, such as busbars in an electrical substation, or large power cables carrying more than a few hundred amperes.\nAside from the geometry of the wire, temperature also has a significant effect on the efficacy of conductors. Temperature affects conductors in two main ways, the first is that materials may expand under the application of heat. The amount that the material will expand is governed by the thermal expansion coefficient specific to the material. Such an expansion (or contraction) will change the geometry of the conductor and therefore its characteristic resistance. However, this effect is generally small, on the order of 10\u22126. An increase in temperature will also increase the number of phonons generated within the material. A phonon is essentially a lattice vibration, or rather a small, harmonic kinetic movement of the atoms of the material. Much like the shaking of a pinball machine, phonons serve to disrupt the path of electrons, causing them to scatter. This electron scattering will decrease the number of electron collisions and therefore will decrease the total amount of current transferred.\n\n\n== Conductor materials ==\n\nConduction materials include metals, electrolytes, superconductors, semiconductors, plasmas and some nonmetallic conductors such as graphite and conductive polymers.\nCopper has a high conductivity. Annealed copper is the international standard to which all other electrical conductors are compared; the International Annealed Copper Standard conductivity is 58 MS/m, although ultra-pure copper can slightly exceed 101% IACS.  The main grade of copper used for electrical applications, such as building wire, motor windings, cables and busbars, is electrolytic-tough pitch (ETP) copper (CW004A or ASTM designation C100140).  If high conductivity copper must be welded or brazed or used in a reducing atmosphere, then oxygen-free high conductivity copper (CW008A or ASTM designation C10100) may be used. Because of its ease of connection by soldering or clamping, copper is still the most common choice for most light-gauge wires.\nSilver is 6% more conductive than copper, but due to cost it is not practical in most cases. However, it is used in specialized equipment, such as satellites, and as a thin plating to mitigate skin effect losses at high frequencies.  Famously, 14,700 short tons (13,300 t) of silver on loan from the United States Treasury were used in the making of the calutron magnets during World War II due to wartime shortages of copper. Aluminum wire is the most common metal in electric power transmission and distribution.  Although only 61% of the conductivity of copper by cross-sectional area, its lower density makes it twice as conductive by mass.  As aluminum is roughly one-third the cost of copper by weight, the economic advantages are considerable when large conductors are required.\nThe disadvantages of aluminum wiring lie in its mechanical and chemical properties.  It readily forms an insulating oxide, making connections heat up.  Its larger coefficient of thermal expansion than the brass materials used for connectors causes connections to loosen.  Aluminum can also \"creep\", slowly deforming under load, which also loosens connections.  These effects can be mitigated with suitably designed connectors and extra care in installation, but they have made aluminum building wiring unpopular past the service drop.\nOrganic compounds such as octane, which has 8 carbon atoms and 18 hydrogen atoms, cannot conduct electricity. Oils are hydrocarbons, since  carbon has the property of tetracovalency and forms covalent bonds with other elements such as hydrogen, since it does not lose or gain electrons, thus does not form ions. Covalent bonds are simply the sharing of electrons. Hence, there is no separation of ions when electricity is passed through it. Liquids made of compounds with only covalent bonds cannot conduct electricity. Certain organic ionic liquids, by contrast, can conduct an electric current. \nWhile pure water is not an electrical conductor, even a small portion of ionic impurities, such as salt, can rapidly transform it into a conductor.\n\n\n== Wire size ==\nWires are measured by their cross sectional area. In many countries, the size is expressed in square millimetres. In North America, conductors are measured by American wire gauge for smaller ones, and circular mils for larger ones.\n\n\n== Conductor ampacity ==\nThe ampacity of a conductor, that is, the amount of current it can carry, is related to its electrical resistance: a lower-resistance conductor can carry a larger value of current. The resistance, in turn, is determined by the material the conductor is made from (as described above) and the conductor's size. For a given material, conductors with a larger cross-sectional area have less resistance than conductors with a smaller cross-sectional area.\nFor bare conductors, the ultimate limit is the point at which power lost to resistance causes the conductor to melt. Aside from fuses, most conductors in the real world are operated far below this limit, however. For example, household wiring is usually insulated with PVC insulation that is only rated to operate to about 60 \u00b0C, therefore, the current in such wires must be limited so that it never heats the copper conductor above 60 \u00b0C, causing a risk of fire. Other, more expensive insulation such as Teflon or fiberglass may allow operation at much higher temperatures.\n\n\n== Isotropy ==\nIf an electric field is applied to a material, and the resulting induced electric current is in the same direction, the material is said to be an isotropic electrical conductor.  If the resulting electric current is in a different direction from the applied electric field, the material is said to be an anisotropic electrical conductor.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n=== Pioneering and historical books ===\nWilliam Henry Preece. On Electrical Conductors.  1883.\nOliver Heaviside. Electrical Papers. Macmillan, 1894.\n\n\n=== Reference books ===\nAnnual Book of ASTM Standards: Electrical Conductors. American Society for Testing and Materials. (every year)\nIET Wiring Regulations. Institution for Engineering and Technology. wiringregulations.net\n\n\n== External links ==\nBBC: Key Stage 2 Bitesize: Electrical Conductors\nThe discovery of conductors and insulators by Gray, Dufay and Franklin.", "Crest_(physics)": "A crest point on a wave is the maximum value of upward displacement within a cycle. A crest is a point on a surface wave where the displacement of the medium is at a maximum. A trough is the opposite of a crest, so the minimum or lowest point in a cycle.\nWhen the crests and troughs of two sine waves of equal amplitude and frequency intersect or collide, while being in phase with each other, the result is called constructive interference and the magnitudes double (above and below the line). When in antiphase \u2013 180\u00b0 out of phase \u2013 the result is destructive interference: the resulting wave is the undisturbed line having zero amplitude.\n\n\n== See also ==\nCrest factor\nSuperposition principle\nWave\n\n\n== References ==\nKinsman, Blair (1984), Wind Waves: Their Generation and Propagation on the Ocean Surface, Dover Publications, ISBN 0-486-49511-6, 704 pages.", "Wave": "In physics, mathematics, and related fields, a wave is a propagating dynamic disturbance (change from equilibrium) of one or more quantities. Waves can be periodic, in which case those quantities oscillate repeatedly about an equilibrium (resting) value at some frequency. When the entire waveform moves in one direction, it is said to be a traveling wave; by contrast, a pair of superimposed periodic waves traveling in opposite directions makes a standing wave. In a standing wave, the amplitude of vibration has nulls at some positions where the wave amplitude appears smaller or even zero. Waves are often described by a wave equation (standing wave field of two opposite waves) or a one-way wave equation for single wave propagation in a defined direction. \nTwo types of waves are most commonly studied in classical physics. In a mechanical wave, stress and strain fields oscillate about a mechanical equilibrium. A mechanical wave is a local deformation (strain) in some physical medium that propagates from particle to particle by creating local stresses that cause strain in neighboring particles too. For example, sound waves are variations of the local pressure and particle motion that propagate through the medium. Other examples of mechanical waves are seismic waves, gravity waves, surface waves and string vibrations. In an electromagnetic wave (such as light), coupling between the electric and magnetic fields which sustains propagation of a wave involving these fields according to Maxwell's equations. Electromagnetic waves can travel through a vacuum and through some dielectric media (at wavelengths where they are considered transparent). Electromagnetic waves, according to their frequencies (or wavelengths) have more specific designations including radio waves, infrared radiation, terahertz waves, visible light, ultraviolet radiation, X-rays and gamma rays.\nOther types of waves include gravitational waves, which are disturbances in spacetime that propagate according to general relativity; heat diffusion waves; plasma waves that combine mechanical deformations and electromagnetic fields; reaction\u2013diffusion waves, such as in the Belousov\u2013Zhabotinsky reaction; and many more. Mechanical and electromagnetic waves transfer energy, momentum, and information, but they do not transfer particles in the medium. In mathematics and electronics waves are studied as signals. On the other hand, some waves have envelopes which do not move at all such as standing waves (which are fundamental to music) and hydraulic jumps. Some, like the probability waves of quantum mechanics, may be completely static.\n\nA physical wave field is almost always confined to some finite region of space, called its domain. For example, the seismic waves generated by earthquakes are significant only in the interior and surface of the planet, so they can be ignored outside it. However, waves with infinite domain, that extend over the whole space, are commonly studied in mathematics, and are very valuable tools for understanding physical waves in finite domains.\nA plane wave is an important mathematical idealization where the disturbance is identical along any (infinite) plane normal to a specific direction of travel. Mathematically, the simplest wave is a sinusoidal plane wave in which at any point the field experiences simple harmonic motion at one frequency. In linear media, complicated waves can generally be decomposed as the sum of many sinusoidal plane waves having different directions of propagation and/or different frequencies. A plane wave is classified as a transverse wave if the field disturbance at each point is described by a vector perpendicular to the direction of propagation (also the direction of energy transfer); or longitudinal wave if those vectors are aligned with the propagation direction. Mechanical waves include both transverse and longitudinal waves; on the other hand electromagnetic plane waves are strictly transverse while sound waves in fluids (such as air) can only be longitudinal. That physical direction of an oscillating field relative to the propagation direction is also referred to as the wave's polarization, which can be an important attribute.\n\n\n== Mathematical description ==\n\n\n=== Single waves ===\nA wave can be described just like a field, namely as a function \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is a position and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is a time.\nThe value of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is a point of space, specifically in the region where the wave is defined. In mathematical terms, it is usually a vector in the Cartesian three-dimensional space \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{3}}\n  . However, in many cases one can ignore one dimension, and let \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   be a point of the Cartesian plane \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}}\n  . This is the case, for example, when studying vibrations of a drum skin. One may even restrict \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   to a point of the Cartesian line \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n   \u2014 that is, the set of real numbers. This is the case, for example, when studying vibrations in a violin string or recorder. The time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , on the other hand, is always assumed to be a scalar; that is, a real number.\nThe value of \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   can be any physical quantity of interest assigned to the point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   that may vary with time. For example, if \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   represents the vibrations inside an elastic solid, the value of \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   is usually a vector that gives the current displacement from \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   of the material particles that would be at the point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   in the absence of vibration. For an electromagnetic wave, the value of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   can be the electric field vector \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  , or the magnetic field vector \n  \n    \n      \n        H\n      \n    \n    {\\displaystyle H}\n  , or any related quantity, such as the Poynting vector \n  \n    \n      \n        E\n        \u00d7\n        H\n      \n    \n    {\\displaystyle E\\times H}\n  . In fluid dynamics, the value of \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   could be the velocity vector of the fluid at the point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , or any scalar property like pressure, temperature, or density. In a chemical reaction, \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   could be the concentration of some substance in the neighborhood of point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   of the reaction medium.\nFor any dimension \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   (1, 2, or 3), the wave's domain is then a subset \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   of \n  \n    \n      \n        \n          \n            R\n          \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{d}}\n  , such that the function value \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   is defined for any point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   in \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  . For example, when describing the motion of a drum skin, one can consider \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   to be a disk (circle) on the plane \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}}\n   with center at the origin \n  \n    \n      \n        (\n        0\n        ,\n        0\n        )\n      \n    \n    {\\displaystyle (0,0)}\n  , and let \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   be the vertical displacement of the skin at the point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   of \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   and at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  .\n\n\n=== Wave families ===\nSometimes one is interested in a single specific wave. More often, however, one needs to understand large set of possible waves; like all the ways that a drum skin can vibrate after being struck once with a drum stick, or all the possible radar echos one could get from an airplane that may be approaching an airport.\nIn some of those situations, one may describe such a family of waves by a function \n  \n    \n      \n        F\n        (\n        A\n        ,\n        B\n        ,\n        \u2026\n        ;\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(A,B,\\ldots ;x,t)}\n   that depends on certain parameters \n  \n    \n      \n        A\n        ,\n        B\n        ,\n        \u2026\n      \n    \n    {\\displaystyle A,B,\\ldots }\n  , besides \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  . Then one can obtain different waves \u2014 that is, different functions of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   and \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   \u2014 by choosing different values for those parameters.\n\nFor example, the sound pressure inside a recorder that is playing a \"pure\" note is typically a standing wave, that can be written as\n\n  \n    \n      \n        F\n        (\n        A\n        ,\n        L\n        ,\n        n\n        ,\n        c\n        ;\n        x\n        ,\n        t\n        )\n        =\n        A\n        \n          (\n          \n            cos\n            \u2061\n            2\n            \u03c0\n            x\n            \n              \n                \n                  2\n                  n\n                  \u2212\n                  1\n                \n                \n                  4\n                  L\n                \n              \n            \n          \n          )\n        \n        \n          (\n          \n            cos\n            \u2061\n            2\n            \u03c0\n            c\n            t\n            \n              \n                \n                  2\n                  n\n                  \u2212\n                  1\n                \n                \n                  4\n                  L\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle F(A,L,n,c;x,t)=A\\left(\\cos 2\\pi x{\\frac {2n-1}{4L}}\\right)\\left(\\cos 2\\pi ct{\\frac {2n-1}{4L}}\\right)}\n  The parameter \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   defines the amplitude of the wave (that is, the maximum sound pressure in the bore, which is related to the loudness of the note); \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the speed of sound; \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   is the length of the bore; and \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is a positive integer (1,2,3,...) that specifies the number of nodes in the standing wave. (The position \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   should be measured from the mouthpiece, and the time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   from any moment at which the pressure at the mouthpiece is maximum. The quantity \n  \n    \n      \n        \u03bb\n        =\n        4\n        L\n        \n          /\n        \n        (\n        2\n        n\n        \u2212\n        1\n        )\n      \n    \n    {\\displaystyle \\lambda =4L/(2n-1)}\n   is the wavelength of the emitted note, and \n  \n    \n      \n        f\n        =\n        c\n        \n          /\n        \n        \u03bb\n      \n    \n    {\\displaystyle f=c/\\lambda }\n   is its frequency.) Many general properties of these waves can be inferred from this general equation, without choosing specific values for the parameters.\nAs another example, it may be that the vibrations of a drum skin after a single strike depend only on the distance \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   from the center of the skin to the strike point, and on the strength \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   of the strike. Then the vibration for all possible strikes can be described by a function \n  \n    \n      \n        F\n        (\n        r\n        ,\n        s\n        ;\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(r,s;x,t)}\n  .\nSometimes the family of waves of interest has infinitely many parameters. For example, one may want to describe what happens to the temperature in a metal bar when it is initially heated at various temperatures at different points along its length, and then allowed to cool by itself in vacuum. In that case, instead of a scalar or vector, the parameter would have to be a function \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   such that \n  \n    \n      \n        h\n        (\n        x\n        )\n      \n    \n    {\\displaystyle h(x)}\n   is the initial temperature at each point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   of the bar. Then the temperatures at later times can be expressed by a function \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   that depends on the function \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   (that is, a functional operator), so that the temperature at a later time is \n  \n    \n      \n        F\n        (\n        h\n        ;\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(h;x,t)}\n  \n\n\n=== Differential wave equations ===\nAnother way to describe and study a family of waves is to give a mathematical equation that, instead of explicitly giving the value of \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n  , only constrains how those values can change with time. Then the family of waves in question consists of all functions \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   that satisfy those constraints \u2014 that is, all solutions of the equation.\nThis approach is extremely important in physics, because the constraints usually are a consequence of the physical processes that cause the wave to evolve. For example, if \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   is the temperature inside a block of some homogeneous and isotropic solid material, its evolution is constrained by the partial differential equation\n\n  \n    \n      \n        \n          \n            \n              \u2202\n              F\n            \n            \n              \u2202\n              t\n            \n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        \u03b1\n        \n          (\n          \n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  F\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      1\n                    \n                    \n                      2\n                    \n                  \n                \n              \n            \n            (\n            x\n            ,\n            t\n            )\n            +\n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  F\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      2\n                    \n                    \n                      2\n                    \n                  \n                \n              \n            \n            (\n            x\n            ,\n            t\n            )\n            +\n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  F\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      3\n                    \n                    \n                      2\n                    \n                  \n                \n              \n            \n            (\n            x\n            ,\n            t\n            )\n          \n          )\n        \n        +\n        \u03b2\n        Q\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle {\\frac {\\partial F}{\\partial t}}(x,t)=\\alpha \\left({\\frac {\\partial ^{2}F}{\\partial x_{1}^{2}}}(x,t)+{\\frac {\\partial ^{2}F}{\\partial x_{2}^{2}}}(x,t)+{\\frac {\\partial ^{2}F}{\\partial x_{3}^{2}}}(x,t)\\right)+\\beta Q(x,t)}\n  where \n  \n    \n      \n        Q\n        (\n        p\n        ,\n        f\n        )\n      \n    \n    {\\displaystyle Q(p,f)}\n   is the heat that is being generated per unit of volume and time in the neighborhood of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   (for example, by chemical reactions happening there); \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle x_{1},x_{2},x_{3}}\n   are the Cartesian coordinates of the point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  ; \n  \n    \n      \n        \u2202\n        F\n        \n          /\n        \n        \u2202\n        t\n      \n    \n    {\\displaystyle \\partial F/\\partial t}\n   is the (first) derivative of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   with respect to \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  ; and \n  \n    \n      \n        \n          \u2202\n          \n            2\n          \n        \n        F\n        \n          /\n        \n        \u2202\n        \n          x\n          \n            i\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\partial ^{2}F/\\partial x_{i}^{2}}\n   is the second derivative of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   relative to \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  . (The symbol \"\n  \n    \n      \n        \u2202\n      \n    \n    {\\displaystyle \\partial }\n  \" is meant to signify that, in the derivative with respect to some variable, all other variables must be considered fixed.)\nThis equation can be derived from the laws of physics that govern the diffusion of heat in solid media. For that reason, it is called the heat equation in mathematics, even though it applies to many other physical quantities besides temperatures.\nFor another example, we can describe all possible sounds echoing within a container of gas by a function \n  \n    \n      \n        F\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle F(x,t)}\n   that gives the pressure at a point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   and time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   within that container. If the gas was initially at uniform temperature and composition, the evolution of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   is constrained by the formula\n\n  \n    \n      \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              F\n            \n            \n              \u2202\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        \u03b1\n        \n          (\n          \n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  F\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      1\n                    \n                    \n                      2\n                    \n                  \n                \n              \n            \n            (\n            x\n            ,\n            t\n            )\n            +\n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  F\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      2\n                    \n                    \n                      2\n                    \n                  \n                \n              \n            \n            (\n            x\n            ,\n            t\n            )\n            +\n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  F\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      3\n                    \n                    \n                      2\n                    \n                  \n                \n              \n            \n            (\n            x\n            ,\n            t\n            )\n          \n          )\n        \n        +\n        \u03b2\n        P\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle {\\frac {\\partial ^{2}F}{\\partial t^{2}}}(x,t)=\\alpha \\left({\\frac {\\partial ^{2}F}{\\partial x_{1}^{2}}}(x,t)+{\\frac {\\partial ^{2}F}{\\partial x_{2}^{2}}}(x,t)+{\\frac {\\partial ^{2}F}{\\partial x_{3}^{2}}}(x,t)\\right)+\\beta P(x,t)}\n  Here \n  \n    \n      \n        P\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle P(x,t)}\n   is some extra compression force that is being applied to the gas near \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   by some external process, such as a loudspeaker or piston right next to \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  .\nThis same differential equation describes the behavior of mechanical vibrations and electromagnetic fields in a homogeneous isotropic non-conducting solid. Note that this equation differs from that of heat flow only in that the left-hand side is \n  \n    \n      \n        \n          \u2202\n          \n            2\n          \n        \n        F\n        \n          /\n        \n        \u2202\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\partial ^{2}F/\\partial t^{2}}\n  , the second derivative of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   with respect to time, rather than the first derivative \n  \n    \n      \n        \u2202\n        F\n        \n          /\n        \n        \u2202\n        t\n      \n    \n    {\\displaystyle \\partial F/\\partial t}\n  . Yet this small change makes a huge difference on the set of solutions \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  . This differential equation is called \"the\" wave equation in mathematics, even though it describes only one very special kind of waves.\n\n\n== Wave in elastic medium ==\n\nConsider a traveling transverse wave (which may be a pulse) on a string (the medium). Consider the string to have a single spatial dimension. Consider this wave as traveling\n\nin the \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   direction in space. For example, let the positive \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   direction be to the right, and the negative \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   direction be to the left.\nwith constant amplitude \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \nwith constant velocity \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  , where \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is\nindependent of wavelength (no dispersion)\nindependent of amplitude (linear media, not nonlinear).\nwith constant waveform, or shapeThis wave can then be described by the two-dimensional functions\n\n  \n    \n      \n        u\n        (\n        x\n        ,\n        t\n        )\n        =\n        F\n        (\n        x\n        \u2212\n        v\n        t\n        )\n      \n    \n    {\\displaystyle u(x,t)=F(x-vt)}\n   (waveform \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   traveling to the right)\n\n  \n    \n      \n        u\n        (\n        x\n        ,\n        t\n        )\n        =\n        G\n        (\n        x\n        +\n        v\n        t\n        )\n      \n    \n    {\\displaystyle u(x,t)=G(x+vt)}\n   (waveform \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   traveling to the left)or, more generally, by d'Alembert's formula:\n\n  \n    \n      \n        u\n        (\n        x\n        ,\n        t\n        )\n        =\n        F\n        (\n        x\n        \u2212\n        v\n        t\n        )\n        +\n        G\n        (\n        x\n        +\n        v\n        t\n        )\n        .\n      \n    \n    {\\displaystyle u(x,t)=F(x-vt)+G(x+vt).}\n  representing two component waveforms \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   and \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   traveling through the medium in opposite directions. A generalized representation of this wave can be obtained as the partial differential equation\n\n  \n    \n      \n        \n          \n            1\n            \n              v\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              u\n            \n            \n              \u2202\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              u\n            \n            \n              \u2202\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {1}{v^{2}}}{\\frac {\\partial ^{2}u}{\\partial t^{2}}}={\\frac {\\partial ^{2}u}{\\partial x^{2}}}.}\n  General solutions are based upon Duhamel's principle.Beside the second order wave equations that are describing a standing wave field, the one-way wave equation describes the propagation of single wave in a defined direction.  \n\n\n=== Wave forms ===\n\nThe form or shape of F in d'Alembert's formula involves the argument x \u2212 vt. Constant values of this argument correspond to constant values of F, and these constant values occur if x increases at the same rate that vt increases. That is, the wave shaped like the function F will move in the positive x-direction at velocity v (and G will propagate at the same speed in the negative x-direction).In the case of a periodic function F with period \u03bb, that is, F(x + \u03bb \u2212 vt) = F(x \u2212 vt), the periodicity of F in space means that a snapshot of the wave at a given time t finds the wave varying periodically in space with period \u03bb (the wavelength of the wave). In a similar fashion, this periodicity of F implies a periodicity in time as well: F(x \u2212 v(t + T)) = F(x \u2212 vt) provided vT = \u03bb, so an observation of the wave at a fixed location x finds the wave undulating periodically in time with period T = \u03bb/v.\n\n\n=== Amplitude and modulation ===\n\nThe amplitude of a wave may be constant (in which case the wave is a c.w. or continuous wave), or may be modulated so as to vary with time and/or position. The outline of the variation in amplitude is called the envelope of the wave. Mathematically, the modulated wave can be written in the form:\n\n  \n    \n      \n        u\n        (\n        x\n        ,\n        t\n        )\n        =\n        A\n        (\n        x\n        ,\n        t\n        )\n        sin\n        \u2061\n        \n          (\n          \n            k\n            x\n            \u2212\n            \u03c9\n            t\n            +\n            \u03d5\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle u(x,t)=A(x,t)\\sin \\left(kx-\\omega t+\\phi \\right),}\n  where \n  \n    \n      \n        A\n        (\n        x\n        ,\n         \n        t\n        )\n      \n    \n    {\\displaystyle A(x,\\ t)}\n   is the amplitude envelope of the wave, \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the wavenumber and \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   is the phase. If the group velocity \n  \n    \n      \n        \n          v\n          \n            g\n          \n        \n      \n    \n    {\\displaystyle v_{g}}\n   (see below) is wavelength-independent, this equation can be simplified as:\n\n  \n    \n      \n        u\n        (\n        x\n        ,\n        t\n        )\n        =\n        A\n        (\n        x\n        \u2212\n        \n          v\n          \n            g\n          \n        \n        t\n        )\n        sin\n        \u2061\n        \n          (\n          \n            k\n            x\n            \u2212\n            \u03c9\n            t\n            +\n            \u03d5\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle u(x,t)=A(x-v_{g}t)\\sin \\left(kx-\\omega t+\\phi \\right),}\n  showing that the envelope moves with the group velocity and retains its shape. Otherwise, in cases where the group velocity varies with wavelength, the pulse shape changes in a manner often described using an envelope equation.\n\n\n=== Phase velocity and group velocity ===\n\nThere are two velocities that are associated with waves, the phase velocity and the group velocity.\nPhase velocity is the rate at which the phase of the wave propagates in space: any given phase of the wave (for example, the crest) will appear to travel at the phase velocity. The phase velocity is given in terms of the wavelength \u03bb (lambda) and period T as\n\n  \n    \n      \n        \n          v\n          \n            \n              p\n            \n          \n        \n        =\n        \n          \n            \u03bb\n            T\n          \n        \n        .\n      \n    \n    {\\displaystyle v_{\\mathrm {p} }={\\frac {\\lambda }{T}}.}\n  \nGroup velocity is a property of waves that have a defined envelope, measuring propagation through space (that is, phase velocity) of the overall shape of the waves' amplitudes \u2013 modulation or envelope of the wave.\n\n\n== Special waves ==\n\n\n=== Sine waves ===\n\n\n=== Plane waves ===\n\nA plane wave is a kind of wave whose value varies only in one spatial direction. That is, its value is constant on a plane that is perpendicular to that direction. Plane waves can be specified by a vector of unit length \n  \n    \n      \n        \n          \n            \n              n\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {n}}}\n   indicating the direction that the wave varies in, and a wave profile describing how the wave varies as a function of the displacement along that direction (\n  \n    \n      \n        \n          \n            \n              n\n              ^\n            \n          \n        \n        \u22c5\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {n}}\\cdot {\\vec {x}}}\n  ) and time (\n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  ). Since the wave profile only depends on the position \n  \n    \n      \n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {x}}}\n   in the combination \n  \n    \n      \n        \n          \n            \n              n\n              ^\n            \n          \n        \n        \u22c5\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {n}}\\cdot {\\vec {x}}}\n  , any displacement in directions perpendicular to \n  \n    \n      \n        \n          \n            \n              n\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {n}}}\n   cannot affect the value of the field.\nPlane waves are often used to model electromagnetic waves far from a source. For electromagnetic plane waves, the electric and magnetic fields themselves are transverse to the direction of propagation, and also perpendicular to each other.\n\n\n=== Standing waves ===\n\nA standing wave, also known as a stationary wave, is a wave whose envelope remains in a constant position. This phenomenon arises as a result of interference between two waves traveling in opposite directions.\nThe sum of two counter-propagating waves (of equal amplitude and frequency) creates a standing wave. Standing waves commonly arise when a boundary blocks further propagation of the wave, thus causing wave reflection, and therefore introducing a counter-propagating wave. For example, when a violin string is displaced, transverse waves propagate out to where the string is held in place at the bridge and the nut, where the waves are reflected back. At the bridge and nut, the two opposed waves are in antiphase and cancel each other, producing a node. Halfway between two nodes there is an antinode, where the two counter-propagating waves enhance each other maximally. There is no net propagation of energy over time.\n\n\t\t\n\t\t\n\n\n== Physical properties ==\n\n\n=== Propagation ===\nWave propagation is any of the ways in which waves travel. Single wave propagation can be calculated by second-order wave equation (standing wavefield) or first-order one-way wave equation.\nWith respect to the direction of the oscillation relative to the propagation direction, we can distinguish between longitudinal wave and transverse waves.\nElectromagnetic waves propagate in vacuum as well as in material media. Propagation of other wave types such as sound may occur only in a transmission medium.\n\n\n==== Reflection of plane waves in a half-space ====\n\nThe propagation and reflection of plane waves\u2014e.g. Pressure waves (P-wave) or Shear waves (SH or SV-waves) are phenomena that were first characterized within the field of classical seismology, and are now considered fundamental concepts in modern seismic tomography. The analytical solution to this problem exists and is well known. The frequency domain solution can be obtained by first finding the Helmholtz decomposition of the displacement field, which is then substituted into the wave equation. From here, the plane wave eigenmodes can be calculated.\n\n\n==== SV wave propagation ====\n\nThe analytical solution of SV-wave in a half-space indicates that the plane SV wave reflects back to the domain as a P and SV waves, leaving out special cases. The angle of the reflected SV wave is identical to the incidence wave, while the angle of the reflected P wave is greater than the SV wave. For the same wave frequency, the SV wavelength is smaller than the P wavelength. This fact has been depicted in this animated picture.\n\n\n==== P wave propagation ====\nSimilar to the SV wave, the P incidence, in general, reflects as the P and SV wave. There are some special cases where the regime is different.\n\n\n=== Wave velocity ===\n\nWave velocity  is a general concept, of various kinds of wave velocities, for a wave's phase and speed concerning energy (and information) propagation. The phase velocity is given as:\n\nwhere:\n\nvp is the phase velocity (in meters per second, m/s),\n\u03c9 is the angular frequency (in radians per second, rad/s),\nk is the wavenumber (in radians per meter, rad/m).The phase speed gives you the speed at which a point of constant phase of the wave will travel for a discrete frequency. The angular frequency \u03c9 cannot be chosen independently from the wavenumber k, but both are related through the dispersion relationship:\n\nIn the special case \u03a9(k) = ck, with c a constant, the waves are called non-dispersive, since all frequencies travel at the same phase speed c. For instance electromagnetic waves in vacuum are non-dispersive. In case of other forms of the dispersion relation, we have dispersive waves. The dispersion relationship depends on the medium through which the waves propagate and on the type of waves (for instance electromagnetic, sound or water waves).\nThe speed at which a resultant wave packet from a narrow range of frequencies will travel is called the group velocity and is determined from the gradient of the dispersion relation:\n\nIn almost all cases, a wave is mainly a movement of energy through a medium. Most often, the group velocity is the velocity at which the energy moves through this medium.\n\nWaves exhibit common behaviors under a number of standard situations, for example:\n\n\n=== Transmission and media ===\n\nWaves normally move in a straight line (that is, rectilinearly) through a transmission medium. Such media can be classified into one or more of the following categories:\n\nA bounded medium if it is finite in extent, otherwise an unbounded medium\nA linear medium if the amplitudes of different waves at any particular point in the medium can be added\nA uniform medium or homogeneous medium if its physical properties are unchanged at different locations in space\nAn anisotropic medium if one or more of its physical properties differ in one or more directions\nAn isotropic medium if its physical properties are the same in all directions\n\n\n=== Absorption ===\n\nWaves are usually defined in media which allow most or all of a wave's energy to propagate without loss. However materials may be characterized as \"lossy\" if they remove energy from a wave, usually converting it into heat. This is termed \"absorption.\" A material which absorbs a wave's energy, either in transmission or reflection, is characterized by a refractive index which is complex. The amount of absorption will generally depend on the frequency (wavelength) of the wave, which, for instance, explains why objects may appear colored.\n\n\n=== Reflection ===\n\nWhen a wave strikes a reflective surface, it changes direction, such that the angle made by the incident wave and line normal to the surface equals the angle made by the reflected wave and the same normal line.\n\n\n=== Refraction ===\n\nRefraction is the phenomenon of a wave changing its speed. Mathematically, this means that the size of the phase velocity changes. Typically, refraction occurs when a wave passes from one medium into another. The amount by which a wave is refracted by a material is given by the refractive index of the material. The directions of incidence and refraction are related to the refractive indices of the two materials by Snell's law.\n\n\n=== Diffraction ===\n\nA wave exhibits diffraction when it encounters an obstacle that bends the wave or when it spreads after emerging from an opening. Diffraction effects are more pronounced when the size of the obstacle or opening is comparable to the wavelength of the wave.\n\n\n=== Interference ===\n\nWhen waves in a linear medium (the usual case) cross each other in a region of space, they do not actually interact with each other, but continue on as if the other one weren't present. However at any point in that region the field quantities describing those waves add according to the superposition principle. If the waves are of the same frequency in a fixed phase relationship, then there will generally be positions at which the two waves are in phase and their amplitudes add, and other positions where they are out of phase and their amplitudes (partially or fully) cancel. This is called an interference pattern.\n\n\n=== Polarization ===\n\nThe phenomenon of polarization arises when wave motion can occur simultaneously in two orthogonal directions. Transverse waves can be polarized, for instance. When polarization is used as a descriptor without qualification, it usually refers to the special, simple case of linear polarization. A transverse wave is linearly polarized if it oscillates in only one direction or plane. In the case of linear polarization, it is often useful to add the relative orientation of that plane, perpendicular to the direction of travel, in which the oscillation occurs, such as \"horizontal\" for instance, if the plane of polarization is parallel to the ground. Electromagnetic waves propagating in free space, for instance, are transverse; they can be polarized by the use of a polarizing filter.\nLongitudinal waves, such as sound waves, do not exhibit polarization. For these waves there is only one direction of oscillation, that is, along the direction of travel.\n\n\n=== Dispersion ===\n\nA wave undergoes dispersion when either the phase velocity or the group velocity depends on the wave frequency.\nDispersion is most easily seen by letting white light pass through a prism, the result of which is to produce the spectrum of colors of the rainbow. Isaac Newton performed experiments with light and prisms, presenting his findings in the Opticks (1704) that white light consists of several colors and that these colors cannot be decomposed any further.\n\n\n== Mechanical waves ==\n\n\n=== Waves on strings ===\n\nThe speed of a transverse wave traveling along a vibrating string (v) is directly proportional to the square root of the tension of the string (T) over the linear mass density (\u03bc):\n\n  \n    \n      \n        v\n        =\n        \n          \n            \n              T\n              \u03bc\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle v={\\sqrt {\\frac {T}{\\mu }}},}\n  where the linear density \u03bc is the mass per unit length of the string.\n\n\n=== Acoustic waves ===\n\nAcoustic or sound waves travel at speed given by\n\n  \n    \n      \n        v\n        =\n        \n          \n            \n              B\n              \n                \u03c1\n                \n                  0\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle v={\\sqrt {\\frac {B}{\\rho _{0}}}},}\n  or the square root of the adiabatic bulk modulus divided by the ambient fluid density (see speed of sound).\n\n\n=== Water waves ===\n\nRipples on the surface of a pond are actually a combination of transverse and longitudinal waves; therefore, the points on the surface follow orbital paths.\nSound \u2013 a mechanical wave that propagates through gases, liquids, solids and plasmas;\nInertial waves, which occur in rotating fluids and are restored by the Coriolis effect;\nOcean surface waves, which are perturbations that propagate through water.\n\n\n=== Seismic waves ===\n\nSeismic waves are waves of energy that travel through the Earth's layers, and are a result of earthquakes, volcanic eruptions, magma movement, large landslides and large man-made explosions that give out low-frequency acoustic energy.\n\n\n=== Doppler effect ===\nThe Doppler effect (or the Doppler shift) is the change in frequency of a wave in relation to an observer who is moving relative to the wave source. It is named after the Austrian physicist Christian Doppler, who described the phenomenon in 1842.\n\n\n=== Shock waves ===\n\nA shock wave is a type of propagating disturbance. When a wave moves faster than the local speed of sound in a fluid, it is a shock wave. Like an ordinary wave, a shock wave carries energy and can propagate through a medium; however, it is characterized by an abrupt, nearly discontinuous change in pressure, temperature and density of the medium.\n\n\n=== Other ===\nWaves of traffic, that is, propagation of different densities of motor vehicles, and so forth, which can be modeled as kinematic waves\nMetachronal wave refers to the appearance of a traveling wave produced by coordinated sequential actions.\n\n\n== Electromagnetic waves ==\n\nAn electromagnetic wave consists of two waves that are oscillations of the electric and magnetic fields. An electromagnetic wave travels in a direction that is at right angles to the oscillation direction of both fields. In the 19th century, James Clerk Maxwell showed that, in vacuum, the electric and magnetic fields satisfy the wave equation both with speed equal to that of the speed of light. From this emerged the idea that light is an electromagnetic wave. Electromagnetic waves can have different frequencies (and thus wavelengths), giving rise to various types of radiation such as radio waves, microwaves, infrared, visible light, ultraviolet, X-rays, and Gamma rays.\n\n\n== Quantum mechanical waves ==\n\n\n=== Schr\u00f6dinger equation ===\nThe Schr\u00f6dinger equation describes the wave-like behavior of particles in quantum mechanics. Solutions of this equation are wave functions which can be used to describe the probability density of a particle.\n\n\n=== Dirac equation ===\nThe Dirac equation is a relativistic wave equation detailing electromagnetic interactions. Dirac waves accounted for the fine details of the hydrogen spectrum in a completely rigorous way. The wave equation also implied the existence of a new form of matter, antimatter, previously unsuspected and unobserved and which was experimentally confirmed. In the context of quantum field theory, the Dirac equation is reinterpreted to describe quantum fields corresponding to spin-1\u20442 particles.\n\n\n=== de Broglie waves ===\n\nLouis de Broglie postulated that all particles with momentum have a wavelength\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            h\n            p\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {h}{p}},}\n  where h is Planck's constant, and p is the magnitude of the momentum of the particle. This hypothesis was at the basis of quantum mechanics. Nowadays, this wavelength is called the de Broglie wavelength. For example, the electrons in a CRT display have a de Broglie wavelength of about 10\u221213 m.\nA wave representing such a particle traveling in the k-direction is expressed by the wave function as follows:\n\n  \n    \n      \n        \u03c8\n        (\n        \n          r\n        \n        ,\n        \n        t\n        =\n        0\n        )\n        =\n        A\n        \n          e\n          \n            i\n            \n              k\n              \u22c5\n              r\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\psi (\\mathbf {r} ,\\,t=0)=Ae^{i\\mathbf {k\\cdot r} },}\n  where the wavelength is determined by the wave vector k as:\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              2\n              \u03c0\n            \n            k\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {2\\pi }{k}},}\n  and the momentum by:\n\n  \n    \n      \n        \n          p\n        \n        =\n        \u210f\n        \n          k\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {p} =\\hbar \\mathbf {k} .}\n  However, a wave like this with definite wavelength is not localized in space, and so cannot represent a particle localized in space. To localize a particle, de Broglie proposed a superposition of different wavelengths ranging around a central value in a wave packet, a waveform often used in quantum mechanics to describe the wave function of a particle. In a wave packet, the wavelength of the particle is not precise, and the local wavelength deviates on either side of the main wavelength value.\nIn representing the wave function of a localized particle, the wave packet is often taken to have a Gaussian shape and is called a Gaussian wave packet. Gaussian wave packets also are used to analyze water waves.For example, a Gaussian wavefunction \u03c8 might take the form:\n\n  \n    \n      \n        \u03c8\n        (\n        x\n        ,\n        \n        t\n        =\n        0\n        )\n        =\n        A\n        exp\n        \u2061\n        \n          (\n          \n            \u2212\n            \n              \n                \n                  x\n                  \n                    2\n                  \n                \n                \n                  2\n                  \n                    \u03c3\n                    \n                      2\n                    \n                  \n                \n              \n            \n            +\n            i\n            \n              k\n              \n                0\n              \n            \n            x\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\psi (x,\\,t=0)=A\\exp \\left(-{\\frac {x^{2}}{2\\sigma ^{2}}}+ik_{0}x\\right),}\n  at some initial time t = 0, where the central wavelength is related to the central wave vector k0 as \u03bb0 = 2\u03c0 / k0. It is well known from the theory of Fourier analysis, or from the Heisenberg uncertainty principle (in the case of quantum mechanics) that a narrow range of wavelengths is necessary to produce a localized wave packet, and the more localized the envelope, the larger the spread in required wavelengths. The Fourier transform of a Gaussian is itself a Gaussian. Given the Gaussian:\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          e\n          \n            \u2212\n            \n              x\n              \n                2\n              \n            \n            \n              /\n            \n            \n              (\n              \n                2\n                \n                  \u03c3\n                  \n                    2\n                  \n                \n              \n              )\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle f(x)=e^{-x^{2}/\\left(2\\sigma ^{2}\\right)},}\n  the Fourier transform is:\n\n  \n    \n      \n        \n          \n            \n              f\n              ~\n            \n          \n        \n        (\n        k\n        )\n        =\n        \u03c3\n        \n          e\n          \n            \u2212\n            \n              \u03c3\n              \n                2\n              \n            \n            \n              k\n              \n                2\n              \n            \n            \n              /\n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\tilde {f}}(k)=\\sigma e^{-\\sigma ^{2}k^{2}/2}.}\n  The Gaussian in space therefore is made up of waves:\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n            1\n            \n              2\n              \u03c0\n            \n          \n        \n        \n          \u222b\n          \n            \u2212\n            \u221e\n          \n          \n            \u221e\n          \n        \n         \n        \n          \n            \n              f\n              ~\n            \n          \n        \n        (\n        k\n        )\n        \n          e\n          \n            i\n            k\n            x\n          \n        \n         \n        d\n        k\n        ;\n      \n    \n    {\\displaystyle f(x)={\\frac {1}{\\sqrt {2\\pi }}}\\int _{-\\infty }^{\\infty }\\ {\\tilde {f}}(k)e^{ikx}\\ dk;}\n  that is, a number of waves of wavelengths \u03bb such that k\u03bb = 2 \u03c0.\nThe parameter \u03c3 decides the spatial spread of the Gaussian along the x-axis, while the Fourier transform shows a spread in wave vector k determined by 1/\u03c3. That is, the smaller the extent in space, the larger the extent in k, and hence in \u03bb = 2\u03c0/k.\n\n\n== Gravity waves ==\nGravity waves are waves generated in a fluid medium or at the interface between two media when the force of gravity or buoyancy tries to restore equilibrium. A ripple on a pond is one example.\n\n\n== Gravitational waves ==\n\nGravitational waves also travel through space. The first observation of gravitational waves was announced on 11 February 2016.\nGravitational waves are disturbances in the curvature of spacetime, predicted by Einstein's theory of general relativity.\n\n\n== See also ==\nIndex of wave articles\n\n\n=== Waves in general ===\n\n\n==== Parameters ====\n\n\n==== Waveforms ====\n\n\n=== Electromagnetic waves ===\n\n\n=== In fluids ===\n\n\n=== In quantum mechanics ===\n\n\n=== In relativity ===\n\n\n=== Other specific types of waves ===\n\n\n=== Related topics ===\n\n\n== References ==\n\n\n== Sources ==\n\n\n== External links ==\n\nThe Feynman Lectures on Physics: Waves\nLinear and nonlinear waves\nScience Aid: Wave properties \u2013 Concise guide aimed at teens", "Sound_intensity": "Sound intensity, also known as acoustic intensity, is defined as the power carried by sound waves per unit area in a direction perpendicular to that area. The SI unit of intensity, which includes sound intensity, is the watt per square meter (W/m2). One application is the noise measurement of sound intensity in the air at a listener's location as a sound energy quantity.Sound intensity is not the same physical quantity as sound pressure. Human hearing is sensitive to sound pressure which is related to sound intensity. In consumer audio electronics, the level differences are called \"intensity\" differences, but sound intensity is a specifically defined quantity and cannot be sensed by a simple microphone.\nSound intensity level is a logarithmic expression of sound intensity relative to a reference intensity.\n\n\n== Mathematical definition ==\nSound intensity, denoted I, is defined by\n\nwhere\n\np is the sound pressure;\nv is the particle velocity.Both I and v are vectors, which means that both have a direction as well as a magnitude. The direction of sound intensity is the average direction in which energy is flowing.\nThe average sound intensity during time T is given by\n\nFor a plane wave,\n\nWhere,\n\n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   is frequency of sound,\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is the amplitude of the sound wave particle displacement,\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is density of medium in which sound is traveling, and\n\n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is speed of sound.\n\n\n== Inverse-square law ==\n\nFor a spherical sound wave, the intensity in the radial direction as a function of distance r from the centre of the sphere is given by\n\nwhere\n\nP is the sound power;\nA(r) is the surface area of a sphere of radius r.Thus sound intensity decreases as 1/r2 from the centre of the sphere:\n\nThis relationship is an inverse-square law.\n\n\n== Sound intensity level ==\n\nSound intensity level (SIL) or acoustic intensity level is the level (a logarithmic quantity) of the intensity of a sound relative to a reference value.\nIt is denoted LI, expressed in nepers, bels, or decibels, and defined by\nwhere\n\nI is the sound intensity;\nI0 is the reference sound intensity;\n1 Np = 1 is the neper;\n1 B = 1/2 ln(10) is the bel;\n1 dB = 1/20 ln(10) is the decibel.The commonly used reference sound intensity in air is\nbeing approximately the lowest sound intensity hearable by an undamaged human ear under room conditions.\nThe proper notations for sound intensity level using this reference are LI /(1 pW/m2) or LI (re 1 pW/m2), but the notations dB SIL, dB(SIL), dBSIL, or dBSIL are very common, even if they are not accepted by the SI.The reference sound intensity I0 is defined such that a progressive plane wave has the same value of sound intensity level (SIL) and sound pressure level (SPL), since\n\nThe equality of SIL and SPL requires that\n\nwhere p0 = 20 \u03bcPa is the reference sound pressure.\nFor a progressive spherical wave,\n\nwhere z0 is the characteristic specific acoustic impedance. Thus,\n\nIn air at ambient temperature, z0 = 410 Pa\u00b7s/m, hence the reference value I0 = 1 pW/m2.In an anechoic chamber which approximates a free field (no reflection) with a single source, measurements in the far field in SPL can be considered to be equal to measurements in SIL. This fact is exploited to measure sound power in anechoic conditions.\n\n\n== Measurement ==\nSound intensity is defined as the time averaged product of sound pressure and acoustic particle velocity. Both quantities can be directly measured by using a sound intensity p-u probe comprising a microphone and a particle velocity sensor, or estimated indirectly by using a p-p probe that approximates the particle velocity by integrating the pressure gradient between two closely spaced microphones.Pressure-based measurement methods are widely used in anechoic conditions for noise quantification purposes. The bias error introduced by a p-p probe can be approximated by\nwhere \n  \n    \n      \n        \n          I\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle I_{n}}\n  is the \u201ctrue\u201d intensity (unaffected by calibration errors), \n  \n    \n      \n        \n          \n            \n              \n                I\n                ^\n              \n            \n          \n          \n            n\n          \n          \n            p\n            \u2212\n            p\n          \n        \n      \n    \n    {\\displaystyle {\\hat {I}}_{n}^{p-p}}\n   is the biased estimate obtained using a p-p probe, \n  \n    \n      \n        \n          p\n          \n            rms\n          \n        \n      \n    \n    {\\displaystyle p_{\\text{rms}}}\n  is the root-mean-squared value of the sound pressure, \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the wave number, \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is the density of air, \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the speed of sound and \n  \n    \n      \n        \u0394\n        r\n      \n    \n    {\\displaystyle \\Delta r}\n   is the spacing between the two microphones. This expression shows that phase calibration errors are inversely proportional to frequency and microphone spacing and directly proportional to the ratio of the mean square sound pressure to the sound intensity. If the pressure-to-intensity ratio is large then even a small phase mismatch will lead to significant bias errors. In practice, sound intensity measurements cannot be performed accurately when the pressure-intensity index is high, which limits the use of p-p intensity probes in environments with high levels of background noise or reflections.\nOn the other hand, the bias error introduced by a p-u probe can be approximated by\nwhere \n  \n    \n      \n        \n          \n            \n              \n                I\n                ^\n              \n            \n          \n          \n            n\n          \n          \n            p\n            \u2212\n            u\n          \n        \n      \n    \n    {\\displaystyle {\\hat {I}}_{n}^{p-u}}\n   is the biased estimate obtained using a p-u probe, \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   and \n  \n    \n      \n        \n          V\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle V_{n}}\n   are the Fourier transform of sound pressure and particle velocity, \n  \n    \n      \n        \n          J\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle J_{n}}\n  is the reactive intensity and  \n  \n    \n      \n        \n          \u03c6\n          \n            ue\n          \n        \n      \n    \n    {\\displaystyle \\varphi _{\\text{ue}}}\n  is the p-u phase mismatch introduced by calibration errors. Therefore, the phase calibration is critical when measurements are carried out under near field conditions, but not so relevant if the measurements are performed out in the far field. The \u201creactivity\u201d (the ratio of the reactive to the active intensity) indicates whether this source of error is of concern or not. Compared to pressure-based probes, p-u intensity probes are unaffected by the pressure-to-intensity index, enabling the estimation of propagating acoustic energy in unfavorable testing environments provided that the distance to the sound source is sufficient.\n\n\n== References ==\n\n\n== External links ==\nHow Many Decibels Is Twice as Loud? Sound Level Change and the Respective Factor of Sound Pressure or Sound Intensity\nAcoustic Intensity\nConversion: Sound Intensity Level to Sound Intensity and Vice Versa\nOhm's Law as Acoustic Equivalent. Calculations\nRelationships of Acoustic Quantities Associated with a Plane Progressive Acoustic Sound Wave\nTable of Sound Levels. Corresponding Sound Intensity and Sound Pressure\nWhat Is Sound Intensity Measurement and Analysis?", "Electric_potential": "The electric potential (also called the electric field potential, potential drop, the electrostatic potential) is defined as the amount of work energy needed to move a unit of electric charge from a reference point to the specific point in an electric field. More precisely, it is the energy per unit charge for a test charge that is so small that the disturbance of the field under consideration is negligible. Furthermore, the motion across the field is supposed to proceed with negligible acceleration, so as to avoid the test charge acquiring kinetic energy or producing radiation. By definition, the electric potential at the reference point is zero units. Typically, the reference point is earth or a point at infinity, although any point can be used. \nIn classical electrostatics, the electrostatic field is a vector quantity expressed as the gradient of the electrostatic potential, which is a scalar quantity denoted by V or occasionally \u03c6, equal to the electric potential energy of any charged particle at any location (measured in joules) divided by the charge of that particle (measured in coulombs). By dividing out the charge on the particle a quotient is obtained that is a property of the electric field itself. In short, an electric potential is the electric potential energy per unit charge.\nThis value can be calculated in either a static (time-invariant) or a dynamic (time-varying) electric field at a specific time with the unit joules per coulomb (J\u22c5C\u22121) or volt (V). The electric potential at infinity is assumed to be zero.\nIn electrodynamics, when time-varying fields are present, the electric field cannot be expressed only in terms of a scalar potential. Instead, the electric field can be expressed in terms of both the scalar electric potential and the magnetic vector potential. The electric potential and the magnetic vector potential together form a four-vector, so that the two kinds of potential are mixed under Lorentz transformations.\nPractically, the electric potential is a continuous function in all space, because a spatial derivative of a discontinuous electric potential yields an electric field of impossibly infinite magnitude. Notably, the electric potential due to an idealized point charge (proportional to 1 \u2044 r, with r the distance from the point charge) is continuous in all space except at the location of the point charge. Though electric field is not continuous across an idealized surface charge, it is not infinite at any point. Therefore, the electric potential is continuous across an idealized surface charge. Additionally, an idealized line of charge has electric potential (proportional to ln(r), with r the radial distance from the line of charge) is continuous everywhere except on the line of charge.\n\n\n== Introduction ==\nClassical mechanics explores concepts such as force, energy, and potential. Force and potential energy are directly related. A net force acting on any object will cause it to accelerate. As an object moves in the direction of a force acting on it, its potential energy decreases. For example, the gravitational potential energy of a cannonball at the top of a hill is greater than at the base of the hill. As it rolls downhill, its potential energy decreases and is being translated to motion \u2013 kinetic energy.\nIt is possible to define the potential of certain force fields so that the potential energy of an object in that field depends only on the position of the object with respect to the field. Two such force fields are a gravitational field and an electric field (in the absence of time-varying magnetic fields). Such fields affect objects because of the intrinsic properties  (e.g., mass or charge) and positions of the objects.\nAn object may possess a property known as electric charge. Since an electric field exerts force on a charged object, if the object has a positive charge, the force will be in the direction of the electric field vector at the location of the charge; if the charge is negative, the force will be in the opposite direction. \nThe magnitude of force is given by the quantity of the charge multiplied by the magnitude of the electric field vector,\n\n\n== Electrostatics ==\n\nThe electric potential at a point r in a static electric field E is given by the line integral\n\nwhere C is an arbitrary path from some fixed reference point to r. In electrostatics, the Maxwell-Faraday equation reveals that the curl \n  \n    \n      \n        \u2207\n        \u00d7\n        \n          E\n        \n      \n    \n    {\\textstyle \\nabla \\times \\mathbf {E} }\n   is zero, making the electric field conservative. Thus, the line integral above does not depend on the specific path C chosen but only on its endpoints, making \n  \n    \n      \n        \n          V\n          \n            \n              E\n            \n          \n        \n      \n    \n    {\\textstyle V_{\\mathbf {E} }}\n   well-defined everywhere. The gradient theorem then allows us to write:\n\nThis states that the electric field points \"downhill\" towards lower voltages. By Gauss's law, the potential can also be found to satisfy Poisson's equation:\n\n  \n    \n      \n        \n          \u2207\n        \n        \u22c5\n        \n          E\n        \n        =\n        \n          \u2207\n        \n        \u22c5\n        \n          (\n          \n            \u2212\n            \n              \u2207\n            \n            \n              V\n              \n                \n                  E\n                \n              \n            \n          \n          )\n        \n        =\n        \u2212\n        \n          \u2207\n          \n            2\n          \n        \n        \n          V\n          \n            \n              E\n            \n          \n        \n        =\n        \u03c1\n        \n          /\n        \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\nabla } \\cdot \\mathbf {E} =\\mathbf {\\nabla } \\cdot \\left(-\\mathbf {\\nabla } V_{\\mathbf {E} }\\right)=-\\nabla ^{2}V_{\\mathbf {E} }=\\rho /\\varepsilon _{0}}\n  where \u03c1 is the total charge density and \n  \n    \n      \n        \n          \u2207\n        \n        \u22c5\n      \n    \n    {\\textstyle \\mathbf {\\nabla } \\cdot }\n   denotes the divergence.\nThe concept of electric potential is closely linked with potential energy. A test charge, q, has an electric potential energy, UE, given by\n\n  \n    \n      \n        \n          U\n          \n            \n              E\n            \n          \n        \n        =\n        q\n        \n        V\n        .\n      \n    \n    {\\displaystyle U_{\\mathbf {E} }=q\\,V.}\n  The potential energy and hence, also the electric potential, is only defined up to an additive constant: one must arbitrarily choose a position where the potential energy and the electric potential are zero.\nThese equations cannot be used if \n  \n    \n      \n        \u2207\n        \u00d7\n        \n          E\n        \n        \u2260\n        \n          0\n        \n      \n    \n    {\\textstyle \\nabla \\times \\mathbf {E} \\neq \\mathbf {0} }\n  , i.e., in the case of a non-conservative electric field (caused by a changing magnetic field; see Maxwell's equations). The generalization of electric potential to this case is described in the section \u00a7 Generalization to electrodynamics.\n\n\n=== Electric potential due to a point charge ===\n\nThe electric potential arising from a point charge, Q, at a distance, r, from the location of Q is observed to be\n\nwhere \u03b50 is the permittivity of vacuum, VE is known as the Coulomb potential, and the ratio,\n\nis known as the Coulomb constant.\nThe electric potential at any location, \n  \n    \n      \n        \n          \n            r\n          \n        \n      \n    \n    {\\textstyle {\\textbf {r}}}\n  , in a system of point charges is equal to the sum of the individual electric potentials due to every point charge in the system. This fact simplifies calculations significantly, because addition of potential (scalar) fields is much easier than addition of the electric (vector) fields. Specifically, the potential of a set of discrete point charges qi at points ri becomes\n\nwhere\n\n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is a point at which the potential is evaluated.\n\n  \n    \n      \n        \n          \n            r\n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{i}}\n   is a point at which there is a nonzero charge.\n\n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n   is the charge at the point \n  \n    \n      \n        \n          \n            r\n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{i}}\n  .and the potential of a continuous charge distribution \u03c1(r) becomes\n\nWhere\n\n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is a point at which the potential is evaluated.\n\n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   is a region containing all the points at which the charge density is nonzero.\n\n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {r} '}\n   is a point inside \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  .\n\n  \n    \n      \n        \u03c1\n        (\n        \n          \n            r\n          \n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle \\rho (\\mathbf {r} ')}\n   is the charge density at the point \n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {r} '}\n  .The equations given above for the electric potential (and all the equations used here) are in the forms required by SI units. In some other (less common) systems of units, such as CGS-Gaussian, many of these equations would be altered.\n\n\n== Generalization to electrodynamics ==\nWhen time-varying magnetic fields are present (which is true whenever there are time-varying electric fields and vice versa), it is not possible to describe the electric field simply in terms of a scalar potential V because the electric field is no longer conservative: \n  \n    \n      \n        \n          \n            \u222b\n            \n              C\n            \n          \n          \n            E\n          \n          \u22c5\n          \n            d\n          \n          \n            \u2113\n          \n        \n      \n    \n    {\\displaystyle \\textstyle \\int _{C}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n   is path-dependent because \n  \n    \n      \n        \n          \u2207\n        \n        \u00d7\n        \n          E\n        \n        \u2260\n        \n          0\n        \n      \n    \n    {\\displaystyle \\mathbf {\\nabla } \\times \\mathbf {E} \\neq \\mathbf {0} }\n   (due to the Maxwell-Faraday equation).\nInstead, one can still define a scalar potential by also including the magnetic vector potential A. In particular, A is defined to satisfy:\n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \u2207\n        \n        \u00d7\n        \n          A\n        \n      \n    \n    {\\displaystyle \\mathbf {B} =\\mathbf {\\nabla } \\times \\mathbf {A} }\n  where B is the magnetic field. By the fundamental theorem of vector calculus, such an A can always be found, since the divergence of the magnetic field is always zero due to the absence of magnetic monopoles. Now, the quantity\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          E\n        \n        +\n        \n          \n            \n              \u2202\n              \n                A\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} =\\mathbf {E} +{\\frac {\\partial \\mathbf {A} }{\\partial t}}}\n  is a conservative field, since the curl of \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle \\mathbf {E} }\n   is canceled by the curl of \n  \n    \n      \n        \n          \n            \n              \u2202\n              \n                A\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\partial \\mathbf {A} }{\\partial t}}}\n   according to the Maxwell\u2013Faraday equation. One can therefore write\n\n  \n    \n      \n        \n          E\n        \n        =\n        \u2212\n        \n          \u2207\n        \n        V\n        \u2212\n        \n          \n            \n              \u2202\n              \n                A\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {E} =-\\mathbf {\\nabla } V-{\\frac {\\partial \\mathbf {A} }{\\partial t}},}\n  where V is the scalar potential defined by the conservative field F.\nThe electrostatic potential is simply the special case of this definition where A is time-invariant.  On the other hand, for time-varying fields,\n\n  \n    \n      \n        \u2212\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        \n          E\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        \u2260\n        \n          V\n          \n            (\n            b\n            )\n          \n        \n        \u2212\n        \n          V\n          \n            (\n            a\n            )\n          \n        \n      \n    \n    {\\displaystyle -\\int _{a}^{b}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}\\neq V_{(b)}-V_{(a)}}\n  unlike electrostatics.\n\n\n=== Gauge freedom ===\n\nThe electrostatic potential could have any constant added to it without affecting the electric field. In electrodynamics, the electric potential has infinitely many degrees of freedom. For any (possibly time-varying or space-varying) scalar field, \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n  , we can perform the following gauge transformation to find a new set of potentials that produce exactly the same electric and magnetic fields:\n\n  \n    \n      \n        \n          V\n          \n            \u2032\n          \n        \n        =\n        V\n        \u2212\n        \n          \n            \n              \u2202\n              \u03c8\n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle V^{\\prime }=V-{\\frac {\\partial \\psi }{\\partial t}}}\n  \n  \n    \n      \n        \n          \n            A\n          \n          \n            \u2032\n          \n        \n        =\n        \n          A\n        \n        +\n        \u2207\n        \u03c8\n      \n    \n    {\\displaystyle \\mathbf {A} ^{\\prime }=\\mathbf {A} +\\nabla \\psi }\n  Given different choices of gauge, the electric potential could have quite different properties. In the Coulomb gauge, the electric potential is given by Poisson's equation\n\n  \n    \n      \n        \n          \u2207\n          \n            2\n          \n        \n        V\n        =\n        \u2212\n        \n          \n            \u03c1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\nabla ^{2}V=-{\\frac {\\rho }{\\varepsilon _{0}}}}\n  just like in electrostatics. However, in the Lorenz gauge, the electric potential is a retarded potential that propagates at the speed of light and is the solution to an inhomogeneous wave equation:\n\n  \n    \n      \n        \n          \u2207\n          \n            2\n          \n        \n        V\n        \u2212\n        \n          \n            1\n            \n              c\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              V\n            \n            \n              \u2202\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \u2212\n        \n          \n            \u03c1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\nabla ^{2}V-{\\frac {1}{c^{2}}}{\\frac {\\partial ^{2}V}{\\partial t^{2}}}=-{\\frac {\\rho }{\\varepsilon _{0}}}}\n  \n\n\n== Units ==\nThe SI derived unit of electric potential is the volt (in honor of Alessandro Volta), denoted as V, which is why the electric potential difference between two points in space is known as a voltage. Older units are rarely used today.  Variants of the centimetre\u2013gram\u2013second system of units included a number of different units for electric potential, including the abvolt and the statvolt.\n\n\n== Galvani potential versus electrochemical potential ==\n\nInside metals (and other solids and liquids), the energy of an electron is affected not only by the electric potential, but also by the specific atomic environment that it is in. When a voltmeter is connected between two different types of metal, it measures the potential difference corrected for the different atomic environments. The quantity measured by a voltmeter is called electrochemical potential or fermi level, while the pure unadjusted electric potential, V, is sometimes called the Galvani potential, \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n  . The terms \"voltage\" and \"electric potential\" are a bit ambiguous but one may refer to either of these in different contexts.\n\n\n== See also ==\nAbsolute electrode potential\nElectrochemical potential\nElectrode potential\n\n\n== References ==\n\n\n== Further reading ==", "Temperature": "Temperature is a physical quantity that expresses quantitatively the perceptions of hotness and coldness. Temperature is measured with a thermometer.\nThermometers are calibrated in various temperature scales that historically have relied on various reference points and thermometric substances for definition. The most common scales are the Celsius scale with the unit symbol \u00b0C (formerly called centigrade), the Fahrenheit scale (\u00b0F), and the Kelvin scale (K), the latter being used predominantly for scientific purposes. The kelvin is one of the seven base units in the International System of Units (SI).\nAbsolute zero, i.e., zero kelvin or \u2212273.15 \u00b0C, is the lowest point in the thermodynamic temperature scale. Experimentally, it can be approached very closely but not actually reached, as recognized in the third law of thermodynamics. It would be impossible to extract energy as heat from a body at that temperature.\nTemperature is important in all fields of natural science, including physics, chemistry, Earth science, astronomy, medicine, biology, ecology, material science, metallurgy, mechanical engineering and geography as well as most aspects of daily life.\n\n\n== Effects ==\nMany physical processes are related to temperature; some of them are given below:\nthe physical properties of materials including the phase (solid, liquid, gaseous or plasma), density, solubility, vapor pressure, electrical conductivity, hardness, wear resistance, thermal conductivity, corrosion resistance, strength\nthe rate and extent to which chemical reactions occur\nthe amount and properties of thermal radiation emitted from the surface of an object\nair temperature affects all living organisms\nthe speed of sound, which in a gas is proportional to the square root of the absolute temperature\n\n\n== Scales ==\n\nTemperature scales need two values for definition: the point chosen as zero degrees and the magnitudes of the incremental unit of temperature.\nThe Celsius scale (\u00b0C) is used for common temperature measurements in most of the world. It is an empirical scale that developed historically, which led to its zero point 0 \u00b0C being defined as the freezing point of water, and 100 \u00b0C as the boiling point of water, both at atmospheric pressure at sea level. It was called a centigrade scale because of the 100-degree interval. Since the standardization of the kelvin in the International System of Units, it has subsequently been redefined in terms of the equivalent fixing points on the Kelvin scale, so that a temperature increment of one degree Celsius is the same as an increment of one kelvin, though numerically the scales differ by an exact offset of 273.15.\nThe Fahrenheit scale is in common use in the United States. Water freezes at 32 \u00b0F and boils at 212 \u00b0F at sea-level atmospheric pressure.\n\n\n=== Absolute zero ===\nAt the absolute zero of temperature, no energy can be removed from matter as heat, a fact expressed in the third law of thermodynamics. At this temperature, matter contains no macroscopic thermal energy, but still has quantum-mechanical zero-point energy as predicted by the uncertainty principle, although this does not enter into the definition of absolute temperature. Experimentally, absolute zero can be approached only very closely; it can never be reached (the lowest temperature attained by experiment is 100 pK). Theoretically, in a body at a temperature of absolute zero, all classical motion of its particles has ceased and they are at complete rest in this classical sense. The absolute zero, defined as 0 K, is exactly equal to \u2212273.15 \u00b0C, or \u2212459.67 \u00b0F.\n\n\n=== Absolute scales ===\nReferring to the Boltzmann constant, to the Maxwell\u2013Boltzmann distribution, and to the Boltzmann statistical mechanical definition of entropy, as distinct from the Gibbs definition, for independently moving microscopic particles, disregarding interparticle potential energy, by international agreement, a temperature scale is defined and said to be absolute because it is independent of the characteristics of particular thermometric substances and thermometer mechanisms. Apart from the absolute zero, it does not have a reference temperature. It is known as the Kelvin scale, widely used in science and technology. The kelvin (the unit name is spelled with a lower-case 'k') is the unit of temperature in the International System of Units (SI). The temperature of a body in a state of thermodynamic equilibrium is always positive relative to the absolute zero.\nBesides the internationally agreed Kelvin scale, there is also a thermodynamic temperature scale, invented by Lord Kelvin, also with its numerical zero at the absolute zero of temperature, but directly relating to purely macroscopic thermodynamic concepts, including the macroscopic entropy, though microscopically referable to the Gibbs statistical mechanical definition of entropy for the canonical ensemble, that takes interparticle potential energy into account, as well as independent particle motion so that it can account for measurements of temperatures near absolute zero. This scale has a reference temperature at the triple point of water, the numerical value of which is defined by measurements using the aforementioned internationally agreed Kelvin scale.\n\n\n=== Kelvin scale ===\nMany scientific measurements use the Kelvin temperature scale (unit symbol: K), named in honor of the physicist who first defined it. It is an absolute scale. Its numerical zero point, 0 K, is at the absolute zero of temperature. Since May, 2019, the kelvin has been defined through particle kinetic theory, and statistical mechanics. In the International System of Units (SI), the magnitude of the kelvin is defined in terms of the Boltzmann constant, the value of which is defined as fixed by international convention.\n\n\n=== Statistical mechanical versus thermodynamic temperature scales ===\nSince May 2019, the magnitude of the kelvin is defined in relation to microscopic phenomena, characterized in terms of statistical mechanics. Previously, but since 1954, the International System of Units defined a scale and unit for the kelvin as a thermodynamic temperature, by using the reliably reproducible temperature of the triple point of water as a second reference point, the first reference point being 0 K at absolute zero.Historically, the temperature of the triple point of water was defined as exactly 273.16 K. Today it is an empirically measured quantity. The freezing point of water at sea-level atmospheric pressure occurs at very close to 273.15 K (0 \u00b0C).\n\n\n== Classification of scales ==\nThere are various kinds of temperature scale. It may be convenient to classify them as empirically and theoretically based. Empirical temperature scales are historically older, while theoretically based scales arose in the middle of the nineteenth century.\n\n\n=== Empirical scales ===\nEmpirically based temperature scales rely directly on measurements of simple macroscopic physical properties of materials. For example, the length of a column of mercury, confined in a glass-walled capillary tube, is dependent largely on temperature and is the basis of the very useful mercury-in-glass thermometer. Such scales are valid only within convenient ranges of temperature. For example, above the boiling point of mercury, a mercury-in-glass thermometer is impracticable. Most materials expand with temperature increase, but some materials, such as water, contract with temperature increase over some specific range, and then they are hardly useful as thermometric materials. A material is of no use as a thermometer near one of its phase-change temperatures, for example, its boiling-point.\nIn spite of these limitations, most generally used practical thermometers are of the empirically based kind. Especially, it was used for calorimetry, which contributed greatly to the discovery of thermodynamics. Nevertheless, empirical thermometry has serious drawbacks when judged as a basis for theoretical physics. Empirically based thermometers, beyond their base as simple direct measurements of ordinary physical properties of thermometric materials, can be re-calibrated, by use of theoretical physical reasoning, and this can extend their range of adequacy.\n\n\n=== Theoretical scales ===\nTheoretically based temperature scales are based directly on theoretical arguments, especially those of kinetic theory and thermodynamics. They are more or less ideally realized in practically feasible physical devices and materials. Theoretically based temperature scales are used to provide calibrating standards for practical empirically based thermometers.\n\n\n==== Microscopic statistical mechanical scale ====\nIn physics, the internationally agreed conventional temperature scale is called the Kelvin scale. It is calibrated through the internationally agreed and prescribed value of the Boltzmann constant, referring to motions of microscopic particles, such as atoms, molecules, and electrons, constituent in the body whose temperature is to be measured. In contrast with the thermodynamic temperature scale invented by Kelvin, the presently conventional Kelvin temperature is not defined through comparison with the temperature of a reference state of a standard body, nor in terms of macroscopic thermodynamics.\nApart from the absolute zero of temperature, the Kelvin temperature of a body in a state of internal thermodynamic equilibrium is defined by measurements of suitably chosen of its physical properties, such as have precisely known theoretical explanations in terms of the Boltzmann constant. That constant refers to chosen kinds of motion of microscopic particles in the constitution of the body. In those kinds of motion, the particles move individually, without mutual interaction. Such motions are typically interrupted by inter-particle collisions, but for temperature measurement, the motions are chosen so that, between collisions, the non-interactive segments of their trajectories are known to be accessible to accurate measurement. For this purpose, interparticle potential energy is disregarded.\nIn an ideal gas, and in other theoretically understood bodies, the Kelvin temperature is defined to be proportional to the average kinetic energy of non-interactively moving microscopic particles, which can be measured by suitable techniques. The proportionality constant is a simple multiple of the Boltzmann constant. If molecules, atoms, or electrons, are emitted from material and their velocities are measured, the spectrum of their velocities often nearly obeys a theoretical law called the Maxwell\u2013Boltzmann distribution, which gives a well-founded measurement of temperatures for which the law holds. There have not yet been successful experiments of this same kind that directly use the Fermi\u2013Dirac distribution for thermometry, but perhaps that will be achieved in the future.The speed of sound in a gas can be calculated theoretically from the molecular character of the gas, from its temperature and pressure, and from the value of the Boltzmann constant. For a gas of known molecular character and pressure, this provides a relation between temperature and the Boltzmann constant. Those quantities can be known or measured more precisely than can the thermodynamic variables that define the state of a sample of water at its triple point. Consequently, taking the value of the Boltzmann constant as a primarily defined reference of exactly defined value, a measurement of the speed of sound can provide a more precise measurement of the temperature of the gas.Measurement of the spectrum of electromagnetic radiation from an ideal three-dimensional black body can provide an accurate temperature measurement because the frequency of maximum spectral radiance of black-body radiation is directly proportional to the temperature of the black body; this is known as Wien's displacement law and has a theoretical explanation in Planck's law and the Bose\u2013Einstein law.\nMeasurement of the spectrum of noise-power produced by an electrical resistor can also provide accurate temperature measurement. The resistor has two terminals and is in effect a one-dimensional body. The Bose-Einstein law for this case indicates that the noise-power is directly proportional to the temperature of the resistor and to the value of its resistance and to the noise bandwidth. In a given frequency band, the noise-power has equal contributions from every frequency and is called Johnson noise. If the value of the resistance is known then the temperature can be found.\n\n\n==== Macroscopic thermodynamic scale ====\nHistorically, till May 2019, the definition of the Kelvin scale was that invented by Kelvin, based on a ratio of quantities of energy in processes in an ideal Carnot engine, entirely in terms of macroscopic thermodynamics. That Carnot engine was to work between two temperatures, that of the body whose temperature was to be measured, and a reference, that of a body at the temperature of the triple point of water. Then the reference temperature, that of the triple point, was defined to be exactly 273.16 K. Since May 2019, that value has not been fixed by definition but is to be measured through microscopic phenomena, involving the Boltzmann constant, as described above. The microscopic statistical mechanical definition does not have a reference temperature.\n\n\n==== Ideal gas ====\nA material on which a macroscopically defined temperature scale may be based is the ideal gas. The pressure exerted by a fixed volume and mass of an ideal gas is directly proportional to its temperature. Some natural gases show so nearly ideal properties over suitable temperature range that they can be used for thermometry; this was important during the development of thermodynamics and is still of practical importance today. The ideal gas thermometer is, however, not theoretically perfect for thermodynamics. This is because the entropy of an ideal gas at its absolute zero of temperature is not a positive semi-definite quantity, which puts the gas in violation of the third law of thermodynamics. In contrast to real materials, the ideal gas does not liquefy or solidify, no matter how cold it is. Alternatively thinking, the ideal gas law, refers to the limit of infinitely high temperature and zero pressure; these conditions guarantee non-interactive motions of the constituent molecules.\n\n\n== Kinetic theory approach ==\nThe magnitude of the kelvin is now defined in terms of kinetic theory, derived from the value of the Boltzmann constant.\nKinetic theory provides a microscopic account of temperature for some bodies of material, especially gases, based on macroscopic systems' being composed of many microscopic particles, such as molecules and ions of various species, the particles of a species being all alike. It explains macroscopic phenomena through the classical mechanics of the microscopic particles. The equipartition theorem of kinetic theory asserts that each classical degree of freedom of a freely moving particle has an average kinetic energy of kBT/2 where kB denotes the Boltzmann constant. The translational motion of the particle has three degrees of freedom, so that, except at very low temperatures where quantum effects predominate, the average translational kinetic energy of a freely moving particle in a system with temperature T will be 3kBT/2.\nMolecules, such as oxygen (O2), have more degrees of freedom than single spherical atoms: they undergo rotational and vibrational motions as well as translations. Heating results in an increase of temperature due to an increase in the average translational kinetic energy of the molecules. Heating will also cause, through equipartitioning, the energy associated with vibrational and rotational modes to increase. Thus a diatomic gas will require more energy input to increase its temperature by a certain amount, i.e. it will have a greater heat capacity than a monatomic gas.\nAs noted above, the speed of sound in a gas can be calculated from the molecular character of the gas, from its temperature and pressure, and from the value of the Boltzmann constant. Taking the value of the Boltzmann constant as a primarily defined reference of exactly defined value, a measurement of the speed of sound can provide a more precise measurement of the temperature of the gas.It is possible to measure the average kinetic energy of constituent microscopic particles if they are allowed to escape from the bulk of the system, through a small hole in the containing wall. The spectrum of velocities has to be measured, and the average calculated from that. It is not necessarily the case that the particles that escape and are measured have the same velocity distribution as the particles that remain in the bulk of the system, but sometimes a good sample is possible.\n\n\n== Thermodynamic approach ==\nTemperature is one of the principal quantities in the study of thermodynamics. Formerly, the magnitude of the kelvin was defined in thermodynamic terms, but nowadays, as mentioned above, it is defined in terms of kinetic theory.\nThe thermodynamic temperature is said to be absolute for two reasons. One is that its formal character is independent of the properties of particular materials. The other reason is that its zero is, in a sense, absolute, in that it indicates absence of microscopic classical motion of the constituent particles of matter, so that they have a limiting specific heat of zero for zero temperature, according to the third law of thermodynamics. Nevertheless, a thermodynamic temperature does in fact have a definite numerical value that has been arbitrarily chosen by tradition and is dependent on the property of particular materials; it is simply less arbitrary than relative \"degrees\" scales such as Celsius and Fahrenheit.  Being an absolute scale with one fixed point (zero), there is only one degree of freedom left to arbitrary choice, rather than two as in relative scales. For the Kelvin scale since May 2019, by international convention, the choice has been made to use knowledge of modes of operation of various thermometric devices, relying on microscopic kinetic theories about molecular motion. The numerical scale is settled by a conventional definition of the value of the Boltzmann constant, which relates macroscopic temperature to average microscopic kinetic energy of particles such as molecules. Its numerical value is arbitrary, and an alternate, less widely used absolute temperature scale exists called the Rankine scale, made to be aligned with the Fahrenheit scale as Kelvin is with Celsius.\nThe thermodynamic definition of temperature is due to Kelvin. It is framed in terms of an idealized device called a Carnot engine, imagined to run in a fictive continuous cycle of successive processes that traverse a cycle of states of its working body. The engine takes in a quantity of heat Q1 from a hot reservoir and passes out a lesser quantity of waste heat Q2 < 0 to a cold reservoir. The net heat energy absorbed by the working body is passed, as thermodynamic work, to a work reservoir, and is considered to be the output of the engine. The cycle is imagined to run so slowly that at each point of the cycle the working body is in a state of thermodynamic equilibrium. The successive processes of the cycle are thus imagined to run reversibly with no entropy production. Then the quantity of entropy taken in from the hot reservoir when the working body is heated is equal to that passed to the cold reservoir when the working body is cooled. Then the absolute or thermodynamic temperatures, T1 and T2,  of the reservoirs are defined such that\n\nThe zeroth law of thermodynamics allows this definition to be used to measure the absolute or thermodynamic temperature of an arbitrary body of interest, by making the other heat reservoir have the same temperature as the body of interest.\nKelvin's original work postulating absolute temperature was published in 1848. It was based on the work of Carnot, before the formulation of the first law of thermodynamics. Carnot had no sound understanding of heat and no specific concept of entropy. He wrote of 'caloric' and said that all the caloric that passed from the hot reservoir was passed into the cold reservoir. Kelvin wrote in his 1848 paper that his scale was absolute in the sense that it was defined \"independently of the properties of any particular kind of matter\". His definitive publication, which sets out the definition just stated, was printed in 1853, a paper read in 1851.Numerical details were formerly settled by making one of the heat reservoirs a cell at the triple point of water, which was defined to have an absolute temperature of 273.16 K. Nowadays, the numerical value is instead obtained from measurement through the microscopic statistical mechanical international definition, as above.\n\n\n=== Intensive variability ===\nIn thermodynamic terms, temperature is an intensive variable because it is equal to a differential coefficient of one extensive variable with respect to another, for a given body. It thus has the dimensions of a ratio of two extensive variables. In thermodynamics, two bodies are often considered as connected by contact with a common wall, which has some specific permeability properties. Such specific permeability can be referred to a specific intensive variable. An example is a diathermic wall that is permeable only to heat; the intensive variable for this case is temperature. When the two bodies have been connected through the specifically permeable wall for a very long time, and have settled to a permanent steady state, the relevant intensive variables are equal in the two bodies; for a diathermal wall, this statement is sometimes called the zeroth law of thermodynamics.In particular, when the body is described by stating its internal energy U, an extensive variable, as a function of its entropy S, also an extensive variable, and other state variables V, N, with U = U (S, V, N), then the temperature is equal to the partial derivative of the internal energy with respect to the entropy:\n\nLikewise, when the body is described by stating its entropy S as a function of its internal energy U, and other state variables V, N, with S = S (U, V, N), then the reciprocal of the temperature is equal to the partial derivative of the entropy with respect to the internal energy:\n\nThe above definition, equation (1), of the absolute temperature, is due to Kelvin. It refers to systems closed to the transfer of matter and has a special emphasis on directly experimental procedures. A presentation of thermodynamics by Gibbs starts at a more abstract level and deals with systems open to the transfer of matter; in this development of thermodynamics, the equations (2) and (3) above are actually alternative definitions of temperature.\n\n\n=== Local thermodynamic equilibrium ===\nReal-world bodies are often not in thermodynamic equilibrium and not homogeneous. For the study by methods of classical irreversible thermodynamics, a body is usually spatially and temporally divided conceptually into 'cells' of small size. If classical thermodynamic equilibrium conditions for matter are fulfilled to good approximation in such a 'cell', then it is homogeneous and a temperature exists for it. If this is so for every 'cell' of the body, then local thermodynamic equilibrium is said to prevail throughout the body.It makes good sense, for example, to say of the extensive variable U, or of the extensive variable S, that it has a density per unit volume or a quantity per unit mass of the system, but it makes no sense to speak of the density of temperature per unit volume or quantity of temperature per unit mass of the system. On the other hand, it makes no sense to speak of the internal energy at a point, while when local thermodynamic equilibrium prevails, it makes good sense to speak of the temperature at a point. Consequently, the temperature can vary from point to point in a medium that is not in global thermodynamic equilibrium, but in which there is local thermodynamic equilibrium.\nThus, when local thermodynamic equilibrium prevails in a body, the temperature can be regarded as a spatially varying local property in that body, and this is because the temperature is an intensive variable.\n\n\n== Basic theory ==\nTemperature is a measure of a quality of a state of a material.  The quality may be regarded as a more abstract entity than any particular temperature scale that measures it, and is called hotness by some writers. The quality of hotness refers to the state of material only in a particular locality, and in general, apart from bodies held in a steady state of thermodynamic equilibrium, hotness varies from place to place. It is not necessarily the case that a material in a particular place is in a state that is steady and nearly homogeneous enough to allow it to have a well-defined hotness or temperature. Hotness may be represented abstractly as a one-dimensional manifold. Every valid temperature scale has its own one-to-one map into the hotness manifold.When two systems in thermal contact are at the same temperature no heat transfers between them. When a temperature difference does exist heat flows spontaneously from the warmer system to the colder system until they are in thermal equilibrium. Such heat transfer occurs by conduction or by thermal radiation.Experimental physicists, for example Galileo and Newton, found that there are indefinitely many empirical temperature scales. Nevertheless, the zeroth law of thermodynamics says that they all measure the same quality. This means that for a body in its own state of internal thermodynamic equilibrium, every correctly calibrated thermometer, of whatever kind, that measures the temperature of the body, records one and the same temperature. For a body that is not in its own state of internal thermodynamic equilibrium, different thermometers can record different temperatures, depending respectively on the mechanisms of operation of the thermometers.\n\n\n=== Bodies in thermodynamic equilibrium ===\nFor experimental physics, hotness means that, when comparing any two given bodies in their respective separate thermodynamic equilibria, any two suitably given empirical thermometers with numerical scale readings will agree as to which is the hotter of the two given bodies, or that they have the same temperature. This does not require the two thermometers to have a linear relation between their numerical scale readings, but it does require that the relation between their numerical readings shall be strictly monotonic. A definite sense of greater hotness can be had, independently of calorimetry, of thermodynamics, and of properties of particular materials, from Wien's displacement law of thermal radiation: the temperature of a bath of thermal radiation is proportional, by a universal constant, to the frequency of the maximum of its frequency spectrum; this frequency is always positive, but can have values that tend to zero. Thermal radiation is initially defined for a cavity in thermodynamic equilibrium. These physical facts justify a mathematical statement that hotness exists on an ordered one-dimensional manifold. This is a fundamental character of temperature and thermometers for bodies in their own thermodynamic equilibrium.Except for a system undergoing a first-order phase change such as the melting of ice, as a closed system receives heat, without a change in its volume and without a change in external force fields acting on it, its temperature rises. For a system undergoing such a phase change so slowly that departure from thermodynamic equilibrium can be neglected, its temperature remains constant as the system is supplied with latent heat. Conversely, a loss of heat from a closed system, without phase change, without change of volume, and without a change in external force fields acting on it, decreases its temperature.\n\n\n=== Bodies in a steady state but not in thermodynamic equilibrium ===\nWhile for bodies in their own thermodynamic equilibrium states, the notion of temperature requires that all empirical thermometers must agree as to which of two bodies is the hotter or that they are at the same temperature, this requirement is not safe for bodies that are in steady states though not in thermodynamic equilibrium. It can then well be that different empirical thermometers disagree about which is hotter, and if this is so, then at least one of the bodies does not have a well-defined absolute thermodynamic temperature. Nevertheless, anyone has given body and any one suitable empirical thermometer can still support notions of empirical, non-absolute, hotness, and temperature, for a suitable range of processes. This is a matter for study in non-equilibrium thermodynamics.\n\n\n=== Bodies not in a steady state ===\nWhen a body is not in a steady-state, then the notion of temperature becomes even less safe than for a body in a steady state not in thermodynamic equilibrium. This is also a matter for study in non-equilibrium thermodynamics.\n\n\n=== Thermodynamic equilibrium axiomatics ===\nFor the axiomatic treatment of thermodynamic equilibrium, since the 1930s, it has become customary to refer to a zeroth law of thermodynamics. The customarily stated minimalist version of such a law postulates only that all bodies, which when thermally connected would be in thermal equilibrium, should be said to have the same temperature by definition, but by itself does not establish temperature as a quantity expressed as a real number on a scale. A more physically informative version of such a law views empirical temperature as a chart on a hotness manifold. While the zeroth law permits the definitions of many different empirical scales of temperature, the second law of thermodynamics selects the definition of a single preferred, absolute temperature, unique up to an arbitrary scale factor, whence called the thermodynamic temperature. If internal energy is considered as a function of the volume and entropy of a homogeneous system in thermodynamic equilibrium, thermodynamic absolute temperature appears as the partial derivative of internal energy with respect the entropy at constant volume. Its natural, intrinsic origin or null point is absolute zero at which the entropy of any system is at a minimum. Although this is the lowest absolute temperature described by the model, the third law of thermodynamics postulates that absolute zero cannot be attained by any physical system.\n\n\n== Heat capacity ==\n\nWhen an energy transfer to or from a body is only as heat, the state of the body changes. Depending on the surroundings and the walls separating them from the body, various changes are possible in the body. They include chemical reactions, increase of pressure, increase of temperature and phase change. For each kind of change under specified conditions, the heat capacity is the ratio of the quantity of heat transferred to the magnitude of the change.For example, if the change is an increase in temperature at constant volume, with no phase change and no chemical change, then the temperature of the body rises and its pressure increases. The quantity of heat transferred, \u0394Q, divided by the observed temperature change, \u0394T, is the body's heat capacity at constant volume:\n\n  \n    \n      \n        \n          C\n          \n            V\n          \n        \n        =\n        \n          \n            \n              \u0394\n              Q\n            \n            \n              \u0394\n              T\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle C_{V}={\\frac {\\Delta Q}{\\Delta T}}.}\n  If heat capacity is measured for a well-defined amount of substance, the specific heat is the measure of the heat required to increase the temperature of such a unit quantity by one unit of temperature. For example, raising the temperature of water by one kelvin (equal to one degree Celsius) requires 4186 joules per kilogram (J/kg).\n\n\n== Measurement ==\n\nTemperature measurement using modern scientific thermometers and temperature scales goes back at least as far as the early 18th century, when Daniel Gabriel Fahrenheit adapted a thermometer (switching to mercury) and a scale both developed by Ole Christensen R\u00f8mer. Fahrenheit's scale is still in use in the United States for non-scientific applications.\nTemperature is measured with thermometers that may be calibrated to a variety of temperature scales. In most of the world (except for Belize, Myanmar, Liberia and the United States), the Celsius scale is used for most temperature measuring purposes. Most scientists measure temperature using the Celsius scale and thermodynamic temperature using the Kelvin scale, which is the Celsius scale offset so that its null point is 0 K = \u2212273.15 \u00b0C, or absolute zero. Many engineering fields in the US, notably high-tech and US federal specifications (civil and military), also use the Kelvin and Celsius scales. Other engineering fields in the US also rely upon the Rankine scale (a shifted Fahrenheit scale) when working in thermodynamic-related disciplines such as combustion.\n\n\n=== Units ===\nThe basic unit of temperature in the International System of Units (SI) is the kelvin. It has the symbol K.\nFor everyday applications, it is often convenient to use the Celsius scale, in which 0 \u00b0C corresponds very closely to the freezing point of water and 100 \u00b0C is its boiling point at sea level. Because liquid droplets commonly exist in clouds at sub-zero temperatures, 0 \u00b0C is better defined as the melting point of ice. In this scale, a temperature difference of 1 degree Celsius is the same as a 1kelvin increment, but the scale is offset by the temperature at which ice melts (273.15 K).\nBy international agreement, until May 2019, the Kelvin and Celsius scales were defined by two fixing points: absolute zero and the triple point of Vienna Standard Mean Ocean Water, which is water specially prepared with a specified blend of hydrogen and oxygen isotopes. Absolute zero was defined as precisely 0 K and \u2212273.15 \u00b0C. It is the temperature at which all classical translational motion of the particles comprising matter ceases and they are at complete rest in the classical model. Quantum-mechanically, however, zero-point motion remains and has an associated energy, the zero-point energy.  Matter is in its ground state, and contains no thermal energy. The temperatures 273.16 K and 0.01 \u00b0C were defined as those of the triple point of water. This definition served the following purposes: it fixed the magnitude of the kelvin as being precisely 1 part in 273.16 parts of the difference between absolute zero and the triple point of water; it established that one kelvin has precisely the same magnitude as one degree on the Celsius scale; and it established the difference between the null points of these scales as being 273.15 K (0 K = \u2212273.15 \u00b0C and 273.16 K = 0.01 \u00b0C). Since 2019, there has been a new definition based on the Boltzmann constant, but the scales are scarcely changed.\nIn the United States, the Fahrenheit scale is the most widely used. On this scale the freezing point of water corresponds to 32 \u00b0F and the boiling point to 212 \u00b0F. The Rankine scale, still used in fields of chemical engineering in the US, is an absolute scale based on the Fahrenheit increment.\n\n\n==== Historical scales ====\n\nThe following temperature scales are in use or have historically been used for measuring temperature:\n\nKelvin scale\nCelsius scale\nFahrenheit scale\nRankine scale\nDelisle scale\nNewton scale\nR\u00e9aumur scale\nR\u00f8mer scale\n\n\n==== Plasma physics ====\nThe field of plasma physics deals with phenomena of electromagnetic nature that involve very high temperatures. It is customary to express temperature as energy in a unit related to the electronvolt or kiloelectronvolt (eV/kB or keV/kB). The corresponding energy, which is dimensionally distinct from temperature, is then calculated as the product of the Boltzmann constant and temperature, \n  \n    \n      \n        E\n        =\n        \n          k\n          \n            B\n          \n        \n        T\n      \n    \n    {\\displaystyle E=k_{\\text{B}}T}\n  . Then, 1 eV/kB is 11605 K. In the study of QCD matter one routinely encounters temperatures of the order of a few hundred MeV/kB, equivalent to about 1012 K.\n\n\n== Theoretical foundation ==\n\nHistorically, there are several scientific approaches to the explanation of temperature: the classical thermodynamic description based on macroscopic empirical variables that can be measured in a laboratory; the kinetic theory of gases which relates the macroscopic description to the probability distribution of the energy of motion of gas particles; and a microscopic explanation based on statistical physics and quantum mechanics. In addition, rigorous and purely mathematical treatments have provided an axiomatic approach to classical thermodynamics and temperature. Statistical physics provides a deeper understanding by describing the atomic behavior of matter and derives macroscopic properties from statistical averages of microscopic states, including both classical and quantum states. In the fundamental physical description, the temperature may be measured directly in units of energy. However, in the practical systems of measurement for science, technology, and commerce, such as the modern metric system of units, the macroscopic and the microscopic descriptions are interrelated by the Boltzmann constant, a proportionality factor that scales temperature to the microscopic mean kinetic energy.\nThe microscopic description in statistical mechanics is based on a model that analyzes a system into its fundamental particles of matter or into a set of classical or quantum-mechanical oscillators and considers the system as a statistical ensemble of microstates. As a collection of classical material particles, the temperature is a measure of the mean energy of motion, called translational kinetic energy, of the particles, whether in solids, liquids, gases, or plasmas. The kinetic energy, a concept of classical mechanics, is half the mass of a particle times its speed squared. In this mechanical interpretation of thermal motion, the kinetic energies of material particles may reside in the velocity of the particles of their translational or vibrational motion or in the inertia of their rotational modes. In monatomic perfect gases and, approximately, in most gas and in simple metals, the temperature is a measure of the mean particle translational kinetic energy, 3/2 kBT. It also determines the probability distribution function of energy. In condensed matter, and particularly in solids, this purely mechanical description is often less useful and the oscillator model provides a better description to account for quantum mechanical phenomena. Temperature determines the statistical occupation of the microstates of the ensemble. The microscopic definition of temperature is only meaningful in the thermodynamic limit, meaning for large ensembles of states or particles, to fulfill the requirements of the statistical model.\nKinetic energy is also considered as a component of thermal energy. The thermal energy may be partitioned into independent components attributed to the degrees of freedom of the particles or to the modes of oscillators in a thermodynamic system. In general, the number of these degrees of freedom that are available for the equipartitioning of energy depends on the temperature, i.e. the energy region of the interactions under consideration. For solids, the thermal energy is associated primarily with the vibrations of its atoms or molecules about their equilibrium position. In an ideal monatomic gas, the kinetic energy is found exclusively in the purely translational motions of the particles. In other systems, vibrational and rotational motions also contribute degrees of freedom.\n\n\n=== Kinetic theory of gases ===\n\nMaxwell and Boltzmann developed a kinetic theory that yields a fundamental understanding of temperature in gases.\nThis theory also explains the ideal gas law and the observed heat capacity of monatomic (or 'noble') gases.\n\nThe ideal gas law is based on observed empirical relationships between pressure (p), volume (V), and temperature (T), and was recognized long before the kinetic theory of gases was developed (see Boyle's and Charles's laws). The ideal gas law states:\n\n  \n    \n      \n        p\n        V\n        =\n        n\n        R\n        T\n        ,\n      \n    \n    {\\displaystyle pV=nRT,}\n  where n is the number of moles of gas and R = 8.314462618... J\u22c5mol\u22121\u22c5K\u22121 is the gas constant.\nThis relationship gives us our first hint that there is an absolute zero on the temperature scale, because it only holds if the temperature is measured on an absolute scale such as Kelvin's. The ideal gas law allows one to measure temperature on this absolute scale using the gas thermometer. The temperature in kelvins can be defined as the pressure in pascals of one mole of gas in a container of one cubic meter, divided by the gas constant.\nAlthough it is not a particularly convenient device, the gas thermometer provides an essential theoretical basis by which all thermometers can be calibrated. As a practical matter, it is not possible to use a gas thermometer to measure absolute zero temperature since the gases condense into a liquid long before the temperature reaches zero. It is possible, however, to extrapolate to absolute zero by using the ideal gas law, as shown in the figure.\nThe kinetic theory assumes that pressure is caused by the force associated with individual atoms striking the walls, and that all energy is translational kinetic energy. Using a sophisticated symmetry argument, Boltzmann deduced what is now called the Maxwell\u2013Boltzmann probability distribution function for the velocity of particles in an ideal gas. From that probability distribution function, the average kinetic energy (per particle) of a monatomic ideal gas is\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            rms\n          \n          \n            2\n          \n        \n        =\n        \n          \n            3\n            2\n          \n        \n        \n          k\n          \n            B\n          \n        \n        T\n        ,\n      \n    \n    {\\displaystyle E_{\\text{k}}={\\frac {1}{2}}mv_{\\text{rms}}^{2}={\\frac {3}{2}}k_{\\text{B}}T,}\n  where the Boltzmann constant kB is the ideal gas constant divided by the Avogadro number, and \n  \n    \n      \n        \n          v\n          \n            rms\n          \n        \n        =\n        \n          \n            \u27e8\n            \n              v\n              \n                2\n              \n            \n            \u27e9\n          \n        \n        =\n        \n          \n            \u27e8\n            \n              v\n              \u22c5\n              v\n            \n            \u27e9\n          \n        \n      \n    \n    {\\textstyle v_{\\text{rms}}={\\sqrt {\\langle v^{2}\\rangle }}={\\sqrt {\\langle \\mathbf {v\\cdot v} \\rangle }}}\n   is the root-mean-square speed. This direct proportionality between temperature and mean molecular kinetic energy is a special case of the equipartition theorem, and holds only in the classical limit of a perfect gas. It does not hold exactly for most substances.\n\n\n=== Zeroth law of thermodynamics ===\n\nWhen two otherwise isolated bodies are connected together by a rigid physical path impermeable to matter, there is the spontaneous transfer of energy as heat from the hotter to the colder of them. Eventually, they reach a state of mutual thermal equilibrium, in which heat transfer has ceased, and the bodies' respective state variables have settled to become unchanging.One statement of the zeroth law of thermodynamics is that if two systems are each in thermal equilibrium with a third system, then they are also in thermal equilibrium with each other.This statement helps to define temperature but it does not, by itself, complete the definition. An empirical temperature is a numerical scale for the hotness of a thermodynamic system. Such hotness may be defined as existing on a one-dimensional manifold, stretching between hot and cold. Sometimes the zeroth law is stated to include the existence of a unique universal hotness manifold, and of numerical scales on it, so as to provide a complete definition of empirical temperature. To be suitable for empirical thermometry, a material must have a monotonic relation between hotness and some easily measured state variable, such as pressure or volume, when all other relevant coordinates are fixed. An exceptionally suitable system is the ideal gas, which can provide a temperature scale that matches the absolute Kelvin scale. The Kelvin scale is defined on the basis of the second law of thermodynamics.\n\n\n=== Second law of thermodynamics ===\n\nAs an alternative to considering or defining the zeroth law of thermodynamics, it was the historical development in thermodynamics to define temperature in terms of the second law of thermodynamics which deals with entropy. The second law states that any process will result in either no change or a net increase in the entropy of the universe. This can be understood in terms of probability.\nFor example, in a series of coin tosses, a perfectly ordered system would be one in which either every toss comes up heads or every toss comes up tails. This means the outcome is always 100% the same result. In contrast, many mixed (disordered) outcomes are possible, and their number increases with each toss. Eventually, the combinations of ~50% heads and ~50% tails dominate, and obtaining an outcome significantly different from 50/50 becomes increasingly unlikely. Thus the system naturally progresses to a state of maximum disorder or entropy.\nAs temperature governs the transfer of heat between two systems and the universe tends to progress toward a maximum of entropy, it is expected that there is some relationship between temperature and entropy. A heat engine is a device for converting thermal energy into mechanical energy, resulting in the performance of work. An analysis of the Carnot heat engine provides the necessary relationships. According to energy conservation and energy being a state function that does not change over a full cycle, the work from a heat engine over a full cycle is equal to the net heat, i.e. the sum of the heat put into the system at high temperature, qH > 0, and the waste heat given off at the low temperature, qC < 0.The efficiency is the work divided by the heat input:\n\nwhere wcy is the work done per cycle. The efficiency depends only on |qC|/qH. Because qC and qH correspond to heat transfer at the temperatures TC and TH, respectively, |qC|/qH should be some function of these temperatures:\n\nCarnot's theorem states that all reversible engines operating between the same heat reservoirs are equally efficient. Thus, a heat engine operating between T1 and T3 must have the same efficiency as one consisting of two cycles, one between T1 and T2, and the second between T2 and T3. This can only be the case if\n\n  \n    \n      \n        \n          q\n          \n            13\n          \n        \n        =\n        \n          \n            \n              \n                q\n                \n                  1\n                \n              \n              \n                q\n                \n                  2\n                \n              \n            \n            \n              \n                q\n                \n                  2\n                \n              \n              \n                q\n                \n                  3\n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle q_{13}={\\frac {q_{1}q_{2}}{q_{2}q_{3}}},}\n  which implies\n\n  \n    \n      \n        \n          q\n          \n            13\n          \n        \n        =\n        f\n        \n          (\n          \n            \n              T\n              \n                1\n              \n            \n            ,\n            \n              T\n              \n                3\n              \n            \n          \n          )\n        \n        =\n        f\n        \n          (\n          \n            \n              T\n              \n                1\n              \n            \n            ,\n            \n              T\n              \n                2\n              \n            \n          \n          )\n        \n        f\n        \n          (\n          \n            \n              T\n              \n                2\n              \n            \n            ,\n            \n              T\n              \n                3\n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle q_{13}=f\\left(T_{1},T_{3}\\right)=f\\left(T_{1},T_{2}\\right)f\\left(T_{2},T_{3}\\right).}\n  Since the first function is independent of T2, this temperature must cancel on the right side, meaning f(T1, T3) is of the form g(T1)/g(T3) (i.e. f(T1, T3) = f(T1, T2)f(T2, T3) = g(T1)/g(T2) \u00b7 g(T2)/g(T3) = g(T1)/g(T3)), where g is a function of a single temperature. A temperature scale can now be chosen with the property that\n\nSubstituting (6) back into (4) gives a relationship for the efficiency in terms of temperature:\n\nFor TC = 0 K the efficiency is 100% and that efficiency becomes greater than 100% below 0 K. Since an efficiency greater than 100% violates the first law of thermodynamics, this implies that 0 K is the minimum possible temperature. In fact, the lowest temperature ever obtained in a macroscopic system was 20 nK, which was achieved in 1995 at NIST. Subtracting the right hand side of (5) from the middle portion and rearranging gives\n\n  \n    \n      \n        \n          \n            \n              q\n              \n                H\n              \n            \n            \n              T\n              \n                H\n              \n            \n          \n        \n        +\n        \n          \n            \n              q\n              \n                C\n              \n            \n            \n              T\n              \n                C\n              \n            \n          \n        \n        =\n        0\n        ,\n      \n    \n    {\\displaystyle {\\frac {q_{\\text{H}}}{T_{\\text{H}}}}+{\\frac {q_{\\text{C}}}{T_{\\text{C}}}}=0,}\n  where the negative sign indicates heat ejected from the system. This relationship suggests the existence of a state function, S, whose change characteristically vanishes for a complete cycle if it is defined by\n\nwhere the subscript indicates a reversible process. This function corresponds to the entropy of the system, which was described previously. Rearranging (8) gives a formula for temperature in terms of fictive infinitesimal quasi-reversible elements of entropy and heat:\n\nFor a constant-volume system where entropy S(E) is a function of its energy E, dE = dqrev and (9) gives\n\ni.e. the reciprocal of the temperature is the rate of increase of entropy with respect to energy at constant volume.\n\n\n=== Definition from statistical mechanics ===\nStatistical mechanics defines temperature based on a system's fundamental degrees of freedom.  Eq.(10) is the defining relation of temperature, where the entropy \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is defined (up to a constant) by the logarithm of the number of microstates of the system in the given macrostate (as specified in the microcanonical ensemble): \n\n  \n    \n      \n        S\n        =\n        \n          k\n          \n            \n              B\n            \n          \n        \n        ln\n        \u2061\n        (\n        W\n        )\n      \n    \n    {\\displaystyle S=k_{\\mathrm {B} }\\ln(W)}\n  where \n  \n    \n      \n        \n          k\n          \n            \n              B\n            \n          \n        \n      \n    \n    {\\displaystyle k_{\\mathrm {B} }}\n   is the Boltzmann constant and W is the number of microstates with the energy E of the system (degeneracy).\nWhen two systems with different temperatures are put into purely thermal connection, heat will flow from the higher temperature system to the lower temperature one; thermodynamically this is understood by the second law of thermodynamics: The total change in entropy following a transfer of energy \n  \n    \n      \n        \u0394\n        E\n      \n    \n    {\\displaystyle \\Delta E}\n   from system 1 to system 2 is:\n\n  \n    \n      \n        \u0394\n        S\n        =\n        \u2212\n        (\n        d\n        S\n        \n          /\n        \n        d\n        E\n        \n          )\n          \n            1\n          \n        \n        \u22c5\n        \u0394\n        E\n        +\n        (\n        d\n        S\n        \n          /\n        \n        d\n        E\n        \n          )\n          \n            2\n          \n        \n        \u22c5\n        \u0394\n        E\n        =\n        \n          (\n          \n            \n              \n                1\n                \n                  T\n                  \n                    2\n                  \n                \n              \n            \n            \u2212\n            \n              \n                1\n                \n                  T\n                  \n                    1\n                  \n                \n              \n            \n          \n          )\n        \n        \u0394\n        E\n      \n    \n    {\\displaystyle \\Delta S=-(dS/dE)_{1}\\cdot \\Delta E+(dS/dE)_{2}\\cdot \\Delta E=\\left({\\frac {1}{T_{2}}}-{\\frac {1}{T_{1}}}\\right)\\Delta E}\n  and is thus positive if \n  \n    \n      \n        \n          T\n          \n            1\n          \n        \n        >\n        \n          T\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle T_{1}>T_{2}}\n  \nFrom the point of view of statistical mechanics, the total number of microstates in the combined system 1 + system 2 is \n  \n    \n      \n        \n          N\n          \n            1\n          \n        \n        \u22c5\n        \n          N\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle N_{1}\\cdot N_{2}}\n  , the logarithm of which (times the Boltzmann constant) is the sum of their entropies; thus a flow of heat from high to low temperature, which brings an increase in total entropy, is more likely than any other scenario (normally it is much more likely), as there are more microstates in the resulting macrostate.\n\n\n=== Generalized temperature from single-particle statistics ===\nIt is possible to extend the definition of temperature even to systems of few particles, like in a quantum dot. The generalized temperature is obtained by considering time ensembles instead of configuration-space ensembles given in statistical mechanics in the case of thermal and particle exchange between a small system of fermions (N even less than 10) with a single/double-occupancy system. The finite quantum grand canonical ensemble, obtained under the hypothesis of ergodicity and orthodicity, allows expressing the generalized temperature from the ratio of the average time of occupation \n  \n    \n      \n        \n          \u03c4\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\tau _{1}}\n   and \n  \n    \n      \n        \n          \u03c4\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\tau _{2}}\n   of the single/double-occupancy system:\n\n  \n    \n      \n        T\n        =\n        \n          \n            \n              E\n              \u2212\n              \n                E\n                \n                  F\n                \n              \n              \n                (\n                \n                  1\n                  +\n                  \n                    \n                      3\n                      \n                        2\n                        N\n                      \n                    \n                  \n                \n                )\n              \n            \n            \n              \n                k\n                \n                  B\n                \n              \n              ln\n              \u2061\n              \n                (\n                \n                  2\n                  \n                    \n                      \n                        \u03c4\n                        \n                          2\n                        \n                      \n                      \n                        \u03c4\n                        \n                          1\n                        \n                      \n                    \n                  \n                \n                )\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle T={\\frac {E-E_{\\text{F}}\\left(1+{\\frac {3}{2N}}\\right)}{k_{\\text{B}}\\ln \\left(2{\\frac {\\tau _{2}}{\\tau _{1}}}\\right)}},}\n  where EF is the Fermi energy. This generalized temperature tends to the ordinary temperature when N goes to infinity.\n\n\n=== Negative temperature ===\n\nOn the empirical temperature scales that are not referenced to absolute zero, a negative temperature is one below the zero-point of the scale used. For example, dry ice has a sublimation temperature of \u221278.5 \u00b0C which is equivalent to \u2212109.3 \u00b0F. On the absolute Kelvin scale this temperature is 194.6 K. No body can be brought to exactly 0 K (the temperature of the ideally coldest possible body) by any finite practicable process; this is a consequence of the third law of thermodynamics.The international kinetic theory temperature of a body cannot take negative values. The thermodynamic temperature scale, however, is not so constrained.\nFor a body of matter, there can sometimes be conceptually defined, in terms of microscopic degrees of freedom, namely particle spins, a subsystem, with a temperature other than that of the whole body. When the body is in its own state of internal thermodynamic equilibrium, the temperatures of the whole body and of the subsystem must be the same. The two temperatures can differ when, by work through externally imposed force fields, energy can be transferred to and from the subsystem, separately from the rest of the body; then the whole body is not in its own state of internal thermodynamic equilibrium. There is an upper limit of energy such a spin subsystem can attain.\nConsidering the subsystem to be in a temporary state of virtual thermodynamic equilibrium, it is possible to obtain a negative temperature on the thermodynamic scale. Thermodynamic temperature is the inverse of the derivative of the subsystem's entropy with respect to its internal energy. As the subsystem's internal energy increases, the entropy increases for some range, but eventually attains a maximum value and then begins to decrease as the highest energy states begin to fill. At the point of maximum entropy, the temperature function shows the behavior of a singularity, because the slope of the entropy as a function of energy decreases to zero and then turns negative. As the subsystem's entropy reaches its maximum, its thermodynamic temperature goes to positive infinity, switching to negative infinity as the slope turns negative. Such negative temperatures are hotter than any positive temperature. Over time, when the subsystem is exposed to the rest of the body, which has a positive temperature, energy is transferred as heat from the negative temperature subsystem to the positive temperature system. The kinetic theory temperature is not defined for such subsystems.\n\n\n== Examples ==\n\n\n== See also ==\n\n\n== Notes and references ==\nNotes\nCitations\n\n\n=== Bibliography of cited references ===\nAdkins, C.J. (1968/1983). Equilibrium Thermodynamics, (1st edition 1968), third edition 1983, Cambridge University Press, Cambridge UK, ISBN 0-521-25445-0.\nBuchdahl, H.A. (1966). The Concepts of Classical Thermodynamics, Cambridge University Press, Cambridge.\nJaynes, E.T. (1965). Gibbs vs Boltzmann entropies, American Journal of Physics, 33(5), 391\u2013398.\nMiddleton, W.E.K. (1966). A History of the Thermometer and its Use in Metrology, Johns Hopkins Press, Baltimore.\nMiller, J (2013). \"Cooling molecules the optoelectric way\". Physics Today. 66 (1): 12\u201314. Bibcode:2013PhT....66a..12M. doi:10.1063/pt.3.1840. Archived from the original on 2016-05-15. Retrieved 2013-07-25.\nPartington, J.R. (1949). An Advanced Treatise on Physical Chemistry, volume 1, Fundamental Principles. The Properties of Gases, Longmans, Green & Co., London, pp. 175\u2013177.\nPippard, A.B. (1957/1966). Elements of Classical Thermodynamics for Advanced Students of Physics, original publication 1957, reprint 1966, Cambridge University Press, Cambridge UK.\nQuinn, T.J. (1983). Temperature, Academic Press, London, ISBN 0-12-569680-9.\nSchooley, J.F. (1986). Thermometry, CRC Press, Boca Raton, ISBN 0-8493-5833-7.\nRoberts, J.K., Miller, A.R. (1928/1960). Heat and Thermodynamics, (first edition 1928), fifth edition, Blackie & Son Limited, Glasgow.\nThomson, W. (Lord Kelvin) (1848). On an absolute thermometric scale founded on Carnot's theory of the motive power of heat, and calculated from Regnault's observations, Proc. Camb. Phil. Soc. (1843/1863) 1, No. 5: 66\u201371.\nThomson, W. (Lord Kelvin) (March 1851). \"On the Dynamical Theory of Heat, with numerical results deduced from Mr Joule's equivalent of a Thermal Unit, and M. Regnault's Observations on Steam\". Transactions of the Royal Society of Edinburgh. XX (part II): 261\u2013268, 289\u2013298.\nTruesdell, C.A. (1980). The Tragicomical History of Thermodynamics, 1822\u20131854, Springer, New York, ISBN 0-387-90403-4.\nTschoegl, N.W. (2000). Fundamentals of Equilibrium and Steady-State Thermodynamics, Elsevier, Amsterdam, ISBN 0-444-50426-5.\nZeppenfeld, M.; Englert, B.G.U.; Gl\u00f6ckner, R.; Prehn, A.; Mielenz, M.; Sommer, C.; van Buuren, L.D.; Motsch, M.; Rempe, G. (2012). \"Sysiphus cooling of electrically trapped polyatomic molecules\". Nature. 491 (7425): 570\u2013573. arXiv:1208.0046. Bibcode:2012Natur.491..570Z. doi:10.1038/nature11595. PMID 23151480. S2CID 4367940.\n\n\n== Further reading ==\nChang, Hasok (2004). Inventing Temperature: Measurement and Scientific Progress. Oxford: Oxford University Press. ISBN 978-0-19-517127-3.\nZemansky, Mark Waldo (1964). Temperatures Very Low and Very High. Princeton, NJ: Van Nostrand.\n\n\n== External links ==\n\nCurrent map of global surface temperatures", "Energy_level": "A quantum mechanical system or particle that is bound\u2014that is, confined spatially\u2014can only take on certain discrete values of energy, called energy levels. This contrasts with classical particles, which can have any amount of energy. The term is commonly used for the energy levels of the electrons in atoms, ions, or molecules, which are bound by the electric field of the nucleus, but can also refer to energy levels of nuclei or vibrational or rotational energy levels in molecules. The energy spectrum of a system with such discrete energy levels is said to be quantized.\nIn chemistry and atomic physics, an electron shell, or principal energy level, may be thought of as the orbit of one or more electrons around an atom's nucleus. The closest shell to the nucleus is called the \"1 shell\" (also called \"K shell\"), followed by the \"2 shell\" (or \"L shell\"), then the \"3 shell\" (or \"M shell\"), and so on farther and farther from the nucleus. The shells correspond with the principal quantum numbers (n = 1, 2, 3, 4 ...) or are labeled alphabetically with letters used in the X-ray notation (K, L, M, N...).\nEach shell can contain only a fixed number of electrons: The first shell can hold up to two electrons, the second shell can hold up to eight (2 + 6) electrons, the third shell can hold up to 18 (2 + 6 + 10) and so on. The general formula is that the nth shell can in principle hold up to 2n2 electrons. Since electrons are electrically attracted to the nucleus, an atom's electrons will generally occupy outer shells only if the more inner shells have already been completely filled by other electrons. However, this is not a strict requirement: atoms may have two or even three incomplete outer shells. (See Madelung rule for more details.) For an explanation of why electrons exist in these shells see electron configuration.If the potential energy is set to zero at infinite distance from the atomic nucleus or molecule, the usual convention, then bound electron states have negative potential energy.\nIf an atom, ion, or molecule is at the lowest possible energy level, it and its electrons are said to be in the ground state. If it is at a higher energy level, it is said to be excited, or any electrons that have higher energy than the ground state are excited. An energy level is regarded as degenerate if there is more than one measurable quantum mechanical state associated with it.\n\n\n== Explanation ==\n\nQuantized energy levels result from the wave behavior of particles, which gives a relationship between a particle's energy and its wavelength. For a confined particle such as an electron in an atom, the wave functions that have well defined energies have the form of a standing wave.  States having well-defined energies are called stationary states because they are the states that do not change in time. Informally, these states correspond to a whole number of wavelengths of the wavefunction along a closed path (a path that ends where it started), such as a circular orbit around an atom, where the number of wavelengths gives the type of atomic orbital (0 for s-orbitals, 1 for p-orbitals and so on).  Elementary examples that show mathematically how energy levels come about are the particle in a box and the quantum harmonic oscillator.\nAny superposition (linear combination) of energy states is also a quantum state, but such states change with time and do not have well-defined energies. A measurement of the energy results in the collapse of the wavefunction, which results in a new state that consists of just a single energy state. Measurement of the possible energy levels of an object is called spectroscopy.\n\n\n== History ==\nThe first evidence of quantization in atoms was the observation of spectral lines in light from the sun in the early 1800s by Joseph von Fraunhofer and William Hyde Wollaston. The notion of energy levels was proposed in 1913 by Danish physicist Niels Bohr in the Bohr theory of the atom. The modern quantum mechanical theory giving an explanation of these energy levels in terms of the Schr\u00f6dinger equation was advanced by Erwin Schr\u00f6dinger and Werner Heisenberg in 1926.\n\n\n== Atoms ==\n\n\n=== Intrinsic energy levels ===\nIn the formulas for energy of electrons at various levels given below in an atom, the zero point for energy is set when the electron in question has completely left the atom, i.e. when the electron's principal quantum number n = \u221e. When the electron is bound to the atom in any closer value of n, the electron's energy is lower and is considered negative.\n\n\n==== Orbital state energy level: atom/ion with nucleus + one electron ====\nAssume there is one electron in a given atomic orbital in a hydrogen-like atom (ion). The energy of its state is mainly determined by the electrostatic interaction of the (negative) electron with the (positive) nucleus. The energy levels of an electron around a nucleus are given by : \n\n  \n    \n      \n        \n          E\n          \n            n\n          \n        \n        =\n        \u2212\n        h\n        c\n        \n          R\n          \n            \u221e\n          \n        \n        \n          \n            \n              Z\n              \n                2\n              \n            \n            \n              n\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle E_{n}=-hcR_{\\infty }{\\frac {Z^{2}}{n^{2}}}}\n  (typically between 1 eV and 103 eV), \nwhere R\u221e is the Rydberg constant, Z is the atomic number, n is the principal quantum number, h is Planck's constant, and c is the speed of light. For hydrogen-like atoms (ions) only, the Rydberg levels depend only on the principal quantum number n.\nThis equation is obtained from combining the Rydberg formula for any hydrogen-like element (shown below) with E = h\u2009\u03bd = h\u2009c\u2009/\u2009\u03bb assuming that the principal quantum number n above = n1 in the Rydberg formula and n2 = \u221e (principal quantum number of the energy level the electron descends from, when emitting a photon). The Rydberg formula was derived from empirical spectroscopic emission data.\n\n  \n    \n      \n        \n          \n            1\n            \u03bb\n          \n        \n        =\n        R\n        \n          Z\n          \n            2\n          \n        \n        \n          (\n          \n            \n              \n                1\n                \n                  n\n                  \n                    1\n                  \n                  \n                    2\n                  \n                \n              \n            \n            \u2212\n            \n              \n                1\n                \n                  n\n                  \n                    2\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle {\\frac {1}{\\lambda }}=RZ^{2}\\left({\\frac {1}{n_{1}^{2}}}-{\\frac {1}{n_{2}^{2}}}\\right)}\n  An equivalent formula can be derived quantum mechanically from the time-independent Schr\u00f6dinger equation with a kinetic energy Hamiltonian operator using a wave function as an eigenfunction to obtain the energy levels as eigenvalues, but the Rydberg constant would be replaced by other fundamental physics constants.\n\n\n==== Electron-electron interactions in atoms ====\nIf there is more than one electron around the atom, electron-electron-interactions raise the energy level. These interactions are often neglected if the spatial overlap of the electron wavefunctions is low.\nFor multi-electron atoms, interactions between electrons cause the preceding equation to be no longer accurate as stated simply with Z as the atomic number. A simple (though not complete) way to understand this is as a shielding effect, where the outer electrons see an effective nucleus of reduced charge, since the inner electrons are bound tightly to the nucleus and partially cancel its charge. This leads to an approximate correction where Z is substituted with an effective nuclear charge symbolized as Zeff that depends strongly on the principal quantum number.\n\nIn such cases, the orbital types (determined by the azimuthal quantum number \u2113) as well as their levels within the molecule affect Zeff and therefore also affect the various atomic electron energy levels. The Aufbau principle of filling an atom with electrons for an electron configuration takes these differing energy levels into account. For filling an atom with electrons in the ground state, the lowest energy levels are filled first and consistent with the Pauli exclusion principle, the Aufbau principle, and Hund's rule.\n\n\n==== Fine structure splitting ====\nFine structure arises from relativistic kinetic energy corrections, spin\u2013orbit coupling (an electrodynamic interaction between the electron's spin and motion and the nucleus's electric field) and the Darwin term (contact term interaction of s shell electrons inside the nucleus). These affect the levels by a typical order of magnitude of 10\u22123 eV.\n\n\n==== Hyperfine structure ====\n\nThis even finer structure is due to electron\u2013nucleus spin\u2013spin interaction, resulting in a typical change in the energy levels by a typical order of magnitude of 10\u22124 eV.\n\n\n=== Energy levels due to external fields ===\n\n\n==== Zeeman effect ====\n\nThere is an interaction energy associated with the magnetic dipole moment, \u03bcL, arising from the electronic orbital angular momentum, L, given by\n\n  \n    \n      \n        U\n        =\n        \u2212\n        \n          \n            \u03bc\n          \n          \n            L\n          \n        \n        \u22c5\n        \n          B\n        \n      \n    \n    {\\displaystyle U=-{\\boldsymbol {\\mu }}_{L}\\cdot \\mathbf {B} }\n  with\n\n  \n    \n      \n        \u2212\n        \n          \n            \u03bc\n          \n          \n            L\n          \n        \n        =\n        \n          \n            \n              \n                e\n                \u210f\n              \n              \n                2\n                m\n              \n            \n          \n        \n        \n          L\n        \n        =\n        \n          \u03bc\n          \n            B\n          \n        \n        \n          L\n        \n      \n    \n    {\\displaystyle -{\\boldsymbol {\\mu }}_{L}={\\dfrac {e\\hbar }{2m}}\\mathbf {L} =\\mu _{B}\\mathbf {L} }\n  .Additionally taking into account the magnetic momentum arising from the electron spin.\nDue to relativistic effects (Dirac equation), there is a magnetic momentum, \u03bcS, arising from the electron spin\n\n  \n    \n      \n        \u2212\n        \n          \n            \u03bc\n          \n          \n            S\n          \n        \n        =\n        \u2212\n        \n          \u03bc\n          \n            B\n          \n        \n        \n          g\n          \n            S\n          \n        \n        \n          S\n        \n      \n    \n    {\\displaystyle -{\\boldsymbol {\\mu }}_{S}=-\\mu _{B}g_{S}\\mathbf {S} }\n  ,with gS the electron-spin g-factor (about 2), resulting in a total magnetic moment, \u03bc,\n\n  \n    \n      \n        \n          \u03bc\n        \n        =\n        \n          \n            \u03bc\n          \n          \n            L\n          \n        \n        +\n        \n          \n            \u03bc\n          \n          \n            S\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\mu }}={\\boldsymbol {\\mu }}_{L}+{\\boldsymbol {\\mu }}_{S}}\n  .The interaction energy therefore becomes\n\n  \n    \n      \n        \n          U\n          \n            B\n          \n        \n        =\n        \u2212\n        \n          \u03bc\n        \n        \u22c5\n        \n          B\n        \n        =\n        \n          \u03bc\n          \n            B\n          \n        \n        B\n        (\n        \n          M\n          \n            L\n          \n        \n        +\n        \n          g\n          \n            S\n          \n        \n        \n          M\n          \n            S\n          \n        \n        )\n      \n    \n    {\\displaystyle U_{B}=-{\\boldsymbol {\\mu }}\\cdot \\mathbf {B} =\\mu _{B}B(M_{L}+g_{S}M_{S})}\n  .\n\n\n==== Stark effect ====\n\n\n== Molecules ==\nChemical bonds between atoms in a molecule form because they make the situation more stable for the involved atoms, which generally means the sum energy level for the involved atoms in the molecule is lower than if the atoms were not so bonded. As separate atoms approach each other to covalently bond, their orbitals affect each other's energy levels to form bonding and antibonding molecular orbitals. The energy level of the bonding orbitals is lower, and the energy level of the antibonding orbitals is higher. For the bond in the molecule to be stable, the covalent bonding electrons occupy the lower energy bonding orbital, which may be signified by such symbols as \u03c3 or \u03c0 depending on the situation. Corresponding anti-bonding orbitals can be signified by adding an asterisk to get \u03c3* or \u03c0* orbitals. A non-bonding orbital in a molecule is an orbital with electrons in outer shells which do not participate in bonding and its energy level is the same as that of the constituent atom. Such orbitals can be designated as n orbitals. The electrons in an n orbital are typically lone pairs.\n \nIn polyatomic molecules, different vibrational and rotational energy levels are also involved.\nRoughly speaking, a molecular energy state, i.e. an eigenstate of the molecular Hamiltonian, is the sum of the electronic, vibrational, rotational, nuclear, and translational components, such that:\n\nwhere Eelectronic is an eigenvalue of the electronic molecular Hamiltonian (the value of the potential energy surface) at the equilibrium geometry of the molecule.\nThe molecular energy levels are labelled by the molecular term symbols. The specific energies of these components vary with the specific energy state and the substance.\n\n\n=== Energy level diagrams ===\nThere are various types of energy level diagrams for bonds between atoms in a molecule.\n\nExamples\nMolecular orbital diagrams, Jablonski diagrams, and Franck\u2013Condon diagrams.\n\n\n== Energy level transitions ==\n\nElectrons in atoms and molecules can change (make transitions in) energy levels by emitting or absorbing a photon (of electromagnetic radiation), whose energy must be exactly equal to the energy difference between the two levels.\nElectrons can also be completely removed from a chemical species such as an atom, molecule, or ion. Complete removal of an electron from an atom can be a form of ionization, which is effectively moving the electron out to an orbital with an infinite principal quantum number, in effect so far away so as to have practically no more effect on the remaining atom (ion). For various types of atoms, there are 1st, 2nd, 3rd, etc. ionization energies for removing the 1st, then the 2nd, then the 3rd, etc. of the highest energy electrons, respectively, from the atom originally in the ground state. Energy in corresponding opposite quantities can also be released, sometimes in the form of photon energy, when electrons are added to positively charged ions or sometimes atoms. Molecules can also undergo transitions in their vibrational or rotational energy levels. Energy level transitions can also be nonradiative, meaning emission or absorption of a photon is not involved.\nIf an atom, ion, or molecule is at the lowest possible energy level, it and its electrons are said to be in the ground state. If it is at a higher energy level, it is said to be excited, or any electrons that have higher energy than the ground state are excited. Such a species can be excited to a higher energy level by absorbing a photon whose energy is equal to the energy difference between the levels. Conversely, an excited species can go to a lower energy level by spontaneously emitting a photon equal to the energy difference. A photon's energy is equal to Planck's constant (h) times its frequency (f) and thus is proportional to its frequency, or inversely to its wavelength (\u03bb).\n\u0394E = h\u2009f = h\u2009c\u2009/\u2009\u03bb,since c, the speed of light, equals to f\u2009\u03bbCorrespondingly, many kinds of spectroscopy are based on detecting the frequency or wavelength of the emitted or absorbed photons to provide information on the material analyzed, including information on the energy levels and electronic structure of materials obtained by analyzing the spectrum.\nAn asterisk is commonly used to designate an excited state. An electron transition in a molecule's bond from a ground state to an excited state may have a designation such as \u03c3 \u2192 \u03c3*, \u03c0 \u2192 \u03c0*, or n \u2192 \u03c0* meaning excitation of an electron from a \u03c3 bonding to a \u03c3 antibonding orbital, from a \u03c0 bonding to a \u03c0 antibonding orbital, or from an n non-bonding to a \u03c0 antibonding orbital. Reverse electron transitions for all these types of excited molecules are also possible to return to their ground states, which can be designated as \u03c3* \u2192 \u03c3, \u03c0* \u2192 \u03c0, or \u03c0* \u2192 n.\nA transition in an energy level of an electron in a molecule may be combined with a vibrational transition and called a vibronic transition. A vibrational and rotational transition may be combined by rovibrational coupling. In rovibronic coupling, electron transitions are simultaneously combined with both vibrational and rotational transitions. Photons involved in transitions may have energy of various ranges in the electromagnetic spectrum, such as X-ray, ultraviolet, visible light, infrared, or microwave radiation, depending on the type of transition. In a very general way, energy level differences between electronic states are larger, differences between vibrational levels are intermediate, and differences between rotational levels are smaller, although there can be overlap. Translational energy levels are practically continuous and can be calculated as kinetic energy using classical mechanics.\nHigher temperature causes fluid atoms and molecules to move faster increasing their translational energy, and thermally excites molecules to higher average amplitudes of vibrational and rotational modes (excites the molecules to higher internal energy levels). This means that as temperature rises, translational, vibrational, and rotational contributions to molecular heat capacity let molecules absorb heat and hold more internal energy. Conduction of heat typically occurs as molecules or atoms collide transferring the heat between each other. At even higher temperatures, electrons can be thermally excited to higher energy orbitals in atoms or molecules. A subsequent drop of an electron to a lower energy level can release a photon, causing a possibly colored glow.\nAn electron farther from the nucleus has higher potential energy than an electron closer to the nucleus, thus it becomes less bound to the nucleus, since its potential energy is negative and inversely dependent on its distance from the nucleus.\n\n\n== Crystalline materials ==\nCrystalline solids are found to have energy bands, instead of or in addition to energy levels. Electrons can take on any energy within an unfilled band. At first this appears to be an exception to the requirement for energy levels. However, as shown in band theory, energy bands are actually made up of many discrete energy levels which are too close together to resolve. Within a band the number of levels is of the order of the number of atoms in the crystal, so although electrons are actually restricted to these energies, they appear to be able to take on a continuum of values. The important energy levels in a crystal are the top of the valence band, the bottom of the conduction band, the Fermi level, the vacuum level, and the energy levels of any defect states in the crystal.\n\n\n== See also ==\nPerturbation theory (quantum mechanics)\nComputational chemistry\n\n\n== References ==", "Velocity": "Velocity is the directional speed of an object in motion as an indication of its rate of change in position as observed from a particular frame of reference and as measured by a particular standard of time (e.g. 60 km/h northbound). Velocity is a fundamental concept in kinematics, the branch of classical mechanics that describes the motion of bodies.\nVelocity is a physical vector quantity; both magnitude and direction are needed to define it. The scalar absolute value (magnitude) of velocity is called speed, being a coherent derived unit whose quantity is measured in the SI (metric system) as metres per second (m/s or m\u22c5s\u22121). For example, \"5 metres per second\" is a scalar, whereas \"5 metres per second east\" is a vector. If there is a change in speed, direction or both, then the object is said to be undergoing an acceleration.\n\n\n== Constant velocity vs acceleration ==\nTo have a constant velocity, an object must have a constant speed in a constant direction. Constant direction constrains the object to motion in a straight path thus, a constant velocity means motion in a straight line at a constant speed.\nFor example, a car moving at a constant 20 kilometres per hour in a circular path has a constant speed, but does not have a constant velocity because its direction changes. Hence, the car is considered to be undergoing an acceleration.\n\n\n== Difference between speed and velocity ==\n\nSpeed, the scalar magnitude of a velocity vector, denotes only how fast an object is moving.\n\n\n== Equation of motion ==\n\n\n=== Average velocity ===\nVelocity is defined as the rate of change of position with respect to time, which may also be referred to as the instantaneous velocity to emphasize the distinction from the average velocity. In some applications the average velocity of an object might be needed, that is to say, the constant velocity that would provide the same resultant displacement as a variable velocity in the same time interval, v(t), over some time period \u0394t. Average velocity can be calculated as:\n\n  \n    \n      \n        \n          \n            \n              v\n              \u00af\n            \n          \n        \n        =\n        \n          \n            \n              \u0394\n              \n                x\n              \n            \n            \n              \u0394\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {\\bar {v}}}={\\frac {\\Delta {\\boldsymbol {x}}}{\\Delta t}}.}\n  The average velocity is always less than or equal to the average speed of an object. This can be seen by realizing that while distance is always strictly increasing, displacement can increase or decrease in magnitude as well as change direction.\nIn terms of a displacement-time (x vs. t) graph, the instantaneous velocity (or, simply, velocity) can be thought of as the slope of the tangent line to the curve at any point, and the average velocity as the slope of the secant line between two points with t coordinates equal to the boundaries of the time period for the average velocity.\nThe average velocity is the same as the velocity averaged over time \u2013 that is to say, its time-weighted average, which may be calculated as the time integral of the velocity:\n\n  \n    \n      \n        \n          \n            \n              v\n              \u00af\n            \n          \n        \n        =\n        \n          \n            1\n            \n              \n                t\n                \n                  1\n                \n              \n              \u2212\n              \n                t\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \u222b\n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \n          v\n        \n        (\n        t\n        )\n         \n        d\n        t\n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\bar {v}}}={1 \\over t_{1}-t_{0}}\\int _{t_{0}}^{t_{1}}{\\boldsymbol {v}}(t)\\ dt,}\n  where we may identify\n\n  \n    \n      \n        \u0394\n        \n          x\n        \n        =\n        \n          \u222b\n          \n            \n              t\n              \n                0\n              \n            \n          \n          \n            \n              t\n              \n                1\n              \n            \n          \n        \n        \n          v\n        \n        (\n        t\n        )\n         \n        d\n        t\n      \n    \n    {\\displaystyle \\Delta {\\boldsymbol {x}}=\\int _{t_{0}}^{t_{1}}{\\boldsymbol {v}}(t)\\ dt}\n  and\n\n  \n    \n      \n        \u0394\n        t\n        =\n        \n          t\n          \n            1\n          \n        \n        \u2212\n        \n          t\n          \n            0\n          \n        \n        .\n      \n    \n    {\\displaystyle \\Delta t=t_{1}-t_{0}.}\n  \n\n\n=== Instantaneous velocity ===\n\nIf we consider v as velocity and x as the displacement (change in position) vector, then we can express the (instantaneous) velocity of a particle or object, at any particular time t, as the derivative of the position with respect to time:\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          lim\n          \n            \n              \u0394\n              t\n            \n            \u2192\n            0\n          \n        \n        \n          \n            \n              \u0394\n              \n                x\n              \n            \n            \n              \u0394\n              t\n            \n          \n        \n        =\n        \n          \n            \n              d\n              \n                x\n              \n            \n            \n              d\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {v}}=\\lim _{{\\Delta t}\\to 0}{\\frac {\\Delta {\\boldsymbol {x}}}{\\Delta t}}={\\frac {d{\\boldsymbol {x}}}{dt}}.}\n  From this derivative equation, in the one-dimensional case it can be seen that the area under a velocity vs. time (v vs. t graph) is the displacement, x. In calculus terms, the integral of the velocity function v(t) is the displacement function x(t). In the figure, this corresponds to the yellow area under the curve labeled s (s being an alternative notation for displacement).\n\n  \n    \n      \n        \n          x\n        \n        =\n        \u222b\n        \n          v\n        \n         \n        d\n        t\n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {x}}=\\int {\\boldsymbol {v}}\\ dt.}\n  Since the derivative of the position with respect to time gives the change in position (in metres) divided by the change in time (in seconds), velocity is measured in metres per second (m/s). Although the concept of an instantaneous velocity might at first seem counter-intuitive, it may be thought of as the velocity that the object would continue to travel at if it stopped accelerating at that moment.\n\n\n=== Relationship to acceleration ===\nAlthough velocity is defined as the rate of change of position, it is often common to start with an expression for an object's acceleration. As seen by the three green tangent lines in the figure, an object's instantaneous acceleration at a point in time is the slope of the line tangent to the curve of a v(t) graph at that point. In other words, acceleration is defined as the derivative of velocity with respect to time:\n\n  \n    \n      \n        \n          a\n        \n        =\n        \n          \n            \n              d\n              \n                v\n              \n            \n            \n              d\n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {a}}={\\frac {d{\\boldsymbol {v}}}{dt}}.}\n  From there, we can obtain an expression for velocity as the area under an a(t) acceleration vs. time graph. As above, this is done using the concept of the integral:\n\n  \n    \n      \n        \n          v\n        \n        =\n        \u222b\n        \n          a\n        \n         \n        d\n        t\n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {v}}=\\int {\\boldsymbol {a}}\\ dt.}\n  \n\n\n==== Constant acceleration ====\nIn the special case of constant acceleration, velocity can be studied using the suvat equations. By considering a as being equal to some arbitrary constant vector, it is trivial to show that\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          u\n        \n        +\n        \n          a\n        \n        t\n      \n    \n    {\\displaystyle {\\boldsymbol {v}}={\\boldsymbol {u}}+{\\boldsymbol {a}}t}\n  with v as the velocity at time t and u as the velocity at time t = 0. By combining this equation with the suvat equation x = ut + at2/2, it is possible to relate the displacement and the average velocity by\n\n  \n    \n      \n        \n          x\n        \n        =\n        \n          \n            \n              (\n              \n                u\n              \n              +\n              \n                v\n              \n              )\n            \n            2\n          \n        \n        t\n        =\n        \n          \n            \n              v\n              \u00af\n            \n          \n        \n        t\n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {x}}={\\frac {({\\boldsymbol {u}}+{\\boldsymbol {v}})}{2}}t={\\boldsymbol {\\bar {v}}}t.}\n  It is also possible to derive an expression for the velocity independent of time, known as the Torricelli equation, as follows:\n\n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        \n          v\n        \n        \u22c5\n        \n          v\n        \n        =\n        (\n        \n          u\n        \n        +\n        \n          a\n        \n        t\n        )\n        \u22c5\n        (\n        \n          u\n        \n        +\n        \n          a\n        \n        t\n        )\n        =\n        \n          u\n          \n            2\n          \n        \n        +\n        2\n        t\n        (\n        \n          a\n        \n        \u22c5\n        \n          u\n        \n        )\n        +\n        \n          a\n          \n            2\n          \n        \n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v^{2}={\\boldsymbol {v}}\\cdot {\\boldsymbol {v}}=({\\boldsymbol {u}}+{\\boldsymbol {a}}t)\\cdot ({\\boldsymbol {u}}+{\\boldsymbol {a}}t)=u^{2}+2t({\\boldsymbol {a}}\\cdot {\\boldsymbol {u}})+a^{2}t^{2}}\n  \n\n  \n    \n      \n        (\n        2\n        \n          a\n        \n        )\n        \u22c5\n        \n          x\n        \n        =\n        (\n        2\n        \n          a\n        \n        )\n        \u22c5\n        (\n        \n          u\n        \n        t\n        +\n        \n          \n            \n              1\n              2\n            \n          \n        \n        \n          a\n        \n        \n          t\n          \n            2\n          \n        \n        )\n        =\n        2\n        t\n        (\n        \n          a\n        \n        \u22c5\n        \n          u\n        \n        )\n        +\n        \n          a\n          \n            2\n          \n        \n        \n          t\n          \n            2\n          \n        \n        =\n        \n          v\n          \n            2\n          \n        \n        \u2212\n        \n          u\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (2{\\boldsymbol {a}})\\cdot {\\boldsymbol {x}}=(2{\\boldsymbol {a}})\\cdot ({\\boldsymbol {u}}t+{\\tfrac {1}{2}}{\\boldsymbol {a}}t^{2})=2t({\\boldsymbol {a}}\\cdot {\\boldsymbol {u}})+a^{2}t^{2}=v^{2}-u^{2}}\n  \n\n  \n    \n      \n        \u2234\n        \n          v\n          \n            2\n          \n        \n        =\n        \n          u\n          \n            2\n          \n        \n        +\n        2\n        (\n        \n          a\n        \n        \u22c5\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle \\therefore v^{2}=u^{2}+2({\\boldsymbol {a}}\\cdot {\\boldsymbol {x}})}\n  where v = |v| etc.\nThe above equations are valid for both Newtonian mechanics and special relativity. Where Newtonian mechanics and special relativity differ is in how different observers would describe the same situation. In particular, in Newtonian mechanics, all observers agree on the value of t and the transformation rules for position create a situation in which all non-accelerating observers would describe the acceleration of an object with the same values. Neither is true for special relativity. In other words, only relative velocity can be calculated.\n\n\n=== Quantities that are dependent on velocity ===\nThe kinetic energy of a moving object is dependent on its velocity and is given by the equation\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}={\\tfrac {1}{2}}mv^{2}}\n  ignoring special relativity, where Ek is the kinetic energy and m is the mass. Kinetic energy is a scalar quantity as it depends on the square of the velocity, however a related quantity, momentum, is a vector and defined by\n\n  \n    \n      \n        \n          p\n        \n        =\n        m\n        \n          v\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {p}}=m{\\boldsymbol {v}}}\n  In special relativity, the dimensionless Lorentz factor appears frequently, and is given by\n\n  \n    \n      \n        \u03b3\n        =\n        \n          \n            1\n            \n              1\n              \u2212\n              \n                \n                  \n                    v\n                    \n                      2\n                    \n                  \n                  \n                    c\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\gamma ={\\frac {1}{\\sqrt {1-{\\frac {v^{2}}{c^{2}}}}}}}\n  where \u03b3 is the Lorentz factor and c is the speed of light.\nEscape velocity is the minimum speed a ballistic object needs to escape from a massive body such as Earth. It represents the kinetic energy that, when added to the object's gravitational potential energy (which is always negative), is equal to zero. The general formula for the escape velocity of an object at a distance r from the center of a planet with mass M is\n\n  \n    \n      \n        \n          v\n          \n            e\n          \n        \n        =\n        \n          \n            \n              \n                2\n                G\n                M\n              \n              r\n            \n          \n        \n        =\n        \n          \n            2\n            g\n            r\n          \n        \n        ,\n      \n    \n    {\\displaystyle v_{\\text{e}}={\\sqrt {\\frac {2GM}{r}}}={\\sqrt {2gr}},}\n  where G is the gravitational constant and g is the gravitational acceleration. The escape velocity from Earth's surface is about 11 200 m/s, and is irrespective of the direction of the object. This makes \"escape velocity\" somewhat of a misnomer, as the more correct term would be \"escape speed\": any object attaining a velocity of that magnitude, irrespective of atmosphere, will leave the vicinity of the base body as long as it doesn't intersect with something in its path.\n\n\n== Relative velocity ==\n\nRelative velocity is a measurement of velocity between two objects as determined in a single coordinate system. Relative velocity is fundamental in both classical and modern physics, since many systems in physics deal with the relative motion of two or more particles. In Newtonian mechanics, the relative velocity is independent of the chosen inertial reference frame. This is not the case anymore with special relativity in which velocities depend on the choice of reference frame.\nIf an object A is moving with velocity vector v and an object B with velocity vector w, then the velocity of object A relative to object B is defined as the difference of the two velocity vectors:\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            A\n            \n               relative to \n            \n            B\n          \n        \n        =\n        \n          v\n        \n        \u2212\n        \n          w\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}_{A{\\text{ relative to }}B}={\\boldsymbol {v}}-{\\boldsymbol {w}}}\n  Similarly, the relative velocity of object B moving with velocity w, relative to object A moving with velocity v is:\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            B\n            \n               relative to \n            \n            A\n          \n        \n        =\n        \n          w\n        \n        \u2212\n        \n          v\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}_{B{\\text{ relative to }}A}={\\boldsymbol {w}}-{\\boldsymbol {v}}}\n  Usually, the inertial frame chosen is that in which the latter of the two mentioned objects is in rest.\n\n\n=== Scalar velocities ===\nIn the one-dimensional case, the velocities are scalars and the equation is either:\n\n  \n    \n      \n        \n          v\n          \n            rel\n          \n        \n        =\n        v\n        \u2212\n        (\n        \u2212\n        w\n        )\n      \n    \n    {\\displaystyle v_{\\text{rel}}=v-(-w)}\n  , if the two objects are moving in opposite directions, or:\n\n  \n    \n      \n        \n          v\n          \n            rel\n          \n        \n        =\n        v\n        \u2212\n        (\n        +\n        w\n        )\n      \n    \n    {\\displaystyle v_{\\text{rel}}=v-(+w)}\n  , if the two objects are moving in the same direction.\n\n\n== Polar coordinates ==\n\nIn polar coordinates, a two-dimensional velocity is described by a radial velocity, defined as the component of velocity away from or toward the origin (also known as velocity made good), and an angular velocity, which is the rate of rotation about the origin (with positive quantities representing counter-clockwise rotation and negative quantities representing clockwise rotation, in a right-handed coordinate system).\nThe radial and angular velocities can be derived from the Cartesian velocity and displacement vectors by decomposing the velocity vector into radial and transverse components. The transverse velocity is the component of velocity along a circle centered at the origin.\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          \n            v\n          \n          \n            T\n          \n        \n        +\n        \n          \n            v\n          \n          \n            R\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}={\\boldsymbol {v}}_{T}+{\\boldsymbol {v}}_{R}}\n  where\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}_{T}}\n   is the transverse velocity\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            R\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}_{R}}\n   is the radial velocity.The magnitude of the radial velocity is the dot product of the velocity vector and the unit vector in the direction of the displacement.\n\n  \n    \n      \n        \n          v\n          \n            R\n          \n        \n        =\n        \n          \n            \n              \n                v\n              \n              \u22c5\n              \n                r\n              \n            \n            \n              |\n              \n                r\n              \n              |\n            \n          \n        \n      \n    \n    {\\displaystyle v_{R}={\\frac {{\\boldsymbol {v}}\\cdot {\\boldsymbol {r}}}{\\left|{\\boldsymbol {r}}\\right|}}}\n  where \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {r}}}\n   is displacement.\nThe magnitude of the transverse velocity is that of the cross product of the unit vector in the direction of the displacement and the velocity vector. It is also the product of the angular speed \n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   and the magnitude of the displacement.\n\n  \n    \n      \n        \n          v\n          \n            T\n          \n        \n        =\n        \n          \n            \n              \n                |\n              \n              \n                r\n              \n              \u00d7\n              \n                v\n              \n              \n                |\n              \n            \n            \n              \n                |\n              \n              \n                r\n              \n              \n                |\n              \n            \n          \n        \n        =\n        \u03c9\n        \n          |\n        \n        \n          r\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle v_{T}={\\frac {|{\\boldsymbol {r}}\\times {\\boldsymbol {v}}|}{|{\\boldsymbol {r}}|}}=\\omega |{\\boldsymbol {r}}|}\n  such that\n\n  \n    \n      \n        \u03c9\n        =\n        \n          \n            \n              \n                |\n              \n              \n                r\n              \n              \u00d7\n              \n                v\n              \n              \n                |\n              \n            \n            \n              \n                |\n              \n              \n                r\n              \n              \n                \n                  |\n                \n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\omega ={\\frac {|{\\boldsymbol {r}}\\times {\\boldsymbol {v}}|}{|{\\boldsymbol {r}}|^{2}}}.}\n  Angular momentum in scalar form is the mass times the distance to the origin times the transverse velocity, or equivalently, the mass times the distance squared times the angular speed. The sign convention for angular momentum is the same as that for angular velocity.\n\n  \n    \n      \n        L\n        =\n        m\n        r\n        \n          v\n          \n            T\n          \n        \n        =\n        m\n        \n          r\n          \n            2\n          \n        \n        \u03c9\n      \n    \n    {\\displaystyle L=mrv_{T}=mr^{2}\\omega }\n  where\n\n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is mass\n\n  \n    \n      \n        r\n        =\n        \n          |\n        \n        \n          r\n        \n        \n          |\n        \n        .\n      \n    \n    {\\displaystyle r=|{\\boldsymbol {r}}|.}\n  The expression \n  \n    \n      \n        m\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle mr^{2}}\n   is known as moment of inertia.\nIf forces are in the radial direction only with an inverse square dependence, as in the case of a gravitational orbit, angular momentum is constant, and transverse speed is inversely proportional to the distance, angular speed is inversely proportional to the distance squared, and the rate at which area is swept out is constant. These relations are known as Kepler's laws of planetary motion.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\nRobert Resnick and Jearl Walker, Fundamentals of Physics, Wiley; 7 Sub edition (June 16, 2004). ISBN 0-471-23231-9.\n\n\n== External links ==\n\nVelocity and Acceleration\nIntroduction to Mechanisms (Carnegie Mellon University)", "Normal_force": "In mechanics, the normal force \n  \n    \n      \n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{n}}\n   is the component of a contact force that is perpendicular to the surface that an object contacts, as in Figure 1.  In this instance normal is used in the geometric sense and means perpendicular, as opposed to the common language use of normal meaning \"ordinary\" or \"expected\". A person standing still on a platform is acted upon by gravity, which would pull them down towards the Earth's core unless there were a countervailing force from the resistance of the platform's molecules, a force which is named the \"normal force\".\nThe normal force is one type of ground reaction force. If the person stands on a slope and does not sink into the ground or slide downhill, the total ground reaction force can be divided into two components: a normal force perpendicular to the ground and a  frictional force parallel to the ground. In another common situation, if an object hits a surface with some speed, and the surface can withstand the impact, the normal force provides for a rapid deceleration, which will depend on the flexibility of the surface and the object.\n\n\n== Equations ==\n\nIn the case of an object resting upon a flat table (unlike on an incline as in Figures 1 and 2), the normal force on the object is equal but in opposite direction to the gravitational force applied on the object (or the weight of the object), that is, \n  \n    \n      \n        \n          F\n          \n            n\n          \n        \n        =\n        m\n        g\n      \n    \n    {\\displaystyle F_{n}=mg}\n  , where m is mass, and g is the gravitational field strength (about 9.81 m/s2 on Earth). The normal force here represents the force applied by the table against the object that prevents it from sinking through the table and requires that the table be sturdy enough to deliver this normal force without breaking.  However, it is easy to assume that the normal force and weight are action-reaction force pairs (a common mistake).  In this case, the normal force and weight need to be equal in magnitude to explain why there is no upward acceleration of the object.  For example, a ball that bounces upwards accelerates upwards because the normal force acting on the ball is larger in magnitude than the weight of the ball.\nWhere an object rests on an incline as in Figures 1 and 2, the normal force is perpendicular to the plane the object rests on. Still, the normal force will be as large as necessary to prevent sinking through the surface, presuming the surface is sturdy enough. The strength of the force can be calculated as:\n\nwhere \n  \n    \n      \n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{n}}\n   is the normal force, m is the mass of the object, g is the gravitational field strength, and \u03b8 is the angle of the inclined surface measured from the horizontal.\nThe normal force is one of the several forces which act on the object. In the simple situations so far considered, the most important other forces acting on it are friction and the force of gravity.\n\n\n=== Using vectors ===\nIn general, the magnitude of the normal force, N, is the projection of the net surface interaction force, T,  in the normal direction, n, and so the normal force vector can be found by scaling the normal direction by the net surface interaction force. The surface interaction force, in turn, is equal to the dot product of the unit normal with the Cauchy stress tensor describing the stress state of the surface. That is:\n\nor, in indicial notation,\n\nThe parallel shear component of the contact force is known as the frictional force (\n  \n    \n      \n        \n          F\n          \n            f\n            r\n          \n        \n      \n    \n    {\\displaystyle F_{fr}}\n  ).\nThe static coefficient of friction for an object on an inclined plane can be calculated as follows:\nfor an object on the point of sliding where \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between the slope and the horizontal.\n\n\n== Physical origin ==\nNormal force is directly a result of Pauli exclusion principle and not a true force per se: it is a result of the interactions of the electrons at the surfaces of the objects. The atoms in the two surfaces cannot penetrate one another without a large investment of energy because there is no low energy state for which the electron wavefunctions from the two surfaces overlap; thus no microscopic force is needed to prevent this penetration.\nHowever these interactions are often modeled as van der Waals force, a force that grows very large very quickly as distance becomes smaller.On the more macroscopic level, such surfaces can be treated as a single object, and two bodies do not penetrate each other due to the stability of matter, which is again a consequence of Pauli exclusion principle, but also of the fundamental forces of nature: cracks in the bodies do not widen due to electromagnetic forces that create the chemical bonds between the atoms; the atoms themselves do not disintegrate because of the electromagnetic forces between the electrons and the nuclei; and the nuclei do not disintegrate due to the nuclear forces.\n\n\n== Applications in real life ==\nIn an elevator either stationary or moving at constant velocity, the normal force on the person's feet balances the person's weight. In an elevator that is accelerating upward, the normal force is greater than the person's ground weight and so the person's perceived weight increases (making the person feel heavier). In an elevator that is accelerating downward, the normal force is less than the person's ground weight and so a passenger's perceived weight decreases. If a passenger were to stand on a weighing scale, such as a conventional bathroom scale, while riding the elevator, the scale will be reading the normal force it delivers to the passenger's feet, and will be different than the person's ground weight if the elevator cab is accelerating up or down.  The weighing scale measures normal force (which varies as the elevator cab accelerates), not gravitational force (which does not vary as the cab accelerates).\nWhen we define upward to be the positive direction, constructing Newton's second law and solving for the normal force on a passenger yields the following equation:\n\nIn a gravitron amusement ride, the static friction caused by and perpendicular to the normal force acting on the passengers against the walls results in suspension of the passengers above the floor as the ride rotates. In such a scenario, the walls of the ride apply normal force to the passengers in the direction of the center, which is a result of the centripetal force applied to the passengers as the ride rotates. As a result of the normal force experienced by the passengers, the static friction between the passengers and the walls of the ride counteracts the pull of gravity on the passengers, resulting in suspension above ground of the passengers throughout the duration of the ride.\nWhen we define the center of the ride to be the positive direction, solving for the normal force on a passenger that is suspended above ground yields the following equation:\n\nwhere \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   is the normal force on the passenger, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the mass of the passenger, \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the tangential velocity of the passenger and \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the distance of the passenger from the center of the ride.\nWith the normal force known, we can solve for the static coefficient of friction needed to maintain a net force of zero in the vertical direction:\n\nwhere \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the static coefficient of friction, and \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n   is the gravitational field strength.\n\n\n== See also ==\nContact mechanics\nNormal stress\n\n\n== References ==", "Electromagnetic_radiation": "In physics, electromagnetic radiation (EMR) consists of waves of the electromagnetic (EM) field, which propagate through space and carry momentum and electromagnetic radiant energy. Types of EMR include radio waves, microwaves, infrared, (visible) light, ultraviolet, X-rays, and gamma rays, all of which are part of the electromagnetic spectrum.Classically, electromagnetic radiation consists of electromagnetic waves, which are synchronized oscillations of electric and magnetic fields.  Depending on the frequency of oscillation, different wavelengths of electromagnetic spectrum are produced. In a vacuum, electromagnetic waves travel at the speed of light, commonly denoted c. In homogeneous, isotropic media, the oscillations of the two fields are perpendicular to each other and perpendicular to the direction of energy and wave propagation, forming a transverse wave. The position of an electromagnetic wave within the electromagnetic spectrum can be characterized by either its frequency of oscillation or its wavelength.  Electromagnetic waves of different frequency are called by different names since they have different sources and effects on matter.  In order of increasing frequency and decreasing wavelength these are: radio waves, microwaves, infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays.Electromagnetic waves are emitted by electrically charged particles undergoing acceleration, and these waves can subsequently interact with other charged particles, exerting force on them.  EM waves carry energy, momentum and angular momentum away from their source particle and can impart those quantities to matter with which they interact.  Electromagnetic radiation is associated with those EM waves that are free to propagate themselves (\"radiate\") without the continuing influence of the moving charges that produced them, because they have achieved sufficient distance from those charges. Thus, EMR is sometimes referred to as the far field. In this language, the near field refers to EM fields near the charges and current that directly produced them, specifically electromagnetic induction and electrostatic induction phenomena.\nIn quantum mechanics, an alternate way of viewing EMR is that it consists of photons, uncharged elementary particles with zero rest mass which are the quanta of the electromagnetic field, responsible for all electromagnetic interactions. Quantum electrodynamics is the theory of how EMR interacts with matter on an atomic level. Quantum effects provide additional sources of EMR, such as the transition of electrons to lower energy levels in an atom and black-body radiation. The energy of an individual photon is quantized and is greater for photons of higher frequency. This relationship is given by Planck's equation E = hf, where E is the energy per photon, f is the frequency of the photon, and h is Planck's constant. A single gamma ray photon, for example, might carry ~100,000 times the energy of a single photon of visible light.\nThe effects of EMR upon chemical compounds and biological organisms depend both upon the radiation's power and its frequency. EMR of visible or lower frequencies (i.e., visible light, infrared, microwaves, and radio waves) is called non-ionizing radiation, because its photons do not individually have enough energy to ionize atoms or molecules, or break chemical bonds. The effects of these radiations on chemical systems and living tissue are caused primarily by heating effects from the combined energy transfer of many photons. In contrast, high frequency ultraviolet, X-rays and gamma rays are called ionizing radiation, since individual photons of such high frequency have enough energy to ionize molecules or break chemical bonds. These radiations have the ability to cause chemical reactions and damage living cells beyond that resulting from simple heating, and can be a health hazard.\n\n\n== Physics ==\n\n\n=== Theory ===\n\n\n==== Maxwell's equations ====\nJames Clerk Maxwell derived a wave form of the electric and magnetic equations, thus uncovering the wave-like nature of electric and magnetic fields and their symmetry. Because the speed of EM waves predicted by the wave equation coincided with the measured speed of light, Maxwell concluded that light itself is an EM wave. Maxwell's equations were confirmed by Heinrich Hertz through experiments with radio waves.\n Maxwell realized that since a lot of physics is symmetrical and mathematically artistic in a way, that there must also be a symmetry between electricity and magnetism. He realized that light is a combination of electricity and magnetism and thus that the two must be tied together. According to Maxwell's equations, a spatially varying electric field is always associated with a magnetic field that changes over time. Likewise, a spatially varying magnetic field is associated with specific changes over time in the electric field. In an electromagnetic wave, the changes in the electric field are always accompanied by a wave in the magnetic field in one direction, and vice versa. This relationship between the two occurs without either type of field causing the other; rather, they occur together. In fact, magnetic fields can be viewed as electric fields in another frame of reference, and electric fields can be viewed as magnetic fields in another frame of reference. Together, these fields form a propagating electromagnetic wave, which moves through space independent of the source. The distant EM field formed in this way by the acceleration of a charge carries energy with it that \"radiates\" away through space, hence the term.\n\n\n==== Near and far fields ====\n\nMaxwell's equations established that some charges and currents (\"sources\") produce a local type of electromagnetic field near them that does not have the behaviour of EMR. Currents directly produce a magnetic field, but it is of a magnetic dipole type that dies out with distance from the current. In a similar manner, moving charges pushed apart in a conductor by a changing electrical potential (such as in an antenna) produce an electric dipole type electrical field, but this also declines with distance. These fields make up the near-field near the EMR source. Neither of these behaviours are responsible for EM radiation. Instead, they cause electromagnetic field behaviour that only efficiently transfers power to a receiver very close to the source, such as the magnetic induction inside a transformer, or the feedback behaviour that happens close to the coil of a metal detector. Typically, near-fields have a powerful effect on their own sources, causing an increased \"load\" (decreased electrical reactance) in the source or transmitter, whenever energy is withdrawn from the EM field by a receiver. Otherwise, these fields do not \"propagate\" freely out into space, carrying their energy away without distance-limit, but rather oscillate, returning their energy to the transmitter if it is not received by a receiver.By contrast, the EM far-field is composed of radiation that is free of the transmitter in the sense that (unlike the case in an electrical transformer) the transmitter requires the same power to send these changes in the fields out, whether the signal is immediately picked up or not. This distant part of the electromagnetic field is \"electromagnetic radiation\" (also called the far-field). The far-fields propagate (radiate) without allowing the transmitter to affect them. This causes them to be independent in the sense that their existence and their energy, after they have left the transmitter, is completely independent of both transmitter and receiver. Due to conservation of energy, the amount of power passing through any spherical surface drawn around the source is the same. Because such a surface has an area proportional to the square of its distance from the source, the power density of EM radiation from an isotropic source decreases with the inverse square of the distance from the source; this is called the inverse-square law. This is in contrast to dipole parts of the EM field close to the source (the near-field), which vary in power according to an inverse cube power law, and thus do not transport a conserved amount of energy over distances, but instead fade with distance, with its energy (as noted) rapidly returning to the transmitter or absorbed by a nearby receiver (such as a transformer secondary coil).\nThe far-field (EMR) depends on a different mechanism for its production than the near-field, and upon different terms in Maxwell's equations. Whereas the magnetic part of the near-field is due to currents in the source, the magnetic field in EMR is due only to the local change in the electric field. In a similar way, while the electric field in the near-field is due directly to the charges and charge-separation in the source, the electric field in EMR is due to a change in the local magnetic field. Both processes for producing electric and magnetic EMR fields have a different dependence on distance than do near-field dipole electric and magnetic fields. That is why the EMR type of EM field becomes dominant in power \"far\" from sources. The term \"far from sources\" refers to how far from the source (moving at the speed of light) any portion of the outward-moving EM field is located, by the time that source currents are changed by the varying source potential, and the source has therefore begun to generate an outwardly moving EM field of a different phase.A more compact view of EMR is that the far-field that composes EMR is generally that part of the EM field that has traveled sufficient distance from the source, that it has become completely disconnected from any feedback to the charges and currents that were originally responsible for it. Now independent of the source charges, the EM field, as it moves farther away, is dependent only upon the accelerations of the charges that produced it. It no longer has a strong connection to the direct fields of the charges, or to the velocity of the charges (currents).In the Li\u00e9nard\u2013Wiechert potential formulation of the electric and magnetic fields due to motion of a single particle (according to Maxwell's equations), the terms associated with acceleration of the particle are those that are responsible for the part of the field that is regarded as electromagnetic radiation. By contrast, the term associated with the changing static electric field of the particle and the magnetic term that results from the particle's uniform velocity, are both associated with the electromagnetic near-field, and do not comprise EM radiation.\n\n\n=== Properties ===\n\nElectrodynamics is the physics of electromagnetic radiation, and electromagnetism is the physical phenomenon associated with the theory of electrodynamics. Electric and magnetic fields obey the properties of superposition. Thus, a field due to any particular particle or time-varying electric or magnetic field contributes to the fields present in the same space due to other causes. Further, as they are vector fields, all magnetic and electric field vectors add together according to vector addition. For example, in optics two or more coherent light waves may interact and by constructive or destructive interference yield a resultant irradiance deviating from the sum of the component irradiances of the individual light waves.The electromagnetic fields of light are not affected by traveling through static electric or magnetic fields in a linear medium such as a vacuum. However, in nonlinear media, such as some crystals, interactions can occur between light and static electric and magnetic fields\u2014these interactions include the Faraday effect and the Kerr effect.In refraction, a wave crossing from one medium to another of different density alters its speed and direction upon entering the new medium. The ratio of the refractive indices of the media determines the degree of refraction, and is summarized by Snell's law. Light of composite wavelengths (natural sunlight) disperses into a visible spectrum passing through a prism, because of the wavelength-dependent refractive index of the prism material (dispersion); that is, each component wave within the composite light is bent a different amount.EM radiation exhibits both wave properties and particle properties at the same time (see wave-particle duality). Both wave and particle characteristics have been confirmed in many experiments. Wave characteristics are more apparent when EM radiation is measured over relatively large timescales and over large distances while particle characteristics are more evident when measuring small timescales and distances. For example, when electromagnetic radiation is absorbed by matter, particle-like properties will be more obvious when the average number of photons in the cube of the relevant wavelength is much smaller than 1. It is not so difficult to experimentally observe non-uniform deposition of energy when light is absorbed, however this alone is not evidence of \"particulate\" behavior. Rather, it reflects the quantum nature of matter. Demonstrating that the light itself is quantized, not merely its interaction with matter, is a more subtle affair.\nSome experiments display both the wave and particle natures of electromagnetic waves, such as the self-interference of a single photon. When a single photon is sent through an interferometer, it passes through both paths, interfering with itself, as waves do, yet is detected by a photomultiplier or other sensitive detector only once.\nA quantum theory of the interaction between electromagnetic radiation and matter such as electrons is described by the theory of quantum electrodynamics.\nElectromagnetic waves can be polarized, reflected, refracted, diffracted or interfere with each other.\n\n\n=== Wave model ===\n In homogeneous, isotropic media, electromagnetic radiation is a transverse wave, meaning that its oscillations are perpendicular to the direction of energy transfer and travel. It comes from the following equations:These equations predicate that any electromagnetic wave must be a transverse wave, where the electric field E and the magnetic field B are both perpendicular to the direction of wave propagation.\nThe electric and magnetic parts of the field in an electromagnetic wave stand in a fixed ratio of strengths to satisfy the two Maxwell equations that specify how one is produced from the other. In dissipation-less (lossless) media, these E and B fields are also in phase, with both reaching maxima and minima at the same points in space (see illustrations). A common misconception is that the E and B fields in electromagnetic radiation are out of phase because a change in one produces the other, and this would produce a phase difference between them as sinusoidal functions (as indeed happens in electromagnetic induction, and in the near-field close to antennas). However, in the far-field EM radiation which is described by the two source-free Maxwell curl operator equations, a more correct description is that a time-change in one type of field is proportional to a space-change in the other. These derivatives require that the E and B fields in EMR are in-phase (see mathematics section below).\nAn important aspect of light's nature is its frequency. The frequency of a wave is its rate of oscillation and is measured in hertz, the SI unit of frequency, where one hertz is equal to one oscillation per second. Light usually has multiple frequencies that sum to form the resultant wave. Different frequencies undergo different angles of refraction, a phenomenon known as dispersion.\nA monochromatic wave (a wave of a single frequency) consists of successive troughs and crests, and the distance between two adjacent crests or troughs is called the wavelength. Waves of the electromagnetic spectrum vary in size, from very long radio waves longer than a continent to very short gamma rays smaller than atom nuclei. Frequency is inversely proportional to wavelength, according to the equation:\n\n  \n    \n      \n        \n          v\n          =\n          f\n          \u03bb\n        \n      \n    \n    {\\displaystyle \\displaystyle v=f\\lambda }\n  where v is the speed of the wave (c in a vacuum or less in other media), f is the frequency and \u03bb is the wavelength. As waves cross boundaries between different media, their speeds change but their frequencies remain constant.\nElectromagnetic waves in free space must be solutions of Maxwell's electromagnetic wave equation. Two main classes of solutions are known, namely plane waves and spherical waves. The plane waves may be viewed as the limiting case of spherical waves at a very large (ideally infinite) distance from the source.  Both types of waves can have a waveform which is an arbitrary time function (so long as it is sufficiently differentiable to conform to the wave equation).  As with any time function, this can be decomposed by means of Fourier analysis into its frequency spectrum, or individual sinusoidal components, each of which contains a single frequency, amplitude and phase. Such a component wave is said to be monochromatic.  A monochromatic electromagnetic wave can be characterized by its frequency or wavelength, its peak amplitude, its phase relative to some reference phase, its direction of propagation, and its polarization.\nInterference is the superposition of two or more waves resulting in a new wave pattern. If the fields have components in the same direction, they constructively interfere, while opposite directions cause destructive interference. An example of interference caused by EMR is electromagnetic interference (EMI) or as it is more commonly known as, radio-frequency interference (RFI).  Additionally, multiple polarization signals can be combined (i.e. interfered) to form new states of polarization, which is known as parallel polarization state generation.The energy in electromagnetic waves is sometimes called radiant energy.\n\n\n=== Particle model and quantum theory ===\n\nAn anomaly arose in the late 19th century involving a contradiction between the wave theory of light and measurements of the electromagnetic spectra that were being emitted by thermal radiators known as black bodies. Physicists struggled with this problem unsuccessfully for many years, and it later became known as the ultraviolet catastrophe. In 1900, Max Planck developed a new theory of black-body radiation that explained the observed spectrum. Planck's theory was based on the idea that black bodies emit light (and other electromagnetic radiation) only as discrete bundles or packets of energy. These packets were called quanta. In 1905, Albert Einstein proposed that light quanta be regarded as real particles. Later the particle of light was given the name photon, to correspond with other particles being described around this time, such as the electron and proton. A photon has an energy, E, proportional to its frequency, f, by\n\n  \n    \n      \n        E\n        =\n        h\n        f\n        =\n        \n          \n            \n              h\n              c\n            \n            \u03bb\n          \n        \n        \n        \n      \n    \n    {\\displaystyle E=hf={\\frac {hc}{\\lambda }}\\,\\!}\n  where h is Planck's constant, \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is the wavelength and c is the speed of light. This is sometimes known as the Planck\u2013Einstein equation. In quantum theory (see first quantization) the energy of the photons is thus directly proportional to the frequency of the EMR wave.Likewise, the momentum p of a photon is also proportional to its frequency and inversely proportional to its wavelength:\n\n  \n    \n      \n        p\n        =\n        \n          \n            E\n            c\n          \n        \n        =\n        \n          \n            \n              h\n              f\n            \n            c\n          \n        \n        =\n        \n          \n            h\n            \u03bb\n          \n        \n        .\n      \n    \n    {\\displaystyle p={E \\over c}={hf \\over c}={h \\over \\lambda }.}\n  The source of Einstein's proposal that light was composed of particles (or could act as particles in some circumstances) was an experimental anomaly not explained by the wave theory: the photoelectric effect, in which light striking a metal surface ejected electrons from the surface, causing an electric current to flow across an applied voltage. Experimental measurements demonstrated that the energy of individual ejected electrons was proportional to the frequency, rather than the intensity, of the light. Furthermore, below a certain minimum frequency, which depended on the particular metal, no current would flow regardless of the intensity. These observations appeared to contradict the wave theory, and for years physicists tried in vain to find an explanation. In 1905, Einstein explained this puzzle by resurrecting the particle theory of light to explain the observed effect. Because of the preponderance of evidence in favor of the wave theory, however, Einstein's ideas were met initially with great skepticism among established physicists. Eventually Einstein's explanation was accepted as new particle-like behavior of light was observed, such as the Compton effect.As a photon is absorbed by an atom, it excites the atom, elevating an electron to a higher energy level (one that is on average farther from the nucleus). When an electron in an excited molecule or atom descends to a lower energy level, it emits a photon of light at a frequency corresponding to the energy difference. Since the energy levels of electrons in atoms are discrete, each element and each molecule emits and absorbs its own characteristic frequencies. Immediate photon emission is called fluorescence, a type of photoluminescence. An example is visible light emitted from fluorescent paints, in response to ultraviolet (blacklight). Many other fluorescent emissions are known in spectral bands other than visible light. Delayed emission is called phosphorescence.\n\n\n=== Wave\u2013particle duality ===\n\nThe modern theory that explains the nature of light includes the notion of wave\u2013particle duality. More generally, the theory states that everything has both a particle nature and a wave nature, and various experiments can be done to bring out one or the other. The particle nature is more easily discerned using an object with a large mass. A bold proposition by Louis de Broglie in 1924 led the scientific community to realize that matter (e.g. electrons) also exhibits wave\u2013particle duality.\n\n\n=== Wave and particle effects of electromagnetic radiation ===\nTogether, wave and particle effects fully explain the emission and absorption spectra of EM radiation. The matter-composition of the medium through which the light travels determines the nature of the absorption and emission spectrum. These bands correspond to the allowed energy levels in the atoms. Dark bands in the absorption spectrum are due to the atoms in an intervening medium between source and observer. The atoms absorb certain frequencies of the light between emitter and detector/eye, then emit them in all directions. A dark band appears to the detector, due to the radiation scattered out of the beam. For instance, dark bands in the light emitted by a distant star are due to the atoms in the star's atmosphere. A similar phenomenon occurs for emission, which is seen when an emitting gas glows due to excitation of the atoms from any mechanism, including heat. As electrons descend to lower energy levels, a spectrum is emitted that represents the jumps between the energy levels of the electrons, but lines are seen because again emission happens only at particular energies after excitation. An example is the emission spectrum of nebulae. Rapidly moving electrons are most sharply accelerated when they encounter a region of force, so they are responsible for producing much of the highest frequency electromagnetic radiation observed in nature.\nThese phenomena can aid various chemical determinations for the composition of gases lit from behind (absorption spectra) and for glowing gases (emission spectra). Spectroscopy (for example) determines what chemical elements comprise a particular star. Spectroscopy is also used in the determination of the distance of a star, using the red shift.\n\n\n=== Propagation speed ===\n\nWhen any wire (or other conducting object such as an antenna) conducts alternating current, electromagnetic radiation is propagated at the same frequency as the current. In many such situations it is possible to identify an electrical dipole moment that arises from separation of charges due to the exciting electrical potential, and this dipole moment oscillates in time, as the charges move back and forth. This oscillation at a given frequency gives rise to changing electric and magnetic fields, which then set the electromagnetic radiation in motion.At the quantum level, electromagnetic radiation is produced when the wavepacket of a charged particle oscillates or otherwise accelerates. Charged particles in a stationary state do not move, but a superposition of such states may result in a transition state that has an electric dipole moment that oscillates in time. This oscillating dipole moment is responsible for the phenomenon of radiative transition between quantum states of a charged particle. Such states occur (for example) in atoms when photons are radiated as the atom shifts from one stationary state to another.As a wave, light is characterized by a velocity (the speed of light), wavelength, and frequency. As particles, light is a stream of photons. Each has an energy related to the frequency of the wave given by Planck's relation E = hf, where E is the energy of the photon, h is Planck's constant, 6.626 \u00d7 10\u221234 J\u00b7s, and f is the frequency of the wave.One rule is obeyed regardless of circumstances: EM radiation in a vacuum travels at the speed of light, relative to the observer, regardless of the observer's velocity.\nIn a medium (other than vacuum), velocity factor or refractive index are considered, depending on frequency and application. Both of these are ratios of the speed in a medium to speed in a vacuum.\n\n\n=== Special theory of relativity ===\n\nBy the late nineteenth century, various experimental anomalies could not be explained by the simple wave theory. One of these anomalies involved a controversy over the speed of light. The speed of light and other EMR predicted by Maxwell's equations did not appear unless the equations were modified in a way first suggested by FitzGerald and Lorentz (see history of special relativity), or else otherwise that speed would depend on the speed of observer relative to the \"medium\" (called luminiferous aether) which supposedly \"carried\" the electromagnetic wave (in a manner analogous to the way air carries sound waves). Experiments failed to find any observer effect. In 1905, Einstein proposed that space and time appeared to be velocity-changeable entities for light propagation and all other processes and laws. These changes accounted for the constancy of the speed of light and all electromagnetic radiation, from the viewpoints of all observers\u2014even those in relative motion.\n\n\n== History of discovery ==\n\nElectromagnetic radiation of wavelengths other than those of visible light were discovered in the early 19th century. The discovery of infrared radiation is ascribed to astronomer William Herschel, who published his results in 1800 before the Royal Society of London. Herschel used a glass prism to refract light from the Sun and detected invisible rays that caused heating beyond the red part of the spectrum, through an increase in the temperature recorded with a thermometer. These \"calorific rays\" were later termed infrared.In 1801, German physicist Johann Wilhelm Ritter discovered ultraviolet in an experiment similar to Herschel's, using sunlight and a glass prism. Ritter noted that invisible rays near the violet edge of a solar spectrum dispersed by a triangular prism darkened silver chloride preparations more quickly than did the nearby violet light. Ritter's experiments were an early precursor to what would become photography. Ritter noted that the ultraviolet rays (which at first were called \"chemical rays\") were capable of causing chemical reactions.\n\nIn 1862\u201364 James Clerk Maxwell developed equations for the electromagnetic field which suggested that waves in the field would travel with a speed that was very close to the known speed of light. Maxwell therefore suggested that visible light (as well as invisible infrared and ultraviolet rays by inference) all consisted of propagating disturbances (or radiation) in the electromagnetic field. Radio waves were first produced deliberately by Heinrich Hertz in 1887, using electrical circuits calculated to produce oscillations at a much lower frequency than that of visible light, following recipes for producing oscillating charges and currents suggested by Maxwell's equations. Hertz also developed ways to detect these waves, and produced and characterized what were later termed radio waves and microwaves.:\u200a286,\u200a7\u200aWilhelm R\u00f6ntgen discovered and named X-rays. After experimenting with high voltages applied to an evacuated tube on 8 November 1895, he noticed a fluorescence on a nearby plate of coated glass. In one month, he discovered X-rays' main properties.:\u200a307\u200aThe last portion of the EM spectrum to be discovered was associated with radioactivity. Henri Becquerel found that uranium salts caused fogging of an unexposed photographic plate through a covering paper in a manner similar to X-rays, and Marie Curie discovered that only certain elements gave off these rays of energy, soon discovering the intense radiation of radium. The radiation from pitchblende was differentiated into alpha rays (alpha particles) and beta rays (beta particles) by Ernest Rutherford through simple experimentation in 1899, but these proved to be charged particulate types of radiation. However, in 1900 the French scientist Paul Villard discovered a third neutrally charged and especially penetrating type of radiation from radium, and after he described it, Rutherford realized it must be yet a third type of radiation, which in 1903 Rutherford named gamma rays. In 1910 British physicist William Henry Bragg demonstrated that gamma rays are electromagnetic radiation, not particles, and in 1914 Rutherford and Edward Andrade measured their wavelengths, finding that they were similar to X-rays but with shorter wavelengths and higher frequency, although a 'cross-over' between X and gamma rays makes it possible to have X-rays with a higher energy (and hence shorter wavelength) than gamma rays and vice versa. The origin of the ray differentiates them, gamma rays tend to be natural phenomena originating from the unstable nucleus of an atom and X-rays are electrically generated (and hence man-made) unless they are as a result of bremsstrahlung X-radiation caused by the interaction of fast moving particles (such as beta particles) colliding with certain materials, usually of higher atomic numbers.:\u200a308,\u200a9\u200a\n\n\n== Electromagnetic spectrum ==\n\nEM radiation (the designation 'radiation' excludes static electric and magnetic and near fields) is classified by wavelength into radio, microwave, infrared, visible, ultraviolet, X-rays and gamma rays. Arbitrary electromagnetic waves can be expressed by Fourier analysis in terms of sinusoidal monochromatic waves, which in turn can each be classified into these regions of the EMR spectrum.\nFor certain classes of EM waves, the waveform is most usefully treated as random, and then spectral analysis must be done by slightly different mathematical techniques appropriate to random or stochastic processes. In such cases, the individual frequency components are represented in terms of their power content, and the phase information is not preserved. Such a representation is called the power spectral density of the random process. Random electromagnetic radiation requiring this kind of analysis is, for example, encountered in the interior of stars, and in certain other very wideband forms of radiation such as the Zero point wave field of the electromagnetic vacuum.\nThe behavior of EM radiation and its interaction with matter depends on its frequency, and changes qualitatively as the frequency changes. Lower frequencies have longer wavelengths, and higher frequencies have shorter wavelengths, and are associated with photons of higher energy. There is no fundamental limit known to these wavelengths or energies, at either end of the spectrum, although photons with energies near the Planck energy or exceeding it (far too high to have ever been observed) will require new physical theories to describe.\n\n\n=== Radio and microwave ===\n\nWhen radio waves impinge upon a conductor, they couple to the conductor, travel along it and induce an electric current on the conductor surface by moving the electrons of the conducting material in correlated bunches of charge. Such effects can cover macroscopic distances in conductors (such as radio antennas), since the wavelength of radio waves is long.\nElectromagnetic radiation phenomena with wavelengths ranging from as long as one meter to as short as one millimeter are called microwaves; with frequencies between 300 MHz (0.3 GHz) and 300 GHz.\nAt radio and microwave frequencies, EMR interacts with matter largely as a bulk collection of charges which are spread out over large numbers of affected atoms. In electrical conductors, such induced bulk movement of charges (electric currents) results in absorption of the EMR, or else separations of charges that cause generation of new EMR (effective reflection of the EMR). An example is absorption or emission of radio waves by antennas, or absorption of microwaves by water or other molecules with an electric dipole moment, as for example inside a microwave oven. These interactions produce either electric currents or heat, or both.\n\n\n=== Infrared ===\n\nLike radio and microwave, infrared (IR) also is reflected by metals (and also most EMR, well into the ultraviolet range). However, unlike lower-frequency radio and microwave radiation, Infrared EMR commonly interacts with dipoles present in single molecules, which change as atoms vibrate at the ends of a single chemical bond. It is consequently absorbed by a wide range of substances, causing them to increase in temperature as the vibrations dissipate as heat. The same process, run in reverse, causes bulk substances to radiate in the infrared spontaneously (see thermal radiation section below).\nInfrared radiation is divided into spectral subregions. While different subdivision schemes exist, the spectrum is commonly divided as near-infrared (0.75\u20131.4 \u03bcm), short-wavelength infrared (1.4\u20133 \u03bcm), mid-wavelength infrared (3\u20138 \u03bcm), long-wavelength infrared (8\u201315 \u03bcm) and far infrared (15\u20131000 \u03bcm).\n\n\n=== Visible light ===\n\nNatural sources produce EM radiation across the spectrum. EM radiation with a wavelength between approximately 400 nm and 700 nm is directly detected by the human eye and perceived as visible light. Other wavelengths, especially nearby infrared (longer than 700 nm) and ultraviolet (shorter than 400 nm) are also sometimes referred to as light.\nAs frequency increases into the visible range, photons have enough energy to change the bond structure of some individual molecules. It is not a coincidence that this happens in the visible range, as the mechanism of vision involves the change in bonding of a single molecule, retinal, which absorbs a single photon. The change in retinal causes a change in the shape of the rhodopsin protein it is contained in, which starts the biochemical process that causes the retina of the human eye to sense the light.\nPhotosynthesis becomes possible in this range as well, for the same reason. A single molecule of chlorophyll is excited by a single photon. In plant tissues that conduct photosynthesis, carotenoids act to quench electronically excited chlorophyll produced by visible light in a process called non-photochemical quenching, to prevent reactions that would otherwise interfere with photosynthesis at high light levels.\nAnimals that detect infrared make use of small packets of water that change temperature, in an essentially thermal process that involves many photons.\nInfrared, microwaves and radio waves are known to damage molecules and biological tissue only by bulk heating, not excitation from single photons of the radiation.\nVisible light is able to affect only a tiny percentage of all molecules. Usually not in a permanent or damaging way, rather the photon excites an electron which then emits another photon when returning to its original position. This is the source of color produced by most dyes. Retinal is an exception. When a photon is absorbed, the retinal permanently changes structure from cis to trans, and requires a protein to convert it back, i.e. reset it to be able to function as a light detector again.\nLimited evidence indicate that some reactive oxygen species are created by visible light in skin, and that these may have some role in photoaging, in the same manner as ultraviolet A.\n\n\n=== Ultraviolet ===\n\nAs frequency increases into the ultraviolet, photons now carry enough energy (about three electron volts or more) to excite certain doubly bonded molecules into permanent chemical rearrangement. In DNA, this causes lasting damage. DNA is also indirectly damaged by reactive oxygen species produced by ultraviolet A (UVA), which has energy too low to damage DNA directly. This is why ultraviolet at all wavelengths can damage DNA, and is capable of causing cancer, and (for UVB) skin burns (sunburn) that are far worse than would be produced by simple heating (temperature increase) effects. This property of causing molecular damage that is out of proportion to heating effects, is characteristic of all EMR with frequencies at the visible light range and above. These properties of high-frequency EMR are due to quantum effects that permanently damage materials and tissues at the molecular level.At the higher end of the ultraviolet range, the energy of photons becomes large enough to impart enough energy to electrons to cause them to be liberated from the atom, in a process called photoionisation. The energy required for this is always larger than about 10 electron volt (eV) corresponding with wavelengths smaller than 124 nm (some sources suggest a more realistic cutoff of 33 eV, which is the energy required to ionize water). This high end of the ultraviolet spectrum with energies in the approximate ionization range, is sometimes called \"extreme UV.\" Ionizing UV is strongly filtered by the Earth's atmosphere.\n\n\n=== X-rays and gamma rays ===\n\nElectromagnetic radiation composed of photons that carry minimum-ionization energy, or more, (which includes the entire spectrum with shorter wavelengths), is therefore termed ionizing radiation. (Many other kinds of ionizing radiation are made of non-EM particles). Electromagnetic-type ionizing radiation extends from the extreme ultraviolet to all higher frequencies and shorter wavelengths, which means that all X-rays and gamma rays qualify. These are capable of the most severe types of molecular damage, which can happen in biology to any type of biomolecule, including mutation and cancer, and often at great depths below the skin, since the higher end of the X-ray spectrum, and all of the gamma ray spectrum, penetrate matter.\n\n\n== Atmosphere and magnetosphere ==\n\nMost UV and X-rays are blocked by absorption first from molecular nitrogen, and then (for wavelengths in the upper UV) from the electronic excitation of dioxygen and finally ozone at the mid-range of UV. Only 30% of the Sun's ultraviolet light reaches the ground, and almost all of this is well transmitted.\nVisible light is well transmitted in air, as it is not energetic enough to excite nitrogen, oxygen, or ozone, but too energetic to excite molecular vibrational frequencies of water vapor.Absorption bands in the infrared are due to modes of vibrational excitation in water vapor. However, at energies too low to excite water vapor, the atmosphere becomes transparent again, allowing free transmission of most microwave and radio waves. Finally, at radio wavelengths longer than 10 m or so (about 30 MHz), the air in the lower atmosphere remains transparent to radio, but plasma in certain layers of the ionosphere begins to interact with radio waves (see skywave). This property allows some longer wavelengths (100 m or 3 MHz) to be reflected and results in shortwave radio beyond line-of-sight. However, certain  ionospheric effects begin to block incoming radiowaves from space, when their frequency is less than about 10 MHz (wavelength longer than about 30 m).\n\n\n== Thermal and electromagnetic radiation as a form of heat ==\n\nThe basic structure of matter involves charged particles bound together. When electromagnetic radiation impinges on matter, it causes the charged particles to oscillate and gain energy. The ultimate fate of this energy depends on the context. It could be immediately re-radiated and appear as scattered, reflected, or transmitted radiation. It may get dissipated into other microscopic motions within the matter, coming to thermal equilibrium and manifesting itself as thermal energy, or even kinetic energy, in the material. With a few exceptions related to high-energy photons (such as fluorescence, harmonic generation, photochemical reactions, the photovoltaic effect for ionizing radiations at far ultraviolet, X-ray and gamma radiation), absorbed electromagnetic radiation simply deposits its energy by heating the material. This happens for infrared, microwave and radio wave radiation. Intense radio waves can thermally burn living tissue and can cook food. In addition to infrared lasers, sufficiently intense visible and ultraviolet lasers can easily set paper afire.Ionizing radiation creates high-speed electrons in a material and breaks chemical bonds, but after these electrons collide many times with other atoms eventually most of the energy becomes thermal energy all in a tiny fraction of a second. This process makes ionizing radiation far more dangerous per unit of energy than non-ionizing radiation. This caveat also applies to UV, even though almost all of it is not ionizing, because UV can damage molecules due to electronic excitation, which is far greater per unit energy than heating effects.Infrared radiation in the spectral distribution of a black body is usually considered a form of heat, since it has an equivalent temperature and is associated with an entropy change per unit of thermal energy. However, \"heat\" is a technical term in physics and thermodynamics and is often confused with thermal energy. Any type of electromagnetic energy can be transformed into thermal energy in interaction with matter. Thus, any electromagnetic radiation can \"heat\" (in the sense of increase the thermal energy temperature of) a material, when it is absorbed.The inverse or time-reversed process of absorption is thermal radiation. Much of the thermal energy in matter consists of random motion of charged particles, and this energy can be radiated away from the matter. The resulting radiation may subsequently be absorbed by another piece of matter, with the deposited energy heating the material.The electromagnetic radiation in an opaque cavity at thermal equilibrium is effectively a form of thermal energy, having maximum radiation entropy.\n\n\n== Biological effects ==\n\nBioelectromagnetics is the study of the interactions and effects of EM radiation on living organisms. The effects of electromagnetic radiation upon living cells, including those in humans, depends upon the radiation's power and frequency. For low-frequency radiation (radio waves to visible light) the best-understood effects are those due to radiation power alone, acting through heating when radiation is absorbed. For these thermal effects, frequency is important as it affects the intensity of the radiation and penetration into the organism (for example, microwaves penetrate better than infrared). It is widely accepted that low frequency fields that are too weak to cause significant heating could not possibly have any biological effect.Some research suggests that weaker non-thermal electromagnetic fields (including weak ELF magnetic fields, although the latter does not strictly qualify as EM radiation) and modulated RF and microwave fields can have biological effects, though the significance of this is unclear.The World Health Organization has classified radio frequency electromagnetic radiation as Group 2B \u2013 possibly carcinogenic. This group contains possible carcinogens such as lead, DDT, and styrene. For example, epidemiological studies looking for a relationship between cell phone use and brain cancer development have been largely inconclusive, save to demonstrate that the effect, if it exists, cannot be a large one.\nAt higher frequencies (visible and beyond), the effects of individual photons begin to become important, as these now have enough energy individually to directly or indirectly damage biological molecules. All UV frequencies have been classed as Group 1 carcinogens by the World Health Organization. Ultraviolet radiation from sun exposure is the primary cause of skin cancer.Thus, at UV frequencies and higher (and probably somewhat also in the visible range), electromagnetic radiation does more damage to biological systems than simple heating predicts. This is most obvious in the \"far\" (or \"extreme\") ultraviolet. UV, with X-ray and gamma radiation, are referred to as ionizing radiation due to the ability of photons of this radiation to produce ions and free radicals in materials (including living tissue). Since such radiation can severely damage life at energy levels that produce little heating, it is considered far more dangerous (in terms of damage-produced per unit of energy, or power) than the rest of the electromagnetic spectrum.\n\n\n=== Use as a weapon ===\n\nThe heat ray is an application of EMR that makes use of microwave frequencies to create an unpleasant heating effect in the upper layer of the skin. A publicly known heat ray weapon called the Active Denial System was developed by the US military as an experimental weapon to deny the enemy access to an area. A death ray is a theoretical weapon that delivers heat ray based on electromagnetic energy at levels that are capable of injuring human tissue. An inventor of a death ray, Harry Grindell Matthews, claimed to have lost sight in his left eye while working on his death ray weapon based on a microwave magnetron from the 1920s (a normal microwave oven creates a tissue damaging cooking effect inside the oven at around 2 kV/m).\n\n\n== Derivation from electromagnetic theory ==\n\nElectromagnetic waves are predicted by the classical laws of electricity and magnetism, known as Maxwell's equations. There are nontrivial solutions of the homogeneous Maxwell's equations (without charges or currents), describing waves of changing electric and magnetic fields. Beginning with Maxwell's equations in free space:\n\nwhere\n\n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle \\mathbf {E} }\n   and \n  \n    \n      \n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {B} }\n   are the electric field (measured in V/m or N/C) and the magnetic field (measured in T or Wb/m2), respectively;\n\n  \n    \n      \n        \u2207\n        \u22c5\n        \n          X\n        \n      \n    \n    {\\displaystyle \\nabla \\cdot \\mathbf {X} }\n   yields the divergence and \n  \n    \n      \n        \u2207\n        \u00d7\n        \n          X\n        \n      \n    \n    {\\displaystyle \\nabla \\times \\mathbf {X} }\n   the curl of a vector field \n  \n    \n      \n        \n          X\n        \n        ;\n      \n    \n    {\\displaystyle \\mathbf {X} ;}\n  \n\n  \n    \n      \n        \n          \n            \n              \u2202\n              \n                B\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\partial \\mathbf {B} }{\\partial t}}}\n   and \n  \n    \n      \n        \n          \n            \n              \u2202\n              \n                E\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\partial \\mathbf {E} }{\\partial t}}}\n   are partial derivatives (rate of change in time, with location fixed) of the magnetic and electric field;\n\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the permeability of a vacuum (4\u03c0 \u00d7 10\u22127 (H/m)), and \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   is the permittivity of a vacuum (8.85\u00d710\u221212 (F/m));Besides the trivial solution\n\nuseful solutions can be derived with the following vector identity, valid for all vectors \n  \n    \n      \n        \n          A\n        \n      \n    \n    {\\displaystyle \\mathbf {A} }\n   in some vector field:\n\nTaking the curl of the second Maxwell equation (2) yields:\n\nEvaluating the left hand side of (5) with the above identity and simplifying using (1), yields:\n\nEvaluating the right hand side of (5) by exchanging the sequence of derivations and inserting the fourth Maxwell equation (4), yields:\n\nCombining (6) and (7) again, gives a vector-valued differential equation for the electric field, solving the homogeneous Maxwell equations:\n\nTaking the curl of the fourth Maxwell equation (4) results in a similar differential equation for a magnetic field solving the homogeneous Maxwell equations:\n\nBoth differential equations have the form of the general wave equation for waves propagating with speed \n  \n    \n      \n        \n          c\n          \n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle c_{0},}\n   where \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is a function of time and location, which gives the amplitude of the wave at some time at a certain location:\n\nThis is also written as: \nwhere \n  \n    \n      \n        \u25fb\n      \n    \n    {\\displaystyle \\Box }\n   denotes the so-called d'Alembert operator, which in Cartesian coordinates is given as:\n\nComparing the terms for the speed of propagation, yields in the case of the electric and magnetic fields:\n\nThis is the speed of light in vacuum. Thus Maxwell's equations connect the vacuum permittivity \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n  , the vacuum permeability \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n  , and the speed of light, c0, via the above equation. This relationship had been discovered by Wilhelm Eduard Weber and Rudolf Kohlrausch prior to the development of Maxwell's electrodynamics, however Maxwell was the first to produce a field theory consistent with waves traveling at the speed of light.\nThese are only two equations versus the original four, so more information pertains to these waves hidden within Maxwell's equations. A generic vector wave for the electric field has the form\n\nHere, \n  \n    \n      \n        \n          \n            E\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {E} _{0}}\n   is the constant amplitude, \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is any second differentiable function, \n  \n    \n      \n        \n          \n            \n              \n                k\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {k} }}}\n   is a unit vector in the direction of propagation, and \n  \n    \n      \n        \n          \n            x\n          \n        \n      \n    \n    {\\displaystyle {\\mathbf {x} }}\n   is a position vector. \n  \n    \n      \n        f\n        \n          \n            (\n            \n              \n                \n                  \n                    \n                      k\n                    \n                    ^\n                  \n                \n              \n              \u22c5\n              \n                x\n              \n              \u2212\n              \n                c\n                \n                  0\n                \n              \n              t\n            \n            )\n          \n        \n      \n    \n    {\\displaystyle f{\\left({\\hat {\\mathbf {k} }}\\cdot \\mathbf {x} -c_{0}t\\right)}}\n   is a generic solution to the wave equation. In other words,\n\nfor a generic wave traveling in the \n  \n    \n      \n        \n          \n            \n              \n                k\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {k} }}}\n   direction.\nFrom the first of Maxwell's equations, we get\n\nThus,\n\nwhich implies that the electric field is orthogonal to the direction the wave propagates. The second of Maxwell's equations yields the magnetic field, namely,\n\nThus,\n\nThe remaining equations will be satisfied by this choice of \n  \n    \n      \n        \n          E\n        \n        ,\n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {E} ,\\mathbf {B} }\n  .\nThe electric and magnetic field waves in the far-field travel at the speed of light. They have a special restricted orientation and proportional magnitudes, \n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n        =\n        \n          c\n          \n            0\n          \n        \n        \n          B\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}=c_{0}B_{0}}\n  , which can be seen immediately from the Poynting vector. The electric field, magnetic field, and direction of wave propagation are all orthogonal, and the wave propagates in the same direction as \n  \n    \n      \n        \n          E\n        \n        \u00d7\n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {E} \\times \\mathbf {B} }\n  . Also, E and B far-fields in free space, which as wave solutions depend primarily on these two Maxwell equations, are in-phase with each other. This is guaranteed since the generic wave solution is first order in both space and time, and the curl operator on one side of these equations results in first-order spatial derivatives of the wave solution, while the time-derivative on the other side of the equations, which gives the other field, is first-order in time, resulting in the same phase shift for both fields in each mathematical operation.\nFrom the viewpoint of an electromagnetic wave traveling forward, the electric field might be oscillating up and down, while the magnetic field oscillates right and left. This picture can be rotated with the electric field oscillating right and left and the magnetic field oscillating down and up. This is a different solution that is traveling in the same direction. This arbitrariness in the orientation with respect to propagation direction is known as polarization. On a quantum level, it is described as photon polarization. The direction of the polarization is defined as the direction of the electric field.\nMore general forms of the second-order wave equations given above are available, allowing for both non-vacuum propagation media and sources. Many competing derivations exist, all with varying levels of approximation and intended applications. One very general example is a form of the electric field equation, which was factorized into a pair of explicitly directional wave equations, and then efficiently reduced into a single uni-directional wave equation by means of a simple slow-evolution approximation.\n\n\n== See also ==\n\n\n== References ==\n\n\"Light: Electromagnetic waves, the electromagnetic spectrum and photons (article)\". Khan Academy. Retrieved 2 May 2021.\n\n\n== Further reading ==\nHecht, Eugene (2001). Optics (4th ed.). Pearson Education. ISBN 978-0-8053-8566-3.\nSerway, Raymond A.; Jewett, John W. (2004). Physics for Scientists and Engineers (6th ed.). Brooks Cole. ISBN 978-0-534-40842-8.\nTipler, Paul (2004). Physics for Scientists and Engineers: Electricity, Magnetism, Light, and Elementary Modern Physics (5th ed.). W. H. Freeman. ISBN 978-0-7167-0810-0.\nReitz, John; Milford, Frederick; Christy, Robert (1992). Foundations of Electromagnetic Theory (4th ed.). Addison Wesley. ISBN 978-0-201-52624-0.\nJackson, John David (1999). Classical Electrodynamics (3rd ed.). John Wiley & Sons. ISBN 978-0-471-30932-1.\nAllen Taflove and Susan C. Hagness (2005). Computational Electrodynamics: The Finite-Difference Time-Domain Method, 3rd ed. Artech House Publishers. ISBN 978-1-58053-832-9.\n\n\n== External links ==\n\nThe Feynman Lectures on Physics Vol. I Ch. 28: Electromagnetic Radiation\n Media related to Electromagnetic radiation at Wikimedia Commons\nElectromagnetic Waves from Maxwell's Equations on Project PHYSNET.\n\"Electromagnetic radiation\" in the Encyclop\u00e6dia Britannica", "Magnetism": "Magnetism is the class of physical attributes that are mediated by a magnetic field, which refers to the capacity to induce attractive and repulsive phenomena in other entities. Electric currents and the magnetic moments of elementary particles giving rise to a magnetic field, which acts on other currents and magnetic moments. Magnetism is one aspect of the combined phenomena of electromagnetism. The most familiar effects occur in ferromagnetic materials, which are strongly attracted by magnetic fields and can be magnetized to become permanent magnets, producing magnetic fields themselves. Demagnetizing a magnet is also possible. Only a few substances are ferromagnetic; the most common ones are iron, cobalt, and nickel and their alloys. The rare-earth metals neodymium and samarium are less common examples. The prefix ferro- refers to iron because permanent magnetism was first observed in lodestone, a form of natural iron ore called magnetite, Fe3O4.\nAll substances exhibit some type of magnetism. Magnetic materials are classified according to their bulk susceptibility. Ferromagnetism is responsible for most of the effects of magnetism encountered in everyday life, but there are actually several types of magnetism. Paramagnetic substances, such as aluminium and oxygen, are weakly attracted to an applied magnetic field; diamagnetic substances, such as copper and carbon, are weakly repelled; while antiferromagnetic materials, such as chromium and spin glasses, have a more complex relationship with a magnetic field. The force of a magnet on paramagnetic, diamagnetic, and antiferromagnetic materials is usually too weak to be felt and can be detected only by laboratory instruments, so in everyday life, these substances are often described as non-magnetic.\nThe magnetic state (or magnetic phase) of a material depends on temperature, pressure, and the applied magnetic field. A material may exhibit more than one form of magnetism as these variables change.\nThe strength of a magnetic field almost always decreases with distance, though the exact mathematical relationship between strength and distance varies. Different configurations of magnetic moments and electric currents can result in complicated magnetic fields.\nOnly magnetic dipoles have been observed although some theories predict the existence of magnetic monopoles.\n\n\n== History ==\n\nMagnetism was first discovered in the ancient world when people noticed that lodestones, naturally magnetized pieces of the mineral magnetite, could attract iron. The word magnet comes from the Greek term \u03bc\u03b1\u03b3\u03bd\u1fc6\u03c4\u03b9\u03c2 \u03bb\u03af\u03b8\u03bf\u03c2 magn\u0113tis lithos, \"the Magnesian stone, lodestone.\" In ancient Greece, Aristotle attributed the first of what could be called a scientific discussion of magnetism to the philosopher Thales of Miletus, who lived from about 625 BC to about 545 BC. The ancient Indian medical text Sushruta Samhita describes using magnetite to remove arrows embedded in a person's body.In ancient China, the earliest literary reference to magnetism lies in a 4th-century BC book named after its author, Guiguzi.\nThe 2nd-century BC annals, L\u00fcshi Chunqiu, also notes:\n\"The lodestone makes iron approach; some (force) is attracting it.\" \nThe earliest mention of the attraction of a needle is in a 1st-century work Lunheng (Balanced Inquiries): \"A lodestone attracts a needle.\" \nThe 11th-century Chinese scientist Shen Kuo was the first person to write\u2014in the Dream Pool Essays\u2014of the magnetic needle compass and that it improved the accuracy of navigation by employing the astronomical concept of true north.\nBy the 12th century, the Chinese were known to use the lodestone compass for navigation. They sculpted a directional spoon from lodestone in such a way that the handle of the spoon always pointed south.\nAlexander Neckam, by 1187, was the first in Europe to describe the compass and its use for navigation. In 1269, Peter Peregrinus de Maricourt wrote the Epistola de magnete, the first extant treatise describing the properties of magnets. In 1282, the properties of magnets and the dry compasses were discussed by Al-Ashraf Umar II, a Yemeni physicist, astronomer, and geographer.Leonardo Garzoni's only extant work, the Due trattati sopra la natura, e le qualit\u00e0 della calamita, is the first known example of a modern treatment of magnetic phenomena. Written in years near 1580 and never published, the treatise had a wide diffusion. In particular, Garzoni is referred to as an expert in magnetism by Niccol\u00f2 Cabeo, whose Philosophia Magnetica (1629) is just a re-adjustment of Garzoni's work. Garzoni's treatise was known also to Giovanni Battista Della Porta.\nIn 1600, William Gilbert published his De Magnete, Magneticisque Corporibus, et de Magno Magnete Tellure (On the Magnet and Magnetic Bodies, and on the Great Magnet the Earth). In this work he describes many of his experiments with his model earth called the terrella. From his experiments, he concluded that the Earth was itself magnetic and that this was the reason compasses pointed north whereas, previously, some believed that it was the pole star Polaris or a large magnetic island on the north pole that attracted the compass.\nAn understanding of the relationship between electricity and magnetism began in 1819 with work by Hans Christian \u00d8rsted, a professor at the University of Copenhagen, who discovered, by the accidental twitching of a compass needle near a wire, that an electric current could create a magnetic field. This landmark experiment is known as \u00d8rsted's Experiment. Following this were several other scientists' experiments, with Andr\u00e9-Marie Amp\u00e8re, who in 1820 discovered that the magnetic field circulating in a closed-path was related to the current flowing through a surface enclosed by the path; Carl Friedrich Gauss; Jean-Baptiste Biot and F\u00e9lix Savart, both of whom in 1820 came up with the Biot\u2013Savart law giving an equation for the magnetic field from a current-carrying wire; Michael Faraday, who in 1831 found that a time-varying magnetic flux through a loop of wire induced a voltage, and others finding further links between magnetism and electricity. James Clerk Maxwell synthesized and expanded these insights into Maxwell's equations, unifying electricity, magnetism, and optics into the field of electromagnetism. In 1905, Albert Einstein used these laws in motivating his theory of special relativity, requiring that the laws held true in all inertial reference frames.\nElectromagnetism has continued to develop into the 21st century, being incorporated into the more fundamental theories of gauge theory, quantum electrodynamics, electroweak theory, and finally the standard model.\n\n\n== Sources ==\n\nMagnetism, at its root, arises from three sources:\n\nElectric current\nSpin magnetic moments of elementary particles\nChanging electric fieldsThe magnetic properties of materials are mainly due to the magnetic moments of their atoms' orbiting electrons. The magnetic moments of the nuclei of atoms are typically thousands of times smaller than the electrons' magnetic moments, so they are negligible in the context of the magnetization of materials. Nuclear magnetic moments are nevertheless very important in other contexts, particularly in nuclear magnetic resonance (NMR) and magnetic resonance imaging (MRI).\nOrdinarily, the enormous number of electrons in a material are arranged such that their magnetic moments (both orbital and intrinsic) cancel out. This is due, to some extent, to electrons combining into pairs with opposite intrinsic magnetic moments as a result of the Pauli exclusion principle (see electron configuration), and combining into filled subshells with zero net orbital motion. In both cases, the electrons preferentially adopt arrangements in which the magnetic moment of each electron is canceled by the opposite moment of another electron. Moreover, even when the electron configuration is such that there are unpaired electrons and/or non-filled subshells, it is often the case that the various electrons in the solid will contribute magnetic moments that point in different, random directions so that the material will not be magnetic.\nSometimes, either spontaneously, or owing to an applied external magnetic field\u2014each of the electron magnetic moments will be, on average, lined up. A suitable material can then produce a strong net magnetic field.\nThe magnetic behavior of a material depends on its structure, particularly its electron configuration, for the reasons mentioned above, and also on the temperature. At high temperatures, random thermal motion makes it more difficult for the electrons to maintain alignment.\n\n\n== Types of magnetism ==\n\n\n=== Diamagnetism ===\n\nDiamagnetism appears in all materials and is the tendency of a material to oppose an applied magnetic field, and therefore, to be repelled by a magnetic field. However, in a material with paramagnetic properties (that is, with a tendency to enhance an external magnetic field), the paramagnetic behavior dominates. Thus, despite its universal occurrence, diamagnetic behavior is observed only in a purely diamagnetic material. In a diamagnetic material, there are no unpaired electrons, so the intrinsic electron magnetic moments cannot produce any bulk effect. In these cases, the magnetization arises from the electrons' orbital motions, which can be understood classically as follows:\n\nWhen a material is put in a magnetic field, the electrons circling the nucleus will experience, in addition to their Coulomb attraction to the nucleus, a Lorentz force from the magnetic field. Depending on which direction the electron is orbiting, this force may increase the centripetal force on the electrons, pulling them in towards the nucleus, or it may decrease the force, pulling them away from the nucleus. This effect systematically increases the orbital magnetic moments that were aligned opposite the field and decreases the ones aligned parallel to the field (in accordance with Lenz's law). This results in a small bulk magnetic moment, with an opposite direction to the applied field.\nThis description is meant only as a heuristic; the Bohr\u2013Van Leeuwen theorem shows that diamagnetism is impossible according to classical physics, and that a proper understanding requires a quantum-mechanical description.\nAll materials undergo this orbital response. However, in paramagnetic and ferromagnetic substances, the diamagnetic effect is overwhelmed by the much stronger effects caused by the unpaired electrons.\n\n\n=== Paramagnetism ===\n\nIn a paramagnetic material there are unpaired electrons; i.e., atomic or molecular orbitals with exactly one electron in them. While paired electrons are required by the Pauli exclusion principle to have their intrinsic ('spin') magnetic moments pointing in opposite directions, causing their magnetic fields to cancel out, an unpaired electron is free to align its magnetic moment in any direction. When an external magnetic field is applied, these magnetic moments will tend to align themselves in the same direction as the applied field, thus reinforcing it.\n\n\n=== Ferromagnetism ===\n\nA ferromagnet, like a paramagnetic substance, has unpaired electrons. However, in addition to the electrons' intrinsic magnetic moment's tendency to be parallel to an applied field, there is also in these materials a tendency for these magnetic moments to orient parallel to each other to maintain a lowered-energy state. Thus, even in the absence of an applied field, the magnetic moments of the electrons in the material spontaneously line up parallel to one another.\nEvery ferromagnetic substance has its own individual temperature, called the Curie temperature, or Curie point, above which it loses its ferromagnetic properties. This is because the thermal tendency to disorder overwhelms the energy-lowering due to ferromagnetic order.\nFerromagnetism only occurs in a few substances; common ones are iron, nickel, cobalt, their alloys, and some alloys of rare-earth metals.\n\n\n==== Magnetic domains ====\n\nThe magnetic moments of atoms in a ferromagnetic material cause them to behave something like tiny permanent magnets. They stick together and align themselves into small regions of more or less uniform alignment called magnetic domains or Weiss domains. Magnetic domains can be observed with a magnetic force microscope to reveal magnetic domain boundaries that resemble white lines in the sketch. There are many scientific experiments that can physically show magnetic fields.\nWhen a domain contains too many molecules, it becomes unstable and divides into two domains aligned in opposite directions so that they stick together more stably.\nWhen exposed to a magnetic field, the domain boundaries move, so that the domains aligned with the magnetic field grow and dominate the structure (dotted yellow area), as shown at the left. When the magnetizing field is removed, the domains may not return to an unmagnetized state. This results in the ferromagnetic material's being magnetized, forming a permanent magnet.\nWhen magnetized strongly enough that the prevailing domain overruns all others to result in only one single domain, the material is magnetically saturated. When a magnetized ferromagnetic material is heated to the Curie point temperature, the molecules are agitated to the point that the magnetic domains lose the organization, and the magnetic properties they cause cease. When the material is cooled, this domain alignment structure spontaneously returns, in a manner roughly analogous to how a liquid can freeze into a crystalline solid.\n\n\n=== Antiferromagnetism ===\n\nIn an antiferromagnet, unlike a ferromagnet, there is a tendency for the intrinsic magnetic moments of neighboring valence electrons to point in opposite directions. When all atoms are arranged in a substance so that each neighbor is anti-parallel, the substance is antiferromagnetic. Antiferromagnets have a zero net magnetic moment because adjacent opposite moment cancels out, meaning that no field is produced by them. Antiferromagnets are less common compared to the other types of behaviors and are mostly observed at low temperatures. In varying temperatures, antiferromagnets can be seen to exhibit diamagnetic and ferromagnetic properties.\nIn some materials, neighboring electrons prefer to point in opposite directions, but there is no geometrical arrangement in which each pair of neighbors is anti-aligned. This is called a spin glass and is an example of geometrical frustration.\n\n\n=== Ferrimagnetism ===\n\nLike ferromagnetism, ferrimagnets retain their magnetization in the absence of a field. However, like antiferromagnets, neighboring pairs of electron spins tend to point in opposite directions. These two properties are not contradictory, because in the optimal geometrical arrangement, there is more magnetic moment from the sublattice of electrons that point in one direction, than from the sublattice that points in the opposite direction.\nMost ferrites are ferrimagnetic. The first discovered magnetic substance, magnetite, is a ferrite and was originally believed to be a ferromagnet; Louis N\u00e9el disproved this, however, after discovering ferrimagnetism.\n\n\n=== Superparamagnetism ===\n\nWhen a ferromagnet or ferrimagnet is sufficiently small, it acts like a single magnetic spin that is subject to Brownian motion. Its response to a magnetic field is qualitatively similar to the response of a paramagnet, but much larger.\n\n\n=== Other types of magnetism ===\nMetamagnetism\nMolecule-based magnets\nSingle-molecule magnet\nSpin glass\n\n\n== Electromagnet ==\n\nAn electromagnet is a type of magnet in which the magnetic field is produced by an electric current. The magnetic field disappears when the current is turned off. Electromagnets usually consist of a large number of closely spaced turns of wire that create the magnetic field. The wire turns are often wound around a magnetic core made from a ferromagnetic or ferrimagnetic material such as iron; the magnetic core concentrates the magnetic flux and makes a more powerful magnet.\nThe main advantage of an electromagnet over a permanent magnet is that the magnetic field can be quickly changed by controlling the amount of electric current in the winding. However, unlike a permanent magnet that needs no power, an electromagnet requires a continuous supply of current to maintain the magnetic field.\nElectromagnets are widely used as components of other electrical devices, such as motors, generators, relays, solenoids, loudspeakers, hard disks, MRI machines, scientific instruments, and magnetic separation equipment. Electromagnets are also employed in industry for picking up and moving heavy iron objects such as scrap iron and steel. Electromagnetism was discovered in 1820.\n\n\n== Magnetism, electricity, and special relativity ==\n\nAs a consequence of Einstein's theory of special relativity, electricity and magnetism are fundamentally interlinked. Both magnetism lacking electricity, and electricity without magnetism, are inconsistent with special relativity, due to such effects as length contraction, time dilation, and the fact that the magnetic force is velocity-dependent. However, when both electricity and magnetism are taken into account, the resulting theory (electromagnetism) is fully consistent with special relativity. In particular, a phenomenon that appears purely electric or purely magnetic to one observer may be a mix of both to another, or more generally the relative contributions of electricity and magnetism are dependent on the frame of reference. Thus, special relativity \"mixes\" electricity and magnetism into a single, inseparable phenomenon called electromagnetism, analogous to how general relativity \"mixes\" space and time into spacetime.\nAll observations on electromagnetism apply to what might be considered to be primarily magnetism, e.g. perturbations in the magnetic field are necessarily accompanied by a nonzero electric field, and propagate at the speed of light.\n\n\n== Magnetic fields in a material ==\n\nIn a vacuum,\n\n  \n    \n      \n        \n          B\n        \n         \n        =\n         \n        \n          \u03bc\n          \n            0\n          \n        \n        \n          H\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} \\ =\\ \\mu _{0}\\mathbf {H} ,}\n  where \u03bc0 is the vacuum permeability.\nIn a material,\n\n  \n    \n      \n        \n          B\n        \n         \n        =\n         \n        \n          \u03bc\n          \n            0\n          \n        \n        (\n        \n          H\n        \n        +\n        \n          M\n        \n        )\n        .\n         \n      \n    \n    {\\displaystyle \\mathbf {B} \\ =\\ \\mu _{0}(\\mathbf {H} +\\mathbf {M} ).\\ }\n  The quantity \u03bc0M is called magnetic polarization.\nIf the field H is small, the response of the magnetization M in a diamagnet or paramagnet is approximately linear:\n\n  \n    \n      \n        \n          M\n        \n        =\n        \u03c7\n        \n          H\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {M} =\\chi \\mathbf {H} ,}\n  the constant of proportionality being called the magnetic susceptibility. If so,\n\n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n        (\n        \n          H\n        \n        +\n        \n          M\n        \n        )\n         \n        =\n         \n        \n          \u03bc\n          \n            0\n          \n        \n        (\n        1\n        +\n        \u03c7\n        )\n        \n          H\n        \n         \n        =\n         \n        \n          \u03bc\n          \n            r\n          \n        \n        \n          \u03bc\n          \n            0\n          \n        \n        \n          H\n        \n         \n        =\n         \n        \u03bc\n        \n          H\n        \n        .\n      \n    \n    {\\displaystyle \\mu _{0}(\\mathbf {H} +\\mathbf {M} )\\ =\\ \\mu _{0}(1+\\chi )\\mathbf {H} \\ =\\ \\mu _{r}\\mu _{0}\\mathbf {H} \\ =\\ \\mu \\mathbf {H} .}\n  In a hard magnet such as a ferromagnet, M is not proportional to the field and is generally nonzero even when H is zero (see Remanence).\n\n\n== Magnetic force ==\n\nThe phenomenon of magnetism is \"mediated\" by the magnetic field. An electric current or magnetic dipole creates a magnetic field, and that field, in turn, imparts magnetic forces on other particles that are in the fields.\nMaxwell's equations, which simplify to the Biot\u2013Savart law in the case of steady currents, describe the origin and behavior of the fields that govern these forces. Therefore, magnetism is seen whenever electrically charged particles are in motion\u2014for example, from movement of electrons in an electric current, or in certain cases from the orbital motion of electrons around an atom's nucleus. They also arise from \"intrinsic\" magnetic dipoles arising from quantum-mechanical spin.\nThe same situations that create magnetic fields\u2014charge moving in a current or in an atom, and intrinsic magnetic dipoles\u2014are also the situations in which a magnetic field has an effect, creating a force. Following is the formula for moving charge; for the forces on an intrinsic dipole, see magnetic dipole.\nWhen a charged particle moves through a magnetic field B, it feels a Lorentz force F given by the cross product:\n\n  \n    \n      \n        \n          F\n        \n        =\n        q\n        (\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {F} =q(\\mathbf {v} \\times \\mathbf {B} )}\n  where\n\n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the electric charge of the particle, and\nv is the velocity vector of the particleBecause this is a cross product, the force is perpendicular to both the motion of the particle and the magnetic field. It follows that the magnetic force does no work on the particle; it may change the direction of the particle's movement, but it cannot cause it to speed up or slow down. The magnitude of the force is\n\n  \n    \n      \n        F\n        =\n        q\n        v\n        B\n        sin\n        \u2061\n        \u03b8\n        \n      \n    \n    {\\displaystyle F=qvB\\sin \\theta \\,}\n  where \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between v and B.\nOne tool for determining the direction of the velocity vector of a moving charge, the magnetic field, and the force exerted is labeling the index finger \"V\", the middle finger \"B\", and the thumb \"F\" with your right hand. When making a gun-like configuration, with the middle finger crossing under the index finger, the fingers represent the velocity vector, magnetic field vector, and force vector, respectively. See also right-hand rule.\n\n\n== Magnetic dipoles ==\n\nA very common source of magnetic field found in nature is a dipole, with a \"South pole\" and a \"North pole\", terms dating back to the use of magnets as compasses, interacting with the Earth's magnetic field to indicate North and South on the globe. Since opposite ends of magnets are attracted, the north pole of a magnet is attracted to the south pole of another magnet. The Earth's North Magnetic Pole (currently in the Arctic Ocean, north of Canada) is physically a south pole, as it attracts the north pole of a compass.\nA magnetic field contains energy, and physical systems move toward configurations with lower energy. When diamagnetic material is placed in a magnetic field, a magnetic dipole tends to align itself in opposed polarity to that field, thereby lowering the net field strength. When ferromagnetic material is placed within a magnetic field, the magnetic dipoles align to the applied field, thus expanding the domain walls of the magnetic domains.\n\n\n=== Magnetic monopoles ===\n\nSince a bar magnet gets its ferromagnetism from electrons distributed evenly throughout the bar, when a bar magnet is cut in half, each of the resulting pieces is a smaller bar magnet. Even though a magnet is said to have a north pole and a south pole, these two poles cannot be separated from each other. A monopole\u2014if such a thing exists\u2014would be a new and fundamentally different kind of magnetic object. It would act as an isolated north pole, not attached to a south pole, or vice versa. Monopoles would carry \"magnetic charge\" analogous to electric charge. Despite systematic searches since 1931, as of 2010, they have never been observed, and could very well not exist.Nevertheless, some theoretical physics models predict the existence of these magnetic monopoles. Paul Dirac observed in 1931 that, because electricity and magnetism show a certain symmetry, just as quantum theory predicts that individual positive or negative electric charges can be observed without the opposing charge, isolated South or North magnetic poles should be observable. Using quantum theory Dirac showed that if magnetic monopoles exist, then one could explain the quantization of electric charge\u2014that is, why the observed elementary particles carry charges that are multiples of the charge of the electron.\nCertain grand unified theories predict the existence of monopoles which, unlike elementary particles, are solitons (localized energy packets). The initial results of using these models to estimate the number of monopoles created in the Big Bang contradicted cosmological observations\u2014the monopoles would have been so plentiful and massive that they would have long since halted the expansion of the universe. However, the idea of inflation (for which this problem served as a partial motivation) was successful in solving this problem, creating models in which monopoles existed but were rare enough to be consistent with current observations.\n\n\n== Units ==\n\n\n=== SI ===\n\n\n=== Other ===\ngauss \u2013 the centimeter-gram-second (CGS) unit of magnetic field (denoted B).\noersted \u2013 the CGS unit of magnetizing field (denoted H)\nmaxwell \u2013 the CGS unit for magnetic flux\ngamma \u2013 a unit of magnetic flux density that was commonly used before the tesla came into use (1.0 gamma = 1.0 nanotesla)\n\u03bc0 \u2013 common symbol for the permeability of free space (4\u03c0 \u00d7 10\u22127 newton/(ampere-turn)2)\n\n\n== Living things ==\n\nSome organisms can detect magnetic fields, a phenomenon known as magnetoception. Some materials in living things are ferromagnetic, though it is unclear if the magnetic properties serve a special function or are merely a byproduct of containing iron. For instance, chitons, a type of marine mollusk, produce magnetite to harden their teeth, and even humans produce magnetite in bodily tissue. Magnetobiology studies the effects of magnetic fields on living organisms; fields naturally produced by an organism are known as biomagnetism. Many biological organisms are mostly made of water, and because water is diamagnetic, extremely strong magnetic fields can repel these living things.\n\n\n== Quantum-mechanical origin of magnetism ==\nWhile heuristic explanations based on classical physics can be formulated, diamagnetism, paramagnetism and ferromagnetism can be fully explained only using quantum theory.\nA successful model was developed already in 1927, by Walter Heitler and Fritz London, who derived, quantum-mechanically, how hydrogen molecules are formed from hydrogen atoms, i.e. from the atomic hydrogen orbitals \n  \n    \n      \n        \n          u\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle u_{A}}\n   and \n  \n    \n      \n        \n          u\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle u_{B}}\n   centered at the nuclei A and B, see below. That this leads to magnetism is not at all obvious, but will be explained in the following.\nAccording to the Heitler\u2013London theory, so-called two-body molecular \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  -orbitals are formed, namely the resulting orbital is:\n\n  \n    \n      \n        \u03c8\n        (\n        \n          \n            r\n          \n          \n            1\n          \n        \n        ,\n        \n        \n        \n          \n            r\n          \n          \n            2\n          \n        \n        )\n        =\n        \n          \n            1\n            \n              2\n            \n          \n        \n        \n        \n        \n          (\n          \n            \n              u\n              \n                A\n              \n            \n            (\n            \n              \n                r\n              \n              \n                1\n              \n            \n            )\n            \n              u\n              \n                B\n              \n            \n            (\n            \n              \n                r\n              \n              \n                2\n              \n            \n            )\n            +\n            \n              u\n              \n                B\n              \n            \n            (\n            \n              \n                r\n              \n              \n                1\n              \n            \n            )\n            \n              u\n              \n                A\n              \n            \n            (\n            \n              \n                r\n              \n              \n                2\n              \n            \n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle \\psi (\\mathbf {r} _{1},\\,\\,\\mathbf {r} _{2})={\\frac {1}{\\sqrt {2}}}\\,\\,\\left(u_{A}(\\mathbf {r} _{1})u_{B}(\\mathbf {r} _{2})+u_{B}(\\mathbf {r} _{1})u_{A}(\\mathbf {r} _{2})\\right)}\n  Here the last product means that a first electron, r1, is in an atomic hydrogen-orbital centered at the second nucleus, whereas the second electron runs around the first nucleus. This \"exchange\" phenomenon is an expression for the quantum-mechanical property that particles with identical properties cannot be distinguished. It is specific not only for the formation of chemical bonds, but also for magnetism. That is, in this connection the term exchange interaction arises, a term which is essential for the origin of magnetism, and which is stronger, roughly by factors 100 and even by 1000, than the energies arising from the electrodynamic dipole-dipole interaction.\nAs for the spin function \n  \n    \n      \n        \u03c7\n        (\n        \n          s\n          \n            1\n          \n        \n        ,\n        \n          s\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\chi (s_{1},s_{2})}\n  , which is responsible for the magnetism, we have the already mentioned Pauli's principle, namely that a symmetric orbital (i.e. with the + sign as above) must be multiplied with an antisymmetric spin function (i.e. with a \u2212 sign), and vice versa. Thus:\n\n  \n    \n      \n        \u03c7\n        (\n        \n          s\n          \n            1\n          \n        \n        ,\n        \n        \n        \n          s\n          \n            2\n          \n        \n        )\n        =\n        \n          \n            1\n            \n              2\n            \n          \n        \n        \n        \n        \n          (\n          \n            \u03b1\n            (\n            \n              s\n              \n                1\n              \n            \n            )\n            \u03b2\n            (\n            \n              s\n              \n                2\n              \n            \n            )\n            \u2212\n            \u03b2\n            (\n            \n              s\n              \n                1\n              \n            \n            )\n            \u03b1\n            (\n            \n              s\n              \n                2\n              \n            \n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle \\chi (s_{1},\\,\\,s_{2})={\\frac {1}{\\sqrt {2}}}\\,\\,\\left(\\alpha (s_{1})\\beta (s_{2})-\\beta (s_{1})\\alpha (s_{2})\\right)}\n  ,I.e., not only \n  \n    \n      \n        \n          u\n          \n            A\n          \n        \n      \n    \n    {\\displaystyle u_{A}}\n   and \n  \n    \n      \n        \n          u\n          \n            B\n          \n        \n      \n    \n    {\\displaystyle u_{B}}\n   must be substituted by \u03b1 and \u03b2, respectively (the first entity means \"spin up\", the second one \"spin down\"), but also the sign + by the \u2212 sign, and finally ri by the discrete values si (= \u00b11\u20442); thereby we have \n  \n    \n      \n        \u03b1\n        (\n        +\n        1\n        \n          /\n        \n        2\n        )\n        =\n        \u03b2\n        (\n        \u2212\n        1\n        \n          /\n        \n        2\n        )\n        =\n        1\n      \n    \n    {\\displaystyle \\alpha (+1/2)=\\beta (-1/2)=1}\n   and \n  \n    \n      \n        \u03b1\n        (\n        \u2212\n        1\n        \n          /\n        \n        2\n        )\n        =\n        \u03b2\n        (\n        +\n        1\n        \n          /\n        \n        2\n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\alpha (-1/2)=\\beta (+1/2)=0}\n  . The \"singlet state\", i.e. the \u2212 sign, means: the spins are antiparallel, i.e. for the solid we have antiferromagnetism, and for two-atomic molecules one has diamagnetism. The tendency to form a (homoeopolar) chemical bond (this means: the formation of a symmetric molecular orbital, i.e. with the + sign) results through the Pauli principle automatically in an antisymmetric spin state (i.e. with the \u2212 sign). In contrast, the Coulomb repulsion of the electrons, i.e. the tendency that they try to avoid each other by this repulsion, would lead to an antisymmetric orbital function (i.e. with the \u2212 sign) of these two particles, and complementary to a symmetric spin function (i.e. with the + sign, one of the so-called \"triplet functions\"). Thus, now the spins would be parallel (ferromagnetism in a solid, paramagnetism in two-atomic gases).\nThe last-mentioned tendency dominates in the metals iron, cobalt and nickel, and in some rare earths, which are ferromagnetic. Most of the other metals, where the first-mentioned tendency dominates, are nonmagnetic (e.g. sodium, aluminium, and magnesium) or antiferromagnetic (e.g. manganese). Diatomic gases are also almost exclusively diamagnetic, and not paramagnetic. However, the oxygen molecule, because of the involvement of \u03c0-orbitals, is an exception important for the life-sciences.\nThe Heitler-London considerations can be generalized to the Heisenberg model of magnetism (Heisenberg 1928).\nThe explanation of the phenomena is thus essentially based on all subtleties of quantum mechanics, whereas the electrodynamics covers mainly the phenomenology.\n\n\n== Optically induced magnetism ==\nOptically induced magnetism is essentially the combination of optics and induced magnetism. Optics is the study of the behavior of light and induced magnetism is when an object is kept near a magnet and the object itself becomes magnetic [1].\nOptically induced magnetism works when an electric current passes through a magnetic layer and the electric current becomes spin-polarized. The spin-polarized current will exert a spin-transfer torque (STT) on the magnetization. This phenomenon can also be generated inside a non-magnetic metal due to the spin\u2013orbit coupling (SOC) Spin\u2013orbit interaction, and the corresponding torque (spin\u2013orbit torque (SOT). \n\n\n=== Method ===\nOptically induced magnetism occurs when an initial photon establishes an electrical polarization within a material and that causes an orbital angular momentum. This occurs on all electric dipoles within the material that transition between L = 0 and L = 1. A second photon can exert a magnetic torque on the orbital angular momentum, and that causes an exchange of orbital angular momentum to rotational angular momentum. The change from orbital angular momentum to rotational angular momentum de-excites the molecule and increases the radius of charge motion. When the radius of charge motion increases, the magnetic dipole Electron magnetic moment increases. This is because the magnetic dipole depends on the area enclosed by the current within the molecule (m = ids). This type of magnetism can occur in materials that are thought to be \"non magnetic,\" such as diamagnets Diamagnetism, as long as the material is dielectric.\nThe more you optically excite the dielectric material, the more magnetic dipoles are formed, and therefore the more magnetic the material becomes. However, the electric dipole Electric dipole moment magnitude will always be larger than the magnetic dipole magnitude, and the magnetic dipole moment will always be relative to the electric dipole moment.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== Bibliography ==\n\nThe Exploratorium Science Snacks \u2013 Subject:Physics/Electricity & Magnetism\nA collection of magnetic structures \u2013 MAGNDATA", "Newton's_law_of_universal_gravitation": "Newton's law of universal gravitation is usually stated as that every particle attracts every other particle in the universe with a force that is proportional to the product of their masses and inversely proportional to the square of the distance between their centers. The publication of the law has become known as the \"first great unification\", as it marked the unification of the previously described phenomena of gravity on Earth with known astronomical behaviors.This is a general physical law derived from empirical observations by what Isaac Newton called inductive reasoning. It is a part of classical mechanics and was formulated in Newton's work Philosophi\u00e6 Naturalis Principia Mathematica (\"the Principia\"), first published on 5 July 1687. When Newton presented Book 1 of the unpublished text in April 1686 to the Royal Society, Robert Hooke made a claim that Newton had obtained the inverse square law from him.\nIn today's language, the law states that every point mass attracts every other point mass by a force acting along the line intersecting the two points. The force is proportional to the product of the two masses, and inversely proportional to the square of the distance between them.The equation for universal gravitation thus takes the form:\n\n  \n    \n      \n        F\n        =\n        G\n        \n          \n            \n              \n                m\n                \n                  1\n                \n              \n              \n                m\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle F=G{\\frac {m_{1}m_{2}}{r^{2}}},}\n  where F is the gravitational force acting between two objects, m1 and m2 are the masses of the objects, r is the distance between the centers of their masses, and G is the gravitational constant.\nThe first test of Newton's law of gravitation between masses in the laboratory was the Cavendish experiment conducted by the British scientist Henry Cavendish in 1798. It took place 111 years after the publication of Newton's Principia and approximately 71 years after his death.\nNewton's law of gravitation resembles Coulomb's law of electrical forces, which is used to calculate the magnitude of the electrical force arising between two charged bodies. Both are inverse-square laws, where force is inversely proportional to the square of the distance between the bodies. Coulomb's law has the product of two charges in place of the product of the masses, and the Coulomb constant in place of the gravitational constant.\nNewton's law has later been superseded by Albert Einstein's theory of general relativity, but the universality of gravitational constant is intact and the law still continues to be used as an excellent approximation of the effects of gravity in most applications. Relativity is required only when there is a need for extreme accuracy, or when dealing with very strong gravitational fields, such as those found near extremely massive and dense objects, or at small distances (such as Mercury's orbit around the Sun).\n\n\n== History ==\n\n\n=== Early history ===\nIn 1604, Galileo Galilei correctly hypothesized that the distance of a falling object is proportional to the square of the time elapsed. The relation of the distance of objects in free fall to the square of the time taken was confirmed by Italian Jesuits Grimaldi and Riccioli between 1640 and 1650. They also made a calculation of the gravity of Earth by recording the oscillations of a pendulum.A modern assessment of the early history of the inverse square law is that \"by the late 1670s\", the assumption of an \"inverse proportion between gravity and the square of distance was rather common and had been advanced by a number of different people for different reasons\". The same author credits Robert Hooke with a significant and seminal contribution, but treats Hooke's claim of priority on the inverse square point as irrelevant, as several individuals besides Newton and Hooke had suggested it. He points instead to the idea of \"compounding the celestial motions\" and the conversion of Newton's thinking away from \"centrifugal\" and towards \"centripetal\" force as Hooke's significant contributions.\nNewton gave credit in his Principia to two people: Bullialdus (who wrote without proof that there was a force on the Earth towards the Sun), and Borelli (who wrote that all planets were attracted towards the Sun). The main influence may have been Borelli, whose book Newton had a copy of.\n\n\n=== Plagiarism dispute ===\nIn 1686, when the first book of Newton's Principia was presented to the Royal Society, Robert Hooke accused Newton of plagiarism by claiming that he had taken from him the \"notion\" of \"the rule of the decrease of Gravity, being reciprocally as the squares of the distances from the Center\". At the same time (according to Edmond Halley's contemporary report) Hooke agreed that \"the Demonstration of the Curves generated thereby\" was wholly Newton's.\n\n\n=== Hooke's work and claims ===\nRobert Hooke published his ideas about the \"System of the World\" in the 1660s, when he read to the Royal Society on March 21, 1666, a paper \"concerning the inflection of a direct motion into a curve by a supervening attractive principle\", and he published them again in somewhat developed form in 1674, as an addition to \"An Attempt to Prove the Motion of the Earth from Observations\". Hooke announced in 1674 that he planned to \"explain a System of the World differing in many particulars from any yet known\", based on three suppositions: that \"all Celestial Bodies whatsoever, have an attraction or gravitating power towards their own Centers\" and \"also attract all the other Celestial Bodies that are within the sphere of their activity\"; that \"all bodies whatsoever that are put into a direct and simple motion, will so continue to move forward in a straight line, till they are by some other effectual powers deflected and bent...\" and that \"these attractive powers are so much the more powerful in operating, by how much the nearer the body wrought upon is to their own Centers\". Thus Hooke postulated mutual attractions between the Sun and planets, in a way that increased with nearness to the attracting body, together with a principle of linear inertia.\nHooke's statements up to 1674 made no mention, however, that an inverse square law applies or might apply to these attractions. Hooke's gravitation was also not yet universal, though it approached universality more closely than previous hypotheses. He also did not provide accompanying evidence or mathematical demonstration. On the latter two aspects, Hooke himself stated in 1674: \"Now what these several degrees [of attraction] are I have not yet experimentally verified\"; and as to his whole proposal: \"This I only hint at present\", \"having my self many other things in hand which I would first compleat, and therefore cannot so well attend it\" (i.e. \"prosecuting this Inquiry\"). It was later on, in writing on 6 January 1679|80 to Newton, that Hooke communicated his \"supposition ... that the Attraction always is in a duplicate proportion to the Distance from the Center Reciprocall, and Consequently that the Velocity will be in a subduplicate proportion to the Attraction and Consequently as Kepler Supposes Reciprocall to the Distance.\" (The inference about the velocity was incorrect.)Hooke's correspondence with Newton during 1679\u20131680 not only mentioned this inverse square supposition for the decline of attraction with increasing distance, but also, in Hooke's opening letter to Newton, of 24 November 1679, an approach of \"compounding the celestial motions of the planets of a direct motion by the tangent & an attractive motion towards the central body\".\n\n\n=== Newton's work and claims ===\nNewton, faced in May 1686 with Hooke's claim on the inverse square law, denied that Hooke was to be credited as author of the idea. Among the reasons, Newton recalled that the idea had been discussed with Sir Christopher Wren previous to Hooke's 1679 letter. Newton also pointed out and acknowledged prior work of others, including Bullialdus, (who suggested, but without demonstration, that there was an attractive force from the Sun in the inverse square proportion to the distance), and Borelli (who suggested, also without demonstration, that there was a centrifugal tendency in counterbalance with a gravitational attraction towards the Sun so as to make the planets move in ellipses). D T Whiteside has described the contribution to Newton's thinking that came from Borelli's book, a copy of which was in Newton's library at his death.Newton further defended his work by saying that had he first heard of the inverse square proportion from Hooke, he would still have some rights to it in view of his demonstrations of its accuracy. Hooke, without evidence in favor of the supposition, could only guess that the inverse square law was approximately valid at great distances from the center. According to Newton, while the 'Principia' was still at pre-publication stage, there were so many a priori reasons to doubt the accuracy of the inverse-square law (especially close to an attracting sphere) that \"without my (Newton's) Demonstrations, to which Mr Hooke is yet a stranger, it cannot believed by a judicious Philosopher to be any where accurate.\"This remark refers among other things to Newton's finding, supported by mathematical demonstration, that if the inverse square law applies to tiny particles, then even a large spherically symmetrical mass also attracts masses external to its surface, even close up, exactly as if all its own mass were concentrated at its center. Thus Newton gave a justification, otherwise lacking, for applying the inverse square law to large spherical planetary masses as if they were tiny particles. In addition, Newton had formulated, in Propositions 43\u201345 of Book 1 and associated sections of Book 3, a sensitive test of the accuracy of the inverse square law, in which he showed that only where the law of force is calculated as the inverse square of the distance will the directions of orientation of the planets' orbital ellipses stay constant as they are observed to do apart from small effects attributable to inter-planetary perturbations.\nIn regard to evidence that still survives of the earlier history, manuscripts written by Newton in the 1660s show that Newton himself had, by 1669, arrived at proofs that in a circular case of planetary motion, \"endeavour to recede\" (what was later called centrifugal force) had an inverse-square relation with distance from the center. After his 1679\u20131680 correspondence with Hooke, Newton adopted the language of inward or centripetal force. According to Newton scholar J. Bruce Brackenridge, although much has been made of the change in language and difference of point of view, as between centrifugal or centripetal forces, the actual computations and proofs remained the same either way. They also involved the combination of tangential and radial displacements, which Newton was making in the 1660s. The lesson offered by Hooke to Newton here, although significant, was one of perspective and did not change the analysis. This background shows there was basis for Newton to deny deriving the inverse square law from Hooke.\n\n\n=== Newton's acknowledgment ===\nOn the other hand, Newton did accept and acknowledge, in all editions of the Principia, that Hooke (but not exclusively Hooke) had separately appreciated the inverse square law in the solar system. Newton acknowledged Wren, Hooke, and Halley in this connection in the Scholium to Proposition 4 in Book 1. Newton also acknowledged to Halley that his correspondence with Hooke in 1679\u201380 had reawakened his dormant interest in astronomical matters, but that did not mean, according to Newton, that Hooke had told Newton anything new or original: \"yet am I not beholden to him for any light into that business but only for the diversion he gave me from my other studies to think on these things & for his dogmaticalness in writing as if he had found the motion in the Ellipsis, which inclined me to try it ...\"\n\n\n=== Modern priority controversy ===\nSince the time of Newton and Hooke, scholarly discussion has also touched on the question of whether Hooke's 1679 mention of 'compounding the motions' provided Newton with something new and valuable, even though that was not a claim actually voiced by Hooke at the time. As described above, Newton's manuscripts of the 1660s do show him actually combining tangential motion with the effects of radially directed force or endeavour, for example in his derivation of the inverse square relation for the circular case. They also show Newton clearly expressing the concept of linear inertia\u2014for which he was indebted to Descartes' work, published in 1644 (as Hooke probably was). These matters do not appear to have been learned by Newton from Hooke.\nNevertheless, a number of authors have had more to say about what Newton gained from Hooke and some aspects remain controversial. The fact that most of Hooke's private papers had been destroyed or have disappeared does not help to establish the truth.\nNewton's role in relation to the inverse square law was not as it has sometimes been represented. He did not claim to think it up as a bare idea. What Newton did, was to show how the inverse-square law of attraction had many necessary mathematical connections with observable features of the motions of bodies in the solar system; and that they were related in such a way that the observational evidence and the mathematical demonstrations, taken together, gave reason to believe that the inverse square law was not just approximately true but exactly true (to the accuracy achievable in Newton's time and for about two centuries afterwards \u2013 and with some loose ends of points that could not yet be certainly examined, where the implications of the theory had not yet been adequately identified or calculated).About thirty years after Newton's death in 1727, Alexis Clairaut, a mathematical astronomer eminent in his own right in the field of gravitational studies, wrote after reviewing what Hooke published, that \"One must not think that this idea ... of Hooke diminishes Newton's glory\"; and that \"the example of Hooke\" serves \"to show what a distance there is between a truth that is glimpsed and a truth that is demonstrated\".\n\n\n=== Newton's reservations ===\nWhile Newton was able to formulate his law of gravity in his monumental work, he was deeply uncomfortable with the notion of \"action at a distance\" that his equations implied. In 1692, in his third letter to Bentley, he wrote: \"That one body may act upon another at a distance through a vacuum without the mediation of anything else, by and through which their action and force may be conveyed from one another, is to me so great an absurdity that, I believe, no man who has in philosophic matters a competent faculty of thinking could ever fall into it.\"\nHe never, in his words, \"assigned the cause of this power\". In all other cases, he used the phenomenon of motion to explain the origin of various forces acting on bodies, but in the case of gravity, he was unable to experimentally identify the motion that produces the force of gravity (although he invented two mechanical hypotheses in 1675 and 1717). Moreover, he refused to even offer a hypothesis as to the cause of this force on grounds that to do so was contrary to sound science. He lamented that \"philosophers have hitherto attempted the search of nature in vain\" for the source of the gravitational force, as he was convinced \"by many reasons\" that there were \"causes hitherto unknown\" that were fundamental to all the \"phenomena of nature\". These fundamental phenomena are still under investigation and, though hypotheses abound, the definitive answer has yet to be found. And in Newton's 1713 General Scholium in the second edition of Principia: \"I have not yet been able to discover the cause of these properties of gravity from phenomena and I feign no hypotheses.... It is enough that gravity does really exist and acts according to the laws I have explained, and that it abundantly serves to account for all the motions of celestial bodies.\"\n\n\n== Modern form ==\nIn modern language, the law states the following:\n\nAssuming SI units, F is measured in newtons (N), m1 and m2 in kilograms (kg), r in meters (m), and the constant G is 6.67430(15)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122.\nThe value of the constant G was first accurately determined from the results of the Cavendish experiment conducted by the British scientist Henry Cavendish in 1798, although Cavendish did not himself calculate a numerical value for G. This experiment was also the first test of Newton's theory of gravitation between masses in the laboratory. It took place 111 years after the publication of Newton's Principia and 71 years after Newton's death, so none of Newton's calculations could use the value of G; instead he could only calculate a force relative to another force.\n\n\n== Bodies with spatial extent ==\n\nIf the bodies in question have spatial extent (as opposed to being point masses), then the gravitational force between them is calculated by summing the contributions of the notional point masses that constitute the bodies. In the limit, as the component point masses become \"infinitely small\", this entails integrating the force (in vector form, see below) over the extents of the two bodies.\nIn this way, it can be shown that an object with a spherically symmetric distribution of mass exerts the same gravitational attraction on external bodies as if all the object's mass were concentrated at a point at its center. (This is not generally true for non-spherically-symmetrical bodies.)\nFor points inside a spherically symmetric distribution of matter, Newton's shell theorem can be used to find the gravitational force. The theorem tells us how different parts of the mass distribution affect the gravitational force measured at a point located a distance r0 from the center of the mass distribution:\nThe portion of the mass that is located at radii r < r0 causes the same force at the radius r0 as if all of the mass enclosed within a sphere of radius r0 was concentrated at the center of the mass distribution (as noted above).\nThe portion of the mass that is located at radii r > r0 exerts no net gravitational force at the radius r0 from the center. That is, the individual gravitational forces exerted on a point at radius r0 by the elements of the mass outside the radius r0 cancel each other.As a consequence, for example, within a shell of uniform thickness and density there is no net gravitational acceleration anywhere within the hollow sphere.\n\n\n== Vector form ==\n\nNewton's law of universal gravitation can be written as a vector equation to account for the direction of the gravitational force as well as its magnitude. In this formula, quantities in bold represent vectors.\n\nwhere\n\nF21 is the force applied on object 2 exerted by object 1,\nG is the gravitational constant,\nm1 and m2 are respectively the masses of objects 1 and 2,\n|r21| = |r2 \u2212 r1| is the distance between objects 1 and 2, and\n\n  \n    \n      \n        \n          \n            \n              \n                r\n                ^\n              \n            \n          \n          \n            21\n          \n        \n         \n        \n          \n            \n              \n                =\n              \n              \n                \n                  d\n                  e\n                  f\n                \n              \n            \n          \n        \n         \n        \n          \n            \n              \n                \n                  r\n                \n                \n                  2\n                \n              \n              \u2212\n              \n                \n                  r\n                \n                \n                  1\n                \n              \n            \n            \n              |\n              \n                \n                  r\n                \n                \n                  2\n                \n              \n              \u2212\n              \n                \n                  r\n                \n                \n                  1\n                \n              \n              |\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} _{21}\\ {\\stackrel {\\mathrm {def} }{=}}\\ {\\frac {\\mathbf {r} _{2}-\\mathbf {r} _{1}}{\\vert \\mathbf {r} _{2}-\\mathbf {r} _{1}\\vert }}}\n   is the unit vector from object 1 to object 2.It can be seen that the vector form of the equation is the same as the scalar form given earlier, except that F is now a vector quantity, and the right hand side is multiplied by the appropriate unit vector. Also, it can be seen that F12 = \u2212F21.\n\n\n== Gravity field ==\n\nThe gravitational field is a vector field that describes the gravitational force that would be applied on an object in any given point in space, per unit mass. It is actually equal to the gravitational acceleration at that point.\nIt is a generalisation of the vector form, which becomes particularly useful if more than two objects are involved (such as a rocket between the Earth and the Moon). For two objects (e.g. object 2 is a rocket, object 1 the Earth), we simply write r instead of r12 and m instead of m2 and define the gravitational field g(r) as:\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \u2212\n        G\n        \n          \n            \n              m\n              \n                1\n              \n            \n            \n              \n                \n                  |\n                  \n                    r\n                  \n                  |\n                \n                \n                  2\n                \n              \n            \n          \n        \n        \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )=-G{m_{1} \\over {{\\vert \\mathbf {r} \\vert }^{2}}}\\,\\mathbf {\\hat {r}} }\n  so that we can write:\n\n  \n    \n      \n        \n          F\n        \n        (\n        \n          r\n        \n        )\n        =\n        m\n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {r} )=m\\mathbf {g} (\\mathbf {r} ).}\n  This formulation is dependent on the objects causing the field. The field has units of acceleration; in SI, this is m/s2.\nGravitational fields are also conservative; that is, the work done by gravity from one position to another is path-independent. This has the consequence that there exists a gravitational potential field V(r) such that\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \u2212\n        \u2207\n        V\n        (\n        \n          r\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )=-\\nabla V(\\mathbf {r} ).}\n  If m1 is a point mass or the mass of a sphere with homogeneous mass distribution, the force field g(r) outside the sphere is isotropic, i.e., depends only on the distance r from the center of the sphere. In that case\n\n  \n    \n      \n        V\n        (\n        r\n        )\n        =\n        \u2212\n        G\n        \n          \n            \n              m\n              \n                1\n              \n            \n            r\n          \n        \n        .\n      \n    \n    {\\displaystyle V(r)=-G{\\frac {m_{1}}{r}}.}\n  the gravitational field is on, inside and outside of symmetric masses.\nAs per Gauss's law, field in a symmetric body can be found by the mathematical equation:\n\n \n  \n    \n      \n        \u2202\n        V\n      \n    \n    {\\displaystyle \\partial V}\n   \n  \n    \n      \n        \n          g\n          (\n          r\n          )\n        \n        \u22c5\n        d\n        \n          A\n        \n        =\n        \u2212\n        4\n        \u03c0\n        G\n        \n          M\n          \n            enc\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {g(r)} \\cdot d\\mathbf {A} =-4\\pi GM_{\\text{enc}},}\n  where \n  \n    \n      \n        \u2202\n        V\n      \n    \n    {\\displaystyle \\partial V}\n   is a closed surface and \n  \n    \n      \n        \n          M\n          \n            enc\n          \n        \n      \n    \n    {\\displaystyle M_{\\text{enc}}}\n   is the mass enclosed by the surface.\nHence, for a hollow sphere of radius \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   and total mass \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  ,\n\n  \n    \n      \n        \n          |\n        \n        \n          g\n          (\n          r\n          )\n        \n        \n          |\n        \n        =\n        \n          \n            {\n            \n              \n                \n                  0\n                  ,\n                \n                \n                  \n                    if \n                  \n                  r\n                  <\n                  R\n                \n              \n              \n                \n              \n              \n                \n                  \n                    \n                      \n                        \n                          G\n                          M\n                        \n                        \n                          r\n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                  ,\n                \n                \n                  \n                    if \n                  \n                  r\n                  \u2265\n                  R\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle |\\mathbf {g(r)} |={\\begin{cases}0,&{\\text{if }}r<R\\\\\\\\{\\dfrac {GM}{r^{2}}},&{\\text{if }}r\\geq R\\end{cases}}}\n  For a uniform solid sphere of radius \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   and total mass \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  ,\n\n  \n    \n      \n        \n          |\n        \n        \n          g\n          (\n          r\n          )\n        \n        \n          |\n        \n        =\n        \n          \n            {\n            \n              \n                \n                  \n                    \n                      \n                        \n                          G\n                          M\n                          r\n                        \n                        \n                          R\n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                  ,\n                \n                \n                  \n                    if \n                  \n                  r\n                  <\n                  R\n                \n              \n              \n                \n              \n              \n                \n                  \n                    \n                      \n                        \n                          G\n                          M\n                        \n                        \n                          r\n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                  ,\n                \n                \n                  \n                    if \n                  \n                  r\n                  \u2265\n                  R\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle |\\mathbf {g(r)} |={\\begin{cases}{\\dfrac {GMr}{R^{3}}},&{\\text{if }}r<R\\\\\\\\{\\dfrac {GM}{r^{2}}},&{\\text{if }}r\\geq R\\end{cases}}}\n  \n\n\n== Limitations ==\nNewton's description of gravity is sufficiently accurate for many practical purposes and is therefore widely used. Deviations from it are small when the dimensionless quantities \n  \n    \n      \n        \u03d5\n        \n          /\n        \n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\phi /c^{2}}\n   and \n  \n    \n      \n        (\n        v\n        \n          /\n        \n        c\n        \n          )\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (v/c)^{2}}\n   are both much less than one, where \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   is the gravitational potential, \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the velocity of the objects being studied, and \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the speed of light in vacuum.\nFor example, Newtonian gravity provides an accurate description of the Earth/Sun system, since\n\n  \n    \n      \n        \n          \n            \u03d5\n            \n              c\n              \n                2\n              \n            \n          \n        \n        =\n        \n          \n            \n              G\n              \n                M\n                \n                  \n                    s\n                    u\n                    n\n                  \n                \n              \n            \n            \n              \n                r\n                \n                  \n                    o\n                    r\n                    b\n                    i\n                    t\n                  \n                \n              \n              \n                c\n                \n                  2\n                \n              \n            \n          \n        \n        \u223c\n        \n          10\n          \n            \u2212\n            8\n          \n        \n        ,\n        \n        \n          \n            (\n            \n              \n                \n                  v\n                  \n                    \n                      E\n                      a\n                      r\n                      t\n                      h\n                    \n                  \n                \n                c\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  2\n                  \u03c0\n                  \n                    r\n                    \n                      \n                        o\n                        r\n                        b\n                        i\n                        t\n                      \n                    \n                  \n                \n                \n                  (\n                  1\n                   \n                  \n                    y\n                    r\n                  \n                  )\n                  c\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        \u223c\n        \n          10\n          \n            \u2212\n            8\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\phi }{c^{2}}}={\\frac {GM_{\\mathrm {sun} }}{r_{\\mathrm {orbit} }c^{2}}}\\sim 10^{-8},\\quad \\left({\\frac {v_{\\mathrm {Earth} }}{c}}\\right)^{2}=\\left({\\frac {2\\pi r_{\\mathrm {orbit} }}{(1\\ \\mathrm {yr} )c}}\\right)^{2}\\sim 10^{-8}}\n  where \n  \n    \n      \n        \n          r\n          \n            orbit\n          \n        \n      \n    \n    {\\displaystyle r_{\\text{orbit}}}\n   is the radius of the Earth's orbit around the Sun.\nIn situations where either dimensionless parameter is large, then\ngeneral relativity must be used to describe the system. General relativity reduces to Newtonian gravity in the limit of small potential and low velocities, so Newton's law of gravitation is often said to be the low-gravity limit of general relativity.\n\n\n=== Observations conflicting with Newton's formula ===\nNewton's theory does not fully explain the precession of the perihelion of the orbits of the planets, especially that of Mercury, which was detected long after the life of Newton. There is a 43 arcsecond per century discrepancy between the Newtonian calculation, which arises only from the gravitational attractions from the other planets, and the observed precession, made with advanced telescopes during the 19th century.\nThe predicted angular deflection of light rays by gravity (treated as particles travelling at the expected speed) that is calculated by using Newton's theory is only one-half of the deflection that is observed by astronomers. Calculations using general relativity are in much closer agreement with the astronomical observations.\nIn spiral galaxies, the orbiting of stars around their centers seems to strongly disobey both Newton's law of universal gravitation and general relativity. Astrophysicists, however, explain this marked phenomenon by assuming the presence of large amounts of dark matter.\n\n\n=== Einstein's solution ===\nThe first two conflicts with observations above were explained by Einstein's theory of general relativity, in which gravitation is a manifestation of curved spacetime instead of being due to a force propagated between bodies. In Einstein's theory, energy and momentum distort spacetime in their vicinity, and other particles move in trajectories determined by the geometry of spacetime. This allowed a description of the motions of light and mass that was consistent with all available observations. In general relativity, the gravitational force is a fictitious force resulting from the curvature of spacetime, because the gravitational acceleration of a body in free fall is due to its world line being a geodesic of spacetime.\n\n\n== Extensions ==\nIn recent years, quests for non-inverse square terms in the law of gravity have been carried out by neutron interferometry.\n\n\n== Solutions of Newton's law of universal gravitation ==\n\nThe n-body problem is an ancient, classical problem of predicting the individual motions of a group of celestial objects interacting with each other gravitationally. Solving this problem \u2014 from the time of the Greeks and on \u2014 has been motivated by the desire to understand the motions of the Sun, planets and the visible stars. In the 20th century, understanding the dynamics of globular cluster star systems became an important n-body problem too. The n-body problem in general relativity is considerably more difficult to solve.\nThe classical physical problem can be informally stated as: given the quasi-steady orbital properties (instantaneous position, velocity and time) of a group of celestial bodies, predict their interactive forces; and consequently, predict their true orbital motions for all future times.The two-body problem has been completely solved, as has the restricted three-body problem.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n Media related to Newton's law of universal gravitation at Wikimedia Commons\nFeather and Hammer Drop on Moon on YouTube\nNewton\u2018s Law of Universal Gravitation Javascript calculator", "Position_(vector)": "In geometry, a position or position vector, also known as location vector or radius vector, is a Euclidean vector that represents the position of a point P in space in relation to an arbitrary reference origin O. Usually denoted x, r, or s, it corresponds to the straight line segment from O to P.\nIn other words, it is the displacement or translation that maps the origin to P:\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          \n            \n              O\n              P\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} ={\\overrightarrow {OP}}}\n  The term position vector is used mostly in the fields of differential geometry, mechanics and occasionally vector calculus.\nFrequently this is used in two-dimensional or three-dimensional space, but can be easily generalized to Euclidean spaces and affine spaces of any dimension.\n\n\n== Relative position ==\n\nThe relative position of a point Q with respect to point P is the Euclidean vector resulting from the subtraction of the two absolute position vectors (each with respect to the origin):\n\n  \n    \n      \n        \u0394\n        \n          r\n        \n        =\n        \n          s\n        \n        \u2212\n        \n          r\n        \n        =\n        \n          \n            \n              P\n              Q\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle \\Delta \\mathbf {r} =\\mathbf {s} -\\mathbf {r} ={\\overrightarrow {PQ}}}\n  where \n  \n    \n      \n        \n          s\n        \n        =\n        \n          \n            \n              O\n              Q\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {s} ={\\overrightarrow {OQ}}}\n  .\nThe relative direction between two points is their relative position normalized as a unit vector:\n\n  \n    \n      \n        \u0394\n        \n          \n            \n              r\n              ^\n            \n          \n        \n        =\n        \u0394\n        \n          r\n        \n        \n          /\n        \n        \u2016\n        \u0394\n        \n          r\n        \n        \u2016\n      \n    \n    {\\displaystyle \\Delta \\mathbf {\\hat {r}} =\\Delta \\mathbf {r} /\\|\\Delta \\mathbf {r} \\|}\n  where the denominator is the distance between the two points, \n  \n    \n      \n        \u2016\n        \u0394\n        \n          r\n        \n        \u2016\n      \n    \n    {\\displaystyle \\|\\Delta \\mathbf {r} \\|}\n  .\n\n\n== Definition ==\n\n\n=== Three dimensions ===\n\nIn three dimensions, any set of three-dimensional coordinates and their corresponding basis vectors can be used to define the location of a point in space\u2014whichever is the simplest for the task at hand may be used.\nCommonly, one uses the familiar Cartesian coordinate system, or sometimes spherical polar coordinates, or cylindrical coordinates:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                (\n                t\n                )\n              \n              \n                \n                \u2261\n                \n                  r\n                \n                (\n                x\n                ,\n                y\n                ,\n                z\n                )\n                \u2261\n                x\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    x\n                  \n                \n                +\n                y\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    y\n                  \n                \n                +\n                z\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    z\n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2261\n                \n                  r\n                \n                (\n                r\n                ,\n                \u03b8\n                ,\n                \u03d5\n                )\n                \u2261\n                r\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    r\n                  \n                \n                \n                  \n                    (\n                  \n                \n                \u03b8\n                (\n                t\n                )\n                ,\n                \u03d5\n                (\n                t\n                )\n                \n                  \n                    )\n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2261\n                \n                  r\n                \n                (\n                r\n                ,\n                \u03d5\n                ,\n                z\n                )\n                \u2261\n                r\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    r\n                  \n                \n                \n                  \n                    (\n                  \n                \n                \u03d5\n                (\n                t\n                )\n                \n                  \n                    )\n                  \n                \n                +\n                z\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    z\n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {r} (t)&\\equiv \\mathbf {r} (x,y,z)\\equiv x(t)\\mathbf {\\hat {e}} _{x}+y(t)\\mathbf {\\hat {e}} _{y}+z(t)\\mathbf {\\hat {e}} _{z}\\\\&\\equiv \\mathbf {r} (r,\\theta ,\\phi )\\equiv r(t)\\mathbf {\\hat {e}} _{r}{\\big (}\\theta (t),\\phi (t){\\big )}\\\\&\\equiv \\mathbf {r} (r,\\phi ,z)\\equiv r(t)\\mathbf {\\hat {e}} _{r}{\\big (}\\phi (t){\\big )}+z(t)\\mathbf {\\hat {e}} _{z},\\\\\\end{aligned}}}\n  where t is a parameter, owing to their rectangular or circular symmetry. These different coordinates and corresponding basis vectors represent the same position vector. More general curvilinear coordinates could be used instead and are in contexts like continuum mechanics and general relativity (in the latter case one needs an additional time coordinate).\n\n\n=== n dimensions ===\nLinear algebra allows for the abstraction of an n-dimensional position vector. A position vector can be expressed as a linear combination of basis vectors:\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          x\n          \n            i\n          \n        \n        \n          \n            e\n          \n          \n            i\n          \n        \n        =\n        \n          x\n          \n            1\n          \n        \n        \n          \n            e\n          \n          \n            1\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          \n            e\n          \n          \n            2\n          \n        \n        +\n        \u22ef\n        +\n        \n          x\n          \n            n\n          \n        \n        \n          \n            e\n          \n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {r} =\\sum _{i=1}^{n}x_{i}\\mathbf {e} _{i}=x_{1}\\mathbf {e} _{1}+x_{2}\\mathbf {e} _{2}+\\dotsb +x_{n}\\mathbf {e} _{n}.}\n  The set of all position vectors forms position space (a vector space whose elements are the position vectors), since positions can be added (vector addition) and scaled in length (scalar multiplication) to obtain another position vector in the space. The notion of \"space\" is intuitive, since each xi (i = 1, 2, \u2026, n) can have any value, the collection of values defines a point in space.\nThe dimension of the position space is n (also denoted dim(R) = n). The coordinates of the vector r with respect to the basis vectors ei are xi. The vector of coordinates forms the coordinate vector or n-tuple (x1, x2, \u2026, xn).\nEach coordinate xi may be parameterized a number of parameters t. One parameter xi(t) would describe a curved 1D path, two parameters xi(t1, t2) describes a curved 2D surface, three xi(t1, t2, t3) describes a curved 3D volume of space, and so on.\nThe linear span of a basis set B = {e1, e2,  \u2026, en} equals the position space R, denoted span(B) = R.\n\n\n== Applications ==\n\n\n=== Differential geometry ===\n\nPosition vector fields are used to describe continuous and differentiable space curves, in which case the independent parameter needs not be time, but can be (e.g.) arc length of the curve.\n\n\n=== Mechanics ===\n\nIn any equation of motion, the position vector r(t) is usually the most sought-after quantity because this function defines the motion of a particle (i.e. a point mass) \u2013 its location relative to a given coordinate system at some time t.\nTo define motion in terms of position, each coordinate may be parametrized by time; since each successive value of time corresponds to a sequence of successive spatial locations given by the coordinates, the continuum limit of many successive locations is a path the particle traces.\nIn the case of one dimension, the position has only one component, so it effectively degenerates to a scalar coordinate. It could be, say, a vector in the x direction, or the radial r direction. Equivalent notations include\n\n  \n    \n      \n        \n          x\n        \n        \u2261\n        x\n        \u2261\n        x\n        (\n        t\n        )\n        ,\n        \n        r\n        \u2261\n        r\n        (\n        t\n        )\n        ,\n        \n        s\n        \u2261\n        s\n        (\n        t\n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {x} \\equiv x\\equiv x(t),\\quad r\\equiv r(t),\\quad s\\equiv s(t).}\n  \n\n\n== Derivatives of position ==\n\nFor a position vector r that is a function of time t, the time derivatives can be computed with respect to t. These derivatives have common utility in the study of kinematics, control theory, engineering and other sciences.\n\nVelocity\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} ={\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}},}\n  \nwhere dr is an infinitesimally small displacement (vector).\nAcceleration\n\n  \n    \n      \n        \n          a\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                v\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n                \n                  2\n                \n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {a} ={\\frac {\\mathrm {d} \\mathbf {v} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} ^{2}\\mathbf {r} }{\\mathrm {d} t^{2}}}.}\n  \nJerk\n\n  \n    \n      \n        \n          j\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                a\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n                \n                  2\n                \n              \n              \n                v\n              \n            \n            \n              \n                d\n              \n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n                \n                  3\n                \n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              \n                t\n                \n                  3\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {j} ={\\frac {\\mathrm {d} \\mathbf {a} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} ^{2}\\mathbf {v} }{\\mathrm {d} t^{2}}}={\\frac {\\mathrm {d} ^{3}\\mathbf {r} }{\\mathrm {d} t^{3}}}.}\n  These names for the first, second and third derivative of position are commonly used in basic kinematics. By extension, the higher-order derivatives can be computed in a similar fashion. Study of these higher-order derivatives can improve approximations of the original displacement function. Such higher-order terms are required in order to accurately represent the displacement function as a sum of an infinite sequence, enabling several analytical techniques in engineering and physics.\n\n\n== See also ==\nAffine space\nCoordinate system\nHorizontal position\nLine element\nParametric surface\nPosition fixing\nSix degrees of freedom\nVertical position\n\n\n== Notes ==\n\n\n== References ==\nKeller, F. J, Gettys, W. E. et al. (1993). \"Physics: Classical and modern\" 2nd ed. McGraw Hill Publishing.\n\n\n== External links ==\n Media related to Position (geometry) at Wikimedia Commons", "Electromotive_force": "In electromagnetism and electronics, electromotive force (also electromotance, abbreviated emf, denoted \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   or \n  \n    \n      \n        \n          \u03be\n        \n      \n    \n    {\\displaystyle {\\xi }}\n  ) is an energy transfer to an electric circuit per unit of electric charge, measured in volts. Devices called electrical transducers provide an emf by converting other forms of energy into electrical energy. Other electrical equipment also produce an emf, such as batteries, which convert chemical energy, and generators, which convert mechanical energy. This energy conversion is achieved by physical forces applying physical work on electric charges. However, electromotive force itself is not a physical force, and ISO/IEC standards have deprecated the term in favor of source voltage or source tension instead (denoted \n  \n    \n      \n        \n          U\n          \n            s\n          \n        \n      \n    \n    {\\displaystyle U_{s}}\n  ).An electronic\u2013hydraulic analogy may view emf as the mechanical work done to water by a pump, which results in a pressure difference (analogous to voltage).In electromagnetic induction, emf can be defined around a closed loop of a conductor as the electromagnetic work that would be done on an elementary electric charge (such as an electron) if it travels once around the loop.For two-terminal devices modeled as a Th\u00e9venin equivalent circuit, an equivalent emf can be measured as the open-circuit voltage between the two terminals. This emf can drive an electric current if an external circuit is attached to the terminals, in which case the device becomes the voltage source of that circuit.\nAlthough an emf gives rise to a voltage and can be measured as a voltage and may sometimes informally be called a \"voltage\", they are not the same phenomenon (see \u00a7 Distinction with potential difference).\n\n\n== Overview ==\nDevices that can provide emf include electrochemical cells, thermoelectric devices, solar cells, photodiodes, electrical generators, inductors, transformers and even Van de Graaff generators. In nature, emf is generated when magnetic field fluctuations occur through a surface. For example, the shifting of the Earth's magnetic field during a geomagnetic storm induces currents in an electrical grid as the lines of the magnetic field are shifted about and cut across the conductors.\nIn a battery, the charge separation that gives rise to a potential difference (voltage) between the terminals is accomplished by chemical reactions at the electrodes that convert chemical potential energy into electromagnetic potential energy. A voltaic cell can be thought of as having a \"charge pump\" of atomic dimensions at each electrode, that is:\n\nA (chemical) source of emf can be thought of as a kind of charge pump that acts to move positive charges from a point of low potential through its interior to a point of high potential. \u2026 By chemical, mechanical or other means, the source of emf performs work \n  \n    \n      \n        \n          \n            d\n          \n        \n        W\n      \n    \n    {\\textstyle {\\mathit {d}}W}\n   on that charge to move it to the high-potential terminal. The emf \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\textstyle {\\mathcal {E}}}\n   of the source is defined as the work \n  \n    \n      \n        \n          \n            d\n          \n        \n        W\n      \n    \n    {\\textstyle {\\mathit {d}}W}\n   done per charge \n  \n    \n      \n        d\n        q\n      \n    \n    {\\textstyle dq}\n  . \n  \n    \n      \n        \n          \n            E\n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n              \n              W\n            \n            \n              \n                \n                  d\n                \n              \n              q\n            \n          \n        \n      \n    \n    {\\textstyle {\\mathcal {E}}={\\frac {{\\mathit {d}}W}{{\\mathit {d}}q}}}\n  .\nIn an electrical generator, a time-varying magnetic field inside the generator creates an electric field via electromagnetic induction, which creates a potential difference between the generator terminals. Charge separation takes place within the generator because electrons flow away from one terminal toward the other, until, in the open-circuit case, an electric field is developed that makes further charge separation impossible. The emf is countered by the electrical voltage due to charge separation. If a load is attached, this voltage can drive a current. The general principle governing the emf in such electrical machines is Faraday's law of induction.\n\n\n== History ==\nIn 1801, Alessandro Volta introduced the term \"force motrice \u00e9lectrique\" to describe the active agent of a battery (which he had invented around 1798).\nThis is called the \"electromotive force\" in English.\nAround 1830, Michael Faraday established that chemical reactions at each of two electrode\u2013electrolyte interfaces provide the \"seat of emf\" for the voltaic cell. That is, these reactions drive the current and are not an endless source of energy as the earlier obsolete theory thought. In the open-circuit case, charge separation continues until the electrical field from the separated charges is sufficient to arrest the reactions. Years earlier, Alessandro Volta, who had measured a contact potential difference at the metal\u2013metal (electrode\u2013electrode) interface of his cells, held the incorrect opinion that contact alone (without taking into account a chemical reaction) was the origin of the emf.\n\n\n== Notation and units of measurement ==\nElectromotive force is often denoted by \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   or \u2130.\nIn a device without internal resistance, if an electric charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   passing through that device gains an energy \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n   via work, the net emf for that device is the energy gained per unit charge: \n  \n    \n      \n        \n          \n            \n              W\n              Q\n            \n          \n        \n        .\n      \n    \n    {\\textstyle {\\tfrac {W}{Q}}.}\n   Like other measures of energy per charge, emf uses the SI unit volt, which is equivalent to a joule (SI unit of energy) per coulomb (SI unit of charge).Electromotive force in electrostatic units is the statvolt (in the centimeter gram second system of units equal in amount to an erg per electrostatic unit of charge).\n\n\n== Formal definitions ==\nInside a source of emf (such as a battery) that is open-circuited, a charge separation occurs between the negative terminal N and the positive terminal P.\nThis leads to an electrostatic field \n  \n    \n      \n        \n          \n            E\n          \n          \n            \n              o\n              p\n              e\n              n\n               \n              c\n              i\n              r\n              c\n              u\n              i\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}_{\\mathrm {open\\ circuit} }}\n   that points from P to N, whereas the emf of the source must be able to drive current from N to P when connected to a circuit.\nThis led Max Abraham to introduce the concept of a nonelectrostatic field \n  \n    \n      \n        \n          \n            E\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}'}\n   that exists only inside the source of emf.\nIn the open-circuit case, \n  \n    \n      \n        \n          \n            E\n          \n          \u2032\n        \n        =\n        \u2212\n        \n          \n            E\n          \n          \n            \n              o\n              p\n              e\n              n\n               \n              c\n              i\n              r\n              c\n              u\n              i\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}'=-{\\boldsymbol {E}}_{\\mathrm {open\\ circuit} }}\n  , while when the source is connected to a circuit the electric field \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}}\n   inside the source changes but \n  \n    \n      \n        \n          \n            E\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}'}\n   remains essentially the same.\nIn the open-circuit case, the conservative electrostatic field created by separation of charge exactly cancels the forces producing the emf. \nMathematically:\n\nwhere \n  \n    \n      \n        \n          \n            E\n          \n          \n            \n              o\n              p\n              e\n              n\n               \n              c\n              i\n              r\n              c\n              u\n              i\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}_{\\mathrm {open\\ circuit} }}\n   is the conservative electrostatic field created by the charge separation associated with the emf, \n  \n    \n      \n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\boldsymbol {\\ell }}}\n   is an element of the path from terminal N to terminal P, '\n  \n    \n      \n        \u22c5\n      \n    \n    {\\displaystyle \\cdot }\n  ' denotes the vector dot product, and \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the electric scalar potential. \nThis emf is the work done on a unit charge by the source's nonelectrostatic field \n  \n    \n      \n        \n          \n            E\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}'}\n   when the charge moves from N to P.\nWhen the source is connected to a load, its emf is just\n\n  \n    \n      \n        \n          \n            \n              E\n            \n          \n          \n            \n              s\n              o\n              u\n              r\n              c\n              e\n            \n          \n        \n        =\n        \n          \u222b\n          \n            N\n          \n          \n            P\n          \n        \n        \n          \n            E\n          \n          \u2032\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n         \n        ,\n      \n    \n    {\\displaystyle {\\mathcal {E}}_{\\mathrm {source} }=\\int _{N}^{P}{\\boldsymbol {E}}'\\cdot \\mathrm {d} {\\boldsymbol {\\ell }}\\ ,}\n  \nand no longer has a simple relation to the electric field \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}}\n   inside it.\nIn the case of a closed path in the presence of a varying magnetic field, the integral of the electric field around the (stationary) closed loop \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   may be nonzero.\nThen, the \"induced emf\" (often called the \"induced voltage\") in the loop is:\nwhere \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}}\n   is the entire electric field, conservative and non-conservative, and the integral is around an arbitrary, but stationary, closed curve \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   through which there is a time-varying magnetic flux \n  \n    \n      \n        \n          \u03a6\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle \\Phi _{C}}\n  , and \n  \n    \n      \n        \n          A\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {A}}}\n   is the vector potential.\nThe electrostatic field does not contribute to the net emf around a circuit because the electrostatic portion of the electric field is conservative (i.e., the work done against the field around a closed path is zero, see Kirchhoff's voltage law, which is valid, as long as the circuit elements remain at rest and radiation is ignored).\nThat is, the \"induced emf\" (like the emf of a battery connected to a load) is not a \"voltage\" in the sense of a difference in the electric scalar potential.\nIf the loop \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   is a conductor that carries current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   in the direction of integration around the loop, and the magnetic flux is due to that current, we have that \n  \n    \n      \n        \n          \u03a6\n          \n            B\n          \n        \n        =\n        L\n        I\n      \n    \n    {\\displaystyle \\Phi _{B}=LI}\n  , where \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   is the self inductance of the loop.\nIf in addition, the loop includes a coil that extends from point 1 to 2, such that the magnetic flux is largely localized to that region, it is customary to speak of that region as an inductor, and to consider that its emf is localized to that region.\nThen, we can consider a different loop \n  \n    \n      \n        \n          C\n          \u2032\n        \n      \n    \n    {\\displaystyle C'}\n   that consists of the coiled conductor from 1 to 2, and an imaginary line down the center of the coil from 2 back to 1.  \nThe magnetic flux, and emf, in loop \n  \n    \n      \n        \n          C\n          \u2032\n        \n      \n    \n    {\\displaystyle C'}\n   is essentially the same as that in loop \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  :\n\nFor a good conductor, \n  \n    \n      \n        \n          \n            E\n          \n          \n            \n              c\n              o\n              n\n              d\n              u\n              c\n              t\n              o\n              r\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}_{\\mathrm {conductor} }}\n   is negligible, so we have, to a good approximation,\n\nwhere \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the electric scalar potential along the centerline between points 1 and 2.\nThus, we can associate an effective \"voltage drop\" \n  \n    \n      \n        L\n         \n        d\n        I\n        \n          /\n        \n        d\n        t\n      \n    \n    {\\displaystyle L\\ dI/dt}\n   with an inductor (even though our basic understanding of induced emf is based on the vector potential rather than the scalar potential), and consider it as a load element in Kirchhoff's voltage law,\n\nwhere now the induced emf is not considered to be a source emf.This definition can be extended to arbitrary sources of emf and paths \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   moving with velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {v}}}\n   through the electric field \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {E}}}\n   and magnetic field \n  \n    \n      \n        \n          B\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {B}}}\n  :\nwhich is a conceptual equation mainly, because the determination of the \"effective forces\" is difficult.\nThe term \n  \n    \n      \n        \n          \u222e\n          \n            C\n          \n        \n        \n          [\n          \n            \n              E\n            \n            +\n            \n              v\n            \n            \u00d7\n            \n              B\n            \n          \n          ]\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle \\oint _{C}\\left[{\\boldsymbol {E}}+{\\boldsymbol {v}}\\times {\\boldsymbol {B}}\\right]\\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n  \nis often called a \"motional emf\".\n\n\n== In (electrochemical) thermodynamics ==\nWhen multiplied by an amount of charge \n  \n    \n      \n        d\n        Q\n      \n    \n    {\\displaystyle dQ}\n   the emf \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   yields a thermodynamic work term \n  \n    \n      \n        \n          \n            E\n          \n        \n        \n        d\n        Q\n      \n    \n    {\\displaystyle {\\mathcal {E}}\\,dQ}\n   that is used in the formalism for the change in Gibbs energy when charge is passed in a battery:\n\n  \n    \n      \n        d\n        G\n        =\n        \u2212\n        S\n        \n        d\n        T\n        +\n        V\n        \n        d\n        P\n        +\n        \n          \n            E\n          \n        \n        \n        d\n        Q\n         \n        ,\n      \n    \n    {\\displaystyle dG=-S\\,dT+V\\,dP+{\\mathcal {E}}\\,dQ\\ ,}\n  where \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is the Gibbs free energy, \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   is the entropy, \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the system volume, \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   is its pressure and \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   is its absolute temperature.\nThe combination \n  \n    \n      \n        (\n        \n          \n            E\n          \n        \n        ,\n        Q\n        )\n      \n    \n    {\\displaystyle ({\\mathcal {E}},Q)}\n   is an example of a conjugate pair of variables. At constant pressure the above relationship produces a Maxwell relation that links the change in open cell voltage with temperature \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   (a measurable quantity) to the change in entropy \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   when charge is passed isothermally and isobarically. The latter is closely related to the reaction entropy of the electrochemical reaction that lends the battery its power. This Maxwell relation is:\n\n  \n    \n      \n        \n          \n            (\n            \n              \n                \n                  \u2202\n                  \n                    \n                      E\n                    \n                  \n                \n                \n                  \u2202\n                  T\n                \n              \n            \n            )\n          \n          \n            Q\n          \n        \n        =\n        \u2212\n        \n          \n            (\n            \n              \n                \n                  \u2202\n                  S\n                \n                \n                  \u2202\n                  Q\n                \n              \n            \n            )\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\left({\\frac {\\partial {\\mathcal {E}}}{\\partial T}}\\right)_{Q}=-\\left({\\frac {\\partial S}{\\partial Q}}\\right)_{T}}\n  If a mole of ions goes into solution (for example, in a Daniell cell, as discussed below) the charge through the external circuit is:\n\n  \n    \n      \n        \u0394\n        Q\n        =\n        \u2212\n        \n          n\n          \n            0\n          \n        \n        \n          F\n          \n            0\n          \n        \n         \n        ,\n      \n    \n    {\\displaystyle \\Delta Q=-n_{0}F_{0}\\ ,}\n  where \n  \n    \n      \n        \n          n\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle n_{0}}\n   is the number of electrons/ion, and \n  \n    \n      \n        \n          F\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle F_{0}}\n   is the Faraday constant and the minus sign indicates discharge of the cell. Assuming constant pressure and volume, the thermodynamic properties of the cell are related strictly to the behavior of its emf by:\n\n  \n    \n      \n        \u0394\n        H\n        =\n        \u2212\n        \n          n\n          \n            0\n          \n        \n        \n          F\n          \n            0\n          \n        \n        \n          (\n          \n            \n              \n                E\n              \n            \n            \u2212\n            T\n            \n              \n                \n                  d\n                  \n                    \n                      E\n                    \n                  \n                \n                \n                  d\n                  T\n                \n              \n            \n          \n          )\n        \n         \n        ,\n      \n    \n    {\\displaystyle \\Delta H=-n_{0}F_{0}\\left({\\mathcal {E}}-T{\\frac {d{\\mathcal {E}}}{dT}}\\right)\\ ,}\n  where \n  \n    \n      \n        \u0394\n        H\n      \n    \n    {\\displaystyle \\Delta H}\n   is the enthalpy of reaction. The quantities on the right are all directly measurable. Assuming constant temperature and pressure:\n\n  \n    \n      \n        \u0394\n        G\n        =\n        \u2212\n        \n          n\n          \n            0\n          \n        \n        \n          F\n          \n            0\n          \n        \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle \\Delta G=-n_{0}F_{0}{\\mathcal {E}}}\n  which is used in the derivation of the Nernst equation.\n\n\n== Distinction with potential difference ==\nAlthough an electrical potential difference (voltage) is sometimes called an emf, however they are formally distinct concepts:\n\nEmf is the cause of a potential difference. Potential difference in turn is a cause of current flow.\nPotential difference itself is not the cause of an emf.\nConsider Kirchhoff's voltage law, which says the sum of potential differences going through any loop in a circuit is zero. For a circuit of a voltage source and a resistor, the sum of the source's applied voltage plus the ohmic voltage drop through the resistor is zero. But the resistor provides no emf, only the voltage source does:\nFor a circuit using a battery source, the emf is due solely to the chemistry in the battery that causes charge separation, which generates a potential difference.\nFor a circuit using an electric generator, the emf is due solely to a time-varying magnetic field within the generator that causes charge separation, which generates a potential difference.\nBoth a 1 volt emf and a 1 volt potential difference correspond to 1 joule per coulomb of charge. However:\na 1 volt emf means that the source supplies an energy of 1 joule to each coulomb of charge passing through.\na 1 volt potential difference between two points on a circuit means that each coulomb of charge will need to either:\ngain 1 joule of energy to move up that potential difference,\nor give up 1 joule of energy to move down that potential difference.In the case of an open circuit, the electric charge that has been separated by the mechanism generating the emf creates an electric field opposing the separation mechanism. For example, the chemical reaction in a voltaic cell stops when the opposing electric field at each electrode is strong enough to arrest the reactions. A larger opposing field can reverse the reactions in what are called reversible cells.The electric charge that has been separated creates an electric potential difference that can (in many cases) be measured with a voltmeter between the terminals of the device, when not connected to a load. The magnitude of the emf for the battery (or other source) is the value of this open-circuit voltage. \nWhen the battery is charging or discharging, the emf itself cannot be measured directly using the external voltage because some voltage is lost inside the source.\nIt can, however, be inferred from a measurement of the current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   and potential difference \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  , provided that the internal resistance \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   already has been measured: \n  \n    \n      \n        \n          \n            E\n          \n        \n        =\n        V\n        +\n        I\n        R\n         \n        .\n      \n    \n    {\\displaystyle {\\mathcal {E}}=V+IR\\ .}\n  \n\"Potential difference\" is not the same as \"induced emf\" (often called \"induced voltage\"). \nThe potential difference (difference in the electric scalar potential) between two points A and B is independent of the path we take from A to B.  \nIf a voltmeter always measured the potential difference between A and B, then the position of the voltmeter would make no difference. \nHowever, it is quite possible for the measurement by a voltmeter between points A and B to depend on the position of the voltmeter, if a time-dependent magnetic field is present. \nFor example, consider an infinitely long solenoid using an AC current to generate a varying flux in the interior of the solenoid. \nOutside the solenoid we have two resistors connected in a ring around the solenoid. \nThe resistor on the left is 100 \u03a9 and the one on the right is 200 \u03a9, they are connected at the top and bottom at points A and B. \nThe induced voltage, by Faraday's law is \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  , so the current \n  \n    \n      \n        I\n        =\n        V\n        \n          /\n        \n        (\n        100\n        +\n        200\n        )\n        .\n      \n    \n    {\\displaystyle I=V/(100+200).}\n   Therefore the voltage across the 100 \u03a9 resistor is \n  \n    \n      \n        100\n         \n        I\n      \n    \n    {\\displaystyle 100\\ I}\n   and the voltage across the 200 \u03a9 resistor is \n  \n    \n      \n        200\n         \n        I\n      \n    \n    {\\displaystyle 200\\ I}\n  , yet the two resistors are connected on both ends, but \n  \n    \n      \n        \n          V\n          \n            A\n            B\n          \n        \n      \n    \n    {\\displaystyle V_{AB}}\n   measured with the voltmeter to the left of the solenoid is not the same as \n  \n    \n      \n        \n          V\n          \n            A\n            B\n          \n        \n      \n    \n    {\\displaystyle V_{AB}}\n   measured with the voltmeter to the right of the solenoid.\n\n\n== Generation ==\n\n\n=== Chemical sources ===\n\nThe question of how batteries (galvanic cells) generate an emf occupied scientists for most of the 19th century. The \"seat of the electromotive force\" was eventually determined in 1889 by Walther Nernst to be primarily at the interfaces between the electrodes and the electrolyte.Atoms in molecules or solids are held together by chemical bonding, which stabilizes the molecule or solid (i.e. reduces its energy). When molecules or solids of relatively high energy are brought together, a spontaneous chemical reaction can occur that rearranges the bonding and reduces the (free) energy of the system. In batteries, coupled half-reactions, often involving metals and their ions, occur in tandem, with a gain of electrons (termed \"reduction\") by one conductive electrode and loss of electrons (termed \"oxidation\") by another (reduction-oxidation or redox reactions). The spontaneous overall reaction can only occur if electrons move through an external wire between the electrodes. The electrical energy given off is the free energy lost by the chemical reaction system.\nAs an example, a Daniell cell consists of a zinc anode (an electron collector) that is oxidized as it dissolves into a zinc sulfate solution. The dissolving zinc leaving behind its electrons in the electrode according to the oxidation reaction (s = solid electrode; aq = aqueous solution):\n\n  \n    \n      \n        \n          Z\n          \n            n\n            \n              (\n              s\n              )\n            \n          \n          \u2192\n          Z\n          \n            n\n            \n              (\n              a\n              q\n              )\n            \n            \n              2\n              +\n            \n          \n          +\n          2\n          \n            e\n            \n              \u2212\n            \n          \n           \n        \n      \n    \n    {\\displaystyle \\mathrm {Zn_{(s)}\\rightarrow Zn_{(aq)}^{2+}+2e^{-}\\ } }\n  The zinc sulfate is the electrolyte in that half cell. It is a solution which contains zinc cations \n  \n    \n      \n        \n          \n            Z\n            n\n          \n          \n            2\n            +\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {Zn} ^{2+}}\n  , and sulfate anions \n  \n    \n      \n        \n          \n            S\n            O\n          \n          \n            4\n          \n          \n            2\n            \u2212\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {SO} _{4}^{2-}}\n   with charges that balance to zero.\nIn the other half cell, the copper cations in a copper sulfate electrolyte move to the copper cathode to which they attach themselves as they adopt electrons from the copper electrode by the reduction reaction:\n\n  \n    \n      \n        \n          C\n          \n            u\n            \n              (\n              a\n              q\n              )\n            \n            \n              2\n              +\n            \n          \n          +\n          2\n          \n            e\n            \n              \u2212\n            \n          \n          \u2192\n          C\n          \n            u\n            \n              (\n              s\n              )\n            \n          \n           \n        \n      \n    \n    {\\displaystyle \\mathrm {Cu_{(aq)}^{2+}+2e^{-}\\rightarrow Cu_{(s)}\\ } }\n  which leaves a deficit of electrons on the copper cathode. The difference of excess electrons on the anode and deficit of electrons on the cathode creates an electrical potential between the two electrodes. (A detailed discussion of the microscopic process of electron transfer between an electrode and the ions in an electrolyte may be found in Conway.) The electrical energy released by this reaction (213 kJ per 65.4 g of zinc) can be attributed mostly due to the 207 kJ weaker bonding (smaller magnitude of the cohesive energy) of zinc, which has filled 3d- and 4s-orbitals, compared to copper, which has an unfilled orbital available for bonding.\nIf the cathode and anode are connected by an external conductor, electrons pass through that external circuit (light bulb in figure), while ions pass through the salt bridge to maintain charge balance until the anode and cathode reach electrical equilibrium of zero volts as chemical equilibrium is reached in the cell. In the process the zinc anode is dissolved while the copper electrode is plated with copper. The salt bridge has to close the electrical circuit while preventing the copper ions from moving to the zinc electrode and being reduced there without generating an external current. It is not made of salt but of material able to wick cations and anions (a dissociated salt) into the solutions. The flow of positively charged cations along the bridge is equivalent to the same number of negative charges flowing in the opposite direction.\nIf the light bulb is removed (open circuit) the emf between the electrodes is opposed by the electric field due to the charge separation, and the reactions stop.\nFor this particular cell chemistry, at 298 K (room temperature), the emf \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   = 1.0934 V, with a temperature coefficient of \n  \n    \n      \n        d\n        \n          \n            E\n          \n        \n        \n          /\n        \n        d\n        T\n      \n    \n    {\\displaystyle d{\\mathcal {E}}/dT}\n   = \u22124.53\u00d710\u22124 V/K.\n\n\n==== Voltaic cells ====\nVolta developed the voltaic cell about 1792, and presented his work March 20, 1800. Volta correctly identified the role of dissimilar electrodes in producing the voltage, but incorrectly dismissed any role for the electrolyte. Volta ordered the metals in a 'tension series', \"that is to say in an order such that any one in the list becomes positive when in contact with any one that succeeds, but negative by contact with any one that precedes it.\" A typical symbolic convention in a schematic of this circuit ( \u2013||\u2013 ) would have a long electrode 1 and a short electrode 2, to indicate that electrode 1 dominates.  Volta's law about opposing electrode emfs implies that, given ten electrodes (for example, zinc and nine other materials), 45 unique combinations of voltaic cells (10 \u00d7 9/2) can be created.\n\n\n==== Typical values ====\nThe electromotive force produced by primary (single-use) and secondary (rechargeable) cells is usually of the order of a few volts. The figures quoted below are nominal, because emf varies according to the size of the load and the state of exhaustion of the cell.\n\n\n==== Other chemical sources ====\nOther chemical sources include fuel cells.\n\n\n=== Electromagnetic induction ===\n\nElectromagnetic induction is the production of a circulating electric field by a time-dependent magnetic field. A time-dependent magnetic field can be produced either by motion of a magnet relative to a circuit, by motion of a circuit relative to another circuit (at least one of these must be carrying an electric current), or by changing the electric current in a fixed circuit. The effect on the circuit itself, of changing the electric current, is known as self-induction; the effect on another circuit is known as mutual induction.\nFor a given circuit, the electromagnetically induced emf is determined purely by the rate of change of the magnetic flux through the circuit according to Faraday's law of induction.\nAn emf is induced in a coil or conductor whenever there is change in the flux linkages. Depending on the way in which the changes are brought about, there are two types: When the conductor is moved in a stationary magnetic field to procure a change in the flux linkage, the emf is statically induced. The electromotive force generated by motion is often referred to as motional emf. When the change in flux linkage arises from a change in the magnetic field around the stationary conductor, the emf is dynamically induced. The electromotive force generated by a time-varying magnetic field  is often referred to as transformer emf.\n\n\n=== Contact potentials ===\n\nWhen solids of two different materials are in contact, thermodynamic equilibrium requires that one of the solids assume a higher electrical potential than the other. This is called the contact potential. Dissimilar metals in contact produce what is known also as a contact electromotive force or Galvani potential. The magnitude of this potential difference is often expressed as a difference in Fermi levels in the two solids when they are at charge neutrality, where the Fermi level (a name for the chemical potential of an electron system) describes the energy necessary to remove an electron from the body to some common point (such as ground). If there is an energy advantage in taking an electron from one body to the other, such a transfer will occur. The transfer causes a charge separation, with one body gaining electrons and the other losing electrons. This charge transfer causes a potential difference between the bodies, which partly cancels the potential originating from the contact, and eventually equilibrium is reached. At thermodynamic equilibrium, the Fermi levels are equal (the electron removal energy is identical) and there is now a built-in electrostatic potential between the bodies.\nThe original difference in Fermi levels, before contact, is referred to as the emf.\nThe contact potential cannot drive steady current through a load attached to its terminals because that current would involve a charge transfer. No mechanism exists to continue such transfer and, hence, maintain a current, once equilibrium is attained.\nOne might inquire why the contact potential does not appear in Kirchhoff's law of voltages as one contribution to the sum of potential drops. The customary answer is that any circuit involves not only a particular diode or junction, but also all the contact potentials due to wiring and so forth around the entire circuit. The sum of all the contact potentials is zero, and so they may be ignored in Kirchhoff's law.\n\n\n=== Solar cell ===\n\nOperation of a solar cell can be understood from its equivalent circuit. Photons with energy greater than the bandgap of the semiconductor create mobile electron\u2013hole pairs. Charge separation occurs because of a pre-existing electric field associated with the p-n junction. This electric field is created from a built-in potential, which arises from the contact potential between the two different materials in the junction. The charge separation between positive holes and negative electrons across the p\u2013n diode yields a forward voltage, the photo voltage, between the illuminated diode terminals, which drives current through any attached load. Photo voltage is sometimes referred to as the photo emf, distinguishing between the effect and the cause.\n\n\n==== Solar cell current\u2013voltage relationship ====\nTwo internal current losses \n  \n    \n      \n        \n          I\n          \n            S\n            H\n          \n        \n        +\n        \n          I\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle I_{SH}+I_{D}}\n   limit the total current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   available to the external circuit. The light-induced charge separation eventually creates a forward current \n  \n    \n      \n        \n          I\n          \n            S\n            H\n          \n        \n      \n    \n    {\\displaystyle I_{SH}}\n   through the cell's internal resistance \n  \n    \n      \n        \n          R\n          \n            S\n            H\n          \n        \n      \n    \n    {\\displaystyle R_{SH}}\n   in the direction opposite the light-induced current \n  \n    \n      \n        \n          I\n          \n            L\n          \n        \n      \n    \n    {\\displaystyle I_{L}}\n  . In addition, the induced voltage tends to forward bias the junction, which at high enough voltages will cause a recombination current \n  \n    \n      \n        \n          I\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle I_{D}}\n   in the diode opposite the light-induced current.\nWhen the output is short-circuited, the output voltage is zeroed, and so the voltage across the diode is smallest. Thus, short-circuiting results in the smallest \n  \n    \n      \n        \n          I\n          \n            S\n            H\n          \n        \n        +\n        \n          I\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle I_{SH}+I_{D}}\n   losses and consequently the maximum output current, which for a high-quality solar cell is approximately equal to the light-induced current \n  \n    \n      \n        \n          I\n          \n            L\n          \n        \n      \n    \n    {\\displaystyle I_{L}}\n  . Approximately this same current is obtained for forward voltages up to the point where the diode conduction becomes significant.\nThe current delivered by the illuminated diode to the external circuit can be simplified (based on certain assumptions) to:\n\n  \n    \n      \n        I\n        =\n        \n          I\n          \n            L\n          \n        \n        \u2212\n        \n          I\n          \n            0\n          \n        \n        \n          (\n          \n            \n              e\n              \n                \n                  V\n                  \n                    m\n                     \n                    \n                      V\n                      \n                        \n                          T\n                        \n                      \n                    \n                  \n                \n              \n            \n            \u2212\n            1\n          \n          )\n        \n         \n        .\n      \n    \n    {\\displaystyle I=I_{L}-I_{0}\\left(e^{\\frac {V}{m\\ V_{\\mathrm {T} }}}-1\\right)\\ .}\n  \n  \n    \n      \n        \n          I\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle I_{0}}\n   is the reverse saturation current. Two parameters that depend on the solar cell construction and to some degree upon the voltage itself are the ideality factor m and the thermal voltage \n  \n    \n      \n        \n          V\n          \n            \n              T\n            \n          \n        \n        =\n        \n          \n            \n              \n                k\n                T\n              \n              q\n            \n          \n        \n      \n    \n    {\\displaystyle V_{\\mathrm {T} }={\\tfrac {kT}{q}}}\n  , which is about 26 millivolts at room temperature.\n\n\n==== Solar cell photo emf ====\n\nSolving the illuminated diode's above simplified current\u2013voltage relationship for output voltage yields:\n\n  \n    \n      \n        V\n        =\n        m\n         \n        \n          V\n          \n            \n              T\n            \n          \n        \n        ln\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  \n                    I\n                    \n                      L\n                    \n                  \n                  \u2212\n                  I\n                \n                \n                  I\n                  \n                    0\n                  \n                \n              \n            \n            +\n            1\n          \n          )\n        \n         \n        ,\n      \n    \n    {\\displaystyle V=m\\ V_{\\mathrm {T} }\\ln \\left({\\frac {I_{\\text{L}}-I}{I_{0}}}+1\\right)\\ ,}\n  which is plotted against \n  \n    \n      \n        I\n        \n          /\n        \n        \n          I\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle I/I_{0}}\n   in the figure.\nThe solar cell's photo emf \n  \n    \n      \n        \n          \n            \n              E\n            \n          \n          \n            \n              p\n              h\n              o\n              t\n              o\n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}_{\\mathrm {photo} }}\n   has the same value as the open-circuit voltage \n  \n    \n      \n        \n          V\n          \n            o\n            c\n          \n        \n      \n    \n    {\\displaystyle V_{oc}}\n  , which is determined by zeroing the output current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  :\n\n  \n    \n      \n        \n          \n            \n              E\n            \n          \n          \n            \n              p\n              h\n              o\n              t\n              o\n            \n          \n        \n        =\n        \n          V\n          \n            oc\n          \n        \n        =\n        m\n         \n        \n          V\n          \n            \n              T\n            \n          \n        \n        ln\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  I\n                  \n                    L\n                  \n                \n                \n                  I\n                  \n                    0\n                  \n                \n              \n            \n            +\n            1\n          \n          )\n        \n         \n        .\n      \n    \n    {\\displaystyle {\\mathcal {E}}_{\\mathrm {photo} }=V_{\\text{oc}}=m\\ V_{\\mathrm {T} }\\ln \\left({\\frac {I_{\\text{L}}}{I_{0}}}+1\\right)\\ .}\n  It has a logarithmic dependence on the light-induced current \n  \n    \n      \n        \n          I\n          \n            L\n          \n        \n      \n    \n    {\\displaystyle I_{L}}\n   and is where the junction's forward bias voltage is just enough that the forward current completely balances the light-induced current. For silicon junctions, it is typically not much more than 0.5 volts. While for high-quality silicon panels it can exceed 0.7 volts in direct sunlight.When driving a resistive load, the output voltage can be determined using Ohm's law and will lie between the short-circuit value of zero volts and the open-circuit voltage \n  \n    \n      \n        \n          V\n          \n            o\n            c\n          \n        \n      \n    \n    {\\displaystyle V_{oc}}\n  . When that resistance is small enough such that \n  \n    \n      \n        I\n        \u2248\n        \n          I\n          \n            L\n          \n        \n      \n    \n    {\\displaystyle I\\approx I_{L}}\n   (the near-vertical part of the two illustrated curves), the solar cell acts more like a current generator rather than a voltage generator, since the current drawn is nearly fixed over a range of output voltages. This contrasts with batteries, which act more like voltage generators.\n\n\n=== Other sources that generate emf ===\nA transformer coupling two circuits may be considered a source of emf for one of the circuits, just as if it were caused by an electrical generator; this is the origin of the term \"transformer emf\".\nFor converting sound waves into voltage signals:\na microphone generates an emf from a moving diaphragm.\na magnetic pickup generates an emf from a varying magnetic field produced by an instrument.\na piezoelectric sensor generates an emf from strain on a piezoelectric crystal.\nDevices that use temperature to produce emfs include thermocouples and thermopiles.\nAny electrical transducer which converts a physical energy into electrical energy.\n\n\n== See also ==\nCounter-electromotive force\nElectric battery\nElectrochemical cell\nElectrolytic cell\nGalvanic cell\nVoltaic pile\n\n\n== References ==\n\n\n== Further reading ==\nGeorge F. Barker, \"On the measurement of electromotive force\". Proceedings of the American Philosophical Society Held at Philadelphia for Promoting Useful Knowledge, American Philosophical Society. January 19, 1883.\nAndrew Gray, \"Absolute Measurements in Electricity and Magnetism\", Electromotive force. Macmillan and co., 1884.\nCharles Albert Perkins, \"Outlines of Electricity and Magnetism\", Measurement of Electromotive Force. Henry Holt and co., 1896.\nJohn Livingston Rutgers Morgan, \"The Elements of Physical Chemistry\", Electromotive force.  J. Wiley, 1899.\n\"Abhandlungen zur Thermodynamik, von H. Helmholtz. Hrsg. von Max Planck\". (Tr. \"Papers to thermodynamics, on H. Helmholtz. Hrsg. by Max Planck\".) Leipzig, W. Engelmann,  Of Ostwald classical author of the accurate sciences series. New consequence. No. 124, 1902.\nTheodore William Richards and Gustavus Edward Behr, jr., \"The electromotive force of iron under varying conditions, and the effect of occluded hydrogen\". Carnegie Institution of Washington publication series, 1906. LCCN 07-3935\nHenry S. Carhart,  \"Thermo-electromotive force in electric cells, the thermo-electromotive force between a metal and a solution of one of its salts\".  New York, D. Van Nostrand company, 1920. LCCN 20-20413\nHazel Rossotti, \"Chemical applications of potentiometry\".  London, Princeton, N.J., Van Nostrand, 1969. ISBN 0-442-07048-9 LCCN 69-11985\nNabendu S. Choudhury, 1973. \"Electromotive force measurements on cells involving beta-alumina solid electrolyte\". NASA technical note, D-7322.\nJohn O'M. Bockris; Amulya K. N. Reddy (1973). \"Electrodics\". Modern Electrochemistry: An Introduction to an Interdisciplinary Area (2 ed.). Springer. ISBN 978-0-306-25002-6.\nRoberts, Dana (1983). \"How batteries work: A gravitational analog\". Am. J. Phys. 51 (9): 829. Bibcode:1983AmJPh..51..829R. doi:10.1119/1.13128.\nG. W. Burns, et al., \"Temperature-electromotive force reference functions and tables for the letter-designated thermocouple types based on the ITS-90\". Gaithersburg, MD : U.S. Dept. of Commerce, National Institute of Standards and Technology, Washington, Supt. of Docs., U.S. G.P.O., 1993.\nNorio Sato (1998). \"Semiconductor photoelectrodes\". Electrochemistry at metal and semiconductor electrodes (2nd ed.). Elsevier. p. 326 ff. ISBN 978-0-444-82806-4.\nHai, Pham Nam; Ohya, Shinobu; Tanaka, Masaaki; Barnes, Stewart E.; Maekawa, Sadamichi (2009-03-08). \"Electromotive force and huge magnetoresistance in magnetic tunnel junctions\". Nature. 458 (7237): 489\u201392. Bibcode:2009Natur.458..489H. doi:10.1038/nature07879. PMID 19270681. S2CID 4320209.", "Plane_mirror": "A plane mirror is a mirror with a flat (planar) reflective surface. For light rays striking a plane mirror, the angle of reflection equals the angle of incidence. The angle of the incidence is the angle between the incident ray and the surface normal (an imaginary line perpendicular to the surface). Therefore, the angle of reflection is the angle between the reflected ray and the normal and a collimated beam of light does not spread out after reflection from a plane mirror, except for diffraction effects.\nA plane mirror makes an image of objects in front of the mirror; these images appear to be behind the plane in which the mirror lies.  A straight line drawn from part of an object to the corresponding part of its image makes a right angle with, and is bisected by, the surface of the plane mirror.  The image formed by a plane mirror is virtual (meaning that the light rays do not actually come from the image) it is not real image (meaning that the light rays do actually come from the image). it is always upright, and of the same shape and size as the object it is reflecting. A virtual image is a copy of an object formed at the location from which the light rays appear to come. Actually, the image formed in the mirror is a perverted image (Perversion), there is a misconception among people about having confused with perverted and laterally-inverted image. If a person is reflected in a plane mirror, the image of his right hand appears to be the left hand of the image.\nPlane mirrors are the only type of mirror for which a object produces an image that is virtual, erect and of the same size as the object in all cases irrespective of the shape, size and distance from mirror of the object however same is possible for other types of mirror (concave and convex) but only for a specific conditions . However the focal length of a plane mirror is infinity; its optical power is zero.\nUsing the mirror equation, where \n  \n    \n      \n        \n          d\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle d_{0}}\n   is the object distance, \n  \n    \n      \n        \n          d\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle d_{i}}\n   is the image distance, and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the focal length:\n\n  \n    \n      \n        \n          \n            1\n            \n              d\n              \n                0\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              d\n              \n                i\n              \n            \n          \n        \n        =\n        \n          \n            1\n            f\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{d_{0}}}+{\\frac {1}{d_{i}}}={\\frac {1}{f}}}\n  Since \n  \n    \n      \n        [\n        \n          \n            1\n            f\n          \n        \n        =\n        0\n        ]\n      \n    \n    {\\displaystyle [{\\frac {1}{f}}=0]}\n  ,\n\n  \n    \n      \n        \n          \n            1\n            \n              d\n              \n                0\n              \n            \n          \n        \n        =\n        \u2212\n        \n          \n            1\n            \n              d\n              \n                i\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{d_{0}}}=-{\\frac {1}{d_{i}}}}\n  \n  \n    \n      \n        \u2212\n        \n          d\n          \n            0\n          \n        \n        =\n        \n          d\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle -d_{0}=d_{i}}\n  Concave and Convex mirrors (spherical mirrors) are also able to produce images similar to a plane mirror. However, the images formed by them are not of the same size as the object like they are in a plane mirror in all conditions rather specific one . In a convex mirror, the virtual image formed is always diminished, whereas in a concave mirror when the object is placed between the focus and the pole, an enlarged virtual image is formed. Therefore, in applications where a virtual image of the same size is required, a plane mirror is preferred over spherical mirrors.\n\n\n== Preparation ==\n\nA plane mirror is made using some highly reflecting and polished surface such as a silver or aluminium surface in a process called silvering. After silvering, a thin layer of red lead oxide is applied at the back of the mirror. The reflecting surface reflects most of the light striking it as long as the surface remains uncontaminated by tarnishing or oxidation. Most modern plane mirrors are designed with a thin piece of plate glass that protects and strengthens the mirror surface and helps prevent tarnishing. Historically, mirrors were simply flat pieces of polished copper, obsidian, brass, or a precious metal. Mirrors made from liquid also exist, as the elements gallium and mercury are both highly reflective in their liquid state.\n\n\n== Relation to curved mirrors ==\nMathematically, a plane mirror can be considered to be the limit of either a concave or a convex spherical curved mirror as the radius, and therefore the focal length becomes infinity.\n\n\n== See also ==\nGeometrical optics\nSpecular reflection\nChinese magic mirror\nLaw of reflection\n\n\n== References ==", "Capacitance": "Capacitance is the capability of a material object or device to store electric charge. It is measured by the change in charge in response to a difference in electric potential, expressed as the ratio of those quantities. Commonly recognized are two closely related notions of capacitance: self capacitance and mutual capacitance.:\u200a237\u2013238\u200a An object that can be electrically charged exhibits self capacitance, for which the electric potential is measured between the object and ground. Mutual capacitance is measured between two components, and is particularly important in the operation of the capacitor, an elementary linear electronic component designed to add capacitance to an electric circuit.\nThe capacitance between two conductors is a function only of the geometry; the opposing surface area of the conductors and the distance between them, and the permittivity of any dielectric material between them. For many dielectric materials, the permittivity, and thus the capacitance, is independent of the potential difference between the conductors and the total charge on them.\nThe SI unit of capacitance is the farad (symbol: F), named after the English physicist Michael Faraday. A 1 farad capacitor, when charged with 1 coulomb of electrical charge, has a potential difference of 1 volt between its plates. The reciprocal of capacitance is called elastance.\n\n\n== Self capacitance ==\nIn discussing electrical circuits, the term capacitance is usually a shorthand for the mutual capacitance between two adjacent conductors, such as the two plates of a capacitor. However, every isolated conductor also exhibits capacitance, here called self capacitance. It is measured by the amount of electric charge that must be added to an isolated conductor to raise its electric potential by one unit of measurement, e.g., one volt. The reference point for this potential is a theoretical hollow conducting sphere, of infinite radius, with the conductor centered inside this sphere.\nSelf capacitance of a conductor is defined by the ratio of charge and electric potential:\n\nwhere\n\n  \n    \n      \n        q\n      \n    \n    {\\textstyle q}\n   is the charge held,\n\n  \n    \n      \n        V\n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \u222b\n        \n          \n            \u03c3\n            r\n          \n        \n        \n        d\n        S\n      \n    \n    {\\textstyle V={\\frac {1}{4\\pi \\varepsilon _{0}}}\\int {\\frac {\\sigma }{r}}\\,dS}\n   is the electric potential,\n\n  \n    \n      \n        \u03c3\n      \n    \n    {\\textstyle \\sigma }\n   is the surface charge density,\n\n  \n    \n      \n        d\n        S\n      \n    \n    {\\textstyle dS}\n   is an infinitesimal element of area on the surface of the conductor,\n\n  \n    \n      \n        r\n      \n    \n    {\\textstyle r}\n   is the length from \n  \n    \n      \n        d\n        S\n      \n    \n    {\\textstyle dS}\n   to a fixed point M on the conductor,\n\n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   is the vacuum permittivity.Using this method, the self capacitance of a conducting sphere of radius \n  \n    \n      \n        R\n      \n    \n    {\\textstyle R}\n   is:\nExample values of self capacitance are:\n\nfor the top \"plate\" of a van de Graaff generator, typically a sphere 20 cm in radius: 22.24 pF,\nthe planet Earth: about 710 \u00b5F.The inter-winding capacitance of a coil is sometimes called self capacitance, but this is a different phenomenon. It is actually mutual capacitance between the individual turns of the coil and is a form of stray or parasitic capacitance. This self capacitance is an important consideration at high frequencies: it changes the impedance of the coil and gives rise to parallel resonance. In many applications this is an undesirable effect and sets an upper frequency limit for the correct operation of the circuit.\n\n\n== Mutual capacitance ==\nA common form is a parallel-plate capacitor, which consists of two conductive plates insulated from each other, usually sandwiching a dielectric material. In a parallel plate capacitor, capacitance is very nearly proportional to the surface area of the conductor plates and inversely proportional to the separation distance between the plates.\nIf the charges on the plates are \n  \n    \n      \n        +\n        q\n      \n    \n    {\\textstyle +q}\n   and \n  \n    \n      \n        \u2212\n        q\n      \n    \n    {\\textstyle -q}\n  , and \n  \n    \n      \n        V\n      \n    \n    {\\textstyle V}\n   gives the voltage between the plates, then the capacitance \n  \n    \n      \n        C\n      \n    \n    {\\textstyle C}\n   is given by \nwhich gives the voltage/current relationship\n\nwhere \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              v\n              (\n              t\n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\textstyle {\\frac {\\mathrm {d} v(t)}{\\mathrm {d} t}}}\n   is the instantaneous rate of change of voltage.\nThe energy stored in a capacitor is found by integrating the work \n  \n    \n      \n        W\n      \n    \n    {\\textstyle W}\n  :\n\n\n=== Capacitance matrix ===\nThe discussion above is limited to the case of two conducting plates, although of arbitrary size and shape. The definition \n  \n    \n      \n        C\n        =\n        Q\n        \n          /\n        \n        V\n      \n    \n    {\\displaystyle C=Q/V}\n   does not apply when there are more than two charged plates, or when the net charge on the two plates is non-zero. To handle this case, Maxwell introduced his coefficients of potential. If three (nearly ideal) conductors are given charges \n  \n    \n      \n        \n          Q\n          \n            1\n          \n        \n        ,\n        \n          Q\n          \n            2\n          \n        \n        ,\n        \n          Q\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle Q_{1},Q_{2},Q_{3}}\n  , then the voltage at conductor 1 is given by\n\nand similarly for the other voltages. Hermann von Helmholtz and Sir William Thomson showed that the coefficients of potential are symmetric, so that \n  \n    \n      \n        \n          P\n          \n            12\n          \n        \n        =\n        \n          P\n          \n            21\n          \n        \n      \n    \n    {\\displaystyle P_{12}=P_{21}}\n  , etc. Thus the system can be described by a collection of coefficients known as the elastance matrix or reciprocal capacitance matrix, which is defined as:\n\nFrom this, the mutual capacitance \n  \n    \n      \n        \n          C\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle C_{m}}\n   between two objects can be defined by solving for the total charge \n  \n    \n      \n        Q\n      \n    \n    {\\textstyle Q}\n   and using \n  \n    \n      \n        \n          C\n          \n            m\n          \n        \n        =\n        Q\n        \n          /\n        \n        V\n      \n    \n    {\\displaystyle C_{m}=Q/V}\n  .\n\nSince no actual device holds perfectly equal and opposite charges on each of the two \"plates\", it is the mutual capacitance that is reported on capacitors.\nThe collection of coefficients \n  \n    \n      \n        \n          C\n          \n            i\n            j\n          \n        \n        =\n        \n          \n            \n              \u2202\n              \n                Q\n                \n                  i\n                \n              \n            \n            \n              \u2202\n              \n                V\n                \n                  j\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle C_{ij}={\\frac {\\partial Q_{i}}{\\partial V_{j}}}}\n   is known as the capacitance matrix, and is the inverse of the elastance matrix.\n\n\n== Capacitors ==\n\nThe capacitance of the majority of capacitors used in electronic circuits is generally several orders of magnitude smaller than the farad. The most common subunits of capacitance in use today are the microfarad (\u00b5F), nanofarad (nF), picofarad (pF), and, in microcircuits, femtofarad (fF). However, specially made supercapacitors can be much larger (as much as hundreds of farads), and parasitic capacitive elements can be less than a femtofarad. In the past, alternate subunits were used in old historical texts; \"mf\" and \"mfd\" for microfarad (\u00b5F); \"mmf\", \"mmfd\", \"pfd\", \"\u00b5\u00b5F\" for picofarad (pF); but are now considered obsolete.Capacitance can be calculated if the geometry of the conductors and the dielectric properties of the insulator between the conductors are known. A qualitative explanation for this can be given as follows. Once a positive charge is put unto a conductor, this charge creates an electrical field, repelling any other positive charge to be moved onto the conductor; i.e., increasing the necessary voltage. But if nearby there is another conductor with a negative charge on it, the electrical field of the positive conductor repelling the second positive charge is weakened (the second positive charge also feels the attracting force of the negative charge). So due to the second conductor with a negative charge, it becomes easier to put a positive charge on the already positive charged first conductor, and vice versa; i.e., the necessary voltage is lowered.\nAs a quantitative example consider the capacitance of a capacitor constructed of two parallel plates both of area  \n  \n    \n      \n        A\n      \n    \n    {\\textstyle A}\n   separated by a distance \n  \n    \n      \n        d\n      \n    \n    {\\textstyle d}\n  . If \n  \n    \n      \n        d\n      \n    \n    {\\textstyle d}\n   is sufficiently small with respect to the smallest chord of \n  \n    \n      \n        A\n      \n    \n    {\\textstyle A}\n  , there holds, to a high level of accuracy:\n\nnote that\n\nwhere\n\n  \n    \n      \n        C\n      \n    \n    {\\textstyle C}\n   is the capacitance, in farads;\n\n  \n    \n      \n        A\n      \n    \n    {\\textstyle A}\n   is the area of overlap of the two plates, in square meters;\n\n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\textstyle \\varepsilon _{0}}\n   is the electric constant (\n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n        \u223c\n        8.854\n        \u00d7\n        \n          10\n          \n            \u2212\n            12\n          \n        \n        F\n        .\n        \n          m\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\textstyle \\varepsilon _{0}\\sim 8.854\\times 10^{-12}F.m^{-1}}\n  );\n\n  \n    \n      \n        \n          \u03b5\n          \n            r\n          \n        \n      \n    \n    {\\textstyle \\varepsilon _{r}}\n   is the relative permittivity (also dielectric constant) of the material in between the plates (\n  \n    \n      \n        \n          \u03b5\n          \n            r\n          \n        \n        =\n        1\n      \n    \n    {\\textstyle \\varepsilon _{r}=1}\n   for air); and\n\n  \n    \n      \n        d\n      \n    \n    {\\textstyle d}\n   is the separation between the plates, in meters.Capacitance is proportional to the area of overlap and inversely proportional to the separation between conducting sheets. The closer the sheets are to each other, the greater the capacitance.\nThe equation is a good approximation if d is small compared to the other dimensions of the plates so that the electric field in the capacitor area is uniform, and the so-called fringing field around the periphery provides only a small contribution to the capacitance.\nCombining the equation for capacitance with the above equation for the energy stored in a capacitance, for a flat-plate capacitor the energy stored is:\n\nwhere \n  \n    \n      \n        W\n      \n    \n    {\\textstyle W}\n   is the energy, in joules; \n  \n    \n      \n        C\n      \n    \n    {\\textstyle C}\n   is the capacitance, in farads; and \n  \n    \n      \n        V\n      \n    \n    {\\textstyle V}\n   is the voltage, in volts.\n\n\n== Stray capacitance ==\n\nAny two adjacent conductors can function as a capacitor, though the capacitance is small unless the conductors are close together for long distances or over a large area. This (often unwanted) capacitance is called parasitic or stray capacitance. Stray capacitance can allow signals to leak between otherwise isolated circuits (an effect called crosstalk), and it can be a limiting factor for proper functioning of circuits at high frequency.\nStray capacitance between the input and output in amplifier circuits can be troublesome because it can form a path for feedback, which can cause instability and parasitic oscillation in the amplifier. It is often convenient for analytical purposes to replace this capacitance with a combination of one input-to-ground capacitance and one output-to-ground capacitance; the original configuration \u2013 including the input-to-output capacitance \u2013 is often referred to as a pi-configuration. Miller's theorem can be used to effect this replacement: it states that, if the gain ratio of two nodes is 1/K, then an impedance of Z connecting the two nodes can be replaced with a Z/1 \u2212 K impedance between the first node and ground and a KZ/K \u2212 1 impedance between the second node and ground. Since impedance varies inversely with capacitance, the internode capacitance, C, is replaced by a capacitance of KC from input to ground and a capacitance of (K \u2212 1)C/K from output to ground. When the input-to-output gain is very large, the equivalent input-to-ground impedance is very small while the output-to-ground impedance is essentially equal to the original (input-to-output) impedance.\n\n\n== Capacitance of conductors with simple shapes ==\nCalculating the capacitance of a system amounts to solving the Laplace equation \n  \n    \n      \n        \n          \u2207\n          \n            2\n          \n        \n        \u03c6\n        =\n        0\n      \n    \n    {\\textstyle \\nabla ^{2}\\varphi =0}\n   with a constant potential \n  \n    \n      \n        \u03c6\n      \n    \n    {\\textstyle \\varphi }\n   on the 2-dimensional surface of the conductors embedded in 3-space. This is simplified by symmetries. There is no solution in terms of elementary functions in more complicated cases.\nFor plane situations, analytic functions may be used to map different geometries to each other. See also Schwarz\u2013Christoffel mapping.\n\n\n== Energy storage ==\nThe energy (measured in joules) stored in a capacitor is equal to the work required to push the charges into the capacitor, i.e. to charge it. Consider a capacitor of capacitance C, holding a charge +q on one plate and \u2212q on the other. Moving a small element of charge dq from one plate to the other against the potential difference V = q/C requires the work dW:\n\nwhere W is the work measured in joules, q is the charge measured in coulombs and C is the capacitance, measured in farads.\nThe energy stored in a capacitor is found by integrating this equation. Starting with an uncharged capacitance (q = 0) and moving charge from one plate to the other until the plates have charge +Q and \u2212Q requires the work W:\n\n\n== Nanoscale systems ==\nThe capacitance of nanoscale dielectric capacitors such as quantum dots may differ from conventional formulations of larger capacitors. In particular, the electrostatic potential difference experienced by electrons in conventional capacitors is spatially well-defined and fixed by the shape and size of metallic electrodes in addition to the statistically large number of electrons present in conventional capacitors. In nanoscale capacitors, however, the electrostatic potentials experienced by electrons are determined by the number and locations of all electrons that contribute to the electronic properties of the device. In such devices, the number of electrons may be very small, so the resulting spatial distribution of equipotential surfaces within the device is exceedingly complex.\n\n\n=== Single-electron devices ===\nThe capacitance of a connected, or \"closed\", single-electron device is twice the capacitance of an unconnected, or \"open\", single-electron device. This fact may be traced more fundamentally to the energy stored in the single-electron device whose \"direct polarization\" interaction energy may be equally divided into the interaction of the electron with the polarized charge on the device itself due to the presence of the electron and the amount of potential energy required to form the polarized charge on the device (the interaction of charges in the device's dielectric material with the potential due to the electron).\n\n\n=== Few-electron devices ===\nThe derivation of a \"quantum capacitance\" of a few-electron device involves the thermodynamic chemical potential of an N-particle system given by\n\nwhose energy terms may be obtained as solutions of the Schr\u00f6dinger equation. The definition of capacitance,\n\nwith the potential difference\n\nmay be applied to the device with the addition or removal of individual electrons,\n and \nThe \"quantum capacitance\" of the device is then\nThis expression of \"quantum capacitance\" may be written as\n\nwhich differs from the conventional expression described in the introduction where \n  \n    \n      \n        \n          W\n          \n            stored\n          \n        \n        =\n        U\n      \n    \n    {\\displaystyle W_{\\text{stored}}=U}\n  , the stored electrostatic potential energy,\n\nby a factor of 1/2 with \n  \n    \n      \n        Q\n        =\n        N\n        e\n      \n    \n    {\\displaystyle Q=Ne}\n  .\nHowever, within the framework of purely classical electrostatic interactions, the appearance of the factor of 1/2 is the result of integration in the conventional formulation involving the work done when charging a capacitor,\n\nwhich is appropriate since \n  \n    \n      \n        \n          d\n        \n        q\n        =\n        0\n      \n    \n    {\\displaystyle \\mathrm {d} q=0}\n   for systems involving either many electrons or metallic electrodes, but in few-electron systems, \n  \n    \n      \n        \n          d\n        \n        q\n        \u2192\n        \u0394\n        \n        Q\n        =\n        e\n      \n    \n    {\\displaystyle \\mathrm {d} q\\to \\Delta \\,Q=e}\n  . The integral generally becomes a summation. One may trivially combine the expressions of capacitance \n \nand electrostatic interaction energy,\n\nto obtain\n\nwhich is similar to the quantum capacitance. A more rigorous derivation is reported in the literature. In particular, to circumvent the mathematical challenges of spatially complex equipotential surfaces within the device, an average electrostatic potential experienced by each electron is utilized in the derivation.\nApparent mathematical differences may be understood more fundamentally. The potential energy, \n  \n    \n      \n        U\n        (\n        N\n        )\n      \n    \n    {\\displaystyle U(N)}\n  , of an isolated device (self-capacitance) is twice that stored in a \"connected\" device in the lower limit N=1. As N grows large, \n  \n    \n      \n        U\n        (\n        N\n        )\n        \u2192\n        U\n      \n    \n    {\\displaystyle U(N)\\to U}\n  . Thus, the general expression of capacitance is\n\nIn nanoscale devices such as quantum dots, the \"capacitor\" is often an isolated or partially isolated component within the device. The primary differences between nanoscale capacitors and macroscopic (conventional) capacitors are the number of excess electrons (charge carriers, or electrons, that contribute to the device's electronic behavior) and the shape and size of metallic electrodes. In nanoscale devices, nanowires consisting of metal atoms typically do not exhibit the same conductive properties as their macroscopic, or bulk material, counterparts.\n\n\n== Capacitance in electronic and semiconductor devices ==\nIn electronic and semiconductor devices, transient or frequency-dependent current between terminals contains both conduction and displacement components. Conduction current is related to moving charge carriers (electrons, holes, ions, etc.), while displacement current is caused by a time-varying electric field. Carrier transport is affected by electric fields and by a number of physical phenomena - such as carrier drift and diffusion, trapping, injection, contact-related effects, impact ionization, etc. As a result, device admittance is frequency-dependent, and a simple electrostatic formula for capacitance \n  \n    \n      \n        C\n        =\n        q\n        \n          /\n        \n        V\n        ,\n      \n    \n    {\\displaystyle C=q/V,}\n   is not applicable. A more general definition of capacitance, encompassing electrostatic formula, is:\nwhere \n  \n    \n      \n        Y\n        (\n        \u03c9\n        )\n      \n    \n    {\\displaystyle Y(\\omega )}\n   is the device admittance, and \n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   is the angular frequency.\nIn general, capacitance is a function of frequency. At high frequencies, capacitance approaches a constant value, equal to \"geometric\" capacitance, determined by the terminals' geometry and dielectric content in the device.\nA paper by Steven Laux presents a review of numerical techniques for capacitance calculation. In particular, capacitance can be calculated by a Fourier transform of a transient current in response to a step-like voltage excitation:\n\n\n== Negative capacitance in semiconductor devices ==\nUsually, capacitance in semiconductor devices is positive. However, in some devices and under certain conditions (temperature, applied voltages, frequency, etc.), capacitance can become negative. Non-monotonic behavior of the transient current in response to a step-like excitation has been proposed as the mechanism of negative capacitance. Negative capacitance has been demonstrated and explored in many different types of semiconductor devices.\n\n\n== Measuring capacitance ==\n\nA capacitance meter is a piece of electronic test equipment used to measure capacitance, mainly of discrete capacitors. For most purposes and in most cases the capacitor must be disconnected from circuit.\nMany DVMs (digital volt meters) have a capacitance-measuring function. These usually operate by charging and discharging the capacitor under test with a known current and measuring the rate of rise of the resulting voltage; the slower the rate of rise, the larger the capacitance. DVMs can usually measure capacitance from nanofarads to a few hundred microfarads, but wider ranges are not unusual.  It is also possible to measure capacitance by passing a known high-frequency alternating current through the device under test and measuring the resulting voltage across it (does not work for polarised capacitors).\n\nMore sophisticated instruments use other techniques such as inserting the capacitor-under-test into a bridge circuit. By varying the values of the other legs in the bridge (so as to bring the bridge into balance), the value of the unknown capacitor is determined. This method of indirect use of measuring capacitance ensures greater precision. Through the use of Kelvin connections and other careful design techniques, these instruments can usually measure capacitors over a range from picofarads to farads.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==", "Dielectric": "In electromagnetism, a dielectric (or dielectric medium) is an electrical insulator that can be polarised by an applied electric field. When a dielectric material is placed in an electric field, electric charges do not flow through the material as they do in an electrical conductor, because they have no loosely bound, or free, electrons that may drift through the material, but instead they shift, only slightly, from their average equilibrium positions, causing dielectric polarisation. Because of dielectric polarisation, positive charges are displaced in the direction of the field and negative charges shift in the direction opposite to the field (for example, if the field is moving parallel to the positive x axis, the negative charges will shift in the negative x direction). This creates an internal electric field that reduces the overall field within the dielectric itself. If a dielectric is composed of weakly bonded molecules, those molecules not only become polarised, but also reorient so that their symmetry axes align to the field.The study of dielectric properties concerns storage and dissipation of electric and magnetic energy in materials. Dielectrics are important for explaining various phenomena in electronics, optics, solid-state physics and cell biophysics.\n\n\n== Terminology ==\nAlthough the term insulator implies low electrical conduction, dielectric typically means materials with a high polarisability. The latter is expressed by a number called the relative permittivity. The term insulator is generally used to indicate electrical obstruction while the term dielectric is used to indicate the energy storing capacity of the material (by means of polarisation). A common example of a dielectric is the electrically insulating material between the metallic plates of a capacitor. The polarisation of the dielectric by the applied electric field increases the capacitor's surface charge for the given electric field strength.The term dielectric was coined by William Whewell (from dia + electric) in response to a request from Michael Faraday. A perfect dielectric is a material with zero electrical conductivity (cf. perfect conductor infinite electrical conductivity), thus exhibiting only a displacement current; therefore it stores and returns electrical energy as if it were an ideal capacitor.\n\n\n== Electric susceptibility ==\n\nThe electric susceptibility \u03c7e of a dielectric material is a measure of how easily it polarises in response to an electric field. This, in turn, determines the electric permittivity of the material and thus influences many other phenomena in that medium, from the capacitance of capacitors to the speed of light.\nIt is defined as the constant of proportionality (which may be a tensor) relating an electric field E to the induced dielectric polarisation density P such that\n\nwhere \u03b50 is the electric permittivity of free space.\nThe susceptibility of a medium is related to its relative permittivity \u03b5r by\n\nSo in the case of a vacuum,\n\nThe electric displacement D is related to the polarisation density P by\n\n\n=== Dispersion and causality ===\nIn general, a material cannot polarise instantaneously in response to an applied field. The more general formulation as a function of time is\n\nThat is, the polarisation is a convolution of the electric field at previous times with time-dependent susceptibility given by \u03c7e(\u0394t). The upper limit of this integral can be extended to infinity as well if one defines \u03c7e(\u0394t) = 0 for \u0394t < 0. An instantaneous response corresponds to Dirac delta function susceptibility \u03c7e(\u0394t) = \u03c7e\u03b4(\u0394t).\nIt is more convenient in a linear system to take the Fourier transform and write this relationship as a function of frequency. Due to the convolution theorem, the integral becomes a simple product,\n\nThe susceptibility (or equivalently the permittivity) is frequency dependent. The change of susceptibility with respect to frequency characterises the dispersion properties of the material.\nMoreover, the fact that the polarisation can only depend on the electric field at previous times (i.e., \u03c7e(\u0394t) = 0 for \u0394t < 0), a consequence of causality, imposes Kramers\u2013Kronig constraints on the real and imaginary parts of the susceptibility \u03c7e(\u03c9).\n\n\n== Dielectric polarisation ==\n\n\n=== Basic atomic model ===\n\nIn the classical approach to the dielectric, the material is made up of atoms. Each atom consists of a cloud of negative charge (electrons) bound to and surrounding a positive point charge at its center. In the presence of an electric field, the charge cloud is distorted, as shown in the top right of the figure.\nThis can be reduced to a simple dipole using the superposition principle. A dipole is characterised by its dipole moment, a vector quantity shown in the figure as the blue arrow labeled M. It is the relationship between the electric field and the dipole moment that gives rise to the behaviour of the dielectric. (Note that the dipole moment points in the same direction as the electric field in the figure. This isn't always the case, and is a major simplification, but is true for many materials.)\nWhen the electric field is removed the atom returns to its original state. The time required to do so is called relaxation time; an exponential decay.\nThis is the essence of the model in physics. The behaviour of the dielectric now depends on the situation. The more complicated the situation, the richer the model must be to accurately describe the behaviour. Important questions are:\n\nIs the electric field constant or does it vary with time? At what rate?\nDoes the response depend on the direction of the applied field (isotropy of the material)?\nIs the response the same everywhere (homogeneity of the material)?\nDo any boundaries or interfaces have to be taken into account?\nIs the response linear with respect to the field, or are there nonlinearities?The relationship between the electric field E and the dipole moment M gives rise to the behaviour of the dielectric, which, for a given material, can be characterised by the function F defined by the equation:\n\nWhen both the type of electric field and the type of material have been defined, one then chooses the simplest function F that correctly predicts the phenomena of interest. Examples of phenomena that can be so modelled include:\n\nRefractive index\nGroup velocity dispersion\nBirefringence\nSelf-focusing\nHarmonic generation\n\n\n=== Dipolar polarisation ===\nDipolar polarisation is a polarisation that is either inherent to polar molecules (orientation polarisation), or can be induced in any molecule in which the asymmetric distortion of the nuclei is possible (distortion polarisation). Orientation polarisation results from a permanent dipole, e.g., that arising from the 104.45\u00b0 angle between the asymmetric bonds between oxygen and hydrogen atoms in the water molecule, which retains polarisation in the absence of an external electric field. The assembly of these dipoles forms a macroscopic polarisation.\nWhen an external electric field is applied, the distance between charges within each permanent dipole, which is related to chemical bonding, remains constant in orientation polarisation; however, the direction of polarisation itself rotates. This rotation occurs on a timescale that depends on the torque and surrounding local viscosity of the molecules. Because the rotation is not instantaneous, dipolar polarisations lose the response to electric fields at the highest frequencies. A molecule rotates about 1 radian per picosecond in a fluid, thus this loss occurs at about 1011 Hz (in the microwave region). The delay of the response to the change of the electric field causes friction and heat.\nWhen an external electric field is applied at infrared frequencies or less, the molecules are bent and stretched by the field and the molecular dipole moment changes. The molecular vibration frequency is roughly the inverse of the time it takes for the molecules to bend, and this distortion polarisation disappears above the infrared.\n\n\n=== Ionic polarisation ===\nIonic polarisation is polarisation caused by relative displacements between positive and negative ions in ionic crystals (for example, NaCl).\nIf a crystal or molecule consists of atoms of more than one kind, the distribution of charges around an atom in the crystal or molecule leans to positive or negative. As a result, when lattice vibrations or molecular vibrations induce relative displacements of the atoms, the centers of positive and negative charges are also displaced. The locations of these centers are affected by the symmetry of the displacements. When the centers don't correspond, polarisation arises in molecules or crystals. This polarisation is called ionic polarisation.\nIonic polarisation causes the ferroelectric effect as well as dipolar polarisation. The ferroelectric transition, which is caused by the lining up of the orientations of permanent dipoles along a particular direction, is called an order-disorder phase transition. The transition caused by ionic polarisations in crystals is called a displacive phase transition.\n\n\n==== In cells ====\nIonic polarisation enables the production of energy-rich compounds in cells (the proton pump in mitochondria) and, at the plasma membrane, the establishment of the resting potential, energetically unfavourable transport of ions, and cell-to-cell communication (the Na+/K+-ATPase).\nAll cells in animal body tissues are electrically polarised \u2013 in other words, they maintain a voltage difference across the cell's plasma membrane, known as the membrane potential. This electrical polarisation results from a complex interplay between ion transporters and ion channels.\nIn neurons, the types of ion channels in the membrane usually vary across different parts of the cell, giving the dendrites, axon, and cell body different electrical properties. As a result, some parts of the membrane of a neuron may be excitable (capable of generating action potentials), whereas others are not.\n\n\n== Dielectric dispersion ==\nIn physics, dielectric dispersion is the dependence of the permittivity of a dielectric material on the frequency of an applied electric field. Because there is a lag between changes in polarisation and changes in the electric field, the permittivity of the dielectric is a complex function of the frequency of the electric field. Dielectric dispersion is very important for the applications of dielectric materials and the analysis of polarisation systems.\nThis is one instance of a general phenomenon known as material dispersion: a frequency-dependent response of a medium for wave propagation.\nWhen the frequency becomes higher:\n\nThe dipolar polarisation can no longer follow the oscillations of the electric field in the microwave region around 1010 Hz,\nThe ionic polarisation and molecular distortion polarisation can no longer track the electric field past the infrared or far-infrared region around 1013 Hz,\nThe electronic polarisation loses its response in the ultraviolet region around 1015 Hz.In the frequency region above ultraviolet, permittivity approaches the constant \u03b50 in every substance, where \u03b50 is the permittivity of the free space. Because permittivity indicates the strength of the relation between an electric field and polarisation, if a polarisation process loses its response, permittivity decreases.\n\n\n== Dielectric relaxation ==\nDielectric relaxation is the momentary delay (or lag) in the dielectric constant of a material. This is usually caused by the delay in molecular polarisation with respect to a changing electric field in a dielectric medium (e.g., inside capacitors or between two large conducting surfaces). Dielectric relaxation in changing electric fields could be considered analogous to hysteresis in changing magnetic fields (e.g., in inductor or transformer cores). Relaxation in general is a delay or lag in the response of a linear system, and therefore dielectric relaxation is measured relative to the expected linear steady state (equilibrium) dielectric values. The time lag between electrical field and polarisation implies an irreversible degradation of Gibbs free energy.\nIn physics, dielectric relaxation refers to the relaxation response of a dielectric medium to an external, oscillating electric field. This relaxation is often described in terms of permittivity as a function of frequency, which can, for ideal systems, be described by the Debye equation. On the other hand, the distortion related to ionic and electronic polarisation shows behaviour of the resonance or oscillator type. The character of the distortion process depends on the structure, composition, and surroundings of the sample.\n\n\n=== Debye relaxation ===\nDebye relaxation is the dielectric relaxation response of an ideal, noninteracting population of dipoles to an alternating external electric field. It is usually expressed in the complex permittivity \u03b5 of a medium as a function of the field's angular frequency \u03c9:\n\nwhere \u03b5\u221e is the permittivity at the high frequency limit, \u0394\u03b5 = \u03b5s \u2212 \u03b5\u221e where \u03b5s is the static, low frequency permittivity, and \u03c4 is the characteristic relaxation time of the medium. Separating into the real part \n  \n    \n      \n        \n          \u03b5\n          \u2032\n        \n      \n    \n    {\\displaystyle \\varepsilon '}\n   and the imaginary part \n  \n    \n      \n        \n          \u03b5\n          \u2033\n        \n      \n    \n    {\\displaystyle \\varepsilon ''}\n   of the complex dielectric permittivity yields:\nNote that the above equation for \n  \n    \n      \n        \n          \n            \n              \u03b5\n              ^\n            \n          \n        \n        (\n        \u03c9\n        )\n      \n    \n    {\\displaystyle {\\hat {\\varepsilon }}(\\omega )}\n  is sometimes written with \n  \n    \n      \n        1\n        \u2212\n        i\n        \u03c9\n        \u03c4\n      \n    \n    {\\displaystyle 1-i\\omega \\tau }\n   in the denominator due to an ongoing sign convention ambiguity whereby many sources represent the time dependence of the complex electric field with \n  \n    \n      \n        exp\n        \u2061\n        (\n        \u2212\n        i\n        \u03c9\n        t\n        )\n      \n    \n    {\\displaystyle \\exp(-i\\omega t)}\n   whereas others use \n  \n    \n      \n        exp\n        \u2061\n        (\n        +\n        i\n        \u03c9\n        t\n        )\n      \n    \n    {\\displaystyle \\exp(+i\\omega t)}\n  . In the former convention, the functions \n  \n    \n      \n        \n          \u03b5\n          \u2032\n        \n      \n    \n    {\\displaystyle \\varepsilon '}\n   and \n  \n    \n      \n        \n          \u03b5\n          \u2033\n        \n      \n    \n    {\\displaystyle \\varepsilon ''}\n   representing real and imaginary parts are given by \n  \n    \n      \n        \n          \n            \n              \u03b5\n              ^\n            \n          \n        \n        (\n        \u03c9\n        )\n        =\n        \n          \u03b5\n          \u2032\n        \n        +\n        i\n        \n          \u03b5\n          \u2033\n        \n      \n    \n    {\\displaystyle {\\hat {\\varepsilon }}(\\omega )=\\varepsilon '+i\\varepsilon ''}\n   whereas in the latter convention \n  \n    \n      \n        \n          \n            \n              \u03b5\n              ^\n            \n          \n        \n        (\n        \u03c9\n        )\n        =\n        \n          \u03b5\n          \u2032\n        \n        \u2212\n        i\n        \n          \u03b5\n          \u2033\n        \n      \n    \n    {\\displaystyle {\\hat {\\varepsilon }}(\\omega )=\\varepsilon '-i\\varepsilon ''}\n  . The above equation uses the latter convention.The dielectric loss is also represented by the loss tangent:\n\nThis relaxation model was introduced by and named after the physicist Peter Debye (1913). It is characteristic for dynamic polarisation with only one relaxation time.\n\n\n=== Variants of the Debye equation ===\nCole\u2013Cole equation\nThis equation is used when the dielectric loss peak shows symmetric broadening.\nCole\u2013Davidson equation\nThis equation is used when the dielectric loss peak shows asymmetric broadening.\nHavriliak\u2013Negami relaxation\nThis equation considers both symmetric and asymmetric broadening.\nKohlrausch\u2013Williams\u2013Watts function\nFourier transform of stretched exponential function.\nCurie\u2013von Schweidler law\nThis shows the response of dielectrics to an applied DC field to behave according to a power law, which can be expressed as an integral over weighted exponential functions..\n\n\n== Paraelectricity ==\n\nParaelectricity is the nominal behaviour of dielectrics when the dielectric permittivity tensor is proportional to the unit matrix, i.e., an applied electric field causes polarisation and/or alignment of dipoles only parallel to the applied electric field. Contrary to the analogy with a paramagnetic material, no permanent electric dipole needs to exist in a paraelectric material. Removal of the fields results in the dipolar polarisation returning to zero. The mechanisms that causes paraelectric behaviour are distortion of individual ions (displacement of the electron cloud from the nucleus) and polarisation of molecules or combinations of ions or defects.\nParaelectricity can occur in crystal phases where electric dipoles are unaligned and thus have the potential to align in an external electric field and weaken it.\nMost dielectric materials are paraelectrics. A specific example of a paraelectric material of high dielectric constant is strontium titanate.\nThe LiNbO3 crystal is ferroelectric below 1430 K, and above this temperature it transforms into a disordered paraelectric phase. Similarly, other perovskites also exhibit paraelectricity at high temperatures.\nParaelectricity has been explored as a possible refrigeration mechanism; polarising a paraelectric by applying an electric field under adiabatic process conditions raises the temperature, while removing the field lowers the temperature. A heat pump that operates by polarising the paraelectric, allowing it to return to ambient temperature (by dissipating the extra heat), bringing it into contact with the object to be cooled, and finally depolarising it, would result in refrigeration.\n\n\n== Tunability ==\nTunable dielectrics are insulators whose ability to store electrical charge changes when a voltage is applied.Generally, strontium titanate (SrTiO3) is used for devices operating at low temperatures, while barium strontium titanate (Ba1\u2212xSrxTiO3) substitutes for room temperature devices. Other potential materials include microwave dielectrics and carbon nanotube (CNT) composites.In 2013, multi-sheet layers of strontium titanate interleaved with single layers of strontium oxide produced a dielectric capable of operating at up to 125 GHz. The material was created via molecular beam epitaxy. The two have mismatched crystal spacing that produces strain within the strontium titanate layer that makes it less stable and tunable.Systems such as Ba1\u2212xSrxTiO3 have a paraelectric\u2013ferroelectric transition just below ambient temperature, providing high tunability. Films suffer significant losses arising from defects.\n\n\n== Applications ==\n\n\n=== Capacitors ===\n\nCommercially manufactured capacitors typically use a solid dielectric material with high permittivity as the intervening medium between the stored positive and negative charges. This material is often referred to in technical contexts as the capacitor dielectric.The most obvious advantage to using such a dielectric material is that it prevents the conducting plates, on which the charges are stored, from coming into direct electrical contact. More significantly, however, a high permittivity allows a greater stored charge at a given voltage. This can be seen by treating the case of a linear dielectric with permittivity \u03b5 and thickness d between two conducting plates with uniform charge density \u03c3\u03b5. In this case the charge density is given by\n\nand the capacitance per unit area by\n\nFrom this, it can easily be seen that a larger \u03b5 leads to greater charge stored and thus greater capacitance.\nDielectric materials used for capacitors are also chosen such that they are resistant to ionisation. This allows the capacitor to operate at higher voltages before the insulating dielectric ionises and begins to allow undesirable current.\n\n\n=== Dielectric resonator ===\n\nA dielectric resonator oscillator (DRO) is an electronic component that exhibits resonance of the polarisation response for a narrow range of frequencies, generally in the microwave band. It consists of a \"puck\" of ceramic that has a large dielectric constant and a low dissipation factor. Such resonators are often used to provide a frequency reference in an oscillator circuit. An unshielded dielectric resonator can be used as a dielectric resonator antenna (DRA).\n\n\n=== BST thin films ===\nFrom 2002 to 2004, the United States Army Research Laboratory (ARL) conducted research on thin film technology. Barium strontium titanate (BST), a ferroelectric thin film, was studied for the fabrication of radio frequency and microwave components, such as voltage-controlled oscillators, tunable filters and phase shifters.The research was part of an effort to provide the Army with highly-tunable, microwave-compatible materials for broadband electric-field tunable devices, which operate consistently in extreme temperatures. This work improved tunability of bulk barium strontium titanate, which is a thin film enabler for electronics components.In a 2004 research paper, U.S. ARL researchers explored how small concentrations of acceptor dopants can dramatically modify the properties of ferroelectric materials such as BST.Researchers \"doped\" BST thin films with magnesium, analyzing the \"structure, microstructure, surface morphology and film/substrate compositional quality\" of the result. The Mg doped BST films showed \"improved dielectric properties, low leakage current, and good tunability\", meriting potential for use in microwave tunable devices.\n\n\n== Some practical dielectrics ==\nDielectric materials can be solids, liquids, or gases. (A high vacuum can also be a useful, nearly lossless dielectric even though its relative dielectric constant is only unity.)\nSolid dielectrics are perhaps the most commonly used dielectrics in electrical engineering, and many solids are very good insulators. Some examples include porcelain, glass, and most plastics. Air, nitrogen and sulfur hexafluoride are the three most commonly used gaseous dielectrics.\n\nIndustrial coatings such as Parylene provide a dielectric barrier between the substrate and its environment.\nMineral oil is used extensively inside electrical transformers as a fluid dielectric and to assist in cooling. Dielectric fluids with higher dielectric constants, such as electrical grade castor oil, are often used in high voltage capacitors to help prevent corona discharge and increase capacitance.\nBecause dielectrics resist the flow of electricity, the surface of a dielectric may retain stranded excess electrical charges. This may occur accidentally when the dielectric is rubbed (the triboelectric effect). This can be useful, as in a Van de Graaff generator or electrophorus, or it can be potentially destructive as in the case of electrostatic discharge.\nSpecially processed dielectrics, called electrets (which should not be confused with ferroelectrics), may retain excess internal charge or \"frozen in\" polarisation. Electrets have a semi-permanent electric field, and are the electrostatic equivalent to magnets. Electrets have numerous practical applications in the home and industry.\nSome dielectrics can generate a potential difference when subjected to mechanical stress, or (equivalently) change physical shape if an external voltage is applied across the material. This property is called piezoelectricity. Piezoelectric materials are another class of very useful dielectrics.\nSome ionic crystals and polymer dielectrics exhibit a spontaneous dipole moment, which can be reversed by an externally applied electric field. This behaviour is called the ferroelectric effect. These materials are analogous to the way ferromagnetic materials behave within an externally applied magnetic field. Ferroelectric materials often have very high dielectric constants, making them quite useful for capacitors.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nJackson, John David (10 August 1998) [1962]. Classical Electrodynamics (3rd ed.). John Wiley & Sons. ISBN 978-0-471-30932-1. OCLC 535998.Scaife, Brendan K. P. (3 September 1998). Principles of Dielectrics. Monographs on the Physics & Chemistry of Materials (2nd ed.). Oxford University Press. ISBN 978-0-198-56557-4.\n\n\n== External links ==\nFeynman's lecture on dielectrics\nDielectric Sphere in an Electric Field\nDissemination of IT for the Promotion of Materials Science (DoITPoMS) Teaching and Learning Package \"Dielectric Materials\" from the University of Cambridge\n Texts on Wikisource:\n\"Dielectric\". Encyclopedia Americana. 1920.\n\"Dielectric\". Encyclop\u00e6dia Britannica (11th ed.). 1911.", "Distance": "Distance is a numerical or occasionally qualitative measurement of how far apart objects or points are. In physics or everyday usage, distance may refer to a physical length or an estimation based on other criteria (e.g. \"two counties over\").  Since spatial cognition is a rich source of conceptual metaphors in human thought, the term is also frequently used metaphorically to mean a measurement of the amount of difference between two similar objects (such as statistical distance between probability distributions or edit distance between strings of text) or a degree of separation (as exemplified by distance between people in a social network).  Most such notions of distance, both physical and metaphorical, are formalized in mathematics using the notion of a metric space.\nIn the social sciences, distance can refer to a qualitative measurement of separation, such as social distance or psychological distance.\n\n\n== Distances in physics and geometry ==\nThe distance between physical locations can be defined in different ways in different contexts.\n\n\n=== Straight-line or Euclidean distance ===\n\nThe distance between two points in physical space is the length of a straight line between them, which is the shortest possible path.  This is the usual meaning of distance in classical physics, including Newtonian mechanics. \nStraight-line distance is formalized mathematically as the Euclidean distance in two- and three-dimensional space.  In Euclidean geometry, the distance between two points A and B is often denoted \n  \n    \n      \n        \n          |\n        \n        A\n        B\n        \n          |\n        \n      \n    \n    {\\displaystyle |AB|}\n  .  In coordinate geometry, Euclidean distance is computed using the Pythagorean theorem. The distance between points (x1, y1) and (x2, y2) in the plane is given by:\nSimilarly, given points (x1, y1, z1) and (x2, y2, z2) in three-dimensional space, the distance between them is:\nThis idea generalizes to higher-dimensional Euclidean spaces.\n\n\n==== Measurement ====\n\nThere are many ways of measuring straight-line distances. For example, it can be done directly using a ruler, or indirectly with a radar (for long distances) or interferometry (for very short distances).  The cosmic distance ladder is a set of ways of measuring extremely long distances.\n\n\n=== Shortest-path distance on a curved surface ===\n\nThe straight-line distance between two points on the surface of the Earth is not very useful for most purposes, since we cannot tunnel straight through the Earth's mantle.  Instead, one typically measures the shortest path along the surface of the Earth, as the crow flies.  This is approximated mathematically by the great-circle distance on a sphere.\nMore generally, the shortest path between two points along a curved surface is known as a geodesic.  The arc length of geodesics gives a way of measuring distance from the perspective of an ant or other flightless creature living on that surface.\n\n\n=== Effects of relativity ===\n\nIn the theory of relativity, because of phenomena such as length contraction and the relativity of simultaneity, distances between objects depend on a choice of inertial frame of reference.  On galactic and larger scales, the measurement of distance is also affected by the expansion of the universe.  In practice, a number of distance measures are used in cosmology to quantify such distances.\n\n\n=== Other spatial distances ===\n\nUnusual definitions of distance can be helpful to model certain physical situations, but are also used in theoretical mathematics:\n\nIn practice, one is often interested in the travel distance between two points along roads, rather than as the crow flies.  In a grid plan, the travel distance between street corners is given by the Manhattan distance: the number of east\u2013west and north\u2013south blocks one must traverse to get between those two points.\nChessboard distance, formalized as Chebyshev distance, is the minimum number of moves a king must make on a chessboard in order to travel between two squares.\n\n\n== Metaphorical distances ==\nMany abstract notions of distance used in mathematics, science and engineering represent a degree of difference or separation between similar objects.  This page gives a few examples.\n\n\n=== Statistical distances ===\n\nIn statistics and information geometry, statistical distances measure the degree of difference between two probability distributions.  There are many kinds of statistical distances, typically formalized as divergences; these allow a set of probability distributions to be understood as a geometrical object called a statistical manifold.  The most elementary is the squared Euclidean distance, which is minimized by the least squares method; this is the most basic Bregman divergence. The most important in information theory is the relative entropy (Kullback\u2013Leibler divergence), which allows one to analogously study maximum likelihood estimation geometrically; this is an example of both an f-divergence and a Bregman divergence (and in fact the only example which is both). Statistical manifolds corresponding to Bregman divergences are flat manifolds in the corresponding geometry, allowing an analog of the Pythagorean theorem (which holds for squared Euclidean distance) to be used for linear inverse problems in inference by optimization theory.\nOther important statistical distances include the Mahalanobis distance and the energy distance.\n\n\n=== Edit distances ===\nIn computer science, an edit distance or string metric between two strings measures how different they are. For example, the words \"dog\" and \"dot\", which differ by just one letter, are closer than \"dog\" and \"cat\", which have no letters in common.  This idea is used in spell checkers and in coding theory, and is mathematically formalized in a number of different ways, including Levenshtein distance, Hamming distance, Lee distance, and Jaro\u2013Winkler distance.\n\n\n=== Distance in graph theory ===\n\nIn a graph, the distance between two vertices is measured by the length of the shortest edge path between them.  For example, if the graph represents a social network, then the idea of six degrees of separation can be interpreted mathematically as saying that the distance between any two vertices is at most six.  Similarly, the Erd\u0151s number and the Bacon number\u2014the number of collaborative relationships away a person is from prolific mathematician Paul Erd\u0151s and actor Kevin Bacon, respectively\u2014are distances in the graphs whose edges represent mathematical or artistic collaborations.\n\n\n=== In the social sciences ===\nIn psychology, human geography, and the social sciences, distance is often theorized not as an objective numerical measurement, but as a qualitative description of a subjective experience.  For example, psychological distance is \"the different ways in which an object might be removed from\" the self along dimensions such as \"time, space, social distance, and hypotheticality\".  In sociology, social distance describes the separation between individuals or social groups in society along dimensions such as social class, race/ethnicity, gender or sexuality.\n\n\n== Mathematical formalization ==\n\nMost of the notions of distance between two points or objects described above are examples of the mathematical idea of a metric.  A metric or distance function is a function d which takes pairs of points or objects to real numbers and satisfies the following rules:\n\nThe distance between an object and itself is always zero.\nThe distance between distinct objects is always positive.\nDistance is symmetric: the distance from x to y is always the same as the distance from y to x.\nDistance satisfies the triangle inequality: if x, y, and z are three objects, then  This condition can be described informally as \"intermediate stops can't speed you up.\"As an exception, many of the divergences used in statistics are not metrics.\n\n\n== Distance between sets ==\n\nThere are multiple ways of measuring the physical distance between objects that consist of more than one point:\n\nOne may measure the distance between representative points such as the center of mass; this is used for astronomical distances such as the Earth\u2013Moon distance.\nOne may measure the distance between the closest points of the two objects; in this sense, the altitude of an airplane or spacecraft is its distance from the Earth.  The same sense of distance is used in Euclidean geometry to define distance from a point to a line, distance from a point to a plane, or, more generally, perpendicular distance between affine subspaces.Even more generally, this idea can be used to define the distance between two subsets of a metric space.  The distance between sets A and B is the infimum of the distances between any two of their respective points: This does not define a metric on the set of such subsets: the distance between overlapping sets is zero, and this distance does not satisfy the triangle inequality for any metric space with two or more points (consider the triple of sets consisting of two distinct singletons and their union).The Hausdorff distance between two subsets of a metric space can be thought of as measuring how far they are from perfectly overlapping.  Somewhat more precisely, the Hausdorff distance between A and B is either the distance from A to the farthest point of B, or the distance from B to the farthest point of A, whichever is larger.  (Here \"farthest point\" must be interpreted as a supremum.)  The Hausdorff distance defines a metric on the set of compact subsets of a metric space.\n\n\n== Related ideas ==\n\nThe word distance is also used for related concepts that are not encompassed by the description \"a numerical measurement of how far apart points or objects are\".\n\n\n=== Distance travelled ===\nThe distance travelled by an object is the length of a specific path travelled between two points, such as the distance walked while navigating a maze.  This can even be a closed distance along a closed curve which starts and ends at the same point, such as a ball thrown straight up, or the Earth when it completes one orbit.  This is formalized mathematically as the arc length of the curve.\nThe distance travelled may also be signed: a \"forward\" distance is positive and a \"backward\" distance is negative.\nCircular distance is the distance traveled by a point on the circumference of a wheel, which can be useful to consider when designing vehicles or mechanical gears (see also odometry). The circumference of the wheel is 2\u03c0 \u00d7 radius; if the radius is 1, each revolution of the wheel causes a vehicle to travel 2\u03c0 radians.\n\n\n=== Displacement and directed distance ===\n\nThe displacement in classical physics measures the change in position of an object during an interval of time.  While distance is a scalar quantity, or a magnitude, displacement is a vector quantity with both magnitude and direction.  In general, the vector measuring the difference between two locations (the relative position) is sometimes called the directed distance.  For example, the directed distance from the New York City Main Library flag pole to the Statue of Liberty flag pole has: \n\nA starting point: library flag pole\nAn ending point: statue flag pole\nA direction: -38\u00b0\nA distance: 8.72 km\n\n\n=== Signed distance ===\n\n\n== See also ==\n\n\n== Library support ==\nPython (programming language)\nInterspace -A package for finding the distance between two vectors, numbers and strings.\nSciPy -Distance computations (scipy.spatial.distance)\nJulia (programming language)\nJulia Statistics Distance -A Julia package for evaluating distances (metrics) between vectors.\n\n\n== References ==\n\n\n== Bibliography ==\nDeza E, Deza M (2006). Dictionary of Distances. Elsevier. ISBN 0-444-52087-2.", "Elastic_collision": "In physics, an elastic collision is an encounter (collision) between two bodies  in which the total kinetic energy of the two bodies remains the same. In an ideal, perfectly elastic collision, there is no net conversion of kinetic energy into other forms such as heat, noise, or potential energy.\nDuring the collision of small objects, kinetic energy is first converted to potential energy associated with a repulsive or attractive force between the particles (when the particles move against this force, i.e. the angle between the force and the relative velocity is obtuse), then this potential energy is converted back to kinetic energy (when the particles move with this force, i.e. the angle between the force and the relative velocity is acute).\nCollisions of atoms are elastic, for example Rutherford backscattering.\nA useful special case of elastic collision is when the two bodies have equal mass, in which case they will simply exchange their momenta.\nThe molecules\u2014as distinct from atoms\u2014of a gas or liquid rarely experience perfectly elastic collisions because kinetic energy is exchanged between the molecules\u2019 translational motion and their internal degrees of freedom with each collision. At any instant, half the collisions are, to a varying extent, inelastic collisions (the pair possesses less kinetic energy in their translational motions after the collision than before), and half could be described as \u201csuper-elastic\u201d (possessing more kinetic energy after the collision than before). Averaged across the entire sample, molecular collisions can be regarded as essentially elastic as long as Planck's law forbids energy from being carried away by black-body photons.\nIn the case of macroscopic bodies, perfectly elastic collisions are an ideal never fully realized, but approximated by the interactions of objects such as billiard balls.\nWhen considering energies, possible rotational energy before and/or after a collision may also play a role.  \n\n\n== Equations ==\n\n\n=== One-dimensional Newtonian ===\n\nIn an elastic collision, both momentum and kinetic energy are conserved. Consider particles 1 and 2 with masses m1, m2, and velocities u1, u2 before collision, v1, v2 after collision. The conservation of the total momentum before and after the collision is expressed by:\nLikewise, the conservation of the total kinetic energy is expressed by:\nThese equations may be solved directly to find \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{1},v_{2}}\n   when \n  \n    \n      \n        \n          u\n          \n            1\n          \n        \n        ,\n        \n          u\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle u_{1},u_{2}}\n   are known:\nIf both masses are the same, we have a trivial solution:\n\nThis simply corresponds to the bodies exchanging their initial velocities to each other.As can be expected, the solution is invariant under adding a constant to all velocities (Galilean relativity), which is like using a frame of reference with constant translational velocity. Indeed, to derive the equations, one may first change the frame of reference so that one of the known velocities is zero, determine the unknown velocities in the new frame of reference, and convert back to the original frame of reference.\n\n\n==== Examples ====\nBefore collision\n\nBall 1: mass = 3 kg,       velocity = 4 m/s\nBall 2: mass = 5 kg,       velocity = \u22126 m/s\nAfter collision\n\nBall 1: velocity = \u22128.5 m/s\nBall 2: velocity = 1.5 m/sAnother situation:\n\nThe following illustrate the case of equal mass, \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        =\n        \n          m\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{1}=m_{2}}\n  .\n\nIn the limiting case where \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle m_{1}}\n   is much larger than \n  \n    \n      \n        \n          m\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{2}}\n  , such as a ping-pong paddle hitting a ping-pong ball or an SUV hitting a trash can, the heavier mass hardly changes velocity, while the lighter mass bounces off, reversing its velocity plus approximately twice that of the heavy one.In the case of a large \n  \n    \n      \n        \n          u\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle u_{1}}\n  , the value of \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   is small if the masses are approximately the same: hitting a much lighter particle does not change the velocity much, hitting a much heavier particle causes the fast particle to bounce back with high speed. This is why a neutron moderator (a medium which slows down fast neutrons, thereby turning them into thermal neutrons capable of sustaining a chain reaction) is a material full of atoms with light nuclei which do not easily absorb neutrons: the lightest nuclei have about the same mass as a neutron.\n\n\n==== Derivation of solution ====\nTo derive the above equations for \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle v_{1},v_{2},}\n   rearrange the kinetic energy and momentum equations:\n\nDividing each side of the top equation by each side of the bottom equation, and using \n  \n    \n      \n        \n          \n            \n              \n                \n                  a\n                  \n                    2\n                  \n                \n                \u2212\n                \n                  b\n                  \n                    2\n                  \n                \n              \n              \n                (\n                a\n                \u2212\n                b\n                )\n              \n            \n          \n        \n        =\n        a\n        +\n        b\n        ,\n      \n    \n    {\\displaystyle {\\tfrac {a^{2}-b^{2}}{(a-b)}}=a+b,}\n   gives:\n\nThat is, the relative velocity of one particle with respect to the other is reversed by the collision. \nNow the above formulas follow from solving a system of linear equations for \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle v_{1},v_{2},}\n   regarding \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        ,\n        \n          m\n          \n            2\n          \n        \n        ,\n        \n          u\n          \n            1\n          \n        \n        ,\n        \n          u\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{1},m_{2},u_{1},u_{2}}\n   as constants:\n\nOnce \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   is determined, \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{2}}\n   can be found by symmetry.\n\n\n==== Center of mass frame ====\nWith respect to the center of mass, both velocities are reversed by the collision: a heavy particle moves slowly toward the center of mass, and bounces back with the same low speed, and a light particle moves fast toward the center of mass, and bounces back with the same high speed.\nThe velocity of the center of mass does not change by the collision. To see this, consider the center of mass at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   before collision and time \n  \n    \n      \n        \n          t\n          \u2032\n        \n      \n    \n    {\\displaystyle t'}\n   after collision:\n\nHence, the velocities of the center of mass before and after collision are:\n\nThe numerators of \n  \n    \n      \n        \n          v\n          \n            \n              \n                x\n                \u00af\n              \n            \n          \n        \n      \n    \n    {\\displaystyle v_{\\bar {x}}}\n   and  \n  \n    \n      \n        \n          v\n          \n            \n              \n                x\n                \u00af\n              \n            \n          \n          \u2032\n        \n      \n    \n    {\\displaystyle v_{\\bar {x}}'}\n   are the total momenta before and after collision. Since momentum is conserved, we have \n  \n    \n      \n        \n          v\n          \n            \n              \n                x\n                \u00af\n              \n            \n          \n        \n        =\n        \n          v\n          \n            \n              \n                x\n                \u00af\n              \n            \n          \n          \u2032\n        \n        \n        .\n      \n    \n    {\\displaystyle v_{\\bar {x}}=v_{\\bar {x}}'\\,.}\n  \n\n\n=== One-dimensional relativistic ===\nAccording to special relativity,\n\nwhere p denotes momentum of any particle with mass, v denotes velocity, and c is the speed of light.\nIn the center of momentum frame where the total momentum equals zero, \n\nHere \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        ,\n        \n          m\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{1},m_{2}}\n   represent the rest masses of the two colliding bodies, \n  \n    \n      \n        \n          u\n          \n            1\n          \n        \n        ,\n        \n          u\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle u_{1},u_{2}}\n   represent their velocities before collision, \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{1},v_{2}}\n   their velocities after collision, \n  \n    \n      \n        \n          p\n          \n            1\n          \n        \n        ,\n        \n          p\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle p_{1},p_{2}}\n   their momenta, \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the speed of light in vacuum, and \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   denotes the total energy, the sum of rest masses and kinetic energies of the two bodies.\nSince the total energy and momentum of the system are conserved and their rest masses do not change, it is shown that the momentum of the colliding body is decided by the rest masses of the colliding bodies, total energy and the total momentum.  Relative to the center of momentum frame, the momentum of each colliding body does not change magnitude after collision, but reverses its direction of movement.\nComparing with classical mechanics, which gives accurate results dealing with macroscopic objects moving much slower than the speed of light, total momentum of the two colliding bodies is frame-dependent. In the center of momentum frame, according to classical mechanics,\n\nThis agrees with the relativistic calculation \n  \n    \n      \n        \n          u\n          \n            1\n          \n        \n        =\n        \u2212\n        \n          v\n          \n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle u_{1}=-v_{1},}\n   despite other differences. \nOne of the postulates in Special Relativity states that the laws of physics, such as conservation of momentum, should be invariant in all inertial frames of reference. In a general inertial frame where the total momentum could be arbitrary,\n\nWe can look at the two moving bodies as one system of which the total momentum is \n  \n    \n      \n        \n          p\n          \n            T\n          \n        \n        ,\n      \n    \n    {\\displaystyle p_{T},}\n   the total energy is \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   and its velocity \n  \n    \n      \n        \n          v\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle v_{c}}\n   is the velocity of its center of mass. Relative to the center of momentum frame the total momentum equals zero. It can be shown that \n  \n    \n      \n        \n          v\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle v_{c}}\n   is given by:\n\nNow the velocities before the collision in the center of momentum frame \n  \n    \n      \n        \n          u\n          \n            1\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle u_{1}'}\n   and \n  \n    \n      \n        \n          u\n          \n            2\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle u_{2}'}\n   are:\n\nWhen \n  \n    \n      \n        \n          u\n          \n            1\n          \n        \n        \u226a\n        c\n      \n    \n    {\\displaystyle u_{1}\\ll c}\n   and \n  \n    \n      \n        \n          u\n          \n            2\n          \n        \n        \u226a\n        c\n        \n        ,\n      \n    \n    {\\displaystyle u_{2}\\ll c\\,,}\n  \n\nTherefore, the classical calculation holds true when the speed of both colliding bodies is much lower than the speed of light (~300,000 kilometres per second).\n\n\n=== Relativistic derivation using hyperbolic functions ===\nUsing the so-called parameter of velocity \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   (usually called the rapidity),\n\nwe get\n\nRelativistic energy and momentum are expressed as follows:\n\nEquations sum of energy and momentum colliding masses \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle m_{1}}\n   and \n  \n    \n      \n        \n          m\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle m_{2},}\n   (velocities \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n        \n          u\n          \n            1\n          \n        \n        ,\n        \n          u\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{1},v_{2},u_{1},u_{2}}\n   correspond to the velocity parameters \n  \n    \n      \n        \n          s\n          \n            1\n          \n        \n        ,\n        \n          s\n          \n            2\n          \n        \n        ,\n        \n          s\n          \n            3\n          \n        \n        ,\n        \n          s\n          \n            4\n          \n        \n      \n    \n    {\\displaystyle s_{1},s_{2},s_{3},s_{4}}\n  ), after dividing by adequate power \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   are as follows:\n\nand dependent equation, the sum of above equations:\n\nsubtract squares both sides equations \"momentum\" from \"energy\" and use the identity \n  \n    \n      \n        \n          cosh\n          \n            2\n          \n        \n        \u2061\n        (\n        s\n        )\n        \u2212\n        \n          sinh\n          \n            2\n          \n        \n        \u2061\n        (\n        s\n        )\n        =\n        1\n        ,\n      \n    \n    {\\textstyle \\cosh ^{2}(s)-\\sinh ^{2}(s)=1,}\n   after simplifying we get:\n\nfor non-zero mass, using the hyperbolic trigonometric identity \n  \n    \n      \n        cosh\n        \u2061\n        (\n        a\n        \u2212\n        b\n        )\n        =\n        cosh\n        \u2061\n        (\n        a\n        )\n        cosh\n        \u2061\n        (\n        b\n        )\n        \u2212\n        sinh\n        \u2061\n        (\n        b\n        )\n        sinh\n        \u2061\n        (\n        a\n        )\n        ,\n      \n    \n    {\\textstyle \\cosh(a-b)=\\cosh(a)\\cosh(b)-\\sinh(b)\\sinh(a),}\n   we get:\n\nas functions \n  \n    \n      \n        cosh\n        \u2061\n        (\n        s\n        )\n      \n    \n    {\\displaystyle \\cosh(s)}\n   is even we get two solutions:\n\nfrom the last equation, leading to a non-trivial solution, we solve \n  \n    \n      \n        \n          s\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle s_{2}}\n   and substitute into the dependent equation, we obtain \n  \n    \n      \n        \n          e\n          \n            \n              s\n              \n                1\n              \n            \n          \n        \n      \n    \n    {\\displaystyle e^{s_{1}}}\n   and then \n  \n    \n      \n        \n          e\n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle e^{s_{2}},}\n   we have:\n\nIt is a solution to the problem, but expressed by the parameters of velocity. Return substitution to get the solution for velocities is:\n\nSubstitute the previous solutions and replace:\n\n  \n    \n      \n        \n          e\n          \n            \n              s\n              \n                3\n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                c\n                +\n                \n                  u\n                  \n                    1\n                  \n                \n              \n              \n                c\n                \u2212\n                \n                  u\n                  \n                    1\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle e^{s_{3}}={\\sqrt {\\frac {c+u_{1}}{c-u_{1}}}}}\n   and \n  \n    \n      \n        \n          e\n          \n            \n              s\n              \n                4\n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                c\n                +\n                \n                  u\n                  \n                    2\n                  \n                \n              \n              \n                c\n                \u2212\n                \n                  u\n                  \n                    2\n                  \n                \n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle e^{s_{4}}={\\sqrt {\\frac {c+u_{2}}{c-u_{2}}}},}\n   after long transformation, with substituting:\n\n  \n    \n      \n        Z\n        =\n        \n          \n            \n              (\n              \n                1\n                \u2212\n                \n                  u\n                  \n                    1\n                  \n                  \n                    2\n                  \n                \n                \n                  /\n                \n                \n                  c\n                  \n                    2\n                  \n                \n              \n              )\n            \n            \n              (\n              \n                1\n                \u2212\n                \n                  u\n                  \n                    2\n                  \n                  \n                    2\n                  \n                \n                \n                  /\n                \n                \n                  c\n                  \n                    2\n                  \n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\textstyle Z={\\sqrt {\\left(1-u_{1}^{2}/c^{2}\\right)\\left(1-u_{2}^{2}/c^{2}\\right)}}}\n  \nwe get:\n\n\n== Two-dimensional ==\nFor the case of two non-spinning colliding bodies in two dimensions, the motion of the bodies is determined by the three conservation laws of momentum, kinetic energy and angular momentum. The overall velocity of each body must be split into two perpendicular velocities: one tangent to the common normal surfaces of the colliding bodies at the point of contact, the other along the line of collision. Since the collision only imparts force along the line of collision, the velocities that are tangent to the point of collision do not change.  The velocities along the line of collision can then be used in the same equations as a one-dimensional collision. The final velocities can then be calculated from the two new component velocities and will depend on the point of collision.  Studies of two-dimensional collisions are conducted for many bodies in the framework of a two-dimensional gas.\n\nIn a center of momentum frame at any time the velocities of the two bodies are in opposite directions, with magnitudes inversely proportional to the masses. In an elastic collision these magnitudes do not change. The directions may change depending on the shapes of the bodies and the point of impact. For example, in the case of spheres the angle depends on the distance between the (parallel) paths of the centers of the two bodies. Any non-zero change of direction is possible: if this distance is zero the velocities are reversed in the collision; if it is close to the sum of the radii of the spheres the two bodies are only slightly deflected.\nAssuming that the second particle is at rest before the collision, the angles of deflection of the two particles, \n  \n    \n      \n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\theta _{1}}\n   and \n  \n    \n      \n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta _{2}}\n  , are related to the angle of deflection \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   in the system of the center of mass by\nThe magnitudes of the velocities of the particles after the collision are:\n\n\n=== Two-dimensional collision with two moving objects ===\nThe final x and y velocities components of the first ball can be calculated as:\nwhere v1 and v2 are the scalar sizes of the two original speeds of the objects, m1 and m2 are their masses, \u03b81 and \u03b82 are their movement angles, that is, \n  \n    \n      \n        \n          v\n          \n            1\n            x\n          \n        \n        =\n        \n          v\n          \n            1\n          \n        \n        cos\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        ,\n        \n        \n          v\n          \n            1\n            y\n          \n        \n        =\n        \n          v\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1x}=v_{1}\\cos \\theta _{1},\\;v_{1y}=v_{1}\\sin \\theta _{1}}\n   (meaning moving directly down to the right is either a \u221245\u00b0 angle, or a 315\u00b0 angle), and lowercase phi (\u03c6) is the contact angle. (To get the x and y velocities of the second ball, one needs to swap all the '1' subscripts with '2' subscripts.)\nThis equation is derived from the fact that the interaction between the two bodies is easily calculated along the contact angle, meaning the velocities of the objects can be calculated in one dimension by rotating the x and y axis to be parallel with the contact angle of the objects, and then rotated back to the original orientation to get the true x and y components of the velocities.In an angle-free representation, the changed velocities are computed using the centers x1 and x2 at the time of contact as\n\nwhere the angle brackets indicate the inner product (or dot product) of two vectors.\n\n\n=== Other conserved quantities ===\nIn the particular case of particles having equal masses, it can be verified by direct computation from the result above that the scalar product of the velocities before and after the collision are the same, that is \n  \n    \n      \n        \u27e8\n        \n          \n            v\n          \n          \n            1\n          \n          \u2032\n        \n        ,\n        \n          \n            v\n          \n          \n            2\n          \n          \u2032\n        \n        \u27e9\n        =\n        \u27e8\n        \n          \n            v\n          \n          \n            1\n          \n        \n        ,\n        \n          \n            v\n          \n          \n            2\n          \n        \n        \u27e9\n        .\n      \n    \n    {\\displaystyle \\langle \\mathbf {v} '_{1},\\mathbf {v} '_{2}\\rangle =\\langle \\mathbf {v} _{1},\\mathbf {v} _{2}\\rangle .}\n   Although this product is not an additive invariant in the same way that momentum and kinetic energy are for elastic collisions, it seems that preservation of this quantity can nonetheless be used to derive higher-order conservation laws.\n\n\n== See also ==\nCollision\nInelastic collision\nCoefficient of restitution\n\n\n== References ==\n\n\n=== General references ===\nLandau, L. D.; Lifshitz, E. M. (1976). Mechanics (3rd ed.). Pergamon Press. ISBN 0-08-021022-8.\nRaymond, David J. \"10.4.1 Elastic collisions\". A Radically Modern Approach to Introductory Physics. Vol. 1: Fundamental Principles. Socorro, New Mexico: New Mexico Tech Press. ISBN 978-0-9830394-5-7.\nSerway, Raymond A.; Jewett, John W. (2014). \"9: Linear Momentum and Collisions\". Physics for scientists and engineers with modern physics (9th ed.). Boston. ISBN 978-1-133-95405-7.\n\n\n== External links ==\nRigid Body Collision Resolution in three dimensions including a derivation using the conservation laws", "Electrostatics": "Electrostatics is a branch of physics that studies electric charges at rest (static electricity).\nSince classical times, it has been known that some materials, such as amber, attract lightweight particles after rubbing. The Greek word for amber, \u1f24\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd (\u1e17lektron), was thus the source of the word 'electricity'. Electrostatic phenomena arise from the forces that electric charges exert on each other. Such forces are described by Coulomb's law.\nEven though electrostatically induced forces seem to be rather weak, some electrostatic forces are relatively large. The force between an electron and a proton, which together make up a hydrogen atom, is about 36 orders of magnitude stronger than the gravitational force acting between them.\nThere are many examples of electrostatic phenomena, from those as simple as the attraction of plastic wrap to one's hand after it is removed from a package, to the apparently spontaneous explosion of grain silos, the damage of electronic components during manufacturing, and photocopier & laser printer operation. Electrostatics involves the buildup of charge on the surface of objects due to contact with other surfaces. Although charge exchange happens whenever any two surfaces contact and separate, the effects of charge exchange are usually noticed only when at least one of the surfaces has a high resistance to electrical flow, because the charges that transfer are trapped there for a long enough time for their effects to be observed. These charges then remain on the object until they either bleed off to ground, or are quickly neutralized by a discharge. The familiar phenomenon of a static \"shock\" is caused by the neutralization of charge built up in the body from contact with insulated surfaces.\n\n\n== Coulomb's law ==\n\nCoulomb's law states that:\n'The magnitude of the electrostatic force of attraction or repulsion between two point charges is directly proportional to the product of the magnitudes of charges and inversely proportional to the square of the distance between them.'\nThe force is along the straight line joining them. If the two charges have the same sign, the electrostatic force between them is repulsive; if they have different signs, the force between them is attractive.\nIf \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the distance (in meters) between two charges, then the force (in newtons) between two point charges \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   and \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   (in coulombs) is:\n\n  \n    \n      \n        F\n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \n            \n              q\n              Q\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        =\n        \n          k\n          \n            0\n          \n        \n        \n          \n            \n              q\n              Q\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n        ,\n      \n    \n    {\\displaystyle F={\\frac {1}{4\\pi \\varepsilon _{0}}}{\\frac {qQ}{r^{2}}}=k_{0}{\\frac {qQ}{r^{2}}}\\,,}\n  where \u03b50 is the vacuum permittivity, or permittivity of free space:\n\n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n        \u2248\n        \n          8.854\n           \n          187\n           \n          817\n          \u00d7\n          \n            10\n            \n              \u2212\n              12\n            \n          \n           \n          \n            C\n            \n              2\n            \n          \n          \n            \u22c5\n          \n          \n            N\n            \n              \u2212\n              1\n            \n          \n          \n            \u22c5\n          \n          \n            m\n            \n              \u2212\n              2\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\varepsilon _{0}\\approx \\mathrm {8.854\\ 187\\ 817\\times 10^{-12}~C^{2}{\\cdot }N^{-1}{\\cdot }m^{-2}} .}\n  The SI units of \u03b50 are equivalently A2\u22c5s4 \u22c5kg\u22121\u22c5m\u22123 or C2\u22c5N\u22121\u22c5m\u22122 or F\u22c5m\u22121. The Coulomb constant is:\n\n  \n    \n      \n        \n          k\n          \n            e\n          \n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \u2248\n        \n          8.987\n           \n          551\n           \n          792\n          \u00d7\n          \n            10\n            \n              9\n            \n          \n           \n          N\n          \n            \u22c5\n          \n          \n            m\n            \n              2\n            \n          \n          \n            \u22c5\n          \n          \n            C\n            \n              \u2212\n              2\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle k_{\\text{e}}={\\frac {1}{4\\pi \\varepsilon _{0}}}\\approx \\mathrm {8.987\\ 551\\ 792\\times 10^{9}~N{\\cdot }m^{2}{\\cdot }C^{-2}} .}\n  A single proton has a charge of e, and the electron has a charge of \u2212e, where,\n\n  \n    \n      \n        e\n        =\n        \n          1.602\n           \n          176\n           \n          634\n          \u00d7\n          \n            10\n            \n              \u2212\n              19\n            \n          \n           \n          C\n        \n        .\n      \n    \n    {\\displaystyle e=\\mathrm {1.602\\ 176\\ 634\\times 10^{-19}~C} .}\n  These physical constants (\u03b50, k0, e) are currently defined so that e is exactly defined, and \u03b50 and k0 are measured quantities.\n\n\n== Electric field ==\n\nThe electric field, \n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {E}}}\n  , in units of newtons per coulomb or volts per meter, is a vector field that can be defined everywhere, except at the location of point charges (where it diverges to infinity). It is defined as the electrostatic force \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        \n      \n    \n    {\\displaystyle {\\vec {F}}\\,}\n   in newtons on a hypothetical small test charge at the point due to Coulomb's Law, divided by the magnitude of the charge \n  \n    \n      \n        q\n        \n      \n    \n    {\\displaystyle q\\,}\n   in coulombs\n\n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            q\n          \n        \n      \n    \n    {\\displaystyle {\\vec {E}}={{\\vec {F}} \\over q}}\n  Electric field lines are useful for visualizing the electric field. Field lines begin on positive charge and terminate on negative charge. They are parallel to the direction of the electric field at each point, and the density of these field lines is a measure of the magnitude of the electric field at any given point.\nConsider a collection of \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   particles of charge \n  \n    \n      \n        \n          Q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle Q_{i}}\n  , located at points \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}_{i}}\n   (called source points), the electric field at \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   (called the field point) is:\n\n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        R\n                      \n                      ^\n                    \n                  \n                \n                \n                  i\n                \n              \n              \n                Q\n                \n                  i\n                \n              \n            \n            \n              \n                \u2016\n                \n                  \n                    \n                      \n                        \n                          R\n                          \u2192\n                        \n                      \n                    \n                  \n                  \n                    i\n                  \n                \n                \u2016\n              \n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\vec {E}}({\\vec {r}})={\\frac {1}{4\\pi \\varepsilon _{0}}}\\sum _{i=1}^{N}{\\frac {{\\widehat {\\mathcal {R}}}_{i}Q_{i}}{\\left\\|{\\mathcal {\\vec {R}}}_{i}\\right\\|^{2}}},}\n  where \n  \n    \n      \n        \n          \n            \n              \n                \n                  R\n                \n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u2212\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\vec {\\mathcal {R}}}_{i}={\\vec {r}}-{\\vec {r}}_{i},}\n   is the displacement vector from a source point \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}_{i}}\n   to the field point \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n  , and \n  \n    \n      \n        \n          \n            \n              \n                \n                  R\n                \n                ^\n              \n            \n          \n          \n            i\n          \n        \n        =\n        \n          \n            \n              \n                \n                  R\n                \n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n        \n          /\n        \n        \n          \u2016\n          \n            \n              \n                \n                  \n                    R\n                  \n                  \u2192\n                \n              \n            \n            \n              i\n            \n          \n          \u2016\n        \n      \n    \n    {\\displaystyle {\\widehat {\\mathcal {R}}}_{i}={\\vec {\\mathcal {R}}}_{i}/\\left\\|{\\vec {\\mathcal {R}}}_{i}\\right\\|}\n  \nis a unit vector that indicates the direction of the field. For a single point charge at the origin, the magnitude of this electric field is \n  \n    \n      \n        E\n        =\n        \n          k\n          \n            e\n          \n        \n        Q\n        \n          /\n        \n        \n          \n            \n              R\n            \n          \n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle E=k_{\\text{e}}Q/{\\mathcal {R}}^{2},}\n   and points away from that charge if it is positive. The fact that the force (and hence the field) can be calculated by summing over all the contributions due to individual source particles is an example of the superposition principle. The electric field produced by a distribution of charges is given by the volume charge density \n  \n    \n      \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\rho ({\\vec {r}})}\n   and can be obtained by converting this sum into a triple integral:\n\n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \u222d\n        \n          \n            \n              \n                \n                  \n                    r\n                    \u2192\n                  \n                \n              \n              \u2212\n              \n                \n                  \n                    r\n                    \u2192\n                  \n                \n              \n              \n                \n                \u2032\n              \n            \n            \n              \n                \u2016\n                \n                  \n                    \n                      \n                        r\n                        \u2192\n                      \n                    \n                  \n                  \u2212\n                  \n                    \n                      \n                        r\n                        \u2192\n                      \n                    \n                  \n                  \n                    \n                    \u2032\n                  \n                \n                \u2016\n              \n              \n                3\n              \n            \n          \n        \n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \n          \n          \u2032\n        \n        )\n        \n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n        \n          \n          \u2032\n        \n      \n    \n    {\\displaystyle {\\vec {E}}({\\vec {r}})={\\frac {1}{4\\pi \\varepsilon _{0}}}\\iiint {\\frac {{\\vec {r}}-{\\vec {r}}\\,'}{\\left\\|{\\vec {r}}-{\\vec {r}}\\,'\\right\\|^{3}}}\\rho ({\\vec {r}}\\,')\\,\\mathrm {d} ^{3}r\\,'}\n  \n\n\n=== Gauss' law ===\nGauss' law states that \"the total electric flux through any closed surface in free space of any shape drawn in an electric field is proportional to the total electric charge enclosed by the surface.\" Mathematically, Gauss's law takes the form of an integral equation:\n\n  \n    \n      \n        \n          \u222e\n          \n            S\n          \n        \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              A\n              \u2192\n            \n          \n        \n        =\n        \n          \n            1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n        \n        \n          Q\n          \n            enclosed\n          \n        \n        =\n        \n          \u222b\n          \n            V\n          \n        \n        \n          \n            \u03c1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n        \u22c5\n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n        ,\n      \n    \n    {\\displaystyle \\oint _{S}{\\vec {E}}\\cdot \\mathrm {d} {\\vec {A}}={\\frac {1}{\\varepsilon _{0}}}\\,Q_{\\text{enclosed}}=\\int _{V}{\\rho  \\over \\varepsilon _{0}}\\cdot \\mathrm {d} ^{3}r,}\n  where \n  \n    \n      \n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n        =\n        \n          d\n        \n        x\n         \n        \n          d\n        \n        y\n         \n        \n          d\n        \n        z\n      \n    \n    {\\displaystyle \\mathrm {d} ^{3}r=\\mathrm {d} x\\ \\mathrm {d} y\\ \\mathrm {d} z}\n   is a volume element. If the charge is distributed over a surface or along a line, replace \n  \n    \n      \n        \u03c1\n        \n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n      \n    \n    {\\displaystyle \\rho \\,\\mathrm {d} ^{3}r}\n   by \n  \n    \n      \n        \u03c3\n        \n        \n          d\n        \n        A\n      \n    \n    {\\displaystyle \\sigma \\,\\mathrm {d} A}\n   or \n  \n    \n      \n        \u03bb\n        \n        \n          d\n        \n        \u2113\n      \n    \n    {\\displaystyle \\lambda \\,\\mathrm {d} \\ell }\n  . The divergence theorem allows Gauss's Law to be written in differential form:\n\n  \n    \n      \n        \n          \n            \n              \u2207\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        =\n        \n          \n            \u03c1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\vec {\\nabla }}\\cdot {\\vec {E}}={\\rho  \\over \\varepsilon _{0}}.}\n  where \n  \n    \n      \n        \n          \n            \n              \u2207\n              \u2192\n            \n          \n        \n        \u22c5\n      \n    \n    {\\displaystyle {\\vec {\\nabla }}\\cdot }\n   is the divergence operator.\n\n\n=== Poisson and Laplace equations ===\nThe definition of electrostatic potential, combined with the differential form of Gauss's law (above), provides a relationship between the potential \u03a6 and the charge density \u03c1:\n\n  \n    \n      \n        \n          \n            \u2207\n          \n          \n            2\n          \n        \n        \u03d5\n        =\n        \u2212\n        \n          \n            \u03c1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\nabla }^{2}\\phi =-{\\rho  \\over \\varepsilon _{0}}.}\n  This relationship is a form of Poisson's equation. In the absence of unpaired electric charge, the equation becomes Laplace's equation:\n\n  \n    \n      \n        \n          \n            \u2207\n          \n          \n            2\n          \n        \n        \u03d5\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle {\\nabla }^{2}\\phi =0,}\n  \n\n\n== Electrostatic approximation ==\nThe validity of the electrostatic approximation rests on the assumption that the electric field is irrotational:\n\n  \n    \n      \n        \n          \n            \n              \u2207\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        =\n        0.\n      \n    \n    {\\displaystyle {\\vec {\\nabla }}\\times {\\vec {E}}=0.}\n  From Faraday's law, this assumption implies the absence or near-absence of time-varying magnetic fields:\n\n  \n    \n      \n        \n          \n            \n              \u2202\n              \n                \n                  \n                    B\n                    \u2192\n                  \n                \n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n        =\n        0.\n      \n    \n    {\\displaystyle {\\partial {\\vec {B}} \\over \\partial t}=0.}\n  In other words, electrostatics does not require the absence of magnetic fields or electric currents. Rather, if magnetic fields or electric currents do exist, they must not change with time, or in the worst-case, they must change with time only very slowly. In some problems, both electrostatics and magnetostatics may be required for accurate predictions, but the coupling between the two can still be ignored. Electrostatics and magnetostatics can both be seen as Galilean limits for electromagnetism.\n\n\n=== Electrostatic potential ===\nAs the electric field is irrotational, it is possible to express the electric field as the gradient of a scalar function, \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n  , called the electrostatic potential (also known as the voltage). An electric field, \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  , points from regions of high electric potential to regions of low electric potential, expressed mathematically as\n\n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              \u2207\n              \u2192\n            \n          \n        \n        \u03d5\n        .\n      \n    \n    {\\displaystyle {\\vec {E}}=-{\\vec {\\nabla }}\\phi .}\n  The gradient theorem can be used to establish that the electrostatic potential     is the amount of work per unit charge required to move a charge from point \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   to point \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n   with the following line integral:\n\n  \n    \n      \n        \u2212\n        \n          \u222b\n          \n            a\n          \n          \n            b\n          \n        \n        \n          \n            \n              \n                E\n                \u2192\n              \n            \n          \n          \u22c5\n          \n            d\n          \n          \n            \n              \n                \u2113\n                \u2192\n              \n            \n          \n        \n        =\n        \u03d5\n        (\n        \n          \n            \n              b\n              \u2192\n            \n          \n        \n        )\n        \u2212\n        \u03d5\n        (\n        \n          \n            \n              a\n              \u2192\n            \n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle -\\int _{a}^{b}{{\\vec {E}}\\cdot \\mathrm {d} {\\vec {\\ell }}}=\\phi ({\\vec {b}})-\\phi ({\\vec {a}}).}\n  From these equations, we see that the electric potential is constant in any region for which the electric field vanishes (such as occurs inside a conducting object).\n\n\n=== Electrostatic energy ===\n\nA test particle's potential energy, \n  \n    \n      \n        \n          U\n          \n            \n              E\n            \n          \n          \n            single\n          \n        \n      \n    \n    {\\displaystyle U_{\\mathrm {E} }^{\\text{single}}}\n  , can be calculated from a line integral of the work, \n  \n    \n      \n        \n          q\n          \n            n\n          \n        \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        \u22c5\n        \n          d\n        \n        \n          \n            \n              \u2113\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle q_{n}{\\vec {E}}\\cdot \\mathrm {d} {\\vec {\\ell }}}\n  . We integrate from a point at infinity, and assume a collection of \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   particles of charge \n  \n    \n      \n        \n          Q\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle Q_{n}}\n  , are already situated at the points \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}_{i}}\n  . This potential energy (in Joules) is:\n\n  \n    \n      \n        \n          U\n          \n            \n              E\n            \n          \n          \n            single\n          \n        \n        =\n        q\n        \u03d5\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        =\n        \n          \n            q\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          \n            \n              Q\n              \n                i\n              \n            \n            \n              \u2016\n              \n                \n                  \n                    \n                      \n                        \n                          R\n                          \u2192\n                        \n                      \n                    \n                    \n                      i\n                    \n                  \n                \n              \n              \u2016\n            \n          \n        \n      \n    \n    {\\displaystyle U_{\\mathrm {E} }^{\\text{single}}=q\\phi ({\\vec {r}})={\\frac {q}{4\\pi \\varepsilon _{0}}}\\sum _{i=1}^{N}{\\frac {Q_{i}}{\\left\\|{\\mathcal {{\\vec {R}}_{i}}}\\right\\|}}}\n  where \n  \n    \n      \n        \n          \n            \n              \n                \n                  R\n                  \n                    i\n                  \n                \n              \n              \u2192\n            \n          \n        \n        =\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        \u2212\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle {\\vec {\\mathcal {R_{i}}}}={\\vec {r}}-{\\vec {r}}_{i}}\n   is the distance of each charge \n  \n    \n      \n        \n          Q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle Q_{i}}\n   from the test charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  , which situated at the point \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n  , and \n  \n    \n      \n        \u03d5\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle \\phi ({\\vec {r}})}\n   is the electric potential that would be at \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   if the test charge were not present. If only two charges are present, the potential energy is \n  \n    \n      \n        \n          k\n          \n            e\n          \n        \n        \n          Q\n          \n            1\n          \n        \n        \n          Q\n          \n            2\n          \n        \n        \n          /\n        \n        r\n      \n    \n    {\\displaystyle k_{\\text{e}}Q_{1}Q_{2}/r}\n  . The total electric potential energy due a collection of N charges is calculating by assembling these particles one at a time:\n\n  \n    \n      \n        \n          U\n          \n            \n              E\n            \n          \n          \n            total\n          \n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \u2211\n          \n            j\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          Q\n          \n            j\n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            j\n            \u2212\n            1\n          \n        \n        \n          \n            \n              Q\n              \n                i\n              \n            \n            \n              r\n              \n                i\n                j\n              \n            \n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          Q\n          \n            i\n          \n        \n        \n          \u03d5\n          \n            i\n          \n        \n        ,\n      \n    \n    {\\displaystyle U_{\\mathrm {E} }^{\\text{total}}={\\frac {1}{4\\pi \\varepsilon _{0}}}\\sum _{j=1}^{N}Q_{j}\\sum _{i=1}^{j-1}{\\frac {Q_{i}}{r_{ij}}}={\\frac {1}{2}}\\sum _{i=1}^{N}Q_{i}\\phi _{i},}\n  where the following sum from, j = 1 to N, excludes i = j:\n\n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \u2211\n          \n            \n              \n                \n                  j\n                  \u2260\n                  i\n                \n                \n                  j\n                  =\n                  1\n                \n              \n            \n          \n          \n            N\n          \n        \n        \n          \n            \n              Q\n              \n                j\n              \n            \n            \n              r\n              \n                i\n                j\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\phi _{i}={\\frac {1}{4\\pi \\varepsilon _{0}}}\\sum _{\\stackrel {j=1}{j\\neq i}}^{N}{\\frac {Q_{j}}{r_{ij}}}.}\n  This electric potential, \n  \n    \n      \n        \n          \u03d5\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\phi _{i}}\n   is what would be measured at \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}_{i}}\n   if the charge \n  \n    \n      \n        \n          Q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle Q_{i}}\n   were missing. This formula obviously excludes the (infinite) energy that would be required to assemble each point charge from a disperse cloud of charge. The sum over charges can be converted into an integral over charge density using the prescription \n  \n    \n      \n        \u2211\n        (\n        \u22ef\n        )\n        \u2192\n        \u222b\n        (\n        \u22ef\n        )\n        \u03c1\n        \n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n      \n    \n    {\\textstyle \\sum (\\cdots )\\rightarrow \\int (\\cdots )\\rho \\,\\mathrm {d} ^{3}r}\n  :\n\n  \n    \n      \n        \n          U\n          \n            \n              E\n            \n          \n          \n            total\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        \u222b\n        \u03c1\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        \u03d5\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n        \n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n        =\n        \n          \n            \n              \u03b5\n              \n                0\n              \n            \n            2\n          \n        \n        \u222b\n        \n          \n            |\n            \n              \n                E\n              \n            \n            |\n          \n          \n            2\n          \n        \n        \n        \n          \n            d\n          \n          \n            3\n          \n        \n        r\n        ,\n      \n    \n    {\\displaystyle U_{\\mathrm {E} }^{\\text{total}}={\\frac {1}{2}}\\int \\rho ({\\vec {r}})\\phi ({\\vec {r}})\\,\\mathrm {d} ^{3}r={\\frac {\\varepsilon _{0}}{2}}\\int \\left|{\\mathbf {E} }\\right|^{2}\\,\\mathrm {d} ^{3}r,}\n  This second expression for electrostatic energy uses the fact that the electric field is the negative gradient of the electric potential, as well as vector calculus identities in a way that resembles integration by parts. These two integrals for electric field energy seem to indicate two mutually exclusive formulas for electrostatic energy density, namely \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        \u03c1\n        \u03d5\n      \n    \n    {\\textstyle {\\frac {1}{2}}\\rho \\phi }\n   and \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        \n          \u03b5\n          \n            0\n          \n        \n        \n          E\n          \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {1}{2}}\\varepsilon _{0}E^{2}}\n  ; they yield equal values for the total electrostatic energy only if both are integrated over all space.\n\n\n=== Electrostatic pressure ===\nOn a conductor, a surface charge will experience a force in the presence of an electric field. This force is the average of the discontinuous electric field at the surface charge. This average in terms of the field just outside the surface amounts to:\n\n  \n    \n      \n        P\n        =\n        \n          \n            \n              \u03b5\n              \n                0\n              \n            \n            2\n          \n        \n        \n          E\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle P={\\frac {\\varepsilon _{0}}{2}}E^{2},}\n  This pressure tends to draw the conductor into the field, regardless of the sign of the surface charge.\n\n\n== Triboelectric series ==\n\nThe triboelectric effect is a type of contact electrification in which certain materials become electrically charged when they are brought into contact with a different material and then separated. One of the materials acquires a positive charge, and the other acquires an equal negative charge. The polarity and strength of the charges produced differ according to the materials, surface roughness, temperature, strain, and other properties. Amber, for example, can acquire an electric charge by friction with a material like wool. This property, first recorded by Thales of Miletus, was the first electrical phenomenon investigated by humans. Other examples of materials that can acquire a significant charge when rubbed together include glass rubbed with silk, and hard rubber rubbed with fur.\n\n\n== Electrostatic generators ==\n\nThe presence of surface charge imbalance means that the objects will exhibit attractive or repulsive forces. This surface charge imbalance, which yields static electricity, can be generated by touching two differing surfaces together and then separating them due to the phenomena of contact electrification and the triboelectric effect. Rubbing two nonconductive objects generates a great amount of static electricity. This is not just the result of friction; two nonconductive surfaces can become charged by just being placed one on top of the other. Since most surfaces have a rough texture, it takes longer to achieve charging through contact than through rubbing. Rubbing objects together increases the amount of adhesive contact between the two surfaces. Usually insulators, i.e., substances that do not conduct electricity, are good at both generating, and holding, a surface charge. Some examples of these substances are rubber, plastic, glass, and pith. Conductive objects rarely generate charge imbalance, except when a metal surface is impacted by solid or liquid nonconductors. The charge that is transferred during contact electrification is stored on the surface of each object. Electrostatic generators, devices which produce very high voltage at very low current and used for classroom physics demonstrations, rely on this effect.\nThe presence of electric current does not detract from the electrostatic forces nor from the sparking, from the corona discharge, or other phenomena. Both phenomena can exist simultaneously in the same system.\n\nSee also: Wimshurst machine, and Van de Graaff generator.\n\n\n== Charge neutralization ==\nThe most familiar natural electrostatic phenomenon, often regarded as an occasional annoyance in seasons of low humidity, is Static electricity. Static electricity is generally harmless, but it can be destructive and harmful in some situations (e.g. electronics manufacturing). When working in direct contact with integrated circuit electronics (especially delicate MOSFETs). In the presence of flammable gas, care must be taken to avoid accumulating and suddenly discharging a static charge (see Electrostatic discharge).\n\n\n== Electrostatic induction ==\n\nElectrostatic induction, discovered by British scientist John Canton in 1753 and Swedish professor Johan Carl Wilcke in 1762 is a redistribution of charges in an object caused by the electric field of a nearby charge. For example, if a positively charged object is brought near an uncharged metal object, the mobile negatively-charged electrons in the metal will be attracted by the external charge, and move to the side of the metal facing it, creating a negative charge on the surface. When the electrons move out of an area they leave a positive charge due to the metal atoms' nuclei, so the side of the metal object facing away from the charge acquires a positive charge. These induced charges disappear when the external charge is removed. Induction is also responsible for the attraction of light objects, such as balloons, paper scraps and foam packing peanuts to static charges. The surface charges induced in conductive objects exactly cancel external electric fields inside the conductor, so there is no electric field inside a metal object. This is the basis for the electric field shielding action of a Faraday cage. Since the electric field is the gradient of the voltage, electrostatic induction is also responsible for making the electric potential (voltage) constant throughout a conductive object.\n\n\n== Static electricity ==\n\nBefore the year 1832, when Michael Faraday published the results of his experiment on the identity of electricities, physicists thought \"static electricity\" was somehow different from other electrical charges. Michael Faraday proved that the electricity induced from the magnet, voltaic electricity produced by a battery, and static electricity are all the same.\nStatic electricity is usually caused when certain materials are rubbed against each other, like wool on plastic or the soles of shoes on carpet. The process causes electrons to be pulled from the surface of one material and relocated on the surface of the other material.\nA static shock occurs when the surface of the second material, negatively charged with electrons, touches a positively charged conductor, or vice versa.\nStatic electricity is commonly used in xerography, air filters, and some coating processes used in manufacturing.\nStatic electricity is a build-up of electric charges on two objects that have become separated from each other. Small electrical components can be damaged by static electricity, and component manufacturers use a number of antistatic devices to avoid this.\n\n\n=== Static electricity and chemical industry ===\nWhen different materials are brought together and then separated, an accumulation of electric charge can occur which leaves one material positively charged while the other becomes negatively charged. The mild shock that you receive when touching a grounded object after walking on carpet is an example of excess electrical charge accumulating in your body from frictional charging between your shoes and the carpet. The resulting charge build-up upon your body can generate a strong electrical discharge. Although experimenting with static electricity may be fun, similar sparks create severe hazards in those industries dealing with flammable substances, where a small electrical spark may ignite explosive mixtures with devastating consequences.\nA similar charging mechanism can occur within low conductivity fluids flowing through pipelines\u2014a process called flow electrification. Fluids which have low electrical conductivity (below 50 picosiemens per meter), are called accumulators. Fluids having conductivities above 50 pS/m are called non-accumulators. In non-accumulators, charges recombine as fast as they are separated and hence electrostatic charge generation is not significant. In the petrochemical industry, 50 pS/m is the recommended minimum value of electrical conductivity for adequate removal of charge from a fluid.\nAn important concept for insulating fluids is the static relaxation time. This is similar to the time constant (tau) within an RC circuit. For insulating materials, it is the ratio of the static dielectric constant divided by the electrical conductivity of the material. For hydrocarbon fluids, this is sometimes approximated by dividing the number 18 by the electrical conductivity of the fluid. Thus a fluid that has an electrical conductivity of 1 pS/cm (100 pS/m) will have an estimated relaxation time of about 18 seconds. The excess charge within a fluid will be almost completely dissipated after 4 to 5 times the relaxation time, or 90 seconds for the fluid in the above example.\nCharge generation increases at higher fluid velocities and larger pipe diameters, becoming quite significant in pipes 8 inches (200 mm) or larger. Static charge generation in these systems is best controlled by limiting fluid velocity. The British standard BS PD CLC/TR 50404:2003 (formerly BS-5958-Part 2) Code of Practice for Control of Undesirable Static Electricity prescribes velocity limits. Because of its large impact on dielectric constant, the recommended velocity for hydrocarbon fluids containing water should be limited to 1 m/s.\nBonding and earthing are the usual ways by which charge buildup can be prevented. For fluids with electrical conductivity below 10 pS/m, bonding and earthing are not adequate for charge dissipation, and anti-static additives may be required.\n\n\n==== Applicable standards ====\nBS PD CLC/TR 50404:2003 Code of Practice for Control of Undesirable Static Electricity\nNFPA 77 (2007) Recommended Practice on Static Electricity\nAPI RP 2003 (1998) Protection Against Ignitions Arising Out of Static, Lightning, and Stray Currents\n\n\n== Electrostatic induction in commercial applications ==\nElectrostatic induction was used in the past to build high-voltage generators known as influence machines.\nThe main component that emerged in these times is the capacitor.\nElectrostatic induction is also used for electro-mechanic precipitation or projection. In such technologies, charged particles of small sizes are collected or deposited intentionally on surfaces. Applications range from electrostatic precipitator to electrostatic coating and inkjet printing.\nElectrostatic actuators have recently been attracting interest in the soft robotics research area. Electrostatic actuators can be employed as clutches for wearable devices which can exhibit mechanical impedance tuning and improved energy efficiency. Other relevant applications include but not limited to multimode hydraulically amplified electrostatic actuators for wearable haptics  and robots driven by electrostatic actuator.\n\n\n== See also ==\nElectromagnetism\nElectronegativity\nElectrostatic discharge\nElectrostatic separator\nElectrostatic voltmeter\nIonic bond\nPermittivity and relative permittivity\nQuantisation of charge\n\n\n== Footnotes ==\n\n\n== References ==\nFaraday, Michael (1839). Experimental Researches in Electricity. London: Royal Inst.\nMichael Faraday. Experimental Researches in Electricity, Volume 1 at Project Gutenberg\nHalliday, David; Robert Resnick; Kenneth S. Krane (1992). Physics. New York: John Wiley & Sons. ISBN 0-471-80457-6.\nGriffiths, David J. (1999). Introduction to Electrodynamics. Upper Saddle River, NJ: Prentice Hall. ISBN 0-13-805326-X.\nHermann A. Haus; James R. Melcher (1989). Electromagnetic Fields and Energy. Englewood Cliffs, NJ: Prentice-Hall. ISBN 0-13-249020-X.\n\n\n== Further reading ==\nEssaysWilliam J. Beaty (1997), \"Humans and sparks: The Cause, Stopping the Pain, and 'Electric People\".BooksWilliam Cecil Dampier (1905), The Theory of Experimental Electricity, Cambridge University Press, (Cambridge physical series). xi, 334 p. illus., diagrs. 23 cm. LCCN 05-40419\nWilliam Thomson Kelvin (1872) Reprint of Papers on Electrostatics and Magnetism By William Thomson Kelvin, Macmillan.\nAlexander McAulay (1893), The Utility of Quaternions in Physics, Electrostatics \u2013 General Problem. Macmillan.\nAlexander Russell (1904) A Treatise on the Theory of Alternating Currents, Cambridge University Press, Second edition, 1914, volume 1. Second edition, 1916, volume 2 via Internet Archive.\n\n\n== External links ==\n\n Media related to Electrostatics at Wikimedia Commons\nThe Feynman Lectures on Physics Vol. II Ch. 4: Electrostatics\nIntroduction to Electrostatics: Point charges can be treated as a distribution using the Dirac delta function Learning materials related to Electrostatics at Wikiversity", "Displacement_(vector)": "In geometry and mechanics, a displacement is a vector whose length is the shortest distance from the initial to the final position of a point P undergoing motion. It quantifies both the distance and direction of the net or total motion along a straight line from the initial position to the final position of the point trajectory. A displacement may be identified with the translation that maps the initial position to the final position.\nA displacement may be also described as a relative position (resulting from the motion), that is, as the final position xf of a point relative to its initial position xi. The corresponding displacement vector can be defined as the difference between the final and initial positions:\n\nIn considering motions of objects over time, the instantaneous velocity of the object is the rate of change of the displacement as a function of time. The instantaneous speed, then, is distinct from velocity, or the time rate of change of the distance travelled along a specific path. The velocity may be equivalently defined as the time rate of change of the position vector. If one considers a moving initial position, or equivalently a moving origin (e.g. an initial position or origin which is fixed to a train wagon, which in turn moves on its rail track), the velocity of P (e.g. a point representing the position of a passenger walking on the train) may be referred to as a relative velocity, as opposed to an absolute velocity, which is computed with respect to a point which is considered to be 'fixed in space' (such as, for instance, a point fixed on the floor of the train station).\nFor motion over a given interval of time, the displacement divided by the length of the time interval defines the average velocity, which is a vector, and differs thus from the average speed, which is a scalar quantity.\n\n\n== Rigid body ==\nIn dealing with the motion of a rigid body, the term displacement may also include the rotations of the body. In this case, the displacement of a particle of the body is called linear displacement (displacement along a line), while the rotation of the body is called angular displacement.\n\n\n== Derivatives ==\nFor a position vector \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n   that is a function of time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , the derivatives can be computed with respect to \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  .  The first two derivatives are frequently encountered in physics.\n\nVelocity\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          \n            \n              d\n              \n                s\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} ={\\frac {d\\mathbf {s} }{\\mathrm {d} t}}}\n  \nAcceleration\n\n  \n    \n      \n        \n          a\n        \n        =\n        \n          \n            \n              d\n              \n                v\n              \n            \n            \n              d\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              \n                s\n              \n            \n            \n              d\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {a} ={\\frac {d\\mathbf {v} }{dt}}={\\frac {d^{2}\\mathbf {s} }{dt^{2}}}}\n  \nJerk\n\n  \n    \n      \n        \n          j\n        \n        =\n        \n          \n            \n              d\n              \n                a\n              \n            \n            \n              d\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              \n                v\n              \n            \n            \n              d\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n                \n                  3\n                \n              \n              \n                s\n              \n            \n            \n              d\n              \n                t\n                \n                  3\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {j} ={\\frac {d\\mathbf {a} }{dt}}={\\frac {d^{2}\\mathbf {v} }{dt^{2}}}={\\frac {d^{3}\\mathbf {s} }{dt^{3}}}}\n  These common names correspond to terminology used in basic kinematics.  By extension, the higher order derivatives can be computed in a similar fashion.  Study of these higher order derivatives can improve approximations of the original displacement function.  Such higher-order terms are required in order to accurately represent the displacement function as a sum of an infinite series, enabling several analytical techniques in engineering and physics. The fourth order derivative is called jounce.\n\n\n== See also ==\nDisplacement field (mechanics)\nEquipollence (geometry)\nMotion vector\nPosition vector\nAffine space\n\n\n== References ==\n\n\n== External links ==\n Media related to Displacement vector at Wikimedia Commons", "Electroscope": "The  electroscope is an early scientific instrument used to detect the presence of electric charge on a body.  It detects charge by the movement of a test object due to the Coulomb electrostatic force on it.  The amount of charge on an object is proportional to its voltage.  The accumulation of enough charge to detect with an electroscope requires hundreds or thousands of volts, so electroscopes are used with high voltage sources such as static electricity and electrostatic machines.  An electroscope can only give a rough indication of the quantity of charge; an instrument that measures electric charge quantitatively is called an electrometer.\nThe electroscope was the first electrical measuring instrument. The first electroscope was a pivoted needle (called the versorium), invented by British physician William Gilbert around 1600.   The pith-ball electroscope and the gold-leaf electroscope are two classical types of electroscope that are still used in physics education to demonstrate the principles of electrostatics.  A type of electroscope is also used in the quartz fiber radiation dosimeter. Electroscopes were used by the Austrian scientist Victor Hess in the discovery of cosmic rays.\n\n\n== Pith-ball electroscope ==\n\nIn 1731, Stephen Gray used a simple hanging thread, which would be attracted to any nearby charged object.  This was the first improvement on Gilbert's versorium from 1600.The pith-ball electroscope, invented by British schoolmaster and physicist John Canton in 1754, consists of one or two small balls of a lightweight nonconductive substance, originally a spongy plant material called pith, suspended by silk or linen thread from the hook of an insulated stand. Tiberius Cavallo made an electroscope in 1770 with pith balls at the end of silver wires. Modern electroscopes usually use balls made of plastic. In order to test the presence of a charge on an object, the object is brought near to the uncharged pith ball. If the object is charged, the ball will be attracted to it and move toward it.\nThe attraction occurs because of induced polarization of the atoms inside the pith ball.  All matter consists of electrically charged particles located close together; each atom consists of a positively charged nucleus with a cloud of negatively charged electrons surrounding it.   The pith is a nonconductor, so the electrons in the ball are bound to atoms of the pith and are not free to leave the atoms and move about in the ball, but they can move a little within the atoms. See diagram. If, for example, a positively charged object (B) is brought near the pith ball (A), the negative electrons (blue minus signs) in each atom (yellow ovals) will be attracted and move slightly toward the side of the atom nearer the object.  The positively charged nuclei (red plus signs) will be repelled and will move slightly away.  Since the negative charges in the pith ball are now nearer the object than the positive charges (C), their attraction is greater than the repulsion of the positive charges, resulting in a net attractive force.  This separation of charge is microscopic, but since there are so many atoms, the tiny forces add up to a large enough force to move a light pith ball.\nThe pith ball can be charged by touching it to a charged object, so some of the charges on the surface of the charged object move to the surface of the ball.  Then the ball can be used to distinguish the polarity of charge on other objects because it will be repelled by objects charged with the same polarity or sign it has, but attracted to charges of the opposite polarity.\nOften the electroscope will have a pair of suspended pith balls.  This allows one to tell at a glance whether the pith balls are charged. If one of the pith balls is touched to a charged object, charging it, the second one will be attracted and touch it, communicating some of the charge to the surface of the second ball.  Now both balls have the same polarity charge, so they repel each other.  They hang in an inverted 'V' shape with the balls spread apart.  The distance between the balls will give a rough idea of the magnitude of the charge.\n\n\n== Gold-leaf electroscope ==\n\nThe gold-leaf electroscope was developed in 1787 by British clergyman and physicist Abraham Bennet, as a more sensitive instrument than  pith ball or straw blade electroscopes then in use. It consists of a vertical metal rod, usually brass, from the end of which hang two parallel strips of thin flexible gold leaf.  A disk or ball terminal is attached to the top of the rod, where the charge to be tested is applied. To protect the gold leaves from drafts of air they are enclosed in a glass bottle, usually open at the bottom and mounted over a conductive base. Often there are grounded metal plates or foil strips in the bottle flanking the gold leaves on either side.   These are a safety measure; if an excessive charge is applied to the delicate gold leaves, they will touch the grounding plates and discharge before tearing.  They also capture charge leaking through the air that  accumulates on the glass walls, increasing the sensitivity of the instrument.  In the precision instruments the inside of the bottle was occasionally evacuated, to prevent the charge on the terminal from leaking off through the ionization of the air.\nWhen the metal terminal is touched with a charged object, the gold leaves spread apart in an inverted 'V'. This is because some of the charge from the object is conducted through the terminal and metal rod to the leaves. Since the leaves receive the same sign charge they repel each other and thus diverge. If the terminal is grounded by touching it with a finger, the charge is transferred through the human body into the earth and the gold leaves close together.\nThe electroscope leaves can also be charged without touching a charged object to the terminal, by electrostatic induction. As the charged object is brought near the electroscope terminal, the leaves spread apart, because the electric field from the object induces a charge in the conductive electroscope rod and leaves, and the charged leaves repel each other. The opposite-sign charge is attracted to the nearby object and collects on the terminal disk, while the same-sign charge is repelled from the object and collects on the leaves (but only as much as left the terminal), so the leaves repel each other.  If the electroscope is grounded while the charged object is nearby, by touching it momentarily with a finger, the repelled same-sign charges travel through the contact to ground, leaving the electroscope with a net charge having the opposite sign as the object.  The leaves initially hang down free because the net charge is concentrated at the terminal end.  When the charged object is moved away, the charge at the terminal spreads into the leaves, causing them to spread apart again.\n\nGold-leaf electroscopes\n\t\t\n\t\t\n\t\t\n\n\n== See also ==\n\n\n== Footnotes ==\n\n\n== External links ==\n\"Pith-ball electroscope\". Physics demonstration resource. St. Mary's University. Retrieved 2015-05-28.\n\"Computer simulation of electroscopes\". Molecular Workbench. Concord Consortium.\n\"Pith Ball and Charged Rod Video\". St. Mary's Physics YouTube Channel. St. Mary's Physics Online. Archived from the original on 2021-12-22.", "Angle_of_incidence": "The angle of incidence, in geometric optics, is the angle between a ray incident on a surface and the line perpendicular (at 90 degree angle) to the surface at the point of incidence, called the normal. The ray can be formed by any waves, such as optical, acoustic, microwave, and X-ray. In the figure below, the line representing a ray makes an angle \u03b8 with the normal (dotted line). The angle of incidence at which light is first totally internally reflected is known as the critical angle. The angle of reflection and angle of refraction are other angles related to beams.\nIn computer graphics and geography, the angle of incidence is also known as the illumination angle of a surface with a light source, such as the Earth's surface and the Sun. It can also be equivalently described as the angle between the tangent plane of the surface and another plane at right angles to the light rays. This means that the illumination angle of a certain point on Earth's surface is 0\u00b0 if the Sun is precisely overhead and that it is 90\u00b0 at sunset or sunrise.\nDetermining the angle of reflection with respect to a planar surface is trivial, but the computation for almost any other surface is significantly more difficult.\n\n\n== Grazing angle or glancing angle ==\n\nWhen dealing with a beam that is nearly parallel to a surface, it is sometimes more useful to refer to the angle between the beam and the surface tangent, rather than that between the beam and the surface normal. The 90-degree complement to the angle of incidence is called the grazing angle or glancing angle. Incidence at small grazing angles is called \"grazing incidence.\"\nGrazing incidence diffraction is used in X-ray spectroscopy and atom optics, where significant reflection can be achieved only at small values of the grazing angle. Ridged mirrors are designed to reflect atoms coming at a small grazing angle. This angle is usually measured in milliradians. In optics, there is Lloyd's mirror.\n\n\n== See also ==\nEffect of sun angle on climate\nIllumination angle\nPhase angle (astronomy)\nPlane of incidence\nReflection (physics)\nRefraction\nTotal internal reflection\n\n\n== References ==\n\n\n== External links ==\nWeisstein, Eric W. \"Angle of incidence\". MathWorld.\ngeometry : rebound on the strip billiards Flash animation", "Mirror_image": "A mirror image (in a plane mirror) is a reflected duplication of an object that appears almost identical, but is reversed in the direction perpendicular to the mirror surface. As an optical effect it results from reflection off from substances such as a mirror or water. It is also a concept in geometry and can be used as a conceptualization process for 3-D structures.\n\n\n== In geometry and geometrical optics ==\n\n\n=== In two dimensions ===\n\nIn geometry, the mirror image of an object or two-dimensional figure is the virtual image formed by reflection in a plane mirror; it is of the same size as the original object, yet different, unless the object or figure has reflection symmetry (also known as a P-symmetry).\nTwo-dimensional mirror images can be seen in the reflections of mirrors or other reflecting surfaces, or on a printed surface seen inside-out. If we first look at an object that is effectively two-dimensional (such as the writing on a card) and then turn the card to face a mirror, the object turns through an angle of 180\u00b0 and we see a left-right reversal in the mirror. In this example, it is the change in orientation rather than the mirror itself that causes the observed reversal. Another example is when we stand with our backs to the mirror and face an object that's in front of the mirror. Then we compare the object with its reflection by turning ourselves 180\u00b0, towards the mirror. Again we perceive a left-right reversal due to a change in our orientation. So, in these examples the mirror does not actually cause the observed reversals.\n\n\n=== In three dimensions ===\n\nThe concept of reflection can be extended to three-dimensional objects, including the inside parts, even if they are not transparent. The term then relates to structural as well as visual aspects. A three-dimensional object is reversed in the direction perpendicular to the mirror surface. In physics, mirror images are investigated in the subject called geometrical optics. More fundamentally in geometry and mathematics they form the principal objects of Coxeter group theory and reflection groups.\nIn chemistry, two versions (isomers) of a molecule, one a \"mirror image\" of the other, are called enantiomers if they are not \"superposable\" (the correct technical term, though the term \"superimposable\" is also used) on each other. That is an example of chirality (chemistry). In general, an object and its mirror image are called enantiomorphs.\nIf a point of an object has coordinates (x, y, z) then the image of this point (as reflected by a mirror in the y, z plane) has coordinates (\u2212x, y, z). Thus reflection is a reversal of the coordinate axis perpendicular (normal) to the mirror's surface. Although a plane mirror reverses an object only in the direction normal to the mirror surface, this turns the entire three-dimensional image seen in the mirror inside-out, so there is a perception of a left-right reversal. Hence, the reversal is somewhat misleadingly called a \"lateral inversion\". The perception of a left-right reversal is geometrically explained by the fact that a three-dimensional object seen in a mirror is an inside-out version of the actual object, like a glove stripped off the left hand and turned into a right-hand glove, but there is still some confusion about the explanation amongst psychologists. The psychology of the perceived left-right reversal is discussed in \"Much ado about mirrors\" by Professor Michael Corballis (see \"external links\", below).\nReflection in a mirror does result in a change in chirality, more specifically from a right-handed to a left-handed coordinate system (or vice versa). If one looks in a mirror two axes (up-down and left-right) coincide with those in the mirror, but  the third axis (front-back) is reversed.\nIf a person stands side-on to a mirror, left and right hands will be reversed directly by the mirror, because the person's left-right axis is then normal to the mirror plane. However, it's important to understand that there are always only two enantiomorphs, the object and its inside-out image. Therefore, no matter how the object is oriented towards the mirror, all the resulting images are fundamentally identical (as Corballis explains in his paper \"Much ado about mirrors\", mentioned above).\nIn the picture of the mountain reflected in the lake (photograph top right), the reversal normal to the reflecting surface is obvious. Notice that there is no obvious front-back or left-right of the mountain. In the example of the urn and mirror (photograph to right), the urn is fairly symmetrical front-back (and left-right). Thus, no obvious reversal of any sort can be seen in the mirror image of the urn.\nA mirror image appears more obviously three-dimensional if the observer moves, or if the image is viewed using binocular vision. This is because the relative position of objects changes as the observer's perspective changes, or is differently viewed with each eye.Looking through a mirror from different positions (but necessarily with the point of observation restricted to the halfspace on one side of the mirror) is like looking at the 3D mirror image of space; without further mirrors only the mirror image of the halfspace before the mirror is relevant; if there is another mirror, the mirror image of the other halfspace is too.\n\n\n==== Effect of mirror on the lighting of the scene ====\nA mirror does not just produce an image of what would be there without it; it also changes the light distribution in the halfspace in front of and behind the mirror. A mirror hanging on the wall makes the room brighter because additional light sources appear in the mirror image. However, the appearance of additional light does not violate the conservation of energy principle, because some light no longer reaches behind the mirror, as the mirror simply re-directs the light energy. In terms of the light distribution, the virtual mirror image has the same appearance and the same effect as a real, symmetrically arranged half-space behind a window (instead of the mirror). Shadows may extend from the mirror into the halfspace before it, and vice versa.\n\n\n== Mirror writing ==\n\nIn mirror writing a text is deliberately displayed as its mirror image, in order to be read through a mirror. For example, emergency vehicles such as ambulances or fire engines use mirror images in order to be read from a vehicle's rear-view mirror. Some movie theaters also use mirror writing in a Rear Window Captioning System used to assist individuals with hearing impairments in watching films.\n\n\n== Systems of mirrors ==\nIn the case of two mirrors, in planes at an angle \u03b1, looking through both from the sector which is the intersection of the two halfspaces, is like looking at a version of the world rotated by an angle of 2\u03b1; the points of observations and directions of looking for which this applies correspond to those for looking through a frame like that of the first mirror, and a frame at the mirror image with respect to the first plane, of the second mirror. If the mirrors have vertical edges then the left edge of the field of view is the plane through the right edge of the first mirror and the edge of the second mirror which is on the right when looked at directly, but on the left in the mirror image.\nIn the case of two parallel mirrors, looking through both at once is like looking at a version of the world which is translated by twice the distance between the mirrors, in the direction perpendicular to them, away from the observer. Since the plane of the mirror in which one looks directly is beyond that of the other mirror, one always looks at an oblique angle, and the translation just mentioned has not only a component away from the observer, but also one in a perpendicular direction. The translated view can also be described by a translation of the observer in opposite direction. For example, with a vertical periscope, the shift of the world is away from the observer and down, both by the length of the periscope, but it is more practical to consider the equivalent shift of the observer: up, and backward.\nIt is also possible to create a non-reversing mirror by placing two first surface mirrors at 90\u00ba to give an image which is not reversed.\n\n\n== See also ==\nAnamorphosis\nChirality, a property of asymmetry important in several branches of science\nFlipped image\nFlopped image\nHandedness\nInfinity mirror\nKaleidoscope\nPlane mirror\nReflection (physics)\nRelative direction\n\n\n== References ==\n\n\n== External links ==\n\nWhy do mirrors reverse images left to right? Why not up and down?\nThe same question explained a little differently, with examples\nWhy do mirrors flip horizontally (but not vertically)?\n\"Much ado about mirrors\" (an academic paper about the psychology involved in the perception of mirror images)", "Laser": "A laser is a device that emits light through a process of optical amplification based on the stimulated emission of electromagnetic radiation. The word laser is an anacronym that originated as an acronym for light amplification by stimulated emission of radiation. The first laser was built in 1960 by Theodore Maiman at Hughes Research Laboratories, based on theoretical work by Charles H. Townes and Arthur Leonard Schawlow.A laser differs from other sources of light in that it emits light that is coherent. Spatial coherence allows a laser to be focused to a tight spot, enabling applications such as laser cutting and lithography. Spatial coherence also allows a laser beam to stay narrow over great distances (collimation), enabling applications such as laser pointers and lidar (light detection and ranging). Lasers can also have high temporal coherence, which allows them to emit light with a very narrow spectrum. Alternatively, temporal coherence can be used to produce ultrashort pulses of light with a broad spectrum but durations as short as a femtosecond.\nLasers are used in optical disc drives, laser printers, barcode scanners, DNA sequencing instruments, fiber-optic, and free-space optical communication, semiconducting chip manufacturing (photolithography), laser surgery and skin treatments, cutting and welding materials, military and law enforcement devices for marking targets and measuring range and speed, and in laser lighting displays for entertainment. Semiconductor lasers in the blue to near-UV have also been used in place of light-emitting diodes (LEDs) to excite fluorescence as a white light source. This permits a much smaller emitting area due to the much greater radiance of a laser and avoids the droop suffered by LEDs; such devices are already used in some car headlamps.\n\n\n== Fundamentals ==\nLasers are distinguished from other light sources by their coherence. Spatial (or transverse) coherence is typically expressed through the output being a narrow beam, which is diffraction-limited. Laser beams can be focused to very tiny spots, achieving a very high irradiance, or they can have a very low divergence to concentrate their power at a great distance. Temporal (or longitudinal) coherence implies a polarized wave at a single frequency, whose phase is correlated over a relatively great distance (the coherence length) along the beam. A beam produced by a thermal or other incoherent light source has an instantaneous amplitude and phase that vary randomly with respect to time and position, thus having a short coherence length.\nLasers are characterized according to their wavelength in a vacuum. Most \"single wavelength\" lasers produce radiation in several modes with slightly different wavelengths. Although temporal coherence implies some degree of monochromaticity, some lasers emit a broad spectrum of light or emit different wavelengths of light simultaneously. Some lasers are not single spatial mode and have light beams that diverge more than is required by the diffraction limit. All such devices are classified as \"lasers\" based on the method of producing light by stimulated emission. Lasers are employed where light of the required spatial or temporal coherence can not be produced using simpler technologies.\n\n\n=== Terminology ===\nThe first device using amplification by stimulated emission operated at microwave frequencies, and was named \"maser\" (\"microwave amplification by stimulated emission of radiation\".) When similar optical devices were developed they were first known as \"optical masers\", until \"microwave\" was replaced by \"light\" in its acronym.All such devices operating at frequencies higher than microwaves are called lasers (including infrared lasers, ultraviolet lasers, X-ray laser, and gamma-ray laser). All devices operating at microwave or lower radio frequencies are called masers.\nA laser that produces light by itself is technically an optical oscillator rather than an optical amplifier as suggested by the acronym. It has been humorously noted that the acronym LOSER, for \"light oscillation by stimulated emission of radiation\", would have been more correct. With the widespread use of the original acronym as a common noun, optical amplifiers have come to be referred to as \"laser amplifiers\".\nThe back-formed verb to lase is frequently used in the field, meaning \"to give off coherent light,\" especially about the gain medium of a laser; when a laser is operating it is said to be \"lasing\". The words laser and maser are also used in cases where there is a coherent state unconnected with any manufactured device, as in astrophysical maser and atom laser.\n\n\n== Design ==\n\nA laser consists of a gain medium, a mechanism to energize it, and something to provide optical feedback. The gain medium is a material with properties that allow it to amplify light by way of stimulated emission. Light of a specific wavelength that passes through the gain medium is amplified (power increases). Feedback enables stimulated emission to amplify predominantly the optical frequency at the peak of the gain-frequency curve.  As stimulated emission grows, eventually one frequency dominates over all others, meaning that a coherent beam has been formed. The process of stimulated emission is analogous to that of an audio oscillator with positive feedback which can occur, for example, when the speaker in a public-address system is placed in proximity to the microphone. The screech one hears is audio oscillation at the peak of the gain-frequency curve for the amplifier.For the gain medium to amplify light, it needs to be supplied with energy in a process called pumping. The energy is typically supplied as an electric current or as light at a different wavelength. Pump light may be provided by a flash lamp or by another laser.\nThe most common type of laser uses feedback from an optical cavity\u2014a pair of mirrors on either end of the gain medium. Light bounces back and forth between the mirrors, passing through the gain medium and being amplified each time. Typically one of the two mirrors, the output coupler, is partially transparent. Some of the light escapes through this mirror. Depending on the design of the cavity (whether the mirrors are flat or curved), the light coming out of the laser may spread out or form a narrow beam. In analogy to electronic oscillators, this device is sometimes called a laser oscillator.\nMost practical lasers contain additional elements that affect the properties of the emitted light, such as the polarization, wavelength, and shape of the beam.\n\n\n== Laser physics ==\n\nElectrons and how they interact with electromagnetic fields are important in our understanding of chemistry and physics.\n\n\n=== Stimulated emission ===\n\nIn the classical view, the energy of an electron orbiting an atomic nucleus is larger for orbits further from the nucleus of an atom. However, quantum mechanical effects force electrons to take on discrete positions in orbitals. Thus, electrons are found in specific energy levels of an atom, two of which are shown below:\n\nAn electron in an atom can absorb energy from light (photons) or heat (phonons) only if there is a transition between energy levels that match the energy carried by the photon or phonon. For light, this means that any given transition will only absorb one particular wavelength of light. Photons with the correct wavelength can cause an electron to jump from the lower to the higher energy level. The photon is consumed in this process.\nWhen an electron is excited from one state to that at a higher energy level with energy difference \u0394E, it will not stay that way forever. Eventually, a photon will be spontaneously created from the vacuum having energy \u0394E. Conserving energy, the electron transitions to a lower energy level that is not occupied, with transitions to different levels having different time constants. This process is called spontaneous emission. Spontaneous emission is a quantum-mechanical effect and a direct physical manifestation of the Heisenberg uncertainty principle. The emitted photon has a random direction, but its wavelength matches the absorption wavelength of the transition. This is the mechanism of fluorescence and thermal emission.\nA photon with the correct wavelength to be absorbed by a transition can also cause an electron to drop from the higher to the lower level, emitting a new photon. The emitted photon exactly matches the original photon in wavelength, phase, and direction. This process is called stimulated emission.\n\n\n=== Gain medium and cavity ===\n\nThe gain medium is put into an excited state by an external source of energy. In most lasers, this medium consists of a population of atoms that have been excited into such a state using an outside light source, or an electrical field that supplies energy for atoms to absorb and be transformed into their excited states.\nThe gain medium of a laser is normally a material of controlled purity, size, concentration, and shape, which amplifies the beam by the process of stimulated emission described above. This material can be of any state: gas, liquid, solid, or plasma. The gain medium absorbs pump energy, which raises some electrons into higher energy (\"excited\") quantum states. Particles can interact with light by either absorbing or emitting photons. Emission can be spontaneous or stimulated. In the latter case, the photon is emitted in the same direction as the light that is passing by. When the number of particles in one excited state exceeds the number of particles in some lower-energy state, population inversion is achieved. In this state, the rate of stimulated emission is larger than the rate of absorption of light in the medium, and therefore the light is amplified. A system with this property is called an optical amplifier. When an optical amplifier is placed inside a resonant optical cavity, one obtains a laser.For lasing media with extremely high gain, so-called superluminescence, light can be sufficiently amplified in a single pass through the gain medium without requiring a resonator. Although often referred to as a laser (see for example nitrogen laser), the light output from such a device lacks the spatial and temporal coherence achievable with lasers. Such a device cannot be described as an oscillator but rather as a high-gain optical amplifier that amplifies its spontaneous emission. The same mechanism describes so-called astrophysical masers/lasers.\nThe optical resonator is sometimes referred to as an \"optical cavity\", but this is a misnomer: lasers use open resonators as opposed to the literal cavity that would be employed at microwave frequencies in a maser.\nThe resonator typically consists of two mirrors between which a coherent beam of light travels in both directions, reflecting on itself so that an average photon will pass through the gain medium repeatedly before it is emitted from the output aperture or lost to diffraction or absorption.\nIf the gain (amplification) in the medium is larger than the resonator losses, then the power of the recirculating light can rise exponentially. But each stimulated emission event returns an atom from its excited state to the ground state, reducing the gain of the medium. With increasing beam power the net gain (gain minus loss) reduces to unity and the gain medium is said to be saturated. In a continuous wave (CW) laser, the balance of pump power against gain saturation and cavity losses produces an equilibrium value of the laser power inside the cavity; this equilibrium determines the operating point of the laser. If the applied pump power is too small, the gain will never be sufficient to overcome the cavity losses, and laser light will not be produced. The minimum pump power needed to begin laser action is called the lasing threshold. The gain medium will amplify any photons passing through it, regardless of direction; but only the photons in a spatial mode supported by the resonator will pass more than once through the medium and receive substantial amplification.\n\n\n=== The light emitted ===\nIn most lasers, lasing begins with spontaneous emission into the lasing mode. This initial light is then amplified by stimulated emission in the gain medium. Stimulated emission produces light that matches the input signal in direction, wavelength, and polarization, whereas the phase of the emitted light is 90 degrees in lead of the stimulating light. This, combined with the filtering effect of the optical resonator gives laser light its characteristic coherence, and may give it uniform polarization and monochromaticity, depending on the resonator's design. The fundamental laser linewidth of light emitted from the lasing resonator can be orders of magnitude narrower than the linewidth of light emitted from the passive resonator. Some lasers use a separate injection seeder to start the process off with a beam that is already highly coherent. This can produce beams with a narrower spectrum than would otherwise be possible.\nIn 1963, Roy J. Glauber showed that coherent states are formed from combinations of photon number states, for which he was awarded the Nobel Prize in physics.  A coherent beam of light is formed by single-frequency quantum photon states distributed according to a Poisson distribution.  As a result, the arrival rate of photons in a laser beam is described by Poisson statistics.Many lasers produce a beam that can be approximated as a Gaussian beam; such beams have the minimum divergence possible for a given beam diameter. Some lasers, particularly high-power ones, produce multimode beams, with the transverse modes often approximated using Hermite\u2013Gaussian or Laguerre-Gaussian functions. Some high-power lasers use a flat-topped profile known as a \"tophat beam\". Unstable laser resonators (not used in most lasers) produce fractal-shaped beams. Specialized optical systems can produce more complex beam geometries, such as Bessel beams and optical vortexes.\nNear the \"waist\" (or focal region) of a laser beam, it is highly collimated: the wavefronts are planar, normal to the direction of propagation, with no beam divergence at that point. However, due to diffraction, that can only remain true well within the Rayleigh range. The beam of a single transverse mode (gaussian beam) laser eventually diverges at an angle that varies inversely with the beam diameter, as required by diffraction theory. Thus, the \"pencil beam\" directly generated by a common helium\u2013neon laser would spread out to a size of perhaps 500 kilometers when shone on the Moon (from the distance of the earth). On the other hand, the light from a semiconductor laser typically exits the tiny crystal with a large divergence: up to 50\u00b0. However even such a divergent beam can be transformed into a similarly collimated beam employing a lens system, as is always included, for instance, in a laser pointer whose light originates from a laser diode. That is possible due to the light being of a single spatial mode. This unique property of laser light, spatial coherence, cannot be replicated using standard light sources (except by discarding most of the light) as can be appreciated by comparing the beam from a flashlight (torch) or spotlight to that of almost any laser.\nA laser beam profiler is used to measure the intensity profile, width, and divergence of laser beams.\nDiffuse reflection of a laser beam from a matte surface produces a speckle pattern with interesting properties.\n\n\n=== Quantum vs. classical emission processes ===\nThe mechanism of producing radiation in a laser relies on stimulated emission, where energy is extracted from a transition in an atom or molecule. This is a quantum phenomenon that was predicted by Albert Einstein, who derived the relationship between the A coefficient describing spontaneous emission and the B coefficient which applies to absorption and stimulated emission. However, in the case of the free electron laser, atomic energy levels are not involved; it appears that the operation of this rather exotic device can be explained without reference to quantum mechanics.\n\n\n== Continuous and pulsed modes of operation ==\n\nA laser can be classified as operating in either continuous or pulsed mode, depending on whether the power output is essentially continuous over time or whether its output takes the form of pulses of light on one or another time scale. Of course, even a laser whose output is normally continuous can be intentionally turned on and off at some rate to create pulses of light. When the modulation rate is on time scales much slower than the cavity lifetime and the period over which energy can be stored in the lasing medium or pumping mechanism, then it is still classified as a \"modulated\" or \"pulsed\" continuous wave laser. Most laser diodes used in communication systems fall into that category.\n\n\n=== Continuous-wave operation ===\nSome applications of lasers depend on a beam whose output power is constant over time. Such a laser is known as continuous-wave (CW) laser. Many types of lasers can be made to operate in continuous-wave mode to satisfy such an application. Many of these lasers lase in several longitudinal modes at the same time, and beats between the slightly different optical frequencies of those oscillations will produce amplitude variations on time scales shorter than the round-trip time (the reciprocal of the frequency spacing between modes), typically a few nanoseconds or less. In most cases, these lasers are still termed \"continuous-wave\" as their output power is steady when averaged over longer periods, with the very high-frequency power variations having little or no impact on the intended application. (However, the term is not applied to mode-locked lasers, where the intention is to create very short pulses at the rate of the round-trip time.)\nFor continuous-wave operation, it is required for the population inversion of the gain medium to be continually replenished by a steady pump source. In some lasing media, this is impossible. In some other lasers, it would require pumping the laser at a very high continuous power level, which would be impractical, or destroying the laser by producing excessive heat. Such lasers cannot be run in CW mode.\n\n\n=== Pulsed operation ===\n\nThe pulsed operation of lasers refers to any laser not classified as a continuous wave so that the optical power appears in pulses of some duration at some repetition rate. This encompasses a wide range of technologies addressing many different motivations. Some lasers are pulsed simply because they cannot be run in continuous mode.\nIn other cases, the application requires the production of pulses having as large an energy as possible. Since the pulse energy is equal to the average power divided by the repetition rate, this goal can sometimes be satisfied by lowering the rate of pulses so that more energy can be built up between pulses. In laser ablation, for example, a small volume of material at the surface of a workpiece can be evaporated if it is heated in a very short time, while supplying the energy gradually would allow for the heat to be absorbed into the bulk of the piece, never attaining a sufficiently high temperature at a particular point.\nOther applications rely on the peak pulse power (rather than the energy in the pulse), especially to obtain nonlinear optical effects. For a given pulse energy, this requires creating pulses of the shortest possible duration utilizing techniques such as Q-switching.\nThe optical bandwidth of a pulse cannot be narrower than the reciprocal of the pulse width. In the case of extremely short pulses, that implies lasing over a considerable bandwidth, quite contrary to the very narrow bandwidths typical of CW lasers. The lasing medium in some dye lasers and vibronic solid-state lasers produces optical gain over a wide bandwidth, making a laser possible that can thus generate pulses of light as short as a few femtoseconds (10\u221215 s).\n\n\n==== Q-switching ====\n\nIn a Q-switched laser, the population inversion is allowed to build up by introducing loss inside the resonator which exceeds the gain of the medium; this can also be described as a reduction of the quality factor or 'Q' of the cavity. Then, after the pump energy stored in the laser medium has approached the maximum possible level, the introduced loss mechanism (often an electro- or acousto-optical element) is rapidly removed (or that occurs by itself in a passive device), allowing lasing to begin which rapidly obtains the stored energy in the gain medium. This results in a short pulse incorporating that energy, and thus a high peak power.\n\n\n==== Mode locking ====\n\nA mode-locked laser is capable of emitting extremely short pulses on the order of tens of picoseconds down to less than 10 femtoseconds. These pulses repeat at the round-trip time, that is, the time that it takes light to complete one round trip between the mirrors comprising the resonator. Due to the Fourier limit (also known as energy\u2013time uncertainty), a pulse of such short temporal length has a spectrum spread over a considerable bandwidth. Thus such a gain medium must have a gain bandwidth sufficiently broad to amplify those frequencies. An example of a suitable material is titanium-doped, artificially grown sapphire (Ti:sapphire), which has a very wide gain bandwidth and can thus produce pulses of only a few femtoseconds duration.\nSuch mode-locked lasers are a most versatile tool for researching processes occurring on extremely short time scales (known as femtosecond physics, femtosecond chemistry and ultrafast science), for maximizing the effect of nonlinearity in optical materials (e.g. in second-harmonic generation, parametric down-conversion, optical parametric oscillators and the like). Unlike the giant pulse of a Q-switched laser, consecutive pulses from a mode-locked laser are phase-coherent, that is, the pulses (and not just their envelopes) are identical and perfectly periodic. For this reason, and the extremely large peak powers attained by such short pulses, such lasers are invaluable in certain areas of research.\n\n\n==== Pulsed pumping ====\nAnother method of achieving pulsed laser operation is to pump the laser material with a source that is itself pulsed, either through electronic charging in the case of flash lamps, or another laser that is already pulsed. Pulsed pumping was historically used with dye lasers where the inverted population lifetime of a dye molecule was so short that a high-energy, fast pump was needed. The way to overcome this problem was to charge up large capacitors which are then switched to discharge through flashlamps, producing an intense flash. Pulsed pumping is also required for three-level lasers in which the lower energy level rapidly becomes highly populated preventing further lasing until those atoms relax to the ground state. These lasers, such as the excimer laser and the copper vapor laser, can never be operated in CW mode.\n\n\n== History ==\n\n\n=== Foundations ===\nIn 1917, Albert Einstein established the theoretical foundations for the laser and the maser in the paper \"Zur Quantentheorie der Strahlung\" (\"On the Quantum Theory of Radiation\") via a re-derivation of Max Planck's law of radiation, conceptually based upon probability coefficients (Einstein coefficients) for the absorption, spontaneous emission, and stimulated emission of electromagnetic radiation. In 1928, Rudolf W. Ladenburg confirmed the existence of the phenomena of stimulated emission and negative absorption. In 1939, Valentin A. Fabrikant predicted the use of stimulated emission to amplify \"short\" waves. In 1947, Willis E. Lamb and R. C. Retherford found apparent stimulated emission in hydrogen spectra and effected the first demonstration of stimulated emission. In 1950, Alfred Kastler (Nobel Prize for Physics 1966) proposed the method of optical pumping, which was experimentally demonstrated two years later by Brossel, Kastler, and Winter.\n\n\n=== Maser ===\n\nIn 1951, Joseph Weber submitted a paper on using stimulated emissions to make a microwave amplifier to the June 1952 Institute of Radio Engineers Vacuum Tube Research Conference at Ottawa, Ontario, Canada. After this presentation, RCA asked Weber to give a seminar on this idea, and Charles H. Townes asked him for a copy of the paper.\n\nIn 1953, Charles H. Townes and graduate students James P. Gordon and Herbert J. Zeiger produced the first microwave amplifier, a device operating on similar principles to the laser, but amplifying microwave radiation rather than infrared or visible radiation. Townes's maser was incapable of continuous output. Meanwhile, in the Soviet Union, Nikolay Basov and Aleksandr Prokhorov were independently working on the quantum oscillator and solved the problem of continuous-output systems by using more than two energy levels. These gain media could release stimulated emissions between an excited state and a lower excited state, not the ground state, facilitating the maintenance of a population inversion. In 1955, Prokhorov and Basov suggested optical pumping of a multi-level system as a method for obtaining the population inversion, later a main method of laser pumping.\nTownes reports that several eminent physicists\u2014among them Niels Bohr, John von Neumann, and Llewellyn Thomas\u2014argued the maser violated Heisenberg's uncertainty principle and hence could not work. Others such as Isidor Rabi and Polykarp Kusch expected that it would be impractical and not worth the effort. In 1964 Charles H. Townes, Nikolay Basov, and Aleksandr Prokhorov shared the Nobel Prize in Physics, \"for fundamental work in the field of quantum electronics, which has led to the construction of oscillators and amplifiers based on the maser\u2013laser principle\".\n\n\n=== Laser ===\nIn April 1957, Japanese engineer Jun-ichi Nishizawa proposed the concept of a \"semiconductor optical maser\" in a patent application.\nThat same year, Charles H. Townes and Arthur Leonard Schawlow, then at Bell Labs, began a serious study of infrared \"optical masers\". As ideas developed, they abandoned infrared radiation to instead concentrate on visible light. In 1958, Bell Labs filed a patent application for their proposed optical maser; and Schawlow and Townes submitted a manuscript of their theoretical calculations to the Physical Review, which was published in 1958.\n\nSimultaneously Columbia University, graduate student Gordon Gould was working on a doctoral thesis about the energy levels of excited thallium. When Gould and Townes met, they spoke of radiation emission, as a general subject; afterward, in November 1957, Gould noted his ideas for a \"laser\", including using an open resonator (later an essential laser-device component). Moreover, in 1958, Prokhorov independently proposed using an open resonator, the first published appearance of this idea. Meanwhile, Schawlow and Townes had decided on an open-resonator laser design \u2013 apparently unaware of Prokhorov's publications and Gould's unpublished laser work.\nAt a conference in 1959, Gordon Gould first published the acronym \"LASER\" in the paper The LASER, Light Amplification by Stimulated Emission of Radiation. Gould's intention was that different \"-ASER\" acronyms should be used for different parts of the spectrum: \"XASER\" for x-rays, \"UVASER\" for ultraviolet, etc. \"LASER\" ended up becoming the generic term for non-microwave devices, although \"RASER\" was briefly popular for denoting radio-frequency-emitting devices.\nGould's notes included possible applications for a laser, such as spectrometry, interferometry, radar, and nuclear fusion. He continued developing the idea and filed a patent application in April 1959. The United States Patent and Trademark Office (USPTO) denied his application, and awarded a patent to Bell Labs, in 1960. That provoked a twenty-eight-year lawsuit, featuring scientific prestige and money as the stakes. Gould won his first minor patent in 1977, yet it was not until 1987 that he won the first significant patent lawsuit victory when a Federal judge ordered the USPTO to issue patents to Gould for the optically pumped and the gas discharge laser devices. The question of just how to assign credit for inventing the laser remains unresolved by historians.On May 16, 1960, Theodore H. Maiman operated the first functioning laser at Hughes Research Laboratories, Malibu, California, ahead of several research teams, including those of Townes, at Columbia University, Arthur L. Schawlow, at Bell Labs, and Gould, at the TRG (Technical Research Group) company. Maiman's functional laser used a flashlamp-pumped synthetic ruby crystal to produce red laser light at 694 nanometers wavelength. The device was only capable of pulsed operation, due to its three-level pumping design scheme. Later that year, the Iranian physicist Ali Javan, and William R. Bennett Jr., and Donald R. Herriott, constructed the first gas laser, using helium and neon that was capable of continuous operation in the infrared (U.S. Patent 3,149,290); later, Javan received the Albert Einstein World Award of Science in 1993. Basov and Javan proposed the semiconductor laser diode concept. In 1962, Robert N. Hall demonstrated the first laser diode device, which was made of gallium arsenide and emitted in the near-infrared band of the spectrum at 850 nm. Later that year, Nick Holonyak Jr. demonstrated the first semiconductor laser with a visible emission. This first semiconductor laser could only be used in pulsed-beam operation, and when cooled to liquid nitrogen temperatures (77 K). In 1970, Zhores Alferov, in the USSR, and Izuo Hayashi and Morton Panish of Bell Labs also independently developed room-temperature, continual-operation diode lasers, using the heterojunction structure.\n\n\n=== Recent innovations ===\n\nSince the early period of laser history, laser research has produced a variety of improved and specialized laser types, optimized for different performance goals, including:\n\nnew wavelength bands\nmaximum average output power\nmaximum peak pulse energy\nmaximum peak pulse power\nminimum output pulse duration\nminimum linewidth\nmaximum power efficiency\nminimum costand this research continues to this day.\nIn 2015, researchers made a white laser, whose light is modulated by a synthetic nanosheet made out of zinc, cadmium, sulfur, and selenium that can emit red, green, and blue light in varying proportions, with each wavelength spanning 191 nm.In 2017, researchers at the Delft University of Technology demonstrated an AC Josephson junction microwave laser. Since the laser operates in the superconducting regime, it is more stable than other semiconductor-based lasers. The device has the potential for applications in quantum computing. In 2017, researchers at the Technical University of Munich demonstrated the smallest mode locking laser capable of emitting pairs of phase-locked picosecond laser pulses with a repetition frequency up to 200 GHz.In 2017, researchers from the Physikalisch-Technische Bundesanstalt (PTB), together with US researchers from JILA, a joint institute of the National Institute of Standards and Technology (NIST) and the University of Colorado Boulder, established a new world record by developing an erbium-doped fiber laser with a linewidth of only 10 millihertz.\n\n\n== Types and operating principles ==\n\n\n=== Gas lasers ===\n\nFollowing the invention of the HeNe gas laser, many other gas discharges have been found to amplify light coherently.\nGas lasers using many different gases have been built and used for many purposes. The helium\u2013neon laser (HeNe) can operate at many different wavelengths, however, the vast majority are engineered to lase at 633 nm; these relatively low-cost but highly coherent lasers are extremely common in optical research and educational laboratories. Commercial carbon dioxide (CO2) lasers can emit many hundreds of watts in a single spatial mode which can be concentrated into a tiny spot. This emission is in the thermal infrared at 10.6 \u00b5m; such lasers are regularly used in industry for cutting and welding. The efficiency of a CO2 laser is unusually high: over 30%. Argon-ion lasers can operate at several lasing transitions between 351 and 528.7 nm. Depending on the optical design one or more of these transitions can be lasing simultaneously; the most commonly used lines are 458 nm, 488 nm and 514.5 nm. A nitrogen transverse electrical discharge in gas at atmospheric pressure (TEA) laser is an inexpensive gas laser, often home-built by hobbyists, which produces rather incoherent UV light at 337.1 nm. Metal ion lasers are gas lasers that generate deep ultraviolet wavelengths. Helium-silver (HeAg) 224 nm and neon-copper (NeCu) 248 nm are two examples. Like all low-pressure gas lasers, the gain media of these lasers have quite narrow oscillation linewidths, less than 3 GHz (0.5 picometers), making them candidates for use in fluorescence suppressed Raman spectroscopy.\nLasing without maintaining the medium excited into a population inversion was demonstrated in 1992 in sodium gas and again in 1995 in rubidium gas by various international teams. This was accomplished by using an external maser to induce \"optical transparency\" in the medium by introducing and destructively interfering the ground electron transitions between two paths so that the likelihood for the ground electrons to absorb any energy has been canceled.\n\n\n==== Chemical lasers ====\nChemical lasers are powered by a chemical reaction permitting a large amount of energy to be released quickly. Such very high-power lasers are especially of interest to the military, however continuous wave chemical lasers at very high power levels, fed by streams of gasses, have been developed and have some industrial applications. As examples, in the hydrogen fluoride laser (2700\u20132900 nm) and the deuterium fluoride laser (3800 nm) the reaction is the combination of hydrogen or deuterium gas with combustion products of ethylene in nitrogen trifluoride.\n\n\n==== Excimer lasers ====\nExcimer lasers are a special sort of gas laser powered by an electric discharge in which the lasing medium is an excimer, or more precisely an exciplex in existing designs. These are molecules that can only exist with one atom in an excited electronic state. Once the molecule transfers its excitation energy to a photon, its atoms are no longer bound to each other and the molecule disintegrates. This drastically reduces the population of the lower energy state thus greatly facilitating a population inversion. Excimers currently used are all noble gas compounds; noble gasses are chemically inert and can only form compounds while in an excited state. Excimer lasers typically operate at ultraviolet wavelengths with major applications including semiconductor photolithography and LASIK eye surgery. Commonly used excimer molecules include ArF (emission at 193 nm), KrCl (222 nm), KrF (248 nm), XeCl (308 nm), and XeF (351 nm).\nThe molecular fluorine laser, emitting at 157 nm in the vacuum ultraviolet is sometimes referred to as an excimer laser, however, this appears to be a misnomer since F2 is a stable compound.\n\n\n=== Solid-state lasers ===\n\nSolid-state lasers use a crystalline or glass rod that is \"doped\" with ions that provide the required energy states. For example, the first working laser was a ruby laser, made from ruby (chromium-doped corundum). The population inversion is maintained in the dopant. These materials are pumped optically using a shorter wavelength than the lasing wavelength, often from a flash tube or another laser. The usage of the term \"solid-state\" in laser physics is narrower than in typical use. Semiconductor lasers (laser diodes) are typically not referred to as solid-state lasers.\nNeodymium is a common dopant in various solid-state laser crystals, including yttrium orthovanadate (Nd:YVO4), yttrium lithium fluoride (Nd:YLF) and yttrium aluminium garnet (Nd:YAG). All these lasers can produce high powers in the infrared spectrum at 1064 nm. They are used for cutting, welding, and marking of metals and other materials, and also in spectroscopy and for pumping dye lasers. These lasers are also commonly frequency doubled, tripled or quadrupled to produce 532 nm (green, visible), 355 nm and 266 nm (UV) beams, respectively. Frequency-doubled diode-pumped solid-state (DPSS) lasers are used to make bright green laser pointers.\nYtterbium, holmium, thulium, and erbium are other common \"dopants\" in solid-state lasers. Ytterbium is used in crystals such as Yb:YAG, Yb:KGW, Yb:KYW, Yb:SYS, Yb:BOYS, Yb:CaF2, typically operating around 1020\u20131050 nm. They are potentially very efficient and high-powered due to a small quantum defect. Extremely high powers in ultrashort pulses can be achieved with Yb:YAG. Holmium-doped YAG crystals emit at 2097 nm and form an efficient laser operating at infrared wavelengths strongly absorbed by water-bearing tissues. The Ho-YAG is usually operated in a pulsed mode and passed through optical fiber surgical devices to resurface joints, remove rot from teeth, vaporize cancers, and pulverize kidney and gall stones.\nTitanium-doped sapphire (Ti:sapphire) produces a highly tunable infrared laser, commonly used for spectroscopy. It is also notable for use as a mode-locked laser producing ultrashort pulses of extremely high peak power.\nThermal limitations in solid-state lasers arise from unconverted pump power that heats the medium. This heat, when coupled with a high thermo-optic coefficient (dn/dT) can cause thermal lensing and reduce the quantum efficiency. Diode-pumped thin disk lasers overcome these issues by having a gain medium that is much thinner than the diameter of the pump beam. This allows for a more uniform temperature in the material. Thin disk lasers have been shown to produce beams of up to one kilowatt.\n\n\n=== Fiber lasers ===\n\nSolid-state lasers or laser amplifiers where the light is guided due to the total internal reflection in a single mode optical fiber are instead called fiber lasers. Guiding of light allows extremely long gain regions providing good cooling conditions; fibers have a high surface area to volume ratio which allows efficient cooling. In addition, the fiber's waveguiding properties tend to reduce the thermal distortion of the beam. Erbium and ytterbium ions are common active species in such lasers.\nQuite often, the fiber laser is designed as a double-clad fiber. This type of fiber consists of a fiber core, an inner cladding, and an outer cladding. The index of the three concentric layers is chosen so that the fiber core acts as a single-mode fiber for the laser emission while the outer cladding acts as a highly multimode core for the pump laser. This lets the pump propagate a large amount of power into and through the active inner core region, while still having a high numerical aperture (NA) to have easy launching conditions.\nPump light can be used more efficiently by creating a fiber disk laser, or a stack of such lasers.\nFiber lasers have a fundamental limit in that the intensity of the light in the fiber cannot be so high that optical nonlinearities induced by the local electric field strength can become dominant and prevent laser operation and/or lead to the material destruction of the fiber. This effect is called photodarkening. In bulk laser materials, the cooling is not so efficient, and it is difficult to separate the effects of photodarkening from the thermal effects, but the experiments in fibers show that the photodarkening can be attributed to the formation of long-living color centers.\n\n\n=== Photonic crystal lasers ===\nPhotonic crystal lasers are lasers based on nano-structures that provide the mode confinement and the density of optical states (DOS) structure required for the feedback to take place. They are typical micrometer-sized and tunable on the bands of the photonic crystals.\n\n\n=== Semiconductor lasers ===\n\nSemiconductor lasers are diodes that are electrically pumped. Recombination of electrons and holes created by the applied current introduces optical gain. Reflection from the ends of the crystal forms an optical resonator, although the resonator can be external to the semiconductor in some designs.\nCommercial laser diodes emit at wavelengths from 375 nm to 3500 nm. Low to medium power laser diodes are used in laser pointers, laser printers and CD/DVD players. Laser diodes are also frequently used to optically pump other lasers with high efficiency. The highest-power industrial laser diodes, with power of up to 20 kW, are used in industry for cutting and welding. External-cavity semiconductor lasers have a semiconductor active medium in a larger cavity. These devices can generate high power outputs with good beam quality, wavelength-tunable narrow-linewidth radiation, or ultrashort laser pulses.\nIn 2012, Nichia and OSRAM developed and manufactured commercial high-power green laser diodes (515/520 nm), which compete with traditional diode-pumped solid-state lasers.Vertical cavity surface-emitting lasers (VCSELs) are semiconductor lasers whose emission direction is perpendicular to the surface of the wafer. VCSEL devices typically have a more circular output beam than conventional laser diodes. As of 2005, only 850 nm VCSELs are widely available, with 1300 nm VCSELs beginning to be commercialized, and 1550 nm devices an area of research. VECSELs are external-cavity VCSELs. Quantum cascade lasers are semiconductor lasers that have an active transition between energy sub-bands of an electron in a structure containing several quantum wells.\nThe development of a silicon laser is important in the field of optical computing. Silicon is the material of choice for integrated circuits, and so electronic and silicon photonic components (such as optical interconnects) could be fabricated on the same chip. Unfortunately, silicon is a difficult lasing material to deal with, since it has certain properties which block lasing. However, recently teams have produced silicon lasers through methods such as fabricating the lasing material from silicon and other semiconductor materials, such as indium(III) phosphide or gallium(III) arsenide, materials that allow coherent light to be produced from silicon. These are called hybrid silicon laser. Recent developments have also shown the use of monolithically integrated nanowire lasers directly on silicon for optical interconnects, paving the way for chip-level applications. These heterostructure nanowire lasers capable of optical interconnects in silicon are also capable of emitting pairs of phase-locked picosecond pulses with a repetition frequency up to 200 GHz, allowing for on-chip optical signal processing. Another type is a Raman laser, which takes advantage of Raman scattering to produce a laser from materials such as silicon.\n\n\n=== Dye lasers ===\n\nDye lasers use an organic dye as the gain medium. The wide gain spectrum of available dyes, or mixtures of dyes, allows these lasers to be highly tunable, or to produce very short-duration pulses (on the order of a few femtoseconds). Although these tunable lasers are mainly known in their liquid form, researchers have also demonstrated narrow-linewidth tunable emission in dispersive oscillator configurations incorporating solid-state dye gain media. In their most prevalent form, these solid state dye lasers use dye-doped polymers as laser media.\n\n\n=== Free-electron lasers ===\n\nFree-electron lasers (FEL) generate coherent, high-power radiation that is widely tunable, currently ranging in wavelength from microwaves through terahertz radiation and infrared to the visible spectrum, to soft X-rays. They have the widest frequency range of any laser type. While FEL beams share the same optical traits as other lasers, such as coherent radiation, FEL operation is quite different. Unlike gas, liquid, or solid-state lasers, which rely on bound atomic or molecular states, FELs use a relativistic electron beam as the lasing medium, hence the term free-electron.\n\n\n=== Exotic media ===\nThe pursuit of a high-quantum-energy laser using transitions between isomeric states of an atomic nucleus has been the subject of wide-ranging academic research since the early 1970s.  Much of this is summarized in three review articles. This research has been international in scope but mainly based in the former Soviet Union and the United States.  While many scientists remain optimistic that a breakthrough is near, an operational gamma-ray laser is yet to be realized.Some of the early studies were directed toward short pulses of neutrons exciting the upper isomer state in a solid so the gamma-ray transition could benefit from the line-narrowing of M\u00f6ssbauer effect. In conjunction, several advantages were expected from two-stage pumping of a three-level system. It was conjectured that the nucleus of an atom, embedded in the near field of a laser-driven coherently-oscillating electron cloud would experience a larger dipole field than that of the driving laser. Furthermore, the nonlinearity of the oscillating cloud would produce both spatial and temporal harmonics, so nuclear transitions of higher multipolarity could also be driven at multiples of the laser frequency.In September 2007, the BBC News reported that there was speculation about the possibility of using positronium annihilation to drive a very powerful gamma ray laser. Dr. David Cassidy of the University of California, Riverside proposed that a single such laser could be used to ignite a nuclear fusion reaction, replacing the banks of hundreds of lasers currently employed in inertial confinement fusion experiments.Space-based X-ray lasers pumped by a nuclear explosion have also been proposed as antimissile weapons. Such devices would be one-shot weapons.\nLiving cells have been used to produce laser light. The cells were genetically engineered to produce green fluorescent protein, which served as the laser's gain medium. The cells were then placed between two 20-micrometer-wide mirrors, which acted as the laser cavity. When the cell was illuminated with blue light, it emitted intensely directed green laser light.\n\n\n=== Natural lasers ===\nLike astrophysical masers, irradiated planetary or stellar gases may amplify light producing a natural laser.  Mars, Venus and MWC 349 exhibit this phenomenon.\n\n\n== Uses ==\n\nWhen lasers were invented in 1960, they were called \"a solution looking for a problem\". Since then, they have become ubiquitous, finding utility in thousands of highly varied applications in every section of modern society, including consumer electronics, information technology, science, medicine, industry, law enforcement, entertainment, and the military. Fiber-optic communication using lasers is a key technology in modern communications, allowing services such as the Internet.\nThe first widely noticeable use of lasers was the supermarket barcode scanner, introduced in 1974. The laserdisc player, introduced in 1978, was the first successful consumer product to include a laser but the compact disc player was the first laser-equipped device to become common, beginning in 1982 followed shortly by laser printers.\nSome other uses are:\n\nCommunications: besides fiber-optic communication, lasers are used for free-space optical communication, including laser communication in space\nMedicine: see below\nIndustry: cutting including converting thin materials, welding, material heat treatment, marking parts (engraving and bonding), additive manufacturing or 3D printing processes such as selective laser sintering and selective laser melting, non-contact measurement of parts and 3D scanning, and laser cleaning.\nMilitary: marking targets, guiding munitions, missile defense, electro-optical countermeasures (EOCM), lidar, blinding troops, firearms sight. See below\nLaw enforcement: LIDAR traffic enforcement. Lasers are used for latent fingerprint detection in the forensic identification field\nResearch: spectroscopy, laser ablation, laser annealing, laser scattering, laser interferometry, lidar, laser capture microdissection, fluorescence microscopy, metrology, laser cooling\nCommercial products: laser printers, barcode scanners, thermometers, laser pointers, holograms, bubblegrams\nEntertainment: optical discs, laser lighting displays, laser turntablesIn 2004, excluding diode lasers, approximately 131,000 lasers were sold with a value of US$2.19 billion. In the same year, approximately 733 million diode lasers, valued at US$3.20 billion, were sold.\n\n\n=== In medicine ===\n\nLasers have many uses in medicine, including laser surgery (particularly eye surgery), laser healing (photobiomodulation therapy), kidney stone treatment, ophthalmoscopy, and cosmetic skin treatments such as acne treatment, cellulite and striae reduction, and hair removal.\nLasers are used to treat cancer by shrinking or destroying tumors or precancerous growths. They are most commonly used to treat superficial cancers that are on the surface of the body or the lining of internal organs. They are used to treat basal cell skin cancer and the very early stages of others like cervical, penile, vaginal, vulvar, and non-small cell lung cancer. Laser therapy is often combined with other treatments, such as surgery, chemotherapy, or radiation therapy. Laser-induced interstitial thermotherapy (LITT), or interstitial laser photocoagulation, uses lasers to treat some cancers using hyperthermia, which uses heat to shrink tumors by damaging or killing cancer cells. Lasers are more precise than traditional surgery methods and cause less damage, pain, bleeding, swelling, and scarring. A disadvantage is that surgeons must acquire specialized training and thus it will likely be more expensive than other treatments.\n\n\n=== As weapons ===\n\nA laser weapon is a laser that is used as a directed-energy weapon.\n\n\n=== Hobbies ===\nIn recent years, some hobbyists have taken an interest in lasers. Lasers used by hobbyists are generally of class IIIa or IIIb (see safety), although some have made their own class IV types. However, compared to other hobbyists, laser hobbyists are far less common, due to the cost and potential dangers involved. Due to the cost of lasers, some hobbyists use inexpensive means to obtain lasers, such as salvaging laser diodes from broken DVD players (red), Blu-ray players (violet), or even higher power laser diodes from CD or DVD burners.Hobbyists have also used surplus lasers taken from retired military applications and modified them for holography. Pulsed ruby and YAG lasers work well for this application.\n\n\n=== Examples by power ===\n\nDifferent applications need lasers with different output powers. Lasers that produce a continuous beam or a series of short pulses can be compared on the basis of their average power. Lasers that produce pulses can also be characterized based on the peak power of each pulse. The peak power of a pulsed laser is many orders of magnitude greater than its average power. The average output power is always less than the power consumed.\n\nExamples of pulsed systems with high peak power:\n\n700 TW (700\u00d71012 W)\u2014National Ignition Facility, a 192-beam, 1.8-megajoule laser system adjoining a 10-meter-diameter target chamber\n10 PW (10\u00d71015 W)\u2014world's most powerful laser as of 2019, located at the ELI-NP facility in M\u0103gurele, Romania.\n\n\n== Safety ==\n\nEven the first laser was recognized as being potentially dangerous. Theodore Maiman characterized the first laser as having the power of one \"Gillette\" as it could burn through one Gillette razor blade. Today, it is accepted that even low-power lasers with only a few milliwatts of output power can be hazardous to human eyesight when the beam hits the eye directly or after reflection from a shiny surface. At wavelengths which the cornea and the lens can focus well, the coherence and low divergence of laser light means that it can be focused by the eye into an extremely small spot on the retina, resulting in localized burning and permanent damage in seconds or even less time.\nLasers are usually labeled with a safety class number, which identifies how dangerous the laser is:\n\nClass 1 is inherently safe, usually because the light is contained in an enclosure, for example in CD players\nClass 2 is safe during normal use; the blink reflex of the eye will prevent damage. Usually up to 1 mW power, for example, laser pointers.\nClass 3R (formerly IIIa) lasers are usually up to 5 mW and involve a small risk of eye damage within the time of the blink reflex. Staring into such a beam for several seconds is likely to cause damage to a spot on the retina.\nClass 3B lasers (5\u2013499 mW) can cause immediate eye damage upon exposure\nClass 4 lasers (\u2265 500 mW) can burn skin, and in some cases, even scattered light from these lasers can cause eye and/or skin damage. Many industrial and scientific lasers are in this class.The indicated powers are for visible-light, continuous-wave lasers. For pulsed lasers and invisible wavelengths, other power limits apply. People working with class 3B and class 4 lasers can protect their eyes with safety goggles which are designed to absorb light of a particular wavelength.\nInfrared lasers with wavelengths longer than about 1.4 micrometers are often referred to as \"eye-safe\", because the cornea tends to absorb light at these wavelengths, protecting the retina from damage. The label \"eye-safe\" can be misleading, however, as it applies only to relatively low-power continuous wave beams; a high-power or Q-switched laser at these wavelengths can burn the cornea, causing severe eye damage, and even moderate-power lasers can injure the eye.\nLasers can be a hazard to both civil and military aviation, due to the potential to temporarily distract or blind pilots. See Lasers and aviation safety for more on this topic.\nCameras based on charge-coupled devices may be more sensitive to laser damage than biological eyes.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n=== Books ===\nBertolotti, Mario (1999, trans. 2004). The History of the Laser. Institute of Physics. ISBN 0-7503-0911-3.\nBromberg, Joan Lisa (1991). The Laser in America, 1950\u20131970. MIT Press. ISBN 978-0-262-02318-4.\nCsele, Mark (2004). Fundamentals of Light Sources and Lasers. Wiley. ISBN 0-471-47660-9.\nKoechner, Walter (1992). Solid-State Laser Engineering. 3rd ed. Springer-Verlag. ISBN 0-387-53756-2.\nSiegman, Anthony E. (1986). Lasers. University Science Books. ISBN 0-935702-11-3.\nSilfvast, William T. (1996). Laser Fundamentals. Cambridge University Press. ISBN 0-521-55617-1.\nSvelto, Orazio (1998). Principles of Lasers. 4th ed. Trans. David Hanna. Springer. ISBN 0-306-45748-2.\nTaylor, Nick (2000). LASER: The inventor, the Nobel laureate, and the thirty-year patent war. New York: Simon & Schuster. ISBN 978-0-684-83515-0.\nWilson, J. & Hawkes, J.F.B. (1987). Lasers: Principles and Applications. Prentice Hall International Series in Optoelectronics, Prentice Hall. ISBN 0-13-523697-5.\nYariv, Amnon (1989). Quantum Electronics. 3rd ed. Wiley. ISBN 0-471-60997-8.\n\n\n=== Periodicals ===\nApplied Physics B: Lasers and Optics (ISSN 0946-2171)\nIEEE Journal of Lightwave Technology (ISSN 0733-8724)\nIEEE Journal of Quantum Electronics (ISSN 0018-9197)\nIEEE Journal of Selected Topics in Quantum Electronics (ISSN 1077-260X)\nIEEE Photonics Technology Letters (ISSN 1041-1135)\nJournal of the Optical Society of America B: Optical Physics (ISSN 0740-3224)\nLaser Focus World (ISSN 0740-2511)\nOptics Letters (ISSN 0146-9592)\nPhotonics Spectra (ISSN 0731-1230)\n\n\n== External links ==\n\nEncyclopedia of laser physics and technology by Dr. R\u00fcdiger Paschotta\nA Practical Guide to Lasers for Experimenters and Hobbyists by Samuel M. Goldwasser\nHomebuilt Lasers Page by Professor Mark Csele\nPowerful laser is 'brightest light in the universe'\u2014The world's most powerful laser as of 2008 might create supernova-like shock waves and possibly even antimatter\n\"Laser Fundamentals\" an online course by Prof. F. Balembois and Dr. S. Forget.\nNorthrop Grumman's Press Release on the Firestrike 15 kW tactical laser product\nWebsite on Lasers 50th anniversary by APS, OSA, SPIE\nAdvancing the Laser anniversary site by SPIE: Video interviews, open-access articles, posters, DVDs\nBright Idea: The First Lasers Archived October 3, 2012, at the Wayback Machine history of the invention, with audio interview clips.\nFree software for Simulation of random laser dynamics\nVideo Demonstrations in Lasers and Optics Produced by the Massachusetts Institute of Technology (MIT). Real-time effects are demonstrated in a way that would be difficult to see in a classroom setting.\nMIT Video Lecture: Understanding Lasers and Fiberoptics\nVirtual Museum of Laser History, from the touring exhibit by SPIE\nwebsite with animations, applications and research about laser and other quantum based phenomena Universite Paris Sud", "Work_(physics)": "In physics, work is the energy transferred to or from an object via the application of force along a displacement. In its simplest form, for a constant force aligned with the direction of motion, the work equals the product of the force strength and the distance traveled. A force is said to do positive work if when applied it has a component in the direction of the displacement of the point of application. A force does negative work if it has a component opposite to the direction of the displacement at the point of application of the force.For example, when a ball is held above the ground and then dropped, the work done by the gravitational force on the ball as it falls is positive, and is equal to the weight of the ball (a force) multiplied by the distance to the ground (a displacement). If the ball is thrown upwards, the work done by its weight is negative, and is equal to the weight multiplied by the displacement in the upwards direction.\nBoth force and displacement are vectors. The work done is given by the dot product of the two vectors. When the force F is constant and the angle \u03b8 between the force and the displacement s is also constant, then the work done is given by:\n\nWork is a scalar quantity, so it has only magnitude and no direction. Work transfers energy from one place to another, or one form to another. The SI unit of work is the joule (J), the same unit as for energy.\n\n\n== History ==\nThe ancient Greek understanding of physics was limited to the statics of simple machines (the balance of forces), and did not include dynamics or the concept of work. During the Renaissance the dynamics of the Mechanical Powers, as the simple machines were called, began to be studied from the standpoint of how far they could lift a load, in addition to the force they could apply, leading eventually to the new concept of mechanical work. The complete dynamic theory of simple machines was worked out by Italian scientist Galileo Galilei in 1600 in Le Meccaniche (On Mechanics), in which he showed the underlying mathematical similarity of the machines as force amplifiers. He was the first to explain that simple machines do not create energy, only transform it.\n\n\n=== Etymology ===\nAccording to the 1957 physics textbook by Max Jammer, the term work was introduced in 1826 by the French mathematician Gaspard-Gustave Coriolis as \"weight lifted through a height\", which is based on the use of early steam engines to lift buckets of water out of flooded ore mines. According to Rene Dugas, French engineer and historian, it is to Solomon of Caux \"that we owe the term work in the sense that it is used in mechanics now\".Although work was not formally used until 1826, similar concepts existed before then.  In 1759, John Smeaton described a quantity that he called \"power\" \"to signify the exertion of strength, gravitation, impulse, or pressure, as to produce motion.\"  Smeaton continues that this quantity can be calculated if \"the weight raised is multiplied by the height to which it can be raised in a given time,\" making this definition remarkably similar to Coriolis'.Before the name of the concept settled upon \"work\", other names for the same concept included moment of activity, quantity of action, latent live force, dynamic effect, efficiency, and even force.\n\n\n== Units ==\nThe SI unit of work is the joule (J), named after the 19th-century English physicist James Prescott Joule, which is defined as the work required to exert a force of one newton through a displacement of one metre.\nThe dimensionally equivalent newton-metre (N\u22c5m) is sometimes used as the measuring unit for work, but this can be confused with the measurement unit of torque. Usage of N\u22c5m is discouraged by the SI authority, since it can lead to confusion as to whether the quantity expressed in newton-metres is a torque measurement, or a measurement of work.Non-SI units of work include the newton-metre, erg, the foot-pound, the foot-poundal, the kilowatt hour, the litre-atmosphere, and the horsepower-hour.  Due to work having the same physical dimension as heat, occasionally measurement units typically reserved for heat or energy content, such as therm, BTU and calorie, are used as a measuring unit.\n\n\n== Work and energy ==\nThe work W done by a constant force of magnitude F on a point that moves a displacement s in a straight line in the direction of the force is the product\n\nFor example, if a force of 10 newtons (F = 10 N) acts along a point that travels 2 metres (s = 2 m), then W = Fs = (10 N) (2 m) = 20 J. This is approximately the work done lifting a 1 kg object from ground level to over a person's head against the force of gravity.\nThe work is doubled either by lifting twice the weight the same distance or by lifting the same weight twice the distance.\nWork is closely related to energy. The work\u2013energy principle states that an increase in the kinetic energy of a rigid body is caused by an equal amount of positive work done on the body by the resultant force acting on that body. Conversely, a decrease in kinetic energy is caused by an equal amount of negative work done by the resultant force. Thus, if the net work is positive, then the particle\u2019s kinetic energy increases by the amount of the work. If the net work done is negative, then the particle\u2019s kinetic energy decreases by the amount of work.From Newton's second law, it can be shown that work on a free (no fields), rigid (no internal degrees of freedom) body, is equal to the change in kinetic energy Ek corresponding to the linear velocity and angular velocity of that body,\n\nThe work of forces generated by a potential function is known as potential energy and the forces are said to be conservative. Therefore, work on an object that is merely displaced in a conservative force field, without change in velocity or rotation, is equal to minus the change of potential energy Ep of the object,\n\nThese formulas show that work is the energy associated with the action of a force, so work subsequently possesses the physical dimensions, and units, of energy.\nThe work/energy principles discussed here are identical to electric work/energy principles.\n\n\n== Constraint forces ==\nConstraint forces determine the object's displacement in the system, limiting it within a range. For example, in the case of a slope plus gravity, the object is stuck to the slope and, when attached to a taut string, it cannot move in an outwards direction to make the string any 'tauter'. It eliminates all displacements in that direction, that is, the velocity in the direction of the constraint is limited to 0, so that the constraint forces do not perform work on the system.\nFor a mechanical system, constraint forces eliminate movement in directions that characterize the constraint. Thus the virtual work done by the forces of constraint is zero, a result which is only true if friction forces are excluded.Fixed, frictionless constraint forces do not perform work on the system, as the angle between the motion and the constraint forces is always 90\u00b0. Examples of workless constraints are: rigid interconnections between particles, sliding motion on a frictionless surface, and rolling contact without slipping.For example, in a pulley system like the Atwood machine, the internal forces on the rope and at the supporting pulley do no work on the system. Therefore, work need only be computed for the gravitational forces acting on the bodies. Another example is the centripetal force exerted inwards by a string on a ball in uniform circular motion sideways constrains the ball to circular motion restricting its movement away from the centre of the circle. This force does zero work because it is perpendicular to the velocity of the ball.\nThe magnetic force on a charged particle is F = qv \u00d7 B, where q is the charge, v is the velocity of the particle, and B is the magnetic field. The result of a cross product is always perpendicular to both of the original vectors, so F \u22a5 v. The dot product of two perpendicular vectors is always zero, so the work W = F \u22c5 v = 0, and the magnetic force does not do work. It can change the direction of motion but never change the speed.\n\n\n== Mathematical calculation ==\nFor moving objects, the quantity of work/time (power) is integrated along the trajectory of the point of application of the force. Thus, at any instant, the rate of the work done by a force (measured in joules/second, or watts) is the scalar product of the force (a vector), and the velocity vector of the point of application. This scalar product of force and velocity is known as instantaneous power. Just as velocities may be integrated over time to obtain a total distance, by the fundamental theorem of calculus, the total work along a path is similarly the time-integral of instantaneous power applied along the trajectory of the point of application.Work is the result of a force on a point that follows a curve X, with a velocity v, at each instant.  The small amount of work \u03b4W that occurs over an instant of time dt is calculated as\n\nwhere the F \u22c5 v is the power over the instant dt.  The sum of these small amounts of work over the trajectory of the point yields the work,\n\nwhere C is the trajectory from x(t1) to x(t2).  This integral is computed along the trajectory of the particle, and is therefore said to be path dependent.\nIf the force is always directed along this line, and the magnitude of the force is F, then this integral simplifies to\n\nwhere s is displacement along the line. If F is constant, in addition to being directed along the line, then the integral simplifies further to\n\nwhere s is the displacement of the point along the line.\nThis calculation can be generalized for a constant force that is not directed along the line, followed by the particle.  In this case the dot product F \u22c5 ds = F cos \u03b8 ds, where \u03b8 is the angle between the force vector and the direction of movement, that is\n\nWhen a force component is perpendicular to the displacement of the object (such as when a body moves in a circular path under a central force), no work is done, since the cosine of 90\u00b0 is zero. Thus, no work can be performed by gravity on a planet with a circular orbit (this is ideal, as all orbits are slightly elliptical). Also, no work is done on a body moving circularly at a constant speed while constrained by mechanical force, such as moving at constant speed in a frictionless ideal centrifuge.\n\n\n=== Work done by a variable force ===\nCalculating the work as \"force times straight path segment\" would only apply in the most simple of circumstances, as noted above. If force is changing, or if the body is moving along a curved path, possibly rotating and not necessarily rigid, then only the path of the application point of the force is relevant for the work done, and only the component of the force parallel to the application point velocity is doing work (positive work when in the same direction, and negative when in the opposite direction of the velocity). This component of force can be described by the scalar quantity called scalar tangential component (F cos(\u03b8), where \u03b8 is the angle between the force and the velocity). And then the most general definition of work can be formulated as follows:\n\n\n=== Torque and rotation ===\nA force couple results from equal and opposite forces, acting on two different points of a rigid body.  The sum (resultant) of these forces may cancel, but their effect on the body is the couple or torque T.  The work of the torque is calculated as\n\nwhere the T \u22c5 \u03c9 is the power over the instant dt.  The sum of these small amounts of work over the trajectory of the rigid body yields the work,\n\nThis integral is computed along the trajectory of the rigid body with an angular velocity \u03c9 that varies with time, and is therefore said to be path dependent.\nIf the angular velocity vector maintains a constant direction, then it takes the form,\n\nwhere \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   is the angle of rotation about the constant unit vector S.  In this case, the work of the torque becomes,\n\nwhere C is the trajectory from \n  \n    \n      \n        \u03d5\n        (\n        \n          t\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle \\phi (t_{1})}\n   to \n  \n    \n      \n        \u03d5\n        (\n        \n          t\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\phi (t_{2})}\n  .  This integral depends on the rotational trajectory \n  \n    \n      \n        \u03d5\n        (\n        t\n        )\n      \n    \n    {\\displaystyle \\phi (t)}\n  , and is therefore path-dependent.\nIf the torque \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   is aligned with the angular velocity vector so that,\n\nand both the torque and angular velocity are constant, then the work takes the form,\n\nThis result can be understood more simply by considering the torque as arising from a force of constant magnitude F, being applied perpendicularly to a lever arm at a distance \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  , as shown in the figure.  This force will act through the distance along the circular arc \n  \n    \n      \n        l\n        =\n        s\n        =\n        r\n        \u03d5\n      \n    \n    {\\displaystyle l=s=r\\phi }\n  , so the work done is\n\nIntroduce the torque \u03c4 = Fr, to obtain\n\nas presented above.\nNotice that only the component of torque in the direction of the angular velocity vector contributes to the work.\n\n\n== Work and potential energy ==\nThe scalar product of a force F and the velocity v of its point of application defines the power input to a system at an instant of time.  Integration of this power over the trajectory of the point of application, C = x(t), defines the work input to the system by the force.\n\n\n=== Path dependence ===\nTherefore, the work done by a force F on an object that travels along a curve C is given by the line integral:\n\nwhere dx(t) defines the trajectory C and v is the velocity along this trajectory.\nIn general this integral requires that the path along which the velocity is defined, so the evaluation of work is said to be path dependent.\nThe time derivative of the integral for work yields the instantaneous power,\n\n\n=== Path independence ===\nIf the work for an applied force is independent of the path, then the work done by the force, by the gradient theorem, defines a potential function which is evaluated at the start and end of the trajectory of the point of application. This means that there is a potential function U(x), that can be evaluated at the two points x(t1) and x(t2) to obtain the work over any trajectory between these two points. It is tradition to define this function with a negative sign so that positive work is a reduction in the potential, that is\n\nThe function U(x) is called the potential energy associated with the applied force.  The force derived from such a potential function is said to be conservative. Examples of forces that have potential energies are gravity and spring forces.\nIn this case, the gradient of work yields\n\nand the force F is said to be \"derivable from a potential.\"Because the potential U defines a force F at every point x in space, the set of forces is called a force field.  The power applied to a body by a force field is obtained from the gradient of the work, or potential, in the direction of the velocity V of the body, that is\n\n\n=== Work by gravity ===\n\nIn the absence of other forces, gravity results in a constant downward acceleration of every freely moving object. Near Earth's surface the acceleration due to gravity is g = 9.8 m\u22c5s\u22122 and the gravitational force on an object of mass m is Fg = mg. It is convenient to imagine this gravitational force concentrated at the center of mass of the object.\nIf an object with weight mg is displaced upwards or downwards a vertical distance y2 \u2212 y1, the work W done on the object is:\n\nwhere Fg is weight (pounds in imperial units, and newtons in SI units), and \u0394y is the change in height y. Notice that the work done by gravity depends only on the vertical movement of the object. The presence of friction does not affect the work done on the object by its weight.\n\n\n=== Work by gravity in space ===\nThe force of gravity exerted by a mass M on another mass m is given by\n\nwhere r is the position vector from M to m and r\u0302 is the unit vector in the direction of r.\nLet the mass m move at the velocity v; then the work of gravity on this mass as it moves from position r(t1) to r(t2) is given by\n\nNotice that the position and velocity of the mass m are given by\n\nwhere er and et are the radial and tangential unit vectors directed relative to the vector from M to m, and we use the fact that \n  \n    \n      \n        d\n        \n          \n            e\n          \n          \n            r\n          \n        \n        \n          /\n        \n        d\n        t\n        =\n        \n          \n            \n              \u03b8\n              \u02d9\n            \n          \n        \n        \n          \n            e\n          \n          \n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle d\\mathbf {e} _{r}/dt={\\dot {\\theta }}\\mathbf {e} _{t}.}\n    Use this to simplify the formula for work of gravity to,\n\nThis calculation uses the fact that\n\nThe function\n\nis the gravitational potential function, also known as gravitational potential energy.  The negative sign follows the convention that work is gained from a loss of potential energy.\n\n\n=== Work by a spring ===\n\nConsider a spring that exerts a horizontal force F = (\u2212kx, 0, 0) that is proportional to its deflection in the x direction independent of how a body moves.  The work of this spring on a body moving along the space with the curve X(t) = (x(t), y(t), z(t)), is calculated using its velocity, v = (vx, vy, vz), to obtain\n\nFor convenience, consider contact with the spring occurs at t = 0, then the integral of the product of the distance x and the x-velocity, xvxdt, over time t is 1/2x2. The work is the product of the distance times the spring force, which is also dependent on distance; hence the x2 result.\n\n\n=== Work by a gas ===\nThe work \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n   done by a body of gas on its surroundings is:\n\nwhere P is pressure, V is volume, and a and b are initial and final volumes.\n\n\n== Work\u2013energy principle ==\nThe principle of work and kinetic energy (also known as the work\u2013energy principle) states that the work done by all forces acting on a particle (the work of the resultant force) equals the change in the kinetic energy of the particle.  That is, the work W done by the resultant force on a particle equals the change in the particle's kinetic energy \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}}\n  ,\nwhere \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   and \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{2}}\n   are the speeds of the particle before and after the work is done, and m is its mass.\nThe derivation of the work\u2013energy principle begins with Newton\u2019s second law of motion and the resultant force on a particle.  Computation of the scalar product of the force with the velocity of the particle evaluates the instantaneous power added to the system.\n(Constraints define the direction of movement of the particle by ensuring there is no component of velocity in the direction of the constraint force. This also means the constraint forces do not add to the instantaneous power.) The time integral of this scalar equation yields work from the instantaneous power, and kinetic energy from the scalar product of acceleration with velocity.  The fact that the work\u2013energy principle eliminates the constraint forces underlies Lagrangian mechanics.This section focuses on the work\u2013energy principle as it applies to particle dynamics.  In more general systems work can change the potential energy of a mechanical device, the thermal energy in a thermal system, or the electrical energy in an electrical device.  Work transfers energy from one place to another or one form to another.\n\n\n=== Derivation for a particle moving along a straight line ===\nIn the case the resultant force F is constant in both magnitude and direction, and parallel to the velocity of the particle, the particle is moving with constant acceleration a along a straight line. The relation between the net force and the acceleration is given by the equation F = ma (Newton's second law), and the particle displacement s can be expressed by the equation\n\nwhich follows from \n  \n    \n      \n        \n          v\n          \n            2\n          \n          \n            2\n          \n        \n        =\n        \n          v\n          \n            1\n          \n          \n            2\n          \n        \n        +\n        2\n        a\n        s\n      \n    \n    {\\displaystyle v_{2}^{2}=v_{1}^{2}+2as}\n   (see Equations of motion).\nThe work of the net force is calculated as the product of its magnitude and the particle displacement. Substituting the above equations, one obtains:\n\nOther derivation:\n\nIn the general case of rectilinear motion, when the net force F is not constant in magnitude, but is constant in direction, and parallel to the velocity of the particle, the work must be integrated along the path of the particle:\n\n\n=== General derivation of the work\u2013energy principle for a particle ===\nFor any net force acting on a particle moving along any curvilinear path, it can be demonstrated that its work equals the change in the kinetic energy of the particle by a simple derivation analogous to the equation above. It is known as the work\u2013energy principle:\n\nThe identity \n  \n    \n      \n        \n          a\n        \n        \u22c5\n        \n          v\n        \n        =\n        \n          \n            1\n            2\n          \n        \n        \n          \n            \n              d\n              \n                v\n                \n                  2\n                \n              \n            \n            \n              d\n              t\n            \n          \n        \n      \n    \n    {\\textstyle \\mathbf {a} \\cdot \\mathbf {v} ={\\frac {1}{2}}{\\frac {dv^{2}}{dt}}}\n   requires some algebra.\nFrom the identity \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        \n          v\n        \n        \u22c5\n        \n          v\n        \n      \n    \n    {\\textstyle v^{2}=\\mathbf {v} \\cdot \\mathbf {v} }\n   and definition \n  \n    \n      \n        \n          a\n        \n        =\n        \n          \n            \n              d\n              \n                v\n              \n            \n            \n              d\n              t\n            \n          \n        \n      \n    \n    {\\textstyle \\mathbf {a} ={\\frac {d\\mathbf {v} }{dt}}}\n  \nit follows\n\nThe remaining part of the above derivation is just simple calculus, same as in the preceding rectilinear case.\n\n\n=== Derivation for a particle in constrained movement ===\nIn particle dynamics, a formula equating work applied to a system to its change in kinetic energy is obtained as a first integral of Newton's second law of motion.  It is useful to notice that the resultant force used in Newton's laws can be separated into forces that are applied to the particle and forces imposed by constraints on the movement of the particle.  Remarkably, the work of a constraint force is zero, therefore only the work of the applied forces need be considered in the work\u2013energy principle.\nTo see this, consider a particle P that follows the trajectory X(t) with a force F acting on it.  Isolate the particle from its environment to expose constraint forces R, then Newton's Law takes the form\n\nwhere m is the mass of the particle.\n\n\n==== Vector formulation ====\nNote that n dots above a vector indicates its nth time derivative.\nThe scalar product of each side of Newton's law with the velocity vector yields\n\nbecause the constraint forces are perpendicular to the particle velocity.  Integrate this equation along its trajectory from the point X(t1) to the point X(t2) to obtain\n\nThe left side of this equation is the work of the applied force as it acts on the particle along the trajectory from time t1 to time t2.  This can also be written as\n\nThis integral is computed along the trajectory X(t) of the particle and is therefore path dependent.\nThe right side of the first integral of Newton's equations can be simplified using the following identity\n\n(see product rule for derivation). Now it is integrated explicitly to obtain the change in kinetic energy,\n\nwhere the kinetic energy of the particle is defined by the scalar quantity,\n\n\n==== Tangential and normal components ====\nIt is useful to resolve the velocity and acceleration vectors into tangential and normal components along the trajectory X(t), such that\n\nwhere\n\nThen, the scalar product of velocity with acceleration in Newton's second law takes the form\n\nwhere the kinetic energy of the particle is defined by the scalar quantity,\n\nThe result is the work\u2013energy principle for particle dynamics,\n\nThis derivation can be generalized to arbitrary rigid body systems.\n\n\n=== Moving in a straight line (skid to a stop) ===\nConsider the case of a vehicle moving along a straight horizontal trajectory under the action of a driving force and gravity that sum to F.  The constraint forces between the vehicle and the road define R, and we have\n\nFor convenience let the trajectory be along the X-axis, so X = (d, 0) and the velocity is V = (v, 0), then R \u22c5 V = 0, and F \u22c5 V = Fxv, where Fx is the component of F along the X-axis, so\n\nIntegration of both sides yields\n\nIf Fx is constant along the trajectory, then the integral of velocity is distance, so\n\nAs an example consider a car skidding to a stop, where k is the coefficient of friction and W is the weight of the car.  Then the force along the trajectory is Fx = \u2212kW.  The velocity v of the car can be determined from the length s of the skid using the work\u2013energy principle,\n\nNotice that this formula uses the fact that the mass of the vehicle is m = W/g.\n\n\n=== Coasting down an inclined surface (gravity racing) ===\nConsider the case of a vehicle that starts at rest and coasts down an inclined surface (such as mountain road), the work\u2013energy principle helps compute the minimum distance that the vehicle travels to reach a velocity V, of say 60 mph (88 fps).  Rolling resistance and air drag will slow the vehicle down so the actual distance will be greater than if these forces are neglected.\nLet the trajectory of the vehicle following the road be X(t) which is a curve in three-dimensional space.  The force acting on the vehicle that pushes it down the road is the constant force of gravity F = (0, 0, W), while the force of the road on the vehicle is the constraint force R.  Newton's second law yields,\n\nThe scalar product of this equation with the velocity, V = (vx, vy, vz), yields\n\nwhere V is the magnitude of V.  The constraint forces between the vehicle and the road cancel from this equation because R \u22c5 V = 0, which means they do no work.\nIntegrate both sides to obtain\n\nThe weight force W is constant along the trajectory and the integral of the vertical velocity is the vertical distance, therefore,\n\nRecall that V(t1)=0. Notice that this result does not depend on the shape of the road followed by the vehicle.\nIn order to determine the distance along the road assume the downgrade is 6%, which is a steep road.  This means the altitude decreases 6 feet for every 100 feet traveled\u2014for angles this small the sin and tan functions are approximately equal.  Therefore, the distance s in feet down a 6% grade to reach the velocity V is at least\n\nThis formula uses the fact that the weight of the vehicle is W = mg.\n\n\n== Work of forces acting on a rigid body ==\nThe work of forces acting at various points on a single rigid body can be calculated from the work of a resultant force and torque.  To see this, let the forces F1, F2, ..., Fn act on the points X1, X2, ..., Xn in a rigid body.\nThe trajectories of Xi, i = 1, ..., n are defined by the movement of the rigid body.  This movement is given by the set of rotations [A(t)] and the trajectory d(t) of a reference point in the body.  Let the coordinates xi i = 1, ..., n define these points in the moving rigid body's reference frame M, so that the trajectories traced in the fixed frame F are given by\n\nThe velocity of the points Xi along their trajectories are\n\nwhere \u03c9 is the angular velocity vector obtained from the skew symmetric matrix\n\nknown as the angular velocity matrix.\nThe small amount of work by the forces over the small displacements \u03b4ri can be determined by approximating the displacement by \u03b4r = v\u03b4t so\n\nor\n\nThis formula can be rewritten to obtain\n\nwhere F and T are the resultant force and torque applied at the reference point d of the moving frame M in the rigid body.\n\n\n== References ==\n\n\n== Bibliography ==\nSerway, Raymond A.; Jewett, John W. (2004). Physics for Scientists and Engineers (6th ed.). Brooks/Cole. ISBN 0-534-40842-7.\nTipler, Paul (1991). Physics for Scientists and Engineers: Mechanics (3rd ed., extended version ed.). W. H. Freeman. ISBN 0-87901-432-6.\n\n\n== External links ==\nWork\u2013energy principle", "Voltage": "Voltage, also known as electric pressure, electric tension, or (electric) potential difference, is the difference in electric potential between two points. In a static electric field, it corresponds to the work needed per unit of charge to move a test charge between the two points. In the International System of Units, the derived unit for voltage is named volt.:\u200a166\u200aThe voltage between points can be caused by the build-up of electric charge (e.g., a capacitor), and from an electromotive force (e.g., electromagnetic induction in generator, inductors, and transformers). On a macroscopic scale, a potential difference can be caused by electrochemical processes (e.g., cells and batteries), the pressure-induced piezoelectric effect, and the thermoelectric effect.\nA voltmeter can be used to measure the voltage between two points in a system. Often a common reference potential such as the ground of the system is used as one of the points. A voltage can represent either a source of energy or the loss, dissipation, or storage of energy.\n\n\n== Definition ==\nIn SI units, work per unit charge is expressed as joules per coulomb, where 1 volt = 1 joule (of work) per 1 coulomb (of charge). The old SI definition for volt used power and current; starting in 1990, the quantum Hall and Josephson effect were used, and recently (2019) fundamental physical constants have been introduced for the definition of all SI units and derived units.:\u200a177f,\u200a197f\u200a Voltage difference is denoted symbolically by \n  \n    \n      \n        \u0394\n        V\n      \n    \n    {\\displaystyle \\Delta V}\n  , simplified V, especially in English-speaking countries, or by U internationally, for instance in the context of Ohm's or Kirchhoff's circuit laws.\nThe electrochemical potential is the voltage that can be directly measured with a voltmeter. The Galvani potential that exists in structures with junctions of dissimilar materials is also work per charge but cannot be measured with a voltmeter in the external circuit (see \u00a7 Galvani potential vs. electrochemical potential).\nVoltage is defined so that negatively charged objects are pulled towards higher voltages, while positively charged objects are pulled towards lower voltages. Therefore, the conventional current in a wire or resistor always flows from higher voltage to lower voltage.\nHistorically, voltage has been referred to using terms like \"tension\" and \"pressure\". Even today, the term \"tension\" is still used, for example within the phrase \"high tension\" (HT) which is commonly used in thermionic valve (vacuum tube) based electronics.\n\n\n=== Definition in electrostatics ===\n\nIn electrostatics, the voltage increase from point \n  \n    \n      \n        \n          \n            r\n          \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{A}}\n   to some point \n  \n    \n      \n        \n          \n            r\n          \n          \n            B\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{B}}\n   is given by the change in electrostatic potential \n  \n    \n      \n        V\n      \n    \n    {\\textstyle V}\n   from \n  \n    \n      \n        \n          \n            r\n          \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{A}}\n   to \n  \n    \n      \n        \n          \n            r\n          \n          \n            B\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{B}}\n  . By definition,:\u200a78\u200a this is:\n\n  \n    \n      \n        \n          \n            \n              \n                \u0394\n                \n                  V\n                  \n                    A\n                    B\n                  \n                \n              \n              \n                \n                =\n                V\n                (\n                \n                  \n                    r\n                  \n                  \n                    B\n                  \n                \n                )\n                \u2212\n                V\n                (\n                \n                  \n                    r\n                  \n                  \n                    A\n                  \n                \n                )\n              \n            \n            \n              \n              \n                \n                =\n                \u2212\n                \n                  \u222b\n                  \n                    \n                      \n                        r\n                      \n                      \n                        0\n                      \n                    \n                  \n                  \n                    \n                      \n                        r\n                      \n                      \n                        B\n                      \n                    \n                  \n                \n                \n                  E\n                \n                \u22c5\n                \n                  d\n                \n                \n                  \u2113\n                \n                \u2212\n                \n                  (\n                  \n                    \u2212\n                    \n                      \u222b\n                      \n                        \n                          \n                            r\n                          \n                          \n                            0\n                          \n                        \n                      \n                      \n                        \n                          \n                            r\n                          \n                          \n                            A\n                          \n                        \n                      \n                    \n                    \n                      E\n                    \n                    \u22c5\n                    \n                      d\n                    \n                    \n                      \u2113\n                    \n                  \n                  )\n                \n              \n            \n            \n              \n              \n                \n                =\n                \u2212\n                \n                  \u222b\n                  \n                    \n                      \n                        r\n                      \n                      \n                        A\n                      \n                    \n                  \n                  \n                    \n                      \n                        r\n                      \n                      \n                        B\n                      \n                    \n                  \n                \n                \n                  E\n                \n                \u22c5\n                \n                  d\n                \n                \n                  \u2113\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\Delta V_{AB}&=V(\\mathbf {r} _{B})-V(\\mathbf {r} _{A})\\\\&=-\\int _{\\mathbf {r} _{0}}^{\\mathbf {r} _{B}}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}-\\left(-\\int _{\\mathbf {r} _{0}}^{\\mathbf {r} _{A}}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}\\right)\\\\&=-\\int _{\\mathbf {r} _{A}}^{\\mathbf {r} _{B}}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}\\end{aligned}}}\n  In this case, the voltage increase from point A to point B is equal to the work done per unit charge, against the electric field, to move the charge from A to B without causing any acceleration.:\u200a90\u201391\u200a Mathematically, this is expressed as the line integral of the electric field along that path. In electrostatics, this line integral is independent of the path taken.:\u200a91\u200aUnder this definition, any circuit where there are time-varying magnetic fields, such as AC circuits, will not have a well-defined voltage between nodes in the circuit, since the electric force is not a conservative force in those cases. However, at lower frequencies when the electric and magnetic fields are not rapidly changing, then this can be neglected (see electrostatic approximation).\n\n\n=== Generalization to electrodynamics ===\n\nThe electric potential can be generalized to electrodynamics, so that differences in electric potential between points are well-defined even in the presence of time-varying fields. However, unlike in electrostatics, the electric field can no longer be expressed only in terms of the electric potential.:\u200a417\u200a Furthermore, the potential is no longer uniquely determined up to a constant, and can take significantly different forms depending on the choice of gauge.:\u200a419\u2013422\u200aIn this general case, some authors use the word \"voltage\" to refer to the line integral of the electric field, rather than to differences in electric potential. In this case, the voltage rise along some path \n  \n    \n      \n        \n          \n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {P}}}\n   from \n  \n    \n      \n        \n          \n            r\n          \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{A}}\n   to \n  \n    \n      \n        \n          \n            r\n          \n          \n            B\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{B}}\n   is given by:\n\n  \n    \n      \n        \u0394\n        \n          V\n          \n            A\n            B\n          \n        \n        =\n        \u2212\n        \n          \u222b\n          \n            \n              P\n            \n          \n        \n        \n          E\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle \\Delta V_{AB}=-\\int _{\\mathcal {P}}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n  However, in this case the \"voltage\" between two points depends on the path taken.\n\n\n=== Treatment in circuit theory ===\nIn circuit analysis and electrical engineering, lumped element models are used to represent and analyze circuits. These elements are idealized and self-contained circuit elements used to model physical components.When using a lumped element model, it is assumed that the effects of changing magnetic fields produced by the circuit are suitably contained to each element. Under these assumptions, the electric field in the region exterior to each component is conservative, and voltages between nodes in the circuit are well-defined, where\n\n  \n    \n      \n        \u0394\n        \n          V\n          \n            A\n            B\n          \n        \n        =\n        \u2212\n        \n          \u222b\n          \n            \n              \n                r\n              \n              \n                A\n              \n            \n          \n          \n            \n              \n                r\n              \n              \n                B\n              \n            \n          \n        \n        \n          E\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n      \n    \n    {\\displaystyle \\Delta V_{AB}=-\\int _{\\mathbf {r} _{A}}^{\\mathbf {r} _{B}}\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}}\n  as long as the path of integration does not pass through the inside of any component. The above is the same formula used in electrostatics. This integral, with the path of integration being along the test leads, is what a voltmeter will actually measure.If uncontained magnetic fields throughout the circuit are not negligible, then their effects can be modelled by adding mutual inductance elements. In the case of a physical inductor though, the ideal lumped representation is often accurate. This is because the external fields of inductors are generally negligible, especially if the inductor has a closed magnetic path. If external fields are negligible, we find that\n\n  \n    \n      \n        \u0394\n        \n          V\n          \n            A\n            B\n          \n        \n        =\n        \u2212\n        \n          \u222b\n          \n            \n              e\n              x\n              t\n              e\n              r\n              i\n              o\n              r\n            \n          \n        \n        \n          E\n        \n        \u22c5\n        \n          d\n        \n        \n          \u2113\n        \n        =\n        L\n        \n          \n            \n              d\n              I\n            \n            \n              d\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\Delta V_{AB}=-\\int _{\\mathrm {exterior} }\\mathbf {E} \\cdot \\mathrm {d} {\\boldsymbol {\\ell }}=L{\\frac {dI}{dt}}}\n  is path-independent, and there is a well-defined voltage across the inductor's terminals. This is the reason that measurements with a voltmeter across an inductor are often reasonably independent of the placement of the test leads.\n\n\n== Volt ==\n\nThe volt (symbol: V) is the derived unit for electric potential, voltage, and electromotive force. The volt is named in honour of the Italian physicist Alessandro Volta  (1745\u20131827), who invented the voltaic pile, possibly the first chemical battery.\n\n\n== Hydraulic analogy ==\n\nA simple analogy for an electric circuit is water flowing in a closed circuit of pipework, driven by a mechanical pump.  This can be called a \"water circuit\".  The potential difference between two points corresponds to the pressure difference between two points. If the pump creates a pressure difference between two points, then water flowing from one point to the other will be able to do work, such as driving a turbine. Similarly, work can be done by an electric current driven by the potential difference provided by a battery. For example, the voltage provided by a sufficiently-charged automobile battery can \"push\" a large current through the windings of an automobile's starter motor. If the pump isn't working, it produces no pressure difference, and the turbine will not rotate. Likewise, if the automobile's battery is very weak or \"dead\" (or \"flat\"), then it will not turn the starter motor.\nThe hydraulic analogy is a useful way of understanding many electrical concepts. In such a system, the work done to move water is equal to the \"pressure drop\" (compare p.d.) multiplied by the volume of water moved. Similarly, in an electrical circuit, the work done to move electrons or other charge-carriers is equal to \"electrical pressure difference\" multiplied by the quantity of electrical charges moved. In relation to \"flow\", the larger the \"pressure difference\" between two points (potential difference or water pressure difference), the greater the flow between them (electric current or water flow). (See \"electric power\".)\n\n\n== Applications ==\n\nSpecifying a voltage measurement requires explicit or implicit specification of the points across which the voltage is measured.  When using a voltmeter to measure voltage, one electrical lead of the voltmeter must be connected to the first point, one to the second point.\nA common use of the term \"voltage\" is in describing the voltage dropped across an electrical device (such as a resistor). The voltage drop across the device can be understood as the difference between measurements at each terminal of the device with respect to a common reference point (or ground). The voltage drop is the difference between the two readings. Two points in an electric circuit that are connected by an ideal conductor without resistance and not within a changing magnetic field have a voltage of zero. Any two points with the same potential may be connected by a conductor and no current will flow between them.\n\n\n=== Addition of voltages ===\nThe voltage between A and C is the sum of the voltage between A and B and the voltage between B and C. The various voltages in a circuit can be computed using Kirchhoff's circuit laws.\nWhen talking about alternating current (AC) there is a difference between instantaneous voltage and average voltage. Instantaneous voltages can be added for direct current (DC) and AC, but average voltages can be meaningfully added only when they apply to signals that all have the same frequency and phase.\n\n\n== Measuring instruments ==\n\nInstruments for measuring voltages include the voltmeter, the potentiometer, and the oscilloscope. Analog voltmeters, such as moving-coil instruments, work by measuring the current through a fixed resistor, which, according to Ohm's Law, is proportional to the voltage across the resistor. The potentiometer works by balancing the unknown voltage against a known voltage in a bridge circuit. The cathode-ray oscilloscope works by amplifying the voltage and using it to deflect an electron beam from a straight path, so that the deflection of the beam is proportional to the voltage.\n\n\n== Typical voltages ==\n\nA common voltage for flashlight batteries is 1.5 volts (DC).\nA common voltage for automobile batteries is 12 volts (DC).\nCommon voltages supplied by power companies to consumers are 110 to 120 volts (AC) and 220 to 240 volts (AC). The voltage in electric power transmission lines used to distribute electricity from power stations can be several hundred times greater than consumer voltages, typically 110 to 1200 kV (AC).\nThe voltage used in overhead lines to power railway locomotives is between 12 kV and 50 kV (AC) or between 0.75 kV and 3 kV (DC).\n\n\n== Galvani potential vs. electrochemical potential ==\n\nInside a conductive material, the energy of an electron is affected not only by the average electric potential but also by the specific thermal and atomic environment that it is in.\nWhen a voltmeter is connected between two different types of metal, it measures not the electrostatic potential difference, but instead something else that is affected by thermodynamics.\nThe quantity measured by a voltmeter is the negative of the difference of the electrochemical potential of electrons (Fermi level) divided by the electron charge and commonly referred to as the voltage difference, while the pure unadjusted electrostatic potential (not measurable with a voltmeter) is sometimes called Galvani potential.\nThe terms \"voltage\" and \"electric potential\" are ambiguous in that, in practice, they can refer to either of these in different contexts.\n\n\n== History ==\nThe term electromotive force was first used by Volta in a letter to Giovanni Aldini in 1798, and first appeared in a published paper in 1801 in Annales de chimie et de physique.:\u200a408\u200a  Volta meant by this a force that was not an electrostatic force, specifically, an electrochemical force.:\u200a405\u200a  The term was taken up by Michael Faraday in connection with electromagnetic induction in the 1820s.  However, a clear definition of voltage and method of measuring it had not been developed at this time.:\u200a554\u200a Volta distinguished electromotive force (emf) from tension (potential difference): the observed potential difference at the terminals of an electrochemical cell when it was open circuit must exactly balance the emf of the cell so that no current flowed.:\u200a405\u200a\n\n\n== See also ==\n\n\n== References ==\n\n\n== Footnotes ==\n\n\n== External links ==\n\nElectrical voltage V, current I, resistivity R, impedance Z, wattage P", "Absorption_spectroscopy": "Absorption spectroscopy refers to spectroscopic techniques that measure the absorption of radiation, as a function of frequency or wavelength, due to its interaction with a sample. The sample absorbs energy, i.e., photons, from the radiating field. The intensity of the absorption varies as a function of frequency, and this variation is the absorption spectrum. Absorption spectroscopy is performed across the electromagnetic spectrum.\nAbsorption spectroscopy is employed as an analytical chemistry tool to determine the presence of a particular substance in a sample and, in many cases, to quantify the amount of the substance present. Infrared and ultraviolet\u2013visible spectroscopy are particularly common in analytical applications. Absorption spectroscopy is also employed in studies of molecular and atomic physics, astronomical spectroscopy and remote sensing.\nThere is a wide range of experimental approaches for measuring absorption spectra. The most common arrangement is to direct a generated beam of radiation at a sample and detect the intensity of the radiation that passes through it. The transmitted energy can be used to calculate the absorption. The source, sample arrangement and detection technique vary significantly depending on the frequency range and the purpose of the experiment.\nFollowing are the major types of absorption spectroscopy:\n\n\n== Absorption spectrum ==\n\nA material's absorption spectrum is the fraction of incident radiation absorbed by the material over a range of frequencies of Electromagnetic Radiation. The absorption spectrum is primarily determined by the atomic and molecular composition of the material. Radiation is more likely to be absorbed at frequencies that match the energy difference between two quantum mechanical states of the molecules. The absorption that occurs due to a transition between two states is referred to as an absorption line and a spectrum is typically composed of many lines.\nThe frequencies where absorption lines occur, as well as their relative intensities, primarily depend on the electronic and molecular structure of the sample. The frequencies will also depend on the interactions between molecules in the sample, the crystal structure in solids, and on several environmental factors (e.g., temperature, pressure, electromagnetic field). The lines will also have a width and shape that are primarily determined by the spectral density or the density of states of the system.\n\n\n=== Theory ===\nAbsorption lines are typically classified by the nature of the quantum mechanical change induced in the molecule or atom. Rotational lines, for instance, occur when the rotational state of a molecule is changed. Rotational lines are typically found in the microwave spectral region. Vibrational lines correspond to changes in the vibrational state of the molecule and are typically found in the infrared region. Electronic lines correspond to a change in the electronic state of an atom or molecule and are typically found in the visible and ultraviolet region. X-ray absorptions are associated with the excitation of inner shell electrons in atoms. These changes can also be combined (e.g. rotation\u2013vibration transitions), leading to new absorption lines at the combined energy of the two changes.\nThe energy associated with the quantum mechanical change primarily determines the frequency of the absorption line but the frequency can be shifted by several types of interactions. Electric and magnetic fields can cause a shift. Interactions with neighboring molecules can cause shifts. For instance, absorption lines of the gas phase molecule can shift significantly when that molecule is in a liquid or solid phase and interacting more strongly with neighboring molecules.\nThe width and shape of absorption lines are determined by the instrument used for the observation, the material absorbing the radiation and the physical environment of that material. It is common for lines to have the shape of a Gaussian or Lorentzian distribution. It is also common for a line to be described solely by its intensity and width instead of the entire shape being characterized.\nThe integrated intensity\u2014obtained by integrating the area under the absorption line\u2014is proportional to the amount of the absorbing substance present. The intensity is also related to the temperature of the substance and the quantum mechanical interaction between the radiation and the absorber. This interaction is quantified by the transition moment and depends on the particular lower state the transition starts from, and the upper state it is connected to.\nThe width of absorption lines may be determined by the spectrometer used to record it. A spectrometer has an inherent limit on how narrow a line it can resolve and so the observed width may be at this limit. If the width is larger than the resolution limit, then it is primarily determined by the environment of the absorber. A liquid or solid absorber, in which neighboring molecules strongly interact with one another, tends to have broader absorption lines than a gas. Increasing the temperature or pressure of the absorbing material will also tend to increase the line width. It is also common for several neighboring transitions to be close enough to one another that their lines overlap and the resulting overall line is therefore broader yet.\n\n\n=== Relation to transmission spectrum ===\nAbsorption and transmission spectra represent equivalent information and one can be calculated from the other through a mathematical transformation. A transmission spectrum will have its maximum intensities at wavelengths where the absorption is weakest because more light is transmitted through the sample. An absorption spectrum will have its maximum intensities at wavelengths where the absorption is strongest.\n\n\n=== Relation to emission spectrum ===\n\nEmission is a process by which a substance releases energy in the form of electromagnetic radiation. Emission can occur at any frequency at which absorption can occur, and this allows the absorption lines to be determined from an emission spectrum. The emission spectrum will typically have a quite different intensity pattern from the absorption spectrum, though, so the two are not equivalent. The absorption spectrum can be calculated from the emission spectrum using Einstein coefficients.\n\n\n=== Relation to scattering and reflection spectra ===\nThe scattering and reflection spectra of a material are influenced by both its index of refraction and its absorption spectrum. In an optical context, the absorption spectrum is typically quantified by the extinction coefficient, and the extinction and index coefficients are quantitatively related through the Kramers\u2013Kronig relation. Therefore, the absorption spectrum can be derived from a scattering or reflection spectrum. This typically requires simplifying assumptions or models, and so the derived absorption spectrum is an approximation.\n\n\n== Applications ==\n\nAbsorption spectroscopy is useful in chemical analysis because of its specificity and its quantitative nature. The specificity of absorption spectra allows compounds to be distinguished from one another in a mixture, making absorption spectroscopy useful in wide variety of applications. For instance, Infrared gas analyzers can be used to identify the presence of pollutants in the air, distinguishing the pollutant from nitrogen, oxygen, water and other expected constituents.The specificity also allows unknown samples to be identified by comparing a measured spectrum with a library of reference spectra. In many cases, it is possible to determine qualitative information about a sample even if it is not in a library. Infrared spectra, for instance, have characteristics absorption bands that indicate if carbon-hydrogen or carbon-oxygen bonds are present.\nAn absorption spectrum can be quantitatively related to the amount of material present using the Beer\u2013Lambert law. Determining the absolute concentration of a compound requires knowledge of the compound's absorption coefficient. The absorption coefficient for some compounds is available from reference sources, and it can also be determined by measuring the spectrum of a calibration standard with a known concentration of the target.\n\n\n=== Remote sensing ===\nOne of the unique advantages of spectroscopy as an analytical technique is that measurements can be made without bringing the instrument and sample into contact. Radiation that travels between a sample and an instrument will contain the spectral information, so the measurement can be made remotely. Remote spectral sensing is valuable in many situations. For example, measurements can be made in toxic or hazardous environments without placing an operator or instrument at risk. Also, sample material does not have to be brought into contact with the instrument\u2014preventing possible cross contamination.\nRemote spectral measurements present several challenges compared to laboratory measurements. The space in between the sample of interest and the instrument may also have spectral absorptions. These absorptions can mask or confound the absorption spectrum of the sample. These background interferences may also vary over time. The source of radiation in remote measurements is often an environmental source, such as sunlight or the thermal radiation from a warm object, and this makes it necessary to distinguish spectral absorption from changes in the source spectrum.\nTo simplify these challenges, Differential optical absorption spectroscopy has gained some popularity, as it focusses on differential absorption features and omits broad-band absorption such as aerosol extinction and extinction due to rayleigh scattering. This method is applied to ground-based, air-borne and satellite based measurements. Some ground-based methods provide the possibility to retrieve tropospheric and stratospheric trace gas profiles.\n\n\n=== Astronomy ===\n\nAstronomical spectroscopy is a particularly significant type of remote spectral sensing. In this case, the objects and samples of interest are so distant from earth that electromagnetic radiation is the only means available to measure them. Astronomical spectra contain both absorption and emission spectral information. Absorption spectroscopy has been particularly important for understanding interstellar clouds and determining that some of them contain molecules. Absorption spectroscopy is also employed in the study of extrasolar planets. Detection of extrasolar planets by the transit method also measures their absorption spectrum and allows for the determination of the planet's atmospheric composition, temperature, pressure, and scale height, and hence allows also for the determination of the planet's mass.\n\n\n=== Atomic and molecular physics ===\nTheoretical models, principally quantum mechanical models, allow for the absorption spectra of atoms and molecules to be related to other physical properties such as electronic structure, atomic or molecular mass, and molecular geometry. Therefore, measurements of the absorption spectrum are used to determine these other properties. Microwave spectroscopy, for example, allows for the determination of bond lengths and angles with high precision.\nIn addition, spectral measurements can be used to determine the accuracy of theoretical predictions. For example, the Lamb shift measured in the hydrogen atomic absorption spectrum was not expected to exist at the time it was measured. Its discovery spurred and guided the development of quantum electrodynamics, and measurements of the Lamb shift are now used to determine the fine-structure constant.\n\n\n== Experimental methods ==\n\n\n=== Basic approach ===\nThe most straightforward approach to absorption spectroscopy is to generate radiation with a source, measure a reference spectrum of that radiation with a detector and then re-measure the sample spectrum after placing the material of interest in between the source and detector. The two measured spectra can then be combined to determine the material's absorption spectrum. The sample spectrum alone is not sufficient to determine the absorption spectrum because it will be affected by the experimental conditions\u2014the spectrum of the source, the absorption spectra of other materials in between the source and detector and the wavelength dependent characteristics of the detector. The reference spectrum will be affected in the same way, though, by these experimental conditions and therefore the combination yields the absorption spectrum of the material alone.\nA wide variety of radiation sources are employed in order to cover the electromagnetic spectrum. For spectroscopy, it is generally desirable for a source to cover a broad swath of wavelengths in order to measure a broad region of the absorption spectrum. Some sources inherently emit a broad spectrum. Examples of these include globars or other black body sources in the infrared, mercury lamps in the visible and ultraviolet and x-ray tubes. One recently developed, novel source of broad spectrum radiation is synchrotron radiation which covers all of these spectral regions. Other radiation sources generate a narrow spectrum but the emission wavelength can be tuned to cover a spectral range. Examples of these include klystrons in the microwave region and lasers across the infrared, visible and ultraviolet region (though not all lasers have tunable wavelengths).\nThe detector employed to measure the radiation power will also depend on the wavelength range of interest. Most detectors are sensitive to a fairly broad spectral range and the sensor selected will often depend more on the sensitivity and noise requirements of a given measurement. Examples of detectors common in spectroscopy include heterodyne receivers in the microwave, bolometers in the millimeter-wave and infrared, mercury cadmium telluride and other cooled semiconductor detectors in the infrared, and photodiodes and photomultiplier tubes in the visible and ultraviolet.\nIf both the source and the detector cover a broad spectral region, then it is also necessary to introduce a means of resolving the wavelength of the radiation in order to determine the spectrum. Often a spectrograph is used to spatially separate the wavelengths of radiation so that the power at each wavelength can be measured independently. It is also common to employ interferometry to determine the spectrum\u2014Fourier transform infrared spectroscopy is a widely used implementation of this technique.\nTwo other issues that must be considered in setting up an absorption spectroscopy experiment include the optics used to direct the radiation and the means of holding or containing the sample material (called a cuvette or cell). For most UV, visible, and NIR measurements the use of precision quartz cuvettes are necessary. In both cases, it is important to select materials that have relatively little absorption of their own in the wavelength range of interest. The absorption of other materials could interfere with or mask the absorption from the sample. For instance, in several wavelength ranges it is necessary to measure the sample under vacuum or in a rare gas environment because gases in the atmosphere have interfering absorption features.\n\n\n=== Specific approaches ===\nAstronomical spectroscopy\nCavity ring down spectroscopy (CRDS)\nLaser absorption spectrometry (LAS)\nM\u00f6ssbauer spectroscopy\nPhotoacoustic spectroscopy\nPhotoemission spectroscopy\nPhotothermal optical microscopy\nPhotothermal spectroscopy\nReflectance spectroscopy\nTunable diode laser absorption spectroscopy (TDLAS)\nX-ray absorption fine structure (XAFS)\nX-ray absorption near edge structure (XANES)\nTotal absorption spectroscopy (TAS)\nReflection-absorption infrared spectroscopy (RAIRS)\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\nSolar absorption spectrum\nWEBB Space Telescope, Part 3 of a series: Spectroscopy 101 \u2013 Types of Spectra and Spectroscopy\nVisible Absorption Spectrum Simulation Archived 2016-11-01 at the Wayback Machine\nPlot Absorption Intensity for many molecules in HITRAN database", "Reflection_(physics)": "Reflection is the change in direction of a wavefront at an interface between two different media so that the wavefront returns into the medium from which it originated. Common examples include the reflection of light, sound and water waves. The law of reflection says that for specular reflection (for example at a mirror) the angle at which the wave is incident on the surface equals the angle at which it is reflected.\nIn acoustics, reflection causes echoes and is used in sonar. In geology, it is important in the study of seismic waves. Reflection is observed with surface waves in bodies of water. Reflection is observed with many types of electromagnetic wave, besides visible light. Reflection of VHF and higher frequencies is important for radio transmission and for radar. Even hard X-rays and gamma rays can be reflected at shallow angles with special \"grazing\" mirrors.\n\n\n== Reflection of light ==\nReflection of light is either specular (mirror-like) or diffuse (retaining the energy, but losing the image) depending on the nature of the interface. In specular reflection the phase of the reflected waves depends on the choice of the origin of coordinates, but the relative phase between s and p (TE and TM) polarizations is fixed by the properties of the media and of the interface between them.A mirror provides the most common model for specular light reflection, and typically consists of a glass sheet with a metallic coating where the significant reflection occurs. Reflection is enhanced in metals by suppression of wave propagation beyond their skin depths.  Reflection also occurs at the surface of transparent media, such as water or glass.\n\nIn the diagram, a light ray PO strikes a vertical mirror at point O, and the reflected ray is OQ. By projecting an imaginary line through point O perpendicular to the mirror, known as the normal, we can measure the angle of incidence, \u03b8i and the angle of reflection, \u03b8r. The law of reflection states that \u03b8i = \u03b8r, or in other words, the angle of incidence equals the angle of reflection.\nIn fact, reflection of light may occur whenever light travels from a medium of a given refractive index into a medium with a different refractive index. In the most general case, a certain fraction of the light is reflected from the interface, and the remainder is refracted.  Solving Maxwell's equations for a light ray striking a boundary allows the derivation of the Fresnel equations, which can be used to predict how much of the light is reflected, and how much is refracted in a given situation. This is analogous to the way impedance mismatch in an electric circuit causes reflection of signals.  Total internal reflection of light from a denser medium occurs if the angle of incidence is greater than the critical angle.\nTotal internal reflection is used as a means of focusing waves that cannot effectively be reflected by common means. X-ray telescopes are constructed by creating a converging \"tunnel\" for the waves. As the waves interact at low angle with the surface of this tunnel they are reflected toward the focus point (or toward another interaction with the tunnel surface, eventually being directed to the detector at the focus). A conventional reflector would be useless as the X-rays would simply pass through the intended reflector.\nWhen light reflects off of a material with higher refractive index than the medium in which is traveling, it undergoes a 180\u00b0 phase shift.  In contrast, when light reflects off of a material with lower refractive index the reflected light is in phase with the incident light.  This is an important principle in the field of thin-film optics.\nSpecular reflection forms images. Reflection from a flat surface forms a mirror image, which appears to be reversed from left to right because we compare the image we see to what we would see if we were rotated into the position of the image. Specular reflection at a curved surface forms an image which may be magnified or demagnified; curved mirrors have optical power. Such mirrors may have surfaces that are spherical or parabolic.\n\n\n=== Laws of reflection ===\n\nIf the reflecting surface is very smooth, the reflection of light that occurs is called specular or regular reflection. The laws of reflection are as follows:\n\nThe incident ray, the reflected ray and the normal to the reflection surface at the point of the incidence lie in the same plane.\nThe angle which the incident ray makes with the normal is equal to the angle which the reflected ray makes to the same normal.\nThe reflected ray and the incident ray are on the opposite sides of the normal.These three laws can all be derived from the Fresnel equations.\n\n\n==== Mechanism ====\n\nIn classical electrodynamics, light is considered as an electromagnetic wave, which is described by Maxwell's equations. Light waves incident on a material induce small oscillations of polarisation in the individual atoms (or oscillation of electrons, in metals), causing each particle to radiate a small secondary wave in all directions, like a dipole antenna. All these waves add up to give specular reflection and refraction, according to the Huygens\u2013Fresnel principle.\nIn the case of dielectrics such as glass, the electric field of the light acts on the electrons in the material, and the moving electrons generate fields and become new radiators. The refracted light in the glass is the combination of the forward radiation of the electrons and the incident light. The reflected light is the combination of the backward radiation of all of the electrons.\nIn metals, electrons with no binding energy are called free electrons. When these electrons oscillate with the incident light, the phase difference between their radiation field and the incident field is \u03c0 (180\u00b0), so the forward radiation cancels the incident light, and backward radiation is just the reflected light.\nLight\u2013matter interaction in terms of photons is a topic of quantum electrodynamics, and is described in detail by Richard Feynman in his popular book QED: The Strange Theory of Light and Matter.\n\n\n=== Diffuse reflection ===\n\nWhen light strikes the surface of a (non-metallic) material it bounces off in all directions due to multiple reflections by the microscopic irregularities inside the material (e.g. the grain boundaries of a polycrystalline material, or the cell or fiber boundaries of an organic material) and by its surface, if it is rough. Thus, an 'image' is not formed. This is called diffuse reflection. The exact form of the reflection depends on the structure of the material. One common model for diffuse reflection is Lambertian reflectance, in which the light is reflected with equal luminance (in photometry) or radiance (in radiometry) in all directions, as defined by Lambert's cosine law.\nThe light sent to our eyes by most of the objects we see is due to diffuse reflection from their surface, so that this is our primary mechanism of physical observation.\n\n\n=== Retroreflection ===\n\nSome surfaces exhibit retroreflection. The structure of these surfaces is such that light is returned in the direction from which it came.\nWhen flying over clouds illuminated by sunlight the region seen around the aircraft's shadow will appear brighter, and a similar effect may be seen from dew on grass. This partial retro-reflection is created by the refractive properties of the curved droplet's surface and reflective properties at the backside of the droplet.\nSome animals' retinas act as retroreflectors (see tapetum lucidum for more detail), as this effectively improves the animals' night vision. Since the lenses of their eyes modify reciprocally the paths of the incoming and outgoing light the effect is that the eyes act as a strong retroreflector, sometimes seen at night when walking in wildlands with a flashlight.\nA simple retroreflector can be made by placing three ordinary mirrors mutually perpendicular to one another (a corner reflector). The image produced is the inverse of one produced by a single mirror. \nA surface can be made partially retroreflective by depositing a layer of tiny refractive spheres on it or by creating small pyramid like structures. In both cases internal reflection causes the light to be reflected back to where it originated. This is used to make traffic signs and automobile license plates reflect light mostly back in the direction from which it came. In this application perfect retroreflection is not desired, since the light would then be directed back into the headlights of an oncoming car rather than to the driver's eyes.\n\n\n=== Multiple reflections ===\n\nWhen light reflects off a mirror, one image appears. Two mirrors placed exactly face to face give the appearance of an infinite number of images along a straight line. The multiple images seen between two mirrors that sit at an angle to each other lie over a circle. The center of that circle is located at the imaginary intersection of the mirrors. A square of four mirrors placed face to face give the appearance of an infinite number of images arranged in a plane. The multiple images seen between four mirrors assembling a pyramid, in which each pair of mirrors sits an angle to each other, lie over a sphere. If the base of the pyramid is rectangle shaped, the images spread over a section of a torus.Note that these are theoretical ideals, requiring perfect alignment of perfectly smooth, perfectly flat perfect reflectors that absorb none of the light. In practice, these situations can only be approached but not achieved because the effects of any surface imperfections in the reflectors propagate and magnify, absorption gradually extinguishes the image, and any observing equipment (biological or technological) will interfere.\n\n\n=== Complex conjugate reflection ===\nIn this process (which is also known as phase conjugation), light bounces exactly back in the direction from which it came due to a nonlinear optical process. Not only the direction of the light is reversed, but the actual wavefronts are reversed as well. A conjugate reflector can be used to remove aberrations from a beam by reflecting it and then passing the reflection through the aberrating optics a second time. If one were to look into a complex conjugating mirror, it would be black because only the photons which left the pupil would reach the pupil.\n\n\n== Other types of reflection ==\n\n\n=== Neutron reflection ===\nMaterials that reflect neutrons, for example beryllium, are used in nuclear reactors and nuclear weapons. In the physical and biological sciences, the reflection of neutrons off of atoms within a material is commonly used to determine the material's internal structure.\n\n\n=== Sound reflection ===\n\nWhen a longitudinal sound wave strikes a flat surface, sound is reflected in a coherent manner provided that the dimension of the reflective surface is large compared to the wavelength of the sound. Note that audible sound has a very wide frequency range (from 20 to about 17000 Hz), and thus a very wide range of wavelengths (from about 20 mm to 17 m). As a result, the overall nature of the reflection varies according to the texture and structure of the surface. For example, porous materials will absorb some energy, and rough materials (where rough is relative to the wavelength) tend to reflect in many directions\u2014to scatter the energy, rather than to reflect it coherently. This leads into the field of architectural acoustics, because the nature of these reflections is critical to the auditory feel of a space. \nIn the theory of exterior noise mitigation, reflective surface size mildly detracts from the concept of a noise barrier by reflecting some of the sound into the opposite direction. Sound reflection can affect the acoustic space.\n\n\n=== Seismic reflection ===\n\nSeismic waves produced by earthquakes or other sources (such as explosions) may be reflected by layers within the Earth.  Study of the deep reflections of waves generated by earthquakes has allowed seismologists to determine the layered structure of the Earth.  Shallower reflections are used in reflection seismology to study the Earth's crust generally, and in particular to prospect for petroleum and natural gas deposits.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nAcoustic reflection\nAnimations demonstrating optical reflection by QED\nSimulation on Laws of Reflection of Sound By Amrita University", "Power_(physics)": "In physics, power is the amount of energy transferred or converted per unit time. In the International System of Units, the unit of power is the watt, equal to one joule per second. In older works, power is sometimes called activity. Power is a scalar quantity.\nPower is related to other quantities; for example, the power involved in moving a ground vehicle is the product of the aerodynamic drag plus traction force on the wheels, and the velocity of the vehicle. The output power of a motor is the product of the torque that the motor generates and the angular velocity of its output shaft.  Likewise, the power dissipated in an electrical element of a circuit is the product of the current flowing through the element and of the voltage across the element.\n\n\n== Definition ==\nPower is the rate with respect to time at which work is done; it is the time derivative of work:\n\nwhere P is power, W is work, and t is time.\nIf a constant force F is applied throughout a distance x, the work done is defined as \n  \n    \n      \n        W\n        =\n        \n          F\n        \n        \u22c5\n        \n          x\n        \n      \n    \n    {\\displaystyle W=\\mathbf {F} \\cdot \\mathbf {x} }\n  . In this case, power can be written as:\n\nIf instead the force is variable over a three-dimensional curve C, then the work is expressed in terms of the line integral:\n\nFrom the fundamental theorem of calculus, we know that  Hence the formula is valid for any general situation.\n\n\n== Units ==\nThe dimension of power is energy divided by time. In the International System of Units (SI), the unit of power is the watt (W), which is equal to one joule per second. Other common and traditional measures are horsepower (hp), comparing to the power of a horse; one mechanical horsepower equals about 745.7 watts. Other units of power include ergs per second (erg/s), foot-pounds per minute, dBm, a logarithmic measure relative to a reference of 1 milliwatt, calories per hour, BTU per hour (BTU/h), and tons of refrigeration.\n\n\n== Average power ==\nAs a simple example, burning one kilogram of coal releases much more energy than detonating a kilogram of TNT, but because the TNT reaction releases energy much more quickly, it delivers far more power than the coal.\nIf \u0394W  is the amount of work performed during a period of time of duration \u0394t, the average power Pavg over that period is given by the formula\n\nIt is the average amount of work done or energy converted per unit of time. The average power is often simply called \"power\" when the context makes it clear.\nThe instantaneous power is then the limiting value of the average power as the time interval \u0394t approaches zero.\n\nIn the case of constant power P, the amount of work performed during a period of duration t is given by\n\nIn the context of energy conversion, it is more customary to use the symbol E rather than W.\n\n\n== Mechanical power ==\n\nPower in mechanical systems is the combination of forces and movement. In particular, power is the product of a force on an object and the object's velocity, or the product of a torque on a shaft and the shaft's angular velocity.\nMechanical power is also described as the time derivative of work.  In mechanics, the work done by a force F on an object that travels along a curve C is given by the line integral:\n\nwhere x defines the path C and v is the velocity along this path.\nIf the force F is derivable from a potential (conservative), then applying the gradient theorem (and remembering that force is the negative of the gradient of the potential energy) yields:\n\nwhere A and B are the beginning and end of the path along which the work was done.\nThe power at any point along the curve C is the time derivative:\n\nIn one dimension, this can be simplified to:\n\nIn rotational systems, power is the product of the torque \u03c4 and angular velocity \u03c9,\n\nwhere \u03c9 measured in radians per second.  The \n  \n    \n      \n        \u22c5\n      \n    \n    {\\displaystyle \\cdot }\n   represents scalar product.\nIn fluid power systems such as hydraulic actuators, power is given by  where p is pressure in pascals or N/m2, and Q is volumetric flow rate in m3/s in SI units.\n\n\n=== Mechanical advantage ===\nIf a mechanical system has no losses, then the input power must equal the output power. This provides a simple formula for the mechanical advantage of the system.\nLet the input power to a device be a force FA acting on a point that moves with velocity vA and the output power be a force FB acts on a point that moves with velocity vB.  If there are no losses in the system, then\n\nand the mechanical advantage of the system (output force per input force) is given by\n\nThe similar relationship is obtained for rotating systems, where TA and \u03c9A are the torque and angular velocity of the input and TB and \u03c9B are the torque and angular velocity of the output.  If there are no losses in the system, then\n\nwhich yields the mechanical advantage\n\nThese relations are important because they define the maximum performance of a device in terms of velocity ratios determined by its physical dimensions.  See for example gear ratios.\n\n\n== Electrical power ==\n\nThe instantaneous electrical power P delivered to a component is given by\n\nwhere \n\n  \n    \n      \n        P\n        (\n        t\n        )\n      \n    \n    {\\displaystyle P(t)}\n   is the instantaneous power, measured in watts (joules per second),\n\n  \n    \n      \n        V\n        (\n        t\n        )\n      \n    \n    {\\displaystyle V(t)}\n   is the potential difference (or voltage drop) across the component, measured in volts, and\n\n  \n    \n      \n        I\n        (\n        t\n        )\n      \n    \n    {\\displaystyle I(t)}\n   is the current through it, measured in amperes.If the component is a resistor with time-invariant voltage to current ratio, then:\n\nwhere\n\nis the electrical resistance, measured in ohms.\n\n\n== Peak power and duty cycle ==\n\nIn the case of a periodic signal \n  \n    \n      \n        s\n        (\n        t\n        )\n      \n    \n    {\\displaystyle s(t)}\n   of period \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  , like a train of identical pulses, the instantaneous power \n  \n    \n      \n        p\n        (\n        t\n        )\n        =\n        \n          |\n        \n        s\n        (\n        t\n        )\n        \n          \n            |\n          \n          \n            2\n          \n        \n      \n    \n    {\\textstyle p(t)=|s(t)|^{2}}\n   is also a periodic function of period \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  .  The peak power is simply defined by:\n\nThe peak power is not always readily measurable, however, and the measurement of the average power \n  \n    \n      \n        \n          P\n          \n            \n              a\n              v\n              g\n            \n          \n        \n      \n    \n    {\\displaystyle P_{\\mathrm {avg} }}\n   is more commonly performed by an instrument.  If one defines the energy per pulse as\n\nthen the average power is\n\nOne may define the pulse length \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   such that \n  \n    \n      \n        \n          P\n          \n            0\n          \n        \n        \u03c4\n        =\n        \n          \u03b5\n          \n            \n              p\n              u\n              l\n              s\n              e\n            \n          \n        \n      \n    \n    {\\displaystyle P_{0}\\tau =\\varepsilon _{\\mathrm {pulse} }}\n   so that the ratios\n\nare equal. These ratios are called the duty cycle of the pulse train.\n\n\n== Radiant power ==\nPower is related to intensity at a radius \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  ; the power emitted by a source can be written as:\n\n\n== See also ==\nSimple machines\nOrders of magnitude (power)\nPulsed power\nIntensity \u2013 in the radiative sense, power per area\nPower gain \u2013 for linear, two-port networks\nPower density\nSignal strength\nSound power\n\n\n== References ==", "Gravity": "In physics, gravity (from Latin  gravitas 'weight') is a fundamental interaction which causes mutual attraction between all things with mass or energy. Gravity is, by far, the weakest of the four fundamental interactions, approximately 1038 times weaker than the strong interaction, 1036 times weaker than the electromagnetic force and 1029 times weaker than the weak interaction. As a result, it has no significant influence at the level of subatomic particles. However, gravity is the most significant interaction between objects at the macroscopic scale, and it determines the motion of planets, stars, galaxies, and even light.\nOn Earth, gravity gives weight to physical objects, and the Moon's gravity is responsible for sublunar tides in the oceans (the corresponding antipodal tide is caused by the inertia of the Earth and Moon orbiting one another). Gravity also has many important biological functions, helping to guide the growth of plants through the process of gravitropism and influencing the circulation of fluids in multicellular organisms. Investigation into the effects of weightlessness has shown that gravity may play a role in immune system function and cell differentiation within the human body.\nThe gravitational attraction between the original gaseous matter in the universe allowed it to coalesce and form stars which eventually condensed into galaxies, so gravity is responsible for many of the large-scale structures in the universe. Gravity has an infinite range, although its effects become weaker as objects get farther away.\nGravity is most accurately described by the general theory of relativity (proposed by Albert Einstein in 1915), which describes gravity not as a force, but as the curvature of spacetime, caused by the uneven distribution of mass, and causing masses to move along geodesic lines. The most extreme example of this curvature of spacetime is a black hole, from which nothing\u2014not even light\u2014can escape once past the black hole's event horizon. However, for most applications, gravity is well approximated by Newton's law of universal gravitation, which describes gravity as a force causing any two bodies to be attracted toward each other, with magnitude proportional to the product of their masses and inversely proportional to the square of the distance between them:\nwhere F is the force, m1 and m2 are the masses of the objects interacting, r is the distance between the centers of the masses and G is the gravitational constant.\nCurrent models of particle physics imply that the earliest instance of gravity in the universe, possibly in the form of quantum gravity, supergravity or a gravitational singularity, along with ordinary space and time, developed during the Planck epoch (up to 10\u221243 seconds after the birth of the universe), possibly from a primeval state, such as a false vacuum, quantum vacuum or virtual particle, in a currently unknown manner. Scientists are currently working to develop a theory of gravity consistent with quantum mechanics, a quantum gravity theory, which would allow gravity to be united in a common mathematical framework (a theory of everything) with the other three fundamental interactions of physics.\n\n\n== Definitions ==\nGravitation is the mutual attraction between all masses in the universe, also known as gravitational attraction. Gravity is the gravitational attraction at the surface of a planet or other celestial body.\n\n\n== History ==\n\n\n=== Ancient world ===\nThe nature and mechanism of gravity was explored by a wide range of ancient scholars. In Greece, Aristotle believed that objects fell towards the Earth because the Earth was the center of the Universe and attracted all of the mass in the Universe towards it. He also thought that the speed of a falling object should increase with its weight, a conclusion which was later shown to be false. While Aristotle's view was widely accepted throughout Ancient Greece, there were other thinkers such as Plutarch who correctly predicted that the attraction of gravity was not unique to the Earth.Although he didn't understand gravity as a force, the ancient Greek philosopher Archimedes discovered the center of gravity of a triangle. He also postulated that if two equal weights did not have the same center of gravity, the center of gravity of the two weights together would be in the middle of the line that joins their centers of gravity. Two centuries later, the Roman engineer and architect Vitruvius contended in his De architectura that gravity is not dependent on a substance's weight but rather on its \"nature\".\nIn the 6th century CE, the Byzantine Alexandrian scholar John Philoponus proposed the theory of impetus, which modifies Aristotle's theory that \"continuation of motion depends on continued action of a force\" by incorporating a causative force which diminishes over time.\nIn India in the seventh century CE, Brahmagupta proposed the idea that gravity is an attractive force which draws objects to the Earth and used the term gurutv\u0101kar\u1e63a\u1e47 to describe it.In the ancient Middle East, gravity was a topic of fierce debate. The Persian intellectual Al-Biruni believed that the force of gravity was not unique to the Earth, and he correctly assumed that other heavenly bodies should exert a gravitational attraction as well. In contrast, Al-Khazini held the same position as Aristotle that all matter in the Universe is attracted to the center of the Earth.\n\n\n=== Scientific revolution ===\n\nIn the mid-16th century, various European scientists experimentally disproved the Aristotelian notion that heavier objects fall at a faster rate. In particular, the Spanish Dominican priest Domingo de Soto wrote in 1551 that bodies in free fall uniformly accelerate. De Soto may have been influenced by earlier experiments conducted by other Dominican priests in Italy, including those by Benedetto Varchi, Francesco Beato, Luca Ghini, and Giovan Bellaso which contradicted Aristotle's teachings on the fall of bodies. The mid-16th century Italian physicist Giambattista Benedetti published papers claiming that, due to specific gravity, objects made of the same material but with different masses would fall at the same speed. With the 1586 Delft tower experiment, the Flemish physicist Simon Stevin observed that two cannonballs of differing sizes and weights fell at the same rate when dropped from a tower. Finally, in the late 16th century, Galileo Galilei's careful measurements of balls rolling down inclines allowed him to firmly establish that gravitational acceleration is the same for all objects. Galileo postulated that air resistance is the reason that objects with a low density and high surface area fall more slowly in an atmosphere.\nIn 1604, Galileo correctly hypothesized that the distance of a falling object is proportional to the square of the time elapsed. This was later confirmed by Italian scientists Jesuits Grimaldi and Riccioli between 1640 and 1650. They also calculated the magnitude of the Earth's gravity by measuring the oscillations of a pendulum.\n\n\n=== Newton's theory of gravitation ===\n\nIn 1684, Newton sent a manuscript to Edmond Halley titled De motu corporum in gyrum ('On the motion of bodies in an orbit'), which provided a physical justification for Kepler's laws of planetary motion. Halley was impressed by the manuscript and urged Newton to expand on it, and a few years later Newton published a groundbreaking book called Philosophi\u00e6 Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy). In this book, Newton described gravitation as a universal force, and claimed  that \"the forces which keep the planets in their orbs must [be] reciprocally as the squares of their distances from the centers about which they revolve.\" This statement was later condensed into the following inverse-square law:\nwhere F is the force, m1 and m2 are the masses of the objects interacting, r is the distance between the centers of the masses and G is the gravitational constant 6.674\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122.Newton's Principia was well received by the scientific community, and his law of gravitation quickly spread across the European world. More than a century later, in 1821, his theory of gravitation rose to even greater prominence when it was used to predict the existence of Neptune. In that year, the French astronomer Alexis Bouvard used this theory to create a table modeling the orbit of Uranus, which was shown to differ significantly from the planet's actual trajectory. In order to explain this discrepancy, many astronomers speculated that there might be a large object beyond the orbit of Uranus which was disrupting its orbit. In 1846, the astronomers John Couch Adams and Urbain Le Verrier independently used Newton's law to predict Neptune's location in the night sky, and the planet was discovered there within a day.\n\n\n=== General relativity ===\n\nEventually, astronomers noticed an eccentricity in the orbit of the planet Mercury which could not be explained by Newton's theory: the perihelion of the orbit was increasing by about 42.98 arcseconds per century. The most obvious explanation for this discrepancy was an as-yet-undiscovered celestial body (such as a planet orbiting the Sun even closer than Mercury), but all efforts to find such a body turned out to be fruitless. Finally, in 1915, Albert Einstein developed a theory of general relativity which was able to accurately model Mercury's orbit.In general relativity, the effects of gravitation are ascribed to spacetime curvature instead of a force. Einstein began to toy with this idea in the form of the equivalence principle, a discovery which he later described as \"the happiest thought of my life.\" In this theory, free fall is considered to be equivalent to inertial motion, meaning that free-falling inertial objects are accelerated relative to non-inertial observers on the ground. In contrast to Newtonian physics, Einstein believed that it was possible for this acceleration to occur without any force being applied to the object.\nEinstein proposed that spacetime is curved by matter, and that free-falling objects are moving along locally straight paths in curved spacetime. These straight paths are called geodesics. As in Newton's first law of motion, Einstein believed that a force applied to an object would cause it to deviate from a geodesic. For instance, people standing on the surface of the Earth are prevented from following a geodesic path because the mechanical resistance of the Earth exerts an upward force on them. This explains why moving along the geodesics in spacetime is considered inertial.\nEinstein's description of gravity was quickly accepted by the majority of physicists, as it was able to explain a wide variety of previously baffling experimental results. In the coming years, a wide range of experiments provided additional support for the idea of general relativity. Today, Einstein's theory of relativity is used for all gravitational calculations where absolute precision is desired, although Newton's inverse-square law continues to be a useful and fairly accurate approximation.\n\n\n== Modern research ==\nIn modern physics, general relativity remains the framework for the understanding of gravity. Physicists continue to work to find solutions to the Einstein field equations that form the basis of general relativity, while some scientists have speculated that general relativity may not be applicable at all in certain scenarios.\n\n\n=== Einstein field equations ===\nThe Einstein field equations are a system of 10 partial differential equations which describe how matter affects the curvature of spacetime. The system is often expressed in the form\n\nwhere G\u03bc\u03bd is the Einstein tensor, g\u03bc\u03bd is the metric tensor, T\u03bc\u03bd is the stress\u2013energy tensor, \u039b is the cosmological constant, \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is the Newtonian constant of gravitation and \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the speed of light. The constant \n  \n    \n      \n        \u03ba\n        =\n        \n          \n            \n              8\n              \u03c0\n              G\n            \n            \n              c\n              \n                4\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\kappa ={\\frac {8\\pi G}{c^{4}}}}\n   is referred to as the Einstein gravitational constant.\nA major area of research is the discovery of exact solutions to the Einstein field equations. Solving these equations amounts to calculating a precise value for the metric tensor (which defines the curvature and geometry of spacetime) under certain physical conditions. There is no formal definition for what constitutes such solutions, but most scientists agree that they should be expressable using elementary functions or linear differential equations. Some of the most notable solutions of the equations include: \n\nThe Schwarzschild solution, which describes spacetime surrounding a spherically symmetric non-rotating uncharged massive object. For compact enough objects, this solution generated a black hole with a central singularity. At points far away from the central mass, the accelerations predicted by the Schwarzschild solution are practically identical to those predicted by Newton's theory of gravity.\nThe Reissner\u2013Nordstr\u00f6m solution, which analyzes a non-rotating spherically symmetric object with charge and was independently discovered by several different researchers between 1916 and 1921. In some cases, this solution can predict the existence of black holes with double event horizons.\nThe Kerr solution, which generalizes the Schwarzchild solution to rotating massive objects. Because of the difficulty of factoring in the effects of rotation into the Einstein field equations, this solution was not discovered until 1963.\nThe Kerr\u2013Newman solution for charged, rotating massive objects. This solution was derived in 1964, using the same technique of complex coordinate transformation that was used for the Kerr solution.\nThe cosmological Friedmann\u2013Lema\u00eetre\u2013Robertson\u2013Walker solution, discovered in 1922 by Alexander Friedmann and then confirmed in 1927 by Georges Lema\u00eetre. This solution was revolutionary for predicting the expansion of the Universe, which was confirmed seven years later after a series of measurements by Edwin Hubble. It even showed that general relativity was incompatible with a static universe, and Einstein later conceded that he had been wrong to design his field equations to account for a Universe that was not expanding.Today, there remain many important situations in which the Einstein field equations have not been solved. Chief among these is the two-body problem, which concerns the geometry of spacetime around two mutually interacting massive objects (such as the Sun and the Earth, or the two stars in a binary star system). The situation gets even more complicated when considering the interactions of three or more massive bodies (the \"n-body problem\"), and some scientists suspect that the Einstein field equations will never be solved in this context. However, it is still possible to construct an approximate solution to the field equations in the n-body problem by using the technique of post-Newtonian expansion. In general, the extreme nonlinearity of the Einstein field equations makes it difficult to solve them in all but the most specific cases.\n\n\n=== Gravity and quantum mechanics ===\n\nDespite its success in predicting the effects of gravity at large scales, general relativity is ultimately incompatible with quantum mechanics. This is because general relativity describes gravity as a smooth, continuous distortion of spacetime, while quantum mechanics holds that all forces arise from the exchange of discrete particles known as quanta. This contradiction is especially vexing to physicists because the other three fundamental forces (strong force, weak force and electromagnetism) were reconciled with a quantum framework decades ago. As a result, modern researchers have begun to search for a theory that could unite both gravity and quantum mechanics under a more general framework.One path is to describe gravity in the framework of quantum field theory, which has been successful to accurately describe the other fundamental interactions. The electromagnetic force arises from an exchange of virtual photons, where the QFT description of gravity is that there is an exchange of virtual gravitons. This description reproduces general relativity in the classical limit. However, this approach fails at short distances of the order of the Planck length, where a more complete theory of quantum gravity (or a new approach to quantum mechanics) is required.\n\n\n=== Tests of general relativity ===\nTesting the predictions of general relativity has historically been difficult, because they are almost identical to the predictions of Newtonian gravity for small energies and masses. Still, since its development, an ongoing series of experimental results have provided support for the theory:\n\nIn 1919, the British astrophysicist Arthur Eddington was able to confirm the predicted gravitational lensing of light during that year's solar eclipse. Eddington measured starlight deflections twice those predicted by Newtonian corpuscular theory, in accordance with the predictions of general relativity. Although Eddington's analysis was later disputed, this experiment made Einstein famous almost overnight and caused general relativity to become widely accepted in the scientific community.\nIn 1959, American physicists Robert Pound and Glen Rebka performed an experiment in which they used gamma rays to confirm the prediction of gravitational time dilation. By sending the rays down a 74-foot tower and measuring their frequency at the bottom, the scientists confirmed that light is redshifted as it moves towards a source of gravity. The observed redshift also supported the idea that time runs more slowly in the presence of a gravitational field.\nThe time delay of light passing close to a massive object was first identified by Irwin I. Shapiro in 1964 in interplanetary spacecraft signals.\nIn 1971, scientists discovered the first-ever black hole in the galaxy Cygnus. The black hole was detected because it was emitting bursts of x-rays as it consumed a smaller star, and it came to be known as Cygnus X-1. This discovery confirmed yet another prediction of general relativity, because Einstein's equations implied that light could not escape from a sufficiently large and compact object.\nGeneral relativity states that gravity acts on light and matter equally, meaning that a sufficiently massive object could warp light around it and create a gravitational lens. This phenomenon was first confirmed by observation in 1979 using the 2.1 meter telescope at Kitt Peak National Observatory in Arizona, which saw two mirror images of the same quasar whose light had been bent around the galaxy YGKOW G1.\nFrame dragging, the idea that a rotating massive object should twist spacetime around it, was confirmed by Gravity Probe B results in 2011.\nIn 2015, the LIGO observatory detected faint gravitational waves, the existence of which had been predicted by general relativity. Scientists believe that the waves emanated from a black hole merger that occurred 1.5 billion light-years away.\n\n\n== Specifics ==\n\n\n=== Earth's gravity ===\n\nEvery planetary body (including the Earth) is surrounded by its own gravitational field, which can be conceptualized with Newtonian physics as exerting an attractive force on all objects. Assuming a spherically symmetrical planet, the strength of this field at any given point above the surface is proportional to the planetary body's mass and inversely proportional to the square of the distance from the center of the body.\n\nThe strength of the gravitational field is numerically equal to the acceleration of objects under its influence. The rate of acceleration of falling objects near the Earth's surface varies very slightly depending on latitude, surface features such as mountains and ridges, and perhaps unusually high or low sub-surface densities. For purposes of weights and measures, a standard gravity value is defined by the International Bureau of Weights and Measures, under the International System of Units (SI).\nThe force of gravity on Earth is the resultant (vector sum) of two forces: (a) The gravitational attraction in accordance with Newton's universal law of gravitation, and (b) the centrifugal force, which results from the choice of an earthbound, rotating frame of reference. The force of gravity is weakest at the equator because of the centrifugal force caused by the Earth's rotation and because points on the equator are furthest from the center of the Earth. The force of gravity varies with latitude and increases from about 9.780 m/s2 at the Equator to about 9.832 m/s2 at the poles. Canada's Hudson Bay has less gravity than any place on Earth.\n\n\n=== Origin ===\nThe earliest gravity (possibly in the form of quantum gravity, supergravity or a gravitational singularity), along with ordinary space and time, developed during the Planck epoch (up to 10\u221243 seconds after the birth of the Universe), possibly from a primeval state (such as a false vacuum, quantum vacuum or virtual particle), in a currently unknown manner.\n\n\n=== Gravitational radiation ===\n\nGeneral relativity predicts that energy can be transported out of a system through gravitational radiation. The first indirect evidence for gravitational radiation was through measurements of the Hulse\u2013Taylor binary in 1973. This system consists of a pulsar and neutron star in orbit around one another. Its orbital period has decreased since its initial discovery due to a loss of energy, which is consistent for the amount of energy loss due to gravitational radiation. This research was awarded the Nobel Prize in Physics in 1993.The first direct evidence for gravitational radiation was measured on 14 September 2015 by the LIGO detectors. The gravitational waves emitted during the collision of two black holes 1.3 billion light years from Earth were measured. This observation confirms the theoretical predictions of Einstein and others that such waves exist. It also opens the way for practical observation and understanding of the nature of gravity and events in the Universe including the Big Bang. Neutron star and black hole formation also create detectable amounts of gravitational radiation. This research was awarded the Nobel Prize in Physics in 2017.\n\n\n=== Speed of gravity ===\n\nIn December 2012, a research team in China announced that it had produced measurements of the phase lag of Earth tides during full and new moons which seem to prove that the speed of gravity is equal to the speed of light. This means that if the Sun suddenly disappeared, the Earth would keep orbiting the vacant point normally for 8 minutes, which is the time light takes to travel that distance. The team's findings were released in Science Bulletin in February 2013.In October 2017, the LIGO and Virgo detectors received gravitational wave signals within 2 seconds of gamma ray satellites and optical telescopes seeing signals from the same direction. This confirmed that the speed of gravitational waves was the same as the speed of light.\n\n\n== Anomalies and discrepancies ==\n\nThere are some observations that are not adequately accounted for, which may point to the need for better theories of gravity or perhaps be explained in other ways.\n\nExtra-fast stars: Stars in galaxies follow a distribution of velocities where stars on the outskirts are moving faster than they should according to the observed distributions of normal matter. Galaxies within galaxy clusters show a similar pattern. Dark matter, which would interact through gravitation but not electromagnetically, would account for the discrepancy. Various modifications to Newtonian dynamics have also been proposed.\nFlyby anomaly: Various spacecraft have experienced greater acceleration than expected during gravity assist maneuvers.\nAccelerating expansion: The metric expansion of space seems to be speeding up. Dark energy has been proposed to explain this. A recent alternative explanation is that the geometry of space is not homogeneous (due to clusters of galaxies) and that when the data are reinterpreted to take this into account, the expansion is not speeding up after all, however this conclusion is disputed.\nAnomalous increase of the astronomical unit: Recent measurements indicate that planetary orbits are widening faster than if this were solely through the Sun losing mass by radiating energy.\nExtra energetic photons: Photons travelling through galaxy clusters should gain energy and then lose it again on the way out. The accelerating expansion of the Universe should stop the photons returning all the energy, but even taking this into account photons from the cosmic microwave background radiation gain twice as much energy as expected. This may indicate that gravity falls off faster than inverse-squared at certain distance scales.\nExtra massive hydrogen clouds: The spectral lines of the Lyman-alpha forest suggest that hydrogen clouds are more clumped together at certain scales than expected and, like dark flow, may indicate that gravity falls off slower than inverse-squared at certain distance scales.\n\n\n== Alternative theories ==\n\n\n=== Historical alternative theories ===\nAristotelian theory of gravity\nLe Sage's theory of gravitation (1784) also called LeSage gravity but originally proposed by Fatio and further elaborated by Georges-Louis Le Sage, based on a fluid-based explanation where a light gas fills the entire Universe.\nRitz's theory of gravitation, Ann. Chem. Phys. 13, 145, (1908) pp. 267\u2013271, Weber\u2013Gauss electrodynamics applied to gravitation. Classical advancement of perihelia.\nNordstr\u00f6m's theory of gravitation (1912, 1913), an early competitor of general relativity.\nKaluza Klein theory (1921)\nWhitehead's theory of gravitation (1922), another early competitor of general relativity.\n\n\n=== Modern alternative theories ===\nBrans\u2013Dicke theory of gravity (1961)\nInduced gravity (1967), a proposal by Andrei Sakharov according to which general relativity might arise from quantum field theories of matter\nString theory (late 1960s)\n\u0192(R) gravity (1970)\nHorndeski theory (1974)\nSupergravity (1976)\nIn the modified Newtonian dynamics (MOND) (1981), Mordehai Milgrom proposes a modification of Newton's second law of motion for small accelerations\nThe self-creation cosmology theory of gravity (1982) by G.A. Barber in which the Brans\u2013Dicke theory is modified to allow mass creation\nLoop quantum gravity (1988) by Carlo Rovelli, Lee Smolin, and Abhay Ashtekar\nNonsymmetric gravitational theory (NGT) (1994) by John Moffat\nTensor\u2013vector\u2013scalar gravity (TeVeS) (2004), a relativistic modification of MOND by Jacob Bekenstein\nChameleon theory (2004) by Justin Khoury and Amanda Weltman.\nPressuron theory (2013) by Olivier Minazzoli and Aur\u00e9lien Hees.\nConformal gravity\nGravity as an entropic force, gravity arising as an emergent phenomenon from the thermodynamic concept of entropy.\nIn the superfluid vacuum theory the gravity and curved spacetime arise as a collective excitation mode of non-relativistic background superfluid.\nMassive gravity, a theory where gravitons and gravitational waves have a non-zero mass\n\n\n== See also ==\n\n\n== Footnotes ==\n\n\n== References ==\n\n\n== Further reading ==\nThorne, Kip S.; Misner, Charles W.; Wheeler, John Archibald (1973). Gravitation. W.H. Freeman. ISBN 978-0-7167-0344-0.\nPanek, Richard (2 August 2019). \"Everything you thought you knew about gravity is wrong\". The Washington Post.\n\n\n== External links ==\n\nThe Feynman Lectures on Physics Vol. I Ch. 7: The Theory of Gravitation\n\"Gravitation\", Encyclopedia of Mathematics, EMS Press, 2001 [1994]\n\"Gravitation, theory of\", Encyclopedia of Mathematics, EMS Press, 2001 [1994]", "Amplitude": "The amplitude of a periodic variable is a measure of its change in a single period (such as time or spatial period). The amplitude of a non-periodic signal is its magnitude compared with a reference value. There are various definitions of amplitude (see below), which are all functions of the magnitude of the differences between the variable's extreme values. In older texts, the phase of a periodic function is sometimes called the amplitude.\n\n\n== Definitions ==\n\n\n=== Peak amplitude & semi-amplitude ===\nFor symmetric periodic waves, like sine waves, square waves or triangle waves peak amplitude and semi amplitude are the same.\n\n\n==== Peak amplitude ====\nIn audio system measurements, telecommunications and others where the measurand is a signal that swings above and below a reference value but is not sinusoidal, peak amplitude is often used. If the reference is zero, this is the maximum absolute value of the signal; if the reference is a mean value (DC component), the peak amplitude is the maximum absolute value of the difference from that reference.\n\n\n==== Semi-amplitude ====\nSemi-amplitude means half of the peak-to-peak amplitude. \nThe majority of scientific literature employs the term amplitude or peak amplitude to mean semi-amplitude.\nIt is the most widely used measure of orbital wobble in astronomy and the measurement of small radial velocity semi-amplitudes of nearby stars is important in the search for exoplanets (see Doppler spectroscopy).\n\n\n==== Ambiguity ====\nIn general, the use of peak amplitude is simple and unambiguous only for symmetric periodic waves, like a sine wave, a square wave, or a triangle wave. For an asymmetric wave (periodic pulses in one direction, for example), the peak amplitude becomes ambiguous. This is because the value is different depending on whether the maximum positive signal is measured relative to the mean, the maximum negative signal is measured relative to the mean, or the maximum positive signal is measured relative to the maximum negative signal (the peak-to-peak amplitude) and then divided by two (the semi-amplitude). In electrical engineering, the usual solution to this ambiguity is to measure the amplitude from a defined reference potential (such as ground or 0 V). Strictly speaking, this is no longer amplitude since there is the possibility that a constant (DC component) is included in the measurement.\n\n\n=== Peak-to-peak amplitude ===\nPeak-to-peak amplitude (abbreviated p\u2013p) is the change between peak (highest amplitude value) and trough (lowest amplitude value, which can be negative). With appropriate circuitry, peak-to-peak amplitudes of electric oscillations can be measured by meters or by viewing the waveform on an oscilloscope. Peak-to-peak is a straightforward measurement on an oscilloscope, the peaks of the waveform being easily identified and measured against the graticule. This remains a common way of specifying amplitude, but sometimes other measures of amplitude are more appropriate.\n\n\n=== Root mean square amplitude ===\n\nRoot mean square (RMS) amplitude is used especially in electrical engineering: the RMS is defined as the square root of the mean over time of the square of the vertical distance of the graph from the rest state;\ni.e. the RMS of the AC waveform (with no DC component).\nFor complicated waveforms, especially non-repeating signals like noise, the RMS amplitude is usually used because it is both unambiguous and has physical significance. For example, the average power transmitted by an acoustic or electromagnetic wave or by an electrical signal is proportional to the square of the RMS amplitude (and not, in general, to the square of the peak amplitude).For alternating current electric power, the  universal practice is to specify RMS values of a sinusoidal waveform. One property of root mean square voltages and currents is that they produce the same heating effect as a direct current in a given resistance.\nThe peak-to-peak value is used, for example, when choosing rectifiers for power supplies, or when estimating the maximum voltage that insulation must withstand. Some common voltmeters are calibrated for RMS amplitude, but respond to the average value of a rectified waveform. Many digital voltmeters and all moving coil meters are in this category. The RMS calibration is only correct for a sine wave input since the ratio between peak, average and RMS values is dependent on waveform. If the wave shape being measured is greatly different from a sine wave, the relationship between RMS and average value changes. True RMS-responding meters were used in radio frequency measurements, where instruments measured the heating effect in a resistor to measure a current. The advent of microprocessor controlled meters capable of calculating RMS by sampling the waveform has made true RMS measurement commonplace.\n\n\n=== Pulse amplitude ===\nIn telecommunication, pulse amplitude is the magnitude of a pulse parameter, such as the voltage level, current level, field intensity, or power level.\nPulse amplitude is measured with respect to a specified reference and therefore should be modified by qualifiers, such as average, instantaneous, peak, or root-mean-square.\nPulse amplitude also applies to the amplitude of frequency- and phase-modulated waveform envelopes.\n\n\n== Formal representation ==\nIn this simple wave equation\n\n  \n    \n      \n        x\n        =\n        A\n        sin\n        \u2061\n        (\n        \u03c9\n        [\n        t\n        \u2212\n        K\n        ]\n        )\n        +\n        b\n         \n        ,\n      \n    \n    {\\displaystyle x=A\\sin(\\omega [t-K])+b\\ ,}\n  \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is the amplitude (or peak amplitude),\n\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is the oscillating variable,\n\n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   is angular frequency,\n\n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is time,\n\n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n   are arbitrary constants representing time and displacement offsets respectively.\n\n\n== Units ==\nThe units of the amplitude depend on the type of wave, but are always in the same units as the oscillating variable. A more general representation of the wave equation is more complex, but the role of amplitude remains analogous to this simple case.\nFor waves on a string, or in a medium such as water, the amplitude is a displacement.\nThe amplitude of sound waves and audio signals (which relates to the volume) conventionally refers to the amplitude of the air pressure in the wave, but sometimes the amplitude of the displacement (movements of the air or the diaphragm of a speaker) is described. The logarithm of the amplitude squared is usually quoted in dB, so a null amplitude corresponds to \u2212\u221e dB. Loudness is related to amplitude and intensity and is one of the most salient qualities of a sound, although in general sounds it can be recognized independently of amplitude. The square of the amplitude is proportional to the intensity of the wave.\nFor electromagnetic radiation, the amplitude of a photon corresponds to the changes in the electric field of the wave. However, radio signals may be carried by electromagnetic radiation; the intensity of the radiation (amplitude modulation) or the frequency of the radiation (frequency modulation) is oscillated and then the individual oscillations are varied (modulated) to produce the signal.\n\n\n== Transient amplitude envelopes ==\nA steady state amplitude remains constant during time, thus is represented by a scalar. Otherwise, the amplitude is transient and must be represented as either a continuous function or a discrete vector. For audio, transient amplitude envelopes model signals better because many common sounds have a transient loudness attack, decay, sustain, and release.\nOther parameters can be assigned steady state or transient amplitude envelopes: high/low frequency/amplitude modulation, Gaussian noise, overtones, etc.\n\n\n== Amplitude normalization ==\nWith waveforms containing many overtones, complex transient timbres can be achieved by assigning each overtone to its own distinct transient amplitude envelope. Unfortunately, this has the effect of modulating the loudness of the sound as well. It makes more sense to separate loudness and harmonic quality to be parameters controlled independently of each other.\nTo do so, harmonic amplitude envelopes are frame-by-frame normalized to become amplitude proportion envelopes, where at each time frame all the harmonic amplitudes will add to 100% (or 1). This way, the main loudness-controlling envelope can be cleanly controlled.In Sound Recognition, max amplitude normalization can be used to help align the key harmonic features of 2 alike sounds, allowing similar timbres to be recognized independent of loudness.\n\n\n== See also ==\n\nComplex amplitude\nWaves and their properties:\nEnvelope\nFrequency\nWavelength\nCrest factor\nAmplitude modulation\nBody thermal amplitude\nAtmospheric thermal amplitude\nWave height\n\n\n== Notes ==", "Gravity_of_Earth": "The gravity of Earth, denoted by g, is the net acceleration that is imparted to objects due to the combined effect of gravitation (from mass distribution within Earth) and the centrifugal force (from the Earth's rotation).\nIt is a vector quantity, whose direction coincides with a plumb bob and strength or magnitude is given by the norm \n  \n    \n      \n        g\n        =\n        \u2016\n        \n          \n            \n              g\n            \n          \n        \n        \u2016\n      \n    \n    {\\displaystyle g=\\|{\\mathit {\\mathbf {g} }}\\|}\n  .\nIn SI units this acceleration is expressed in metres per second squared (in symbols, m/s2 or m\u00b7s\u22122) or equivalently in newtons per kilogram (N/kg or N\u00b7kg\u22121). Near Earth's surface, the gravity acceleration is approximately 9.81 m/s2 (32.2 ft/s2), which means that, ignoring the effects of air resistance, the speed of an object falling freely will increase by about 9.81 metres (32.2 ft) per second every second. This quantity is sometimes referred to informally as little g (in contrast, the gravitational constant G is referred to as big G).\nThe precise strength of Earth's gravity varies depending on the location. The nominal \"average\" value at Earth's surface, known as standard gravity is, by definition, 9.80665 m/s2 (32.1740 ft/s2). This quantity is denoted variously as gn, ge (though this sometimes means the normal equatorial value on Earth, 9.78033 m/s2 (32.0877 ft/s2)), g0, gee, or simply g (which is also used for the variable local value).\nThe weight of an object on Earth's surface is the downwards force on that object, given by Newton's second law of motion, or F = m a (force = mass \u00d7 acceleration). Gravitational acceleration contributes to the total gravity acceleration, but other factors, such as the rotation of Earth, also contribute, and, therefore, affect the weight of the object. Gravity does not normally include the gravitational pull of the Moon and Sun, which are accounted for in terms of tidal effects.\n\n\n== Variation in magnitude ==\nA non-rotating perfect sphere of uniform mass density, or whose density varies solely with distance from the centre (spherical symmetry), would produce a gravitational field of uniform magnitude at all points on its surface. The Earth is rotating and is also not spherically symmetric; rather, it is slightly flatter at the poles while bulging at the Equator: an oblate spheroid. There are consequently slight deviations in the magnitude of gravity across its surface.\nGravity on the Earth's surface varies by around 0.7%, from 9.7639 m/s2 on the Nevado Huascar\u00e1n mountain in Peru to 9.8337 m/s2 at the surface of the Arctic Ocean. In large cities, it ranges from 9.7806 in Kuala Lumpur, Mexico City, and Singapore to 9.825 in Oslo and Helsinki.\n\n\n=== Conventional value ===\nIn 1901 the third General Conference on Weights and Measures defined a standard gravitational acceleration for the surface of the Earth: gn = 9.80665 m/s2. It was based on measurements done at the Pavillon de Breteuil near Paris in 1888, with a theoretical correction applied in order to convert to a latitude of 45\u00b0 at sea level. This definition is thus not a value of any particular place or carefully worked out average, but an agreement for a value to use if a better actual local value is not known or not important. It is also used to define the units kilogram force and pound force.\nCalculating the gravity at Earth's surface using the average radius of Earth (6,371 kilometres (3,959 mi)), the experimentally determined value of the gravitational constant, and the Earth mass of 5.9722 \u00d71024 kg gives an acceleration of 9.8203 m/s2, slightly greater than the standard gravity of 9.80665 m/s2. The value of standard gravity corresponds to the gravity on Earth at a radius of 6,375.4 kilometres (3,961.5 mi).\n\n\n=== Latitude ===\n\nThe surface of the Earth is rotating, so it is not an inertial frame of reference. At latitudes nearer the Equator, the outward centrifugal force produced by Earth's rotation is larger than at polar latitudes. This counteracts the Earth's gravity to a small degree \u2013 up to a maximum of 0.3% at the Equator \u2013 and reduces the apparent downward acceleration of falling objects.\nThe second major reason for the difference in gravity at different latitudes is that the Earth's equatorial bulge (itself also caused by centrifugal force from rotation) causes objects at the Equator to be further from the planet's center than objects at the poles. Because the force due to gravitational attraction between two bodies (the Earth and the object being weighed) varies inversely with the square of the distance between them, an object at the Equator experiences a weaker gravitational pull than an object on one of the poles.\nIn combination, the equatorial bulge and the effects of the surface centrifugal force due to rotation mean that sea-level gravity increases from about 9.780 m/s2 at the Equator to about 9.832 m/s2 at the poles, so an object will weigh approximately 0.5% more at the poles than at the Equator.\n\n\n=== Altitude ===\n\nGravity decreases with altitude as one rises above the Earth's surface because greater altitude means greater distance from the Earth's centre. All other things being equal, an increase in altitude from sea level to 9,000 metres (30,000 ft) causes a weight decrease of about 0.29%. (An additional factor affecting apparent weight is the decrease in air density at altitude, which lessens an object's buoyancy. This would increase a person's apparent weight at an altitude of 9,000 metres by about 0.08%)\nIt is a common misconception that astronauts in orbit are weightless because they have flown high enough to escape the Earth's gravity. In fact, at an altitude of 400 kilometres (250 mi), equivalent to a typical orbit of the ISS, gravity is still nearly 90% as strong as at the Earth's surface. Weightlessness actually occurs because orbiting objects are in free-fall.The effect of ground elevation depends on the density of the ground (see Slab correction section). A person flying at 9,100 m (30,000 ft) above sea level over mountains will feel more gravity than someone at the same elevation but over the sea. However, a person standing on the Earth's surface feels less gravity when the elevation is higher.\nThe following formula approximates the Earth's gravity variation with altitude:\n\n  \n    \n      \n        \n          g\n          \n            h\n          \n        \n        =\n        \n          g\n          \n            0\n          \n        \n        \n          \n            (\n            \n              \n                \n                  R\n                  \n                    \n                      e\n                    \n                  \n                \n                \n                  \n                    R\n                    \n                      \n                        e\n                      \n                    \n                  \n                  +\n                  h\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle g_{h}=g_{0}\\left({\\frac {R_{\\mathrm {e} }}{R_{\\mathrm {e} }+h}}\\right)^{2}}\n  Where\n\ngh is the gravitational acceleration at height h above sea level.\nRe is the Earth's mean radius.\ng0 is the standard gravitational acceleration.The formula treats the Earth as a perfect sphere with a radially symmetric distribution of mass; a more accurate mathematical treatment is discussed below.\n\n\n=== Depth ===\n\nAn approximate value for gravity at a distance r from the center of the Earth can be obtained by assuming that the Earth's density is spherically symmetric. The gravity depends only on the mass inside the sphere of radius r. All the contributions from outside cancel out as a consequence of the inverse-square law of gravitation. Another consequence is that the gravity is the same as if all the mass were concentrated at the center. Thus, the gravitational acceleration at this radius is\n\n  \n    \n      \n        g\n        (\n        r\n        )\n        =\n        \u2212\n        \n          \n            \n              G\n              M\n              (\n              r\n              )\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle g(r)=-{\\frac {GM(r)}{r^{2}}}.}\n  where G is the gravitational constant and M(r) is the total mass enclosed within radius r. If the Earth had a constant density \u03c1, the mass would be M(r) = (4/3)\u03c0\u03c1r3 and the dependence of gravity on depth would be\n\n  \n    \n      \n        g\n        (\n        r\n        )\n        =\n        \n          \n            \n              4\n              \u03c0\n            \n            3\n          \n        \n        G\n        \u03c1\n        r\n        .\n      \n    \n    {\\displaystyle g(r)={\\frac {4\\pi }{3}}G\\rho r.}\n  The gravity g\u2032 at depth d is given by g\u2032 = g(1 \u2212 d/R) where g is acceleration due to gravity on the surface of the Earth, d is depth and R is the radius of the Earth.\nIf the density decreased linearly with increasing radius from a density \u03c10 at the center to \u03c11 at the surface, then \u03c1(r) = \u03c10 \u2212 (\u03c10 \u2212 \u03c11) r / re, and the dependence would be\n\n  \n    \n      \n        g\n        (\n        r\n        )\n        =\n        \n          \n            \n              4\n              \u03c0\n            \n            3\n          \n        \n        G\n        \n          \u03c1\n          \n            0\n          \n        \n        r\n        \u2212\n        \u03c0\n        G\n        \n          (\n          \n            \n              \u03c1\n              \n                0\n              \n            \n            \u2212\n            \n              \u03c1\n              \n                1\n              \n            \n          \n          )\n        \n        \n          \n            \n              r\n              \n                2\n              \n            \n            \n              r\n              \n                \n                  e\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle g(r)={\\frac {4\\pi }{3}}G\\rho _{0}r-\\pi G\\left(\\rho _{0}-\\rho _{1}\\right){\\frac {r^{2}}{r_{\\mathrm {e} }}}.}\n  The actual depth dependence of density and gravity, inferred from seismic travel times (see Adams\u2013Williamson equation), is shown in the graphs below.\n\n\n=== Local topography and geology ===\n\nLocal differences in topography (such as the presence of mountains), geology (such as the density of rocks in the vicinity), and deeper tectonic structure cause local and regional differences in the Earth's gravitational field, known as gravitational anomalies. Some of these anomalies can be very extensive, resulting in bulges in sea level, and throwing pendulum clocks out of synchronisation.\nThe study of these anomalies forms the basis of gravitational geophysics. The fluctuations are measured with highly sensitive gravimeters, the effect of topography and other known factors is subtracted, and from the resulting data conclusions are drawn. Such techniques are now used by prospectors to find oil and mineral deposits. Denser rocks (often containing mineral ores) cause higher than normal local gravitational fields on the Earth's surface. Less dense sedimentary rocks cause the opposite.\n\nThere is a strong correlation between the gravity derivation map of earth from NASA GRACE with positions of recent volcanic activity, ridge spreading and volcanos: these regions have a stronger gravitation than theoretical predictions.\n\n\n=== Other factors ===\nIn air or water, objects experience a supporting buoyancy force which reduces the apparent strength of gravity (as measured by an object's weight). The magnitude of the effect depends on the air density (and hence air pressure) or the water density respectively; see Apparent weight for details.\nThe gravitational effects of the Moon and the Sun (also the cause of the tides) have a very small effect on the apparent strength of Earth's gravity, depending on their relative positions; typical variations are 2 \u00b5m/s2 (0.2 mGal) over the course of a day.\n\n\n== Direction ==\n\nGravity acceleration is a vector quantity, with direction in addition to magnitude. In a spherically symmetric Earth, gravity would point directly towards the sphere's centre. As the Earth's figure is slightly flatter, there are consequently significant deviations in the direction of gravity: essentially the difference between geodetic latitude and geocentric latitude. Smaller deviations, called vertical deflection, are caused by local mass anomalies, such as mountains.\n\n\n== Comparative values worldwide ==\nTools exist for calculating the strength of gravity at various cities around the world. The effect of latitude can be clearly seen with gravity in high-latitude cities: Anchorage (9.826 m/s2), Helsinki (9.825 m/s2), being about 0.5% greater than that in cities near the equator: Kuala Lumpur (9.776 m/s2).  The effect of altitude can be seen in Mexico City (9.776 m/s2; altitude 2,240 metres (7,350 ft)), and by comparing Denver (9.798 m/s2; 1,616 metres (5,302 ft)) with Washington, D.C. (9.801 m/s2; 30 metres (98 ft)), both of which are near 39\u00b0 N. Measured values can be obtained from Physical and Mathematical Tables by T.M. Yarwood and F. Castle, Macmillan, revised edition 1970.\n\n\n== Mathematical models ==\n\nIf the terrain is at sea level, we can estimate, for the Geodetic Reference System 1980, \n  \n    \n      \n        g\n        {\n        \u03d5\n        }\n      \n    \n    {\\displaystyle g\\{\\phi \\}}\n  , the acceleration at latitude \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n  :\n\n  \n    \n      \n        \n          \n            \n              \n                g\n                {\n                \u03d5\n                }\n              \n              \n                \n                =\n                9.780327\n                \n                \n                \n                  m\n                \n                \u22c5\n                \n                  \n                    s\n                  \n                  \n                    \u2212\n                    2\n                  \n                \n                \n                \n                \n                  (\n                  \n                    1\n                    +\n                    0.0053024\n                    \n                    \n                      sin\n                      \n                        2\n                      \n                    \n                    \u2061\n                    \u03d5\n                    \u2212\n                    0.0000058\n                    \n                    \n                      sin\n                      \n                        2\n                      \n                    \n                    \u2061\n                    2\n                    \u03d5\n                  \n                  )\n                \n                ,\n              \n            \n            \n              \n              \n                \n                =\n                9.780327\n                \n                \n                \n                  m\n                \n                \u22c5\n                \n                  \n                    s\n                  \n                  \n                    \u2212\n                    2\n                  \n                \n                \n                \n                \n                  (\n                  \n                    1\n                    +\n                    0.0052792\n                    \n                    \n                      sin\n                      \n                        2\n                      \n                    \n                    \u2061\n                    \u03d5\n                    +\n                    0.0000232\n                    \n                    \n                      sin\n                      \n                        4\n                      \n                    \n                    \u2061\n                    \u03d5\n                  \n                  )\n                \n                ,\n              \n            \n            \n              \n              \n                \n                =\n                9.780327\n                \n                \n                \n                  m\n                \n                \u22c5\n                \n                  \n                    s\n                  \n                  \n                    \u2212\n                    2\n                  \n                \n                \n                \n                \n                  (\n                  \n                    1.0053024\n                    \u2212\n                    0.0053256\n                    \n                    \n                      cos\n                      \n                        2\n                      \n                    \n                    \u2061\n                    \u03d5\n                    +\n                    0.0000232\n                    \n                    \n                      cos\n                      \n                        4\n                      \n                    \n                    \u2061\n                    \u03d5\n                  \n                  )\n                \n                ,\n              \n            \n            \n              \n              \n                \n                =\n                9.780327\n                \n                \n                \n                  m\n                \n                \u22c5\n                \n                  \n                    s\n                  \n                  \n                    \u2212\n                    2\n                  \n                \n                \n                \n                \n                  (\n                  \n                    1.0026454\n                    \u2212\n                    0.0026512\n                    \n                    cos\n                    \u2061\n                    2\n                    \u03d5\n                    +\n                    0.0000058\n                    \n                    \n                      cos\n                      \n                        2\n                      \n                    \n                    \u2061\n                    2\n                    \u03d5\n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}g\\{\\phi \\}&=9.780327\\,\\,\\mathrm {m} \\cdot \\mathrm {s} ^{-2}\\,\\,\\left(1+0.0053024\\,\\sin ^{2}\\phi -0.0000058\\,\\sin ^{2}2\\phi \\right),\\\\&=9.780327\\,\\,\\mathrm {m} \\cdot \\mathrm {s} ^{-2}\\,\\,\\left(1+0.0052792\\,\\sin ^{2}\\phi +0.0000232\\,\\sin ^{4}\\phi \\right),\\\\&=9.780327\\,\\,\\mathrm {m} \\cdot \\mathrm {s} ^{-2}\\,\\,\\left(1.0053024-0.0053256\\,\\cos ^{2}\\phi +0.0000232\\,\\cos ^{4}\\phi \\right),\\\\&=9.780327\\,\\,\\mathrm {m} \\cdot \\mathrm {s} ^{-2}\\,\\,\\left(1.0026454-0.0026512\\,\\cos 2\\phi +0.0000058\\,\\cos ^{2}2\\phi \\right)\\end{aligned}}}\n  This is the International Gravity Formula 1967, the 1967 Geodetic Reference System Formula, Helmert's equation or Clairaut's formula.An alternative formula for g as a function of latitude is the WGS (World Geodetic System) 84 Ellipsoidal Gravity Formula:\n\n  \n    \n      \n        g\n        {\n        \u03d5\n        }\n        =\n        \n          \n            G\n          \n          \n            e\n          \n        \n        \n          [\n          \n            \n              \n                1\n                +\n                k\n                \n                  sin\n                  \n                    2\n                  \n                \n                \u2061\n                \u03d5\n              \n              \n                1\n                \u2212\n                \n                  e\n                  \n                    2\n                  \n                \n                \n                  sin\n                  \n                    2\n                  \n                \n                \u2061\n                \u03d5\n              \n            \n          \n          ]\n        \n        ,\n        \n        \n      \n    \n    {\\displaystyle g\\{\\phi \\}=\\mathbb {G} _{e}\\left[{\\frac {1+k\\sin ^{2}\\phi }{\\sqrt {1-e^{2}\\sin ^{2}\\phi }}}\\right],\\,\\!}\n  where,\n\n  \n    \n      \n        a\n        ,\n        \n        b\n      \n    \n    {\\displaystyle a,\\,b}\n   are the equatorial and polar semi-axes, respectively;\n\n  \n    \n      \n        \n          e\n          \n            2\n          \n        \n        =\n        1\n        \u2212\n        (\n        b\n        \n          /\n        \n        a\n        \n          )\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle e^{2}=1-(b/a)^{2}}\n   is the spheroid's eccentricity, squared;\n\n  \n    \n      \n        \n          \n            G\n          \n          \n            e\n          \n        \n        ,\n        \n        \n          \n            G\n          \n          \n            p\n          \n        \n        \n      \n    \n    {\\displaystyle \\mathbb {G} _{e},\\,\\mathbb {G} _{p}\\,}\n   is the defined gravity at the equator and poles, respectively;\n\n  \n    \n      \n        k\n        =\n        \n          \n            \n              b\n              \n              \n                \n                  G\n                \n                \n                  p\n                \n              \n              \u2212\n              a\n              \n              \n                \n                  G\n                \n                \n                  e\n                \n              \n            \n            \n              a\n              \n              \n                \n                  G\n                \n                \n                  e\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle k={\\frac {b\\,\\mathbb {G} _{p}-a\\,\\mathbb {G} _{e}}{a\\,\\mathbb {G} _{e}}}}\n   (formula constant);then, where \n  \n    \n      \n        \n          \n            G\n          \n          \n            p\n          \n        \n        =\n        9.8321849378\n        \n        \n        \n          m\n        \n        \u22c5\n        \n          \n            s\n          \n          \n            \u2212\n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {G} _{p}=9.8321849378\\,\\,\\mathrm {m} \\cdot \\mathrm {s} ^{-2}}\n  ,\n\n  \n    \n      \n        g\n        {\n        \u03d5\n        }\n        =\n        9.7803253359\n        \n        \n        \n          m\n        \n        \u22c5\n        \n          \n            s\n          \n          \n            \u2212\n            2\n          \n        \n        \n          [\n          \n            \n              \n                1\n                +\n                0.001931852652\n                \n                \n                  sin\n                  \n                    2\n                  \n                \n                \u2061\n                \u03d5\n              \n              \n                1\n                \u2212\n                0.0066943799901\n                \n                \n                  sin\n                  \n                    2\n                  \n                \n                \u2061\n                \u03d5\n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle g\\{\\phi \\}=9.7803253359\\,\\,\\mathrm {m} \\cdot \\mathrm {s} ^{-2}\\left[{\\frac {1+0.001931852652\\,\\sin ^{2}\\phi }{\\sqrt {1-0.0066943799901\\,\\sin ^{2}\\phi }}}\\right]}\n  .where the semi-axes of the earth are:\n\n  \n    \n      \n        a\n        =\n        6378137.0\n        \n        \n        \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle a=6378137.0\\,\\,{\\mbox{m}}}\n  \n\n  \n    \n      \n        b\n        =\n        6356752.314245\n        \n        \n        \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle b=6356752.314245\\,\\,{\\mbox{m}}}\n  The difference between the WGS-84 formula and Helmert's equation is less than 0.68 \u03bcm\u00b7s\u22122.\nFurther reductions are applied to obtain gravity anomalies (see: Gravity anomaly#Computation).\n\n\n== Estimating g from the law of universal gravitation ==\nFrom the law of universal gravitation, the force on a body acted upon by Earth's gravitational force is given by\n\n  \n    \n      \n        F\n        =\n        G\n        \n          \n            \n              \n                m\n                \n                  1\n                \n              \n              \n                m\n                \n                  2\n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        =\n        \n          (\n          \n            G\n            \n              \n                \n                  M\n                  \n                    \u2295\n                  \n                \n                \n                  r\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n        m\n      \n    \n    {\\displaystyle F=G{\\frac {m_{1}m_{2}}{r^{2}}}=\\left(G{\\frac {M_{\\oplus }}{r^{2}}}\\right)m}\n  where r is the distance between the centre of the Earth and the body (see below), and here we take \n  \n    \n      \n        \n          M\n          \n            \u2295\n          \n        \n      \n    \n    {\\displaystyle M_{\\oplus }}\n   to be the mass of the Earth and m to be the mass of the body.\nAdditionally, Newton's second law, F = ma, where m is mass and a is acceleration, here tells us that\n\n  \n    \n      \n        F\n        =\n        m\n        g\n      \n    \n    {\\displaystyle F=mg}\n  Comparing the two formulas it is seen that:\n\n  \n    \n      \n        g\n        =\n        G\n        \n          \n            \n              M\n              \n                \u2295\n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle g=G{\\frac {M_{\\oplus }}{r^{2}}}}\n  So, to find the acceleration due to gravity at sea level, substitute the values of the gravitational constant, G, the Earth's mass (in kilograms), m1, and the Earth's radius (in metres), r, to obtain the value of g:\n\n  \n    \n      \n        g\n        =\n        G\n        \n          \n            \n              M\n              \n                \u2295\n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        =\n        6.674\n        \u22c5\n        \n          10\n          \n            \u2212\n            11\n          \n        \n        \n          \n            \n              m\n            \n            \n              3\n            \n          \n          \n          \n            \n              k\n              g\n            \n            \n              \u2212\n              1\n            \n          \n          \n            \n              s\n            \n            \n              \u2212\n              2\n            \n          \n        \n        \u00d7\n        \n          \n            \n              6\n              \u00d7\n              \n                10\n                \n                  24\n                \n              \n              \n                k\n                g\n              \n            \n            \n              (\n              6.4\n              \u00d7\n              \n                10\n                \n                  6\n                \n              \n              \n                m\n              \n              \n                )\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        9\n        +\n        \n          \n            795\n            \n              2\n              \n                10\n              \n            \n          \n        \n        \u2248\n        9.77637\n        \n        \n          \n            m\n          \n          \n          \n            \n              s\n            \n            \n              \u2212\n              2\n            \n          \n        \n      \n    \n    {\\displaystyle g=G{\\frac {M_{\\oplus }}{r^{2}}}=6.674\\cdot 10^{-11}\\mathrm {{m}^{3}\\,{kg}^{-1}{s}^{-2}} \\times {\\frac {6\\times 10^{24}\\mathrm {kg} }{(6.4\\times 10^{6}\\mathrm {m} )^{2}}}=9+{\\frac {795}{2^{10}}}\\approx 9.77637\\,\\mathrm {{m}\\,{s}^{-2}} }\n  This formula only works because of the mathematical fact that the gravity of a uniform spherical body, as measured on or above its surface, is the same as if all its mass were concentrated at a point at its centre. This is what allows us to use the Earth's radius for r.\nThe value obtained agrees approximately with the measured value of g. The difference may be attributed to several factors, mentioned above under \"Variations\":\n\nThe Earth is not homogeneous\nThe Earth is not a perfect sphere, and an average value must be used for its radius\nThis calculated value of g only includes true gravity. It does not include the reduction of constraint force that we perceive as a reduction of gravity due to the rotation of Earth, and some of gravity being counteracted by centrifugal force.There are significant uncertainties in the values of r and m1 as used in this calculation, and the value of G is also rather difficult to measure precisely.\nIf G, g and r are known then a reverse calculation will give an estimate of the mass of the Earth. This method was used by Henry Cavendish.\n\n\n== Measurement ==\n\nThe measurement of Earth's gravity is called gravimetry.\n\n\n=== Satellite measurements ===\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\nAltitude gravity calculator\nGRACE \u2013 Gravity Recovery and Climate Experiment\nGGMplus high resolution data (2013)\nGeoid 2011 model Potsdam Gravity Potato", "Deformation_(engineering)": "In engineering, deformation refers to the change in size or shape of an object. Displacements are the absolute change in position of a point on the object. Deflection is the relative change in external displacements on an object. Strain is the relative internal change in shape of an infinitesimally small cube of material and can be expressed as a non-dimensional change in length or angle of distortion of the cube. Strains are related to the forces acting on the cube, which are known as stress, by a stress-strain curve. The relationship between stress and strain is generally linear and reversible up until the yield point and the deformation is elastic. The linear relationship for a material is known as Young's modulus. Above the yield point, some degree of permanent distortion remains after unloading and is termed plastic deformation. The determination of the stress and strain throughout a solid object is given by the field of strength of materials and for a structure by structural analysis.\nEngineering stress and engineering strain are approximations to the internal state that may be determined from the external forces and deformations of an object, provided that there is no significant change in size. When there is a significant change in size, the true stress and true strain can be derived from the instantaneous size of the object.\nIn the figure it can be seen that the compressive loading (indicated by the arrow) has caused deformation in the cylinder so that the original shape (dashed lines) has changed (deformed) into one with bulging sides. The sides bulge because the material, although strong enough to not crack or otherwise fail, is not strong enough to support the load without change. As a result, the material is forced out laterally. Internal forces (in this case at right angles to the deformation) resist the applied load.\nThe concept of a rigid body can be applied if the deformation is negligible.\n\n\n== Types of deformation ==\nDepending on the type of material, size and geometry of the object, and the forces applied, various types of deformation may result. The image to the right shows the engineering stress vs. strain diagram for a typical ductile material such as steel. Different deformation modes may occur under different conditions, as can be depicted using a deformation mechanism map.\nPermanent deformation is irreversible; the deformation stays even after removal of the applied forces, while the temporary deformation is recoverable as it disappears after the removal of applied forces.\nTemporary deformation is also called elastic deformation, while the permanent deformation is called plastic deformation.\n\n\n=== Elastic deformation ===\n\nThe study of temporary or elastic deformation in the case of engineering strain is applied to materials used in mechanical and structural engineering, such as concrete and steel, which are subjected to very small deformations. Engineering strain is modeled by infinitesimal strain theory, also called small strain theory, small deformation theory, small displacement theory, or small displacement-gradient theory where strains and rotations are both small.\nFor some materials, e.g. elastomers and polymers, subjected to large deformations, the engineering definition of strain is not applicable, e.g. typical engineering strains greater than 1%, thus other more complex definitions of strain are required, such as stretch, logarithmic strain, Green strain, and Almansi strain. Elastomers and shape memory metals such as Nitinol exhibit large elastic deformation ranges, as does rubber. However, elasticity is nonlinear in these materials. \nNormal metals, ceramics and most crystals show linear elasticity and a smaller elastic range.\nLinear elastic deformation is governed by Hooke's law, which states:\n\n  \n    \n      \n        \u03c3\n        =\n        E\n        \u03b5\n      \n    \n    {\\displaystyle \\sigma =E\\varepsilon }\n  where\n\n\u03c3 is the applied stress;\nE is a material constant called Young's modulus or elastic modulus;\n\u03b5 is the resulting strain.This relationship only applies in the elastic range and indicates that the slope of the stress vs. strain curve can be used to find Young's modulus (E). Engineers often use this calculation in tensile tests.\nNote that not all elastic materials undergo linear elastic deformation; some, such as concrete, gray cast iron, and many polymers, respond in a nonlinear fashion. For these materials Hooke's law is inapplicable.\n\n\n=== True stress and strain ===\nSince we disregard the change of area during deformation above, the true stress and strain curve should be re-derived. For deriving the stress strain curve, we can assume that the volume change is 0 even if we deformed the materials. We can assume that:\n\n  \n    \n      \n        \n          A\n          \n            i\n          \n        \n        \u00d7\n        \n          \u03b5\n          \n            i\n          \n        \n        =\n        \n          A\n          \n            f\n          \n        \n        \u00d7\n        \n          \u03b5\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle A_{i}\\times \\varepsilon _{i}=A_{f}\\times \\varepsilon _{f}}\n  Then, the true stress can be expressed as below:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \u03c3\n                  \n                    T\n                  \n                \n                =\n                \n                  \n                    F\n                    \n                      A\n                      \n                        f\n                      \n                    \n                  \n                \n              \n              \n                \n                =\n                \n                  \n                    F\n                    \n                      A\n                      \n                        i\n                      \n                    \n                  \n                \n                \u00d7\n                \n                  \n                    \n                      A\n                      \n                        i\n                      \n                    \n                    \n                      A\n                      \n                        f\n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u03c3\n                  \n                    e\n                  \n                \n                \u00d7\n                \n                  \n                    \n                      l\n                      \n                        f\n                      \n                    \n                    \n                      l\n                      \n                        i\n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u03c3\n                  \n                    E\n                  \n                \n                \u00d7\n                \n                  \n                    \n                      \n                        l\n                        \n                          i\n                        \n                      \n                      +\n                      \u03b4\n                      l\n                    \n                    \n                      l\n                      \n                        i\n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u03c3\n                  \n                    E\n                  \n                \n                (\n                1\n                +\n                \n                  \u03b5\n                  \n                    E\n                  \n                \n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\sigma _{T}={\\frac {F}{A_{f}}}&={\\frac {F}{A_{i}}}\\times {\\frac {A_{i}}{A_{f}}}\\\\&=\\sigma _{e}\\times {\\frac {l_{f}}{l_{i}}}\\\\[2pt]&=\\sigma _{E}\\times {\\frac {l_{i}+\\delta l}{l_{i}}}\\\\[2pt]&=\\sigma _{E}(1+\\varepsilon _{E})\\end{aligned}}}\n  Additionally, the true strain \u03b5T can be express as below:\n\n  \n    \n      \n        \n          \u03b5\n          \n            T\n          \n        \n        =\n        \n          \n            \n              d\n              l\n            \n            \n              l\n              \n                0\n              \n            \n          \n        \n        +\n        \n          \n            \n              d\n              l\n            \n            \n              l\n              \n                1\n              \n            \n          \n        \n        +\n        \n          \n            \n              d\n              l\n            \n            \n              l\n              \n                2\n              \n            \n          \n        \n        +\n        \u22ef\n        =\n        \n          \u2211\n          \n            i\n          \n        \n        \n          \n            \n              d\n              l\n            \n            \n              l\n              \n                i\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{T}={\\frac {dl}{l_{0}}}+{\\frac {dl}{l_{1}}}+{\\frac {dl}{l_{2}}}+\\cdots =\\sum _{i}{\\frac {dl}{l_{i}}}}\n  Then, we can express the value as \n\n  \n    \n      \n        \n          \u222b\n          \n            \n              l\n              \n                0\n              \n            \n          \n          \n            \n              l\n              \n                i\n              \n            \n          \n        \n        \n          \n            \n              d\n              l\n            \n            l\n          \n        \n        \n        d\n        x\n        =\n        ln\n        \u2061\n        \n          (\n          \n            \n              \n                l\n                \n                  i\n                \n              \n              \n                l\n                \n                  0\n                \n              \n            \n          \n          )\n        \n        =\n        ln\n        \u2061\n        (\n        1\n        +\n        \n          \u03b5\n          \n            E\n          \n        \n        )\n      \n    \n    {\\displaystyle \\int _{l_{0}}^{l_{i}}{\\frac {dl}{l}}\\,dx=\\ln \\left({\\frac {l_{i}}{l_{0}}}\\right)=\\ln(1+\\varepsilon _{E})}\n  Thus, we can induce the plot in terms of \n  \n    \n      \n        \n          \u03c3\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{T}}\n   and \n  \n    \n      \n        \n          \u03b5\n          \n            E\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{E}}\n   as right figure.\nAdditionally, based on the true stress-strain curve, we can estimate the region where necking starts to happen. Since necking starts to appear after ultimate tensile stress where the maximum force applied, we can express this situation as below:\n\n  \n    \n      \n        d\n        F\n        =\n        0\n        =\n        \n          \u03c3\n          \n            T\n          \n        \n        d\n        \n          A\n          \n            i\n          \n        \n        +\n        \n          A\n          \n            i\n          \n        \n        d\n        \n          \u03c3\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle dF=0=\\sigma _{T}dA_{i}+A_{i}d\\sigma _{T}}\n  so this form can be expressed as below:\n\n  \n    \n      \n        \n          \n            \n              d\n              \n                \u03c3\n                \n                  T\n                \n              \n            \n            \n              \u03c3\n              \n                T\n              \n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              d\n              \n                A\n                \n                  i\n                \n              \n            \n            \n              A\n              \n                i\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {d\\sigma _{T}}{\\sigma _{T}}}=-{\\frac {dA_{i}}{A_{i}}}}\n  It indicates that the necking starts to appear where reduction of area becomes much significant compared to the stress change. Then the stress will be localized to specific area where the necking appears.\nAdditionally, we can induce various relation based on true stress-strain curve.\n1) True strain and stress curve can be expressed by the approximate linear relationship by taking a log on true stress and strain. The relation can be expressed as below:\n\n  \n    \n      \n        \n          \u03c3\n          \n            T\n          \n        \n        =\n        K\n        \u00d7\n        (\n        \n          \u03b5\n          \n            T\n          \n        \n        \n          )\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{T}=K\\times (\\varepsilon _{T})^{n}}\n  Where \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n   is stress coefficient and \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is strain-hardening coefficient. Usually, the value of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   has range around 0.02 to 0.5 at room temperature. If \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is 1, we can express this material as perfect elastic material.2) In reality, stress is also highly dependent on the rate of strain variation. Thus, we can induce the empirical equation based on the strain rate variation.\n\n  \n    \n      \n        \n          \u03c3\n          \n            T\n          \n        \n        =\n        \n          K\n          \u2032\n        \n        \u00d7\n        (\n        \n          \n            \n              \n                \u03b5\n                \n                  T\n                \n              \n              \u02d9\n            \n          \n        \n        \n          )\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{T}=K'\\times ({\\dot {\\varepsilon _{T}}})^{m}}\n  \nWhere \n  \n    \n      \n        \n          K\n          \u2032\n        \n      \n    \n    {\\displaystyle K'}\n   is constant related to the material flow stress. \n  \n    \n      \n        \n          \n            \n              \n                \u03b5\n                \n                  T\n                \n              \n              \u02d9\n            \n          \n        \n      \n    \n    {\\displaystyle {\\dot {\\varepsilon _{T}}}}\n   indicates the derivative of strain by the time, which is also known as strain rate. \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the strain-rate sensitivity. Moreover, value of \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is related to the resistance toward the necking. Usually, the value of \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is at the range of 0-0.1 at room temperature and as high as 0.8 when the temperature is increased.\nBy combining the 1) and 2), we can create the ultimate relation as below:\n\n  \n    \n      \n        \n          \u03c3\n          \n            T\n          \n        \n        =\n        \n          K\n          \u2033\n        \n        \u00d7\n        (\n        \n          \u03b5\n          \n            T\n          \n        \n        \n          )\n          \n            n\n          \n        \n        (\n        \n          \n            \n              \n                \u03b5\n                \n                  T\n                \n              \n              \u02d9\n            \n          \n        \n        \n          )\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{T}=K''\\times (\\varepsilon _{T})^{n}({\\dot {\\varepsilon _{T}}})^{m}}\n  Where \n  \n    \n      \n        \n          K\n          \u2033\n        \n      \n    \n    {\\displaystyle K''}\n   is the global constant for relating strain, strain rate and stress.\n3) Based on the true stress-strain curve and its derivative form, we can estimate the strain necessary to start necking. This can be calculated based on the intersection between true stress-strain curve as shown in right.\nThis figure also shows the dependency of the necking strain at different temperature. In case of FCC metals, both of the stress-strain curve at its derivative are highly dependent on temperature. Therefore, at higher temperature, necking starts to appear even under lower strain value.\nAll of these properties indicate the importance of calculating the true stress-strain curve for further analyzing the behavior of materials in sudden environment.\n4) A graphical method, so-called \"Considere construction\", can help determine the behavior of stress-strain curve whether necking or drawing happens on the sample. By setting \n  \n    \n      \n        \u03bb\n        =\n        L\n        \n          /\n        \n        \n          L\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\lambda =L/L_{0}}\n  as determinant, the true stress and strain can be expressed with engineering stress and strain as below:\n\n  \n    \n      \n        \n          \u03c3\n          \n            T\n          \n        \n        =\n        \n          \u03c3\n          \n            e\n          \n        \n        \u00d7\n        \u03bb\n        ,\n        \n        \n          \u03b5\n          \n            T\n          \n        \n        =\n        ln\n        \u2061\n        \u03bb\n        .\n      \n    \n    {\\displaystyle \\sigma _{T}=\\sigma _{e}\\times \\lambda ,\\qquad \\varepsilon _{T}=\\ln \\lambda .}\n  Therefore, the value of engineering stress can be expressed by the secant line from made by true stress and \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   value where \n  \n    \n      \n        \u03bb\n        =\n        0\n      \n    \n    {\\displaystyle \\lambda =0}\n   to \n  \n    \n      \n        \u03bb\n        =\n        1\n      \n    \n    {\\displaystyle \\lambda =1}\n  . By analyzing the shape of \n  \n    \n      \n        \n          \u03c3\n          \n            T\n          \n        \n        \u2212\n        \u03bb\n      \n    \n    {\\displaystyle \\sigma _{T}-\\lambda }\n   diagram and secant line, we can determine whether the materials show drawing or necking.\n\nOn the figure (a), there is only concave upward Considere plot. It indicates that there is no yield drop so the material will be suffered from fracture before it yields. On the figure (b), there is specific point where the tangent matches with secant line at point where \n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            Y\n          \n        \n      \n    \n    {\\displaystyle \\lambda =\\lambda _{Y}}\n  . After this value, the slope becomes smaller than the secant line where necking starts to appear. On the figure (c), there is point where yielding starts to appear but when \n  \n    \n      \n        \u03bb\n        =\n        \n          \u03bb\n          \n            d\n          \n        \n      \n    \n    {\\displaystyle \\lambda =\\lambda _{d}}\n  , the drawing happens. After drawing, all the material will stretch and eventually show fracture. Between \n  \n    \n      \n        \n          \u03bb\n          \n            Y\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{Y}}\n   and \n  \n    \n      \n        \n          \u03bb\n          \n            d\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{d}}\n  , the material itself does not stretch but rather, only the neck starts to stretch out.\n\n\n=== Plastic deformation ===\n\nThis type of deformation is not undone simply by removing the applied force. An object in the plastic deformation range, however, will first have undergone elastic deformation, which is undone simply be removing the applied force, so the object will return part way to its original shape. Soft thermoplastics have a rather large plastic deformation range as do ductile metals such as copper, silver, and gold. Steel does, too, but not cast iron. Hard thermosetting plastics, rubber, crystals, and ceramics have minimal plastic deformation ranges. An example of a material with a large plastic deformation range is wet chewing gum, which can be stretched to dozens of times its original length.\nUnder tensile stress, plastic deformation is characterized by a strain hardening region and a necking region and finally, fracture (also called rupture). During strain hardening the material becomes stronger through the movement of atomic dislocations. The necking phase is indicated by a reduction in cross-sectional area of the specimen. Necking begins after the ultimate strength is reached. During necking, the material can no longer withstand the maximum stress and the strain in the specimen rapidly increases. Plastic deformation ends with the fracture of the material.\n\n\n==== Compressive failure ====\nUsually, compressive stress applied to bars, columns, etc. leads to shortening.\nLoading a structural element or specimen will increase the compressive stress until it reaches its compressive strength. According to the properties of the material, failure modes are yielding for materials with ductile behavior (most metals, some soils and plastics) or rupturing for brittle behavior (geomaterials, cast iron, glass, etc.).\nIn long, slender structural elements \u2014 such as columns or truss bars \u2014 an increase of compressive force F leads to structural failure due to buckling at lower stress than the compressive strength.\n\n\n=== Fracture ===\n\nThis type of deformation is also irreversible. A break occurs after the material has reached the end of the elastic, and then plastic, deformation ranges. At this point forces accumulate until they are sufficient to cause a fracture. All materials will eventually fracture, if sufficient forces are applied.\n\n\n== Misconceptions ==\nA popular misconception is that all materials that bend are \"weak\" and those that don't are \"strong\". In reality, many materials that undergo large elastic and plastic deformations, such as steel, are able to absorb stresses that would cause brittle materials, such as glass, with minimal plastic deformation ranges, to break.\n\n\n== See also ==\n\n\n== References ==", "Electromagnetic_spectrum": "The electromagnetic spectrum is the range of frequencies (the spectrum) of electromagnetic radiation and their respective wavelengths and photon energies.\nThe electromagnetic spectrum covers electromagnetic waves with frequencies ranging from below one hertz to above 1025 hertz, corresponding to wavelengths from thousands of kilometers down to a fraction of the size of an atomic nucleus.  This frequency range is divided into separate bands, and the electromagnetic waves within each frequency band are called by different names; beginning at the low-frequency (long-wavelength) end of the spectrum these are: radio waves, microwaves, infrared, visible light, ultraviolet, X-rays, and gamma rays at the high-frequency (short wavelength) end.  The electromagnetic waves in each of these bands have different characteristics, such as how they are produced, how they interact with matter, and their practical applications.  There is no known limit for long and short wavelengths. Extreme ultraviolet, soft X-rays, hard X-rays and gamma rays are  classified as ionizing radiation because their photons have enough energy to ionize atoms, causing chemical reactions. Radiation of visible light and longer wavelengths are classified as nonionizing radiation because they have insufficient energy to cause these effects.\nThroughout most of the electromagnetic spectrum, spectroscopy can be used to separate waves of different frequencies, producing a spectrum of the constituent frequencies.  Spectroscopy is used to study the interactions of electromagnetic waves with matter.\n\n\n== History and discovery ==\n\nHumans have always been aware of visible light and radiant heat but for most of history it was not known that these phenomena were connected or were representatives of a more extensive principle. The ancient Greeks recognized that light traveled in straight lines and studied some of its properties, including reflection and refraction. Light was intensively studied from the beginning of the 17th century leading to the invention of important instruments like the telescope and microscope.  Isaac Newton was the first to use the term spectrum for the range of colours that white light could be split into with a prism.  Starting in 1666, Newton showed that these colours were intrinsic to light and could be recombined into white light.  A debate arose over whether light had a wave nature or a particle nature with Ren\u00e9 Descartes, Robert Hooke and Christiaan Huygens favouring a wave description and Newton favouring a particle description.  Huygens in particular had a well developed theory from which he was able to derive the laws of reflection and refraction.  Around 1801, Thomas Young measured the wavelength of a light beam with his two-slit experiment thus conclusively demonstrating that light was a wave.\nIn 1800, William Herschel discovered infrared radiation.  He was studying the temperature of different colours by moving a thermometer through light split by a prism. He noticed that the highest temperature was beyond red. He theorized that this temperature change was due to \"calorific rays\", a type of light ray that could not be seen.  The next year, Johann Ritter, working at the other end of the spectrum, noticed what he called \"chemical rays\" (invisible light rays that induced certain chemical reactions). These behaved similarly to visible violet light rays, but were beyond them in the spectrum.  They were later renamed ultraviolet radiation.\nThe study of electromagnetism began in 1820 when Hans Christian \u00d8rsted discovered that electric currents produce magnetic fields (Oersted's law). Light was first linked to electromagnetism in 1845, when Michael Faraday noticed that the polarization of light traveling through a transparent material responded to a magnetic field (see Faraday effect). During the 1860s, James Clerk Maxwell developed four partial differential equations (Maxwell's equations) for the electromagnetic field. Two of these equations predicted the possibility and behavior of waves in the field. Analyzing the speed of these theoretical waves, Maxwell realized that they must travel at a speed that was about the known speed of light. This startling coincidence in value led Maxwell to make the inference that light itself is a type of electromagnetic wave. Maxwell's equations predicted an infinite range of frequencies of electromagnetic waves, all traveling at the speed of light. This was the first indication of the existence of the entire electromagnetic spectrum.\nMaxwell's predicted waves included waves at very low frequencies compared to infrared, which in theory might be created by oscillating charges in an ordinary electrical circuit of a certain type. Attempting to prove Maxwell's equations and detect such low frequency electromagnetic radiation, in 1886, the physicist Heinrich Hertz built an apparatus to generate and detect what are now called radio waves. Hertz found the waves and was able to infer (by measuring their wavelength and multiplying it by their frequency) that they traveled at the speed of light. Hertz also demonstrated that the new radiation could be both reflected and refracted by various dielectric media, in the same manner as light. For example, Hertz was able to focus the waves using a lens made of tree resin. In a later experiment, Hertz similarly produced and measured the properties of microwaves. These new types of waves paved the way for inventions such as the wireless telegraph and the radio.\nIn 1895, Wilhelm R\u00f6ntgen noticed a new type of radiation emitted during an experiment with an evacuated tube subjected to a high voltage. He called this radiation \"x-rays\" and found that they were able to travel through parts of the human body but were reflected or stopped by denser matter such as bones. Before long, many uses were found for this radiography.\nThe last portion of the electromagnetic spectrum was filled in with the discovery of gamma rays. In 1900, Paul Villard was studying the radioactive emissions of radium when he identified a new type of radiation that he at first thought consisted of particles similar to known alpha and beta particles, but with the power of being far more penetrating than either. However, in 1910, British physicist William Henry Bragg demonstrated that gamma rays are electromagnetic radiation, not particles, and in 1914, Ernest Rutherford (who had named them gamma rays in 1903 when he realized that they were fundamentally different from charged alpha and beta particles) and Edward Andrade measured their wavelengths, and found that gamma rays were similar to X-rays, but with shorter wavelengths.\nThe wave-particle debate was rekindled in 1901 when Max Planck discovered that light is absorbed only in discrete \"quanta\", now called photons, implying that light has a particle nature.  This idea was made explicit by Albert Einstein in 1905, but never accepted by Planck and many other contemporaries.  The modern position of science is that electromagnetic radiation has both a wave and a particle nature, the wave-particle duality. The contradictions arising from this position are still being debated by scientists and philosophers.\n\n\n== Range ==\nElectromagnetic waves are typically described by any of the following three physical properties: the frequency f, wavelength \u03bb, or photon energy E. Frequencies observed in astronomy range from 2.4\u00d71023 Hz (1 GeV gamma rays) down to the local plasma frequency of the ionized interstellar medium (~1 kHz). Wavelength is inversely proportional to the wave frequency, so gamma rays have very short wavelengths that are fractions of the size of atoms, whereas wavelengths on the opposite end of the spectrum can be indefinitely long. Photon energy is directly proportional to the wave frequency, so gamma ray photons have the highest energy (around a billion electron volts), while radio wave photons have very low energy (around a femtoelectronvolt). These relations are illustrated by the following equations:\n\n  \n    \n      \n        f\n        =\n        \n          \n            c\n            \u03bb\n          \n        \n        ,\n        \n        \n          or\n        \n        \n        f\n        =\n        \n          \n            E\n            h\n          \n        \n        ,\n        \n        \n          or\n        \n        \n        E\n        =\n        \n          \n            \n              h\n              c\n            \n            \u03bb\n          \n        \n        ,\n      \n    \n    {\\displaystyle f={\\frac {c}{\\lambda }},\\quad {\\text{or}}\\quad f={\\frac {E}{h}},\\quad {\\text{or}}\\quad E={\\frac {hc}{\\lambda }},}\n  where:\n\nc = 299792458 m/s is the speed of light in vacuum\nh = 6.62607015\u00d710\u221234 J\u00b7s = 4.13566733(10)\u00d710\u221215 eV\u00b7s is the Planck constant.Whenever electromagnetic waves travel in a medium with matter, their wavelength is decreased. Wavelengths of electromagnetic radiation, whatever medium they are traveling through, are usually quoted in terms of the vacuum wavelength, although this is not always explicitly stated.\nGenerally, electromagnetic radiation is classified by wavelength into radio wave, microwave, infrared, visible light, ultraviolet, X-rays and gamma rays. The behavior of EM radiation depends on its wavelength. When EM radiation interacts with single atoms and molecules, its behavior also depends on the amount of energy per quantum (photon) it carries.\nSpectroscopy can detect a much wider region of the EM spectrum than the visible wavelength range of 400 nm to 700 nm in a vacuum. A common laboratory spectroscope can detect wavelengths from 2 nm to 2500 nm. Detailed information about the physical properties of objects, gases, or even stars can be obtained from this type of device. Spectroscopes are widely used in astrophysics. For example, many hydrogen atoms emit a radio wave photon that has a wavelength of 21.12 cm. Also, frequencies of 30 Hz and below can be produced by and are important in the study of certain stellar nebulae and frequencies as high as 2.9\u00d71027 Hz have been detected from astrophysical sources.\n\n\n== Regions ==\n\nThe types of electromagnetic radiation are broadly classified into the following classes (regions, bands or types):\nGamma radiation\nX-ray radiation\nUltraviolet radiation\nVisible light\nInfrared radiation\nMicrowave radiation\nRadio wavesThis classification goes in the increasing order of wavelength, which is characteristic of the type of radiation.There are no precisely defined boundaries between the bands of the electromagnetic spectrum; rather they fade into each other like the bands in a rainbow (which is the sub-spectrum of visible light). Radiation of each frequency and wavelength (or in each band) has a mix of properties of the two regions of the spectrum that bound it. For example, red light resembles infrared radiation in that it can excite and add energy to some chemical bonds and indeed must do so to power the chemical mechanisms responsible for photosynthesis and the working of the visual system.\nThe distinction between X-rays and gamma rays is partly based on sources: the photons generated from nuclear decay or other nuclear and subnuclear/particle process are always termed gamma rays, whereas X-rays are generated by electronic transitions involving highly energetic inner atomic electrons. In general, nuclear transitions are much more energetic than electronic transitions, so gamma rays are more energetic than X-rays, but exceptions exist. By analogy to electronic transitions, muonic atom transitions are also said to produce X-rays, even though their energy may exceed 6 megaelectronvolts (0.96 pJ), whereas there are many (77 known to be less than 10 keV (1.6 fJ)) low-energy nuclear transitions (e.g., the 7.6 eV (1.22 aJ) nuclear transition of thorium-229m), and, despite being one million-fold less energetic than some muonic X-rays, the emitted photons are still called gamma rays due to their nuclear origin.The convention that EM radiation that is known to come from the nucleus is always called \"gamma ray\" radiation is the only convention that is universally respected, however. Many astronomical gamma ray sources (such as gamma ray bursts) are known to be too energetic (in both intensity and wavelength) to be of nuclear origin. Quite often, in high-energy physics and in medical radiotherapy, very high energy EMR (in the > 10 MeV region)\u2014which is of higher energy than any nuclear gamma ray\u2014is not called X-ray or gamma ray, but instead by the generic term of \"high-energy photons\".\nThe region of the spectrum where a particular observed electromagnetic radiation falls is reference frame-dependent (due to the Doppler shift for light), so EM radiation that one observer would say is in one region of the spectrum could appear to an observer moving at a substantial fraction of the speed of light with respect to the first to be in another part of the spectrum. For example, consider the cosmic microwave background. It was produced when matter and radiation decoupled, by the de-excitation of hydrogen atoms to the ground state. These photons were from Lyman series transitions, putting them in the ultraviolet (UV) part of the electromagnetic spectrum. Now this radiation has undergone enough cosmological red shift to put it into the microwave region of the spectrum for observers moving slowly (compared to the speed of light) with respect to the cosmos.\n\n\n=== Rationale for names ===\nElectromagnetic radiation interacts with matter in different ways across the spectrum. These types of interaction are so different that historically different names have been applied to different parts of the spectrum, as though these were different types of radiation. Thus, although these \"different kinds\" of electromagnetic radiation form a quantitatively continuous spectrum of frequencies and wavelengths, the spectrum remains divided for practical reasons arising from these qualitative interaction differences.\n\n\n== Types of radiation ==\n\n\n=== Radio waves ===\n\nRadio waves are emitted and received by antennas, which consist of conductors such as metal rod resonators.  In artificial generation of radio waves, an electronic device called a transmitter generates an AC electric current which is applied to an antenna.  The oscillating electrons in the antenna generate oscillating electric and magnetic fields that radiate away from the antenna as radio waves.  In reception of radio waves, the oscillating electric and magnetic fields of a radio wave couple to the electrons in an antenna, pushing them back and forth, creating oscillating currents which are applied to a radio receiver.  Earth's atmosphere is mainly transparent to radio waves, except for layers of charged particles in the ionosphere which can reflect certain frequencies.\nRadio waves are extremely widely used to transmit information across distances in radio communication systems such as radio broadcasting, television, two way radios,  mobile phones, communication satellites, and wireless networking.  In a radio communication system, a radio frequency current is modulated with an information-bearing signal in a transmitter by varying either the amplitude, frequency or phase, and applied to an antenna.  The radio waves carry the information across space to a receiver, where they are received by an antenna and the information extracted by demodulation in the receiver.     Radio waves are also used for navigation in systems like Global Positioning System (GPS) and navigational beacons, and locating distant objects in radiolocation and radar.  They are also used for remote control, and for industrial heating.\nThe use of the radio spectrum is strictly regulated by governments, coordinated by the International Telecommunication Union (ITU) which allocates frequencies to different users for different uses.\n\n\n=== Microwaves ===\n\nMicrowaves are radio waves of short wavelength, from about 10 centimeters to one millimeter, in the SHF and EHF frequency bands.   Microwave energy is produced with klystron and magnetron tubes, and with solid state devices such as Gunn and IMPATT diodes.  Although they are emitted and absorbed by short antennas, they are also absorbed by polar molecules, coupling to vibrational and rotational modes, resulting in bulk heating.  Unlike higher frequency waves such as infrared and visible light which are absorbed mainly at surfaces, microwaves can penetrate into materials and deposit their energy below the surface.   This effect is used to heat food in microwave ovens, and for industrial heating and medical diathermy.    Microwaves are the main wavelengths used in radar, and are used for satellite communication, and wireless networking technologies such as Wi-Fi. The copper cables (transmission lines) which are used to carry lower-frequency radio waves to antennas have excessive power losses at microwave frequencies, and metal pipes called waveguides are used to carry them.  Although at the low end of the band the atmosphere is mainly transparent, at the upper end of the band absorption of microwaves by atmospheric gases limits practical propagation distances to a few kilometers.\nTerahertz radiation or sub-millimeter radiation is a region of the spectrum from about 100 GHz to 30 terahertz (THz) between microwaves and far infrared which can be regarded as belonging to either band. Until recently, the range was rarely studied and few sources existed for microwave energy in the so-called terahertz gap, but applications such as imaging and communications are now appearing. Scientists are also looking to apply terahertz technology in the armed forces, where high-frequency waves might be directed at enemy troops to incapacitate their electronic equipment.  Terahertz radiation is strongly absorbed by atmospheric gases, making this frequency range useless for long-distance communication.\n\n\n=== Infrared radiation ===\n\nThe infrared part of the electromagnetic spectrum covers the range from roughly 300 GHz to 400 THz (1 mm \u2013 750 nm). It can be divided into three parts:\nFar-infrared, from 300 GHz to 30 THz (1 mm \u2013 10 \u03bcm). The lower part of this range may also be called microwaves or terahertz waves. This radiation is typically absorbed by so-called rotational modes in gas-phase molecules, by molecular motions in liquids, and by phonons in solids. The water in Earth's atmosphere absorbs so strongly in this range that it renders the atmosphere in effect opaque. However, there are certain wavelength ranges (\"windows\") within the opaque range that allow partial transmission, and can be used for astronomy. The wavelength range from approximately 200 \u03bcm up to a few mm is often referred to as Submillimetre astronomy, reserving far infrared for wavelengths below 200 \u03bcm.\nMid-infrared, from 30 to 120 THz (10\u20132.5 \u03bcm). Hot objects (black-body radiators) can radiate strongly in this range, and human skin at normal body temperature radiates strongly at the lower end of this region. This radiation is absorbed by molecular vibrations, where the different atoms in a molecule vibrate around their equilibrium positions. This range is sometimes called the fingerprint region, since the mid-infrared absorption spectrum of a compound is very specific for that compound.\nNear-infrared, from 120 to 400 THz (2,500\u2013750 nm). Physical processes that are relevant for this range are similar to those for visible light. The highest frequencies in this region can be detected directly by some types of photographic film, and by many types of solid state image sensors for infrared photography and videography.\n\n\n=== Visible light ===\n\nAbove infrared in frequency comes visible light. The Sun emits its peak power in the visible region, although integrating the entire emission power spectrum through all wavelengths shows that the Sun emits slightly more infrared than visible light. By definition, visible light is the part of the EM spectrum the human eye is the most sensitive to. Visible light (and near-infrared light) is typically absorbed and emitted by electrons in molecules and atoms that move from one energy level to another. This action allows the chemical mechanisms that underlie human vision and plant photosynthesis. The light that excites the human visual system is a very small portion of the electromagnetic spectrum. A rainbow shows the optical (visible) part of the electromagnetic spectrum; infrared (if it could be seen) would be located just beyond the red side of the rainbow whilst ultraviolet would appear just beyond the opposite violet end.\nElectromagnetic radiation with a wavelength between 380 nm and 760 nm (400\u2013790 terahertz) is detected by the human eye and perceived as visible light. Other wavelengths, especially near infrared (longer than 760 nm) and ultraviolet (shorter than 380 nm) are also sometimes referred to as light, especially when the visibility to humans is not relevant. White light is a combination of lights of different wavelengths in the visible spectrum. Passing white light through a prism splits it up into the several colours of light observed in the visible spectrum between 400 nm and 780 nm.\nIf radiation having a frequency in the visible region of the EM spectrum reflects off an object, say, a bowl of fruit, and then strikes the eyes, this results in visual perception of the scene. The brain's visual system processes the multitude of reflected frequencies into different shades and hues, and through this insufficiently-understood psychophysical phenomenon, most people perceive a bowl of fruit.\nAt most wavelengths, however, the information carried by electromagnetic radiation is not directly detected by human senses. Natural sources produce EM radiation across the spectrum, and technology can also manipulate a broad range of wavelengths. Optical fiber transmits light that, although not necessarily in the visible part of the spectrum (it is usually infrared), can carry information. The modulation is similar to that used with radio waves.\n\n\n=== Ultraviolet radiation ===\n\nNext in frequency comes ultraviolet (UV). The wavelength of UV rays is shorter than the violet end of the visible spectrum but longer than the X-ray.\nUV is the longest wavelength radiation whose photons are energetic enough to ionize atoms, separating electrons from them, and thus causing chemical reactions.  Short wavelength UV and the shorter wavelength radiation above it (X-rays and gamma rays) are called ionizing radiation, and exposure to them can damage living tissue, making them a health hazard.  UV can also cause many substances to glow with visible light; this is called fluorescence.\nAt the middle range of UV, UV rays cannot ionize but can break chemical bonds, making molecules unusually reactive. Sunburn, for example, is caused by the disruptive effects of middle range UV radiation on skin cells, which is the main cause of skin cancer. UV rays in the middle range can irreparably damage the complex DNA molecules in the cells producing thymine dimers making it a very potent mutagen.\nThe Sun emits UV radiation (about 10% of its total power), including extremely short wavelength UV that could potentially destroy most life on land (ocean water would provide some protection for life there). However, most of the Sun's damaging UV wavelengths are absorbed by the atmosphere before they reach the surface. The higher energy (shortest wavelength) ranges of UV (called \"vacuum UV\") are absorbed by nitrogen and, at longer wavelengths, by simple diatomic oxygen in the air. Most of the UV in the mid-range of energy is blocked by the ozone layer, which absorbs strongly in the important 200\u2013315 nm range, the lower energy part of which is too long for ordinary dioxygen in air to absorb. This leaves less than 3% of sunlight at sea level in UV, with all of this remainder at the lower energies. The remainder is UV-A, along with some UV-B. The very lowest energy range of UV between 315 nm and visible light (called UV-A) is not blocked well by the atmosphere, but does not cause sunburn and does less biological damage. However, it is not harmless and does create oxygen radicals, mutations and skin damage.\n\n\n=== X-rays ===\n\nAfter UV come X-rays, which, like the upper ranges of UV are also ionizing. However, due to their higher energies, X-rays can also interact with matter by means of the Compton effect. Hard X-rays have shorter wavelengths than soft X-rays and as they can pass through many substances with little absorption, they can be used to 'see through' objects with 'thicknesses' less than that equivalent to a few meters of water. One notable use is diagnostic X-ray imaging in medicine (a process known as radiography). X-rays are useful as probes in high-energy physics. In astronomy, the accretion disks around neutron stars and black holes emit X-rays, enabling studies of these phenomena. X-rays are also emitted by stellar corona and are strongly emitted by some types of nebulae. However, X-ray telescopes must be placed outside the Earth's atmosphere to see astronomical X-rays, since the great depth of the atmosphere of Earth is opaque to X-rays (with areal density of 1000 g/cm2), equivalent to 10 meters thickness of water. This is an amount sufficient to block almost all astronomical X-rays (and also astronomical gamma rays\u2014see below).\n\n\n=== Gamma rays ===\n\nAfter hard X-rays come gamma rays, which were discovered by Paul Ulrich Villard in 1900. These are the most energetic photons, having no defined lower limit to their wavelength. In astronomy they are valuable for studying high-energy objects or regions, however as with X-rays this can only be done with telescopes outside the Earth's atmosphere. Gamma rays are used experimentally by physicists for their penetrating ability and are produced by a number of  radioisotopes. They are used for irradiation of foods and seeds for sterilization, and in medicine they are occasionally used in radiation cancer therapy. More commonly, gamma rays are used for diagnostic imaging in nuclear medicine, an example being PET scans. The wavelength of gamma rays can be measured with high accuracy through the effects of Compton scattering.\n\n\n== See also ==\n\n\n== Notes and references ==\n\n\n== External links ==\n\nAustralian Radiofrequency Spectrum Allocations Chart (from Australian Communications and Media Authority)\nCanadian Table of Frequency Allocations Archived 2008-12-09 at the Wayback Machine (from Industry Canada)\nU.S. Frequency Allocation Chart \u2013 Covering the range 3 kHz to 300 GHz (from Department of Commerce)\nUK frequency allocation table (from Ofcom, which inherited the Radiocommunications Agency's duties, pdf format)\nFlash EM Spectrum Presentation / Tool \u2013 Very complete and customizable.\nPoster \"Electromagnetic Radiation Spectrum\" (992 kB)", "Emission_spectrum": "The emission spectrum of a chemical element or chemical compound is the spectrum of frequencies of electromagnetic radiation emitted due to an electron making a transition from a high energy state to a lower energy state. The photon energy of the emitted photon is equal to the energy difference between the two states. There are many possible electron transitions for each atom, and each transition has a specific energy difference. This collection of different transitions, leading to different radiated wavelengths, make up an emission spectrum. Each element's emission spectrum is unique. Therefore, spectroscopy can be used to identify elements in matter of unknown composition. Similarly, the emission spectra of molecules can be used in chemical analysis of substances.\n\n\n== Emission ==\nIn physics, emission is the process by which a higher energy quantum mechanical state of a particle becomes converted to a lower one through the emission of a photon, resulting in the production of light. The frequency of light emitted is a function of the energy of the transition. \nSince energy must be conserved, the energy difference between the two states equals the energy carried off by the photon. The energy states of the transitions can lead to emissions over a very large range of frequencies. For example, visible light is emitted by the coupling of electronic states in atoms and molecules (then the phenomenon is called fluorescence or phosphorescence). On the other hand, nuclear shell transitions can emit high energy gamma rays, while nuclear spin transitions emit low energy radio waves.\nThe emittance of an object quantifies how much light is emitted by it. This may be related to other properties of the object through the Stefan\u2013Boltzmann law.\nFor most substances, the amount of emission varies with the temperature and the spectroscopic composition of the object, leading to the appearance of color temperature and emission lines. Precise measurements at many wavelengths allow the identification of a substance via emission spectroscopy.\nEmission of radiation is typically described using semi-classical quantum mechanics: the particle's energy levels and spacings are determined from quantum mechanics, and light is treated as an oscillating electric field that can drive a transition if it is in resonance with the system's natural frequency. The quantum mechanics problem is treated using time-dependent perturbation theory and leads to the general result known as Fermi's golden rule. The description has been superseded by quantum electrodynamics, although the semi-classical version continues to be more useful in most practical computations.\n\n\n== Origins ==\nWhen the electrons in the atom are excited, for example by being heated, the additional energy pushes the electrons to higher energy orbitals. When the electrons fall back down and leave the excited state, energy is re-emitted in the form of a photon. The wavelength (or equivalently, frequency) of the photon is determined by the difference in energy between the two states. These emitted photons form the element's spectrum.\nThe fact that only certain colors appear in an element's atomic emission spectrum means that only certain frequencies of light are emitted. Each of these frequencies are related to energy by the formula:\n\nwhere \n  \n    \n      \n        \n          E\n          \n            photon\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{photon}}}\n   is the energy of the photon, \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   is its frequency, and \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n   is Planck's constant.\nThis concludes that only photons with specific energies are emitted by the atom. The principle of the atomic emission spectrum explains the varied colors in neon signs, as well as chemical flame test results (described below).\nThe frequencies of light that an atom can emit are dependent on states the electrons can be in. When excited, an electron moves to a higher energy level or orbital. When the electron falls back to its ground level the light is emitted.\n\nThe above picture shows the visible light emission spectrum for hydrogen. If only a single atom of hydrogen were present, then only a single wavelength would be observed at a given instant. Several of the possible emissions are observed because the sample contains many hydrogen atoms that are in different initial energy states and reach different final energy states. These different combinations lead to simultaneous emissions at different wavelengths.\n\n\n=== Radiation from molecules ===\nAs well as the electronic transitions discussed above, the energy of a molecule can also change via rotational, vibrational, and vibronic (combined vibrational and electronic) transitions. These energy transitions often lead to closely spaced groups of many different spectral lines, known as spectral bands. Unresolved band spectra may appear as a spectral continuum.\n\n\n== Emission spectroscopy ==\nLight consists of electromagnetic radiation of different wavelengths. Therefore, when the elements or their compounds are heated either on a flame or by an electric arc they emit energy in the form of light. Analysis of this light, with the help of a spectroscope gives us a discontinuous spectrum. A spectroscope or a spectrometer is an instrument which is used for separating the components of light, which have different wavelengths. The spectrum appears in a series of lines called the line spectrum. This line spectrum is called an atomic spectrum when it originates from an atom in elemental form. Each element has a different atomic spectrum. The production of line spectra by the atoms of an element indicate that an atom can radiate only a certain amount of energy. This leads to the conclusion that bound electrons cannot have just any amount of energy but only a certain amount of energy.\nThe emission spectrum can be used to determine the composition of a material, since it is different for each element of the periodic table. One example is astronomical spectroscopy: identifying the composition of stars by analysing the received light.\nThe emission spectrum characteristics of some elements are plainly visible to the naked eye when these elements are heated. For example, when platinum wire is dipped into a sodium nitrate solution and then inserted into a flame, the sodium atoms emit an amber yellow color. Similarly, when indium is inserted into a flame, the flame becomes blue. These definite characteristics allow elements to be identified by their atomic emission spectrum. Not all emitted lights are perceptible to the naked eye, as the spectrum also includes ultraviolet rays and infrared radiation.\nAn emission spectrum is formed when an excited gas is viewed directly through a spectroscope.\n\nEmission spectroscopy is a spectroscopic technique which examines the wavelengths of photons emitted by atoms or molecules during their transition from an excited state to a lower energy state. Each element emits a characteristic set of discrete wavelengths according to its electronic structure, and by observing these wavelengths the elemental composition of the sample can be determined. Emission spectroscopy developed in the late 19th century and efforts in theoretical explanation of atomic emission spectra eventually led to quantum mechanics.\nThere are many ways in which atoms can be brought to an excited state. Interaction with electromagnetic radiation is used in fluorescence spectroscopy, protons or other heavier particles in Particle-Induced X-ray Emission and electrons or X-ray photons in Energy-dispersive X-ray spectroscopy or X-ray fluorescence. The simplest method is to heat the sample to a high temperature, after which the excitations are produced by collisions between the sample atoms. This method is used in flame emission spectroscopy, and it was also the method used by Anders Jonas \u00c5ngstr\u00f6m when he discovered the phenomenon of discrete emission lines in the 1850s.Although the emission lines are caused by a transition between quantized energy states and may at first look very sharp, they do have a finite width, i.e. they are composed of more than one wavelength of light. This spectral line broadening has many different causes.\n\nEmission spectroscopy is often referred to as optical emission spectroscopy because of the light nature of what is being emitted. \n\n\n== History ==\n\nIn 1756 Thomas Melvill  observed the emission of distinct patterns of colour when salts were added to alcohol flames.  By 1785 James Gregory discovered the principles of diffraction grating and  American astronomer David Rittenhouse made the first engineered diffraction grating. In 1821 Joseph von Fraunhofer solidified this significant experimental leap of replacing a prism as the source of wavelength dispersion improving the spectral resolution and allowing for the dispersed wavelengths to be quantified.In 1835, Charles Wheatstone reported that different metals could be distinguished by bright lines in the emission spectra of their sparks, thereby introducing an alternative to flame spectroscopy.\nIn 1849, J. B. L. Foucault experimentally demonstrated that absorption and emission lines at the same wavelength are both due to the same material, with the difference between the two originating from the temperature of the light source.\nIn 1853, the Swedish physicist Anders Jonas \u00c5ngstr\u00f6m presented observations and theories about gas spectra. \u00c5ngstr\u00f6m postulated that an incandescent gas emits luminous rays of the same wavelength as those it can absorb. At the same time George Stokes and William Thomson (Kelvin) were discussing similar postulates. \u00c5ngstr\u00f6m also measured the emission spectrum from hydrogen later labeled the Balmer lines.\nIn 1854 and 1855, David Alter published observations on the spectra of metals and gases, including an independent observation of the Balmer lines of hydrogen.By 1859, Gustav Kirchhoff and Robert Bunsen noticed that several Fraunhofer lines (lines in the solar spectrum) coincide with characteristic emission lines identified in the spectra of heated elements. It was correctly deduced that dark lines in the solar spectrum are caused by absorption by chemical elements in the solar atmosphere.\n\n\n== Experimental technique in flame emission spectroscopy ==\nThe solution containing the relevant substance to be analysed is drawn into the burner and dispersed into the flame as a fine spray. The solvent evaporates first, leaving finely divided solid particles which move to the hottest region of the flame where gaseous atoms and ions are produced through the dissociation of molecules. Here electrons are excited as described above, and the spontaneously emit photon to decay to lower energy states. It is common for a monochromator to be used to allow for easy detection.\nOn a simple level, flame emission spectroscopy can be observed using just a flame and samples of metal salts. This method of qualitative analysis is called a flame test. For example, sodium salts placed in the flame will glow yellow from sodium ions, while strontium (used in road flares) ions color it red. Copper wire will create a blue colored flame, however in the presence of chloride gives green (molecular contribution by CuCl). \n\n\n== Emission coefficient ==\nEmission coefficient is a coefficient in the power output per unit time of an electromagnetic source, a calculated value in physics. The emission coefficient of a gas varies with the wavelength of the light. It has units of ms\u22123sr\u22121. It is also used as a measure of environmental emissions (by mass) per MWh of electricity generated, see: Emission factor.\n\n\n=== Scattering of light ===\nIn Thomson scattering a charged particle emits radiation under incident light. The particle may be an ordinary atomic electron, so emission coefficients have practical applications.\nIf X dV d\u03a9 d\u03bb is the energy scattered by a volume element dV into solid angle d\u03a9 between wavelengths \u03bb and \u03bb + d\u03bb per unit time then the Emission coefficient is X.\nThe values of X in Thomson scattering can be predicted from incident flux, the density of the charged particles and their Thomson differential cross section (area/solid angle).\n\n\n=== Spontaneous emission ===\nA warm body emitting photons has a monochromatic emission coefficient relating to its temperature and total power radiation. This is sometimes called the second Einstein coefficient, and can be deduced from quantum mechanical theory.\n\n\n== See also ==\nAbsorption spectroscopy\nAbsorption spectrum\nAtomic spectral line\nElectromagnetic spectroscopy\nGas-discharge lamp, Table of emission spectra of gas discharge lamps\nIsomeric shift\nIsotopic shift\nLuminous coefficient\nPlasma physics\nRydberg formula\nSpectral theory\nThe Diode equation includes the emission coefficient (which is not related to the one discussed here)\nThermionic emission\n\n\n== References ==\n\n\n== External links ==\nEmission spectra of atmospheric gases\nNIST Physical Reference Data\u2014Atomic Spectroscopy Databases\nColor Simulation of Element Emission Spectrum Based on NIST data\nHydrogen emission spectrum", "Specular_reflection": "Specular reflection, or regular reflection, is the mirror-like reflection of waves, such as light, from a surface.The law of reflection states that a reflected ray of light emerges from the reflecting surface at the same angle to the surface normal as the incident ray, but on the opposing side of the surface normal in the plane formed by the incident and reflected rays. This behavior was first described by Hero of Alexandria (AD c. 10\u201370). Later, Alhazen gave a complete statement of the law of reflection. He was first to state that the incident ray, the reflected ray, and the normal to the surface all lie in a same plane perpendicular to reflecting plane.Specular reflection may be contrasted with diffuse reflection, in which light is scattered away from the surface in a range of directions.\n\n\n== Law of reflection ==\n\nWhen light encounters a boundary of a material, it is affected by the optical and electronic response functions of the material to electromagnetic waves. Optical processes, which comprise reflection and refraction, are expressed by the difference of the refractive index on both sides of the boundary, whereas reflectance and absorption are the real and imaginary parts of the response due to the electronic structure of the material.\nThe degree of participation of each of these processes in the transmission is a function of the frequency, or wavelength, of the light, its polarization, and its angle of incidence. In general, reflection increases with increasing angle of incidence, and with increasing absorptivity at the boundary. The Fresnel equations describe the physics at the optical boundary.\nReflection may occur as specular, or mirror-like, reflection and diffuse reflection. Specular reflection reflects all light which arrives from a given direction at the same angle, whereas diffuse reflection reflects light in a broad range of directions. The distinction may be illustrated with surfaces coated with glossy paint and matte paint. Matte paints exhibit essentially complete diffuse reflection, while glossy paints show a larger component of specular behavior. A surface built from a non-absorbing powder, such as plaster, can be a nearly perfect diffuser, whereas polished metallic objects can specularly reflect light very efficiently. The reflecting material of mirrors is usually aluminum or silver.\nLight propagates in space as a wave front of electromagnetic fields. A ray of light is characterized by the direction normal to the wave front (wave normal). When a ray encounters a surface, the angle that the wave normal makes with respect to the surface normal is called the angle of incidence and the plane defined by both directions is the plane of incidence. Reflection of the incident ray also occurs in the plane of incidence.\nThe law of reflection states that the angle of reflection of a ray equals the angle of incidence, and that the incident direction, the surface normal, and the reflected direction are coplanar.\nWhen the light impinges perpendicularly to the surface, it is reflected straight back in the source direction.\nThe phenomenon of reflection arises from the diffraction of a plane wave on a flat boundary. When the boundary size is much larger than the wavelength, then the electromagnetic fields at the boundary are oscillating exactly in phase only for the specular direction.\n\n\n=== Vector formulation ===\n\nThe law of reflection can also be equivalently expressed using linear algebra. The direction of a reflected ray is determined by the vector of incidence and the surface normal vector. Given an incident direction \n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {i} }}\n   from the light source to the surface and the surface normal direction \n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              n\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {n} },}\n   the specularly reflected direction \n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              s\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {s} }}\n   (all unit vectors) is:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              s\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              i\n            \n          \n        \n        \u2212\n        2\n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              n\n            \n          \n        \n        \n          (\n          \n            \n              \n                \n                  \n                    d\n                    ^\n                  \n                \n              \n              \n                \n                  n\n                \n              \n            \n            \u22c5\n            \n              \n                \n                  \n                    d\n                    ^\n                  \n                \n              \n              \n                \n                  i\n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {s} }=\\mathbf {\\hat {d}} _{\\mathrm {i} }-2\\mathbf {\\hat {d}} _{\\mathrm {n} }\\left(\\mathbf {\\hat {d}} _{\\mathrm {n} }\\cdot \\mathbf {\\hat {d}} _{\\mathrm {i} }\\right),}\n  where \n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              n\n            \n          \n        \n        \u22c5\n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {n} }\\cdot \\mathbf {\\hat {d}} _{\\mathrm {i} }}\n   is a scalar obtained with the dot product. Different authors may define the incident and reflection directions with different signs.\nAssuming these Euclidean vectors are represented in column form, the equation can be equivalently expressed as a matrix-vector multiplication:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              s\n            \n          \n        \n        =\n        \n          R\n        \n        \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              i\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {s} }=\\mathbf {R} \\;\\mathbf {\\hat {d}} _{\\mathrm {i} },}\n  where \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbf {R} }\n   is the so-called Householder transformation matrix, defined as:\n\n  \n    \n      \n        \n          R\n        \n        =\n        \n          I\n        \n        \u2212\n        2\n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              n\n            \n          \n        \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              n\n            \n          \n          \n            \n              T\n            \n          \n        \n        ;\n      \n    \n    {\\displaystyle \\mathbf {R} =\\mathbf {I} -2\\mathbf {\\hat {d}} _{\\mathrm {n} }\\mathbf {\\hat {d}} _{\\mathrm {n} }^{\\mathrm {T} };}\n  in terms of the identity matrix \n  \n    \n      \n        \n          I\n        \n      \n    \n    {\\displaystyle \\mathbf {I} }\n   and twice the outer product of \n  \n    \n      \n        \n          \n            \n              \n                d\n                ^\n              \n            \n          \n          \n            \n              n\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {d}} _{\\mathrm {n} }}\n  .\n\n\n== Reflectivity ==\nReflectivity is the ratio of the power of the reflected wave to that of the incident wave. It is a function of the wavelength of radiation, and is related to the refractive index of the material as expressed by Fresnel's equations. In regions of the electromagnetic spectrum in which absorption by the material is significant, it is related to the electronic absorption spectrum through the imaginary component of the complex refractive index. The electronic absorption spectrum of an opaque material, which is difficult or impossible to measure directly, may therefore be indirectly determined from the reflection spectrum by a Kramers-Kronig transform. The polarization of the reflected light depends on the symmetry of the arrangement of the incident probing light with respect to the absorbing transitions dipole moments in the material.\nMeasurement of specular reflection is performed with normal or varying incidence reflection spectrophotometers (reflectometer) using a scanning variable-wavelength light source. Lower quality measurements using a glossmeter quantify the glossy appearance of a surface in gloss units.\n\n\n== Consequences ==\n\n\n=== Internal reflection ===\nWhen light is propagating in a material and strikes an interface with a material of lower index of refraction, some of the light is reflected. If the angle of incidence is greater than the critical angle, total internal reflection occurs: all of the light is reflected. The critical angle can be shown to be given by\n\n  \n    \n      \n        \n          \u03b8\n          \n            crit\n          \n        \n        =\n        arcsin\n        \n        \n          (\n          \n            \n              \n                n\n                \n                  2\n                \n              \n              \n                n\n                \n                  1\n                \n              \n            \n          \n          )\n        \n        \n        .\n      \n    \n    {\\displaystyle \\theta _{\\text{crit}}=\\arcsin \\!\\left({\\frac {n_{2}}{n_{1}}}\\right)\\!.}\n  \n\n\n=== Polarization ===\nWhen light strikes an interface between two materials, the reflected light is generally partially polarized. However, if the light strikes the interface at Brewster's angle, the reflected light is completely linearly polarized parallel to the interface. Brewster's angle is given by\n\n  \n    \n      \n        \n          \u03b8\n          \n            \n              B\n            \n          \n        \n        =\n        arctan\n        \n        \n          (\n          \n            \n              \n                n\n                \n                  2\n                \n              \n              \n                n\n                \n                  1\n                \n              \n            \n          \n          )\n        \n        \n        .\n      \n    \n    {\\displaystyle \\theta _{\\mathrm {B} }=\\arctan \\!\\left({\\frac {n_{2}}{n_{1}}}\\right)\\!.}\n  \n\n\n=== Reflected images ===\n\nThe image in a flat mirror has these features:\n\nIt is the same distance behind the mirror as the object is in front.\nIt is the same size as the object.\nIt is the right way up (erect).\nIt is reversed.\nIt is virtual, meaning that the image appears to be behind the mirror, and cannot be projected onto a screen.The reversal of images by a plane mirror is perceived differently depending on the circumstances. In many cases, the image in a mirror appears to be reversed from left to right. If a flat mirror is mounted on the ceiling it can appear to reverse up and down if a person stands under it and looks up at it. Similarly a car turning left will still appear to be turning left in the rear view mirror for the driver of a car in front of it. The reversal of directions, or lack thereof, depends on how the directions are defined. More specifically a mirror changes the handedness of the coordinate system, one axis of the coordinate system appears to be reversed, and the chirality of the image may change. For example, the image of a right shoe will look like a left shoe.\n\n\n== Examples ==\n\nA classic example of specular reflection is a mirror, which is specifically designed for specular reflection.\nIn addition to visible light, specular reflection can be observed in the ionospheric reflection of radiowaves and the reflection of radio- or microwave radar signals by flying objects. The measurement technique of x-ray reflectivity exploits specular reflectivity to study thin films and interfaces with sub-nanometer resolution, using either modern laboratory sources or synchrotron x-rays.\nNon-electromagnetic waves can also exhibit specular reflection, as in acoustic mirrors which reflect sound, and atomic mirrors, which reflect neutral atoms. For the efficient reflection of atoms from a solid-state mirror, very cold atoms and/or grazing incidence are used in order to provide significant quantum reflection; ridged mirrors are used to enhance the specular reflection of atoms. Neutron reflectometry uses specular reflection to study material surfaces and thin film interfaces in an analogous fashion to x-ray reflectivity.\n\n\n== See also ==\nGeometric optics\nHamiltonian optics\nReflection coefficient\nReflection (mathematics)\nSpecular highlight\nSpecularity\n\n\n== Notes ==\n\n\n== References ==\nHecht, Eugene (1987). Optics (2nd ed.). Addison Wesley. ISBN 0-201-11609-X.", "Le_Sage's_theory_of_gravitation": "Le Sage's theory of gravitation is a kinetic theory of gravity originally proposed by Nicolas Fatio de Duillier in 1690 and later by Georges-Louis Le Sage in 1748.  The theory proposed a mechanical explanation for Newton's gravitational force in terms of streams of tiny unseen particles (which Le Sage called ultra-mundane corpuscles) impacting all material objects from all directions. According to this model, any two material bodies partially shield each other from the impinging corpuscles, resulting in a net imbalance in the pressure exerted by the impact of corpuscles on the bodies, tending to drive the bodies together. This mechanical explanation for gravity never gained widespread acceptance.\n\n\n== Basic theory ==\nThe theory posits that the force of gravity is the result of tiny particles (corpuscles) moving at high speed in all directions, throughout the universe. The intensity of the flux of particles is assumed to be the same in all directions, so an isolated object A is struck equally from all sides, resulting in only an inward-directed pressure but no net directional force (P1).\n\nWith a second object B present, however, a fraction of the particles that would otherwise have struck A from the direction of B is intercepted, so B works as a shield, i.e. from the direction of B, A will be struck by fewer particles than from the opposite direction. Likewise B will be struck by fewer particles from the direction of A than from the opposite direction. One can say that A and B are \"shadowing\" each other, and the two bodies are pushed toward each other by the resulting imbalance of forces (P2). Thus the apparent attraction between bodies is, according to this theory, actually a diminished push from the direction of other bodies, so the theory is sometimes called push gravity or shadow gravity, although it is more widely referred to as Lesage gravity.\n\nNature of collisions\n\nIf the collisions of body A and the gravific particles are fully elastic, the intensity of the reflected particles would be as strong as of the incoming ones, so no net directional force would arise. The same is true if a second body B is introduced, where B acts as a shield against gravific particles in the direction of A. The gravific particle C which ordinarily would strike on A is blocked by B, but another particle D which ordinarily would not have struck A, is re-directed by the reflection on B, and therefore replaces C. Thus if the collisions are fully elastic, the reflected particles between A and B would fully compensate any shadowing effect. In order to account for a net gravitational force, it must be assumed that the collisions are not fully elastic, or at least that the reflected particles are slowed, so that their momentum is reduced after the impact. This would result in streams with diminished momentum departing from A, and streams with undiminished momentum arriving at A, so a net directional momentum toward the center of A would arise (P3). Under this assumption, the reflected particles in the two-body case will not fully compensate the shadowing effect, because the reflected flux is weaker than the incident flux.\n\nInverse square law\n\nSince it is assumed that some or all of the gravific particles converging on an object are either absorbed or slowed by the object, it follows that the intensity of the flux of gravific particles emanating from the direction of a massive object is less than the flux converging on the object. We can imagine this imbalance of momentum flow \u2013 and therefore of the force exerted on any other body in the vicinity \u2013 distributed over a spherical surface centered on the object (P4). The imbalance of momentum flow over an entire spherical surface enclosing the object is independent of the size of the enclosing sphere, whereas the surface area of the sphere increases in proportion to the square of the radius. Therefore, the momentum imbalance per unit area decreases inversely as the square of the distance.\n\nMass proportionality\nFrom the premises outlined so far, there arises only a force which is proportional to the surface of the bodies. But gravity is proportional to the masses. To satisfy the need for mass proportionality, the theory posits that a) the basic elements of matter are very small so that gross matter consists mostly of empty space, and b) that the particles are so small, that only a small fraction of them would be intercepted by gross matter. The result is, that the \"shadow\" of each body is proportional to the surface of every single element of matter. If it is then assumed that the elementary opaque elements of all matter are identical (i.e., having the same ratio of density to area), it will follow that the shadow effect is, at least approximately, proportional to the mass (P5).\n\n\n== Fatio ==\n\nNicolas Fatio presented the first formulation of his thoughts on gravitation in a letter to Christiaan Huygens in the spring of 1690. Two days later Fatio read the content of the letter before the Royal Society in London. In the following years Fatio composed several draft manuscripts of his major work De la Cause de la Pesanteur, but none of this material was published in his lifetime. In 1731 Fatio also sent his theory as a Latin poem, in the style of Lucretius, to the Paris Academy of Science, but it was dismissed. Some fragments of these manuscripts and copies of the poem were later acquired by Le Sage who failed to find a publisher for Fatio's papers. So it lasted until 1929, when the only complete copy of Fatio's manuscript was published by Karl Bopp, and in 1949 Gagnebin used the collected fragments in possession of Le Sage to reconstruct the paper. The Gagnebin edition includes revisions made by Fatio as late as 1743, forty years after he composed the draft on which the Bopp edition was based. However, the second half of the Bopp edition contains the mathematically most advanced parts of Fatio's theory, and were not included by Gagnebin in his edition. For a detailed analysis of Fatio's work, and a comparison between the Bopp and the Gagnebin editions, see Zehe The following description is mainly based on the Bopp edition.\n\n\n=== Features of Fatio's theory ===\nFatio's pyramid (Problem I)\n\nFatio assumed that the universe is filled with minute particles, which are moving indiscriminately with very high speed and rectilinearly in all directions. To illustrate his thoughts he used the following example: Suppose an object C, on which an infinite small plane zz and a sphere centered about zz is drawn. Into this sphere Fatio placed the pyramid PzzQ, in which some particles are streaming in the direction of zz and also some particles, which were already reflected by C and therefore depart from zz. Fatio proposed that the mean velocity of the reflected particles is lower and therefore their momentum is weaker than that of the incident particles. The result is one stream, which pushes all bodies in the direction of zz. So on one hand the speed of the stream remains constant, but on the other hand at larger proximity to zz the density of the stream increases and therefore its intensity is proportional to 1/r2. And because one can draw an infinite number of such pyramids around C, the proportionality applies to the entire range around C.\n\nReduced speed\nIn order to justify the assumption, that the particles are traveling after their reflection with diminished velocities, Fatio stated the following assumptions:\n\nEither ordinary matter, or the gravific particles, or both are inelastic, or\nthe impacts are fully elastic, but the particles are not absolutely hard, and therefore are in a state of vibration after the impact, and/or\ndue to friction the particles begin to rotate after their impacts.These passages are the most incomprehensible parts of Fatio's theory, because he never clearly decided which sort of collision he actually preferred. However, in the last version of his theory in 1742 he shortened the related passages and ascribed \"perfect elasticity or spring force\" to the particles and on the other hand \"imperfect elasticity\" to gross matter, therefore the particles would be reflected with diminished velocities. Additionally, Fatio faced another problem: What is happening if the particles collide with each other? Inelastic collisions would lead to a steady decrease of the particle speed and therefore a decrease of the gravitational force. To avoid this problem, Fatio supposed that the diameter of the particles is very small compared to their mutual distance, so their interactions are very rare.\n\nCondensation\nFatio thought for a long time that, since corpuscles approach material bodies at a higher speed than they recede from them (after reflection), there would be a progressive accumulation of corpuscles near material bodies (an effect which he called \"condensation\"). However, he later realized that although the incoming corpuscles are quicker, they are spaced further apart than are the reflected corpuscles, so the inward and outward flow rates are the same. Hence there is no secular accumulation of corpuscles, i.e., the density of the reflected corpuscles remains constant (assuming that they are small enough that no noticeably greater rate of self-collision occurs near the massive body). More importantly, Fatio noted that, by increasing both the velocity and the elasticity of the corpuscles, the difference between the speeds of the incoming and reflected corpuscles (and hence the difference in densities) can be made arbitrarily small while still maintaining the same effective gravitational force.\n\nPorosity of gross matter\n\nIn order to ensure mass proportionality, Fatio assumed that gross matter is extremely permeable to the flux of corpuscles. He sketched 3 models to justify this assumption:\n\nHe assumed that matter is an accumulation of small \"balls\" whereby their diameter compared with their distance among themselves is \"infinitely\" small. But he rejected this proposal, because under this condition the bodies would approach each other and therefore would not remain stable.\nThen he assumed that the balls could be connected through bars or lines and would form some kind of crystal lattice. However, he rejected this model too \u2013 if several atoms are together, the gravific fluid is not able to penetrate this structure equally in all direction, and therefore mass proportionality is impossible.\nAt the end Fatio also removed the balls and only left the lines or the net. By making them \"infinitely\" smaller than their distance among themselves, thereby a maximum penetration capacity could be achieved.Pressure force of the particles (Problem II)\nAlready in 1690 Fatio assumed, that the \"push force\" exerted by the particles on a plain surface is the sixth part of the force, which would be produced if all particles are lined up normal to the surface. Fatio now gave a proof of this proposal by determination of the force, which is exerted by the particles on a certain point zz. He derived the formula p = \u03c1v2zz/6. This solution is very similar to the formula known in the kinetic theory of gases p = \u03c1v2/3, which was found by Daniel Bernoulli in 1738. This was the first time that a solution analogous to the similar result in kinetic theory was pointed out \u2013 long before the basic concept of the latter theory was developed. However, Bernoulli's value is twice as large as Fatio's one, because according to Zehe, Fatio only calculated the value mv for the change of impulse after the collision, but not 2mv and therefore got the wrong result. (His result is only correct in the case of totally inelastic collisions.) Fatio tried to use his solution not only for explaining gravitation, but for explaining the behaviour of gases as well. He tried to construct a thermometer, which should indicate the \"state of motion\" of the air molecules and therefore estimate the temperature. But Fatio (unlike Bernoulli) did not identify heat and the movements of the air particles \u2013 he used another fluid, which should be responsible for this effect. It is also unknown, whether Bernoulli was influenced by Fatio or not.\n\nInfinity (Problem III)\nIn this chapter Fatio examines the connections between the term infinity and its relations to his theory. Fatio often justified his considerations with the fact that different phenomena are \"infinitely smaller or larger\" than others and so many problems can be reduced to an undetectable value. For example, the diameter of the bars is infinitely smaller than their distance to each other; or the speed of the particles is infinitely larger than those of gross matter; or the speed difference between reflected and non-reflected particles is infinitely small.\n\nResistance of the medium (Problem IV)\nThis is the mathematically most complex part of Fatio's theory. There he tried to estimate the resistance of the particle streams for moving bodies. Supposing u is the velocity of gross matter, v is the velocity of the gravific particles and \u03c1 the density of the medium. In the case v \u226a u and \u03c1 = constant Fatio stated that the resistance is \u03c1u2. In the case v \u226b u and \u03c1 = constant the resistance is 4/3\u03c1uv. Now, Newton stated that the lack of resistance to the orbital motion requires an extreme sparseness of any medium in space. So Fatio decreased the density of the medium and stated, that to maintain sufficient gravitational force this reduction must be compensated by changing v \"inverse proportional to the square root of the density\". This follows from Fatio's particle pressure, which is proportional to \u03c1v2. According to Zehe, Fatio's attempt to increase v to a very high value would actually leave the resistance very small compared with gravity, because the resistance in Fatio's model is proportional to \u03c1uv but gravity (i.e. the particle pressure) is proportional to \u03c1v2.\n\n\n=== Reception of Fatio's theory ===\nFatio was in communication with some of the most famous scientists of his time.\n\nThere was a strong personal relationship between Isaac Newton and Fatio in the years 1690 to 1693. Newton's statements on Fatio's theory differed widely. For example, after describing the necessary conditions for a mechanical explanation of gravity, he wrote in an (unpublished) note in his own printed copy of the Principia in 1692:The unique hypothesis by which gravity can be explained is however of this kind, and was first devised by the most ingenious geometer Mr. N. Fatio. On the other hand, Fatio himself stated that although Newton had commented privately that Fatio's theory was the best possible mechanical explanation of gravity, he also acknowledged that Newton tended to believe that the true explanation of gravitation was not mechanical. Also, Gregory noted in his \"Memoranda\": \"Mr. Newton and Mr. Halley laugh at Mr. Fatio\u2019s manner of explaining gravity.\" This was allegedly noted by him on December 28, 1691. However, the real date is unknown, because both ink and feather which were used, differ from the rest of the page. After 1694, the relationship between the two men cooled down.\nChristiaan Huygens was the first person informed by Fatio of his theory, but never accepted it. Fatio believed he had convinced Huygens of the consistency of his theory, but Huygens denied this in a letter to Gottfried Leibniz. There was also a short correspondence between Fatio and Leibniz on the theory. Leibniz criticized Fatio's theory for demanding empty space between the particles, which was rejected by him (Leibniz) on philosophical grounds. Jakob Bernoulli expressed an interest in Fatio's Theory, and urged Fatio to write his thoughts on gravitation in a complete manuscript, which was actually done by Fatio. Bernoulli then copied the manuscript, which now resides in the university library of Basel, and was the base of the Bopp edition.\nNevertheless, Fatio's theory remained largely unknown with a few exceptions like Cramer and Le Sage, because he never was able to formally publish his works and he fell under the influence of a group of religious fanatics called the \"French prophets\" (which belonged to the camisards) and therefore his public reputation was ruined.\n\n\n== Cramer and Redeker ==\nIn 1731 the Swiss mathematician Gabriel Cramer published a dissertation, at the end of which appeared a sketch of a theory very similar to Fatio's \u2013 including net structure of matter, analogy to light, shading \u2013 but without mentioning Fatio's name. It was known to Fatio that Cramer had access to a copy of his main paper, so he accused Cramer of only repeating his theory without understanding it. It was also Cramer who informed Le Sage about Fatio's theory in 1749. In 1736 the German physician Franz Albert Redeker also published a similar theory. Any connection between Redeker and Fatio is unknown.\n\n\n== Le Sage ==\n\nThe first exposition of his theory, Essai sur l'origine des forces mortes, was sent by Le Sage to the Academy of Sciences at Paris in 1748, but it was never published. According to Le Sage, after creating and sending his essay he was informed on the theories of Fatio, Cramer and Redeker. In 1756 for the first time one of his expositions of the theory was published, and in 1758 he sent a more detailed exposition, Essai de Chymie M\u00e9chanique, to a competition to the Academy of Sciences in Rouen. In this paper he tried to explain both the nature of gravitation and chemical affinities. The exposition of the theory which became accessible to a broader public, Lucr\u00e8ce Newtonien (1784), in which the correspondence with Lucretius\u2019 concepts was fully developed. Another exposition of the theory was published from Le Sage's notes posthumously by Pierre Pr\u00e9vost in 1818.\n\n\n=== Le Sage's basic concept ===\n\nLe Sage discussed the theory in great detail and he proposed quantitative estimates for some of the theory's parameters.\n\nHe called the gravitational particles ultramundane corpuscles, because he supposed them to originate beyond our known universe. The distribution of the ultramundane flux is isotropic and the laws of its propagation are very similar to that of light.\nLe Sage argued that no gravitational force would arise if the matter-particle-collisions are perfectly elastic . So he proposed that the particles and the basic constituents of matter are \"absolutely hard\" and asserted that this implies a complicated form of interaction, completely inelastic in the direction normal to the surface of the ordinary matter, and perfectly elastic in the direction tangential to the surface. He then commented that this implies the mean speed of scattered particles is 2/3 of their incident speed. To avoid inelastic collisions between the particles, he supposed that their diameter is very small relative to their mutual distance.\nThat resistance of the flux is proportional to uv (where v is the velocity of the particles and u that of gross matter) and gravity is proportional to v2, so the ratio resistance/gravity can be made arbitrarily small by increasing v. Therefore, he suggested that the ultramundane corpuscles might move at the speed of light, but after further consideration he adjusted this to 105 times the speed of light.\nTo maintain mass proportionality, ordinary matter consists of cage-like structures, in which their diameter is only the 107th part of their mutual distance. Also the \"bars\", which constitute the cages, were small (around 1020 times as long as thick) relative to the dimensions of the cages, so the particles can travel through them nearly unhindered.\nLe Sage also attempted to use the shadowing mechanism to account for the forces of cohesion, and for forces of different strengths, by positing the existence of multiple species of ultramundane corpuscles of different sizes, as illustrated in Figure 9.Le Sage said that he was the first one, who drew all consequences from the theory and also Pr\u00e9vost said that Le Sage's theory was more developed than Fatio's theory. However, by comparing the two theories and after a detailed analysis of Fatio's papers (which also were in possession of Le Sage) Zehe judged that Le Sage contributed nothing essentially new and he often did not reach Fatio's level.\n\n\n=== Reception of Le Sage's theory ===\nLe Sage's ideas were not well-received during his day, except for some of his friends and associates like Pierre Pr\u00e9vost, Charles Bonnet, Jean-Andr\u00e9 Deluc, Charles Mahon, 3rd Earl Stanhope and Simon Lhuilier. They mentioned and described Le Sage's theory in their books and papers, which were used by their contemporaries as a secondary source for Le Sage's theory (because of the lack of published papers by Le Sage himself) .\n\nEuler, Bernoulli, and Boscovich\nLeonhard Euler once remarked that Le Sage's model was \"infinitely better\" than that of all other authors, and that all objections are balanced out in this model, but later he said the analogy to light had no weight for him, because he believed in the wave nature of light. After further consideration, Euler came to disapprove of the model, and he wrote to Le Sage:\nYou must excuse me Sir, if I have a great repugnance for your ultramundane corpuscles, and I shall always prefer to confess my ignorance of the cause of gravity than to have recourse to such strange hypotheses.\nDaniel Bernoulli was pleased by the similarity of Le Sage's model and his own thoughts on the nature of gases. However, Bernoulli himself was of the opinion that his own kinetic theory of gases was only a speculation, and likewise he regarded Le Sage's theory as highly speculative.Roger Joseph Boscovich pointed out, that Le Sage's theory is the first one, which actually can explain gravity by mechanical means. However, he rejected the model because of the enormous and unused quantity of ultramundane matter. John Playfair described Boscovich's arguments by saying:\n\nAn immense multitude of atoms, thus destined to pursue their never ending journey through the infinity of space, without changing their direction, or returning to the place from which they came, is a supposition very little countenanced by the usual economy of nature. Whence is the supply of these innumerable torrents; must it not involve a perpetual exertion of creative power, infinite both in extent and in duration?\nA very similar argument was later given by Maxwell (see the sections below). Additionally, Boscovich denied the existence of all contact and immediate impulse at all, but proposed repulsive and attractive actions at a distance.\n\nLichtenberg, Kant, and Schelling\nGeorg Christoph Lichtenberg's knowledge of Le Sage's theory was based on \"Lucrece Newtonien\" and a summary by Pr\u00e9vost. Lichtenberg originally believed (like Descartes) that every explanation of natural phenomena must be based on rectilinear motion and impulsion, and Le Sage's theory fulfilled these conditions. In 1790 he expressed in one of his papers his enthusiasm for the theory, believing that Le Sage's theory embraces all of our knowledge and makes any further dreaming on that topic useless. He went on by saying: \"If it is a dream, it is the greatest and the most magnificent which was ever dreamed...\" and that we can fill with it a gap in our books, which can only be filled by a dream.He often referred to Le Sage's theory in his lectures on physics at the University of G\u00f6ttingen. However, around 1796 Lichtenberg changed his views after being persuaded by the arguments of Immanuel Kant, who criticized any kind of theory that attempted to replace attraction with impulsion. Kant pointed out that the very existence of spatially extended configurations of matter, such as particles of non-zero radius, implies the existence of some sort of binding force to hold the extended parts of the particle together. Now, that force cannot be explained by the push from the gravitational particles, because those particles too must hold together in the same way. To avoid this circular reasoning, Kant asserted that there must exist a fundamental attractive force. This was precisely the same objection that had always been raised against the impulse doctrine of Descartes in the previous century, and had led even the followers of Descartes to abandon that aspect of his philosophy.\nAnother German philosopher, Friedrich Wilhelm Joseph Schelling, rejected Le Sage's model because its mechanistic materialism was incompatible with Schelling's very idealistic and anti-materialistic philosophy.\nLaplace\nPartly in consideration of Le Sage's theory, Pierre-Simon Laplace undertook to determine the necessary speed of gravity in order to be consistent with astronomical observations. He calculated that the speed must be \u201cat least a hundred millions of times greater than that of light\u201d, in order to avoid unacceptably large inequalities due to aberration effects in the lunar motion. This was taken by most researchers, including Laplace, as support for the Newtonian concept of instantaneous action at a distance, and to indicate the implausibility of any model such as Le Sage's. Laplace also argued that to maintain mass-proportionality the upper limit for earth's molecular surface area is at the most the ten-millionth of earth surface. To Le Sage's disappointment, Laplace never directly mentioned Le Sage's theory in his works.\n\n\n== Kinetic theory ==\nBecause the theories of Fatio, Cramer and Redeker were not widely known, Le Sage's exposition of the theory enjoyed a resurgence of interest in the latter half of the 19th century, coinciding with the development of the kinetic theory.\n\nLeray\nSince Le Sage's particles must lose speed when colliding with ordinary matter (in order to produce a net gravitational force), a huge amount of energy must be converted to internal energy modes. If those particles have no internal energy modes, the excess energy can only be absorbed by ordinary matter. Addressing this problem, Armand Jean Leray proposed a particle model (perfectly similar to Le Sage's) in which he asserted that the absorbed energy is used by the bodies to produce magnetism and heat. He suggested, that this might be an answer for the question of where the energy output of the stars comes from.\n\nKelvin and Tait\n\nLe Sage's own theory became a subject of renewed interest in the latter part of the 19th century following a paper published by Kelvin in 1873. Unlike Leray, who treated the heat problem imprecisely, Kelvin stated that the absorbed energy represents a very high heat, sufficient to vaporize any object in a fraction of a second. So Kelvin reiterated an idea that Fatio had originally proposed in the 1690s for attempting to deal with the thermodynamic problem inherent in Le Sage's theory. He proposed that the excess heat might be absorbed by internal energy modes of the particles themselves, based on his proposal of the vortex-nature of matter. In other words, the original translational kinetic energy of the particles is transferred to internal energy modes, chiefly vibrational or rotational, of the particles. Appealing to Clausius's proposition that the energy in any particular mode of a gas molecule tends toward a fixed ratio of the total energy, Kelvin went on to suggest that the energized but slower moving particles would subsequently be restored to their original condition due to collisions (on the cosmological scale) with other particles. Kelvin also asserted that it would be possible to extract limitless amounts of free energy from the ultramundane flux, and described a perpetual motion machine to accomplish this.\nSubsequently, Peter Guthrie Tait called the Le Sage theory the only plausible explanation of gravitation which has been propounded at that time. He went on by saying:\n\nThe most singular thing about it is that, if it be true, it will probably lead us to regard all kinds of energy as ultimately Kinetic.\nKelvin himself, however, was not optimistic that Le Sage's theory could ultimately give a satisfactory account of phenomena. After his brief paper in 1873 noted above, he never returned to the subject, except to make the following comment:\n\nThis kinetic theory of matter is a dream, and can be nothing else, until it can explain chemical affinity, electricity, magnetism, gravitation, and the inertia of masses (that is, crowds) of vortices. Le Sage's theory might give an explanation of gravity and of its relation to inertia of masses, on the vortex theory, were it not for the essential aeolotropy of crystals, and the seemingly perfect isotropy of gravity. No finger post pointing towards a way that can possibly lead to a surmounting of this difficulty, or a turning of its flank, has been discovered, or imagined as discoverable.\nPreston\nSamuel Tolver Preston illustrated that many of the postulates introduced by Le Sage concerning the gravitational particles, such as rectilinear motion, rare interactions, etc.., could be collected under the single notion that they behaved (on the cosmological scale) as the particles of a gas with an extremely long mean free path. Preston also accepted Kelvin's proposal of internal energy modes of the particles. He illustrated Kelvin's model by comparing it with the collision of a steel ring and an anvil \u2013 the anvil would not be shaken very much, but the steel ring would be in a state of vibration and therefore departs with diminished velocity. He also argued, that the mean free path of the particles is at least the distance between the planets \u2013 on longer distances the particles regain their translational energy due collisions with each other, so he concluded that on longer distances there would be no attraction between the bodies, independent of their size. Paul Drude suggested that this could possibly be a connection with some theories of Carl Gottfried Neumann and Hugo von Seeliger, who proposed some sort of absorption of gravity in open space.\nMaxwell\n\nA review of the Kelvin-Le Sage theory was published by James Clerk Maxwell in the Ninth Edition of the Encyclop\u00e6dia Britannica under the title Atom in 1875. After describing the basic concept of the theory he wrote (with sarcasm according to Aronson):\nHere, then, seems to be a path leading towards an explanation of the law of gravitation, which, if it can be shown to be in other respects consistent with facts, may turn out to be a royal road into the very arcana of science.\nMaxwell commented on Kelvin's suggestion of different energy modes of the particles that this implies the gravitational particles are not simple primitive entities, but rather systems, with their own internal energy modes, which must be held together by (unexplained) forces of attraction. He argues that the temperature of bodies must tend to approach that at which the average kinetic energy of a molecule of the body would be equal to the average kinetic energy of an ultra-mundane particle and he states that the latter quantity must be much greater than the former and concludes that ordinary matter should be incinerated within seconds under the Le Sage bombardment. He wrote:\n\nWe have devoted more space to this theory than it seems to deserve, because it is ingenious, and because it is the only theory of the cause of gravitation which has been so far developed as to be capable of being attacked and defended.\nMaxwell also argued that the theory requires \"an enormous expenditure of external power\" and therefore violating the conservation of energy as the fundamental principle of nature. Preston responded to Maxwell's criticism by arguing that the kinetic energy of each individual simple particle could be made arbitrarily low by positing a sufficiently low mass (and higher number density) for the particles. But this issue later was discussed in a more detailed way by Poincar\u00e9, who showed that the thermodynamic problem within Le Sage models remained unresolved.\n\nIsenkrahe, Ry\u0161\u00e1nek, du Bois-Reymond\nCaspar Isenkrahe presented his model in a variety of publications between 1879 and 1915.\n\nHis basic assumptions were very similar to those of Le Sage and Preston, but he gave a more detailed application of the kinetic theory. However, by asserting that the velocity of the corpuscles after collision was reduced without any corresponding increase in the energy of any other object, his model violated the conservation of energy. He noted that there is a connection between the weight of a body and its density (because any decrease in the density of an object reduces the internal shielding) so he went on to assert that warm bodies should be heavier than colder ones (related to the effect of thermal expansion).\nIn another model Adalbert Ry\u0161\u00e1nek in 1887\n\nalso gave a careful analysis, including an application of Maxwell's law of the particle velocities in a gas. He distinguished between a gravitational and a luminiferous aether. This separation of those two mediums was necessary, because according to his calculations the absence of any drag effect in the orbit of Neptune implies a lower limit for the particle velocity of 5 \u00b7 1019 cm/s. He (like Leray) argued that the absorbed energy is converted into heat, which might be transferred into the luminiferous aether and/or is used by the stars to maintain their energy output. However, these qualitative suggestions were unsupported by any quantitative evaluation of the amount of heat actually produced.\nIn 1888 Paul du Bois-Reymond argued against Le Sage's model, partly because the predicted force of gravity in Le Sage's theory is not strictly proportional to mass. In order to achieve exact mass proportionality as in Newton's theory (which implies no shielding or saturation effects and an infinitely porous structure of matter), the ultramundane flux must be infinitely intense. Du Bois-Reymond rejected this as absurd. In addition, du Bois-Reymond like Kant observed that Le Sage's theory cannot meet its goal, because it invokes concepts like \"elasticity\" and \"absolute hardness\" etc., which (in his opinion) can only be explained by means of attractive forces. The same problem arises for the cohesive forces in molecules. As a result, the basic intent of such models, which is to dispense with elementary forces of attraction, is impossible.\n\n\n== Wave models ==\nKeller and Boisbaudran\nIn 1863, Fran\u00e7ois Antoine Edouard and Em. Keller presented a theory by using a Le Sage type mechanism in combination with longitudinal waves of the aether. They supposed that those waves are propagating in every direction and losing some of their momentum after the impact on bodies, so between two bodies the pressure exerted by the waves is weaker than the pressure around them. In 1869, Paul-Emile Lecoq de Boisbaudran presented the same model as Leray (including absorption and the production of heat etc.), but like Keller and Keller, he replaced the particles with longitudinal waves of the aether.\n\nLorentz\n\nAfter these attempts, other authors in the early 20th century substituted electromagnetic radiation for Le Sage's particles. This was in connection with Lorentz ether theory and the electron theory of that time, in which the electrical constitution of matter was assumed.\nIn 1900 Hendrik Lorentz wrote that Le Sage's particle model is not consistent with the electron theory of his time. But the realization that trains of electromagnetic waves could produce some pressure, in combination with the penetrating power of R\u00f6ntgen rays (now called x-rays), led him to conclude that nothing argues against the possible existence of even more penetrating radiation than x-rays, which could replace Le Sage's particles. Lorentz showed that an attractive force between charged particles (which might be taken to model the elementary subunits of matter) would indeed arise, but only if the incident energy were entirely absorbed. This was the same fundamental problem which had afflicted the particle models. So Lorentz wrote:\n\nThe circumstance however, that this attraction could only exist, if in some way or other electromagnetic energy were continually disappearing, is so serious a difficulty, that what has been said cannot be considered as furnishing an explanation of gravitation. Nor is this the only objection that can be raised. If the mechanism of gravitation consisted in vibrations which cross the aether with the velocity of light, the attraction ought to be modified by the motion of the celestial bodies to a much larger extent than astronomical observations make it possible to admit.\nIn 1922 Lorentz first examined Martin Knudsen's investigation on rarefied gases and in connection with that he discussed Le Sage's particle model, followed by a summary of his own electromagnetic Le Sage model \u2013 but he repeated his conclusion from 1900: Without absorption no gravitational effect.\nIn 1913 David Hilbert referred to Lorentz's theory and criticised it by arguing that no force in the form 1/r2 can arise, if the mutual distance of the atoms is large enough when compared with their wavelength.\nJ.J. Thomson\nIn 1904 J. J. Thomson considered a Le Sage-type model in which the primary ultramundane flux consisted of a hypothetical form of radiation much more penetrating even than x-rays. He argued that Maxwell's heat problem might be avoided by assuming that the absorbed energy is not converted into heat, but re-radiated in a still more penetrating form. He noted that this process possibly can explain where the energy of radioactive substances comes from \u2013 however, he stated that an internal cause of radioactivity is more probable. In 1911 Thomson went back to this subject in his article \"Matter\" in the Encyclop\u00e6dia Britannica Eleventh Edition. There he stated, that this form of secondary radiation is somewhat analogous to how the passage of electrified particles through matter causes the radiation of the even more penetrating x-rays. He remarked:\n\nIt is a very interesting result of recent discoveries that the machinery which Le Sage introduced for the purpose of his theory has a very close analogy with things for which we have now direct experimental evidence....R\u00f6ntgen rays, however, when absorbed do not, as far as we know, give rise to more penetrating R\u00f6ntgen rays as they should to explain attraction, but either to less penetrating rays or to rays of the same kind.\nTommasina and Brush\nUnlike Lorentz and Thomson, Thomas Tommasina between 1903 and 1928 suggested long wavelength radiation to explain gravity, and short wavelength radiation for explaining the cohesive forces of matter. Charles F. Brush in 1911 also proposed long wavelength radiation. But he later revised his view and changed to extremely short wavelengths.\n\n\n== Later assessments ==\nDarwin\nIn 1905, George Darwin subsequently calculated the gravitational force between two bodies at extremely close range to determine if geometrical effects would lead to a deviation from Newton's law. Here Darwin replaced Le Sage's cage-like units of ordinary matter with microscopic hard spheres of uniform size. He concluded that only in the instance of perfectly inelastic collisions (zero reflection) would Newton's law stand up, thus reinforcing the thermodynamic problem of Le Sage's theory. Also, such a theory is only valid if the normal and the tangential components of impact are totally inelastic (contrary to Le Sage's scattering mechanism), and the elementary particles are exactly of the same size. He went on to say that the emission of light is the exact converse of the absorption of Le Sage's particles. A body with different surface temperatures will move in the direction of the colder part. In a later review of gravitational theories, Darwin briefly described Le Sage's theory and said he gave the theory serious consideration, but then wrote:\n\nI will not refer further to this conception, save to say that I believe that no man of science is disposed to accept it as affording the true road.\nPoincar\u00e9\n\nPartially based on the calculations of Darwin, an important criticism was given by Henri Poincar\u00e9 in 1908. He concluded that the attraction is proportional to \n  \n    \n      \n        S\n        \n          \n            \u03c1\n          \n        \n        v\n      \n    \n    {\\displaystyle S{\\sqrt {\\rho }}v}\n  , where S is earth's molecular surface area, v is the velocity of the particles, and \u03c1 is the density of the medium. Following Laplace, he argued that to maintain mass-proportionality the upper limit for S is at the most a ten-millionth of the Earth's surface. Now, drag (i.e. the resistance of the medium) is proportional to S\u03c1v and therefore the ratio of drag to attraction is inversely proportional to Sv. To reduce drag, Poincar\u00e9 calculated a lower limit for v = 24 \u00b7 1017 times the speed of light. So there are lower limits for Sv and v, and an upper limit for S and with those values one can calculate the produced heat, which is proportional to S\u03c1v3. The calculation shows that earth's temperature would rise by 1026 degrees per second. Poincar\u00e9 noticed, \"that the earth could not long stand such a regime.\" Poincar\u00e9 also analyzed some wave models (Tommasina and Lorentz), remarking that they suffered the same problems as the particle models. To reduce drag, superluminal wave velocities were necessary, and they would still be subject to the heating problem. After describing a similar re-radiation model like Thomson, he concluded: \"Such are the complicated hypotheses to which we are led when we seek to make Le Sage's theory tenable\".\nHe also stated that if in Lorentz' model the absorbed energy is fully converted into heat, that would raise earth's temperature by 1013 degrees per second. Poincar\u00e9 then went on to consider Le Sage's theory in the context of the \"new dynamics\" that had been developed at the end of the 19th and the beginning of the 20th centuries, specifically recognizing the relativity principle. For a particle theory, he remarked that \"it is difficult to imagine a law of collision compatible with the principle of relativity\", and the problems of drag and heating remain.\n\n\n== Predictions and criticism ==\n\n\n=== Matter and particles ===\nPorosity of matter\nA basic prediction of the theory is the extreme porosity of matter. As supposed by Fatio and Le Sage in 1690/1758 (and before them, Huygens) matter must consist mostly of empty space so that the very small particles can penetrate the bodies nearly undisturbed and therefore every single part of matter can take part in the gravitational interaction. This prediction has been (in some respects) confirmed over the course of the time. Indeed, matter consists mostly of empty space and certain particles like neutrinos can pass through matter nearly unhindered. However, the image of elementary particles as classical entities who interact directly, determined by their shapes and sizes (in the sense of the net structure proposed by Fatio/Le Sage and the equisized spheres of Isenkrahe/Darwin), is not consistent with current understanding of elementary particles. The Lorentz/Thomson proposal of electrical charged particles as the basic constituents of matter is inconsistent with current physics as well.\n\nCosmic radiation\nEvery Le Sage-type model assumes the existence of a space-filling isotropic flux or radiation of enormous intensity and penetrating capability. This has some similarity to the cosmic microwave background radiation (CMBR) discovered in the 20th century. CMBR is indeed a space-filling and fairly isotropic flux, but its intensity is extremely small, as is its penetrating capability. The flux of neutrinos, emanating from (for example) the sun, possesses the penetrating properties envisaged by Le Sage for his ultramundane corpuscles, but this flux is not isotropic (since individual stars are the main sources of neutrinos) and the intensity is even less than that of the CMBR. Of course, neither the CMBR nor neutrinos propagate at superluminal speeds, which is another necessary attribute of Le Sage's particles. From a more modern point of view, discarding the simple \u201cpush\u201d concept of Le Sage, the suggestion that the neutrino (or some other particle similar to the neutrino) might be the mediating particle in a quantum field theory of gravitation was considered and disproved by Feynman.\n\n\n=== Gravitational shielding ===\n\nAlthough matter is postulated to be very sparse in the Fatio\u2013Le Sage theory, it cannot be perfectly transparent, because in that case no gravitational force would exist. However, the lack of perfect transparency leads to problems: with sufficient mass the amount of shading produced by two pieces of matter becomes less than the sum of the shading that each of them would produce separately, due to the overlap of their shadows (P10, above). This hypothetical effect, called gravitational shielding, implies that addition of matter does not result in a direct proportional increase in the gravitational mass.  Therefore, in order to be viable, Fatio and Le Sage postulated that the shielding effect is so small as to be undetectable, which requires that the interaction cross-section of matter must be extremely small (P10, below). This places an extremely high lower-bound on the intensity of the flux required to produce the observed force of gravity. Any form of gravitational shielding would represent a violation of the equivalence principle, and would be inconsistent with the extremely precise null result observed in the E\u00f6tv\u00f6s experiment and its successors \u2014 all of which have instead confirmed the precise equivalence of active and passive gravitational mass with inertial mass that was predicted by general relativity. For more historical information on the connection between gravitational shielding and Le Sage gravity, see Martins, and Borzeszkowski et al.\nSince Isenkrahe's proposal on the connection between density, temperature and weight was based purely on the anticipated effects of changes in material density, and since temperature at a given density can be increased or decreased, Isenkrahe's comments do not imply any fundamental relation between temperature and gravitation. (There actually is a relation between temperature and gravitation, as well as between binding energy and gravitation, but these actual effects have nothing to do with Isenkrahe's proposal. See the section below on \"Coupling to energy\".) Regarding the prediction of a relation between gravitation and density, all experimental evidence indicates that there is no such relation.\n\n\n=== Speed of gravity ===\nDrag\nAccording to Le Sage's theory, an isolated body is subjected to drag if it is in motion relative to the unique isotropic frame of the ultramundane flux (i.e., the frame in which the speed of the ultramundane corpuscles is the same in all directions). This is due to the fact that, if a body is in motion, the particles striking the body from the front have a higher speed (relative to the body) than those striking the body from behind \u2013 this effect will act to decrease the distance between the sun and the earth. The magnitude of this drag is proportional to vu, where v is the speed of the particles and u is the speed of the body, whereas the characteristic force of gravity is proportional to v2, so the ratio of drag to gravitational force is proportional to u/v. Thus for a given characteristic strength of gravity, the amount of drag for a given speed u can be made arbitrarily small by increasing the speed v of the ultramundane corpuscles. However, in order to reduce the drag to an acceptable level (i.e., consistent with observation) in terms of classical mechanics, the speed v must be many orders of magnitude greater than the speed of light. This makes Le Sage theory fundamentally incompatible with the modern science of mechanics based on special relativity, according to which no particle (or wave) can exceed the speed of light. In addition, even if superluminal particles were possible, the effective temperature of such a flux would be sufficient to incinerate all ordinary matter in a fraction of a second.\n\nAberration\nAs shown by Laplace, another possible Le Sage effect is orbital aberration due to finite speed of gravity.  Unless the Le Sage particles are moving at speeds much greater than the speed of light, as Le Sage and Kelvin supposed, there is a time delay in the interactions between bodies (the transit time).  In the case of orbital motion this results in each body reacting to a retarded position of the other, which creates a leading force component.  Contrary to the drag effect, this component will act to accelerate both objects away from each other.  In order to maintain stable orbits, the effect of gravity must either propagate much faster than the speed of light or must not be a purely central force. This has been suggested by many as a conclusive disproof of any Le Sage type of theory. In contrast, general relativity is consistent with the lack of appreciable aberration identified by Laplace, because even though gravity propagates at the speed of light in general relativity, the expected aberration is almost exactly cancelled by velocity-dependent terms in the interaction.\n\n\n=== Range of gravity ===\nIn many particle models, such as Kelvin's, the range of gravity is limited due to the nature of particle interactions amongst themselves. The range is effectively determined by the rate that the proposed internal modes of the particles can eliminate the momentum defects (shadows) that are created by passing through matter. Such predictions as to the effective range of gravity will vary and are dependent upon the specific aspects and assumptions as to the modes of interactions that are available during particle interactions.  However, for this class of models the observed large-scale structure of the cosmos constrains such dispersion to those that will allow for the aggregation of such immense gravitational structures.\n\n\n=== Energy ===\n\n\n==== Absorption ====\nAs noted in the historical section, a major problem for every Le Sage model is the energy and heat issue. As Maxwell and Poincar\u00e9 showed, inelastic collisions lead to a vaporization of matter within fractions of a second and the suggested solutions were not convincing. For example, Aronson gave a simple proof of Maxwell's assertion:\n\nSuppose that, contrary to Maxwell's hypothesis, the molecules of gross matter actually possess more energy than the particles. In that case the particles would, on the average, gain energy in the collision and the particles intercepted by body B would be replaced by more energetic ones rebounding from body B. Thus the effect of gravity would be reversed: there would be a mutual repulsion between all bodies of mundane matter, contrary to observation. If, on the other hand, the average kinetic energies of the particles and of the molecules are the same, then no net transfer of energy would take place, and the collisions would be equivalent to elastic ones, which, as has been demonstrated, do not yield a gravitational force.\nLikewise Isenkrahe's violation of the energy conservation law is unacceptable, and Kelvin's application of Clausius' theorem leads (as noted by Kelvin himself) to some sort of perpetual motion mechanism. The suggestion of a secondary re-radiation mechanism for wave models attracted the interest of JJ Thomson, but was not taken very seriously by either Maxwell or Poincar\u00e9, because it entails a gross violation of the second law of thermodynamics (huge amounts of energy spontaneously being converted from a colder to a hotter form), which is one of the most solidly established of all physical laws.\nThe energy problem has also been considered in relation to the idea of mass accretion in connection with the Expanding Earth theory. Among the early theorists to link mass increase in some sort of push gravity model to Earth expansion were Yarkovsky and Hilgenberg. The idea of mass accretion and the expanding earth theory are not currently considered to be viable by mainstream scientists. This is because, among other reasons, according to the principle of mass-energy equivalence, if the Earth was absorbing the energy of the ultramundane flux at the rate necessary to produce the observed force of gravity (i.e. by using the values calculated by Poincar\u00e9), its mass would be doubling in each fraction of a second.\n\n\n==== Coupling to energy ====\nBased on observational evidence, it is now known that gravity interacts with all forms of energy, and not just with mass.  The electrostatic binding energy of the nucleus, the energy of weak interactions in the nucleus, and the kinetic energy of electrons in atoms, all contribute to the gravitational mass of an atom, as has been confirmed to high precision in E\u00f6tv\u00f6s type experiments.\nThis means, for example, that when the atoms of a quantity of gas are moving more rapidly, the gravitation of that gas increases.\nMoreover, Lunar Laser Ranging experiments have shown that even gravitational binding energy itself also gravitates, with a strength consistent with the equivalence principle to high precision\n\u2014\nwhich furthermore demonstrates that any successful theory of gravitation must be nonlinear and self-coupling.\nLe Sage's theory does not predict any of these aforementioned effects, nor do any of the known variants of Le Sage's theory.\n\n\n== Non-gravitational applications and analogies ==\nMock gravity\nLyman Spitzer in 1941 calculated, that absorption of radiation between two dust particles lead to a net attractive force which varies proportional to 1/r2 (evidently he was unaware of Le Sage's shadow mechanism and especially Lorentz's considerations on radiation pressure and gravity). George Gamow, who called this effect \"mock gravity\", proposed in 1949 that after the Big Bang the temperature of electrons dropped faster than the temperature of background radiation. Absorption of radiation lead to a Lesage mechanism between electrons, which might have had an important role in the process of galaxy formation shortly after the Big Bang. However, this proposal was disproved by Field in 1971, who showed that this effect was much too small, because electrons and background radiation were nearly in thermal equilibrium. Hogan and White proposed in 1986 that mock gravity might have influenced the formation of galaxies by absorption of pregalactic starlight. But it was shown by Wang and Field that any form of mock gravity is incapable of producing enough force to influence galaxy formation.\n\nPlasma\nThe Le Sage mechanism also has been identified as a significant factor in the behavior of dusty plasma. A.M. Ignatov has shown that an attractive force arises between two dust grains suspended in an isotropic collisionless plasma due to inelastic collisions between ions of the plasma and the grains of dust. This attractive force is inversely proportional to the square of the distance between dust grains, and can counterbalance the Coulomb repulsion between dust grains.\n\nVacuum energy\nIn quantum field theory the existence of virtual particles is proposed, which lead to the so-called Casimir effect. Casimir calculated that between two plates only particles with specific wavelengths should be counted when calculating the vacuum energy.  Therefore, the energy density between the plates is less if the plates are close together, leading to a net attractive force between the plates. However, the conceptual framework of this effect is very different from the theory of Fatio and Le Sage.\n\n\n== Recent activity ==\nThe re-examination of Le Sage's theory in the 19th century identified several closely interconnected problems with the theory.  These relate to excessive heating, frictional drag, shielding, and gravitational aberration.  The recognition of these problems, in conjunction with a general shift away from mechanical based theories, resulted in a progressive loss of interest in Le Sage's theory. Ultimately in the 20th century Le Sage's theory was eclipsed by Einstein's theory of general relativity.\nIn 1965 Richard Feynman examined the Fatio/Lesage mechanism, primarily as an example of an attempt to explain a \"complicated\" physical law (in this case, Newton's inverse-square law of gravity) in terms of simpler primitive operations without the use of complex mathematics, and also as an example of a failed theory. He notes that the mechanism of \"bouncing particles\" reproduces the inverse-square force law and that \"the strangeness of the mathematical relation will be very much reduced\", but then remarks that the scheme \"does not work\", because of the drag it predicts would be experienced by moving bodies.There are occasional attempts to re-habilitate the theory outside the mainstream, including those of Radzievskii and Kagalnikova (1960), Shneiderov (1961), Buonomano and Engels (1976), Adamut (1982), Popescu (1982), Jaakkola (1996), Tom Van Flandern (1999), Edwards (2007)  and Edwards (2022).A variety of Le Sage models and related topics are discussed in Edwards, et al.\n\n\n== Primary sources ==\n\n\n== Secondary sources ==\n\n\n== External links ==\n\n Media related to Le Sage gravity at Wikimedia Commons", "Total_internal_reflection": "In physics, total internal reflection (TIR) is the phenomenon in which waves arriving at the interface (boundary) from one medium to another (e.g., from water to air) are not refracted into the second (\"external\") medium, but completely reflected back into the first (\"internal\") medium. It occurs when the second medium has a higher wave speed (i.e., lower refractive index) than the first, and the waves are incident at a sufficiently oblique angle on the interface. For example, the water-to-air surface in a typical fish tank, when viewed obliquely from below, reflects the underwater scene like a mirror with no loss of brightness (Fig.\u202f1).\nTIR occurs not only with electromagnetic waves such as light and microwaves, but also with other types of waves, including sound and water waves. If the waves are capable of forming a narrow beam (Fig.\u202f2), the reflection tends to be described in terms of \"rays\" rather than waves; in a medium whose properties are independent of direction, such as air, water or glass, the \"rays\" are perpendicular to the associated wavefronts.\n\nRefraction is generally accompanied by partial reflection. When waves are refracted from a medium of lower propagation speed (higher refractive index) to a medium of higher speed\u2014e.g., from water to air\u2014the angle of refraction (between the outgoing ray and the surface normal) is greater than the angle of incidence (between the incoming ray and the normal). As the angle of incidence approaches a certain threshold, called the critical angle, the angle of refraction approaches 90\u00b0, at which the refracted ray becomes parallel to the boundary surface. As the angle of incidence increases beyond the critical angle, the conditions of refraction can no longer be satisfied, so there is no refracted ray, and the partial reflection becomes total. For visible light, the critical angle is about 49\u00b0 for incidence from water to air, and about 42\u00b0 for incidence from common glass to air.\nDetails of the mechanism of TIR give rise to more subtle phenomena. While total reflection, by definition, involves no continuing flow of power across the interface between the two media, the external medium carries a so-called evanescent wave, which travels along the interface with an amplitude that falls off exponentially with distance from the interface. The \"total\" reflection is indeed total if the external medium is lossless (perfectly transparent), continuous, and of infinite extent, but can be conspicuously less than total if the evanescent wave is absorbed by a lossy external medium (\"attenuated total reflectance\"), or diverted by the outer boundary of the external medium or by objects embedded in that medium (\"frustrated\" TIR). Unlike partial reflection between transparent media, total internal reflection is accompanied by a non-trivial phase shift (not just zero or 180\u00b0) for each component of polarization (perpendicular or parallel to the plane of incidence), and the shifts vary with the angle of incidence. The explanation of this effect by Augustin-Jean Fresnel, in 1823, added to the evidence in favor of the wave theory of light.\nThe phase shifts are utilized by Fresnel's invention, the Fresnel rhomb, to modify polarization. The efficiency of the total internal reflection is exploited by optical fibers (used in telecommunications cables and in image-forming fiberscopes), and by reflective prisms, such as image-erecting Porro/roof prisms for monoculars and binoculars.\n\n\n== Optical description ==\n\nAlthough total internal reflection can occur with any kind of wave that can be said to have oblique incidence, including (e.g.) microwaves and sound waves,\u2009 it is most familiar in the case of light waves.\nTotal internal reflection of light can be demonstrated using a semicircular-cylindrical block of common glass or acrylic glass. In Fig.\u202f3, a \"ray box\" projects a narrow beam of light (a \"ray\") radially inward. The semicircular cross-section of the glass allows the incoming ray to remain perpendicular to the curved portion of the air/glass surface, and then hence to continue in a straight line towards the flat part of the surface, although its angle with the flat part varies.\nWhere the ray meets the flat glass-to-air interface, the angle between the ray and the normal (perpendicular) to the interface is called the angle of incidence. If this angle is sufficiently small, the ray is partly reflected but mostly transmitted, and the transmitted portion is refracted away from the normal, so that the angle of refraction (between the refracted ray and the normal to the interface) is greater than the angle of incidence. For the moment, let us call the angle of incidence \u03b8i and the angle of refraction \u03b8t (where t is for transmitted, reserving r for reflected). As \u03b8i increases and approaches a certain \"critical angle\", denoted by \u03b8c (or sometimes \u03b8cr), the angle of refraction approaches 90\u00b0 (that is, the refracted ray approaches a tangent to the interface), and the refracted ray becomes fainter while the reflected ray becomes brighter. As \u03b8i increases beyond \u03b8c, the refracted ray disappears and only the reflected ray remains, so that all of the energy of the incident ray is reflected; this is total internal reflection (TIR). In brief:\n\nIf\u2009 \u03b8i < \u03b8c\u200d,\u200d the incident ray is split, being partly reflected and partly refracted;\nIf\u2009 \u03b8i > \u03b8c\u200d,\u200d the incident ray suffers total internal reflection (TIR); none of it is transmitted.\n\n\n== Critical angle ==\nThe critical angle is the smallest angle of incidence that yields total reflection, or equivalently the largest angle for which a refracted ray exists. For light waves incident from an \"internal\" medium with a single refractive index n1\u200a,\u200d to an \"external\" medium with a single refractive index n2\u200a,\u200d the critical angle is given by\u200d \n  \n    \n      \n        \n          \u03b8\n          \n            \n              c\n            \n            \n          \n        \n        =\n        arcsin\n        \u2061\n        (\n        \n          n\n          \n            2\n          \n        \n        \n          /\n        \n        \n          n\n          \n            1\n          \n        \n        )\n        \n        ,\n      \n    \n    {\\displaystyle \\theta _{{\\text{c}}\\!}=\\arcsin(n_{2}/n_{1})\\,,}\n   and is defined if\u200d n2 \u2264 n1.\u2009 For some other types of waves, it is more convenient to think in terms of propagation velocities rather than refractive indices. The explanation of the critical angle in terms of velocities is more general and will therefore be discussed first\u3002\n\nWhen a wavefront is refracted from one medium to another, the incident (incoming) and refracted (outgoing) portions of the wavefront meet at a common line on the refracting surface (interface). Let this line, denoted by L, move at velocity u across the surface, where u is measured normal to L\u200d (Fig.\u202f4). Let the incident and refracted wavefronts propagate with normal velocities \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   and \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{2}}\n   (respectively), and let them make the dihedral angles \u03b81 and \u03b82 (respectively) with the interface. From the geometry,\u200d \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   is the component of u in the direction normal to the incident wave, so that\u200d \n  \n    \n      \n        \n          v\n          \n            1\n            \n          \n        \n        =\n        u\n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle v_{1\\!}=u\\sin \\theta _{1}\\,.}\n   Similarly,\u200d \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        u\n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle v_{2}=u\\sin \\theta _{2}\\,.}\n   Solving each equation for 1/u and equating the results, we obtain the general law of refraction for waves:\n\nBut the dihedral angle between two planes is also the angle between their normals. So \u03b81 is the angle between the normal to the incident wavefront and the normal to the interface, while \u03b82 is the angle between the normal to the refracted wavefront and the normal to the interface; and Eq.\u202f(1) tells us that the sines of these angles are in the same ratio as the respective velocities.This result has the form of \"Snell's law\", except that we have not yet said that the ratio of velocities is constant, nor identified \u03b81 and \u03b82 with the angles of incidence and refraction (called \u03b8i and \u03b8t above). However, if we now suppose that the properties of the media are isotropic (independent of direction), two further conclusions follow: first, the two velocities, and hence their ratio, are independent of their directions; and second, the wave-normal directions coincide with the ray directions, so that \u03b81 and \u03b82 coincide with the angles of incidence and refraction as defined above.\n\nObviously the angle of refraction cannot exceed 90\u00b0. In the limiting case, we put\u200d \u03b82 = 90\u00b0 and\u200d \u03b81\u2009= \u03b8c\u200d in Eq.\u202f(1), and solve for the critical angle:\n\nIn deriving this result, we retain the assumption of isotropic media in order to identify \u03b81 and \u03b82 with the angles of incidence and refraction.For electromagnetic waves, and especially for light, it is customary to express the above results in terms of refractive indices. The refractive index of a medium with normal velocity \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   is defined as\u200d \n  \n    \n      \n        \n          n\n          \n            1\n            \n          \n        \n        =\n        c\n        \n          /\n        \n        \n          v\n          \n            1\n          \n        \n        \n        ,\n      \n    \n    {\\displaystyle n_{1\\!}=c/v_{1}\\,,}\n   where c is the speed of light in vacuum.\u2009 Hence\u200d \n  \n    \n      \n        \n          v\n          \n            1\n            \n          \n        \n        =\n        c\n        \n          /\n        \n        \n          n\n          \n            1\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle v_{1\\!}=c/n_{1}\\,.}\n  \u2009 Similarly,\u200d \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        c\n        \n          /\n        \n        \n          n\n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle v_{2}=c/n_{2}\\,.}\n  \u2009 Making these substitutions in Eqs.\u202f(1)\u2009and\u2009(2), we obtain\n\nand\n\nEq.\u202f(3) is the law of refraction for general media, in terms of refractive indices, provided that \u03b81 and \u03b82 are taken as the dihedral angles; but if the media are isotropic, then n1 and n2 become independent of direction while \u03b81 and \u03b82 may be taken as the angles of incidence and refraction for the rays, and Eq.\u202f(4) follows. So, for isotropic media, Eqs.\u202f(3)\u2009and\u2009(4) together describe the behavior in Fig.\u202f5.\nAccording to Eq.\u202f(4), for incidence from water (n1 \u2248 1.333)\u200d to air (n2 \u2248 1),\u200d we have\u200d \u03b8c \u2248 48.6\u00b0,\u200d whereas for incidence from common glass or acrylic (n1 \u2248 1.50)\u200d to air (n2 \u2248 1),\u200d we have\u200d \u03b8c \u2248 41.8\u00b0.\nThe arcsin function yielding \u03b8c is defined only if\u200d n2 \u2264 n1\u2009 \n  \n    \n      \n        (\n        \n          v\n          \n            2\n          \n        \n        \u2265\n        \n          v\n          \n            1\n          \n        \n        )\n        \n        .\n      \n    \n    {\\displaystyle (v_{2}\\geq v_{1})\\,.}\n  \u2009 Hence, for isotropic media, total internal reflection cannot occur if the second medium has a higher refractive index (lower normal velocity) than the first. For example, there cannot be TIR for incidence from air to water; rather, the critical angle for incidence from water to air\u200d is the angle of refraction at grazing incidence from air to water (Fig.\u202f6).The medium with the higher refractive index is commonly described as optically denser, and the one with the lower refractive index as optically rarer. Hence it is said that total internal reflection is possible for \"dense-to-rare\" incidence, but not for \"rare-to-dense\" incidence.\n\n\n== Everyday examples ==\n\nWhen standing beside an aquarium with one's eyes below the water level, one is likely to see fish or submerged objects reflected in the water-air surface (Fig.\u202f1). The brightness of the reflected image \u2013 just as bright as the \"direct\" view \u2013 can be startling.\nA similar effect can be observed by opening one's eyes while swimming just below the water's surface. If the water is calm, the surface outside the critical angle (measured from the vertical) appears mirror-like, reflecting objects below. The region above the water cannot be seen except overhead, where the hemispherical field of view is compressed into a conical field known as Snell's window, whose angular diameter is twice the critical angle (cf. Fig.\u202f6).\u2009 The field of view above the water is theoretically 180\u00b0 across, but seems less because as we look closer to the horizon, the vertical dimension is more strongly compressed by the refraction; e.g., by Eq.\u202f(3), for air-to-water incident angles of 90\u00b0, 80\u00b0, and 70\u00b0, the corresponding angles of refraction are 48.6\u00b0 (\u03b8cr in Fig.\u202f6), 47.6\u00b0, and 44.8\u00b0, indicating that the image of a point 20\u00b0 above the horizon is 3.8\u00b0 from the edge of Snell's window\u200d while the image of a point 10\u00b0 above the horizon is only 1\u00b0 from the edge.Fig.\u202f7, for example, is a photograph taken near the bottom of the shallow end of a swimming pool. What looks like a broad horizontal stripe on the right-hand wall\u200d consists of the lower edges of a row of orange tiles, and their reflections; this marks the water level, which can then be traced across the other wall. The swimmer has disturbed the surface above her, scrambling the lower half of her reflection, and distorting the reflection of the ladder (to the right). But most of the surface is still calm, giving a clear reflection of the tiled bottom of the pool. The space above the water is not visible except at the top of the frame, where the handles of the ladder are just discernible above the edge of Snell's window \u2013 within which the reflection of the bottom of the pool is only partial, but still noticeable in the photograph. One can even discern the color-fringing of the edge of Snell's window, due to variation of the refractive index, hence of the critical angle, with wavelength (see Dispersion).\n\nThe critical angle influences the angles at which gemstones are cut. The round \"brilliant\" cut, for example, is designed to refract light incident on the front facets, reflect it twice by TIR off the back facets, and transmit it out again through the front facets, so that the stone looks bright. Diamond (Fig.\u202f8) is especially suitable for this treatment, because its high refractive index (about 2.42) and consequently small critical angle (about 24.5\u00b0) yield the desired behavior over a wide range of viewing angles. Cheaper materials that are similarly amenable to this treatment include cubic zirconia (index\u202f\u2248\u202f2.15) and moissanite (non-isotropic, hence doubly refractive, with an index ranging from about 2.65 to 2.69, depending on direction and polarization); both of these are therefore popular as diamond simulants.\n\n\n== Evanescent wave ==\n\nMathematically, waves are described in terms of time-varying fields, a \"field\" being a function of location in space. A propagating wave requires an \"effort\" field and a \"flow\" field, the latter being a vector (if we are working in two or three dimensions). The product of effort and flow is related to power (see System equivalence). For example, for sound waves in a non-viscous fluid, we might take the effort field as the pressure (a scalar), and the flow field as the fluid velocity (a vector). The product of these two is intensity (power per unit area). For electromagnetic waves, we shall take the effort field as the electric field\u200a E\u200a, and the flow field as the magnetizing field\u200a H. Both of these are vectors, and their vector product is again the intensity (see Poynting vector).When a wave in (say) medium 1 is reflected off the interface between medium 1 and medium 2, the flow field in medium 1 is the vector sum of the flow fields due to the incident and reflected waves.\u2009 If the reflection is oblique, the incident and reflected fields are not in opposite directions and therefore cannot cancel out at the interface; even if the reflection is total, either the normal component or the tangential component of the combined field (as a function of location and time) must be non-zero adjacent to the interface. Furthermore, the physical laws governing the fields will generally imply that one of the two components is continuous across the interface (that is, it does not suddenly change as we cross the interface); for example, for electromagnetic waves, one of the interface conditions is that the tangential component of H is continuous if there is no surface current. Hence, even if the reflection is total, there must be some penetration of the flow field into medium 2; and this, in combination with the laws relating the effort and flow fields, implies that there will also be some penetration of the effort field. The same continuity condition implies that the variation (\"waviness\") of the field in medium 2 will be synchronized with that of the incident and reflected waves in medium 1.\n\nBut, if the reflection is total, the spatial penetration of the fields into medium 2 must be limited somehow, or else the total extent and hence the total energy of those fields would continue to increase, draining power from medium 1. Total reflection of a continuing wavetrain permits some energy to be stored in medium 2, but does not permit a continuing transfer of power from medium 1 to medium 2.\nThus, using mostly qualitative reasoning, we can conclude that total internal reflection must be accompanied by a wavelike field in the \"external\" medium, traveling along the interface in synchronism with the incident and reflected waves, but with some sort of limited spatial penetration into the \"external\" medium; such a field may be called an evanescent wave.\nFig.\u202f9 shows the basic idea. The incident wave is assumed to be plane and sinusoidal. The reflected wave, for simplicity, is not shown. The evanescent wave travels to the right in lock-step with the incident and reflected waves, but its amplitude falls off with increasing distance from the interface.\n(Two features of the evanescent wave in Fig.\u202f9 are to be explained later: first, that the evanescent wave crests are perpendicular to the interface; and second, that the evanescent wave is slightly ahead of the incident wave.)\n\n\n=== FTIR (Frustrated Total Internal Reflection) ===\nIf the internal reflection is to be total, there must be no diversion of the evanescent wave. Suppose, for example, that electromagnetic waves incident from glass (with a higher refractive index) to air (with a lower refractive index) at a certain angle of incidence are subject to TIR. And suppose that we have a third medium (often identical to the first) whose refractive index is sufficiently high that, if the third medium were to replace the second, we would get a standard transmitted wavetrain for the same angle of incidence. Then, if the third medium is brought within a distance of a few wavelengths from the surface of the first medium, where the evanescent wave has significant amplitude in the second medium, then the evanescent wave is effectively refracted into the third medium, giving non-zero transmission into the third medium, and therefore less than total reflection back into the first medium. As the amplitude of the evanescent wave decays across the air gap, the transmitted waves are attenuated, so that there is less transmission, and therefore more reflection, than there would be with no gap; but as long as there is some transmission, the reflection is less than total. This phenomenon is called frustrated total internal reflection (where \"frustrated\" negates \"total\"), abbreviated \"frustrated TIR\" or \"FTIR\".\n\nFrustrated TIR can be observed by looking into the top of a glass of water held in one's hand (Fig.\u202f10). If the glass is held loosely, contact may not be sufficiently close and widespread to produce a noticeable effect. But if it is held more tightly, the ridges of one's fingerprints interact strongly with the evanescent waves, allowing the ridges to be seen through the otherwise totally reflecting glass-air surface.The same effect can be demonstrated with microwaves, using paraffin wax as the \"internal\" medium (where the incident and reflected waves exist). In this case the permitted gap width might be (e.g.) 1\u202fcm or several cm, which is easily observable and adjustable.The term frustrated TIR also applies to the case in which the evanescent wave is scattered by an object sufficiently close to the reflecting interface. This effect, together with the strong dependence of the amount of scattered light on the distance from the interface, is exploited in total internal reflection microscopy.The mechanism of FTIR is called evanescent-wave coupling, and is a good analog to visualize quantum tunneling. Due to the wave nature of matter, an electron has a non-zero probability of \"tunneling\" through a barrier, even if classical mechanics would say that its energy is insufficient. Similarly, due to the wave nature of light, a photon has a non-zero probability of crossing a gap, even if ray optics would say that its approach is too oblique.\nAnother reason why internal reflection may be less than total, even beyond the critical angle, is that the external medium may be \"lossy\" (less than perfectly transparent), in which case the external medium will absorb energy from the evanescent wave, so that the maintenance of the evanescent wave will draw power from the incident wave. The consequent less-than-total reflection is called attenuated total reflectance (ATR). This effect, and especially the frequency-dependence of the absorption, can be used to study the composition of an unknown external medium.\n\n\n=== Derivation of evanescent wave ===\nIn a uniform plane sinusoidal electromagnetic wave, the electric field\u200a E has the form\n\nwhere Ek is the (constant) complex amplitude vector,  i is the imaginary unit,  k is the wave vector (whose magnitude k is the angular wavenumber),  r is the position vector,  \u03c9 is the angular frequency,  t is time, and it is understood that the real part of the expression is the physical field. The magnetizing field\u200a H has the same form with the same k and \u03c9. The value of the expression is unchanged if the position r varies in a direction normal to k; hence k is normal to the wavefronts.\nIf \u2113 is the component of r in the direction of k\u200d,\u200d the field (5) can be written \n  \n    \n      \n        \n          \n            E\n            \n              k\n            \n          \n        \n        \n          e\n          \n            i\n            (\n            k\n            \u2113\n            \u2212\n            \u03c9\n            t\n            )\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {E_{k}} e^{i(k\\ell -\\omega t)}\\,.}\n    If the argument of \n  \n    \n      \n        \n          e\n          \n            i\n            (\n            \u22ef\n            )\n          \n        \n      \n    \n    {\\displaystyle e^{i(\\cdots )}}\n   is to be constant,  \u2113 must increase at the velocity\u200d \n  \n    \n      \n        \u03c9\n        \n          /\n        \n        k\n        \n        ,\n        \n      \n    \n    {\\displaystyle \\omega /k\\,,\\,}\n   known as the phase velocity. This in turn is equal to \n  \n    \n      \n        c\n        \n          /\n        \n        n\n        \n        ,\n        \n      \n    \n    {\\displaystyle c/n\\,,\\,}\n   where c is the phase velocity in the reference medium (taken as vacuum) and n is the local refractive index w.r.t. the reference medium. Solving for k gives\u200d \n  \n    \n      \n        k\n        =\n        n\n        \u03c9\n        \n          /\n        \n        c\n        \n        ,\n        \n      \n    \n    {\\displaystyle k=n\\omega /c\\,,\\,}\n   i.e.\n\nwhere \n  \n    \n      \n        \n        \n          k\n          \n            0\n          \n        \n        =\n        \u03c9\n        \n          /\n        \n        c\n        \n      \n    \n    {\\displaystyle \\,k_{0}=\\omega /c\\,}\n   is the wavenumber in vacuum.From (5), the electric field in the \"external\" medium has the form\n\nwhere kt is the wave vector for the transmitted wave (we assume isotropic media, but the transmitted wave is not yet assumed to be evanescent).\n\nIn Cartesian coordinates (x,\u200ay,\u200dz), let the region\u200d y < 0\u200d have refractive index n1\u200d,\u200d and let the region\u200d y > 0\u200d have refractive index n2. Then the xz plane is the interface, and the y axis is normal to the interface (Fig.\u202f11). Let i and j (in bold roman type) be the unit vectors in the x and y directions, respectively. Let the plane of incidence (containing the incident wave-normal and the normal to the interface) be the xy plane (the plane of the page), with the angle of incidence \u03b8i measured from j towards i. Let the angle of refraction, measured in the same sense, be \u03b8t\u2009 (t for transmitted, reserving  r for reflected).\nFrom (6), the transmitted wave vector kt has magnitude n2k0. Hence, from the geometry,\n\nwhere the last step uses Snell's law. Taking the dot product with the position vector, we get\n\nso that Eq.\u202f(7) becomes\n\nIn the case of TIR, the angle \u03b8t does not exist in the usual sense. But we can still interpret (8) for the transmitted (evanescent) wave, by allowing cos\u2009\u03b8t to be complex. This becomes necessary when we write cos\u2009\u03b8t in terms of sin\u2009\u03b8t\u200d,\u200d and thence in terms of sin\u2009\u03b8i using Snell's law:\n\nFor \u03b8i greater than the critical angle, the value under the square-root symbol is negative, so that\nTo determine which sign is applicable, we substitute (9) into (8), obtaining\n\nwhere the undetermined sign is the opposite of that in (9). For an evanescent transmitted wave \u2013 that is, one whose amplitude decays as y increases \u2013 the undetermined sign in (10) must be minus, so the undetermined sign in (9) must be plus.With the correct sign, the result (10) can be abbreviated\n\nwhere\n\nand k0 is the wavenumber in vacuum, i.e. \n  \n    \n      \n        \n        \u03c9\n        \n          /\n        \n        c\n        \n        .\n      \n    \n    {\\displaystyle \\,\\omega /c\\,.}\n  \nSo the evanescent wave is a plane sinewave traveling in the x direction, with an amplitude that decays exponentially in the y direction (cf. Fig.\u202f9). It is evident that the energy stored in this wave likewise travels in the x direction and does not cross the interface. Hence the Poynting vector generally has a component in the x direction, but its y component averages to zero (although its instantaneous y component is not identically zero).\n\nEq.\u202f(11) indicates that the amplitude of the evanescent wave falls off by a factor e as the coordinate y (measured from the interface) increases by the distance\u200d \n  \n    \n      \n        d\n        =\n        1\n        \n          /\n        \n        \u03ba\n        \n        ,\n        \n      \n    \n    {\\displaystyle d=1/\\kappa \\,,\\,}\n   commonly called the \"penetration depth\" of the evanescent wave. Taking reciprocals of the first equation of (12), we find that the penetration depth is\nwhere \u03bb0 is the wavelength in vacuum, i.e. \n  \n    \n      \n        \n        2\n        \u03c0\n        \n          /\n        \n        \n          k\n          \n            0\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle \\,2\\pi /k_{0}\\,.}\n  \u2009 Dividing the numerator and denominator by n2 yields\n\nwhere \n  \n    \n      \n        \n        \n          \u03bb\n          \n            2\n          \n        \n        =\n        \n          \u03bb\n          \n            0\n          \n        \n        \n          /\n        \n        \n          n\n          \n            2\n          \n        \n        \n      \n    \n    {\\displaystyle \\,\\lambda _{2}=\\lambda _{0}/n_{2}\\,}\n   is the wavelength in the second (external) medium. Hence we can plot d in units of \u03bb2\u200a, as a function of the angle of incidence, for various values of \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        \n          /\n        \n        \n          n\n          \n            2\n            \n          \n        \n      \n    \n    {\\displaystyle n_{1}/n_{2\\,}}\n   (Fig.\u202f12).\u2009 As \u03b8i decreases towards the critical angle, the denominator approaches zero, so that d increases without limit \u2013 as is to be expected, because as soon as \u03b8i is less than critical, uniform plane waves are permitted in the external medium. As \u03b8i approaches 90\u00b0 (grazing incidence),\u2009 d approaches a minimum\n\nFor incidence from water to air, or common glass to air,\u2009 dmin is not much different from \u03bb2/2\u03c0.\u2009 But d is larger at smaller angles of incidence (Fig.\u202f12), and the amplitude may still be significant at distances of several times d; for example, because e\u22124.6 is just greater than 0.01, the evanescent wave amplitude within a distance 4.6\u200dd\u200a of the interface is at least 1% of its value at the interface. Hence, speaking loosely, we tend to say that the evanescent wave amplitude is significant within \"a few wavelengths\" of the interface.\n\n\n== Phase shifts ==\nBetween 1817 and 1823, Augustin-Jean Fresnel discovered that total internal reflection is accompanied by a non-trivial phase shift (that is, a phase shift that is not restricted to 0\u00b0 or 180\u00b0), as the Fresnel reflection coefficient acquires a non-zero imaginary part. We shall now explain this effect for electromagnetic waves in the case of linear, homogeneous, isotropic, non-magnetic media. The phase shift turns out to be an advance, which grows as the incidence angle increases beyond the critical angle, but which depends on the polarization of the incident wave.\nIn equations (5), (7), (8), (10), and (11), we advance the phase by the angle \u03d5 if we replace \u03c9t by \u03c9t+\u03d5\u2009 (that is, if we replace \u2212\u03c9t by \u2212\u03c9t\u2212\u03d5),\u2009 with the result that the (complex) field is multiplied by e\u2212i\u03d5. So a phase advance is equivalent to multiplication by a complex constant with a negative argument. This becomes more obvious when (e.g.) the field (5) is factored as \n  \n    \n      \n        \n          \n            E\n            \n              k\n            \n          \n        \n        \n          e\n          \n            i\n            \n              k\n              \u22c5\n              r\n            \n          \n        \n        \n          e\n          \n            \u2212\n            i\n            \u03c9\n            t\n          \n        \n        ,\n        \n      \n    \n    {\\displaystyle \\mathbf {E_{k}} e^{i\\mathbf {k\\cdot r} }e^{-i\\omega t},\\,}\n   where the last factor contains the time-dependence.To represent the polarization of the incident, reflected, or transmitted wave, the electric field adjacent to an interface can be resolved into two perpendicular components, known as the s and p components, which are parallel to the surface and the plane of incidence, respectively; in other words, the s and p components are respectively square and parallel to the plane of incidence.For each component of polarization, the incident, reflected, or transmitted electric field (E in Eq.\u202f(5)) has a certain direction, and can be represented by its (complex) scalar component in that direction. The reflection or transmission coefficient can then be defined as a ratio of complex components at the same point, or at infinitesimally separated points on opposite sides of the interface. But, in order to fix the signs of the coefficients, we must choose positive senses for the \"directions\". For the s components, the obvious choice is to say that the positive directions of the incident, reflected, and transmitted fields are all the same (e.g., the z direction in Fig.\u202f11). For the p components, this article adopts the convention that the positive directions of the incident, reflected, and transmitted fields are inclined towards the same medium (that is, towards the same side of the interface, e.g. like the red arrows in Fig.\u202f11).\u2009 But the reader should be warned that some books use a different convention for the p components, causing a different sign in the resulting formula for the reflection coefficient.For the s polarization, let the reflection and transmission coefficients be rs and ts respectively. For the p polarization, let the corresponding coefficients be rp and tp\u200a. Then, for linear, homogeneous, isotropic, non-magnetic media, the coefficients are given by:\n\n(For a derivation of the above, see\u200a Fresnel equations\u200a \u00a7\u202fTheory.)\nNow we suppose that the transmitted wave is evanescent. With the correct sign (+), substituting (9) into (13) gives\n\nwhere\n\nthat is, n is the index of the \"internal\" medium relative to the \"external\" one, or the index of the internal medium if the external one is vacuum.\u2009 So the magnitude of rs is 1, and the argument of rs is\n\nwhich gives a phase advance of\u200d\nMaking the same substitution in (14), we find that ts has the same denominator as rs with a positive real numerator (instead of a complex conjugate numerator) and therefore has half the argument of rs\u200d,\u200d so that the phase advance of the evanescent wave is half that of the reflected wave.\nWith the same choice of sign, substituting (9) into (15) gives\n\nwhose magnitude is 1, and whose argument is\n\nwhich gives a phase advance of\u200d\nMaking the same substitution in (16), we again find that the phase advance of the evanescent wave is half that of the reflected wave.\nEquations (17) and (18) apply when\u200d \u03b8c \u2264 \u03b8i < 90\u00b0, where \u03b8i is the angle of incidence and \u03b8c is the critical angle\u200d arcsin\u200a(1/n).\u2009 These equations show that\n\neach phase advance is zero at the critical angle (for which the numerator is zero);\neach phase advance approaches 180\u00b0 as\u200d \u03b8i \u2192 90\u00b0; and\n\u03b4p > \u03b4s\u200d at intermediate values of \u03b8i (because the factor n is in the numerator of (18) and the denominator of (17)).For \u03b8i \u2264 \u03b8c\u200d,\u200d the reflection coefficients are given by equations (13) and (15), and are real, so that the phase shift is either 0\u00b0 (if the coefficient is positive) or 180\u00b0 (if the coefficient is negative).\nIn (13), if we put\u200d \n  \n    \n      \n        \n          n\n          \n            2\n          \n        \n        =\n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            i\n          \n        \n        \n          /\n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle n_{2}=n_{1}\\sin \\theta _{\\text{i}}/\\sin \\theta _{\\text{t}}}\n   (Snell's law) and multiply the numerator and denominator by\u200d 1/n1\u2009sin\u2009\u03b8t\u200d,\u200d we obtain\u200a\n\nwhich is positive for all angles of incidence with a transmitted ray (since\u200d \u03b8t > \u03b8i), giving a phase shift \u03b4s of zero.\nIf we do likewise with (15), the result is easily shown to be equivalent to\u200a\n\nwhich is negative for small angles (that is, near normal incidence), but changes sign at Brewster's angle, where\u200a \u03b8i and \u03b8t are complementary. Thus the phase shift \u03b4p is 180\u00b0 for small \u03b8i but switches to 0\u00b0 at Brewster's angle. Combining the complementarity with Snell's law yields\u200d \u03b8i = arctan\u200a(1/n)\u200d as Brewster's angle for dense-to-rare incidence.(Equations (19) and (20) are known as Fresnel's sine law and Fresnel's tangent law. Both reduce to 0/0 at normal incidence, but yield the correct results in the limit as\u200d \u03b8i \u2192 0. That they have opposite signs as we approach normal incidence is an obvious disadvantage of the sign convention used in this article; the corresponding advantage is that they have the same signs at grazing incidence.)\n\nThat completes the information needed to plot \u03b4s and \u03b4p for all angles of incidence. This is done in Fig.\u202f13, with \u03b4p in red and \u03b4s in blue, for three refractive indices. On the angle-of-incidence scale (horizontal axis), Brewster's angle is where \u03b4p (red) falls from 180\u00b0 to 0\u00b0, and the critical angle is where both \u03b4p and \u03b4s (red and blue) start to rise again. To the left of the critical angle is the region of partial reflection, where both reflection coefficients are real (phase 0\u00b0 or 180\u00b0) with magnitudes less than 1. To the right of the critical angle is the region of total reflection, where both reflection coefficients are complex with magnitudes equal to 1. In that region, the black curves show the phase advance of the p component relative to the s component:\nIt can be seen that a refractive index of 1.45 is not enough to give a 45\u00b0 phase difference, whereas a refractive index of 1.5 is enough (by a slim margin) to give a 45\u00b0 phase difference at two angles of incidence: about 50.2\u00b0 and 53.3\u00b0.\nThis 45\u00b0 relative shift is employed in Fresnel's invention, now known as the Fresnel rhomb, in which the angles of incidence are chosen such that the two internal reflections cause a total relative phase shift of 90\u00b0 between the two polarizations of an incident wave. This device performs the same function as a birefringent quarter-wave plate, but is more achromatic (that is, the phase shift of the rhomb is less sensitive to wavelength). Either device may be used, for instance, to transform linear polarization to circular polarization (which Fresnel also discovered) and vice versa.\n\nIn Fig.\u202f13,  \u03b4 is computed by a final subtraction; but there are other ways of expressing it. Fresnel himself, in 1823, gave a formula for\u200a cos\u2009\u03b4.\u2009 Born and Wolf (1970, p.\u202f50) derive an expression for\u200d tan\u200a(\u03b4/2), and find its maximum analytically.\nFor TIR of a beam with finite width, the variation in the phase shift with the angle of incidence gives rise to the Goos\u2013H\u00e4nchen effect, which is a lateral shift of the reflected beam within the plane of incidence. This effect applies to linear polarization in the s or p direction. The Imbert\u2013Fedorov effect is an analogous effect for circular or elliptical polarization, and produces a shift perpendicular to the plane of incidence.\n\n\n== Applications ==\n\nOptical fibers exploit total internal reflection to carry signals over long distances with little attenuation. They are used in telecommunication cables, and in image-forming fiberscopes such as colonoscopes.In the catadioptric Fresnel lens, invented by Augustin-Jean Fresnel for use in lighthouses, the outer prisms use TIR to deflect light from the lamp through a greater angle than would be possible with purely refractive prisms, but with less absorption of light (and less risk of tarnishing) than with conventional mirrors.\n\nOther reflecting prisms that use TIR include the following (with some overlap between the categories):\nImage-erecting prisms for binoculars and spotting scopes include paired 45\u00b0-90\u00b0-45\u00b0 Porro prisms (Fig.\u202f14), the Porro\u2013Abbe prism, the inline Koenig and Abbe\u2013Koenig prisms, and the compact inline Schmidt\u2013Pechan prism. (The last consists of two components, of which one is a kind of Bauernfeind prism, which requires a reflective coating on one of its two reflecting faces, due to a sub-critical angle of incidence.) These prisms have the additional function of folding the optical path from the objective lens to the prime focus, reducing the overall length for a given primary focal length.\nA prismatic star diagonal for an astronomical telescope may consist of a single Porro prism (configured for a single reflection, giving a mirror-reversed image) or an Amici roof prism (which gives a non-reversed image).\nRoof prisms use TIR at two faces meeting at a sharp 90\u00b0 angle. This category includes the Koenig, Abbe\u2013Koenig, Schmidt\u2013Pechan, and Amici types (already mentioned), and the roof pentaprism used in SLR cameras; the last of these requires a reflective coating on one non-TIR face.\nA prismatic corner reflector uses three total internal reflections to reverse the direction of incoming light.\nThe Dove prism gives an inline view with mirror-reversal.Polarizing prisms: Although the Fresnel rhomb, which converts between linear and elliptical polarization, is not birefringent (doubly refractive), there are other kinds of prisms that combine birefringence with TIR in such a way that light of a particular polarization is totally reflected while light of the orthogonal polarization is at least partly transmitted. Examples include the Nicol prism, Glan\u2013Thompson prism, Glan\u2013Foucault prism (or \"Foucault prism\"), and Glan\u2013Taylor prism.Refractometers, which measure refractive indices, often use the critical angle.Rain sensors for automatic windscreen/windshield wipers have been implemented using the principle that total internal reflection will guide an infrared beam from a source to a detector if the outer surface of the windshield is dry, but any water drops on the surface will divert some of the light.Edge-lit LED panels, used (e.g.) for backlighting of LCD computer monitors, exploit TIR to confine the LED light to the acrylic glass pane, except that some of the light is scattered by etchings on one side of the pane, giving an approximately uniform luminous emittance.\n\nTotal internal reflection microscopy (TIRM) uses the evanescent wave to illuminate small objects close to the reflecting interface. The consequent scattering of the evanescent wave (a form of frustrated TIR), makes the objects appear bright when viewed from the \"external\" side. In the total internal reflection fluorescence microscope (TIRFM), instead of relying on simple scattering, we choose an evanescent wavelength short enough to cause fluorescence (Fig.\u202f15). The high sensitivity of the illumination to the distance from the interface allows measurement of extremely small displacements and forces.A beam-splitter cube uses frustrated TIR to divide the power of the incoming beam between the transmitted and reflected beams. The width of the air gap (or low-refractive-index gap) between the two prisms can be made adjustable, giving higher transmission and lower reflection for a narrower gap, or higher reflection and lower transmission for a wider gap.Optical modulation can be accomplished by means of frustrated TIR with a rapidly variable gap. As the transmission coefficient is highly sensitive to the gap width (the function being approximately exponential until the gap is almost closed), this technique can achieve a large dynamic range.\nOptical fingerprinting devices have used frustrated TIR to record images of persons' fingerprints without the use of ink (cf. Fig.\u202f11).Gait analysis can be performed by using frustrated TIR with a high-speed camera, to capture and analyze footprints.A gonioscope, used in optometry and ophthalmology for the diagnosis of glaucoma, suppresses TIR in order to look into the angle between the iris and the cornea. This view is usually blocked by TIR at the cornea-air interface. The gonioscope replaces the air with a higher-index medium, allowing transmission at oblique incidence, typically followed by reflection in a \"mirror\", which itself may be implemented using TIR.Some multi-touch interactive tables and whiteboards utilise FTIR to detect fingers touching the screen. An infrared camera is placed behind the screen surface, which is edge-lit by infrared LEDs; when touching the surface FTIR causes some of the infrared light to escape the screen plane, and the camera sees this as bright areas. Computer vision software is then used to translate this into a series of coordinates and gestures.\n\n\n== History ==\n\n\n=== Discovery ===\nThe surprisingly comprehensive and largely correct explanations of the rainbow by Theodoric of Freiberg (written between 1304 and 1310) and Kam\u0101l al-D\u012bn al-F\u0101ris\u012b (completed by 1309), although sometimes mentioned in connection with total internal reflection (TIR), are of dubious relevance because the internal reflection of sunlight in a spherical raindrop is not total. But, according to Carl Benjamin Boyer, Theodoric's treatise on the rainbow also classified optical phenomena under five causes, the last of which was \"a total reflection at the boundary of two transparent media\". Theodoric's work was forgotten until it was rediscovered by Giovanni Battista Venturi in 1814.\n\nTheodoric having fallen into obscurity, the discovery of TIR was generally attributed to Johannes Kepler, who published his findings in his Dioptrice in 1611. Although Kepler failed to find the true law of refraction, he showed by experiment that for air-to-glass incidence, the incident and refracted rays rotated in the same sense about the point of incidence, and that as the angle of incidence varied through \u00b190\u00b0, the angle of refraction (as we now call it) varied through \u00b142\u00b0. He was also aware that the incident and refracted rays were interchangeable. But these observations did not cover the case of a ray incident from glass to air at an angle beyond 42\u00b0, and Kepler promptly concluded that such a ray could only be reflected.Ren\u00e9 Descartes rediscovered the law of refraction and published it in his Dioptrique of 1637. In the same work he mentioned the senses of rotation of the incident and refracted rays and the condition of TIR. But he neglected to discuss the limiting case, and consequently failed give an expression for the critical angle, although he could easily have done so.\n\n\n=== Huygens and Newton: Rival explanations ===\nChristiaan Huygens, in his Treatise on Light (1690), paid much attention to the threshold at which the incident ray is \"unable to penetrate into the other transparent substance\". Although he gave neither a name nor an algebraic expression for the critical angle, he gave numerical examples for glass-to-air and water-to-air incidence, noted the large change in the angle of refraction for a small change in the angle of incidence near the critical angle, and cited this as the cause of the rapid increase in brightness of the reflected ray as the refracted ray approaches the tangent to the interface. Huygens' insight is confirmed by modern theory: in Eqs.\u202f(13) and (15) above, there is nothing to say that the reflection coefficients increase exceptionally steeply as \u03b8t approaches 90\u00b0, except that, according to Snell's law,\u2009 \u03b8t itself is an increasingly steep function of \u03b8i.\n\nHuygens offered an explanation of TIR within the same framework as his explanations of the laws of rectilinear propagation, reflection, ordinary refraction, and even the extraordinary refraction of \"Iceland crystal\" (calcite). That framework rested on two premises: first, every point crossed by a propagating wavefront becomes a source of secondary wavefronts (\"Huygens' principle\"); and second, given an initial wavefront, any subsequent position of the wavefront is the envelope (common tangent surface) of all the secondary wavefronts emitted from the initial position. All cases of reflection or refraction by a surface are then explained simply by considering the secondary waves emitted from that surface. In the case of refraction from a medium of slower propagation to a medium of faster propagation, there is a certain obliquity of incidence beyond which it is impossible for the secondary wavefronts to form a common tangent in the second medium; this is what we now call the critical angle. As the incident wavefront approaches this critical obliquity, the refracted wavefront becomes concentrated against the refracting surface, augmenting the secondary waves that produce the reflection back into the first medium.Huygens' system even accommodated partial reflection at the interface between different media, albeit vaguely, by analogy with the laws of collisions between particles of different sizes. However, as long as the wave theory continued to assume longitudinal waves, it had no chance of accommodating polarization, hence no chance of explaining the polarization-dependence of extraordinary refraction, or of the partial reflection coefficient, or of the phase shift in TIR.\n\nIsaac Newton rejected the wave explanation of rectilinear propagation, believing that if light consisted of waves, it would \"bend and spread every way\" into the shadows. His corpuscular theory of light explained rectilinear propagation more simply, and it accounted for the ordinary laws of refraction and reflection, including TIR, on the hypothesis that the corpuscles of light were subject to a force acting perpendicular to the interface. In this model, for dense-to-rare incidence, the force was an attraction back towards the denser medium, and the critical angle was the angle of incidence at which the normal velocity of the approaching corpuscle was just enough to reach the far side of the force field; at more oblique incidence, the corpuscle would be turned back. Newton gave what amounts to a formula for the critical angle, albeit in words: \"as the Sines are which measure the Refraction, so is the Sine of Incidence at which the total Reflexion begins, to the Radius of the Circle\".Newton went beyond Huygens in two ways. First, not surprisingly, Newton pointed out the relationship between TIR and dispersion: when a beam of white light approaches a glass-to-air interface at increasing obliquity, the most strongly-refracted rays (violet) are the first to be \"taken out\" by \"total Reflexion\", followed by the less-refracted rays. Second, he observed that total reflection could be frustrated (as we now say) by laying together two prisms, one plane and the other slightly convex; and he explained this simply by noting that the corpuscles would be attracted not only to the first prism, but also to the second.In two other ways, however, Newton's system was less coherent. First, his explanation of partial reflection depended not only on the supposed forces of attraction between corpuscles and media, but also on the more nebulous hypothesis of \"Fits of easy Reflexion\" and \"Fits of easy Transmission\". Second, although his corpuscles could conceivably have \"sides\" or \"poles\", whose orientations could conceivably determine whether the corpuscles suffered ordinary or extraordinary refraction in \"Island-Crystal\", his geometric description of the extraordinary refraction was theoretically unsupported and empirically inaccurate.\n\n\n=== Laplace, Malus, and attenuated total reflectance (ATR) ===\nWilliam Hyde Wollaston, in the first of a pair of papers read to the Royal Society of London in 1802, reported his invention of a refractometer based on the critical angle of incidence from an internal medium of known \"refractive power\" (refractive index) to an external medium whose index was to be measured. With this device, Wollaston measured the \"refractive powers\" of numerous materials, some of which were too opaque to permit direct measurement of an angle of refraction. Translations of his papers were published in France in 1803, and apparently came to the attention of Pierre-Simon Laplace.\n\nAccording to Laplace's elaboration of Newton's theory of refraction, a corpuscle incident on a plane interface between two homogeneous isotropic media was subject to a force field that was symmetrical about the interface. If both media were transparent, total reflection would occur if the corpuscle were turned back before it exited the field in the second medium. But if the second medium were opaque, reflection would not be total unless the corpuscle were turned back before it left the first medium; this required a larger critical angle than the one given by Snell's law, and consequently impugned the validity of Wollaston's method for opaque media. Laplace combined the two cases into a single formula for the relative refractive index in terms of the critical angle (minimum angle of incidence for TIR). The formula contained a parameter which took one value for a transparent external medium and another value for an opaque external medium. Laplace's theory further predicted a relationship between refractive index and density for a given substance.\n\nIn 1807, Laplace's theory was tested experimentally by his prot\u00e9g\u00e9, \u00c9tienne-Louis Malus. Taking Laplace's formula for the refractive index as given, and using it to measure the refractive index of bees' wax in the liquid (transparent) state and the solid (opaque) state at various temperatures (hence various densities), Malus verified Laplace's relationship between refractive index and density.But Laplace's theory implied that if the angle of incidence exceeded his modified critical angle, the reflection would be total even if the external medium was absorbent. Clearly this was wrong: in Eqs.\u202f(12) above, there is no threshold value of the angle \u03b8i beyond which \u03ba becomes infinite; so the penetration depth of the evanescent wave (1/\u03ba) is always non-zero, and the external medium, if it is at all lossy, will attenuate the reflection. As to why Malus apparently observed such an angle for opaque wax, we must infer that there was a certain angle beyond which the attenuation of the reflection was so small that ATR was visually indistinguishable from TIR.\n\n\n=== Fresnel and the phase shift ===\nFresnel came to the study of total internal reflection through his research on polarization. In 1811, Fran\u00e7ois Arago discovered that polarized light was apparently \"depolarized\" in an orientation-dependent and color-dependent manner when passed through a slice of doubly-refractive crystal: the emerging light showed colors when viewed through an analyzer (second polarizer). Chromatic polarization, as this phenomenon came to be called, was more thoroughly investigated in 1812 by Jean-Baptiste Biot. In 1813, Biot established that one case studied by Arago, namely quartz cut perpendicular to its optic axis, was actually a gradual rotation of the plane of polarization with distance.\n\nIn 1816, Fresnel offered his first attempt at a wave-based theory of chromatic polarization. Without (yet) explicitly invoking transverse waves, his theory treated the light as consisting of two perpendicularly polarized components. In 1817 he noticed that plane-polarized light seemed to be partly depolarized by total internal reflection, if initially polarized at an acute angle to the plane of incidence. By including total internal reflection in a chromatic-polarization experiment, he found that the apparently depolarized light was a mixture of components polarized parallel and perpendicular to the plane of incidence, and that the total reflection introduced a phase difference between them. Choosing an appropriate angle of incidence (not yet exactly specified) gave a phase difference of 1/8 of a cycle. Two such reflections from the \"parallel faces\" of \"two coupled prisms\" gave a phase difference of 1/4 of a cycle. In that case, if the light was initially polarized at 45\u00b0 to the plane of incidence and reflection, it appeared to be completely depolarized after the two reflections. These findings were reported in a memoir submitted and read to the French Academy of Sciences in November 1817.In 1821, Fresnel derived formulae equivalent to his sine and tangent laws (Eqs.\u202f(19) and (20), above)\u2009 by modeling light waves as transverse elastic waves with vibrations perpendicular to what had previously been called the plane of polarization. Using old experimental data, he promptly confirmed that the equations correctly predicted the direction of polarization of the reflected beam when the incident beam was polarized at 45\u00b0 to the plane of incidence, for light incident from air onto glass or water. The experimental confirmation was reported in a \"postscript\" to the work in which Fresnel expounded his mature theory of chromatic polarization, introducing transverse waves. Details of the derivation were given later, in a memoir read to the academy in January 1823. The derivation combined conservation of energy with continuity of the tangential vibration at the interface, but failed to allow for any condition on the normal component of vibration.Meanwhile, in a memoir submitted in December 1822, Fresnel coined the terms linear polarization, circular polarization, and elliptical polarization. For circular polarization, the two perpendicular components were a quarter-cycle (\u00b190\u00b0) out of phase.\nThe new terminology was useful in the memoir of January 1823, containing the detailed derivations of the sine and tangent laws: in that same memoir, Fresnel found that for angles of incidence greater than the critical angle, the resulting reflection coefficients were complex with unit magnitude. Noting that the magnitude represented the amplitude ratio as usual, he guessed that the argument represented the phase shift, and verified the hypothesis by experiment. The verification involved\n\ncalculating the angle of incidence that would introduce a total phase difference of 90\u00b0 between the s and p components, for various numbers of total internal reflections at that angle (generally there were two solutions),\nsubjecting light to that number of total internal reflections at that angle of incidence, with an initial linear polarization at 45\u00b0 to the plane of incidence, and\nchecking that the final polarization was circular.This procedure was necessary because, with the technology of the time, one could not measure the s and p phase-shifts directly, and one could not measure an arbitrary degree of ellipticality of polarization, such as might be caused by the difference between the phase shifts. But one could verify that the polarization was circular, because the brightness of the light was then insensitive to the orientation of the analyzer.\nFor glass with a refractive index of 1.51, Fresnel calculated that a 45\u00b0 phase difference between the two reflection coefficients (hence a 90\u00b0 difference after two reflections) required an angle of incidence of 48\u00b037' or 54\u00b037'. He cut a rhomb to the latter angle and found that it performed as expected. Thus the specification of the Fresnel rhomb was completed. Similarly, Fresnel calculated and verified the angle of incidence that would give a 90\u00b0 phase difference after three reflections at the same angle, and four reflections at the same angle. In each case there were two solutions, and in each case he reported that the larger angle of incidence gave an accurate circular polarization (for an initial linear polarization at 45\u00b0 to the plane of reflection). For the case of three reflections he also tested the smaller angle, but found that it gave some coloration due to the proximity of the critical angle and its slight dependence on wavelength. (Compare Fig.\u202f13 above, which shows that the phase difference \u03b4 is more sensitive to the refractive index for smaller angles of incidence.)\nFor added confidence, Fresnel predicted and verified that four total internal reflections at 68\u00b027' would give an accurate circular polarization if two of the reflections had water as the external medium while the other two had air, but not if the reflecting surfaces were all wet or all dry.Fresnel's deduction of the phase shift in TIR is thought to have been the first occasion on which a physical meaning was attached to the argument of a complex number. Although this reasoning was applied without the benefit of knowing that light waves were electromagnetic, it passed the test of experiment, and survived remarkably intact after James Clerk Maxwell changed the presumed nature of the waves. Meanwhile, Fresnel's success inspired James MacCullagh and Augustin-Louis Cauchy, beginning in 1836, to analyze reflection from metals by using the Fresnel equations with a complex refractive index. The imaginary part of the complex index represents absorption.The term critical angle, used for convenience in the above narrative, is anachronistic: it apparently dates from 1873.In the 20th century, quantum electrodynamics reinterpreted the amplitude of an electromagnetic wave in terms of the probability of finding a photon. In this framework, partial transmission and frustrated TIR concern the probability of a photon crossing a boundary, and attenuated total reflectance concerns the probability of a photon being absorbed on the other side.\nResearch into the more subtle aspects of the phase shift in TIR, including the Goos\u2013H\u00e4nchen and Imbert\u2013Fedorov effects and their quantum interpretations, has continued into the 21st century.\n\n\n== Gallery ==\n\n\t\t\n\t\t\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Bibliography ==\nS. Bochner (June 1963), \"The significance of some basic mathematical conceptions for physics\", Isis, 54 (2): 179\u2013205; JSTOR 228537.\nM. Born and E. Wolf, 1970, Principles of Optics, 4th Ed., Oxford: Pergamon Press.\nC.B. Boyer, 1959, The Rainbow: From Myth to Mathematics, New York: Thomas Yoseloff.\nJ.Z. Buchwald (December 1980), \"Experimental investigations of double refraction from Huygens to Malus\", Archive for History of Exact Sciences, 21 (4): 311\u2013373.\nJ.Z. Buchwald, 1989, The Rise of the Wave Theory of Light: Optical Theory and Experiment in the Early Nineteenth Century, University of Chicago Press, ISBN 0-226-07886-8.\nO. Darrigol, 2012, A History of Optics: From Greek Antiquity to the Nineteenth Century, Oxford, ISBN 978-0-19-964437-7.\nR. Fitzpatrick, 2013, Oscillations and Waves: An Introduction, Boca Raton, FL: CRC Press, ISBN 978-1-4665-6608-8.\nR. Fitzpatrick, 2013a, \"Total Internal Reflection\", University of Texas at Austin, accessed 14 March 2018.\nA. Fresnel, 1866\u200a (ed.\u2009 H. de Senarmont, E. Verdet, and L. Fresnel), Oeuvres compl\u00e8tes d'Augustin Fresnel, Paris: Imprimerie Imp\u00e9riale (3 vols., 1866\u201370), vol.\u20091 (1866).\nE. Hecht, 2017, Optics, 5th Ed., Pearson Education, ISBN 978-1-292-09693-3.\nC. Huygens, 1690, Trait\u00e9 de la Lumi\u00e8re (Leiden: Van der Aa), translated by S.P. Thompson as Treatise on Light, University of Chicago Press, 1912; Project Gutenberg, 2005. (Cited page numbers match the 1912 edition and the Gutenberg HTML edition.)\nF.A. Jenkins and H.E. White, 1976, Fundamentals of Optics, 4th Ed., New York: McGraw-Hill, ISBN 0-07-032330-5.\nT.H. Levitt, 2013, A Short Bright Flash: Augustin Fresnel and the Birth of the Modern Lighthouse, New York: W.W. Norton, ISBN 978-0-393-35089-0.\nH. Lloyd, 1834, \"Report on the progress and present state of physical optics\", Report of the Fourth Meeting of the British Association for the Advancement of Science (held at Edinburgh in 1834), London: J. Murray, 1835, pp.\u202f295\u2013413.\nI. Newton, 1730, Opticks: or, a Treatise of the Reflections, Refractions, Inflections, and Colours of Light, 4th Ed. (London: William Innys, 1730; Project Gutenberg, 2010); republished with foreword by A. Einstein and Introduction by E.T. Whittaker (London: George Bell & Sons, 1931); reprinted with additional Preface by I.B. Cohen and Analytical Table of Contents by D.H.D. Roller,  Mineola, NY: Dover, 1952, 1979 (with revised preface), 2012. (Cited page numbers match the Gutenberg HTML edition and the Dover editions.)\nH.G.J. Rutten and M.A.M.\u2009van Venrooij, 1988 (fifth printing, 2002), Telescope Optics: A Comprehensive Manual for Amateur Astronomers, Richmond,\u202fVA: Willmann-Bell, ISBN 978-0-943396-18-7.\nJ.A. Stratton, 1941, Electromagnetic Theory, New York: McGraw-Hill.\nW. Whewell, 1857, History of the Inductive Sciences: From the Earliest to the Present Time, 3rd Ed., London: J.W. Parker & Son, vol.\u202f2.\nE. T. Whittaker, 1910, [https://archive.org/details/historyoftheorie00whitrich A History of the Theories of Aether and Electricity: From the Age of Descartes to the Close of the Nineteenth Century, London: Longmans, Green, & Co.\n\n\n== External links ==\n\nMr. Mangiacapre, \"Fluorescence in a Liquid\" (video, 1m\u200d28s), uploaded 13 March 2012.\u2009 (Fluorescence and TIR of a violet laser beam in quinine water.)\nPhysicsatUVM, \"Frustrated Total Internal Reflection\" (video, 37s), uploaded 21 November 2011.\u2009 (\"A laser beam undergoes total internal reflection in a fogged piece of plexiglass...\")\nSMUPhysics, \"Internal Reflection\" (video, 12s), uploaded 20 May 2010.\u2009 (Transition from refraction through critical angle to TIR in a 45\u00b0-90\u00b0-45\u00b0 prism.)", "Plasticity_(physics)": "In physics and materials science, plasticity (also known as plastic deformation) is the ability of a solid material to undergo permanent deformation, a non-reversible change of shape in response to applied forces.  For example, a solid piece of metal being bent or pounded into a new shape displays plasticity as permanent changes occur within the material itself. In engineering, the transition from elastic behavior to plastic behavior is known as yielding.\nPlastic deformation is observed in most materials, particularly metals, soils, rocks, concrete, and foams. However, the physical mechanisms that cause plastic deformation can vary widely.  At a crystalline scale, plasticity in metals is usually a consequence of dislocations. Such defects are relatively rare in most crystalline materials, but are numerous in some and part of their crystal structure; in such cases, plastic crystallinity can result. In brittle materials such as rock, concrete and bone, plasticity is caused predominantly by slip at microcracks. In cellular materials such as liquid foams or biological tissues, plasticity is mainly a consequence of bubble or cell rearrangements, notably T1 processes.\nFor many ductile metals, tensile loading applied to a sample will cause it to behave in an elastic manner.  Each increment of load is accompanied by a proportional increment in extension. When the load is removed, the piece returns to its original size.  However, once the load exceeds a threshold \u2013 the yield strength \u2013 the extension increases more rapidly than in the elastic region; now when the load is removed, some degree of extension will remain.\nElastic deformation, however, is an approximation and its quality depends on the time frame considered and loading speed. If, as indicated in the graph opposite, the deformation includes elastic deformation, it is also often referred to as \"elasto-plastic deformation\" or \"elastic-plastic deformation\".\nPerfect plasticity is a property of materials to undergo irreversible deformation without any increase in stresses or loads.  Plastic materials that have been hardened by prior deformation, such as cold forming, may need increasingly higher stresses to deform further.  Generally, plastic deformation is also dependent on the deformation speed, i.e. higher stresses usually have to be applied to increase the rate of deformation. Such materials are said to deform visco-plastically.\n\n\n== Contributing properties ==\nThe plasticity of a material is directly proportional to the ductility and malleability of the material.\n\n\n== Physical mechanisms ==\n\n\n=== In metals ===\nPlasticity in a crystal of pure metal is primarily caused by two modes of deformation in the crystal lattice: slip and twinning. Slip is a shear deformation which moves the atoms through many interatomic distances relative to their initial positions.  Twinning is the plastic deformation which takes place along two planes due to a set of forces applied to a given metal piece.\nMost metals show more plasticity when hot than when cold. Lead shows sufficient plasticity at room temperature, while cast iron does not possess sufficient plasticity for any forging operation even when hot.  This property is of importance in forming, shaping and extruding operations on metals. Most metals are rendered plastic by heating and hence shaped hot.\n\n\n==== Slip systems ====\n\nCrystalline materials contain uniform planes of atoms organized with long-range order. Planes may slip past each other along their close-packed directions, as is shown on the slip systems page. The result is a permanent change of shape within the crystal and plastic deformation. The presence of dislocations increases the likelihood of planes.\n\n\n==== Reversible plasticity ====\nOn the nanoscale the primary plastic deformation in simple face-centered cubic metals is reversible, as long as there is no material transport in form of cross-slip. Shape-memory alloys such as Nitinol wire also exhibit a reversible form of plasticity which is more properly called pseudoelasticity.\n\n\n==== Shear banding ====\nThe presence of other defects within a crystal may entangle dislocations or otherwise prevent them from gliding. When this happens, plasticity is localized to particular regions in the material. For crystals, these regions of localized plasticity are called shear bands.\n\n\n==== Microplasticity ====\nMicroplasticity is a local phenomenon in metals. It occurs for stress values where the metal is globally in the elastic domain while some local areas are in the plastic domain.\n\n\n=== Amorphous materials ===\n\n\n==== Crazing ====\nIn amorphous materials, the discussion of \"dislocations\" is inapplicable, since the entire material lacks long range order. These materials can still undergo plastic deformation. Since amorphous materials, like polymers, are not well-ordered, they contain a large amount of free volume, or wasted space. Pulling these materials in tension opens up these regions and can give materials a hazy appearance. This haziness is the result of crazing, where fibrils are formed within the material in regions of high hydrostatic stress. The material may go from an ordered appearance to a \"crazy\" pattern of strain and stretch marks.\n\n\n=== Cellular materials ===\nThese materials plastically deform when the bending moment exceeds the fully plastic moment. This applies to open cell foams where the bending moment is exerted on the cell walls. The foams can be made of any material with a plastic yield point which includes rigid polymers and metals. This method of modeling the foam as beams is only valid if the ratio of the density of the foam to the density of the matter is less than 0.3. This is because beams yield axially instead of bending.  In closed cell foams, the yield strength is increased if the material is under tension because of the membrane that spans the face of the cells.\n\n\n=== Soils and sand ===\n\nSoils, particularly clays, display a significant amount of inelasticity under load.  The causes of plasticity in soils can be quite complex and are strongly dependent on the microstructure, chemical composition, and water content.  Plastic behavior in soils is caused primarily by the rearrangement of clusters of adjacent grains.\n\n\n=== Rocks and concrete ===\n\nInelastic deformations of rocks and concrete are primarily caused by the formation of microcracks and sliding motions relative to these cracks.  At high temperatures and pressures, plastic behavior can also be affected by the motion of dislocations in individual grains in the microstructure.\n\n\n== Time-independent yielding and plastic flow in crystalline materials ==\nTime-independent plastic flow in both single crystals and polycrystals is defined by a critical/maximum resolved shear stress (\u03c4CRSS), initiating dislocation migration along parallel slip planes of a single slip system, thereby defining the transition from elastic to plastic deformation behavior in crystalline materials.\n\n\n=== Time-independent yielding and plastic flow in single crystals ===\nThe critical resolved shear stress for single crystals is defined by Schmid\u2019s law \u03c4CRSS=\u03c3y/m, where \u03c3y is the yield strength of the single crystal and m is the Schmid factor. The Schmid factor comprises two variables \u03bb and \u03c6, defining the angle between the slip plane direction and the tensile force applied, and the angle between the slip plane normal and the tensile force applied, respectively. Notably, because m > 1, \u03c3y > \u03c4CRSS.\n\n\n==== Critical resolved shear stress dependence on temperature, strain rate, and point defects ====\nThere are three characteristic regions of the critical resolved shear stress as a function of temperature. In the low temperature region 1 (T \u2264 0.25Tm), the strain rate \u03ad must be high to achieve high \u03c4CRSS which is required to initiate dislocation glide and equivalently plastic flow. In region 1, the critical resolved shear stress has two components: athermal (\u03c4a) and thermal (\u03c4*) shear stresses, arising from the stress required to move dislocations in the presence of other dislocations, and the resistance of point defect obstacles to dislocation migration, respectively. At T = T*, the moderate temperature region 2 (0.25Tm < T < 0.7Tm) is defined, where the thermal shear stress component \u03c4* \u2192 0, representing the elimination of point defect impedance to dislocation migration. Thus the temperature-independent critical resolved shear stress \u03c4CRSS = \u03c4a remains so until region 3 is defined. Notably, in region 2 moderate temperature time-dependent plastic deformation (creep) mechanisms such as solute-drag should be considered. Furthermore, in the high temperature region 3 (T \u2265 0.7Tm) \u03ad can be low, contributing to low \u03c4CRSS, however plastic flow will still occur due to thermally activated high temperature time-dependent plastic deformation mechanisms such as Nabarro\u2013Herring (NH) and Coble diffusional flow through the lattice and along the single crystal surfaces, respectively, as well as dislocation climb-glide creep.\n\n\n==== Stages of time-independent plastic flow, post yielding ====\nDuring the easy glide stage 1, the work hardening rate, defined by the change in shear stress with respect to shear strain (d\u03c4/d\u03b3) is low, representative of a small amount of applied shear stress necessary to induce a large amount of shear strain. Facile dislocation glide and corresponding flow is attributed to dislocation migration along parallel slip planes only (i.e. one slip system). Moderate impedance to dislocation migration along parallel slip planes is exhibited according to the weak stress field interactions between these dislocations, which heightens with smaller interplanar spacing. Overall, these migrating dislocations within a single slip system act as weak obstacles to flow, and a modest rise in stress is observed in comparison to the yield stress. During the linear hardening stage 2 of flow, the work hardening rate becomes high as considerable stress is required to overcome the stress field interactions of dislocations migrating on non-parallel slip planes (i.e. multiple slip systems), acting as strong obstacles to flow. Much stress is required to drive continual dislocation migration for small strains. The shear flow stress is directly proportional to the square root of the dislocation density (\u03c4flow ~\u03c1\u00bd), irrespective of the evolution of dislocation configurations, displaying the reliance of hardening on the number of dislocations present. Regarding this evolution of dislocation configurations, at small strains the dislocation arrangement is a random 3D array of intersecting lines. Moderate strains correspond to cellular dislocation structures of heterogeneous dislocation distribution with large dislocation density at the cell boundaries, and small dislocation density within the cell interior. At even larger strains the cellular dislocation structure reduces in size until a minimum size is achieved. Finally, the work hardening rate becomes low again in the exhaustion/saturation of hardening stage 3 of plastic flow, as small shear stresses produce large shear strains. Notably, instances when multiple slip systems are oriented favorably with respect to the applied stress, the \u03c4CRSS for these systems may be similar and yielding may occur according to dislocation migration along multiple slip systems with non-parallel slip planes, displaying a stage 1 work-hardening rate typically characteristic of stage 2. Lastly, distinction between time-independent plastic deformation in body-centered cubic transition metals and face centered cubic metals is summarized below.\n\n\n=== Time-independent yielding and plastic flow in polycrystals ===\nPlasticity in polycrystals differs substantially from that in single crystals due to the presence of grain boundary (GB) planar defects, which act as very strong obstacles to plastic flow by impeding dislocation migration along the entire length of the activated slip plane(s). Hence, dislocations cannot pass from one grain to another across the grain boundary. The following sections explore specific GB requirements for extensive plastic deformation of polycrystals prior to fracture, as well as the influence of microscopic yielding within individual crystallites on macroscopic yielding of the polycrystal. The critical resolved shear stress for polycrystals is defined by Schmid\u2019s law as well (\u03c4CRSS=\u03c3y/\u1e41), where \u03c3y is the yield strength of the polycrystal and \u1e41 is the weighted Schmid factor. The weighted Schmid factor reflects the least favorably oriented slip system among the most favorably oriented slip systems of the grains constituting the GB. \n\n\n==== Grain boundary constraint in polycrystals ====\nThe GB constraint for polycrystals can be explained by considering a grain boundary in the xz plane between two single crystals A and B of identical composition, structure, and slip systems, but misoriented with respect to each other. To ensure that voids do not form between individually deforming grains, the GB constraint for the bicrystal is as follows:\n\u03b5xxA = \u03b5xxB (the x-axial strain at the GB must be equivalent for A and B), \u03b5zzA = \u03b5zzB (the z-axial strain at the GB must be equivalent for A and B), and \u03b5xzA = \u03b5xzB (the xz shear strain along the xz-GB plane must be equivalent for A and B). In addition, this GB constraint requires that five independent slip systems be activated per crystallite constituting the GB. Notably, because independent slip systems are defined as slip planes on which dislocation migrations cannot be reproduced by any combination of dislocation migrations along other slip system\u2019s planes, the number of geometrical slip systems for a given crystal system - which by definition can be constructed by slip system combinations - is typically greater than that of independent slip systems. Significantly, there is a maximum of five independent slip systems for each of the seven crystal systems, however, not all seven crystal systems acquire this upper limit. In fact, even within a given crystal system, the composition and Bravais lattice diversifies the number of independent slip systems (see the table below). In cases for which crystallites of a polycrystal do not obtain five independent slip systems, the GB condition cannot be met, and thus the time-independent deformation of individual crystallites results in cracks and voids at the GBs of the polycrystal, and soon fracture is realized. Hence, for a given composition and structure, a single crystal with less than five independent slip systems is stronger (exhibiting a greater extent of plasticity) than its polycrystalline form.\n\n\n==== Implications of the grain boundary constraint in polycrystals ====\nAlthough the two crystallites A and B discussed in the above section have identical slip systems, they are misoriented with respect to each other, and therefore misoriented with respect to the applied force. Thus, microscopic yielding within a crystallite interior may occur according to the rules governing single crystal time-independent yielding. Eventually, the activated slip planes within the grain interiors will permit dislocation migration to the GB where many dislocations then pile up as geometrically necessary dislocations. This pile up corresponds to strain gradients across individual grains as the dislocation density near the GB is greater than that in the grain interior, imposing a stress on the adjacent grain in contact. When considering the AB bicrystal as a whole, the most favorably oriented slip system in A will not be the that in B, and hence \u03c4ACRSS \u2260 \u03c4BCRSS. Paramount is the fact that macroscopic yielding of the bicrystal is prolonged until the higher value of \u03c4CRSS between grains A and B is achieved, according to the GB constraint. Thus, for a given composition and structure, a polycrystal with five independent slip systems is stronger (greater extent of plasticity) than its single crystalline form. Correspondingly, the work hardening rate will be higher for the polycrystal than the single crystal, as more stress is required in the polycrystal to produce strains. Importantly, just as with single crystal flow stress, \u03c4flow ~\u03c1\u00bd, but is also inversely proportional to the square root of average grain diameter (\u03c4flow ~d-\u00bd ). Therefore, the flow stress of a polycrystal, and hence the polycrystal\u2019s strength, increases with small grain size. The reason for this is that smaller grains have a relatively smaller number of slip planes to be activated, corresponding to a fewer number of dislocations migrating to the GBs, and therefore less stress induced on adjacent grains due to dislocation pile up. In addition, for a given volume of polycrystal, smaller grains present more strong obstacle grain boundaries. These two factors provide an understanding as to why the onset of macroscopic flow in fine-grained polycrystals occurs at larger applied stresses than in coarse-grained polycrystals.\n\n\n== Mathematical descriptions ==\n\n\n=== Deformation theory ===\n\nThere are several mathematical descriptions of plasticity. One is deformation theory (see e.g. Hooke's law) where the Cauchy stress tensor (of order d-1 in d dimensions) is a function of the strain tensor. Although this description is accurate when a small part of matter is subjected to increasing loading (such as strain loading), this theory cannot account for irreversibility.\nDuctile materials can sustain large plastic deformations without fracture.  However, even ductile metals will fracture when the strain becomes large enough\u2014this is as a result of work hardening of the material, which causes it to become brittle.  Heat treatment such as annealing can restore the ductility of a worked piece, so that shaping can continue.\n\n\n=== Flow plasticity theory ===\n\nIn 1934, Egon Orowan, Michael Polanyi and Geoffrey Ingram Taylor, roughly simultaneously, realized that the plastic deformation of ductile materials could be explained in terms of the theory of dislocations.  The mathematical theory of plasticity, flow plasticity theory, uses a set of non-linear, non-integrable equations to describe the set of changes on strain and stress with respect to a previous state and a small increase of deformation.\n\n\n== Yield criteria ==\n\nIf the stress exceeds a critical value, as was mentioned above, the material will undergo plastic, or irreversible, deformation. This critical stress can be tensile or compressive.  The Tresca and the von Mises criteria are commonly used to determine whether a material has yielded.  However, these criteria have proved inadequate for a large range of materials and several other yield criteria are also in widespread use.\n\n\n=== Tresca criterion ===\nThe Tresca criterion is based on the notion that when a material fails, it does so in shear, which is a relatively good assumption when considering metals. Given the principal stress state, we can use Mohr's circle to solve for the maximum shear stresses our material will experience and conclude that the material will fail if\n\n  \n    \n      \n        \n          \u03c3\n          \n            1\n          \n        \n        \u2212\n        \n          \u03c3\n          \n            3\n          \n        \n        \u2265\n        \n          \u03c3\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{1}-\\sigma _{3}\\geq \\sigma _{0}}\n  where \u03c31 is the maximum normal stress, \u03c33 is the minimum normal stress, and \u03c30 is the stress under which the material fails in uniaxial loading. A yield surface may be constructed, which provides a visual representation of this concept. Inside of the yield surface, deformation is elastic. On the surface, deformation is plastic. It is impossible for a material to have stress states outside its yield surface.\n\n\n=== Huber\u2013von Mises criterion ===\n\nThe Huber\u2013von Mises criterion is based on the Tresca criterion but takes into account the assumption that hydrostatic stresses do not contribute to material failure. M. T. Huber was the first who proposed the criterion of shear energy. Von Mises solves for an effective stress under uniaxial loading, subtracting out hydrostatic stresses, and states that all effective stresses greater than that which causes material failure in uniaxial loading will result in plastic deformation.\n\n  \n    \n      \n        \n          \u03c3\n          \n            v\n          \n          \n            2\n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        [\n        (\n        \n          \u03c3\n          \n            11\n          \n        \n        \u2212\n        \n          \u03c3\n          \n            22\n          \n        \n        \n          )\n          \n            2\n          \n        \n        +\n        (\n        \n          \u03c3\n          \n            22\n          \n        \n        \u2212\n        \n          \u03c3\n          \n            33\n          \n        \n        \n          )\n          \n            2\n          \n        \n        +\n        (\n        \n          \u03c3\n          \n            11\n          \n        \n        \u2212\n        \n          \u03c3\n          \n            33\n          \n        \n        \n          )\n          \n            2\n          \n        \n        +\n        6\n        (\n        \n          \u03c3\n          \n            23\n          \n          \n            2\n          \n        \n        +\n        \n          \u03c3\n          \n            31\n          \n          \n            2\n          \n        \n        +\n        \n          \u03c3\n          \n            12\n          \n          \n            2\n          \n        \n        )\n        ]\n      \n    \n    {\\displaystyle \\sigma _{v}^{2}={\\tfrac {1}{2}}[(\\sigma _{11}-\\sigma _{22})^{2}+(\\sigma _{22}-\\sigma _{33})^{2}+(\\sigma _{11}-\\sigma _{33})^{2}+6(\\sigma _{23}^{2}+\\sigma _{31}^{2}+\\sigma _{12}^{2})]}\n  Again, a visual representation of the yield surface may be constructed using the above equation, which takes the shape of an ellipse. Inside the surface, materials undergo elastic deformation. Reaching the surface means the material undergoes plastic deformations.\n\n\n== See also ==\nAtterberg limits\nPlastometer\nPoisson's ratio\n\n\n== References ==\n\n\n== Further reading ==\nAshby, M. F. (2001). \"Plastic Deformation of Cellular Materials\". Encyclopedia of Materials: Science and Technology. Vol. 7. Oxford: Elsevier. pp. 7068\u20137071. ISBN 0-08-043152-6.\nHan, W.; Reddy, B. D. (2013). Plasticity: Mathematical Theory and Numerical Analysis (2nd ed.). New York: Springer. ISBN 978-1-4614-5939-2.\nKachanov, L. M. (2004). Fundamentals of the Theory of Plasticity. Dover Books. ISBN 0-486-43583-0.\nKhan, A. S.; Huang, S. (1995). Continuum Theory of Plasticity. Wiley. ISBN 0-471-31043-3.\nSimo, J. C.; Hughes, T. J. (1998). Computational Inelasticity. Springer. ISBN 0-387-97520-9.\nVan Vliet, K. J. (2006). \"Mechanical Behavior of Materials\". MIT Course Number 3.032. Massachusetts Institute of Technology.", "Elasticity_(physics)": "In physics and materials science, elasticity is the ability of a body to resist a distorting influence and to return to its original size and shape when that influence or force is removed. Solid objects will deform when adequate loads are applied to them; if the material is elastic, the object will return to its initial shape and size after removal. This is in contrast to plasticity, in which the object fails to do so and instead remains in its deformed state.\nThe physical reasons for elastic behavior can be quite different for different materials. In metals, the atomic lattice changes size and shape when forces are applied (energy is added to the system).  When forces are removed, the lattice goes back to the original lower energy state. For rubbers and other polymers, elasticity is caused by the stretching of polymer chains when forces are applied.\nHooke's law states that the force required to deform elastic objects should be directly proportional to the distance of deformation, regardless of how large that distance becomes. This is known as perfect elasticity, in which a given object will return to its original shape no matter how strongly it is deformed. This is an ideal concept only; most materials which possess elasticity in practice remain purely elastic only up to very small deformations, after which plastic (permanent) deformation occurs.\nIn engineering, the elasticity of a material is quantified by the elastic modulus such as the Young's modulus, bulk modulus or shear modulus which measure the amount of stress needed to achieve a unit of strain; a higher modulus indicates that the material is harder to deform. The SI unit of this modulus is the pascal (Pa). The material's elastic limit or yield strength is the maximum stress that can arise before the onset of plastic deformation. Its SI unit is also the pascal (Pa).\n\n\n== Overview ==\nWhen an elastic material is deformed due to an external force, it experiences internal resistance to the deformation and restores it to its original state if the external force is no longer applied. There are various elastic moduli, such as Young's modulus, the shear modulus, and the bulk modulus, all of which are measures of the inherent elastic properties of a material as a resistance to deformation under an applied load. The various moduli apply to different kinds of deformation. For instance, Young's modulus applies to extension/compression of a body, whereas the shear modulus applies to its shear. Young's modulus and shear modulus are only for solids, whereas the bulk modulus is for solids, liquids, and gases.\nThe elasticity of materials is described by a stress\u2013strain curve, which shows the relation between stress (the average restorative internal force per unit area) and strain (the relative deformation). The curve is generally nonlinear, but it can (by use of a Taylor series) be approximated as linear for sufficiently small deformations (in which higher-order terms are negligible). If the material is isotropic, the linearized stress\u2013strain relationship is called Hooke's law, which is often presumed to apply up to the elastic limit for most metals or crystalline materials whereas nonlinear elasticity is generally required to model large deformations of rubbery materials even in the elastic range. For even higher stresses, materials exhibit plastic behavior, that is, they deform irreversibly and do not return to their original shape after stress is no longer applied. For rubber-like materials such as elastomers, the slope of the stress\u2013strain curve increases with stress, meaning that rubbers progressively become more difficult to stretch, while for most metals, the gradient decreases at very high stresses, meaning that they progressively become easier to stretch. Elasticity is not exhibited only by solids; non-Newtonian fluids, such as viscoelastic fluids, will also exhibit elasticity in certain conditions quantified by the Deborah number. In response to a small, rapidly applied and removed strain, these fluids may deform and then return to their original shape. Under larger strains, or strains applied for longer periods of time, these fluids may start to flow like a viscous liquid.\nBecause the elasticity of a material is described in terms of a stress\u2013strain relation, it is essential that the terms stress and strain be defined without ambiguity.  Typically, two types of relation are considered.  The first type deals with materials that are elastic only for small strains.  The second deals with materials that are not limited to small strains.  Clearly, the second type of relation is more general in the sense that it must include the first type as a special case.\nFor small strains, the measure of stress that is used is the Cauchy stress while the measure of strain that is used is the infinitesimal strain tensor; the resulting (predicted) material behavior is termed linear elasticity, which (for isotropic media) is called the generalized Hooke's law. Cauchy elastic materials and hypoelastic materials are models that extend Hooke's law to allow for the possibility of large rotations, large distortions, and intrinsic or induced anisotropy.\nFor more general situations, any of a number of stress measures can be used, and it is generally desired (but not required) that the elastic stress\u2013strain relation be phrased in terms of a finite strain measure that is work conjugate to the selected stress measure, i.e., the time integral of the inner product of the stress measure with the rate of the strain measure should be equal to the change in internal energy for any adiabatic process that remains below the elastic limit.\n\n\n== Units ==\n\n\n=== International System ===\nThe SI unit for elasticity and the elastic modulus is the pascal (Pa). This unit is defined as force per unit area, generally a measurement of pressure, which in mechanics corresponds to stress. The pascal and therefore elasticity have the dimension L\u22121\u22c5M\u22c5T\u22122.\nFor most commonly used engineering materials, the elastic modulus is on the scale of gigapascals (GPa, 109 Pa).\n\n\n== Linear elasticity ==\n\nAs noted above, for small deformations, most elastic materials such as springs exhibit linear elasticity and can be described by a linear relation between the stress and strain. This relationship is known as Hooke's law.  A geometry-dependent version of the idea was first formulated by Robert Hooke in 1675 as a Latin anagram, \"ceiiinosssttuv\". He published the answer in 1678: \"Ut tensio, sic vis\" meaning \"As the extension, so the force\", a linear relationship commonly referred to as Hooke's law. This law can be stated as a relationship between tensile force F and corresponding extension displacement x,\n\n  \n    \n      \n        F\n        =\n        k\n        x\n        ,\n      \n    \n    {\\displaystyle F=kx,}\n  where k is a constant known as the rate or spring constant. It can also be stated as a relationship between stress \u03c3 and strain \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  :\n\n  \n    \n      \n        \u03c3\n        =\n        E\n        \u03b5\n        ,\n      \n    \n    {\\displaystyle \\sigma =E\\varepsilon ,}\n  where E is known as the elastic modulus or Young's modulus.\nAlthough the general proportionality constant between stress and strain in three dimensions is a 4th-order tensor called stiffness, systems that exhibit symmetry, such as a one-dimensional rod, can often be reduced to applications of Hooke's law.\n\n\n== Finite elasticity ==\nThe elastic behavior of objects that undergo finite deformations has been described using a number of models, such as Cauchy elastic material models, Hypoelastic material models, and Hyperelastic material models. The deformation gradient (F) is the primary deformation measure used in finite strain theory.\n\n\n=== Cauchy elastic materials ===\n\nA material is said to be Cauchy-elastic if the Cauchy stress tensor \u03c3 is a function of the deformation gradient  F alone:\n\n  \n    \n      \n         \n        \n          \u03c3\n        \n        =\n        \n          \n            G\n          \n        \n        (\n        \n          F\n        \n        )\n      \n    \n    {\\displaystyle \\ {\\boldsymbol {\\sigma }}={\\mathcal {G}}({\\boldsymbol {F}})}\n  It is generally incorrect to state that Cauchy stress is a function of merely a strain tensor, as such a model lacks crucial information about material rotation needed to produce correct results for an anisotropic medium subjected to vertical extension in comparison to the same extension applied horizontally and then subjected to a 90-degree rotation; both these deformations have the same spatial strain tensors yet must produce different values of the Cauchy stress tensor.\nEven though the stress in a Cauchy-elastic material depends only on the state of deformation, the work done by stresses might depend on the path of deformation. Therefore, Cauchy elasticity includes non-conservative \"non-hyperelastic\" models (in which work of deformation is path dependent) as well as conservative \"hyperelastic material\" models (for which stress can be derived from a scalar \"elastic potential\" function).\n\n\n=== Hypoelastic materials ===\n\nA hypoelastic material can be rigorously defined as one that is modeled using a constitutive equation satisfying the following two criteria:\nThe Cauchy stress \n  \n    \n      \n        \n          \u03c3\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\sigma }}}\n   at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   depends only on the order in which the body has occupied its past configurations, but not on the time rate at which these past configurations were traversed. As a special case, this criterion includes a Cauchy elastic material, for which the current stress depends only on the current configuration rather than the history of past configurations.\nThere is a tensor-valued function \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   such that \n  \n    \n      \n        \n          \n            \n              \u03c3\n              \u02d9\n            \n          \n        \n        =\n        G\n        (\n        \n          \u03c3\n        \n        ,\n        \n          L\n        \n        )\n        \n        ,\n      \n    \n    {\\displaystyle {\\dot {\\boldsymbol {\\sigma }}}=G({\\boldsymbol {\\sigma }},{\\boldsymbol {L}})\\,,}\n   in which \n  \n    \n      \n        \n          \n            \n              \u03c3\n              \u02d9\n            \n          \n        \n      \n    \n    {\\displaystyle {\\dot {\\boldsymbol {\\sigma }}}}\n   is the material rate of the Cauchy stress tensor, and \n  \n    \n      \n        \n          L\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {L}}}\n   is the spatial velocity gradient tensor.If only these two original criteria are used to define hypoelasticity, then hyperelasticity would be included as a special case, which prompts some constitutive modelers to append a third criterion that specifically requires a hypoelastic model to not be hyperelastic (i.e., hypoelasticity implies that stress is not derivable from an energy potential). If this third criterion is adopted, it follows that a hypoelastic material might admit nonconservative adiabatic loading paths that start and end with the same deformation gradient but do not start and end at the same internal energy.\nNote that the second criterion requires only that the function \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   exists. As detailed in the main hypoelastic material article, specific formulations of hypoelastic models typically employ so-called objective rates so that the \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   function exists only implicitly and is typically needed explicitly only for numerical stress updates performed via direct integration of the actual (not objective) stress rate.\n\n\n=== Hyperelastic materials ===\n\nHyperelastic materials (also called Green elastic materials) are conservative models that are derived from a strain energy density function (W).  A model is hyperelastic if and only if it is possible to express the Cauchy stress tensor as a function of the deformation gradient via a relationship of the form\n\n  \n    \n      \n        \n          \u03c3\n        \n        =\n        \n          \n            \n              \n                \n              \n              \n                \n                  1\n                \n              \n            \n            \n              \n                \n              \n              \n                \n                  J\n                \n              \n            \n          \n        \n         \n        \n          \n            \n              \n                \n              \n              \n                \n                  \u2202\n                  W\n                \n              \n            \n            \n              \n                \n              \n              \n                \n                  \u2202\n                  \n                    F\n                  \n                \n              \n            \n          \n        \n        \n          \n            F\n          \n          \n            \n              T\n            \n          \n        \n        \n        \n          where\n        \n        \n        J\n        :=\n        det\n        \n          F\n        \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {\\sigma }}={\\cfrac {1}{J}}~{\\cfrac {\\partial W}{\\partial {\\boldsymbol {F}}}}{\\boldsymbol {F}}^{\\textsf {T}}\\quad {\\text{where}}\\quad J:=\\det {\\boldsymbol {F}}\\,.}\n  This formulation takes the energy potential (W) as a function of the deformation gradient (\n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {F}}}\n  ). By also requiring satisfaction of material objectivity, the energy potential may be alternatively regarded as a function of the Cauchy-Green deformation tensor (\n  \n    \n      \n        \n          C\n        \n        :=\n        \n          \n            F\n          \n          \n            \n              T\n            \n          \n        \n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {C}}:={\\boldsymbol {F}}^{\\textsf {T}}{\\boldsymbol {F}}}\n  ), in which case the hyperelastic model may be written alternatively as\n\n  \n    \n      \n        \n          \u03c3\n        \n        =\n        \n          \n            \n              \n                \n              \n              \n                \n                  2\n                \n              \n            \n            \n              \n                \n              \n              \n                \n                  J\n                \n              \n            \n          \n        \n         \n        \n          F\n        \n        \n          \n            \n              \n                \n              \n              \n                \n                  \u2202\n                  W\n                \n              \n            \n            \n              \n                \n              \n              \n                \n                  \u2202\n                  \n                    C\n                  \n                \n              \n            \n          \n        \n        \n          \n            F\n          \n          \n            \n              T\n            \n          \n        \n        \n        \n          where\n        \n        \n        J\n        :=\n        det\n        \n          F\n        \n        \n        .\n      \n    \n    {\\displaystyle {\\boldsymbol {\\sigma }}={\\cfrac {2}{J}}~{\\boldsymbol {F}}{\\cfrac {\\partial W}{\\partial {\\boldsymbol {C}}}}{\\boldsymbol {F}}^{\\textsf {T}}\\quad {\\text{where}}\\quad J:=\\det {\\boldsymbol {F}}\\,.}\n  \n\n\n== Applications ==\nLinear elasticity is used widely in the design and analysis of structures such as beams, plates and shells, and sandwich composites.  This theory is also the basis of much of fracture mechanics.\nHyperelasticity is primarily used to determine the response of elastomer-based objects such as gaskets and of biological materials such as soft tissues and cell membranes.\n\n\n== Factors affecting elasticity ==\nFor isotropic materials, the presence of fractures affects the Young and the shear moduli perpendicular to the planes of the cracks, which decrease (Young's modulus faster than the shear modulus) as the fracture density increases, indicating that the presence of cracks makes bodies brittler. Microscopically, the stress\u2013strain relationship of materials is in general governed by the Helmholtz free energy, a thermodynamic quantity. Molecules settle in the configuration which minimizes the free energy, subject to constraints derived from their structure, and, depending on whether the energy or the entropy term dominates the free energy, materials can broadly be classified as energy-elastic and entropy-elastic. As such, microscopic factors affecting the free energy, such as the equilibrium distance between molecules, can affect the elasticity of materials: for instance, in inorganic materials, as the equilibrium distance between molecules at 0 K increases, the bulk modulus decreases. The effect of temperature on elasticity is difficult to isolate, because there are numerous factors affecting it. For instance, the bulk modulus of a material is dependent on the form of its lattice, its behavior under expansion, as well as the vibrations of the molecules, all of which are dependent on temperature.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\nThe Feynman Lectures on Physics Vol. II Ch. 38: Elasticity", "Phase_velocity": "The phase velocity of a wave is the rate at which the wave propagates in any medium. This is the velocity at which the phase of any one frequency component of the wave travels. For such a component, any given phase of the wave (for example, the crest) will appear to travel at the phase velocity. The phase velocity is given in terms of the wavelength \u03bb (lambda) and time period T as\n\n  \n    \n      \n        \n          v\n          \n            \n              p\n            \n          \n        \n        =\n        \n          \n            \u03bb\n            T\n          \n        \n        .\n      \n    \n    {\\displaystyle v_{\\mathrm {p} }={\\frac {\\lambda }{T}}.}\n  Equivalently, in terms of the wave's angular frequency \u03c9, which specifies angular change per unit of time, and wavenumber (or angular wave number) k, which represent the angular change per unit of space,\n\n  \n    \n      \n        \n          v\n          \n            \n              p\n            \n          \n        \n        =\n        \n          \n            \u03c9\n            k\n          \n        \n        .\n      \n    \n    {\\displaystyle v_{\\mathrm {p} }={\\frac {\\omega }{k}}.}\n  To gain some basic intuition for this equation, we consider a propagating (cosine) wave A cos(kx \u2212 \u03c9t). We want to see how fast a particular phase of the wave travels. For example, we can choose kx - \u03c9t = 0, the phase of the first crest. This implies  kx = \u03c9t, and so  v = x / t = \u03c9 / k. \nFormally, we let the phase \u03c6 = kx - \u03c9t and see immediately that  \u03c9 = -d\u03c6 / dt and  k = d\u03c6 / dx. So, it immediately follows that  \n\n  \n    \n      \n        \n          \n            \n              \u2202\n              x\n            \n            \n              \u2202\n              t\n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              \u2202\n              \u03d5\n            \n            \n              \u2202\n              t\n            \n          \n        \n        \n          \n            \n              \u2202\n              x\n            \n            \n              \u2202\n              \u03d5\n            \n          \n        \n        =\n        \n          \n            \u03c9\n            k\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\partial x}{\\partial t}}=-{\\frac {\\partial \\phi }{\\partial t}}{\\frac {\\partial x}{\\partial \\phi }}={\\frac {\\omega }{k}}.}\n  As a result we observe a inverse relation between the angular frequency and wavevector. If the wave has higher frequency oscillations, the wave length must be shortened for the phase velocity to remain constant. Additionally, the phase velocity of electromagnetic radiation may \u2013 under certain circumstances (for example anomalous dispersion) \u2013 exceed the speed of light in vacuum, but this does not indicate any superluminal information or energy transfer. It was theoretically described by physicists such as Arnold Sommerfeld and L\u00e9on Brillouin.\nThe previous definition of phase velocity has been demonstrated for an isolated wave. However, such a definition can be extended to a beat of waves, or to a signal composed of multiple waves. For this it is necessary to mathematically write the beat or signal as a low frequency envelope multiplying a carrier. Thus the phase velocity of the carrier determines the phase velocity of the wave set.\n\n\n== Group velocity ==\n\nThe group velocity of a collection of waves is defined as\n\n  \n    \n      \n        \n          v\n          \n            g\n          \n        \n        =\n        \n          \n            \n              \u2202\n              \u03c9\n            \n            \n              \u2202\n              k\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle v_{g}={\\frac {\\partial \\omega }{\\partial k}}.}\n  When multiple sinusoidal waves are propagating together, the resultant superposition of the waves can result in an \"envelope\" wave as well as a \"carrier\" wave that lies inside the envelope. This commonly appears in wireless communications, modulation, a change in amplitude and/or phase is employed to send data. To gain some intuition for this definition, we consider a superposition of (cosine) waves f(x, t) with their respective angular frequencies and wavevectors. \n\n  \n    \n      \n        \n          \n            \n              \n                f\n                (\n                x\n                ,\n                t\n                )\n              \n              \n                \n                =\n                cos\n                \u2061\n                (\n                \n                  k\n                  \n                    1\n                  \n                \n                x\n                \u2212\n                \n                  \u03c9\n                  \n                    1\n                  \n                \n                t\n                )\n                +\n                cos\n                \u2061\n                (\n                \n                  k\n                  \n                    2\n                  \n                \n                x\n                \u2212\n                \n                  \u03c9\n                  \n                    2\n                  \n                \n                t\n                )\n              \n            \n            \n              \n              \n                \n                =\n                2\n                cos\n                \u2061\n                \n                  (\n                  \n                    \n                      \n                        (\n                        \n                          k\n                          \n                            2\n                          \n                        \n                        \u2212\n                        \n                          k\n                          \n                            1\n                          \n                        \n                        )\n                        x\n                        \u2212\n                        (\n                        \n                          \u03c9\n                          \n                            2\n                          \n                        \n                        \u2212\n                        \n                          \u03c9\n                          \n                            1\n                          \n                        \n                        )\n                        t\n                      \n                      2\n                    \n                  \n                  )\n                \n                cos\n                \u2061\n                \n                  (\n                  \n                    \n                      \n                        (\n                        \n                          k\n                          \n                            2\n                          \n                        \n                        +\n                        \n                          k\n                          \n                            1\n                          \n                        \n                        )\n                        x\n                        \u2212\n                        (\n                        \n                          \u03c9\n                          \n                            2\n                          \n                        \n                        +\n                        \n                          \u03c9\n                          \n                            1\n                          \n                        \n                        )\n                        t\n                      \n                      2\n                    \n                  \n                  )\n                \n              \n            \n            \n              \n              \n                \n                =\n                2\n                \n                  f\n                  \n                    1\n                  \n                \n                (\n                x\n                ,\n                t\n                )\n                \n                  f\n                  \n                    2\n                  \n                \n                (\n                x\n                ,\n                t\n                )\n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}f(x,t)&=\\cos(k_{1}x-\\omega _{1}t)+\\cos(k_{2}x-\\omega _{2}t)\\\\&=2\\cos \\left({\\frac {(k_{2}-k_{1})x-(\\omega _{2}-\\omega _{1})t}{2}}\\right)\\cos \\left({\\frac {(k_{2}+k_{1})x-(\\omega _{2}+\\omega _{1})t}{2}}\\right)\\\\&=2f_{1}(x,t)f_{2}(x,t).\\end{aligned}}}\n  So, we have a product of two waves: an envelope wave formed by  f1  and a carrier wave formed by  f2 . We call the velocity of the envelope wave the group velocity. We see that the phase velocity of  f1  is  \n\n  \n    \n      \n        \n          \n            \n              \n                \u03c9\n                \n                  2\n                \n              \n              \u2212\n              \n                \u03c9\n                \n                  1\n                \n              \n            \n            \n              \n                k\n                \n                  2\n                \n              \n              \u2212\n              \n                k\n                \n                  1\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {\\omega _{2}-\\omega _{1}}{k_{2}-k_{1}}}.}\n  In the continuous differential case, this becomes the definition of the group velocity.\n\n\n== Refractive index ==\nIn the context of electromagnetics and optics, the frequency is some function \u03c9(k) of the wave number, so in general, the phase velocity and the group velocity depend on specific medium and frequency. The ratio between the speed of light c and the phase velocity vp is known as the refractive index, n = c / vp = ck / \u03c9. \nIn this way, we can obtain another form for group velocity for electromagnetics. Writing  n = n(\u03c9), a quick way to derive this form is to observe\n\n  \n    \n      \n        k\n        =\n        \n          \n            1\n            c\n          \n        \n        \u03c9\n        n\n        (\n        \u03c9\n        )\n        \n        \u27f9\n        \n        d\n        k\n        =\n        \n          \n            1\n            c\n          \n        \n        \n          (\n          \n            n\n            (\n            \u03c9\n            )\n            +\n            \u03c9\n            \n              \n                \u2202\n                \n                  \u2202\n                  \u03c9\n                \n              \n            \n            n\n            (\n            \u03c9\n            )\n          \n          )\n        \n        d\n        \u03c9\n        .\n      \n    \n    {\\displaystyle k={\\frac {1}{c}}\\omega n(\\omega )\\implies dk={\\frac {1}{c}}\\left(n(\\omega )+\\omega {\\frac {\\partial }{\\partial \\omega }}n(\\omega )\\right)d\\omega .}\n  We can then rearrange the above to obtain \n\n  \n    \n      \n        \n          v\n          \n            g\n          \n        \n        =\n        \n          \n            \n              \u2202\n              w\n            \n            \n              \u2202\n              k\n            \n          \n        \n        =\n        \n          \n            c\n            \n              n\n              +\n              \u03c9\n              \n                \n                  \n                    \u2202\n                    n\n                  \n                  \n                    \u2202\n                    \u03c9\n                  \n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle v_{g}={\\frac {\\partial w}{\\partial k}}={\\frac {c}{n+\\omega {\\frac {\\partial n}{\\partial \\omega }}}}.}\n  From this formula, we see that the group velocity is equal to the phase velocity only when the refractive index is a constant dn / dk = 0. When this occurs, the medium is called non-dispersive, as opposed to dispersive, where various properties of the medium depend on the frequency \u03c9. The relation \u03c9 = \u03c9(k) is known as the dispersion relation of the medium.\n\n\n== See also ==\n\n\n== References ==\n\n\n=== Footnotes ===\n\n\n=== Bibliography ===", "Fracture": "Fracture is the separation of an object or material into two or more pieces under the action of stress. The fracture of a solid usually occurs due to the development of certain displacement discontinuity surfaces within the solid. If a displacement develops perpendicular to the surface, it is called a normal tensile crack or simply a crack; if a displacement develops tangentially, it is called a shear crack, slip band or dislocation.Brittle fractures occur without any apparent deformation before fracture. Ductile fractures occur after visible deformation. Fracture strength, or breaking strength, is the stress when a specimen fails or fractures. The detailed understanding of how a fracture occurs and develops in materials is the object of fracture mechanics.\n\n\n== Strength ==\n\nFracture strength, also known as breaking strength, is the stress at which a specimen fails via fracture. This is usually determined for a given specimen by a tensile test, which charts the stress\u2013strain curve (see image). The final recorded point is the fracture strength.\nDuctile materials have a fracture strength lower than the ultimate tensile strength (UTS), whereas in brittle materials the fracture strength is equivalent to the UTS. If a ductile material reaches its ultimate tensile strength in a load-controlled situation, it will continue to deform, with no additional load application, until it ruptures.  However, if the loading is displacement-controlled, the deformation of the material may relieve the load, preventing rupture.\nThe statistics of fracture in random materials have very intriguing behavior, and was noted by the architects and engineers quite early. Indeed, fracture or breakdown studies might be the oldest physical science studies, which still remain intriguing and very much alive. Leonardo da Vinci, more than 500 years ago, observed that the tensile strengths of nominally identical specimens of iron wire decrease with increasing length of the wires (see e.g., for a recent discussion). Similar observations were made by Galileo Galilei more than 400 years ago. This is the manifestation of the extreme statistics of failure (bigger sample volume can have larger defects due to cumulative fluctuations where failures nucleate and induce lower strength of the sample).\n\n\n== Types ==\nThere are two types of fractures: brittle and ductile fractures respectively without or with plastic deformation prior to failure. \n\n\n=== Brittle ===\n\nIn brittle fracture, no apparent plastic deformation takes place before fracture. Brittle fracture typically involves little energy absorption and occurs at high speeds\u2014up to 2,133.6 m/s (7,000 ft/s) in steel. In most cases brittle fracture will continue even when loading is discontinued.In brittle crystalline materials, fracture can occur by cleavage as the result of tensile stress acting normal to crystallographic planes with low bonding (cleavage planes). In amorphous solids, by contrast, the lack of a crystalline structure results in a conchoidal fracture, with cracks proceeding normal to the applied tension.\nThe fracture strength (or micro-crack nucleation stress) of a  material was first theoretically estimated by Alan Arnold Griffith in 1921:\n\n  \n    \n      \n        \n          \u03c3\n          \n            \n              t\n              h\n              e\n              o\n              r\n              e\n              t\n              i\n              c\n              a\n              l\n            \n          \n        \n        =\n        \n          \n            \n              \n                E\n                \u03b3\n              \n              \n                r\n                \n                  o\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma _{\\mathrm {theoretical} }={\\sqrt {\\frac {E\\gamma }{r_{o}}}}}\n  where: \u2013\n\n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is the Young's modulus of the material,\n\n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is the surface energy, and\n\n  \n    \n      \n        \n          r\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle r_{o}}\n   is the micro-crack length (or equilibrium distance between atomic centers in a crystalline solid).On the other hand, a crack introduces a stress concentration modeled by Inglis's equation\n\n  \n    \n      \n        \n          \u03c3\n          \n            \n              e\n              l\n              l\n              i\n              p\n              t\n              i\n              c\n              a\n              l\n               \n              c\n              r\n              a\n              c\n              k\n            \n          \n        \n        =\n        \n          \u03c3\n          \n            \n              a\n              p\n              p\n              l\n              i\n              e\n              d\n            \n          \n        \n        \n          (\n          \n            1\n            +\n            2\n            \n              \n                \n                  a\n                  \u03c1\n                \n              \n            \n          \n          )\n        \n        =\n        2\n        \n          \u03c3\n          \n            \n              a\n              p\n              p\n              l\n              i\n              e\n              d\n            \n          \n        \n        \n          \n            \n              a\n              \u03c1\n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma _{\\mathrm {elliptical\\ crack} }=\\sigma _{\\mathrm {applied} }\\left(1+2{\\sqrt {\\frac {a}{\\rho }}}\\right)=2\\sigma _{\\mathrm {applied} }{\\sqrt {\\frac {a}{\\rho }}}}\n   (For sharp cracks)where: \u2013\n\n  \n    \n      \n        \n          \u03c3\n          \n            \n              a\n              p\n              p\n              l\n              i\n              e\n              d\n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma _{\\mathrm {applied} }}\n   is the loading stress,\n\n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n   is half the length of the crack, and\n\n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is the radius of curvature at the crack tip.Putting these two equations together gets\n\n  \n    \n      \n        \n          \u03c3\n          \n            \n              f\n              r\n              a\n              c\n              t\n              u\n              r\n              e\n            \n          \n        \n        =\n        \n          \n            \n              \n                E\n                \u03b3\n                \u03c1\n              \n              \n                4\n                a\n                \n                  r\n                  \n                    o\n                  \n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\sigma _{\\mathrm {fracture} }={\\sqrt {\\frac {E\\gamma \\rho }{4ar_{o}}}}.}\n  Sharp cracks (small \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n  ) and large defects (large \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  ) both lower the fracture strength of the material.\nRecently, scientists have discovered supersonic fracture, the phenomenon of crack propagation faster than the speed of sound in a material. This phenomenon was recently also verified by experiment of fracture in rubber-like materials.\nThe basic sequence in a typical brittle fracture is: introduction of a flaw either before or after the material is put in service, slow and stable crack propagation under recurring loading, and sudden rapid failure when the crack reaches critical crack length based on the conditions defined by fracture mechanics. Brittle fracture may be avoided by controlling three primary factors: material fracture toughness (Kc), nominal stress level (\u03c3), and introduced flaw size (a). Residual stresses, temperature, loading rate, and stress concentrations also contribute to brittle fracture by influencing the three primary factors.Under certain conditions, ductile materials can exhibit brittle behavior. Rapid loading, low temperature, and triaxial stress constraint conditions may cause ductile materials to fail without prior deformation.\n\n\n=== Ductile ===\n\nIn ductile fracture, extensive plastic deformation (necking) takes place before fracture. The terms \"rupture\" and \"ductile rupture\" describe the ultimate failure of ductile materials loaded in tension. The extensive plasticity causes the crack to propagate slowly due to the absorption of a large amount of energy before fracture.\n\nBecause ductile rupture involves a high degree of plastic deformation, the fracture behavior of a propagating crack as modelled above changes fundamentally. Some of the energy from stress concentrations at the crack tips is dissipated by plastic deformation ahead of the crack as it propagates.\nThe basic steps in ductile fracture are void formation, void coalescence (also known as crack formation), crack propagation, and failure, often resulting in a cup-and-cone shaped failure surface. Voids typically coalesce around precipitates, secondary phases, inclusions, and at grain boundaries in the material. Ductile fracture is typically transgranular and deformation due to dislocation slip can cause the shear lip characteristic of cup and cone fracture.\n\n\n== Characteristics ==\nThe manner in which a crack propagates through a material gives insight into the mode of fracture. With ductile fracture a crack moves slowly and is accompanied by a large amount of plastic deformation around the crack tip. A ductile crack will usually not propagate unless an increased stress is applied and generally cease propagating when loading is removed. In a ductile material, a crack may progress to a section of the material where stresses are slightly lower and stop due to the blunting effect of plastic deformations at the crack tip. On the other hand, with brittle fracture, cracks spread very rapidly with little or no plastic deformation. The cracks that propagate in a brittle material will continue to grow once initiated.\nCrack propagation is also categorized by the crack characteristics at the microscopic level. A crack that passes through the grains within the material is undergoing transgranular fracture. A crack that propagates along the grain boundaries is termed an intergranular fracture.  Typically, the bonds between material grains are stronger at room temperature than the material itself, so transgranular fracture is more likely to occur. When temperatures increase enough to weaken the grain bonds, intergranular fracture is the more common fracture mode.\n\n\n== Testing ==\nFracture in materials is studied and quantified in multiple ways. Fracture is largely determined by the fracture toughness (\n  \n    \n      \n        \n          \n            K\n          \n          \n            \n              c\n            \n          \n        \n      \n    \n    {\\textstyle \\mathrm {K} _{\\mathrm {c} }}\n  ), so fracture testing is often done to determine this. The two most widely used techniques for determining fracture toughness are the three-point flexural test and the compact tension test.\nBy performing the compact tension and three-point flexural tests, one is able to determine the fracture toughness through the following equation:\n\n  \n    \n      \n        \n          \n            K\n            \n              c\n            \n          \n        \n        =\n        \n          \u03c3\n          \n            \n              F\n            \n          \n        \n        \n          \n            \u03c0\n            \n              c\n            \n          \n        \n        \n          f\n           \n          (\n          c\n          \n            /\n          \n          a\n          )\n        \n      \n    \n    {\\displaystyle \\mathrm {K_{c}} =\\sigma _{\\mathrm {F} }{\\sqrt {\\pi \\mathrm {c} }}\\mathrm {f\\ (c/a)} }\n  Where:-\n\n  \n    \n      \n        \n          f\n           \n          (\n          c\n          \n            /\n          \n          a\n          )\n        \n      \n    \n    {\\displaystyle \\mathrm {f\\ (c/a)} }\n   is an empirically-derived equation to capture the test sample geometry\n\n  \n    \n      \n        \n          \u03c3\n          \n            \n              F\n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma _{\\mathrm {F} }}\n   is the fracture stress, and\n\n  \n    \n      \n        \n          c\n        \n      \n    \n    {\\displaystyle \\mathrm {c} }\n   is the crack length.To accurately attain \n  \n    \n      \n        \n          \n            K\n          \n          \n            \n              c\n            \n          \n        \n      \n    \n    {\\textstyle \\mathrm {K} _{\\mathrm {c} }}\n  , the value of \n  \n    \n      \n        \n          c\n        \n      \n    \n    {\\textstyle \\mathrm {c} }\n   must be precisely measured. This is done by taking the test piece with its fabricated notch of length \n  \n    \n      \n        \n          c\n          \u2032\n        \n      \n    \n    {\\textstyle \\mathrm {c\\prime } }\n   and sharpening this notch to better emulate a crack tip found in real-world materials. Cyclical prestressing the sample can then induce a fatigue crack which extends the crack from the fabricated notch length of \n  \n    \n      \n        \n          c\n          \u2032\n        \n      \n    \n    {\\textstyle \\mathrm {c\\prime } }\n    to \n  \n    \n      \n        \n          c\n        \n      \n    \n    {\\textstyle \\mathrm {c} }\n  . This value \n  \n    \n      \n        \n          c\n        \n      \n    \n    {\\textstyle \\mathrm {c} }\n   is used in the above equations for determining \n  \n    \n      \n        \n          \n            K\n          \n          \n            \n              c\n            \n          \n        \n      \n    \n    {\\textstyle \\mathrm {K} _{\\mathrm {c} }}\n  .Following this test, the sample can then be reoriented such that further loading of a load (F) will extend this crack and thus a load versus sample deflection curve can be obtained. With this curve, the slope of the linear portion, which is the inverse of the compliance of the material, can be obtained. This is then used to derive f(c/a) as defined above in the equation. With the knowledge of all these variables, \n  \n    \n      \n        \n          \n            K\n          \n          \n            \n              c\n            \n          \n        \n      \n    \n    {\\textstyle \\mathrm {K} _{\\mathrm {c} }}\n   can then be calculated.\n\n\n== Ceramics and inorganic glasses ==\nCeramics and inorganic glasses have fracturing behavior that differ those of metallic materials. Ceramics have high strengths and perform well in high temperatures due to the material strength being independent of temperature. Ceramics have low toughness as determined by testing under a tensile load; often, ceramics have \n  \n    \n      \n        \n          \n            K\n          \n          \n            \n              c\n            \n          \n        \n      \n    \n    {\\textstyle \\mathrm {K} _{\\mathrm {c} }}\n   values that are ~5% of that found in metals. However, as demonstrated by Faber and Evans, fracture toughness can be predicted and improved with crack deflection around second phase particles. Ceramics are usually loaded in compression in everyday use, so the compressive strength is often referred to as the strength; this strength can often exceed that of most metals. However, ceramics are brittle and thus most work done revolves around preventing brittle fracture. Due to how ceramics are manufactured and processed, there are often preexisting defects in the material introduce a high degree of variability in the Mode I brittle fracture. Thus, there is a probabilistic nature to be accounted for in the design of ceramics. The Weibull distribution predicts the survival probability of a fraction of samples with a certain volume that survive a tensile stress sigma, and is often used to better assess the success of a ceramic in avoiding fracture.\n\n\n== Fiber bundles ==\nTo model fracture of a bundle of fibers, the Fiber Bundle Model was introduced by Thomas Pierce  in 1926 as a model to understand the strength of composite materials. The bundle consists of a  large number of parallel Hookean springs of identical length and each having identical spring constants. They have however different breaking stresses. All these springs are suspended from a rigid horizontal platform. The load is attached  to a horizontal platform, connected to the lower ends of the springs. When this lower platform is absolutely rigid, the load at any point of time is shared equally (irrespective of how many fibers or springs have broken and where) by all the surviving fibers. This mode of load-sharing is called Equal-Load-Sharing mode. The lower platform can also be assumed to have finite rigidity, so that local deformation of the platform occurs wherever springs fail and the surviving neighbor fibers have to share a larger fraction of that transferred from the failed fiber. The extreme case is that of local load-sharing model, where load of the failed spring or fiber is shared (usually equally) by the surviving nearest neighbor fibers.\n\n\n== Disasters ==\nFailures caused by brittle fracture have not been limited to any particular category of engineered structure. Though brittle fracture is less common than other types of failure, the impacts to life and property can be more severe. The following notable historic failures were attributed to brittle fracture:\n\nPressure vessels: Great Molasses Flood in 1919, New Jersey molasses tank failure in 1973\nBridges: King Street Bridge span collapse in 1962, Silver Bridge collapse in 1967, partial failure of the Hoan Bridge in 2000\nShips: Titanic in 1912, Liberty ships during World War II, SS Schenectady in 1943\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nDieter, G. E. (1988) Mechanical Metallurgy ISBN 0-07-100406-8\nA. Garcimartin, A. Guarino, L. Bellon and S. Cilberto (1997) \" Statistical Properties of Fracture Precursors \". Physical Review Letters, 79, 3202 (1997)\nCallister, Jr., William D. (2002) Materials Science and Engineering: An Introduction. ISBN 0-471-13576-3\nPeter Rhys Lewis, Colin Gagg, Ken Reynolds, CRC Press (2004), Forensic Materials Engineering: Case Studies.\n\n\n== External links ==\nVirtual museum of failed products at The Open University\nFracture and Reconstruction of a Clay Bowl\nDuctile fracture", "Free_fall": "In Newtonian physics, free fall is any motion of a body where gravity is the only force acting upon it.  In the context of general relativity, where gravitation is reduced to a space-time curvature, a body in free fall has no force acting on it.\nAn object in the technical sense of the term \"free fall\" may not necessarily be falling down in the usual sense of the term. An object moving upwards might not normally be considered to be falling, but if it is subject to only the force of gravity, it is said to be in free fall.  The Moon is thus in free fall around the Earth, though its orbital speed keeps it in very far orbit from the Earth's surface.\nIn a roughly uniform gravitational field gravity acts on each part of a body approximately equally.  When there are no other forces, such as the normal force exerted between a body (e.g. an astronaut in orbit) and its surrounding objects, it will result in the sensation of weightlessness, a condition that also occurs when the gravitational field is weak (such as when far away from any source of gravity).\nThe term \"free fall\" is often used more loosely than in the strict sense defined above. Thus, falling through an atmosphere without a deployed parachute, or lifting device, is also often referred to as free fall. The aerodynamic drag forces in such situations prevent them from producing full weightlessness, and thus a skydiver's \"free fall\" after reaching terminal velocity produces the sensation of the body's weight being supported on a cushion of air.\n\n\n== History ==\nIn the Western world prior to the 16th century, it was generally assumed that the speed of a falling body would be proportional to its weight\u2014that is, a 10 kg object was expected to fall ten times faster than an otherwise identical 1 kg object through the same medium. The ancient Greek philosopher Aristotle (384\u2013322 BC) discussed falling objects in Physics (Book VII), one of the oldest books on mechanics (see Aristotelian physics). Although, in the 6th century, John Philoponus challenged this argument and said that, by observation, two balls of very different weights will fall at nearly the same speed.In 12th-century Iraq, Abu'l-Barak\u0101t al-Baghd\u0101d\u012b gave an explanation for the gravitational acceleration of falling bodies. According to Shlomo Pines, al-Baghd\u0101d\u012b's theory of motion was \"the oldest negation of Aristotle's fundamental dynamic law [namely, that a constant force produces a uniform motion], [and is thus an] anticipation in a vague fashion of the fundamental law of classical mechanics [namely, that a force applied continuously produces acceleration].\"According to a tale that may be apocryphal, in 1589\u201392 Galileo dropped two objects of unequal mass from the Leaning Tower of Pisa. Given the speed at which such a fall would occur, it is doubtful that Galileo could have extracted much information from this experiment. Most of his observations of falling bodies were really of bodies rolling down ramps. This slowed things down enough to the point where he was able to measure the time intervals with water clocks and his own pulse (stopwatches having not yet been invented). He repeated this \"a full hundred times\" until he had achieved \"an accuracy such that the deviation between two observations never exceeded one-tenth of a pulse beat.\" In 1589\u201392, Galileo wrote De Motu Antiquiora, an unpublished manuscript on the motion of falling bodies.\n\n\n== Examples ==\n\nExamples of objects in free fall include:\n\nA spacecraft (in space) with propulsion off (e.g. in a continuous orbit, or on a suborbital trajectory (ballistics) going up for some minutes, and then down).\nAn object dropped at the top of a drop tube.\nAn object thrown upward or a person jumping off the ground at low speed (i.e. as long as air resistance is negligible in comparison to weight).Technically, an object is in free fall even when moving upwards or instantaneously at rest at the top of its motion. If gravity is the only influence acting, then the acceleration is always downward and has the same magnitude for all bodies, commonly denoted \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  .\nSince all objects fall at the same rate in the absence of other forces, objects and people will experience weightlessness in these situations.\nExamples of objects not in free-fall:\n\nFlying in an aircraft: there is also an additional force of lift.\nStanding on the ground: the gravitational force is counteracted by the normal force from the ground.\nDescending to the Earth using a parachute, which balances the force of gravity with an aerodynamic drag force (and with some parachutes, an additional lift force).The example of a falling skydiver who has not yet deployed a parachute is not considered free fall from a physics perspective, since they experience a drag force that equals their weight once they have achieved terminal velocity (see below).\n\nNear the surface of the Earth, an object in free fall in a vacuum will accelerate at approximately 9.8 m/s2, independent of its mass. With air resistance acting on an object that has been dropped, the object will eventually reach a terminal velocity, which is around 53 m/s (190 km/h or 118 mph) for a human skydiver. The terminal velocity depends on many factors including mass, drag coefficient, and relative surface area and will only be achieved if the fall is from sufficient altitude. A typical skydiver in a spread-eagle position will reach terminal velocity after about 12 seconds, during which time they will have fallen around 450 m (1,500 ft).Free fall was demonstrated on the moon by astronaut David Scott on August 2, 1971. He simultaneously released a hammer and a feather from the same height above the moon's surface. The hammer and the feather both fell at the same rate and hit the surface at the same time. This demonstrated Galileo's discovery that, in the absence of air resistance, all objects experience the same acceleration due to gravity. On the Moon, however, the gravitational acceleration is approximately 1.63 m/s2, or only about 1\u20446\u200athat on Earth.\n\n\n== Free fall in Newtonian mechanics ==\n\n\n=== Uniform gravitational field without air resistance ===\nThis is the \"textbook\" case of the vertical motion of an object falling a small distance close to the surface of a planet. It is a good approximation in air as long as the force of gravity on the object is much greater than the force of air resistance, or equivalently the object's velocity is always much less than the terminal velocity (see below).\n\n  \n    \n      \n        v\n        (\n        t\n        )\n        =\n        \n          v\n          \n            0\n          \n        \n        \u2212\n        g\n        t\n        \n      \n    \n    {\\displaystyle v(t)=v_{0}-gt\\,}\n  \n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \n          v\n          \n            0\n          \n        \n        t\n        +\n        \n          y\n          \n            0\n          \n        \n        \u2212\n        \n          \n            1\n            2\n          \n        \n        g\n        \n          t\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle y(t)=v_{0}t+y_{0}-{\\frac {1}{2}}gt^{2}}\n  where\n\n  \n    \n      \n        \n          v\n          \n            0\n          \n        \n        \n      \n    \n    {\\displaystyle v_{0}\\,}\n   is the initial velocity (m/s).\n\n  \n    \n      \n        v\n        (\n        t\n        )\n        \n      \n    \n    {\\displaystyle v(t)\\,}\n   is the vertical velocity with respect to time (m/s).\n\n  \n    \n      \n        \n          y\n          \n            0\n          \n        \n        \n      \n    \n    {\\displaystyle y_{0}\\,}\n   is the initial altitude (m).\n\n  \n    \n      \n        y\n        (\n        t\n        )\n        \n      \n    \n    {\\displaystyle y(t)\\,}\n   is the altitude with respect to time (m).\n\n  \n    \n      \n        t\n        \n      \n    \n    {\\displaystyle t\\,}\n   is time elapsed (s).\n\n  \n    \n      \n        g\n        \n      \n    \n    {\\displaystyle g\\,}\n   is the acceleration due to gravity (9.81 m/s2 near the surface of the earth).If the initial velocity is zero, then the distance fallen from the initial position will grow as the square of the elapsed time. Moreover, because the odd numbers sum to the perfect squares, the distance fallen in successive time intervals grows as the odd numbers. This description of the behavior of falling bodies was given by Galileo.\n\n\n=== Uniform gravitational field with air resistance ===\n\nThis case, which applies to skydivers, parachutists or any body of mass, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  , and cross-sectional area, \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  , with Reynolds number well above the critical Reynolds number, so that the air resistance is proportional to the square of the fall velocity, \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  , has an equation of motion\n\n  \n    \n      \n        m\n        \n          \n            \n              \n                d\n              \n              v\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        m\n        g\n        \u2212\n        \n          \n            1\n            2\n          \n        \n        \u03c1\n        \n          C\n          \n            \n              D\n            \n          \n        \n        A\n        \n          v\n          \n            2\n          \n        \n        \n        ,\n      \n    \n    {\\displaystyle m{\\frac {\\mathrm {d} v}{\\mathrm {d} t}}=mg-{\\frac {1}{2}}\\rho C_{\\mathrm {D} }Av^{2}\\,,}\n  where \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is the air density and \n  \n    \n      \n        \n          C\n          \n            \n              D\n            \n          \n        \n      \n    \n    {\\displaystyle C_{\\mathrm {D} }}\n   is the drag coefficient, assumed to be constant although in general it will depend on the Reynolds number.\nAssuming an object falling from rest and no change in air density with altitude, the solution is:\n\n  \n    \n      \n        v\n        (\n        t\n        )\n        =\n        v\n        tanh\n        \u2061\n        \n          (\n          \n            \n              \n                g\n                t\n              \n              v\n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle v(t)=v\\tanh \\left({\\frac {gt}{v}}\\right),}\n  where the terminal speed is given by\n\n  \n    \n      \n        \n          v\n          \n            \u221e\n          \n        \n        =\n        \n          \n            \n              \n                2\n                m\n                g\n              \n              \n                \u03c1\n                \n                  C\n                  \n                    D\n                  \n                \n                A\n              \n            \n          \n        \n        \n        .\n      \n    \n    {\\displaystyle v_{\\infty }={\\sqrt {\\frac {2mg}{\\rho C_{D}A}}}\\,.}\n  The object's speed versus time can be integrated over time to find the vertical position as a function of time:\n\n  \n    \n      \n        y\n        =\n        \n          y\n          \n            0\n          \n        \n        \u2212\n        \n          \n            \n              v\n              \n                \u221e\n              \n              \n                2\n              \n            \n            g\n          \n        \n        ln\n        \u2061\n        cosh\n        \u2061\n        \n          (\n          \n            \n              \n                g\n                t\n              \n              \n                v\n                \n                  \u221e\n                \n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle y=y_{0}-{\\frac {v_{\\infty }^{2}}{g}}\\ln \\cosh \\left({\\frac {gt}{v_{\\infty }}}\\right).}\n  Using the figure of 56 m/s for the terminal velocity of a human, one finds that after 10 seconds he will have fallen 348 metres and attained 94% of terminal velocity, and after 12 seconds he will have fallen 455 metres and will have attained 97% of terminal velocity. However, when the air density cannot be assumed to be constant, such as for objects falling from high altitude, the equation of motion becomes much more difficult to solve analytically and a numerical simulation of the motion is usually necessary. The figure shows the forces acting on meteoroids falling through the Earth's upper atmosphere. HALO jumps, including Joe Kittinger's and Felix Baumgartner's record jumps, also belong in this category.\n\n\n=== Inverse-square law gravitational field ===\nIt can be said that two objects in space orbiting each other in the absence of other forces are in free fall around each other, e.g. that the Moon or an artificial satellite \"falls around\" the Earth, or a planet \"falls around\" the Sun. Assuming spherical objects means that the equation of motion is governed by Newton's law of universal gravitation, with solutions to the gravitational two-body problem being elliptic orbits obeying Kepler's laws of planetary motion. This connection between falling objects close to the Earth and orbiting objects is best illustrated by the thought experiment, Newton's cannonball.\nThe motion of two objects moving radially towards each other with no angular momentum can be considered a special case of an elliptical orbit of eccentricity e = 1 (radial elliptic trajectory). This allows one to compute the free-fall time for two point objects on a radial path. The solution of this equation of motion yields time as a function of separation:\n\n  \n    \n      \n        t\n        (\n        y\n        )\n        =\n        \n          \n            \n              \n                \n                  \n                    y\n                    \n                      0\n                    \n                  \n                \n                \n                  3\n                \n              \n              \n                2\n                \u03bc\n              \n            \n          \n        \n        \n          (\n          \n            \n              \n                \n                  \n                    y\n                    \n                      y\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  (\n                  \n                    1\n                    \u2212\n                    \n                      \n                        y\n                        \n                          y\n                          \n                            0\n                          \n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n            +\n            arccos\n            \u2061\n            \n              \n                \n                  y\n                  \n                    y\n                    \n                      0\n                    \n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle t(y)={\\sqrt {\\frac {{y_{0}}^{3}}{2\\mu }}}\\left({\\sqrt {{\\frac {y}{y_{0}}}\\left(1-{\\frac {y}{y_{0}}}\\right)}}+\\arccos {\\sqrt {\\frac {y}{y_{0}}}}\\right),}\n  where\n\n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is the time after the start of the fall\n\n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n   is the distance between the centers of the bodies\n\n  \n    \n      \n        \n          y\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle y_{0}}\n   is the initial value of \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n\n  \n    \n      \n        \u03bc\n        =\n        G\n        (\n        \n          m\n          \n            1\n          \n        \n        +\n        \n          m\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu =G(m_{1}+m_{2})}\n   is the standard gravitational parameter.Substituting \n  \n    \n      \n        y\n        =\n        0\n      \n    \n    {\\displaystyle y=0}\n   we get the free-fall time.\nThe separation as a function of time is given by the inverse of the equation. The inverse is represented exactly by the analytic power series:\n\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \n          \u2211\n          \n            n\n            =\n            1\n          \n          \n            \u221e\n          \n        \n        \n          [\n          \n            \n              lim\n              \n                r\n                \u2192\n                0\n              \n            \n            \n              (\n              \n                \n                  \n                    \n                      x\n                      \n                        n\n                      \n                    \n                    \n                      n\n                      !\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        d\n                      \n                      \n                        \n                        n\n                        \u2212\n                        1\n                      \n                    \n                    \n                      \n                        d\n                      \n                      \n                        r\n                        \n                          \n                          n\n                          \u2212\n                          1\n                        \n                      \n                    \n                  \n                \n                \n                  [\n                  \n                    \n                      r\n                      \n                        n\n                      \n                    \n                    \n                      \n                        (\n                        \n                          \n                            \n                              7\n                              2\n                            \n                          \n                          (\n                          arcsin\n                          \u2061\n                          (\n                          \n                            \n                              r\n                            \n                          \n                          )\n                          \u2212\n                          \n                            \n                              r\n                              \u2212\n                              \n                                r\n                                \n                                  2\n                                \n                              \n                            \n                          \n                          )\n                        \n                        )\n                      \n                      \n                        \u2212\n                        \n                          \n                            2\n                            3\n                          \n                        \n                        n\n                      \n                    \n                  \n                  ]\n                \n              \n              )\n            \n          \n          ]\n        \n        .\n      \n    \n    {\\displaystyle y(t)=\\sum _{n=1}^{\\infty }\\left[\\lim _{r\\to 0}\\left({\\frac {x^{n}}{n!}}{\\frac {\\mathrm {d} ^{\\,n-1}}{\\mathrm {d} r^{\\,n-1}}}\\left[r^{n}\\left({\\frac {7}{2}}(\\arcsin({\\sqrt {r}})-{\\sqrt {r-r^{2}}})\\right)^{-{\\frac {2}{3}}n}\\right]\\right)\\right].}\n  Evaluating this yields:\n\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \n          y\n          \n            0\n          \n        \n        \n          (\n          \n            x\n            \u2212\n            \n              \n                1\n                5\n              \n            \n            \n              x\n              \n                2\n              \n            \n            \u2212\n            \n              \n                3\n                175\n              \n            \n            \n              x\n              \n                3\n              \n            \n            \u2212\n            \n              \n                23\n                7875\n              \n            \n            \n              x\n              \n                4\n              \n            \n            \u2212\n            \n              \n                1894\n                3031875\n              \n            \n            \n              x\n              \n                5\n              \n            \n            \u2212\n            \n              \n                3293\n                21896875\n              \n            \n            \n              x\n              \n                6\n              \n            \n            \u2212\n            \n              \n                2418092\n                62077640625\n              \n            \n            \n              x\n              \n                7\n              \n            \n            \u2212\n            \u22ef\n          \n          )\n        \n         \n        ,\n      \n    \n    {\\displaystyle y(t)=y_{0}\\left(x-{\\frac {1}{5}}x^{2}-{\\frac {3}{175}}x^{3}-{\\frac {23}{7875}}x^{4}-{\\frac {1894}{3031875}}x^{5}-{\\frac {3293}{21896875}}x^{6}-{\\frac {2418092}{62077640625}}x^{7}-\\cdots \\right)\\ ,}\n  where\n\n  \n    \n      \n        x\n        =\n        \n          \n            [\n            \n              \n                \n                  3\n                  2\n                \n              \n              \n                (\n                \n                  \n                    \n                      \u03c0\n                      2\n                    \n                  \n                  \u2212\n                  t\n                  \n                    \n                      \n                        \n                          2\n                          \u03bc\n                        \n                        \n                          \n                            \n                              y\n                              \n                                0\n                              \n                            \n                          \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                )\n              \n            \n            ]\n          \n          \n            2\n            \n              /\n            \n            3\n          \n        \n        .\n      \n    \n    {\\displaystyle x=\\left[{\\frac {3}{2}}\\left({\\frac {\\pi }{2}}-t{\\sqrt {\\frac {2\\mu }{{y_{0}}^{3}}}}\\right)\\right]^{2/3}.}\n  \n\n\n== Free fall in general relativity ==\n\nIn general relativity, an object in free fall is subject to no force and is an inertial body moving along a geodesic. Far away from any sources of space-time curvature, where spacetime is flat, the Newtonian theory of free fall agrees with general relativity. Otherwise the two disagree; e.g., only general relativity can account for the precession of orbits, the orbital decay or inspiral of compact binaries due to gravitational waves, and the relativity of direction (geodetic precession and frame dragging).\nThe experimental observation that all objects in free fall accelerate at the same rate, as noted by Galileo and then embodied in Newton's theory as the equality of gravitational and inertial masses, and later confirmed to high accuracy by modern forms of the E\u00f6tv\u00f6s experiment, is the basis of the equivalence principle, from which basis Einstein's theory of general relativity initially took off.\n\n\n== See also ==\nEquations for a falling body\nG-force\nHigh-altitude military parachuting\nMicro-g environment\nReduced-gravity aircraft\nTerminal velocity\nWeightlessness\n\n\n== References ==\n\n\n== External links ==\nFreefall formula calculator\nThe Way Things Fall an educational website", "Force": "In physics, a force is an influence that causes the motion of an object with mass to change its velocity (e.g. moving from a state of rest), i.e., to accelerate. It can be a push or a pull, always with magnitude and direction, making it a vector quantity. It is measured in the SI unit of newton (N) and represented by the symbol F (formerly P).\nThe original form of Newton's second law states that the net force acting upon an object is equal to the rate at which its momentum changes with time. If the mass of the object is constant, this law implies that the acceleration of an object is directly proportional to the net force acting on the object, is in the direction of the net force, and is inversely proportional to the mass of the object.\nConcepts related to force include: thrust, which increases the velocity of an object; drag, which decreases the velocity of an object; and torque, which produces changes in rotational speed of an object. In an extended body, each part usually applies forces on the adjacent parts; the distribution of such forces through the body is the internal mechanical stress. Such internal mechanical stresses cause no acceleration of that body as the forces balance one another. Pressure, the distribution of many small forces applied over an area of a body, is a simple type of stress that if unbalanced can cause the body to accelerate. Stress usually causes deformation of solid materials, or flow in fluids.\n\n\n== Development of the concept ==\nPhilosophers in antiquity used the concept of force in the study of stationary and moving objects and simple machines, but thinkers such as Aristotle and Archimedes retained fundamental errors in understanding force. In part this was due to an incomplete understanding of the sometimes non-obvious force of friction, and a consequently inadequate view of the nature of natural motion. A fundamental error was the belief that a force is required to maintain motion, even at a constant velocity. Most of the previous misunderstandings about motion and force were eventually corrected by Galileo Galilei and Sir Isaac Newton. With his mathematical insight, Sir Isaac Newton formulated laws of motion that were not improved for nearly three hundred years. By the early 20th century, Einstein developed a theory of relativity that correctly predicted the action of forces on objects with increasing momenta near the speed of light, and also provided insight into the forces produced by gravitation and inertia.\nWith modern insights into quantum mechanics and technology that can accelerate particles close to the speed of light, particle physics has devised a Standard Model to describe forces between particles smaller than atoms. The Standard Model predicts that exchanged particles called gauge bosons are the fundamental means by which forces are emitted and absorbed. Only four main interactions are known: in order of decreasing strength, they are: strong, electromagnetic, weak, and gravitational.:\u200a2\u201310\u200a:\u200a79\u200a High-energy particle physics observations made during the 1970s and 1980s confirmed that the weak and electromagnetic forces are expressions of a more fundamental electroweak interaction.\n\n\n== Pre-Newtonian concepts ==\n\nSince antiquity the concept of force has been recognized as integral to the functioning of each of the simple machines. The mechanical advantage given by a simple machine allowed for less force to be used in exchange for that force acting over a greater distance for the same amount of work. Analysis of the characteristics of forces ultimately culminated in the work of Archimedes who was especially famous for formulating a treatment of buoyant forces inherent in fluids.Aristotle provided a philosophical discussion of the concept of a force as an integral part of Aristotelian cosmology. In Aristotle's view, the terrestrial sphere contained four elements that come to rest at different \"natural places\" therein. Aristotle believed that motionless objects on Earth, those composed mostly of the elements earth and water, to be in their natural place on the ground and that they will stay that way if left alone. He distinguished between the innate tendency of objects to find their \"natural place\" (e.g., for heavy bodies to fall), which led to \"natural motion\", and unnatural or forced motion, which required continued application of a force. This theory, based on the everyday experience of how objects move, such as the constant application of a force needed to keep a cart moving, had conceptual trouble accounting for the behavior of projectiles, such as the flight of arrows. The place where the archer moves the projectile was at the start of the flight, and while the projectile sailed through the air, no discernible efficient cause acts on it. Aristotle was aware of this problem and proposed that the air displaced through the projectile's path carries the projectile to its target. This explanation demands a continuum like air for change of place in general.Aristotelian physics began facing criticism in medieval science, first by John Philoponus in the 6th century.\nThe shortcomings of Aristotelian physics would not be fully corrected until the 17th century work of Galileo Galilei, who was influenced by the late medieval idea that objects in forced motion carried an innate force of impetus. Galileo constructed an experiment in which stones and cannonballs were both rolled down an incline to disprove the Aristotelian theory of motion. He showed that the bodies were accelerated by gravity to an extent that was independent of their mass and argued that objects retain their velocity unless acted on by a force, for example friction.In the early 17th century, before Newton's Principia, the term \"force\" (Latin: vis) was applied to many physical and non-physical phenomena, e.g., for an acceleration of a point. The product of a point mass and the square of its velocity was named vis viva (live force) by Leibniz. The modern concept of force corresponds to Newton's vis motrix (accelerating force).\n\n\n== Newtonian mechanics ==\n\nSir Isaac Newton described the motion of all objects using the concepts of inertia and force, and in doing so he found they obey certain conservation laws. In 1687, Newton published his thesis Philosophi\u00e6 Naturalis Principia Mathematica. In this work Newton set out three laws of motion that to this day are the way forces are described in physics.\n\n\n=== First law ===\n\nNewton's first law of motion states that objects continue to move in a state of constant velocity unless acted upon by an external net force (resultant force). This law is an extension of Galileo's insight that constant velocity was associated with a lack of net force (see a more detailed description of this below). Newton proposed that every object with mass has an innate inertia that functions as the fundamental equilibrium \"natural state\" in place of the Aristotelian idea of the \"natural state of rest\". That is, Newton's empirical first law contradicts the intuitive Aristotelian belief that a net force is required to keep an object moving with constant velocity. By making rest physically indistinguishable from non-zero constant velocity, Newton's first law directly connects inertia with the concept of relative velocities. Specifically, in systems where objects are moving with different velocities, it is impossible to determine which object is \"in motion\" and which object is \"at rest\". The laws of physics are the same in every inertial frame of reference, that is, in all frames related by a Galilean transformation.\nFor instance, while traveling in a moving vehicle at a constant velocity, the laws of physics do not change as a result of its motion. If a person riding within the vehicle throws a ball straight up, that person will observe it rise vertically and fall vertically and not have to apply a force in the direction the vehicle is moving. Another person, observing the moving vehicle pass by, would observe the ball follow a curving parabolic path in the same direction as the motion of the vehicle. It is the inertia of the ball associated with its constant velocity in the direction of the vehicle's motion that ensures the ball continues to move forward even as it is thrown up and falls back down. From the perspective of the person in the car, the vehicle and everything inside of it is at rest: It is the outside world that is moving with a constant speed in the opposite direction of the vehicle. Since there is no experiment that can distinguish whether it is the vehicle that is at rest or the outside world that is at rest, the two situations are considered to be physically indistinguishable. Inertia therefore applies equally well to constant velocity motion as it does to rest.\n\n\n=== Second law ===\n\nA modern statement of Newton's second law is a vector equation:\nwhere \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}}\n   is the momentum of the system, and \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   is the net (vector sum) force. If a body is in equilibrium, there is zero net force by definition (balanced forces may be present nevertheless). In contrast, the second law states that if there is an unbalanced force acting on an object it will result in the object's momentum changing over time.By the definition of momentum,\n\nwhere m is the mass and \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}}\n   is the velocity.:\u200a9\u20131,\u200a9\u20132\u200aIf Newton's second law is applied to a system of constant mass, m may be moved outside the derivative operator. The equation then becomes\n\nBy substituting the definition of acceleration, the algebraic version of Newton's second law is derived:\n\nNewton never explicitly stated the formula in the reduced form above.Newton's second law asserts the direct proportionality of acceleration to force and the inverse proportionality of acceleration to mass. Accelerations can be defined through kinematic measurements, which are well-described through reference frame analysis in advanced physics. General relativity offers an equivalence between space-time and mass, but lacking a coherent theory of quantum gravity, it is unclear as to how or whether this connection is relevant on microscales. With some justification, Newton's second law can be taken as a quantitative definition of mass by writing the law as an equality; the relative units of force and mass then are fixed.\nSome textbooks use Newton's second law as a definition of force, but this has been disparaged in other textbooks.:\u200a12\u20131\u200a:\u200a59\u200a Notable physicists, philosophers and mathematicians who have sought a more explicit definition of the concept of force include Ernst Mach and Walter Noll.Newton's second law can be used to measure the strength of forces. For instance, knowledge of the masses of planets along with the accelerations of their orbits allows scientists to calculate the gravitational forces on planets.\n\n\n=== Third law ===\n\nWhenever one body exerts a force on another, the latter simultaneously exerts an equal and opposite force on the first. In vector form, if \n  \n    \n      \n        \n          \n            \n              \n                F\n                \u2192\n              \n            \n          \n          \n            1\n            ,\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}_{1,2}}\n   is the force of body 1 on body 2 and \n  \n    \n      \n        \n          \n            \n              \n                F\n                \u2192\n              \n            \n          \n          \n            2\n            ,\n            1\n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}_{2,1}}\n   that of body 2 on body 1, then\n\nThis law is sometimes referred to as the action-reaction law, with \n  \n    \n      \n        \n          \n            \n              \n                F\n                \u2192\n              \n            \n          \n          \n            1\n            ,\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}_{1,2}}\n   called the action and \n  \n    \n      \n        \u2212\n        \n          \n            \n              \n                F\n                \u2192\n              \n            \n          \n          \n            2\n            ,\n            1\n          \n        \n      \n    \n    {\\displaystyle -{\\vec {F}}_{2,1}}\n   the reaction.\nNewton's Third Law is a result of applying symmetry to situations where forces can be attributed to the presence of different objects. The third law means that all forces are interactions between different bodies, and thus that there is no such thing as a unidirectional force or a force that acts on only one body.\nIn a system composed of object 1 and object 2, the net force on the system due to their mutual interactions is zero:\n\nMore generally, in a closed system of particles, all internal forces are balanced. The particles may accelerate with respect to each other but the center of mass of the system will not accelerate. If an external force acts on the system, it will make the center of mass accelerate in proportion to the magnitude of the external force divided by the mass of the system.:\u200a19\u20131\u200aCombining Newton's Second and Third Laws, it is possible to show that the linear momentum of a system is conserved. In a system of two particles, if \n  \n    \n      \n        \n          \n            \n              \n                p\n                \u2192\n              \n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}_{1}}\n   is the momentum of object 1 and \n  \n    \n      \n        \n          \n            \n              \n                p\n                \u2192\n              \n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}_{2}}\n   the momentum of object 2, then\n\nUsing similar arguments, this can be generalized to a system with an arbitrary number of particles. In general, as long as all forces are due to the interaction of objects with mass, it is possible to define a system such that net momentum is never lost nor gained.\n\n\n== Special theory of relativity ==\nIn the special theory of relativity, mass and energy are equivalent (as can be seen by calculating the work required to accelerate an object). When an object's velocity increases, so does its energy and hence its mass equivalent (inertia). It thus requires more force to accelerate it the same amount than it did at a lower velocity. Newton's Second Law,\n\nremains valid because it is a mathematical definition.:\u200a855\u2013876\u200a But for relativistic momentum to be conserved, it must be redefined as:\n\nwhere \n  \n    \n      \n        \n          m\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle m_{0}}\n   is the rest mass and \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   the speed of light.\nThe relativistic expression relating force and acceleration for a particle with constant non-zero rest mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   moving in the \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   direction is:\n\nwhere\n\nis called the Lorentz factor.\nIn the early history of relativity, the expressions \n  \n    \n      \n        \n          \u03b3\n          \n            3\n          \n        \n        m\n      \n    \n    {\\displaystyle \\gamma ^{3}m}\n   and \n  \n    \n      \n        \u03b3\n        m\n      \n    \n    {\\displaystyle \\gamma m}\n   were called longitudinal and transverse mass. Relativistic force does not produce a constant acceleration, but an ever-decreasing acceleration as the object approaches the speed of light. \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   approaches asymptotically an infinite value and is undefined for an object with a non-zero rest mass as it approaches the speed of light, and the theory yields no prediction at that speed.\nIf \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is very small compared to \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  , then \n  \n    \n      \n        \u03b3\n      \n    \n    {\\displaystyle \\gamma }\n   is very close to 1 and\n\nis a close approximation. Even for use in relativity, one can restore the form of\n\nthrough the use of four-vectors. This relation is correct in relativity when \n  \n    \n      \n        \n          F\n          \n            \u03bc\n          \n        \n      \n    \n    {\\displaystyle F^{\\mu }}\n   is the four-force, \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the invariant mass, and \n  \n    \n      \n        \n          A\n          \n            \u03bc\n          \n        \n      \n    \n    {\\displaystyle A^{\\mu }}\n   is the four-acceleration.\n\n\n== Descriptions ==\n\nSince forces are perceived as pushes or pulls, this can provide an intuitive understanding for describing forces. As with other physical concepts (e.g. temperature), the intuitive understanding of forces is quantified using precise operational definitions that are consistent with direct observations and compared to a standard measurement scale. Through experimentation, it is determined that laboratory measurements of forces are fully consistent with the conceptual definition of force offered by Newtonian mechanics.\nForces act in a particular direction and have sizes dependent upon how strong the push or pull is. Because of these characteristics, forces are classified as \"vector quantities\". This means that forces follow a different set of mathematical rules than physical quantities that do not have direction (denoted scalar quantities). For example, when determining what happens when two forces act on the same object, it is necessary to know both the magnitude and the direction of both forces to calculate the result. If both of these pieces of information are not known for each force, the situation is ambiguous. For example, if you know that two people are pulling on the same rope with known magnitudes of force but you do not know which direction either person is pulling, it is impossible to determine what the acceleration of the rope will be. The two people could be pulling against each other as in tug of war or the two people could be pulling in the same direction. In this simple one-dimensional example, without knowing the direction of the forces it is impossible to decide whether the net force is the result of adding the two force magnitudes or subtracting one from the other. Associating forces with vectors avoids such problems.\nHistorically, forces were first quantitatively investigated in conditions of static equilibrium where several forces canceled each other out. Such experiments demonstrate the crucial properties that forces are additive vector quantities: they have magnitude and direction. When two forces act on a point particle, the resulting force, the resultant (also called the net force), can be determined by following the parallelogram rule of vector addition: the addition of two vectors represented by sides of a parallelogram, gives an equivalent resultant vector that is equal in magnitude and direction to the transversal of the parallelogram. The magnitude of the resultant varies from the difference of the magnitudes of the two forces to their sum, depending on the angle between their lines of action. If acting on an extended body, their respective lines of application must also be specified in order to account for their effects on the body's motion.\nFree-body diagrams can be used as a convenient way to keep track of forces acting on a system. Ideally, these diagrams are drawn with the angles and relative magnitudes of the force vectors preserved so that graphical vector addition can be done to determine the net force.As well as being added, forces can also be resolved into independent components at right angles to each other. A horizontal force pointing northeast can therefore be split into two forces, one pointing north, and one pointing east. Summing these component forces using vector addition yields the original force. Resolving force vectors into components of a set of basis vectors is often a more mathematically clean way to describe forces than using magnitudes and directions. This is because, for orthogonal components, the components of the vector sum are uniquely determined by the scalar addition of the components of the individual vectors. Orthogonal components are independent of each other because forces acting at ninety degrees to each other have no effect on the magnitude or direction of the other. Choosing a set of orthogonal basis vectors is often done by considering what set of basis vectors will make the mathematics most convenient. Choosing a basis vector that is in the same direction as one of the forces is desirable, since that force would then have only one non-zero component. Orthogonal force vectors can be three-dimensional with the third component being at right-angles to the other two.\n\n\n=== Equilibrium ===\nWhen all the forces that act upon an object are balanced, then the object is said to be in a state of equilibrium. Hence, equilibrium occurs when the resultant force acting on a point particle is zero (that is, the vector sum of all forces is zero). When dealing with an extended body, it is also necessary that the net torque be zero.\nThere are two kinds of equilibrium: static equilibrium and dynamic equilibrium.\n\n\n==== Static ====\n\nStatic equilibrium was understood well before the invention of classical mechanics. Objects that are at rest have zero net force acting on them.The simplest case of static equilibrium occurs when two forces are equal in magnitude but opposite in direction. For example, an object on a level surface is pulled (attracted) downward toward the center of the Earth by the force of gravity. At the same time, a force is applied by the surface that resists the downward force with equal upward force (called a normal force). The situation produces zero net force and hence no acceleration.Pushing against an object that rests on a frictional surface can result in a situation where the object does not move because the applied force is opposed by static friction, generated between the object and the table surface. For a situation with no movement, the static friction force exactly balances the applied force resulting in no acceleration. The static friction increases or decreases in response to the applied force up to an upper limit determined by the characteristics of the contact between the surface and the object.A static equilibrium between two forces is the most usual way of measuring forces, using simple devices such as weighing scales and spring balances. For example, an object suspended on a vertical spring scale experiences the force of gravity acting on the object balanced by a force applied by the \"spring reaction force\", which equals the object's weight. Using such tools, some quantitative force laws were discovered: that the force of gravity is proportional to volume for objects of constant density (widely exploited for millennia to define standard weights); Archimedes' principle for buoyancy; Archimedes' analysis of the lever; Boyle's law for gas pressure; and Hooke's law for springs. These were all formulated and experimentally verified before Isaac Newton expounded his Three Laws of Motion.\n\n\n==== Dynamic ====\n\nDynamic equilibrium was first described by Galileo who noticed that certain assumptions of Aristotelian physics were contradicted by observations and logic. Galileo realized that simple velocity addition demands that the concept of an \"absolute rest frame\" did not exist. Galileo concluded that motion in a constant velocity was completely equivalent to rest. This was contrary to Aristotle's notion of a \"natural state\" of rest that objects with mass naturally approached. Simple experiments showed that Galileo's understanding of the equivalence of constant velocity and rest were correct. For example, if a mariner dropped a cannonball from the crow's nest of a ship moving at a constant velocity, Aristotelian physics would have the cannonball fall straight down while the ship moved beneath it. Thus, in an Aristotelian universe, the falling cannonball would land behind the foot of the mast of a moving ship. When this experiment is actually conducted, the cannonball always falls at the foot of the mast, as if the cannonball knows to travel with the ship despite being separated from it. Since there is no forward horizontal force being applied on the cannonball as it falls, the only conclusion left is that the cannonball continues to move with the same velocity as the boat as it falls. Thus, no force is required to keep the cannonball moving at the constant forward velocity.Moreover, any object traveling at a constant velocity must be subject to zero net force (resultant force). This is the definition of dynamic equilibrium: when all the forces on an object balance but it still moves at a constant velocity.\nA simple case of dynamic equilibrium occurs in constant velocity motion across a surface with kinetic friction. In such a situation, a force is applied in the direction of motion while the kinetic friction force exactly opposes the applied force. This results in zero net force, but since the object started with a non-zero velocity, it continues to move with a non-zero velocity. Aristotle misinterpreted this motion as being caused by the applied force. When kinetic friction is taken into consideration it is clear that there is no net force causing constant velocity motion.\n\n\n=== Quantum mechanics ===\n\nThe notion \"force\" keeps its meaning in quantum mechanics, though one is now dealing with operators instead of classical variables and though the physics is now described by the Schr\u00f6dinger equation instead of Newtonian equations. This has the consequence that the results of a measurement are now sometimes \"quantized\", i.e. they appear in discrete portions. This is, of course, difficult to imagine in the context of \"forces\". The potentials V(x, y, z) or fields, from which the forces generally can be derived, are treated similarly to classical position variables, i.e., \n  \n    \n      \n        V\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        \u2192\n        \n          \n            \n              V\n              ^\n            \n          \n        \n        (\n        \n          \n            \n              x\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              y\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              z\n              ^\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle V(x,y,z)\\to {\\hat {V}}({\\hat {x}},{\\hat {y}},{\\hat {z}})}\n  .\nThis becomes different only in the framework of quantum field theory, where these fields are also quantized.\nQuantum mechanics has a caveat; the particles acting onto each other do not only possess the spatial variable, but also a discrete intrinsic angular momentum-like variable called the \"spin\", and there is the Pauli exclusion principle relating the space and the spin variables. Depending on the value of the spin, identical particles split into two different classes, fermions and bosons. If two identical fermions (e.g. electrons) have a symmetric spin function (e.g. parallel spins) the spatial variables must be antisymmetric (i.e. they exclude each other from their places much as if there was a repulsive force), and vice versa, i.e. for antiparallel spins the position variables must be symmetric (i.e. the apparent force must be attractive). Thus in the case of two fermions there is a strictly negative correlation between spatial and spin variables, whereas for two bosons (e.g. quanta of electromagnetic waves, photons) the correlation is strictly positive.\nThus the notion \"force\" loses already part of its meaning.\n\n\n=== Feynman diagrams ===\n\nIn modern particle physics, forces and the acceleration of particles are explained as a mathematical by-product of exchange of momentum-carrying gauge bosons. With the development of quantum field theory and general relativity, it was realized that force is a redundant concept arising from conservation of momentum (4-momentum in relativity and momentum of virtual particles in quantum electrodynamics). The conservation of momentum can be directly derived from the homogeneity or symmetry of space and so is usually considered more fundamental than the concept of a force. Thus the currently known fundamental forces are considered more accurately to be \"fundamental interactions\".:\u200a199\u2013128\u200a When particle A emits (creates) or absorbs (annihilates) virtual particle B, a momentum conservation results in recoil of particle A making impression of repulsion or attraction between particles A A' exchanging by B. This description applies to all forces arising from fundamental interactions. While sophisticated mathematical descriptions are needed to predict, in full detail, the accurate result of such interactions, there is a conceptually simple way to describe such interactions through the use of Feynman diagrams. In a Feynman diagram, each matter particle is represented as a straight line (see world line) traveling through time, which normally increases up or to the right in the diagram. Matter and anti-matter particles are identical except for their direction of propagation through the Feynman diagram. World lines of particles intersect at interaction vertices, and the Feynman diagram represents any force arising from an interaction as occurring at the vertex with an associated instantaneous change in the direction of the particle world lines. Gauge bosons are emitted away from the vertex as wavy lines and, in the case of virtual particle exchange, are absorbed at an adjacent vertex.The utility of Feynman diagrams is that other types of physical phenomena that are part of the general picture of fundamental interactions but are conceptually separate from forces can also be described using the same rules. For example, a Feynman diagram can describe in succinct detail how a neutron decays into an electron, proton, and neutrino, an interaction mediated by the same gauge boson that is responsible for the weak nuclear force.\n\n\n== Fundamental interactions ==\n\nAll of the known forces of the universe are classified into four fundamental interactions. The strong and the weak forces act only at very short distances, and are responsible for the interactions between subatomic particles, including nucleons and compound nuclei. The electromagnetic force acts between electric charges, and the gravitational force acts between masses. All other forces in nature derive from these four fundamental interactions. For example, friction is a manifestation of the electromagnetic force acting between atoms of two surfaces, and the Pauli exclusion principle, which does not permit atoms to pass through each other. Similarly, the forces in springs, modeled by Hooke's law, are the result of electromagnetic forces and the Pauli exclusion principle acting together to return an object to its equilibrium position. Centrifugal forces are acceleration forces that arise simply from the acceleration of rotating frames of reference.:\u200a12\u201311\u200a:\u200a359\u200aThe fundamental theories for forces developed from the unification of different ideas. For example, Sir Isaac Newton unified, with his universal theory of gravitation, the force responsible for objects falling near the surface of the Earth with the force responsible for the falling of celestial bodies about the Earth (the Moon) and around the Sun (the planets). Michael Faraday and James Clerk Maxwell demonstrated that electric and magnetic forces were unified through a theory of electromagnetism. In the 20th century, the development of quantum mechanics led to a modern understanding that the first three fundamental forces (all except gravity) are manifestations of matter (fermions) interacting by exchanging virtual particles called gauge bosons. This Standard Model of particle physics assumes a similarity between the forces and led scientists to predict the unification of the weak and electromagnetic forces in electroweak theory, which was subsequently confirmed by observation. The complete formulation of the Standard Model predicts an as yet unobserved Higgs mechanism, but observations such as neutrino oscillations suggest that the Standard Model is incomplete. A Grand Unified Theory that allows for the combination of the electroweak interaction with the strong force is held out as a possibility with candidate theories such as supersymmetry proposed to accommodate some of the outstanding unsolved problems in physics. Physicists are still attempting to develop self-consistent unification models that would combine all four fundamental interactions into a theory of everything. Einstein tried and failed at this endeavor, but currently the most popular approach to answering this question is string theory.:\u200a212\u2013219\u200a\n\n\n=== Gravitational ===\n\nWhat we now call gravity was not identified as a universal force until the work of Isaac Newton. Before Newton, the tendency for objects to fall towards the Earth was not understood to be related to the motions of celestial objects. Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object. Today, this acceleration due to gravity towards the surface of the Earth is usually designated as \n  \n    \n      \n        \n          \n            \n              g\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {g}}}\n   and has a magnitude of about 9.81 meters per second squared (this measurement is taken from sea level and may vary depending on location), and points toward the center of the Earth. This observation means that the force of gravity on an object at the Earth's surface is directly proportional to the object's mass. Thus an object that has a mass of \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   will experience a force:\n\nFor an object in free-fall, this force is unopposed and the net force on the object is its weight. For objects not in free-fall, the force of gravity is opposed by the reaction forces applied by their supports. For example, a person standing on the ground experiences zero net force, since a normal force (a reaction force) is exerted by the ground upward on the person that counterbalances his weight that is directed downward.Newton's contribution to gravitational theory was to unify the motions of heavenly bodies, which Aristotle had assumed were in a natural state of constant motion, with falling motion observed on the Earth. He proposed a law of gravity that could account for the celestial motions that had been described earlier using Kepler's laws of planetary motion.Newton came to realize that the effects of gravity might be observed in different ways at larger distances. In particular, Newton determined that the acceleration of the Moon around the Earth could be ascribed to the same force of gravity if the acceleration due to gravity decreased as an inverse square law. Further, Newton realized that the acceleration of a body due to gravity is proportional to the mass of the other attracting body. Combining these ideas gives a formula that relates the mass (\n  \n    \n      \n        \n          m\n          \n            \u2295\n          \n        \n      \n    \n    {\\displaystyle m_{\\oplus }}\n  ) and the radius (\n  \n    \n      \n        \n          R\n          \n            \u2295\n          \n        \n      \n    \n    {\\displaystyle R_{\\oplus }}\n  ) of the Earth to the gravitational acceleration:\n\nwhere the vector direction is given by \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {r}}}\n  , is the unit vector directed outward from the center of the Earth.In this equation, a dimensional constant \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is used to describe the relative strength of gravity. This constant has come to be known as the Newtonian constant of gravitation, though its value was unknown in Newton's lifetime. Not until 1798 was Henry Cavendish able to make the first measurement of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   using a torsion balance; this was widely reported in the press as a measurement of the mass of the Earth since knowing \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   could allow one to solve for the Earth's mass given the above equation. Newton realized that since all celestial bodies followed the same laws of motion, his law of gravity had to be universal. Succinctly stated, Newton's Law of Gravitation states that the force on a spherical object of mass \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle m_{1}}\n   due to the gravitational pull of mass \n  \n    \n      \n        \n          m\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{2}}\n   is\n\nwhere \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the distance between the two objects' centers of mass and \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {r}}}\n   is the unit vector pointed in the direction away from the center of the first object toward the center of the second object.This formula was powerful enough to stand as the basis for all subsequent descriptions of motion within the solar system until the 20th century. During that time, sophisticated methods of perturbation analysis were invented to calculate the deviations of orbits due to the influence of multiple bodies on a planet, moon, comet, or asteroid. The formalism was exact enough to allow mathematicians to predict the existence of the planet Neptune before it was observed.\n\nMercury's orbit did not match that predicted by Newton's Law of Gravitation. Some astrophysicists predicted the existence of an undiscovered planet (Vulcan) that could explain the discrepancies. When Albert Einstein formulated his theory of general relativity (GR) he focused on Mercury's problematic orbit and found that his theory added a correction, which could account for the discrepancy. This was the first time that Newton's Theory of Gravity had been shown to be inexact.Since then, general relativity has been acknowledged as the theory that best explains gravity. In GR, gravitation is not viewed as a force, but rather, objects moving freely in gravitational fields travel under their own inertia in straight lines through curved space-time \u2013 defined as the shortest space-time path between two space-time events. From the perspective of the object, all motion occurs as if there were no gravitation whatsoever. It is only when observing the motion in a global sense that the curvature of space-time can be observed and the force is inferred from the object's curved path. Thus, the straight line path in space-time is seen as a curved line in space, and it is called the ballistic trajectory of the object. For example, a basketball thrown from the ground moves in a parabola, as it is in a uniform gravitational field. Its space-time trajectory is almost a straight line, slightly curved (with the radius of curvature of the order of few light-years). The time derivative of the changing momentum of the object is what we label as \"gravitational force\".\n\n\n=== Electromagnetic ===\n\nThe electrostatic force was first described in 1784 by Coulomb as a force that existed intrinsically between two charges.:\u200a519\u200a The properties of the electrostatic force were that it varied as an inverse square law directed in the radial direction, was both attractive and repulsive (there was intrinsic polarity), was independent of the mass of the charged objects, and followed the superposition principle. Coulomb's law unifies all these observations into one succinct statement.Subsequent mathematicians and physicists found the construct of the electric field to be useful for determining the electrostatic force on an electric charge at any point in space. The electric field was based on using a hypothetical \"test charge\" anywhere in space and then using Coulomb's Law to determine the electrostatic force.:\u200a4-6 to 4-8\u200a Thus the electric field anywhere in space is defined as\n\nwhere \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the magnitude of the hypothetical test charge.\nMeanwhile, the Lorentz force of magnetism was discovered to exist between two electric currents. It has the same mathematical character as Coulomb's Law with the proviso that like currents attract and unlike currents repel. Similar to the electric field, the magnetic field can be used to determine the magnetic force on an electric current at any point in space. In this case, the magnitude of the magnetic field was determined to be\n\nwhere \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the magnitude of the hypothetical test current and \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of hypothetical wire through which the test current flows. The magnetic field exerts a force on all magnets including, for example, those used in compasses. The fact that the Earth's magnetic field is aligned closely with the orientation of the Earth's axis causes compass magnets to become oriented because of the magnetic force pulling on the needle.\nThrough combining the definition of electric current as the time rate of change of electric charge, a rule of vector multiplication called Lorentz's Law describes the force on a charge moving in a magnetic field. The connection between electricity and magnetism allows for the description of a unified electromagnetic force that acts on a charge. This force can be written as a sum of the electrostatic force (due to the electric field) and the magnetic force (due to the magnetic field). Fully stated, this is the law:\n\nwhere \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   is the electromagnetic force, \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the magnitude of the charge of the particle, \n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {E}}}\n   is the electric field, \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}}\n   is the velocity of the particle that is crossed with the magnetic field (\n  \n    \n      \n        \n          \n            \n              B\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {B}}}\n  ).\nThe origin of electric and magnetic fields would not be fully explained until 1864 when James Clerk Maxwell unified a number of earlier theories into a set of 20 scalar equations, which were later reformulated into 4 vector equations by Oliver Heaviside and Josiah Willard Gibbs. These \"Maxwell Equations\" fully described the sources of the fields as being stationary and moving charges, and the interactions of the fields themselves. This led Maxwell to discover that electric and magnetic fields could be \"self-generating\" through a wave that traveled at a speed that he calculated to be the speed of light. This insight united the nascent fields of electromagnetic theory with optics and led directly to a complete description of the electromagnetic spectrum.Attempts to reconcile electromagnetic theory with two observations, the photoelectric effect, and the nonexistence of the ultraviolet catastrophe, proved troublesome. Through the work of leading theoretical physicists, a new theory of electromagnetism was developed using quantum mechanics. This final modification to electromagnetic theory ultimately led to quantum electrodynamics (or QED), which fully describes all electromagnetic phenomena as being mediated by wave\u2013particles known as photons. In QED, photons are the fundamental exchange particle, which described all interactions relating to electromagnetism including the electromagnetic force.\n\n\n=== Strong nuclear ===\n\nThere are two \"nuclear forces\", which today are usually described as interactions that take place in quantum theories of particle physics. The strong nuclear force:\u200a940\u200a is the force responsible for the structural integrity of atomic nuclei while the weak nuclear force:\u200a951\u200a is responsible for the decay of certain nucleons into leptons and other types of hadrons.The strong force is today understood to represent the interactions between quarks and gluons as detailed by the theory of quantum chromodynamics (QCD). The strong force is the fundamental force mediated by gluons, acting upon quarks, antiquarks, and the gluons themselves. The (aptly named) strong interaction is the \"strongest\" of the four fundamental forces.\nThe strong force only acts directly upon elementary particles. A residual is observed between hadrons (notably, the nucleons in atomic nuclei), known as the nuclear force. Here the strong force acts indirectly, transmitted as gluons that form part of the virtual pi and rho mesons, the classical transmitters of the nuclear force. The failure of many searches for free quarks has shown that the elementary particles affected are not directly observable. This phenomenon is called color confinement.\n\n\n=== Weak nuclear ===\n\nThe weak force is due to the exchange of the heavy W and Z bosons. Since the weak force is mediated by two types of bosons, it can be divided into two types of interaction or \"vertices\" \u2014 charged current, involving the electrically charged W+ and W\u2212 bosons, and neutral current, involving electrically neutral Z0 bosons. The most familiar effect of weak interaction is beta decay (of neutrons in atomic nuclei) and the associated radioactivity. This is a type of charged-current interaction. The word \"weak\" derives from the fact that the field strength is some 1013 times less than that of the strong force. Still, it is stronger than gravity over short distances. A consistent electroweak theory has also been developed, which shows that electromagnetic forces and the weak force are indistinguishable at a temperatures in excess of approximately 1015 kelvins. Such temperatures have been probed in modern particle accelerators and show the conditions of the universe in the early moments of the Big Bang.\n\n\n== Non-fundamental types ==\nSome forces are consequences of the fundamental ones. In such situations, idealized models can be used to gain physical insight.\n\n\n=== Normal ===\n\nThe normal force is due to repulsive forces of interaction between atoms at close contact. When their electron clouds overlap, Pauli repulsion (due to fermionic nature of electrons) follows resulting in the force that acts in a direction normal to the surface interface between two objects.:\u200a93\u200a The normal force, for example, is responsible for the structural integrity of tables and floors as well as being the force that responds whenever an external force pushes on a solid object. An example of the normal force in action is the impact force on an object crashing into an immobile surface.\n\n\n=== Friction ===\n\nFriction is a surface force that opposes relative motion. The frictional force is directly related to the normal force that acts to keep two solid objects separated at the point of contact. There are two broad classifications of frictional forces: static friction and kinetic friction.\nThe static friction force (\n  \n    \n      \n        \n          F\n          \n            \n              s\n              f\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {sf} }}\n  ) will exactly oppose forces applied to an object parallel to a surface contact up to the limit specified by the coefficient of static friction (\n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n              f\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {sf} }}\n  ) multiplied by the normal force (\n  \n    \n      \n        \n          F\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle F_{N}}\n  ). In other words, the magnitude of the static friction force satisfies the inequality:\n\nThe kinetic friction force (\n  \n    \n      \n        \n          F\n          \n            \n              k\n              f\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {kf} }}\n  ) is independent of both the forces applied and the movement of the object. Thus, the magnitude of the force equals:\n\nwhere \n  \n    \n      \n        \n          \u03bc\n          \n            \n              k\n              f\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {kf} }}\n   is the coefficient of kinetic friction. For most surface interfaces, the coefficient of kinetic friction is less than the coefficient of static friction.\n\n\n=== Tension ===\n\nTension forces can be modeled using ideal strings that are massless, frictionless, unbreakable, and unstretchable. They can be combined with ideal pulleys, which allow ideal strings to switch physical direction. Ideal strings transmit tension forces instantaneously in action-reaction pairs so that if two objects are connected by an ideal string, any force directed along the string by the first object is accompanied by a force directed along the string in the opposite direction by the second object. By connecting the same string multiple times to the same object through the use of a set-up that uses movable pulleys, the tension force on a load can be multiplied. For every string that acts on a load, another factor of the tension force in the string acts on the load. Such machines allow a mechanical advantage for a corresponding increase in the length of displaced string needed to move the load. These tandem effects result ultimately in the conservation of mechanical energy since the work done on the load is the same no matter how complicated the machine.\n\n\n=== Elasticity ===\n\nAn elastic force acts to return a spring to its natural length. An ideal spring is taken to be massless, frictionless, unbreakable, and infinitely stretchable. Such springs exert forces that push when contracted, or pull when extended, in proportion to the displacement of the spring from its equilibrium position. This linear relationship was described by Robert Hooke in 1676, for whom Hooke's law is named. If \n  \n    \n      \n        \u0394\n        x\n      \n    \n    {\\displaystyle \\Delta x}\n   is the displacement, the force exerted by an ideal spring equals:\n\nwhere \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the spring constant (or force constant), which is particular to the spring. The minus sign accounts for the tendency of the force to act in opposition to the applied load.\n\n\n=== Continuum mechanics ===\n\nNewton's laws and Newtonian mechanics in general were first developed to describe how forces affect idealized point particles rather than three-dimensional objects. In real life, matter has extended structure and forces that act on one part of an object might affect other parts of an object. For situations where lattice holding together the atoms in an object is able to flow, contract, expand, or otherwise change shape, the theories of continuum mechanics describe the way forces affect the material. For example, in extended fluids, differences in pressure result in forces being directed along the pressure gradients as follows:\n\nwhere \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the volume of the object in the fluid and \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   is the scalar function that describes the pressure at all locations in space. Pressure gradients and differentials result in the buoyant force for fluids suspended in gravitational fields, winds in atmospheric science, and the lift associated with aerodynamics and flight.A specific instance of such a force that is associated with dynamic pressure is fluid resistance: a body force that resists the motion of an object through a fluid due to viscosity. For so-called \"Stokes' drag\" the force is approximately proportional to the velocity, but opposite in direction:\n\nwhere:\n\n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n   is a constant that depends on the properties of the fluid and the dimensions of the object (usually the cross-sectional area), and\n\n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}}\n   is the velocity of the object.More formally, forces in continuum mechanics are fully described by a stress\u2013tensor with terms that are roughly defined as\n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is the relevant cross-sectional area for the volume for which the stress-tensor is being calculated. This formalism includes pressure terms associated with forces that act normal to the cross-sectional area (the matrix diagonals of the tensor) as well as shear terms associated with forces that act parallel to the cross-sectional area (the off-diagonal elements). The stress tensor accounts for forces that cause all strains (deformations) including also tensile stresses and compressions.:\u200a133\u2013134\u200a:\u200a38-1\u201338-11\u200a\n\n\n=== Fictitious ===\n\nThere are forces that are frame dependent, meaning that they appear due to the adoption of non-Newtonian (that is, non-inertial) reference frames. Such forces include the centrifugal force and the Coriolis force. These forces are considered fictitious because they do not exist in frames of reference that are not accelerating. Because these forces are not genuine they are also referred to as \"pseudo forces\".:\u200a12\u201311\u200aIn general relativity, gravity becomes a fictitious force that arises in situations where spacetime deviates from a flat geometry. As an extension, Kaluza\u2013Klein theory and string theory ascribe electromagnetism and the other fundamental forces respectively to the curvature of differently scaled dimensions, which would ultimately imply that all forces are fictitious.\n\n\n== Rotation and torque ==\n\nForces that cause extended objects to rotate are associated with torques. Mathematically, the torque of a force \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   is defined relative to an arbitrary reference point as the cross-product:\n\nwhere \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   is the position vector of the force application point relative to the reference point.\nTorque is the rotation equivalent of force in the same way that angle is the rotational equivalent for position, angular velocity for velocity, and angular momentum for momentum. As a consequence of Newton's First Law of Motion, there exists rotational inertia that ensures that all bodies maintain their angular momentum unless acted upon by an unbalanced torque. Likewise, Newton's Second Law of Motion can be used to derive an analogous equation for the instantaneous angular acceleration of the rigid body:\n\nwhere\n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the moment of inertia of the body\n\n  \n    \n      \n        \n          \n            \n              \u03b1\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {\\alpha }}}\n   is the angular acceleration of the body.This provides a definition for the moment of inertia, which is the rotational equivalent for mass. In more advanced treatments of mechanics, where the rotation over a time interval is described, the moment of inertia must be substituted by the tensor that, when properly analyzed, fully determines the characteristics of rotations including precession and nutation.\nEquivalently, the differential form of Newton's Second Law provides an alternative definition of torque:\nwhere \n  \n    \n      \n        \n          \n            \n              L\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {L}}}\n   is the angular momentum of the particle.\nNewton's Third Law of Motion requires that all objects exerting torques themselves experience equal and opposite torques, and therefore also directly implies the conservation of angular momentum for closed systems that experience rotations and revolutions through the action of internal torques.\n\n\n=== Centripetality ===\n\nFor an object accelerating in circular motion, the unbalanced force acting on the object equals:\nwhere \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the mass of the object, \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the velocity of the object and \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the distance to the center of the circular path and \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {r}}}\n   is the unit vector pointing in the radial direction outwards from the center. This means that the unbalanced centripetal force felt by any object is always directed toward the center of the curving path. Such forces act perpendicular to the velocity vector associated with the motion of an object, and therefore do not change the speed of the object (magnitude of the velocity), but only the direction of the velocity vector. The unbalanced force that accelerates an object can be resolved into a component that is perpendicular to the path, and one that is tangential to the path. This yields both the tangential force, which accelerates the object by either slowing it down or speeding it up, and the radial (centripetal) force, which changes its direction.\n\n\n== Kinematic integrals ==\n\nForces can be used to define a number of physical concepts by integrating with respect to kinematic variables. For example, integrating with respect to time gives the definition of impulse:\nwhich by Newton's Second Law must be equivalent to the change in momentum (yielding the Impulse momentum theorem).\nSimilarly, integrating with respect to position gives a definition for the work done by a force::\u200a13\u20133\u200a\nwhich is equivalent to changes in kinetic energy (yielding the work energy theorem).:\u200a13\u20133\u200aPower P is the rate of change dW/dt of the work W, as the trajectory is extended by a position change \n  \n    \n      \n        d\n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle d{\\vec {x}}}\n   in a time interval dt::\u200a13\u20132\u200a\nso\n\nwith \n  \n    \n      \n        \n          \n            \n              v\n              \u2192\n            \n          \n        \n        =\n        \n          d\n        \n        \n          \n            \n              x\n              \u2192\n            \n          \n        \n        \n          /\n        \n        \n          d\n        \n        t\n      \n    \n    {\\displaystyle {\\vec {v}}=\\mathrm {d} {\\vec {x}}/\\mathrm {d} t}\n   the velocity.\n\n\n== Potential energy ==\n\nInstead of a force, often the mathematically related concept of a potential energy field can be used for convenience. For instance, the gravitational force acting upon an object can be seen as the action of the gravitational field that is present at the object's location. Restating mathematically the definition of energy (via the definition of work), a potential scalar field \n  \n    \n      \n        U\n        (\n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle U({\\vec {r}})}\n   is defined as that field whose gradient is equal and opposite to the force produced at every point:\n\nForces can be classified as conservative or nonconservative. Conservative forces are equivalent to the gradient of a potential while nonconservative forces are not.\n\n\n=== Conservation ===\n\nA conservative force that acts on a closed system has an associated mechanical work that allows energy to convert only between kinetic or potential forms. This means that for a closed system, the net mechanical energy is conserved whenever a conservative force acts on the system. The force, therefore, is related directly to the difference in potential energy between two different locations in space, and can be considered to be an artifact of the potential field in the same way that the direction and amount of a flow of water can be considered to be an artifact of the contour map of the elevation of an area.Conservative forces include gravity, the electromagnetic force, and the spring force. Each of these forces has models that are dependent on a position often given as a radial vector \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   emanating from spherically symmetric potentials. Examples of this follow:\nFor gravity:\n\nwhere \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is the gravitational constant, and \n  \n    \n      \n        \n          m\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle m_{n}}\n   is the mass of object n.\nFor electrostatic forces:\n\nwhere \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   is electric permittivity of free space, and \n  \n    \n      \n        \n          q\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle q_{n}}\n   is the electric charge of object n.\nFor spring forces:\n\nwhere \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the spring constant.For certain physical scenarios, it is impossible to model forces as being due to gradient of potentials. This is often due to macrophysical considerations that yield forces as arising from a macroscopic statistical average of microstates. For example, friction is caused by the gradients of numerous electrostatic potentials between the atoms, but manifests as a force model that is independent of any macroscale position vector. Nonconservative forces other than friction include other contact forces, tension, compression, and drag. For any sufficiently detailed description, all these forces are the results of conservative ones since each of these macroscopic forces are the net results of the gradients of microscopic potentials.The connection between macroscopic nonconservative forces and microscopic conservative forces is described by detailed treatment with statistical mechanics. In macroscopic closed systems, nonconservative forces act to change the internal energies of the system, and are often associated with the transfer of heat. According to the Second law of thermodynamics, nonconservative forces necessarily result in energy transformations within closed systems from ordered to more random conditions as entropy increases.\n\n\n== Units of measurement ==\nThe SI unit of force is the newton (symbol N), which is the force required to accelerate a one kilogram mass at a rate of one meter per second squared, or kg\u00b7m\u00b7s\u22122. The corresponding CGS unit is the dyne, the force required to accelerate a one gram mass by one centimeter per second squared, or g\u00b7cm\u00b7s\u22122. A newton is thus equal to 100,000 dynes.\nThe gravitational foot-pound-second English unit of force is the pound-force (lbf), defined as the force exerted by gravity on a pound-mass in the standard gravitational field of 9.80665 m\u00b7s\u22122. The pound-force provides an alternative unit of mass: one slug is the mass that will accelerate by one foot per second squared when acted on by one pound-force.An alternative unit of force in a different foot-pound-second system, the absolute fps system, is the poundal, defined as the force required to accelerate a one-pound mass at a rate of one foot per second squared. The units of slug and poundal are designed to avoid a constant of proportionality in Newton's Second Law.\nThe pound-force has a metric counterpart, less commonly used than the newton: the kilogram-force (kgf) (sometimes kilopond), is the force exerted by standard gravity on one kilogram of mass. The kilogram-force leads to an alternate, but rarely used unit of mass: the metric slug (sometimes mug or hyl) is that mass that accelerates at 1 m\u00b7s\u22122 when subjected to a force of 1 kgf. The kilogram-force is not a part of the modern SI system, and is generally deprecated, sometimes used for expressing aircraft weight, jet thrust, bicycle spoke tension, torque wrench settings and engine output torque. Other arcane units include the sth\u00e8ne, which is equivalent to 1000 N, and the kip, which is equivalent to 1000 lbf.\n\nSee also Ton-force.\n\n\n== Force measurement ==\nSee force gauge, spring scale, load cell\n\n\n== See also ==\nOrders of magnitude (force)\nParallel force system \u2013 EngineeringPages displaying short descriptions with no spaces\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n\nVideo lecture on Newton's three laws by Walter Lewin from MIT OpenCourseWare\nA Java simulation on vector addition of forces\nForce demonstrated as any influence on an object that changes the object's shape or motion (video)", "Wavelength": "In physics, the wavelength is the spatial period of a periodic wave\u2014the distance over which the wave's shape repeats. It is the distance between consecutive corresponding points of the same phase on the wave, such as two adjacent crests, troughs, or zero crossings, and is a characteristic of both traveling waves and standing waves, as well as other spatial wave patterns. The inverse of the wavelength is called the spatial frequency. Wavelength is commonly designated by the Greek letter lambda (\u03bb).\nThe term wavelength is also sometimes applied to modulated waves, and to the sinusoidal envelopes of modulated waves or waves formed by interference of several sinusoids.Assuming a sinusoidal wave moving at a fixed wave speed, wavelength is inversely proportional to frequency of the wave: waves with higher frequencies have shorter wavelengths, and lower frequencies have longer wavelengths.Wavelength depends on the medium (for example, vacuum, air, or water) that a wave travels through. Examples of waves are sound waves, light, water waves and periodic electrical signals in a conductor. A sound wave is a variation in air pressure, while in light and other electromagnetic radiation the strength of the electric and the magnetic field vary. Water waves are variations in the height of a body of water. In a crystal lattice vibration, atomic positions vary.\nThe range of wavelengths or frequencies for wave phenomena is called a spectrum. The name originated with the visible light spectrum but now can be applied to the entire electromagnetic spectrum as well as to a sound spectrum or vibration spectrum.\n\n\n== Sinusoidal waves ==\nIn linear media, any wave pattern can be described in terms of the independent propagation of sinusoidal components. The wavelength \u03bb of a sinusoidal waveform traveling at constant speed \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is given by\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            v\n            f\n          \n        \n        \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {v}{f}}\\,\\,,}\n  where \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is called the phase speed (magnitude of the phase velocity) of the wave and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the wave's frequency. In a dispersive medium, the phase speed itself depends upon the frequency of the wave, making the relationship between wavelength and frequency nonlinear.\nIn the case of electromagnetic radiation\u2014such as light\u2014in free space, the phase speed is the speed of light, about 3\u00d7108 m/s. Thus the wavelength of a 100 MHz electromagnetic (radio) wave is about: 3\u00d7108 m/s divided by 108 Hz = 3 metres. The wavelength of visible light ranges from deep red, roughly 700 nm, to violet, roughly 400 nm (for other examples, see electromagnetic spectrum).\nFor sound waves in air, the speed of sound is 343 m/s (at room temperature and atmospheric pressure). The wavelengths of sound frequencies audible to the human ear (20 Hz\u201320 kHz) are thus between approximately 17 m and 17 mm, respectively. Somewhat higher frequencies are used by bats so they can resolve targets smaller than 17 mm. Wavelengths in audible sound are much longer than those in visible light.\n\n\n=== Standing waves ===\nA standing wave is an undulatory motion that stays in one place. A sinusoidal standing wave includes stationary points of no motion, called nodes, and the wavelength is twice the distance between nodes.\nThe upper figure shows three standing waves in a box. The walls of the box are considered to require the wave to have nodes at the walls of the box (an example of boundary conditions) determining which wavelengths are allowed. For example, for an electromagnetic wave, if the box has ideal metal walls, the condition for nodes at the walls results because the metal walls cannot support a tangential electric field, forcing the wave to have zero amplitude at the wall.\nThe stationary wave can be viewed as the sum of two traveling sinusoidal waves of oppositely directed velocities. Consequently, wavelength, period, and wave velocity are related just as for a traveling wave. For example, the speed of light can be determined from observation of standing waves in a metal box containing an ideal vacuum.\n\n\n=== Mathematical representation ===\nTraveling sinusoidal waves are often represented mathematically in terms of their velocity v (in the x direction), frequency f and wavelength \u03bb as:\n\n  \n    \n      \n        y\n        (\n        x\n        ,\n         \n        t\n        )\n        =\n        A\n        cos\n        \u2061\n        \n          (\n          \n            2\n            \u03c0\n            \n              (\n              \n                \n                  \n                    x\n                    \u03bb\n                  \n                \n                \u2212\n                f\n                t\n              \n              )\n            \n          \n          )\n        \n        =\n        A\n        cos\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                \n                \u03bb\n              \n            \n            (\n            x\n            \u2212\n            v\n            t\n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle y(x,\\ t)=A\\cos \\left(2\\pi \\left({\\frac {x}{\\lambda }}-ft\\right)\\right)=A\\cos \\left({\\frac {2\\pi }{\\lambda }}(x-vt)\\right)}\n  where y is the value of the wave at any position x and time t, and A is the amplitude of the wave. They are also commonly expressed in terms of wavenumber k (2\u03c0 times the reciprocal of wavelength) and angular frequency \u03c9 (2\u03c0 times the frequency) as:\n\n  \n    \n      \n        y\n        (\n        x\n        ,\n         \n        t\n        )\n        =\n        A\n        cos\n        \u2061\n        \n          (\n          \n            k\n            x\n            \u2212\n            \u03c9\n            t\n          \n          )\n        \n        =\n        A\n        cos\n        \u2061\n        \n          (\n          \n            k\n            (\n            x\n            \u2212\n            v\n            t\n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle y(x,\\ t)=A\\cos \\left(kx-\\omega t\\right)=A\\cos \\left(k(x-vt)\\right)}\n  in which wavelength and wavenumber are related to velocity and frequency as:\n\n  \n    \n      \n        k\n        =\n        \n          \n            \n              2\n              \u03c0\n            \n            \u03bb\n          \n        \n        =\n        \n          \n            \n              2\n              \u03c0\n              f\n            \n            v\n          \n        \n        =\n        \n          \n            \u03c9\n            v\n          \n        \n        ,\n      \n    \n    {\\displaystyle k={\\frac {2\\pi }{\\lambda }}={\\frac {2\\pi f}{v}}={\\frac {\\omega }{v}},}\n  or\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              2\n              \u03c0\n            \n            k\n          \n        \n        =\n        \n          \n            \n              2\n              \u03c0\n              v\n            \n            \u03c9\n          \n        \n        =\n        \n          \n            v\n            f\n          \n        \n        .\n      \n    \n    {\\displaystyle \\lambda ={\\frac {2\\pi }{k}}={\\frac {2\\pi v}{\\omega }}={\\frac {v}{f}}.}\n  In the second form given above, the phase (kx \u2212 \u03c9t) is often generalized to (k\u2022r \u2212 \u03c9t), by replacing the wavenumber k with a wave vector that specifies the direction and wavenumber of a plane wave in 3-space, parameterized by position vector r. In that case, the wavenumber k, the magnitude of k, is still in the same relationship with wavelength as shown above, with v being interpreted as scalar speed in the direction of the wave vector. The first form, using reciprocal wavelength in the phase, does not generalize as easily to a wave in an arbitrary direction.\nGeneralizations to sinusoids of other phases, and to complex exponentials, are also common; see plane wave. The typical convention of using the cosine phase instead of the sine phase when describing a wave is based on the fact that the cosine is the real part of the complex exponential in the wave\n\n  \n    \n      \n        A\n        \n          e\n          \n            i\n            \n              (\n              \n                k\n                x\n                \u2212\n                \u03c9\n                t\n              \n              )\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Ae^{i\\left(kx-\\omega t\\right)}.}\n  \n\n\n=== General media ===\n\nThe speed of a wave depends upon the medium in which it propagates. In particular, the speed of light in a medium is less than in vacuum, which means that the same frequency will correspond to a shorter wavelength in the medium than in vacuum, as shown in the figure at right.\nThis change in speed upon entering a medium causes refraction, or a change in direction of waves that encounter the interface between media at an angle. For electromagnetic waves, this change in the angle of propagation is governed by Snell's law.\nThe wave velocity in one medium not only may differ from that in another, but the velocity typically varies with wavelength. As a result, the change in direction upon entering a different medium changes with the wavelength of the wave.\nFor electromagnetic waves the speed in a medium is governed by its refractive index according to\n\n  \n    \n      \n        v\n        =\n        \n          \n            c\n            \n              n\n              (\n              \n                \u03bb\n                \n                  0\n                \n              \n              )\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle v={\\frac {c}{n(\\lambda _{0})}},}\n  where c is the speed of light in vacuum and n(\u03bb0) is the refractive index of the medium at wavelength \u03bb0, where the latter is measured in vacuum rather than in the medium. The corresponding wavelength in the medium is\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              \u03bb\n              \n                0\n              \n            \n            \n              n\n              (\n              \n                \u03bb\n                \n                  0\n                \n              \n              )\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\lambda ={\\frac {\\lambda _{0}}{n(\\lambda _{0})}}.}\n  When wavelengths of electromagnetic radiation are quoted, the wavelength in vacuum usually is intended unless the wavelength is specifically identified as the wavelength in some other medium. In acoustics, where a medium is essential for the waves to exist, the wavelength value is given for a specified medium.\nThe variation in speed of light with wavelength is known as dispersion, and is also responsible for the familiar phenomenon in which light is separated into component colors by a prism. Separation occurs when the refractive index inside the prism varies with wavelength, so different wavelengths propagate at different speeds inside the prism, causing them to refract at different angles. The mathematical relationship that describes how the speed of light within a medium varies with wavelength is known as a dispersion relation.\n\n\n==== Nonuniform media ====\n\nWavelength can be a useful concept even if the wave is not periodic in space. For example, in an ocean wave approaching shore, shown in the figure, the incoming wave undulates with a varying local wavelength that depends in part on the depth of the sea floor compared to the wave height. The analysis of the wave can be based upon comparison of the local wavelength with the local water depth.\n\nWaves that are sinusoidal in time but propagate through a medium whose properties vary with position (an inhomogeneous medium) may propagate at a velocity that varies with position, and as a result may not be sinusoidal in space. The figure at right shows an example. As the wave slows down, the wavelength gets shorter and the amplitude increases; after a place of maximum response, the short wavelength is associated with a high loss and the wave dies out.\nThe analysis of differential equations of such systems is often done approximately, using the WKB method (also known as the Liouville\u2013Green method). The method integrates phase through space using a local wavenumber, which can be interpreted as indicating a \"local wavelength\" of the solution as a function of time and space.\nThis method treats the system locally as if it were uniform with the local properties; in particular, the local wave velocity associated with a frequency is the only thing needed to estimate the corresponding local wavenumber or wavelength. In addition, the method computes a slowly changing amplitude to satisfy other constraints of the equations or of the physical system, such as for conservation of energy in the wave.\n\n\n==== Crystals ====\n\nWaves in crystalline solids are not continuous, because they are composed of vibrations of discrete particles arranged in a regular lattice. This produces aliasing because the same vibration can be considered to have a variety of different wavelengths, as shown in the figure. Descriptions using more than one of these wavelengths are redundant; it is conventional to choose the longest wavelength that fits the phenomenon. The range of wavelengths sufficient to provide a description of all possible waves in a crystalline medium corresponds to the wave vectors confined to the Brillouin zone.This indeterminacy in wavelength in solids is important in the analysis of wave phenomena such as energy bands and lattice vibrations. It is mathematically equivalent to the aliasing of a signal that is sampled at discrete intervals.\n\n\n== More general waveforms ==\n\nThe concept of wavelength is most often applied to sinusoidal, or nearly sinusoidal, waves, because in a linear system the sinusoid is the unique shape that propagates with no shape change \u2013 just a phase change and potentially an amplitude change. The wavelength (or alternatively wavenumber or wave vector) is a characterization of the wave in space, that is functionally related to its frequency, as constrained by the physics of the system. Sinusoids are the simplest traveling wave solutions, and more complex solutions can be built up by superposition.\nIn the special case of dispersion-free and uniform media, waves other than sinusoids propagate with unchanging shape and constant velocity. In certain circumstances, waves of unchanging shape also can occur in nonlinear media; for example, the figure shows ocean waves in shallow water that have sharper crests and flatter troughs than those of a sinusoid, typical of a cnoidal wave, a traveling wave so named because it is described by the Jacobi elliptic function of m-th order, usually denoted as cn(x; m). Large-amplitude ocean waves with certain shapes can propagate unchanged, because of properties of the nonlinear surface-wave medium.\n\nIf a traveling wave has a fixed shape that repeats in space or in time, it is a periodic wave. Such waves are sometimes regarded as having a wavelength even though they are not sinusoidal. As shown in the figure, wavelength is measured between consecutive corresponding points on the waveform.\n\n\n=== Wave packets ===\n\nLocalized wave packets, \"bursts\" of wave action where each wave packet travels as a unit, find application in many fields of physics. A wave packet has an envelope that describes the overall amplitude of the wave; within the envelope, the distance between adjacent peaks or troughs is sometimes called a local wavelength. An example is shown in the figure. In general, the envelope of the wave packet moves at a speed different from the constituent waves.Using Fourier analysis, wave packets can be analyzed into infinite sums (or integrals) of sinusoidal waves of different wavenumbers or wavelengths.Louis de Broglie postulated that all particles with a specific value of momentum p have a wavelength \u03bb = h/p, where h is Planck's constant. This hypothesis was at the basis of quantum mechanics. Nowadays, this wavelength is called the de Broglie wavelength. For example, the electrons in a CRT display have a De Broglie wavelength of about 10\u221213 m. To prevent the wave function for such a particle being spread over all space, de Broglie proposed using wave packets to represent particles that are localized in space. The spatial spread of the wave packet, and the spread of the wavenumbers of sinusoids that make up the packet, correspond to the uncertainties in the particle's position and momentum, the product of which is bounded by Heisenberg uncertainty principle.\n\n\n== Interference and diffraction ==\n\n\n=== Double-slit interference ===\n\nWhen sinusoidal waveforms add, they may reinforce each other (constructive interference) or cancel each other (destructive interference) depending upon their relative phase. This phenomenon is used in the interferometer. A simple example is an experiment due to Young where light is passed through two slits.\nAs shown in the figure, light is passed through two slits and shines on a screen. The path of the light to a position on the screen is different for the two slits, and depends upon the angle \u03b8 the path makes with the screen. If we suppose the screen is far enough from the slits (that is, s is large compared to the slit separation d) then the paths are nearly parallel, and the path difference is simply d sin \u03b8. Accordingly, the condition for constructive interference is:\n\n  \n    \n      \n        d\n        sin\n        \u2061\n        \u03b8\n        =\n        m\n        \u03bb\n         \n        ,\n      \n    \n    {\\displaystyle d\\sin \\theta =m\\lambda \\ ,}\n  where m is an integer, and for destructive interference is:\n\n  \n    \n      \n        d\n        sin\n        \u2061\n        \u03b8\n        =\n        (\n        m\n        +\n        1\n        \n          /\n        \n        2\n        )\n        \u03bb\n         \n        .\n      \n    \n    {\\displaystyle d\\sin \\theta =(m+1/2)\\lambda \\ .}\n  Thus, if the wavelength of the light is known, the slit separation can be determined from the interference pattern or fringes, and vice versa.\nFor multiple slits, the pattern is\n\n  \n    \n      \n        \n          I\n          \n            q\n          \n        \n        =\n        \n          I\n          \n            1\n          \n        \n        \n          sin\n          \n            2\n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                q\n                \u03c0\n                g\n                sin\n                \u2061\n                \u03b1\n              \n              \u03bb\n            \n          \n          )\n        \n        \n          /\n        \n        \n          sin\n          \n            2\n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                \u03c0\n                g\n                sin\n                \u2061\n                \u03b1\n              \n              \u03bb\n            \n          \n          )\n        \n         \n        ,\n      \n    \n    {\\displaystyle I_{q}=I_{1}\\sin ^{2}\\left({\\frac {q\\pi g\\sin \\alpha }{\\lambda }}\\right)/\\sin ^{2}\\left({\\frac {\\pi g\\sin \\alpha }{\\lambda }}\\right)\\ ,}\n  where q is the number of slits, and g is the grating constant. The first factor, I1, is the single-slit result, which modulates the more rapidly varying second factor that depends upon the number of slits and their spacing. In the figure I1 has been set to unity, a very rough approximation.\nThe effect of interference is to redistribute the light, so the energy contained in the light is not altered, just where it shows up.\n\n\n=== Single-slit diffraction ===\n\nThe notion of path difference and constructive or destructive interference used above for the double-slit experiment applies as well to the display of a single slit of light intercepted on a screen. The main result of this interference is to spread out the light from the narrow slit into a broader image on the screen. This distribution of wave energy is called diffraction.\nTwo types of diffraction are distinguished, depending upon the separation between the source and the screen: Fraunhofer diffraction or far-field diffraction at large separations and Fresnel diffraction or near-field diffraction at close separations.\nIn the analysis of the single slit, the non-zero width of the slit is taken into account, and each point in the aperture is taken as the source of one contribution to the beam of light (Huygens' wavelets). On the screen, the light arriving from each position within the slit has a different path length, albeit possibly a very small difference. Consequently, interference occurs.\nIn the Fraunhofer diffraction pattern sufficiently far from a single slit, within a small-angle approximation, the intensity spread S is related to position x via a squared sinc function:\n\n  \n    \n      \n        S\n        (\n        u\n        )\n        =\n        \n          \n            s\n            i\n            n\n            c\n          \n          \n            2\n          \n        \n        (\n        u\n        )\n        =\n        \n          \n            (\n            \n              \n                \n                  sin\n                  \u2061\n                  \u03c0\n                  u\n                \n                \n                  \u03c0\n                  u\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n         \n        ;\n      \n    \n    {\\displaystyle S(u)=\\mathrm {sinc} ^{2}(u)=\\left({\\frac {\\sin \\pi u}{\\pi u}}\\right)^{2}\\ ;}\n   \u2002with\u2002 \n  \n    \n      \n        u\n        =\n        \n          \n            \n              x\n              L\n            \n            \n              \u03bb\n              R\n            \n          \n        \n         \n        ,\n      \n    \n    {\\displaystyle u={\\frac {xL}{\\lambda R}}\\ ,}\n  where L is the slit width, R is the distance of the pattern (on the screen) from the slit, and \u03bb is the wavelength of light used. The function S has zeros where u is a non-zero integer, where are at x values at a separation proportion to wavelength.\n\n\n=== Diffraction-limited resolution ===\n\nDiffraction is the fundamental limitation on the resolving power of optical instruments, such as telescopes (including radiotelescopes) and microscopes.\nFor a circular aperture, the diffraction-limited image spot is known as an Airy disk; the distance x in the single-slit diffraction formula is replaced by radial distance r and the sine is replaced by 2J1, where J1 is a first order Bessel function.The resolvable spatial size of objects viewed through a microscope is limited according to the Rayleigh criterion, the radius to the first null of the Airy disk, to a size proportional to the wavelength of the light used, and depending on the numerical aperture:\n\n  \n    \n      \n        \n          r\n          \n            A\n            i\n            r\n            y\n          \n        \n        =\n        1.22\n        \n          \n            \u03bb\n            \n              2\n              \n                N\n                A\n              \n            \n          \n        \n         \n        ,\n      \n    \n    {\\displaystyle r_{Airy}=1.22{\\frac {\\lambda }{2\\mathrm {NA} }}\\ ,}\n  where the numerical aperture is defined as \n  \n    \n      \n        \n          N\n          A\n        \n        =\n        n\n        sin\n        \u2061\n        \u03b8\n        \n      \n    \n    {\\displaystyle \\mathrm {NA} =n\\sin \\theta \\;}\n   for \u03b8 being the half-angle of the cone of rays accepted by the microscope objective.\nThe angular size of the central bright portion (radius to first null of the Airy disk) of the image diffracted by a circular aperture, a measure most commonly used for telescopes and cameras, is:\n\n  \n    \n      \n        \u03b4\n        =\n        1.22\n        \n          \n            \u03bb\n            D\n          \n        \n         \n        ,\n      \n    \n    {\\displaystyle \\delta =1.22{\\frac {\\lambda }{D}}\\ ,}\n  where \u03bb is the wavelength of the waves that are focused for imaging, D the entrance pupil diameter of the imaging system, in the same units, and the angular resolution \u03b4 is in radians.\nAs with other diffraction patterns, the pattern scales in proportion to wavelength, so shorter wavelengths can lead to higher resolution.\n\n\n== Subwavelength ==\nThe term subwavelength is used to describe an object having one or more dimensions smaller than the length of the wave with which the object interacts. For example, the term subwavelength-diameter optical fibre means an optical fibre whose diameter is less than the wavelength of light propagating through it.\nA subwavelength particle is a particle smaller than the wavelength of light with which it interacts (see Rayleigh scattering). Subwavelength apertures are holes smaller than the wavelength of light propagating through them. Such structures have applications in extraordinary optical transmission, and zero-mode waveguides, among other areas of photonics.\nSubwavelength may also refer to a phenomenon involving subwavelength objects; for example, subwavelength imaging.\n\n\n== Angular wavelength ==\n\nA quantity related to the wavelength is the angular wavelength (also known as reduced wavelength), usually symbolized by \u019b (lambda-bar). It is equal to the \"regular\" wavelength \"reduced\" by a factor of 2\u03c0 (\u019b = \u03bb/2\u03c0). It is usually encountered in quantum mechanics, where it is used in combination with the reduced Planck constant (symbol \u0127, h-bar) and the angular frequency (symbol \u03c9) or angular wavenumber (symbol k). It is also used to measure the amplitude of mechanical waves, where the amplitude is equal to displacement divided by reduced wavelength.\n\n\n== See also ==\nEmission spectrum\nEnvelope (waves)\nFraunhofer lines \u2013 dark lines in the solar spectrum, traditionally used as standard optical wavelength references\nIndex of wave articles\nLength measurement\nSpectral line\nSpectroscopy\nSpectrum\n\n\n== References ==\n\n\n== External links ==\n\nConversion: Wavelength to Frequency and vice versa \u2013 Sound waves and radio waves\nTeaching resource for 14\u201316 years on sound including wavelength\nThe visible electromagnetic spectrum displayed in web colors with according wavelengths", "Field_(physics)": "In physics, a field is a physical quantity, represented by a scalar, vector, or tensor, that has a value for each point in space and time. For example, on a weather map, the surface temperature is described by assigning a number to each point on the map; the temperature can be considered at a certain point in time or over some interval of time, to study the dynamics of temperature change. A surface wind map, assigning an arrow to each point on a map that describes the wind speed and direction at that point, is an example of a vector field, i.e. a 1-dimensional (rank-1) tensor field. Field theories, mathematical descriptions of how field values change in space and time, are ubiquitous in physics. For instance, the electric field is another rank-1 tensor field, while electrodynamics can be formulated in terms of two interacting vector fields at each point in spacetime, or as a single-rank 2-tensor field.In the modern framework of the quantum theory of fields, even without referring to a test particle, a field occupies space, contains energy, and its presence precludes a classical \"true vacuum\". This has led physicists to consider electromagnetic fields to be a physical entity, making the field concept a supporting paradigm of the edifice of modern physics. \"The fact that the electromagnetic field can possess momentum and energy makes it very real ... a particle makes a field, and a field acts on another particle, and the field has such familiar properties as energy content and momentum, just as particles can have.\" In practice, the strength of most fields diminishes with distance, eventually becoming undetectable. For instance the strength of many relevant classical fields, such as the gravitational field in Newton's theory of gravity or the electrostatic field in classical electromagnetism, is inversely proportional to the square of the distance from the source (i.e., they follow Gauss's law). \nA field can be classified as a scalar field, a vector field, a spinor field or a tensor field according to whether the represented physical quantity is a scalar, a vector, a spinor, or a tensor, respectively. A field has a consistent tensorial character wherever it is defined: i.e. a field cannot be a scalar field somewhere and a vector field somewhere else. For example, the Newtonian gravitational field is a vector field: specifying its value at a point in spacetime requires three numbers, the components of the gravitational field vector at that point. Moreover, within each category (scalar, vector, tensor), a field can be either a classical field or a quantum field, depending on whether it is characterized by numbers or quantum operators respectively. In this theory an equivalent representation of field is a field particle, for instance a boson.\n\n\n== History ==\nTo Isaac Newton, his law of universal gravitation simply expressed the gravitational force that acted between any pair of massive objects. When looking at the motion of many bodies all interacting with each other, such as the planets in the Solar System, dealing with the force between each pair of bodies separately rapidly becomes computationally inconvenient. In the eighteenth century, a new quantity was devised to simplify the bookkeeping of all these gravitational forces. This quantity, the gravitational field, gave at each point in space the total gravitational acceleration which would be felt by a small object at that point. This did not change the physics in any way: it did not matter if all the gravitational forces on an object were calculated individually and then added together, or if all the contributions were first added together as a gravitational field and then applied to an object.The development of the independent concept of a field truly began in the nineteenth century with the development of the theory of electromagnetism. In the early stages, Andr\u00e9-Marie Amp\u00e8re and Charles-Augustin de Coulomb could manage with Newton-style laws that expressed the forces between pairs of electric charges or electric currents. However, it became much more natural to take the field approach and express these laws in terms of electric and magnetic fields; in 1849 Michael Faraday became the first to coin the term \"field\".The independent nature of the field became more apparent with James Clerk Maxwell's discovery that waves in these fields propagated at a finite speed. Consequently, the forces on charges and currents no longer just depended on the positions and velocities of other charges and currents at the same time, but also on their positions and velocities in the past.Maxwell, at first, did not adopt the modern concept of a field as a fundamental quantity that could independently exist. Instead, he supposed that the electromagnetic field expressed the deformation of some underlying medium\u2014the luminiferous aether\u2014much like the tension in a rubber membrane. If that were the case, the observed velocity of the electromagnetic waves should depend upon the velocity of the observer with respect to the aether. Despite much effort, no experimental evidence of such an effect was ever found; the situation was resolved by the introduction of the special theory of relativity by Albert Einstein in 1905. This theory changed the way the viewpoints of moving observers were related to each other.  They became related to each other in such a way that velocity of electromagnetic waves in Maxwell's theory would be the same for all observers. By doing away with the need for a background medium, this development opened the way for physicists to start thinking about fields as truly independent entities.In the late 1920s, the new rules of quantum mechanics were first applied to the electromagnetic field. In 1927, Paul Dirac used quantum fields to successfully explain how the decay of an atom to a lower quantum state led to the spontaneous emission of a photon, the quantum of the electromagnetic field. This was soon followed by the realization (following the work of Pascual Jordan, Eugene Wigner, Werner Heisenberg, and Wolfgang Pauli) that all particles, including electrons and protons, could be understood as the quanta of some quantum field, elevating fields to the status of the most fundamental objects in nature. That said, John Wheeler and Richard Feynman seriously considered Newton's pre-field concept of action at a distance (although they set it aside because of the ongoing utility of the field concept for research in general relativity and quantum electrodynamics).\n\n\n== Classical fields ==\n\nThere are several examples of classical fields. Classical field theories remain useful wherever quantum properties do not arise, and can be active areas of research. Elasticity of materials, fluid dynamics and Maxwell's equations are cases in point.\nSome of the simplest physical fields are vector force fields. Historically, the first time that fields were taken seriously was with Faraday's lines of force when describing the electric field. The gravitational field was then similarly described.\n\n\n=== Newtonian gravitation ===\n\nA classical field theory describing gravity is Newtonian gravitation, which describes the gravitational force as a mutual interaction between two masses.\nAny body with mass M is associated with a gravitational field g which describes its influence on other bodies with mass. The gravitational field of M at a point r in space corresponds to the ratio between force F that M exerts on a small or negligible test mass m located at r and the test mass itself:\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          \n            \n              \n                F\n              \n              (\n              \n                r\n              \n              )\n            \n            m\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )={\\frac {\\mathbf {F} (\\mathbf {r} )}{m}}.}\n  Stipulating that m is much smaller than M ensures that the presence of m has a negligible influence on the behavior of M.\nAccording to Newton's law of universal gravitation, F(r) is given by\n\n  \n    \n      \n        \n          F\n        \n        (\n        \n          r\n        \n        )\n        =\n        \u2212\n        \n          \n            \n              G\n              M\n              m\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {r} )=-{\\frac {GMm}{r^{2}}}{\\hat {\\mathbf {r} }},}\n  where \n  \n    \n      \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {r} }}}\n   is a unit vector lying along the line joining M and m and pointing from M to m. Therefore, the gravitational field of M is\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          \n            \n              \n                F\n              \n              (\n              \n                r\n              \n              )\n            \n            m\n          \n        \n        =\n        \u2212\n        \n          \n            \n              G\n              M\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )={\\frac {\\mathbf {F} (\\mathbf {r} )}{m}}=-{\\frac {GM}{r^{2}}}{\\hat {\\mathbf {r} }}.}\n  The experimental observation that inertial mass and gravitational mass are equal to an unprecedented level of accuracy leads to the identity that gravitational field strength is identical to the acceleration experienced by a particle. This is the starting point of the equivalence principle, which leads to general relativity.\nBecause the gravitational force F is conservative, the gravitational field g can be rewritten in terms of the gradient of a scalar function, the gravitational potential \u03a6(r):\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \u2212\n        \u2207\n        \u03a6\n        (\n        \n          r\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )=-\\nabla \\Phi (\\mathbf {r} ).}\n  \n\n\n=== Electromagnetism ===\n\nMichael Faraday first realized the importance of a field as a physical quantity, during his investigations into magnetism. He realized that electric and magnetic fields are not only fields of force which dictate the motion of particles, but also have an independent physical reality because they carry energy.\nThese ideas eventually led to the creation, by James Clerk Maxwell, of the first unified field theory in physics with the introduction of equations for the electromagnetic field. The modern version of these equations is called Maxwell's equations.\n\n\n==== Electrostatics ====\n\nA charged test particle with charge q experiences a force F based solely on its charge. We can similarly describe the electric field E so that F = qE. Using this and Coulomb's law tells us that the electric field due to a single charged particle is\n\n  \n    \n      \n        \n          E\n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03f5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \n            q\n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {E} ={\\frac {1}{4\\pi \\epsilon _{0}}}{\\frac {q}{r^{2}}}{\\hat {\\mathbf {r} }}.}\n  The electric field is conservative, and hence can be described by a scalar potential, V(r):\n\n  \n    \n      \n        \n          E\n        \n        (\n        \n          r\n        \n        )\n        =\n        \u2212\n        \u2207\n        V\n        (\n        \n          r\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {E} (\\mathbf {r} )=-\\nabla V(\\mathbf {r} ).}\n  \n\n\n==== Magnetostatics ====\n\nA steady current I flowing along a path \u2113 will create a field B, that exerts a force on nearby moving charged particles that is quantitatively different from the electric field force described above. The force exerted by I on a nearby charge q with velocity v is\n\n  \n    \n      \n        \n          F\n        \n        (\n        \n          r\n        \n        )\n        =\n        q\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        (\n        \n          r\n        \n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {r} )=q\\mathbf {v} \\times \\mathbf {B} (\\mathbf {r} ),}\n  where B(r) is the magnetic field, which is determined from I by the Biot\u2013Savart law:\n\n  \n    \n      \n        \n          B\n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          \n            \n              \u03bc\n              \n                0\n              \n            \n            \n              4\n              \u03c0\n            \n          \n        \n        \u222b\n        \n          \n            \n              I\n              d\n              \n                \u2113\n              \n              \u00d7\n              \n                \n                  \n                    \n                      r\n                    \n                    ^\n                  \n                \n              \n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {B} (\\mathbf {r} )={\\frac {\\mu _{0}}{4\\pi }}\\int {\\frac {Id{\\boldsymbol {\\ell }}\\times {\\hat {\\mathbf {r} }}}{r^{2}}}.}\n  The magnetic field is not conservative in general, and hence cannot usually be written in terms of a scalar potential. However, it can be written in terms of a vector potential, A(r):\n\n  \n    \n      \n        \n          B\n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          \u2207\n        \n        \u00d7\n        \n          A\n        \n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {B} (\\mathbf {r} )={\\boldsymbol {\\nabla }}\\times \\mathbf {A} (\\mathbf {r} )}\n  \n\n\n==== Electrodynamics ====\n\nIn general, in the presence of both a charge density \u03c1(r, t) and current density J(r, t), there will be both an electric and a magnetic field, and both will vary in time. They are determined by Maxwell's equations, a set of differential equations which directly relate E and B to \u03c1 and J.Alternatively, one can describe the system in terms of its scalar and vector potentials V and A. A set of integral equations known as retarded potentials allow one to calculate V and A from \u03c1 and J, and from there the electric and magnetic fields are determined via the relations\n\n  \n    \n      \n        \n          E\n        \n        =\n        \u2212\n        \n          \u2207\n        \n        V\n        \u2212\n        \n          \n            \n              \u2202\n              \n                A\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {E} =-{\\boldsymbol {\\nabla }}V-{\\frac {\\partial \\mathbf {A} }{\\partial t}}}\n  \n\n  \n    \n      \n        \n          B\n        \n        =\n        \n          \u2207\n        \n        \u00d7\n        \n          A\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {B} ={\\boldsymbol {\\nabla }}\\times \\mathbf {A} .}\n  At the end of the 19th century, the electromagnetic field was understood as a collection of two vector fields in space. Nowadays, one recognizes this as a single antisymmetric 2nd-rank tensor field in spacetime.\n\n\n=== Gravitation in general relativity ===\n\nEinstein's theory of gravity, called general relativity, is another example of a field theory. Here the principal field is the metric tensor, a symmetric 2nd-rank tensor field in spacetime. This replaces Newton's law of universal gravitation.\n\n\n=== Waves as fields ===\nWaves can be constructed as physical fields, due to their finite propagation speed and causal nature when a simplified physical model of an isolated closed system is set. They are also subject to the inverse-square law.\nFor electromagnetic waves, there are optical fields, and terms such as near- and far-field limits for diffraction. In practice though, the field theories of optics are superseded by the electromagnetic field theory of Maxwell.\n\n\n== Quantum fields ==\n\nIt is now believed that quantum mechanics should underlie all physical phenomena, so that a classical field theory should, at least in principle, permit a recasting in quantum mechanical terms; success yields the corresponding quantum field theory. For example, quantizing classical electrodynamics gives quantum electrodynamics. Quantum electrodynamics is arguably the most successful scientific theory; experimental data confirm its predictions to a higher precision (to more significant digits) than any other theory.  The two other fundamental quantum field theories are quantum chromodynamics and the electroweak theory.\n\nIn quantum chromodynamics, the color field lines are coupled at short distances by gluons, which are polarized by the field and line up with it. This effect increases within a short distance (around 1 fm from the vicinity of the quarks) making the color force increase within a short distance, confining the quarks within hadrons. As the field lines are pulled together tightly by gluons, they do not \"bow\" outwards as much as an electric field between electric charges.These three quantum field theories can all be derived as special cases of the so-called standard model of particle physics. General relativity, the Einsteinian field theory of gravity, has yet to be successfully quantized. However an extension, thermal field theory, deals with quantum field theory at finite temperatures, something seldom considered in quantum field theory.\nIn BRST theory one deals with odd fields, e.g. Faddeev\u2013Popov ghosts. There are different descriptions of odd classical fields both on graded manifolds and supermanifolds.\nAs above with classical fields, it is possible to approach their quantum counterparts from a purely mathematical view using similar techniques as before. The equations governing the quantum fields are in fact PDEs (specifically, relativistic wave equations (RWEs)). Thus one can speak of Yang\u2013Mills, Dirac, Klein\u2013Gordon and Schr\u00f6dinger fields as being solutions to their respective equations. A possible problem is that these RWEs can deal with complicated mathematical objects with exotic algebraic properties (e.g. spinors are not tensors, so may need calculus for spinor fields), but these in theory can still be subjected to analytical methods given appropriate mathematical generalization.\n\n\n== Field theory ==\nField theory usually refers to a construction of the dynamics of a field, i.e., a specification of how a field changes with time or with respect to other independent physical variables on which the field depends. Usually this is done by writing a Lagrangian or a Hamiltonian of the field, and treating it as a classical or quantum mechanical system with an infinite number of degrees of freedom. The resulting field theories are referred to as classical or quantum field theories.\nThe dynamics of a classical field are usually specified by the Lagrangian density in terms of the field components; the dynamics can be obtained by using the action principle.\nIt is possible to construct simple fields without any prior knowledge of physics using only mathematics from multivariable calculus, potential theory and partial differential equations (PDEs). For example, scalar PDEs might consider quantities such as amplitude, density and pressure fields for the wave equation and fluid dynamics; temperature/concentration fields for the heat/diffusion equations. Outside of physics proper (e.g., radiometry and computer graphics), there are even light fields. All these previous examples are scalar fields. Similarly for vectors, there are vector PDEs for displacement, velocity and vorticity fields in (applied mathematical) fluid dynamics, but vector calculus may now be needed in addition, being calculus for vector fields (as are these three quantities, and those for vector PDEs in general). More generally problems in continuum mechanics may involve for example, directional elasticity (from which comes the term tensor, derived from the Latin word for stretch), complex fluid flows or anisotropic diffusion, which are framed as matrix-tensor PDEs, and then require matrices or tensor fields, hence matrix or tensor calculus. The scalars (and hence the vectors, matrices and tensors) can be real or complex as both are fields in the abstract-algebraic/ring-theoretic sense.\nIn a general setting, classical fields are described by sections of fiber bundles and their dynamics is formulated in the terms of jet manifolds (covariant classical field theory).In modern physics, the most often studied fields are those that model the four fundamental forces which one day may lead to the Unified Field Theory.\n\n\n=== Symmetries of fields ===\nA convenient way of classifying a field (classical or quantum) is by the symmetries it possesses. Physical symmetries are usually of two types:\n\n\n==== Spacetime symmetries ====\n\nFields are often classified by their behaviour under transformations of spacetime. The terms used in this classification are:\n\nscalar fields (such as temperature) whose values are given by a single variable at each point of space. This value does not change under transformations of space.\nvector fields (such as the magnitude and direction of the force at each point in a magnetic field) which are specified by attaching a vector to each point of space. The components of this vector transform between themselves contravariantly under rotations in space. Similarly, a dual (or co-) vector field attaches a dual vector to each point of space, and the components of each dual vector transform covariantly.\ntensor fields, (such as the stress tensor of a crystal) specified by a tensor at each point of space. Under rotations in space, the components of the tensor transform in a more general way which depends on the number of covariant indices and contravariant indices.\nspinor fields (such as the Dirac spinor) arise in quantum field theory to describe particles with spin which transform like vectors except for one of their components; in other words, when one rotates a vector field 360 degrees around a specific axis, the vector field turns to itself; however, spinors would turn to their negatives in the same case.\n\n\n==== Internal symmetries ====\n\nFields may have internal symmetries in addition to spacetime symmetries. In many situations, one needs fields which are a list of spacetime scalars: (\u03c61, \u03c62, ... \u03c6N). For example, in weather prediction these may be temperature, pressure, humidity, etc. In particle physics, the color symmetry of the interaction of quarks is an example of an internal symmetry, that of the strong interaction. Other examples are isospin, weak isospin, strangeness and any other flavour symmetry.\nIf there is a symmetry of the problem, not involving spacetime, under which these components transform into each other, then this set of symmetries is called an internal symmetry. One may also make a classification of the charges of the fields under internal symmetries.\n\n\n=== Statistical field theory ===\n\nStatistical field theory attempts to extend the field-theoretic paradigm toward many-body  systems and statistical mechanics. As above, it can be approached by the usual infinite number of degrees of freedom argument.\nMuch like statistical mechanics has some overlap between quantum and classical mechanics, statistical field theory has links to both quantum and classical field theories, especially the former with which it shares many methods. One important example is mean field theory.\n\n\n=== Continuous random fields ===\nClassical fields as above, such as the electromagnetic field, are usually infinitely differentiable functions, but they are in any case almost always twice differentiable. In contrast, generalized functions are not continuous. When dealing carefully with classical fields at finite temperature, the mathematical methods of continuous random fields are used, because thermally fluctuating classical fields are nowhere differentiable. Random fields are indexed sets of random variables; a continuous random field is a random field that has a set of functions as its index set. In particular, it is often mathematically convenient to take a continuous random field to have a Schwartz space of functions as its index set, in which case the continuous random field is a tempered distribution.\nWe can think about a continuous random field, in a (very) rough way, as an ordinary function that is \n  \n    \n      \n        \u00b1\n        \u221e\n      \n    \n    {\\displaystyle \\pm \\infty }\n   almost everywhere, but such that when we take a weighted average of all the infinities over any finite region, we get a finite result. The infinities are not well-defined; but the finite values can be associated with the functions used as the weight functions to get the finite values, and that can be well-defined. We can define a continuous random field well enough as a linear map from a space of functions into the real numbers.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\n\"Fields\". Principles of Physical Science. Encyclop\u00e6dia Britannica (Macropaedia). Vol. 25 (15th ed.). 1994. p. 815.\nLandau, Lev D. and Lifshitz, Evgeny M. (1971). Classical Theory of Fields (3rd ed.). London: Pergamon. ISBN 0-08-016019-0. Vol. 2 of the Course of Theoretical Physics.\nJepsen, Kathryn (July 18, 2013). \"Real talk: Everything is made of fields\" (PDF). Symmetry Magazine.\n\n\n== External links ==\n\nParticle and Polymer Field Theories", "Inelastic_collision": "An inelastic collision, in contrast to an elastic collision, is a collision in which kinetic energy is not conserved due to the action of internal friction.\nIn collisions of macroscopic bodies, some kinetic energy is turned into vibrational energy of the atoms, causing a heating effect, and the bodies are deformed.\nThe molecules of a gas or liquid rarely experience perfectly elastic collisions because kinetic energy is exchanged between the molecules' translational motion and their internal degrees of freedom with each collision. At any one instant, half the collisions are \u2013 to a varying extent \u2013 inelastic (the pair possesses less kinetic energy after the collision than before), and half could be described as \u201csuper-elastic\u201d (possessing more kinetic energy after the collision than before). Averaged across an entire sample, molecular collisions are elastic.Although inelastic collisions do not conserve kinetic energy, they do obey conservation of momentum. Simple ballistic pendulum problems obey the conservation of kinetic energy only when the block swings to its largest angle.\nIn nuclear physics, an inelastic collision is one in which the incoming particle causes the nucleus it strikes to become excited or to break up. Deep inelastic scattering is a method of probing the structure of subatomic particles in much the same way as Rutherford probed the inside of the atom (see Rutherford scattering). Such experiments were performed on protons in the late 1960s using high-energy electrons at the Stanford Linear Accelerator (SLAC). As in Rutherford scattering, deep inelastic scattering of electrons by proton targets revealed that most of the incident electrons interact very little and pass straight through, with only a small number bouncing back. This indicates that the charge in the proton is concentrated in small lumps, reminiscent of Rutherford's discovery that the positive charge in an atom is concentrated at the nucleus. However, in the case of the proton, the evidence suggested three distinct concentrations of charge (quarks) and not one.\n\n\n== Formula ==\nThe formula for the velocities after a one-dimensional collision is:\n\nwhere\n\nva is the final velocity of the first object after impact\nvb is the final velocity of the second object after impact\nua is the initial velocity of the first object before impact\nub is the initial velocity of the second object before impact\nma is the mass of the first object\nmb is the mass of the second object\nCR is the coefficient of restitution; if it is 1 we have an elastic collision; if it is 0 we have a perfectly inelastic collision, see below.In a center of momentum frame the formulas reduce to:\n\nFor two- and three-dimensional collisions the velocities in these formulas are the components perpendicular to the tangent line/plane at the point of contact.\nIf assuming the objects are not rotating before or after the collision, the normal impulse is:\n\nwhere \n  \n    \n      \n        \n          \n            \n              n\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {n}}}\n   is the normal vector.\nAssuming no friction, this gives the velocity updates:\n\n\n== Perfectly inelastic collision ==\n\nA perfectly inelastic collision occurs when the maximum amount of kinetic energy\nof a system is lost. In a perfectly inelastic collision, i.e., a zero coefficient of restitution,  the colliding particles stick together. In such a collision, kinetic energy is lost by bonding the two bodies together. This bonding energy usually results in a maximum kinetic energy loss of the system. It is necessary to consider conservation of momentum: (Note: In the sliding block example above, momentum of the two body system is only conserved if the surface has zero friction. With friction, momentum of the two bodies is transferred to the surface that the two bodies are sliding upon. Similarly, if there is air resistance, the momentum of the bodies can be transferred to the air.) The equation below holds true for the two-body (Body A, Body B) system collision in the example above. In this example, momentum of the system is conserved because there is no friction between the sliding bodies and the surface.\n\nwhere v is the final velocity, which is hence given by\n\nThe reduction of total kinetic energy is equal to the total kinetic energy before the collision in a center of momentum frame with respect to the system of two particles, because in such a frame the kinetic energy after the collision is zero. In this frame most of the kinetic energy before the collision is that of the particle with the smaller mass. In another frame, in addition to the reduction of kinetic energy there may be a transfer of kinetic energy from one particle to the other; the fact that this depends on the frame shows how relative this is. The reduction of kinetic energy \n  \n    \n      \n        \n          E\n          \n            r\n          \n        \n      \n    \n    {\\displaystyle E_{r}}\n   is hence:\n\nWith time reversed we have the situation of two objects pushed away from each other, e.g. shooting a projectile, or a rocket applying thrust (compare the derivation of the Tsiolkovsky rocket equation).\n\n\n== Partially inelastic collisions ==\nPartially inelastic collisions are the most common form of collisions in the real world. In this type of collision, the objects involved in the collisions do not stick, but some kinetic energy is still lost. Friction, sound and heat are some ways the kinetic energy can be lost through partial inelastic collisions.\n\n\n== References ==", "Euclidean_vector": "In mathematics, physics, and engineering, a Euclidean vector or simply a vector (sometimes called a geometric vector or spatial vector) is a geometric object that has magnitude (or length) and direction. Vectors can be added to other vectors according to vector algebra. A Euclidean vector is frequently represented by a directed line segment, or graphically as an arrow connecting an initial point A with a terminal point B, and denoted by \n  \n    \n      \n        \n          \n            \n              A\n              B\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle {\\overrightarrow {AB}}}\n   . \nA vector is what is needed to \"carry\" the point A to the point B; the Latin word vector means \"carrier\". It was first used by 18th century astronomers investigating planetary revolution around the Sun. The magnitude of the vector is the distance between the two points, and the direction refers to the direction of displacement from A to B. Many algebraic operations on real numbers such as addition, subtraction, multiplication, and negation have close analogues for vectors, operations which obey the familiar algebraic laws of commutativity, associativity, and distributivity. These operations and associated laws qualify Euclidean vectors as an example of the more generalized concept of vectors defined simply as elements of a vector space.\nVectors play an important role in physics: the velocity and acceleration of a moving object and the forces acting on it can all be described with vectors. Many other physical quantities can be usefully thought of as vectors. Although most of them do not represent distances (except, for example, position or displacement), their magnitude and direction can still be represented by the length and direction of an arrow. The mathematical representation of a physical vector depends on the coordinate system used to describe it. Other vector-like objects that describe physical quantities and transform in a similar way under changes of the coordinate system include pseudovectors and tensors.\n\n\n== History ==\nThe vector concept, as we know it today, is the result of a gradual development over a period of more than 200 years. About a dozen people contributed significantly to its development. In 1835, Giusto Bellavitis abstracted the basic idea when he established the concept of equipollence. Working in a Euclidean plane, he made equipollent any pair of parallel line segments of the same length and orientation. Essentially, he realized an equivalence relation on the pairs of points (bipoints) in the plane, and thus erected the first space of vectors in the plane.:\u200a52\u20134\u200a The term vector was introduced by William Rowan Hamilton as part of a quaternion, which is a sum q = s + v of a real number s (also called scalar) and a 3-dimensional vector. Like Bellavitis, Hamilton viewed vectors as representative of classes of equipollent directed segments. As complex numbers use an imaginary unit to complement the real line, Hamilton considered the vector v to be the imaginary part of a quaternion:\nThe algebraically imaginary part, being geometrically constructed by a straight line, or radius vector, which has, in general, for each determined quaternion, a determined length and determined direction in space, may be called the vector part, or simply the vector of the quaternion.\nSeveral other mathematicians developed vector-like systems in the middle of the nineteenth century,  including Augustin Cauchy, Hermann Grassmann, August M\u00f6bius, Comte de Saint-Venant, and Matthew O'Brien. Grassmann's 1840 work Theorie der Ebbe und Flut (Theory of the Ebb and Flow) was the first system of spatial analysis that is similar to today's system, and had ideas corresponding to the cross product, scalar product and vector differentiation. Grassmann's work was largely neglected until the 1870s. Peter Guthrie Tait carried the quaternion standard after Hamilton. His 1867 Elementary Treatise of Quaternions included extensive treatment of the nabla or del operator \u2207. In 1878, Elements of Dynamic was published by William Kingdon Clifford. Clifford simplified the quaternion study by isolating the dot product and cross product of two vectors from the complete quaternion product. This approach made vector calculations available to engineers\u2014and others working in three dimensions and skeptical of the fourth.\nJosiah Willard Gibbs, who was exposed to quaternions through James Clerk Maxwell's Treatise on Electricity and Magnetism, separated off their vector part for independent treatment. The first half of Gibbs's Elements of Vector Analysis, published in 1881, presents what is essentially the modern system of vector analysis. In 1901, Edwin Bidwell Wilson published Vector Analysis, adapted from Gibb's lectures, which banished any mention of quaternions in the development of vector calculus.\n\n\n== Overview ==\nIn physics and engineering, a vector is typically regarded as a geometric entity characterized by a magnitude and a direction. It is formally defined as a directed line segment, or arrow, in a Euclidean space. In pure mathematics, a vector is defined more generally as any element of a vector space. In this context, vectors are abstract entities which may or may not be characterized by a magnitude and a direction. This generalized definition implies that the above-mentioned geometric entities are a special kind of vectors, as they are elements of a special kind of vector space called Euclidean space. This particular article is about vectors strictly defined as arrows in Euclidean space. When it becomes necessary to distinguish these special vectors from vectors as defined in pure mathematics, they are sometimes referred to as geometric, spatial, or Euclidean vectors.\nBeing an arrow, a Euclidean vector possesses a definite initial point and terminal point. A vector with fixed initial and terminal point is called a bound vector. When only the magnitude and direction of the vector matter, then the particular initial point is of no importance, and the vector is called a free vector. Thus two arrows \n  \n    \n      \n        \n          \n            \n              \n                A\n                B\n              \n              \n                \n                \u27f6\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\stackrel {\\,\\longrightarrow }{AB}}}\n   and \n  \n    \n      \n        \n          \n            \n              \n                \n                  A\n                  \u2032\n                \n                \n                  B\n                  \u2032\n                \n              \n              \n                \n                \u27f6\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\stackrel {\\,\\longrightarrow }{A'B'}}}\n   in space represent the same free vector if they have the same magnitude and direction: that is, they are equipollent if the quadrilateral ABB\u2032A\u2032 is a parallelogram. If the Euclidean space is equipped with a choice of origin, then a free vector is equivalent to the bound vector of the same magnitude and direction whose initial point is the origin. The term vector also has generalizations to higher dimensions, and to more formal approaches with much wider applications.\n\n\n=== Further information ===\nIn classical Euclidean geometry (i.e., synthetic geometry), vectors were introduced (during the 19th century) as equivalence classes under equipollence, of ordered pairs of points; two pairs (A, B) and (C, D) being equipollent if the points A, B, D, C, in this order, form a parallelogram. Such an equivalence class is called a vector, more precisely, a Euclidean vector. The equivalence class of (A, B) is often denoted \n  \n    \n      \n        \n          \n            \n              A\n              B\n            \n            \u2192\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\overrightarrow {AB}}.}\n  \nA Euclidean vector is thus an equivalence class of directed segments with the same magnitude (e.g., the length of the line segment (A, B)) and same direction (e.g., the direction from A to B). In physics, Euclidean vectors are used to represent physical quantities that have both magnitude and direction, but are not located at a specific place, in contrast to scalars, which have no direction. For example, velocity, forces and acceleration are represented by vectors.\nIn modern geometry, Euclidean spaces are often defined from linear algebra. More precisely, a Euclidean space E is defined as a set to which is associated an inner product space of finite dimension over the reals \n  \n    \n      \n        \n          \n            E\n            \u2192\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\overrightarrow {E}},}\n   and a group action of the additive group of \n  \n    \n      \n        \n          \n            E\n            \u2192\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\overrightarrow {E}},}\n   which is free and transitive (See Affine space for details of this construction). The elements of \n  \n    \n      \n        \n          \n            E\n            \u2192\n          \n        \n      \n    \n    {\\displaystyle {\\overrightarrow {E}}}\n   are called translations. It has been proven that the two definitions of Euclidean spaces are equivalent, and that the equivalence classes under equipollence may be identified with translations.\nSometimes, Euclidean vectors are considered without reference to a Euclidean space. In this case, a Euclidean vector is an element of a normed vector space of finite dimension over the reals, or, typically, an element of \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n   equipped with the dot product. This makes sense, as the addition in such a vector space acts freely and transitively on the vector space itself. That is, \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n   is a Euclidean space, with itself as an associated vector space, and the dot product as an inner product.\nThe Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n   is often presented as the Euclidean space of dimension n. This is motivated by the fact that every Euclidean space of dimension n is isomorphic to the Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}.}\n   More precisely, given such a Euclidean space, one may choose any point O as an origin. By Gram\u2013Schmidt process, one may also find an orthonormal basis of the associated vector space (a basis such that the inner product of two basis vectors is 0 if they are different and 1 if they are equal). This defines Cartesian coordinates of any point P of the space, as the coordinates on this basis of the vector \n  \n    \n      \n        \n          \n            \n              O\n              P\n            \n            \u2192\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\overrightarrow {OP}}.}\n   These choices define an isomorphism of the given Euclidean space onto \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbb {R} ^{n},}\n   by mapping any point to the n-tuple of its Cartesian coordinates, and every vector to its coordinate vector.\n\n\n=== Examples in one dimension ===\nSince the physicist's concept of force has a direction and a magnitude, it may be seen as a vector. As an example, consider a rightward force F of 15 newtons. If the positive axis is also directed rightward, then F is represented by the vector 15 N, and if positive points leftward, then the vector for F is \u221215 N. In either case, the magnitude of the vector is 15 N. Likewise, the vector representation of a displacement \u0394s of 4 meters would be 4 m or \u22124 m, depending on its direction, and its magnitude would be 4 m regardless.\n\n\n=== In physics and engineering ===\nVectors are fundamental in the physical sciences. They can be used to represent any quantity that has magnitude, has direction, and which adheres to the rules of vector addition. An example is velocity, the magnitude of which is speed. For instance, the velocity 5 meters per second upward could be represented by the vector (0, 5) (in 2 dimensions with the positive y-axis as 'up'). Another quantity represented by a vector is force, since it has a magnitude and direction and follows the rules of vector addition. Vectors also describe many other physical quantities, such as linear displacement, displacement, linear acceleration, angular acceleration, linear momentum, and angular momentum. Other physical vectors, such as the electric and magnetic field, are represented as a system of vectors at each point of a physical space; that is, a vector field. Examples of quantities that have magnitude and direction, but fail to follow the rules of vector addition, are angular displacement and electric current. Consequently, these are not vectors.\n\n\n=== In Cartesian space ===\nIn the Cartesian coordinate system, a bound vector can be represented by identifying the coordinates of its initial and terminal point. For instance, the points A = (1, 0, 0) and B = (0, 1, 0) in space determine the bound vector \n  \n    \n      \n        \n          \n            \n              A\n              B\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle {\\overrightarrow {AB}}}\n   pointing from the point x = 1 on the x-axis to the point y = 1 on the y-axis.\nIn Cartesian coordinates, a free vector may be thought of in terms of a corresponding bound vector, in this sense, whose initial point has the coordinates of the origin O = (0, 0, 0). It is then determined by the coordinates of that bound vector's terminal point. Thus the free vector represented by (1, 0, 0) is a vector of unit length\u2014pointing along the direction of the positive x-axis.\nThis coordinate representation of free vectors allows their algebraic features to be expressed in a convenient numerical fashion. For example, the sum of the two (free) vectors (1, 2, 3) and (\u22122, 0, 4) is the (free) vector\n\n\n=== Euclidean and affine vectors ===\nIn the geometrical and physical settings, it is sometimes possible to associate, in a natural way, a length or magnitude and a direction to vectors. In addition, the notion of direction is strictly associated with the notion of an angle between two vectors. If the dot product of two vectors is defined\u2014a scalar-valued product of two vectors\u2014then it is also possible to define a length; the dot product gives a convenient algebraic characterization of both angle (a function of the dot product between any two non-zero vectors) and length (the square root of the dot product of a vector by itself). In three dimensions, it is further possible to define the cross product, which supplies an algebraic characterization of the area and orientation in space of the parallelogram defined by two vectors (used as sides of the parallelogram). In any dimension (and, in particular, higher dimensions), it's possible to define the exterior product, which (among other things) supplies an algebraic characterization of the area and orientation in space of the n-dimensional parallelotope defined by n vectors.\nIn a pseudo-Euclidean space, a vector's squared length can be positive, negative, or zero. An important example is Minkowski space (which is important to our understanding of special relativity).\nHowever, it is not always possible or desirable to define the length of a vector. This more general type of spatial vector is the subject of vector spaces (for free vectors) and affine spaces (for bound vectors, as each represented by an ordered pair of \"points\"). One physical example comes from thermodynamics, where many quantities of interest can be considered vectors in a space with no notion of length or angle.\n\n\n=== Generalizations ===\nIn physics, as well as mathematics, a vector is often identified with a tuple of components, or list of numbers, that act as scalar coefficients for a set of basis vectors. When the basis is transformed, for example by rotation or stretching, then the components of any vector in terms of that basis also transform in an opposite sense. The vector itself has not changed, but the basis has, so the components of the vector must change to compensate. The vector is called covariant or contravariant, depending on how the transformation of the vector's components is related to the transformation of the basis. In general, contravariant vectors are \"regular vectors\" with units of distance (such as a displacement), or distance times some other unit (such as velocity or acceleration); covariant vectors, on the other hand, have units of one-over-distance such as gradient. If you change units (a special case of a change of basis) from meters to millimeters, a scale factor of 1/1000, a displacement of 1 m becomes 1000 mm\u2014a contravariant change in numerical value. In contrast, a gradient of 1 K/m becomes 0.001 K/mm\u2014a covariant change in value (for more, see covariance and contravariance of vectors). Tensors are another type of quantity that behave in this way; a vector is one type of tensor.\nIn pure mathematics, a vector is any element of a vector space over some field and is often represented as a coordinate vector. The vectors described in this article are a very special case of this general definition, because they are contravariant with respect to the ambient space. Contravariance captures the physical intuition behind the idea that a vector has \"magnitude and direction\".\n\n\n== Representations ==\n\nVectors are usually denoted in lowercase boldface, as in \n  \n    \n      \n        \n          u\n        \n      \n    \n    {\\displaystyle \\mathbf {u} }\n  , \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   and \n  \n    \n      \n        \n          w\n        \n      \n    \n    {\\displaystyle \\mathbf {w} }\n  , or in lowercase italic boldface, as in a. (Uppercase letters are typically used to represent matrices.) Other conventions include \n  \n    \n      \n        \n          \n            \n              a\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {a}}}\n   or a, especially in handwriting. Alternatively, some use a tilde (~) or a wavy underline drawn beneath the symbol, e.g. \n  \n    \n      \n        \n          \n            a\n            \n              \n              \n                \u223c\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\underset {^{\\sim }}{a}}}\n  , which is a convention for indicating boldface type. If the vector represents a directed distance or displacement from a point A to a point B (see figure), it can also be denoted as \n  \n    \n      \n        \n          \n            \n              \n                A\n                B\n              \n              \n                \u27f6\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\stackrel {\\longrightarrow }{AB}}}\n   or AB. In German literature, it was especially common to represent vectors with small fraktur letters such as \n  \n    \n      \n        \n          \n            a\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {a}}}\n  .\nVectors are usually shown in graphs or other diagrams as arrows (directed line segments), as illustrated in the figure. Here, the point A is called the origin, tail, base, or initial point, and the point B is called the head, tip, endpoint, terminal point or final point. The length of the arrow is proportional to the vector's magnitude, while the direction in which the arrow points indicates the vector's direction.\n\nOn a two-dimensional diagram, a vector perpendicular to the plane of the diagram is sometimes desired. These vectors are commonly shown as small circles. A circle with a dot at its centre (Unicode U+2299 \u2299) indicates a vector pointing out of the front of the diagram, toward the viewer. A circle with a cross inscribed in it (Unicode U+2297 \u2297) indicates a vector pointing into and behind the diagram. These can be thought of as viewing the tip of an arrow head on and viewing the flights of an arrow from the back.\n\nIn order to calculate with vectors, the graphical representation may be too cumbersome. Vectors in an n-dimensional Euclidean space can be represented as coordinate vectors in a Cartesian coordinate system. The endpoint of a vector can be identified with an ordered list of n real numbers (n-tuple). These numbers are the coordinates of the endpoint of the vector, with respect to a given Cartesian coordinate system, and are typically called the scalar components (or scalar projections) of the vector on the axes of the coordinate system.\nAs an example in two dimensions (see figure), the vector from the origin O = (0, 0) to the point A = (2, 3) is simply written as\n\nThe notion that the tail of the vector coincides with the origin is implicit and easily understood. Thus, the more explicit notation \n  \n    \n      \n        \n          \n            \n              O\n              A\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle {\\overrightarrow {OA}}}\n   is usually deemed not necessary (and is indeed rarely used).\nIn three dimensional Euclidean space (or R3), vectors are identified with triples of scalar components:\n\nalso written,\n\nThis can be generalised to n-dimensional Euclidean space (or Rn).\n\nThese numbers are often arranged into a column vector or row vector, particularly when dealing with matrices, as follows:\n\nAnother way to represent a vector in n-dimensions is to introduce the standard basis vectors. For instance, in three dimensions, there are three of them:\n\nThese have the intuitive interpretation as vectors of unit length pointing up the x-, y-, and z-axis of a Cartesian coordinate system, respectively. In terms of these, any vector a in R3 can be expressed in the form:\n\nor\n\nwhere a1, a2, a3 are called the vector components (or vector projections) of a on the basis vectors or, equivalently, on the corresponding Cartesian axes x, y, and z (see figure), while a1, a2, a3 are the respective scalar components (or scalar projections).\nIn introductory physics textbooks, the standard basis vectors are often denoted \n  \n    \n      \n        \n          i\n        \n        ,\n        \n          j\n        \n        ,\n        \n          k\n        \n      \n    \n    {\\displaystyle \\mathbf {i} ,\\mathbf {j} ,\\mathbf {k} }\n   instead (or \n  \n    \n      \n        \n          \n            \n              x\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              y\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              z\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {x}} ,\\mathbf {\\hat {y}} ,\\mathbf {\\hat {z}} }\n  , in which the hat symbol ^ typically denotes unit vectors). In this case, the scalar and vector components are denoted respectively ax, ay, az, and ax, ay, az (note the difference in boldface). Thus,\n\nThe notation ei is compatible with the index notation and the summation convention commonly used in higher level mathematics, physics, and engineering.\n\n\n=== Decomposition or resolution ===\n\nAs explained above, a vector is often described by a set of vector components that add up to form the given vector. Typically, these components are the projections of the vector on a set of mutually perpendicular reference axes (basis vectors). The vector is said to be decomposed or resolved with respect to that set.\n\nThe decomposition or resolution of a vector into components is not unique, because it depends on the choice of the axes on which the vector is projected.\nMoreover, the use of Cartesian unit vectors such as \n  \n    \n      \n        \n          \n            \n              x\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              y\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              z\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {x}} ,\\mathbf {\\hat {y}} ,\\mathbf {\\hat {z}} }\n   as a basis in which to represent a vector is not mandated. Vectors can also be expressed in terms of an arbitrary basis, including the unit vectors of a cylindrical coordinate system (\n  \n    \n      \n        \n          \n            \n              \u03c1\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              \u03d5\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              z\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\hat {\\rho }}},{\\boldsymbol {\\hat {\\phi }}},\\mathbf {\\hat {z}} }\n  ) or spherical coordinate system (\n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              \u03b8\n              ^\n            \n          \n        \n        ,\n        \n          \n            \n              \u03d5\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {r}} ,{\\boldsymbol {\\hat {\\theta }}},{\\boldsymbol {\\hat {\\phi }}}}\n  ). The latter two choices are more convenient for solving problems which possess cylindrical or spherical symmetry, respectively.\nThe choice of a basis does not affect the properties of a vector or its behaviour under transformations.\nA vector can also be broken up with respect to \"non-fixed\" basis vectors that change their orientation as a function of time or space. For example, a vector in three-dimensional space can be decomposed with respect to two axes, respectively normal, and tangent to a surface (see figure). Moreover, the radial and tangential components of a vector relate to the radius of rotation of an object. The former is parallel to the radius and the latter is orthogonal to it.In these cases, each of the components may be in turn decomposed with respect to a fixed coordinate system or basis set (e.g., a global coordinate system, or inertial reference frame).\n\n\n== Basic properties ==\nThe following section uses the Cartesian coordinate system with basis vectors\n\nand assumes that all vectors have the origin as a common base point. A vector a will be written as\n\n\n=== Equality ===\nTwo vectors are said to be equal if they have the same magnitude and direction. Equivalently they will be equal if their coordinates are equal. So two vectors\n\nand\n\nare equal if\n\n\n=== Opposite, parallel, and antiparallel vectors ===\nTwo vectors are opposite if they have the same magnitude but opposite direction.  So two vectors\n\nand\n\nare opposite if\n\nTwo vectors are parallel if they have the same direction but not necessarily the same magnitude, or antiparallel if they have opposite direction but not necessarily the same magnitude.\n\n\n=== Addition and subtraction ===\n\nThe sum of a and b of two vectors may be defined as\n\nThe resulting vector is sometimes called the resultant vector of a and b.\nThe addition may be represented graphically by placing the tail of the arrow b at the head of the arrow a, and then drawing an arrow from the tail of a to the head of b. The new arrow drawn represents the vector a + b, as illustrated below:\n\nThis addition method is sometimes called the parallelogram rule because a and b form the sides of a parallelogram and a + b is one of the diagonals. If a and b are bound vectors that have the same base point, this point will also be the base point of a + b. One can check geometrically that a + b = b + a and (a + b) + c = a + (b + c).\nThe difference of a and b is\n\nSubtraction of two vectors can be geometrically illustrated as follows: to subtract b from a, place the tails of a and b at the same point, and then draw an arrow from the head of b to the head of a. This new arrow represents the vector (-b) + a, with (-b) being the opposite of  b,  see drawing. And (-b) + a = a \u2212 b.\n\n\n=== Scalar multiplication ===\n\nA vector may also be multiplied, or re-scaled, by a real number r. In the context of conventional vector algebra, these real numbers are often called scalars (from scale) to distinguish them from vectors. The operation of multiplying a vector by a scalar is called scalar multiplication. The resulting vector is\n\nIntuitively, multiplying by a scalar r stretches a vector out by a factor of r. Geometrically, this can be visualized (at least in the case when r is an integer) as placing r copies of the vector in a line where the endpoint of one vector is the initial point of the next vector.\nIf r is negative, then the vector changes direction: it flips around by an angle of 180\u00b0. Two examples (r = \u22121 and r = 2) are given below:\n\nScalar multiplication is distributive over vector addition in the following sense: r(a + b) = ra + rb for all vectors a and b and all scalars r. One can also show that a \u2212 b = a + (\u22121)b.\n\n\n=== Length ===\nThe length or magnitude or norm of the vector a is denoted by \u2016a\u2016 or, less commonly, |a|, which is not to be confused with the absolute value (a scalar \"norm\").\nThe length of the vector a can be computed with the Euclidean norm,\n\nwhich is a consequence of the Pythagorean theorem since the basis vectors e1, e2, e3 are orthogonal unit vectors.\nThis happens to be equal to the square root of the dot product, discussed below, of the vector with itself:\n\n\n==== Unit vector ====\n\nA unit vector is any vector with a length of one; normally unit vectors are used simply to indicate direction. A vector of arbitrary length can be divided by its length to create a unit vector. This is known as normalizing a vector. A unit vector is often indicated with a hat as in \u00e2.\nTo normalize a vector a = (a1, a2, a3), scale the vector by the reciprocal of its length \u2016a\u2016. That is:\n\n\n==== Zero vector ====\n\nThe zero vector is the vector with length zero. Written out in coordinates, the vector is (0, 0, 0), and it is commonly denoted \n  \n    \n      \n        \n          \n            \n              0\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {0}}}\n  , 0, or simply 0. Unlike any other vector, it has an arbitrary or indeterminate direction, and cannot be normalized (that is, there is no unit vector that is a multiple of the zero vector). The sum of the zero vector with any vector a is a (that is, 0 + a = a).\n\n\n=== Dot product ===\n\nThe dot product of two vectors a and b (sometimes called the inner product, or, since its result is a scalar, the scalar product) is denoted by a \u2219 b, and is defined as:\n\nwhere \u03b8 is the measure of the angle between a and b (see trigonometric function for an explanation of cosine). Geometrically, this means that a and b are drawn with a common start point, and then the length of a is multiplied with the length of the component of b that points in the same direction as a.\nThe dot product can also be defined as the sum of the products of the components of each vector as\n\n\n=== Cross product ===\n\nThe cross product (also called the vector product or outer product) is only meaningful in three or seven dimensions. The cross product differs from the dot product primarily in that the result of the cross product of two vectors is a vector. The cross product, denoted a \u00d7 b, is a vector perpendicular to both a and b and is defined as\n\nwhere \u03b8 is the measure of the angle between a and b, and n is a unit vector perpendicular to both a and b which completes a right-handed system. The right-handedness constraint is necessary because there exist two unit vectors that are perpendicular to both a and b, namely, n and (\u2212n).\n\nThe cross product a \u00d7 b is defined so that a, b, and a \u00d7 b also becomes a right-handed system (although a and b are not necessarily orthogonal). This is the right-hand rule.\nThe length of a \u00d7 b can be interpreted as the area of the parallelogram having a and b as sides.\nThe cross product can be written as\n\nFor arbitrary choices of spatial orientation (that is, allowing for left-handed as well as right-handed coordinate systems) the cross product of two vectors is a pseudovector instead of a vector (see below).\n\n\n=== Scalar triple product ===\n\nThe scalar triple product (also called the box product or mixed triple product) is not really a new operator, but a way of applying the other two multiplication operators to three vectors. The scalar triple product is sometimes denoted by (a b c) and defined as:\n\nIt has three primary uses. First, the absolute value of the box product is the volume of the parallelepiped which has edges that are defined by the three vectors. Second, the scalar triple product is zero if and only if the three vectors are linearly dependent, which can be easily proved by considering that in order for the three vectors to not make a volume, they must all lie in the same plane. Third, the box product is positive if and only if the three vectors a, b and c are right-handed.\nIn components (with respect to a right-handed orthonormal basis), if the three vectors are thought of as rows (or columns, but in the same order), the scalar triple product is simply the determinant of the 3-by-3 matrix having the three vectors as rows\n\nThe scalar triple product is linear in all three entries and anti-symmetric in the following sense:\n\n\n=== Conversion between multiple Cartesian bases ===\nAll examples thus far have dealt with vectors expressed in terms of the same basis, namely, the e basis {e1, e2, e3}. However, a vector can be expressed in terms of any number of different bases that are not necessarily aligned with each other, and still remain the same vector.  In the e basis, a vector a is expressed, by definition, as\n\nThe scalar components in the e basis are, by definition,\n\nIn another orthonormal basis n = {n1, n2, n3} that is not necessarily aligned with e, the vector a is expressed as\n\nand the scalar components in the n basis are, by definition,\n\nThe values of p, q, r, and u, v, w relate to the unit vectors in such a way that the resulting vector sum is exactly the same physical vector a in both cases.  It is common to encounter vectors known in terms of different bases (for example, one basis fixed to the Earth and a second basis fixed to a moving vehicle).  In such a case it is necessary to develop a method to convert between bases so the basic vector operations such as addition and subtraction can be performed.  One way to express u, v, w in terms of p, q, r is to use column matrices along with a direction cosine matrix containing the information that relates the two bases.  Such an expression can be formed by substitution of the above equations to form\n\nDistributing the dot-multiplication gives\n\nReplacing each dot product with a unique scalar gives\n\nand these equations can be expressed as the single matrix equation\n\nThis matrix equation relates the scalar components of a in the n basis (u,v, and w) with those in the e basis (p, q, and r).  Each matrix element cjk is the direction cosine relating nj to ek. The term direction cosine refers to the cosine of the angle between two unit vectors, which is also equal to their dot product. Therefore,\n\nBy referring collectively to e1, e2, e3 as the e basis and to n1, n2, n3 as the n basis, the matrix containing all the cjk is known as the \"transformation matrix from e to n\", or the \"rotation matrix from e to n\" (because it can be imagined as the \"rotation\" of a vector from one basis to another), or the \"direction cosine matrix from e to n\" (because it contains direction cosines).  The properties of a rotation matrix are such that its inverse is equal to its transpose. This means that the \"rotation matrix from e to n\" is the transpose of \"rotation matrix from n to e\".\nThe properties of a direction cosine matrix, C are:\nthe determinant is unity, |C| = 1;\nthe inverse is equal to the transpose;\nthe rows and columns are orthogonal unit vectors, therefore their dot products are zero.The advantage of this method is that a direction cosine matrix can usually be obtained independently by using Euler angles or a quaternion to relate the two vector bases, so the basis conversions can be performed directly, without having to work out all the dot products described above.\nBy applying several matrix multiplications in succession, any vector can be expressed in any basis so long as the set of direction cosines is known relating the successive bases.\n\n\n=== Other dimensions ===\nWith the exception of the cross and triple products, the above formulae generalise to two dimensions and higher dimensions. For example, addition generalises to two dimensions as\n\nand in four dimensions as\n\nThe cross product does not readily generalise to other dimensions, though the closely related exterior product does, whose result is a bivector. In two dimensions this is simply a pseudoscalar\n\nA seven-dimensional cross product is similar to the cross product in that its result is a vector orthogonal to the two arguments; there is however no natural way of selecting one of the possible such products.\n\n\n== Physics ==\nVectors have many uses in physics and other sciences.\n\n\n=== Length and units ===\nIn abstract vector spaces, the length of the arrow depends on a dimensionless scale. If it represents, for example, a force, the \"scale\" is of physical dimension length/force. Thus there is typically consistency in scale among quantities of the same dimension, but otherwise scale ratios may vary; for example, if \"1 newton\" and \"5 m\" are both represented with an arrow of 2 cm, the scales are 1 m:50 N and 1:250 respectively. Equal length of vectors of different dimension has no particular significance unless there is some proportionality constant inherent in the system that the diagram represents. Also length of a unit vector (of dimension length, not length/force, etc.) has no coordinate-system-invariant significance.\n\n\n=== Vector-valued functions ===\n\nOften in areas of physics and mathematics, a vector evolves in time, meaning that it depends on a time parameter t. For instance, if r represents the position vector of a particle, then r(t) gives a parametric representation of the trajectory of the particle. Vector-valued functions can be differentiated and integrated by differentiating or integrating the components of the vector, and many of the familiar rules from calculus continue to hold for the derivative and integral of vector-valued functions.\n\n\n=== Position, velocity and acceleration ===\nThe position of a point x = (x1, x2, x3) in three-dimensional space can be represented as a position vector whose base point is the origin\n\nThe position vector has dimensions of length.\nGiven two points x = (x1, x2, x3), y = (y1, y2, y3) their displacement is a vector\n\nwhich specifies the position of y relative to x. The length of this vector gives the straight-line distance from x to y. Displacement has the dimensions of length.\nThe velocity v of a point or particle is a vector, its length gives the speed. For constant velocity the position at time t will be\n\nwhere x0 is the position at time t = 0. Velocity is the time derivative of position. Its dimensions are length/time.\nAcceleration a of a point is vector which is the time derivative of velocity. Its dimensions are length/time2.\n\n\n=== Force, energy, work ===\nForce is a vector with dimensions of mass\u00d7length/time2 and Newton's second law is the scalar multiplication\n\nWork is the dot product of force and displacement\n\n\n== Vectors, pseudovectors, and transformations ==\nAn alternative characterization of Euclidean vectors, especially in physics, describes them as lists of quantities which behave in a certain way under a coordinate transformation. A contravariant vector is required to have components that \"transform opposite to the basis\" under changes of basis. The vector itself does not change when the basis is transformed; instead, the components of the vector make a change that cancels the change in the basis. In other words, if the reference axes (and the basis derived from it) were rotated in one direction, the component representation of the vector would rotate in the opposite way to generate the same final vector. Similarly, if the reference axes were stretched in one direction, the components of the vector would reduce in an exactly compensating way. Mathematically, if the basis undergoes a transformation described by an invertible matrix M, so that a coordinate vector x is transformed to x\u2032 = Mx, then a contravariant vector v must be similarly transformed via v\u2032 = M\n  \n    \n      \n        \n          \n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle ^{-1}}\n  v. This important requirement is what distinguishes a contravariant vector from any other triple of physically meaningful quantities. For example, if v consists of the x, y, and z-components of velocity, then v is a contravariant vector: if the coordinates of space are stretched, rotated, or twisted, then the components of the velocity transform in the same way. On the other hand, for instance, a triple consisting of the length, width, and height of a rectangular box could make up the three components of an abstract vector, but this vector would not be contravariant, since rotating the box does not change the box's length, width, and height. Examples of contravariant vectors include displacement, velocity, electric field, momentum, force, and acceleration.\nIn the language of differential geometry, the requirement that the components of a vector transform according to the same matrix of the coordinate transition is equivalent to defining a contravariant vector to be a tensor of contravariant rank one. Alternatively, a contravariant vector is defined to be a tangent vector, and the rules for transforming a contravariant vector follow from the chain rule.\nSome vectors transform like contravariant vectors, except that when they are reflected through a mirror, they flip and gain a minus sign. A transformation that switches right-handedness to left-handedness and vice versa like a mirror does is said to change the orientation of space. A vector which gains a minus sign when the orientation of space changes is called a pseudovector or an axial vector. Ordinary vectors are sometimes called true vectors or polar vectors to distinguish them from pseudovectors. Pseudovectors occur most frequently as the cross product of two ordinary vectors.\nOne example of a pseudovector is angular velocity. Driving in a car, and looking forward, each of the wheels has an angular velocity vector pointing to the left. If the world is reflected in a mirror which switches the left and right side of the car, the reflection of this angular velocity vector points to the right, but the actual angular velocity vector of the wheel still points to the left, corresponding to the minus sign. Other examples of pseudovectors include magnetic field, torque, or more generally any cross product of two (true) vectors.\nThis distinction between vectors and pseudovectors is often ignored, but it becomes important in studying symmetry properties. See parity (physics).\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Mathematical treatments ===\nApostol, Tom (1967). Calculus. Vol. 1: One-Variable Calculus with an Introduction to Linear Algebra. Wiley. ISBN 978-0-471-00005-1.\nApostol, Tom (1969). Calculus. Vol. 2: Multi-Variable Calculus and Linear Algebra with Applications. Wiley. ISBN 978-0-471-00007-5.\nHeinbockel, J. H. (2001), Introduction to Tensor Calculus and Continuum Mechanics, Trafford Publishing, ISBN 1-55369-133-4.\nIt\u00f4, Kiyosi (1993), Encyclopedic Dictionary of Mathematics (2nd ed.), MIT Press, ISBN 978-0-262-59020-4.\nIvanov, A.B. (2001) [1994], \"Vector\", Encyclopedia of Mathematics, EMS Press.\nKane, Thomas R.; Levinson, David A. (1996), Dynamics Online, Sunnyvale, California: OnLine Dynamics.\nLang, Serge (1986). Introduction to Linear Algebra (2nd ed.). Springer. ISBN 0-387-96205-0.\nPedoe, Daniel (1988). Geometry: A comprehensive course. Dover. ISBN 0-486-65812-0.\n\n\n=== Physical treatments ===\nAris, R. (1990). Vectors, Tensors and the Basic Equations of Fluid Mechanics. Dover. ISBN 978-0-486-66110-0.\nFeynman, Richard; Leighton, R.; Sands, M. (2005). \"Chapter 11\". The Feynman Lectures on Physics. Vol. I (2nd ed.). Addison Wesley. ISBN 978-0-8053-9046-9.\n\n\n== External links ==\n\n\"Vector\", Encyclopedia of Mathematics, EMS Press, 2001 [1994]\nOnline vector identities (PDF)\nIntroducing Vectors A conceptual introduction (applied mathematics)", "Friction": "Friction is the force resisting the relative motion of solid surfaces, fluid layers, and material elements sliding against each other. There are several types of friction:\n\nDry friction is a force that opposes the relative lateral motion of two solid surfaces in contact. Dry friction is subdivided into static friction (\"stiction\") between non-moving surfaces, and kinetic friction between moving surfaces. With the exception of atomic or molecular friction, dry friction generally arises from the interaction of surface features, known as asperities (see Figure 1).\nFluid friction describes the friction between layers of a viscous fluid that are moving relative to each other.Lubricated friction is a case of fluid friction where a lubricant fluid separates two solid surfaces.Skin friction is a component of drag, the force resisting the motion of a fluid across the surface of a body.\nInternal friction is the force resisting motion between the elements making up a solid material while it undergoes deformation.When surfaces in contact move relative to each other, the friction between the two surfaces converts kinetic energy into thermal energy (that is, it converts work to heat). This property can have dramatic consequences, as illustrated by the use of friction created by rubbing pieces of wood together to start a fire. Kinetic energy is converted to thermal energy whenever motion with friction occurs, for example when a viscous fluid is stirred. Another important consequence of many types of friction can be wear, which may lead to performance degradation or damage to components. Friction is a component of the science of tribology.\nFriction is desirable and important in supplying traction to facilitate motion on land. Most land vehicles rely on friction for acceleration, deceleration and changing direction. Sudden reductions in traction can cause loss of control and accidents.\nFriction is not itself a fundamental force. Dry friction arises from a combination of inter-surface adhesion, surface roughness, surface deformation, and surface contamination. The complexity of these interactions makes the calculation of friction from first principles  impractical and necessitates the use of empirical methods for analysis and the development of theory.\nFriction is a non-conservative force \u2013 work done against friction is path dependent. In the presence of friction, some kinetic energy is always transformed to thermal energy, so mechanical energy is not conserved.\n\n\n== History ==\nThe Greeks, including Aristotle, Vitruvius, and Pliny the Elder, were interested in the cause and mitigation of friction. They were aware of differences between static and kinetic friction with Themistius stating in 350 A.D. that \"it is easier to further the motion of a moving body than to move a body at rest\".The classic laws of sliding friction were discovered by Leonardo da Vinci  in 1493, a pioneer in tribology, but the laws documented in his notebooks were not published and remained unknown. These laws were rediscovered by Guillaume Amontons in 1699 and became known as Amonton's three laws of dry friction.   Amontons presented the nature of friction in terms of surface irregularities and the force required to raise the weight pressing the surfaces together. This view was further elaborated by Bernard Forest de B\u00e9lidor and Leonhard Euler (1750), who derived the angle of repose of a weight on an inclined plane and first distinguished between static and kinetic friction.John Theophilus Desaguliers (1734) first recognized the role of adhesion in friction. Microscopic forces cause surfaces to stick together; he proposed that friction was the force necessary to tear the adhering surfaces apart.\nThe understanding of friction was further developed by Charles-Augustin de Coulomb (1785). Coulomb investigated the influence of four main factors on friction: the nature of the materials in contact and their surface coatings; the extent of the surface area; the normal pressure (or load); and the length of time that the surfaces remained in contact (time of repose). Coulomb further considered the influence of sliding velocity, temperature and humidity, in order to decide between the different explanations on the nature of friction that had been proposed. The distinction between static and dynamic friction is made in Coulomb's friction law (see below), although this distinction was already drawn by Johann Andreas von Segner in 1758.\nThe effect of the time of repose was explained by Pieter van Musschenbroek (1762) by considering the surfaces of fibrous materials, with fibers meshing together, which takes a finite time in which the friction increases.\nJohn Leslie (1766\u20131832) noted a weakness in the views of Amontons and Coulomb: If friction arises from a weight being drawn up the inclined plane of successive asperities, why then isn't it balanced through descending the opposite slope? Leslie was equally skeptical about the role of adhesion proposed by Desaguliers, which should on the whole have the same tendency to accelerate as to retard the motion. In Leslie's view, friction should be seen as a time-dependent process of flattening, pressing down asperities, which creates new obstacles in what were cavities before.\nArthur Jules Morin (1833) developed the concept of sliding versus rolling friction.  Osborne Reynolds (1866) derived the equation of viscous flow.  This completed the classic empirical model of friction (static, kinetic, and fluid) commonly used today in engineering. In 1877,  Fleeming Jenkin and J. A. Ewing investigated the continuity between static and kinetic friction.The focus of research during the 20th century has been to understand the physical mechanisms behind friction. Frank Philip Bowden and David Tabor (1950) showed that, at a microscopic level, the actual area of contact between surfaces is a very small fraction of the apparent area.  This actual area of contact, caused by asperities increases with pressure. The development of the atomic force microscope (ca. 1986)  enabled scientists to study friction at the atomic scale, showing that, on that scale, dry friction is the product of the inter-surface shear stress and the contact area. These two discoveries explain Amonton's first law (below); the macroscopic proportionality between normal force and static frictional force between dry surfaces.\n\n\n== Laws of dry friction ==\nThe elementary property of sliding (kinetic) friction were discovered by experiment in the 15th to 18th centuries and were expressed as three empirical laws:\n\nAmontons'  First Law: The force of friction is directly proportional to the applied load.\nAmontons' Second Law: The force of friction is independent of the apparent area of contact.\nCoulomb's Law of Friction: Kinetic friction is independent of the sliding velocity.\n\n\n== Dry friction ==\nDry friction resists relative lateral motion of two solid surfaces in contact. The two regimes of dry friction are 'static friction' (\"stiction\") between non-moving surfaces, and kinetic friction (sometimes called sliding friction or dynamic friction) between moving surfaces.\nCoulomb friction, named after Charles-Augustin de Coulomb, is an approximate model used to calculate the force of dry friction. It is governed by the model:\n\nwhere\n\n  \n    \n      \n        \n          F\n          \n            \n              f\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {f} }}\n   is the force of friction exerted by each surface on the other.  It is parallel to the surface, in a direction opposite to the net applied force.\n\n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   is the coefficient of friction, which is an empirical property of the contacting materials,\n\n  \n    \n      \n        \n          F\n          \n            \n              n\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {n} }}\n   is the normal force exerted by each surface on the other, directed perpendicular (normal) to the surface.The Coulomb friction \n  \n    \n      \n        \n          F\n          \n            \n              f\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {f} }}\n   may take any value from zero up to \n  \n    \n      \n        \u03bc\n        \n          F\n          \n            \n              n\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu F_{\\mathrm {n} }}\n  , and the direction of the frictional force against a surface is opposite to the motion that surface would experience in the absence of friction. Thus, in the static case, the frictional force is exactly what it must be in order to prevent motion between the surfaces; it balances the net force tending to cause such motion. In this case, rather than providing an estimate of the actual frictional force, the Coulomb approximation provides a threshold value for this force, above which motion would commence. This maximum force is known as traction.\nThe force of friction is always exerted in a direction that opposes movement (for kinetic friction) or potential movement (for static friction) between the two surfaces. For example, a curling stone sliding along the ice experiences a kinetic force slowing it down. For an example of potential movement, the drive wheels of an accelerating car experience a frictional force pointing forward; if they did not, the wheels would spin, and the rubber would slide backwards along the pavement. Note that it is not the direction of movement of the vehicle they oppose, it is the direction of (potential) sliding between tire and road.\n\n\n=== Normal force ===\n\nThe normal force is defined as the net force compressing two parallel surfaces together, and its direction is perpendicular to the surfaces. In the simple case of a mass resting on a horizontal surface, the only component of the normal force is the force due to gravity, where \n  \n    \n      \n        N\n        =\n        m\n        g\n        \n      \n    \n    {\\displaystyle N=mg\\,}\n  . In this case, conditions of equilibrium tell us that the magnitude of the friction force is zero, \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle F_{f}=0}\n  . In fact, the friction force always satisfies \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        \u2264\n        \u03bc\n        N\n      \n    \n    {\\displaystyle F_{f}\\leq \\mu N}\n  , with equality reached only at a critical ramp angle (given by \n  \n    \n      \n        \n          tan\n          \n            \u2212\n            1\n          \n        \n        \u2061\n        \u03bc\n      \n    \n    {\\displaystyle \\tan ^{-1}\\mu }\n  ) that is steep enough to initiate sliding. \nThe friction coefficient is an empirical (experimentally measured) structural property that depends only on various aspects of the contacting materials, such as surface roughness. The coefficient of friction is not a function of mass or volume. For instance, a large aluminum block has the same coefficient of friction as a small aluminum block. However, the magnitude of the friction force itself depends on the normal force, and hence on the mass of the block. \nDepending on the situation, the calculation of the normal force \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   might include forces other than gravity. If an object is on a level surface and subjected to an external force \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   tending to cause it to slide, then the normal force between the object and the surface is just \n  \n    \n      \n        N\n        =\n        m\n        g\n        +\n        \n          P\n          \n            y\n          \n        \n      \n    \n    {\\displaystyle N=mg+P_{y}}\n  , where \n  \n    \n      \n        m\n        g\n      \n    \n    {\\displaystyle mg}\n   is the block's weight and \n  \n    \n      \n        \n          P\n          \n            y\n          \n        \n      \n    \n    {\\displaystyle P_{y}}\n   is the downward component of the external force. Prior to sliding, this friction force is \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        =\n        \u2212\n        \n          P\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle F_{f}=-P_{x}}\n  , where \n  \n    \n      \n        \n          P\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle P_{x}}\n   is the horizontal component of the external force. Thus, \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        \u2264\n        \u03bc\n        N\n      \n    \n    {\\displaystyle F_{f}\\leq \\mu N}\n   in general. Sliding commences only after this frictional force reaches the value \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        =\n        \u03bc\n        N\n      \n    \n    {\\displaystyle F_{f}=\\mu N}\n  . Until then, friction is whatever it needs to be to provide equilibrium, so it can be treated as simply a reaction.  \nIf the object is on a tilted surface such as an inclined plane, the normal force from gravity is smaller than \n  \n    \n      \n        m\n        g\n      \n    \n    {\\displaystyle mg}\n  , because less of the force of gravity is perpendicular to the face of the plane. The normal force and the frictional force are ultimately determined using vector analysis, usually via a free body diagram. \nIn general, process for solving any statics problem with friction is to treat contacting surfaces tentatively as immovable so that the corresponding tangential reaction force between them can be calculated. If this frictional reaction force satisfies \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        \u2264\n        \u03bc\n        N\n      \n    \n    {\\displaystyle F_{f}\\leq \\mu N}\n  , then the tentative assumption was correct, and it is the actual frictional force. Otherwise, the friction force must be set equal to \n  \n    \n      \n        \n          F\n          \n            f\n          \n        \n        =\n        \u03bc\n        N\n      \n    \n    {\\displaystyle F_{f}=\\mu N}\n  , and then the resulting force imbalance would then determine the acceleration associated with slipping.\n\n\n=== Coefficient of friction ===\nThe coefficient of friction (COF), often symbolized by the Greek letter \u00b5, is a dimensionless scalar value which equals the ratio of the force of friction between two bodies and the force pressing them together, either during or at the onset of slipping. The coefficient of friction depends on the materials used; for example, ice on steel has a low coefficient of friction, while rubber on pavement has a high coefficient of friction. Coefficients of friction range from near zero to greater than one. The coefficient of friction between two surfaces of similar metals is greater than that between two surfaces of different metals; for example, brass has a higher coefficient of friction when moved against brass, but less if moved against steel or aluminum.For surfaces at rest relative to each other, \n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =\\mu _{\\mathrm {s} }}\n  , where \n  \n    \n      \n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {s} }}\n   is the coefficient of static friction. This is usually larger than its kinetic counterpart. The coefficient of static friction exhibited by a pair of contacting surfaces depends upon the combined effects of material deformation characteristics and surface roughness, both of which have their origins in the chemical bonding between atoms in each of the bulk materials and between the material surfaces and any adsorbed material. The fractality of surfaces, a parameter describing the scaling behavior of surface asperities, is known to play an important role in determining the magnitude of the static friction.For surfaces in relative motion \n  \n    \n      \n        \u03bc\n        =\n        \n          \u03bc\n          \n            \n              k\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu =\\mu _{\\mathrm {k} }}\n  , where \n  \n    \n      \n        \n          \u03bc\n          \n            \n              k\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {k} }}\n   is the coefficient of kinetic friction. The Coulomb friction is equal to \n  \n    \n      \n        \n          F\n          \n            \n              f\n            \n          \n        \n      \n    \n    {\\displaystyle F_{\\mathrm {f} }}\n  , and the frictional force on each surface is exerted in the direction opposite to its motion relative to the other surface.\nArthur Morin introduced the term and demonstrated the utility of the coefficient of friction. The coefficient of friction is an empirical measurement\u2009\u2014\u2009it has to be measured experimentally, and cannot be found through calculations. Rougher surfaces tend to have higher effective values. Both static and kinetic coefficients of friction depend on the pair of surfaces in contact; for a given pair of surfaces, the coefficient of static friction is usually larger than that of kinetic friction; in some sets the two coefficients are equal, such as teflon-on-teflon.\nMost dry materials in combination have friction coefficient values between 0.3 and 0.6. Values outside this range are rarer, but teflon, for example, can have a coefficient as low as 0.04. A value of zero would mean no friction at all, an elusive property. Rubber in contact with other surfaces can yield friction coefficients from 1 to 2. Occasionally it is maintained that \u03bc is always < 1, but this is not true. While in most relevant applications \u03bc < 1, a value above 1 merely implies that the force required to slide an object along the surface is greater than the normal force of the surface on the object. For example, silicone rubber or acrylic rubber-coated surfaces have a coefficient of friction that can be substantially larger than 1.\nWhile it is often stated that the COF is a \"material property,\" it is better categorized as a \"system property.\" Unlike true material properties (such as conductivity, dielectric constant, yield strength), the COF for any two materials depends on system variables like temperature, velocity, atmosphere and also what are now popularly described as aging and deaging times; as well as on geometric properties of the interface between the materials, namely surface structure. For example, a copper pin sliding against a thick copper plate can have a COF that varies from 0.6 at low speeds (metal sliding against metal) to below 0.2 at high speeds when the copper surface begins to melt due to frictional heating. The latter speed, of course, does not determine the COF uniquely; if the pin diameter is increased so that the frictional heating is removed rapidly, the temperature drops, the pin remains solid and the COF rises to that of a 'low speed' test.\n\n\n==== Approximate coefficients of friction ====\nUnder certain conditions some materials have very low friction coefficients. An example is (highly ordered pyrolytic) graphite which can have a friction coefficient below 0.01.\nThis ultralow-friction regime is called superlubricity.\n\n\n=== Static friction ===\n\nStatic friction is friction between two or more solid objects that are not moving relative to each other. For example, static friction can prevent an object from sliding down a sloped surface. The coefficient of static friction, typically denoted as \u03bcs, is usually higher than the coefficient of kinetic friction. Static friction is considered to arise as the result of surface roughness features across multiple length scales at solid surfaces. These features, known as asperities are present down to nano-scale dimensions and result in true solid to solid contact existing only at a limited number of points accounting for only a fraction of the apparent or nominal contact area. The linearity between applied load and true contact area, arising from asperity deformation, gives rise to the linearity between static frictional force and normal force, found for typical Amonton\u2013Coulomb type friction.The static friction force must be overcome by an applied force before an object can move. The maximum possible friction force between two surfaces before sliding begins is the product of the coefficient of static friction and the normal force: \n  \n    \n      \n        \n          F\n          \n            max\n          \n        \n        =\n        \n          \u03bc\n          \n            \n              s\n            \n          \n        \n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{\\text{max}}=\\mu _{\\mathrm {s} }F_{\\text{n}}}\n  . When there is no sliding occurring, the friction force can have any value from zero up to \n  \n    \n      \n        \n          F\n          \n            max\n          \n        \n      \n    \n    {\\displaystyle F_{\\text{max}}}\n  . Any force smaller than \n  \n    \n      \n        \n          F\n          \n            max\n          \n        \n      \n    \n    {\\displaystyle F_{\\text{max}}}\n   attempting to slide one surface over the other is opposed by a frictional force of equal magnitude and opposite direction. Any force larger than \n  \n    \n      \n        \n          F\n          \n            max\n          \n        \n      \n    \n    {\\displaystyle F_{\\text{max}}}\n   overcomes the force of static friction and causes sliding to occur. The instant sliding occurs, static friction is no longer applicable\u2014the friction between the two surfaces is then called kinetic friction. However, an apparent static friction can be observed even in the case when the true static friction is zero.An example of static friction is the force that prevents a car wheel from slipping as it rolls on the ground. Even though the wheel is in motion, the patch of the tire in contact with the ground is stationary relative to the ground, so it is static rather than kinetic friction. Upon slipping, the wheel friction changes to kinetic friction.  An anti-lock braking system operates on the principle of allowing a locked wheel to resume rotating so that the car maintains static friction.\nThe maximum value of static friction, when motion is impending, is sometimes referred to as limiting friction,\nalthough this term is not used universally.\n\n\n=== Kinetic friction ===\nKinetic friction, also known as dynamic friction or sliding friction, occurs when two objects are moving relative to each other and rub together (like a sled on the ground). The coefficient of kinetic friction is typically denoted as \u03bck, and is usually less than the coefficient of static friction for the same materials. However, Richard Feynman comments that \"with dry metals it is very hard to show any difference.\"\nThe friction force between two surfaces after sliding begins is the product of the coefficient of kinetic friction and the normal force: \n  \n    \n      \n        \n          F\n          \n            k\n          \n        \n        =\n        \n          \u03bc\n          \n            \n              k\n            \n          \n        \n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{k}=\\mu _{\\mathrm {k} }F_{n}}\n  . This is responsible for the Coulomb damping of an oscillating or vibrating system.\nNew models are beginning to show how kinetic friction can be greater than static friction. Kinetic friction is now understood, in many cases, to be primarily caused by chemical bonding between the surfaces, rather than interlocking asperities; however, in many other cases roughness effects are dominant, for example in rubber to road friction. Surface roughness and contact area affect kinetic friction for micro- and nano-scale objects where surface area forces dominate inertial forces.The origin of kinetic friction at nanoscale can be explained by thermodynamics. Upon sliding, new surface forms at the back of a sliding true contact, and existing surface disappears at the front of it. Since all surfaces involve the thermodynamic surface energy, work must be spent in creating the new surface, and energy is released as heat in removing the surface. Thus, a force is required to move the back of the contact, and frictional heat is released at the front.\n\n\n=== Angle of friction ===\n\nFor certain applications, it is more useful to define static friction in terms of the maximum angle before which one of the items will begin sliding. This is called the angle of friction or friction angle. It is defined as:\n\nand thus:\n\nwhere \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle from horizontal and \u03bcs is the static coefficient of friction between the objects. This formula can also be used to calculate \u03bcs from empirical measurements of the friction angle.\n\n\n=== Friction at the atomic level ===\nDetermining the forces required to move atoms past each other is a challenge in designing nanomachines. In 2008 scientists for the first time were able to move a single atom across a surface, and measure the forces required. Using ultrahigh vacuum and nearly zero temperature (5 K), a modified atomic force microscope was used to drag a cobalt atom, and a carbon monoxide molecule, across surfaces of copper and platinum.\n\n\n=== Limitations of the Coulomb model ===\nThe Coulomb approximation follows from the assumptions that: surfaces are in atomically close contact only over a small fraction of their overall area; that this contact area is proportional to the normal force (until saturation, which takes place when all area is in atomic contact); and that the frictional force is proportional to the applied normal force, independently of the contact area. The Coulomb approximation is fundamentally an empirical construct. It is a rule-of-thumb describing the approximate outcome of an extremely complicated physical interaction. The strength of the approximation is its simplicity and versatility. Though the relationship between normal force and frictional force is not exactly linear (and so the frictional force is not entirely independent of the contact area of the surfaces), the Coulomb approximation is an adequate representation of friction for the analysis of many physical systems.\nWhen the surfaces are conjoined, Coulomb friction becomes a very poor approximation (for example, adhesive tape resists sliding even when there is no normal force, or a negative normal force). In this case, the frictional force may depend strongly on the area of contact. Some drag racing tires are adhesive for this reason. However, despite the complexity of the fundamental physics behind friction, the relationships are accurate enough to be useful in many applications.\n\n\n==== \"Negative\" coefficient of friction ====\nAs of 2012, a single study has demonstrated the potential for an effectively negative coefficient of friction in the low-load regime, meaning that a decrease in normal force leads to an increase in friction. This contradicts everyday experience in which an increase in normal force leads to an increase in friction.  This was reported in the journal Nature in October 2012 and involved the friction encountered by an atomic force microscope stylus when dragged across a graphene sheet in the presence of graphene-adsorbed oxygen.\n\n\n=== Numerical simulation of the Coulomb model ===\nDespite being a simplified model of friction, the Coulomb model is useful in many numerical simulation applications such as multibody systems and granular material. Even its most simple expression encapsulates the fundamental effects of sticking and sliding which are required in many applied cases, although specific algorithms have to be designed in order to efficiently numerically integrate mechanical systems with Coulomb friction and bilateral or unilateral contact. Some quite nonlinear effects, such as the so-called Painlev\u00e9 paradoxes, may be encountered with Coulomb friction.\n\n\n=== Dry friction and instabilities ===\nDry friction can induce several types of instabilities in mechanical systems which display a stable behaviour in the absence of friction. \nThese instabilities may be caused by the decrease of the friction force with an increasing velocity of sliding, by material expansion due to heat generation during friction (the thermo-elastic instabilities), or by pure dynamic effects of sliding of two elastic materials (the Adams\u2013Martins instabilities). The latter were originally discovered in 1995 by George G. Adams and Jo\u00e3o Arm\u00e9nio Correia Martins for smooth surfaces and were later found in periodic rough surfaces. In particular, friction-related dynamical instabilities are thought to be responsible for brake squeal and the 'song' of a glass harp, phenomena which involve stick and slip, modelled as a drop of friction coefficient with velocity.A practically important case is the self-oscillation of the strings of bowed instruments such as the violin, cello, hurdy-gurdy, erhu, etc.\nA connection between dry friction and flutter instability in a simple mechanical system has been discovered, watch the movie Archived 2015-01-10 at the Wayback Machine for more details.\nFrictional instabilities can lead to the formation of new self-organized patterns (or \"secondary structures\") at the sliding interface, such as in-situ formed tribofilms which are utilized for the reduction of friction and wear in so-called self-lubricating materials.\n\n\n== Fluid friction ==\n\nFluid friction occurs between fluid layers that are moving relative to each other. This internal resistance to flow is named viscosity. In everyday terms, the viscosity of a fluid is described as its \"thickness\". Thus, water is \"thin\", having a lower viscosity, while honey is \"thick\", having a higher viscosity. The less viscous the fluid, the greater its ease of deformation or movement.\nAll real fluids (except superfluids) offer some resistance to shearing and therefore are viscous. For teaching and explanatory purposes it is helpful to use the concept of an inviscid fluid or an ideal fluid which offers no resistance to shearing and so is not viscous.\n\n\n== Lubricated friction ==\n\nLubricated friction is a case of fluid friction where a fluid separates two solid surfaces. Lubrication is a technique employed to reduce wear of one or both surfaces in close proximity moving relative to each another by interposing a substance called a lubricant between the surfaces.\nIn most cases the applied load is carried by pressure generated within the fluid due to the frictional viscous resistance to motion of the lubricating fluid between the surfaces. Adequate lubrication allows smooth continuous operation of equipment, with only mild wear, and without excessive stresses or seizures at bearings. When lubrication breaks down, metal or other components can rub destructively over each other, causing heat and possibly damage or failure.\n\n\n== Skin friction ==\n\nSkin friction arises from the interaction between the fluid and the skin of the body, and is directly related to the area of the surface of the body that is in contact with the fluid. Skin friction follows the drag equation and rises with the square of the velocity.\nSkin friction is caused by viscous drag in the boundary layer around the object. There are two ways to decrease skin friction: the first is to shape the moving body so that smooth flow is possible, like an airfoil. The second method is to decrease the length and cross-section of the moving object as much as is practicable.\n\n\n== Internal friction ==\n\nInternal friction is the force resisting motion between the elements making up a solid material while it undergoes deformation.\nPlastic deformation in solids is an irreversible change in the internal molecular structure of an object. This change may be due to either (or both) an applied force or a change in temperature. The change of an object's shape is called strain. The force causing it is called stress.\nElastic deformation in solids is reversible change in the internal molecular structure of an object. Stress does not necessarily cause permanent change. As deformation occurs, internal forces oppose the applied force. If the applied stress is not too large these opposing forces may completely resist the applied force, allowing the object to assume a new equilibrium state and to return to its original shape when the force is removed. This is known as elastic deformation or elasticity.\n\n\n== Radiation friction ==\nAs a consequence of light pressure, Einstein in 1909 predicted the existence of \"radiation friction\" which would oppose the movement of matter. He wrote, \"radiation will exert pressure on both sides of the plate. The forces of pressure exerted on the two sides are equal if the plate is at rest. However, if it is in motion, more radiation will be reflected on the surface that is ahead during the motion (front surface) than on the back surface. The backward-acting force of pressure exerted on the front surface is thus larger than the force of pressure acting on the back. Hence, as the resultant of the two forces, there remains a force that counteracts the motion of the plate and that increases with the velocity of the plate. We will call this resultant 'radiation friction' in brief.\"\n\n\n== Other types of friction ==\n\n\n=== Rolling resistance ===\n\nRolling resistance is the force that resists the rolling of a wheel or other circular object along a surface caused by deformations in the object or surface. Generally the force of rolling resistance is less than that associated with kinetic friction. Typical values for the coefficient of rolling resistance are 0.001.\nOne of the most common examples of rolling resistance is the movement of motor vehicle tires on a road, a process which generates heat and sound as by-products.\n\n\n=== Braking friction ===\nAny wheel equipped with a brake is capable of generating a large retarding force, usually for the purpose of slowing and stopping a vehicle or piece of rotating machinery. Braking friction differs from rolling friction because the coefficient of friction for rolling friction is small whereas the coefficient of friction for braking friction is designed to be large by choice of materials for brake pads.\n\n\n=== Triboelectric effect ===\n\nRubbing dissimilar materials against one another can cause a build-up of electrostatic charge, which can be hazardous if flammable gases or vapours are present. When the static build-up discharges, explosions can be caused by ignition of the flammable mixture.\n\n\n=== Belt friction ===\n\nBelt friction is a physical property observed from the forces acting on a belt wrapped around a pulley, when one end is being pulled. The resulting tension, which acts on both ends of the belt, can be modeled by the belt friction equation.\nIn practice, the theoretical tension acting on the belt or rope calculated by the belt friction equation can be compared to the maximum tension the belt can support. This helps a designer of such a rig to know how many times the belt or rope must be wrapped around the pulley to prevent it from slipping. Mountain climbers and sailing crews demonstrate a standard knowledge of belt friction when accomplishing basic tasks.\n\n\n== Reducing friction ==\n\n\n=== Devices ===\nDevices such as wheels, ball bearings, roller bearings, and air cushion or other types of fluid bearings can change sliding friction into a much smaller type of rolling friction.\nMany thermoplastic materials such as nylon, HDPE and PTFE are commonly used in low friction bearings. They are especially useful because the coefficient of friction falls with increasing imposed load. For improved wear resistance, very high molecular weight grades are usually specified for heavy duty or critical bearings.\n\n\n=== Lubricants ===\nA common way to reduce friction is by using a lubricant, such as oil, water, or grease, which is placed between the two surfaces, often dramatically lessening the coefficient of friction. The science of friction and lubrication is called tribology. Lubricant technology is when lubricants are mixed with the application of science, especially to industrial or commercial objectives.\nSuperlubricity, a recently discovered effect, has been observed in graphite: it is the substantial decrease of friction between two sliding objects, approaching zero levels. A very small amount of frictional energy would still be dissipated.\nLubricants to overcome friction need not always be thin, turbulent fluids or powdery solids such as graphite and talc; acoustic lubrication actually uses sound as a lubricant.\nAnother way to reduce friction between two parts is to superimpose micro-scale vibration to one of the parts. This can be sinusoidal vibration as used in ultrasound-assisted cutting or vibration noise, known as dither.\n\n\n== Energy of friction ==\nAccording to the law of conservation of energy, no energy is destroyed due to friction, though it may be lost to the system of concern. Energy is transformed from other forms into thermal energy. A sliding hockey puck comes to rest because friction converts its kinetic energy into heat which raises the thermal energy of the puck and the ice surface. Since heat quickly dissipates, many early philosophers, including Aristotle, wrongly concluded that moving objects lose energy without a driving force.\nWhen an object is pushed along a surface along a path C, the energy converted to heat is given by a line integral, in accordance with the definition of work\n\n  \n    \n      \n        \n          E\n          \n            t\n            h\n          \n        \n        =\n        \n          \u222b\n          \n            C\n          \n        \n        \n          \n            F\n          \n          \n            \n              f\n              r\n              i\n              c\n            \n          \n        \n        (\n        \n          x\n        \n        )\n        \u22c5\n        d\n        \n          x\n        \n         \n        =\n        \n          \u222b\n          \n            C\n          \n        \n        \n          \u03bc\n          \n            \n              k\n            \n          \n        \n         \n        \n          \n            F\n          \n          \n            \n              n\n            \n          \n        \n        (\n        \n          x\n        \n        )\n        \u22c5\n        d\n        \n          x\n        \n        ,\n      \n    \n    {\\displaystyle E_{th}=\\int _{C}\\mathbf {F} _{\\mathrm {fric} }(\\mathbf {x} )\\cdot d\\mathbf {x} \\ =\\int _{C}\\mu _{\\mathrm {k} }\\ \\mathbf {F} _{\\mathrm {n} }(\\mathbf {x} )\\cdot d\\mathbf {x} ,}\n  where\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            \n              f\n              r\n              i\n              c\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} _{\\mathrm {fric} }}\n   is the friction force,\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            \n              n\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} _{\\mathrm {n} }}\n   is the vector obtained by multiplying the magnitude of the normal force by a unit vector pointing against the object's motion,\n\n  \n    \n      \n        \n          \u03bc\n          \n            \n              k\n            \n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\mathrm {k} }}\n   is the coefficient of kinetic friction, which is inside the integral because it may vary from location to location (e.g. if the material changes along the path),\n\n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n   is the position of the object.Energy lost to a system as a result of friction is a classic example of thermodynamic irreversibility.\n\n\n=== Work of friction ===\nIn the reference frame of the interface between two surfaces, static friction does no work, because there is never displacement between the surfaces. In the same reference frame, kinetic friction is always in the direction opposite the motion, and does negative work. However, friction can do positive work in certain frames of reference. One can see this by placing a heavy box on a rug, then pulling on the rug quickly. In this case, the box slides backwards relative to the rug, but moves forward relative to the frame of reference in which the floor is stationary. Thus, the kinetic friction between the box and rug accelerates the box in the same direction that the box moves, doing positive work.The work done by friction can translate into deformation, wear, and heat that can affect the contact surface properties (even the coefficient of friction between the surfaces). This can be beneficial as in polishing. The work of friction is used to mix and join materials such as in the process of friction welding. Excessive erosion or wear of mating sliding surfaces occurs when work due to frictional forces rise to unacceptable levels. Harder corrosion particles caught between mating surfaces in relative motion (fretting) exacerbates wear of frictional forces. As surfaces are worn by work due to friction, fit and surface finish of an object may degrade until it no longer functions properly. For example, bearing seizure or failure may result from excessive wear due to work of friction.\n\n\n== Applications ==\nFriction is an important factor in many engineering disciplines.\n\n\n=== Transportation ===\nAutomobile brakes inherently rely on friction, slowing a vehicle by converting its kinetic energy into heat. Incidentally, dispersing this large amount of heat safely is one technical challenge in designing brake systems. Disk brakes rely on friction between a disc and brake pads that are squeezed transversely against the rotating disc. In drum brakes, brake shoes or pads are pressed outwards against a rotating cylinder (brake drum) to create friction. Since braking discs can be more efficiently cooled than drums, disc brakes have better stopping performance.\nRail adhesion refers to the grip wheels of a train have on the rails, see Frictional contact mechanics.\nRoad slipperiness is an important design and safety factor for automobilesSplit friction is a particularly dangerous condition arising due to varying friction on either side of a car.\nRoad texture affects the interaction of tires and the driving surface.\n\n\n=== Measurement ===\nA tribometer is an instrument that measures friction on a surface.\nA profilograph is a device used to measure pavement surface roughness.\n\n\n=== Household usage ===\nFriction is used to heat and ignite matchsticks (friction between the head of a matchstick and the rubbing surface of the match box).\nSticky pads are used to prevent object from slipping off smooth surfaces by effectively increasing the friction coefficient between the surface and the object.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\"Friction\" . Encyclop\u00e6dia Britannica. Vol. 11 (11th ed.). 1911.\nCoefficients of Friction \u2013 tables of coefficients, plus many links\nMeasurement of friction power\nPhysclips: Mechanics with animations and video clips from the University of New South Wales\nValues for Coefficient of Friction \u2013 CRC Handbook of Chemistry and Physics\nCharacteristic Phenomena in Conveyor Chain\nAtomic-scale Friction Research and Education Synergy Hub (AFRESH) an Engineering Virtual Organization for the atomic-scale friction community to share, archive, link, and discuss data, knowledge and tools related to atomic-scale friction.\nCoefficients of friction of various material pairs in atmosphere and vacuum.", "Hertz": "The hertz (symbol: Hz) is the unit of frequency in the International System of Units (SI), equivalent to one event (or cycle) per second. The hertz is an SI derived unit whose expression in terms of SI base units is s\u22121, meaning that one hertz is the reciprocal of one second. It is named after Heinrich Rudolf Hertz (1857\u20131894), the first person to provide conclusive proof of the existence of electromagnetic waves. Hertz are commonly expressed in multiples: kilohertz (kHz), megahertz (MHz), gigahertz (GHz), terahertz (THz).\nSome of the unit's most common uses are in the description of periodic waveforms and musical tones, particularly those used in radio- and audio-related applications. It is also used to describe the clock speeds at which computers and other electronics are driven. The units are sometimes also used as a representation of the energy of a photon, via the Planck relation E = h\u03bd, where E is the photon's energy, \u03bd is its frequency, and h is the Planck constant.\n\n\n== Definition ==\nThe hertz is equivalent to one cycle per second. The International Committee for Weights and Measures defined the second as \"the duration of 9192631770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom\" and then adds: \"It follows that the hyperfine splitting in the ground state of the caesium 133 atom is exactly 9192631770 hertz, \u03bdhfs Cs = 9192631770 Hz.\" The dimension of the unit hertz is 1/time (T\u22121). Expressed in base SI units, the unit is the reciprocal second (1/s).\nIn English, \"hertz\" is also used as the plural form. As an SI unit, Hz can be prefixed; commonly used multiples are kHz (kilohertz, 103 Hz), MHz (megahertz, 106 Hz), GHz (gigahertz, 109 Hz) and THz (terahertz, 1012 Hz). One hertz simply means \"one event per second\" (where the event being counted may be a complete cycle); 100 Hz means \"one hundred events per second\", and so on. The unit may be applied to any periodic event\u2014for example, a clock might be said to tick at 1 Hz, or a human heart might be said to beat at 1.2 Hz.\nThe occurrence rate of aperiodic or stochastic events is expressed in reciprocal second or inverse second (1/s or s\u22121) in general or, in the specific case of radioactivity, in becquerels. Whereas 1 Hz is one cycle (or periodic event) per second, 1 Bq is one radionuclide event per second on average.\nEven though frequency, angular velocity, angular frequency and radioactivity all have the dimension T\u22121, of these only frequency is expressed using the unit hertz. Thus a disc rotating at 60 revolutions per minute (rpm) is said to have an angular velocity of 2\u03c0 rad/s and a frequency of rotation of 1 Hz. The correspondence between a frequency f with the unit hertz and an angular velocity \u03c9 with the unit radians per second is\n\n  \n    \n      \n        \u03c9\n        =\n        2\n        \u03c0\n        f\n      \n    \n    {\\displaystyle \\omega =2\\pi f}\n   and \n  \n    \n      \n        f\n        =\n        \n          \n            \u03c9\n            \n              2\n              \u03c0\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {\\omega }{2\\pi }}.}\n  The hertz is named after Heinrich Hertz. As with every SI unit named for a person, its symbol starts with an upper case letter (Hz), but when written in full it follows the rules for capitalisation of a common noun; i.e., \"hertz\" becomes capitalised at the beginning of a sentence and in titles, but is otherwise in lower case.\n\n\n== History ==\n\nThe hertz is named after the German physicist Heinrich Hertz (1857\u20131894), who made important scientific contributions to the study of electromagnetism. The name was established by the International Electrotechnical Commission (IEC) in 1935. It was adopted by the General Conference on Weights and Measures (CGPM) (Conf\u00e9rence g\u00e9n\u00e9rale des poids et mesures) in 1960, replacing the previous name for the unit, \"cycles per second\" (cps), along with its related multiples, primarily \"kilocycles per second\" (kc/s) and \"megacycles per second\" (Mc/s), and occasionally \"kilomegacycles per second\" (kMc/s). The term \"cycles per second\" was largely replaced by \"hertz\" by the 1970s.In some usage, the \"per second\" was omitted, so that \"megacycles\" (Mc) was used as an abbreviation of \"megacycles per second\" (that is, megahertz (MHz)).\n\n\n== Applications ==\n\n\n=== Sound and vibration ===\nSound is a traveling longitudinal wave, which is an oscillation of pressure. Humans perceive the frequency of a sound as its pitch. Each musical note corresponds to a particular frequency. An infant's ear is able to perceive frequencies ranging from 20 Hz to 20000 Hz; the average adult human can hear sounds between 20 Hz and 16000 Hz. The range of ultrasound, infrasound and other physical vibrations such as molecular and atomic vibrations extends from a few femtohertz into the terahertz range and beyond.\n\n\n=== Electromagnetic radiation ===\nElectromagnetic radiation is often described by its frequency\u2014the number of oscillations of the perpendicular electric and magnetic fields per second\u2014expressed in hertz.\nRadio frequency radiation is usually measured in kilohertz (kHz), megahertz (MHz), or gigahertz (GHz). Light is electromagnetic radiation that is even higher in frequency, and has frequencies in the range of tens (infrared) to thousands (ultraviolet) of terahertz. Electromagnetic radiation with frequencies in the low terahertz range (intermediate between those of the highest normally usable radio frequencies and long-wave infrared light) is often called terahertz radiation. Even higher frequencies exist, such as that of gamma rays, which can be measured in exahertz (EHz). (For historical reasons, the frequencies of light and higher frequency electromagnetic radiation are more commonly specified in terms of their wavelengths or photon energies: for a more detailed treatment of this and the above frequency ranges, see Electromagnetic spectrum.)\n\n\n=== Computers ===\n\nIn computers, most central processing units (CPU) are labeled in terms of their clock rate expressed in megahertz (MHz) or gigahertz (GHz). This specification refers to the frequency of the CPU's master clock signal. This signal is nominally a square wave, which is an electrical voltage that switches between low and high logic levels at regular intervals. As the hertz has become the primary unit of measurement accepted by the general populace to determine the performance of a CPU, many experts have criticized this approach, which they claim is an easily manipulable benchmark. Some processors use multiple clock cycles to perform a single operation, while others can perform multiple operations in a single cycle. For personal computers, CPU clock speeds have ranged from approximately 1 MHz in the late 1970s (Atari, Commodore, Apple computers) to up to 6 GHz in IBM Power microprocessors.\nVarious computer buses, such as the front-side bus connecting the CPU and northbridge, also operate at various frequencies in the megahertz range.\n\n\n== SI multiples ==\n\nHigher frequencies than the International System of Units provides prefixes for are believed to occur naturally in the frequencies of the quantum-mechanical vibrations of massive particles, although these are not directly observable and must be inferred through other phenomena. By convention, these are typically not expressed in hertz, but in terms of the equivalent energy, which is proportional to the frequency by the factor of the Planck constant.\n\n\n== Unicode ==\nThe CJK Compatibility block in Unicode contains characters for common SI units for frequency. These are intended for compatibility with East Asian character encodings, and not for use in new documents (which would be expected to use Latin letters, e.g. \"MHz\").\nU+3390 \u3390 SQUARE HZ\nU+3391 \u3391 SQUARE KHZ\nU+3392 \u3392 SQUARE MHZ\nU+3393 \u3393 SQUARE GHZ\nU+3394 \u3394 SQUARE THZ\n\n\n== See also ==\nAlternating current\nBandwidth (signal processing)\nElectronic tuner\nFLOPS\nFrequency changer\nNormalized frequency (signal processing)\nOrders of magnitude (frequency)\nPeriodic function\nRadian per second\nRate\nSampling rate\n\n\n== Notes and references ==\n\n\n== External links ==\nSI Brochure: Unit of time (second)\nNational Research Council of Canada: Cesium fountain clock\nNational Research Council of Canada: Optical frequency standard based on a single trapped ion (archived 23 December 2013)\nNational Research Council of Canada: Optical frequency comb (archived 27 June 2013)\nNational Physical Laboratory: Time and frequency Optical atomic clocks\nOnline Tone Generator", "Doppler_effect": "The Doppler effect or Doppler shift (or simply Doppler, when in context) is the apparent change in frequency of a wave in relation to an observer moving relative to the wave source. It is named after the Austrian physicist Christian Doppler, who described the phenomenon in 1842.\nA common example of Doppler shift is the change of pitch heard when a vehicle sounding a horn approaches and recedes from an observer. Compared to the emitted frequency, the received frequency is higher during the approach, identical at the instant of passing by, and lower during the recession.The reason for the Doppler effect is that when the source of the waves is moving towards the observer, each successive wave crest is emitted from a position closer to the observer than the crest of the previous wave.  Therefore, each wave takes slightly less time to reach the observer than the previous wave. Hence, the time between the arrivals of successive wave crests at the observer is reduced, causing an increase in the frequency. While they are traveling, the distance between successive wave fronts is reduced, so the waves \"bunch together\".  Conversely, if the source of waves is moving away from the observer, each wave is emitted from a position farther from the observer than the previous wave, so the arrival time between successive waves is increased, reducing the frequency. The distance between successive wave fronts is then increased, so the waves \"spread out\". \nFor waves that propagate in a medium, such as sound waves, the velocity of the observer and of the source are relative to the medium in which the waves are transmitted. The total Doppler effect may therefore result from motion of the source, motion of the observer, motion of the medium, or any combination thereof. For waves propagating in vacuum, such as electromagnetic waves or gravitational waves, only the difference in velocity between the observer and the source needs to be considered. If this relative speed is not negligible compared to the speed of light, a more complicated relativistic Doppler effect arises.\n\n\n== History ==\n\nDoppler first proposed this effect in 1842 in his treatise \"\u00dcber das farbige Licht der Doppelsterne und einiger anderer Gestirne des Himmels\" (On the coloured light of the binary stars and some other stars of the heavens). The hypothesis was tested for sound waves by Buys Ballot in 1845. He confirmed that the sound's pitch was higher than the emitted frequency when the sound source approached him, and lower than the emitted frequency when the sound source receded from him. Hippolyte Fizeau discovered independently the same phenomenon on electromagnetic waves in 1848 (in France, the effect is sometimes called \"effet Doppler-Fizeau\" but that name was not adopted by the rest of the world as Fizeau's discovery was six years after Doppler's proposal). In Britain, John Scott Russell made an experimental study of the Doppler effect (1848).\n\n\n== General ==\nIn classical physics, where the speeds of source and the receiver relative to the medium are lower than the speed of waves in the medium, the relationship between observed frequency \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   and emitted frequency \n  \n    \n      \n        \n          f\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle f_{\\text{0}}}\n   is given by:\nwhere\n\n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the propagation speed of waves in the medium;\n\n  \n    \n      \n        \n          v\n          \n            r\n          \n        \n      \n    \n    {\\displaystyle v_{\\text{r}}}\n   is the speed of the receiver relative to the medium, added to \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   if the receiver is moving towards the source, subtracted if the receiver is moving away from the source;\n\n  \n    \n      \n        \n          v\n          \n            s\n          \n        \n      \n    \n    {\\displaystyle v_{\\text{s}}}\n   is the speed of the source relative to the medium, added to \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   if the source is moving away from the receiver, subtracted if the source is moving towards the receiver.Note this relationship predicts that the frequency will decrease if either source or receiver is moving away from the other.\nEquivalently, under the assumption that the source is either directly approaching or receding from the observer:\n\nwhere \n\n  \n    \n      \n        \n          v\n          \n            w\n            r\n          \n        \n      \n    \n    {\\displaystyle v_{wr}}\n   is the wave's speed relative to the receiver;\n\n  \n    \n      \n        \n          v\n          \n            w\n            s\n          \n        \n      \n    \n    {\\displaystyle v_{ws}}\n   is the wave's speed relative to the source;\n\n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is the wavelength.If the source approaches the observer at an angle (but still with a constant speed), the observed frequency that is first heard is higher than the object's emitted frequency. Thereafter, there is a monotonic decrease in the observed frequency as it gets closer to the observer, through equality when it is coming from a direction perpendicular to the relative motion (and was emitted at the point of closest approach; but when the wave is received, the source and observer will no longer be at their closest), and a continued monotonic decrease as it recedes from the observer. When the observer is very close to the path of the object, the transition from high to low frequency is very abrupt. When the observer is far from the path of the object, the transition from high to low frequency is gradual.\nIf the speeds \n  \n    \n      \n        \n          v\n          \n            s\n          \n        \n      \n    \n    {\\displaystyle v_{\\text{s}}}\n   and \n  \n    \n      \n        \n          v\n          \n            r\n          \n        \n        \n      \n    \n    {\\displaystyle v_{\\text{r}}\\,}\n   are small compared to the speed of the wave, the relationship between observed frequency \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   and emitted frequency \n  \n    \n      \n        \n          f\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle f_{\\text{0}}}\n   is approximately\nwhere\n\n  \n    \n      \n        \u0394\n        f\n        =\n        f\n        \u2212\n        \n          f\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\Delta f=f-f_{0}}\n  \n\n  \n    \n      \n        \u0394\n        v\n        =\n        \u2212\n        (\n        \n          v\n          \n            r\n          \n        \n        \u2212\n        \n          v\n          \n            s\n          \n        \n        )\n      \n    \n    {\\displaystyle \\Delta v=-(v_{\\text{r}}-v_{\\text{s}})}\n   is the opposite of the relative speed of the receiver with respect to the source: it is positive when the source and the receiver are moving towards each other.\n\n\t\t\n\t\t\n\t\t\n\n\n== Consequences ==\nWith an observer stationary relative to the medium, if a moving source is emitting waves with an actual frequency \n  \n    \n      \n        \n          f\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle f_{0}}\n   (in this case, the wavelength is changed, the transmission velocity of the wave keeps constant; note that the transmission velocity of the wave does not depend on the velocity of the source), then the observer detects waves with a frequency \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   given by\n\nA similar analysis for a moving observer and a stationary source (in this case, the wavelength keeps constant, but due to the motion, the rate at which the observer receives waves and hence the transmission velocity of the wave [with respect to the observer] is changed) yields the observed frequency:\n\nAssuming a stationary observer and a source moving at the speed of sound, the Doppler equation predicts a perceived momentary infinite frequency by an observer in front of a source that is traveling at the speed of sound. All the peaks are at the same place, so the wavelength is zero and the frequency is infinite. This overlay of all the waves produces a shock wave which for sound waves is known as a sonic boom.\nWhen the source moves faster than the wave speed the source outruns the wave. The equation gives negative frequency values, which have no physical sense in this context (no sound at all will be heard by the observer until the source passes past them).\nLord Rayleigh predicted the following effect in his classic book on sound: if the observer were moving from the (stationary) source at twice the speed of sound, a musical piece previously emitted by that source would be heard in correct tempo and pitch, but as if played backwards.\n\n\n== Applications ==\n\n\n=== Acoustic Doppler current profiler ===\nAn acoustic Doppler current profiler (ADCP) is a hydroacoustic current meter similar to a sonar, used to measure water current velocities over a depth range using the Doppler effect of sound waves scattered back from particles within the water column. The term ADCP is a generic term for all acoustic current profilers, although the abbreviation originates from an instrument series introduced by RD Instruments in the 1980s.  The working frequencies range of ADCPs range from 38 kHz to several Megahertz. The device used in the air for wind speed profiling using sound is known as SODAR and works with the same underlying principles.\n\n\n=== Robotics ===\nDynamic real-time path planning in robotics to aid the movement of robots in a sophisticated environment with moving obstacles often take help of Doppler effect. Such applications are specially used for competitive robotics where the environment is constantly changing, such as robosoccer.\n\n\n=== Sirens ===\n\nA siren on a passing emergency vehicle will start out higher than its stationary pitch, slide down as it passes, and continue lower than its stationary pitch as it recedes from the observer. Astronomer John Dobson explained the effect thus:\n\nThe reason the siren slides is because it doesn't hit you.\nIn other words, if the siren approached the observer directly, the pitch would remain constant, at a higher than stationary pitch, until the vehicle hit him, and then immediately jump to a new lower pitch. Because the vehicle passes by the observer, the radial speed does not remain constant, but instead varies as a function of the angle between his line of sight and the siren's velocity:\n\nwhere \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between the object's forward velocity and the line of sight from the object to the observer.\n\n\n=== Astronomy ===\n\nThe Doppler effect for electromagnetic waves such as light is of widespread use in astronomy to measure the speed at which stars and galaxies are approaching or receding from us, resulting in so called blueshift or redshift, respectively. This may be used to detect if an apparently single star is, in reality, a close binary, to measure the rotational speed of stars and galaxies, or to detect exoplanets. This effect typically happens on a very small scale; there would not be a noticeable difference in visible light to the unaided eye.\nThe use of the Doppler effect in astronomy depends on knowledge of precise frequencies of discrete lines in the spectra of stars.\nAmong the nearby stars, the largest radial velocities with respect to the Sun are +308 km/s (BD-15\u00b04041, also known as LHS 52, 81.7 light-years away) and \u2212260 km/s (Woolley 9722, also known as Wolf 1106 and LHS 64, 78.2 light-years away). Positive radial speed means the star is receding from the Sun, negative that it is approaching.\nRedshift is also used to measure the expansion of space, but this is not truly a Doppler effect. Rather, redshifting due to the expansion of space is known as cosmological redshift, which can be derived purely from the Robertson-Walker metric under the formalism of general relativity. Having said this, it also happens that there are detectable Doppler effects on cosmological scales, which, if incorrectly interpreted as cosmological in origin, lead to the observation of redshift-space distortions.\n\n\n=== Radar ===\n\nThe Doppler effect is used in some types of radar, to measure the velocity of detected objects. A radar beam is fired at a moving target \u2014 e.g. a motor car, as police use radar to detect speeding motorists \u2014 as it approaches or recedes from the radar source. Each successive radar wave has to travel farther to reach the car, before being reflected and re-detected near the source. As each wave has to move farther, the gap between each wave increases, increasing the wavelength. In some situations, the radar beam is fired at the moving car as it approaches, in which case each successive wave travels a lesser distance, decreasing the wavelength. In either situation, calculations from the Doppler effect accurately determine the car's speed. Moreover, the proximity fuze, developed during World War II, relies upon Doppler radar to detonate explosives at the correct time, height, distance, etc.Because the Doppler shift affects the wave incident upon the target as well as the wave reflected back to the radar, the change in frequency observed by a radar due to a target moving at relative speed \n  \n    \n      \n        \u0394\n        v\n      \n    \n    {\\displaystyle \\Delta v}\n   is twice that from the same target emitting a wave:\n\n\n=== Medical ===\n\nAn echocardiogram can, within certain limits, produce an accurate assessment of the direction of blood flow and the velocity of blood and cardiac tissue at any arbitrary point using the Doppler effect. One of the limitations is that the ultrasound beam should be as parallel to the blood flow as possible. Velocity measurements allow assessment of cardiac valve areas and function, abnormal communications between the left and right side of the heart, leaking of blood through the valves (valvular regurgitation), and calculation of the cardiac output. Contrast-enhanced ultrasound using gas-filled microbubble contrast media can be used to improve velocity or other flow-related medical measurements.Although \"Doppler\" has become synonymous with \"velocity measurement\" in medical imaging, in many cases it is not the frequency shift (Doppler shift) of the received signal that is measured, but the phase shift (when the received signal arrives).Velocity measurements of blood flow are also used in other fields of medical ultrasonography, such as obstetric ultrasonography and neurology. Velocity measurement of blood flow in arteries and veins based on Doppler effect is an effective tool for diagnosis of vascular problems like stenosis.\n\n\n=== Flow measurement ===\nInstruments such as the laser Doppler velocimeter (LDV), and acoustic Doppler velocimeter (ADV) have been developed to measure velocities in a fluid flow. The LDV emits a light beam and the ADV emits an ultrasonic acoustic burst, and measure the Doppler shift in wavelengths of reflections from particles moving with the flow. The actual flow is computed as a function of the water velocity and phase. This technique allows non-intrusive flow measurements, at high precision and high frequency.\n\n\n=== Velocity profile measurement ===\nDeveloped originally for velocity measurements in medical applications (blood flow), Ultrasonic Doppler Velocimetry (UDV) can measure in real time complete velocity profile in almost any liquids containing particles in suspension such as dust, gas bubbles, emulsions. Flows can be pulsating, oscillating, laminar or turbulent, stationary or transient. This technique is fully non-invasive.\n\n\n=== Satellites ===\n\n\n==== Satellite navigation ====\n\nThe Doppler shift can be exploited for satellite navigation such as in Transit and DORIS. \n\n\n==== Satellite communication ====\n\nDoppler also needs to be compensated in satellite communication. \nFast moving satellites can have a Doppler shift of dozens of kilohertz relative to a ground station. The speed, thus magnitude of Doppler effect, changes due to earth curvature. Dynamic Doppler compensation, where the frequency of a signal is changed progressively during transmission, is used so the satellite receives a constant frequency signal. After realizing that the Doppler shift had not been considered before launch of the  Huygens probe of the 2005 Cassini\u2013Huygens mission, the probe trajectory was altered to approach Titan in such a way that its transmissions traveled perpendicular to its direction of motion relative to Cassini, greatly reducing the Doppler shift.Doppler shift of the direct path can be estimated by the following formula:\nwhere \n  \n    \n      \n        \n          v\n          \n            mob\n          \n        \n      \n    \n    {\\displaystyle v_{\\text{mob}}}\n   is the speed of the mobile station, \n  \n    \n      \n        \n          \u03bb\n          \n            \n              c\n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda _{\\rm {c}}}\n   is the wavelength of the carrier, \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   is the elevation angle of the satellite and \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the driving direction with respect to the satellite.\nThe additional Doppler shift due to the satellite moving can be described as:\n\nwhere \n  \n    \n      \n        \n          v\n          \n            \n              r\n              e\n              l\n              ,\n              s\n              a\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle v_{\\rm {rel,sat}}}\n   is the relative speed of the satellite.\n\n\n=== Audio ===\nThe Leslie speaker, most commonly associated with and predominantly used with the famous Hammond organ, takes advantage of the Doppler effect by using an electric motor to rotate an acoustic horn around a loudspeaker, sending its sound in a circle. This results at the listener's ear in rapidly fluctuating frequencies of a keyboard note.\n\n\n=== Vibration measurement ===\nA laser Doppler vibrometer (LDV) is a non-contact instrument for measuring vibration. The laser beam from the LDV is directed at the surface of interest, and the vibration amplitude and frequency are extracted from the Doppler shift of the laser beam frequency due to the motion of the surface.\n\n\n=== Developmental biology ===\nDuring the segmentation of vertebrate embryos, waves of gene expression sweep across the presomitic mesoderm, the tissue from which the precursors of the vertebrae (somites) are formed. A new somite is formed upon arrival of a wave at the anterior end of the presomitic mesoderm. In zebrafish, it has been shown that the shortening of the presomitic mesoderm during segmentation leads to a Doppler-like effect as the anterior end of the tissue moves into the waves. This effect contributes to the period of segmentation.\n\n\n== Inverse Doppler effect ==\nSince 1968 scientists such as Victor Veselago have speculated about the possibility of an inverse Doppler effect. The size of the Doppler shift depends on the refractive index of the medium a wave is traveling through. But some materials are capable of negative refraction, which should lead to a Doppler shift that works in a direction opposite that of a conventional Doppler shift. The first experiment that detected this effect was conducted by Nigel Seddon and Trevor Bearpark in Bristol, United Kingdom in 2003. Later, the inverse Doppler effect was observed in some inhomogeneous materials, and predicted inside a Vavilov\u2013Cherenkov cone.\n\n\n== See also ==\n\n\n== Primary sources ==\n\n\n== References ==\n\n\n== Further reading ==\nDoppler, C. (1842). \u00dcber das farbige Licht der Doppelsterne und einiger anderer Gestirne des Himmels (About the coloured light of the binary stars and some other stars of the heavens). Publisher: Abhandlungen der K\u00f6nigl. B\u00f6hm. Gesellschaft der Wissenschaften (V. Folge, Bd. 2, S. 465\u2013482) [Proceedings of the Royal Bohemian Society of Sciences (Part V, Vol 2)]; Prague: 1842 (Reissued 1903). Some sources mention 1843 as year of publication because in that year the article was published in the Proceedings of the Bohemian Society of Sciences. Doppler himself referred to the publication as \"Prag 1842 bei Borrosch und Andr\u00e9\", because in 1842 he had a preliminary edition printed that he distributed independently.\n\"Doppler and the Doppler effect\", E. N. da C. Andrade, Endeavour Vol. XVIII No. 69, January 1959 (published by ICI London). Historical account of Doppler's original paper and subsequent developments.\nDavid Nolte (2020). The fall and rise of the Doppler effect. Physics Today, v. 73, pgs. 31 - 35. DOI: 10.1063/PT.3.4429\nAdrian, Eleni (24 June 1995). \"Doppler Effect\". NCSA. Archived from the original on 12 May 2009. Retrieved 2008-07-13.\n\n\n== External links ==\n Media related to Doppler effect at Wikimedia Commons\nDoppler Effect, ScienceWorld", "Dispersion_(optics)": "In optics and in wave propagation in general, dispersion is the phenomenon in which the phase velocity of a wave depends on its frequency; sometimes the term chromatic dispersion is used for specificity to optics in particular.\nA medium having this common property may be termed a dispersive medium (plural dispersive media).\nAlthough the term is used in the field of optics to describe light and other electromagnetic waves, dispersion in the same sense can apply to any sort of wave motion such as acoustic dispersion in the case of sound and seismic waves, and in gravity waves (ocean waves). Within optics, dispersion is a property of telecommunication signals along transmission lines (such as microwaves in coaxial cable) or the pulses of light in optical fiber.\nIn optics, one important and familiar consequence of dispersion is the change in the angle of refraction of different colors of light, as seen in the spectrum produced by a dispersive prism and in chromatic aberration of lenses. Design of compound achromatic lenses, in which chromatic aberration is largely cancelled, uses a quantification of a glass's dispersion given by its Abbe number V, where lower Abbe numbers correspond to greater dispersion over the visible spectrum. In some applications such as telecommunications, the absolute phase of a wave is often not important but only the propagation of wave packets or \"pulses\"; in that case one is interested only in variations of group velocity with frequency, so-called group-velocity dispersion.\nAll common transmission media also vary in attenuation (normalized to transmission length) as a function of frequency, leading to attenuation distortion; this is not dispersion, although sometimes reflections at closely spaced impedance boundaries (e.g. crimped segments in a cable) can produce signal distortion with further aggravates inconsistent transit time as observed across signal bandwidth.\n\n\n== Examples ==\nThe most familiar example of dispersion is probably a rainbow, in which dispersion causes the spatial separation of a white light into components of different wavelengths (different colors). However, dispersion also has an effect in many other circumstances: for example, group-velocity dispersion causes pulses to spread in optical fibers, degrading signals over long distances; also, a cancellation between group-velocity dispersion and nonlinear effects leads to soliton waves.\n\n\n== Material and waveguide dispersion ==\nMost often, chromatic dispersion refers to bulk material dispersion, that is,  the change in refractive index with optical frequency. However, in a waveguide there is also the phenomenon of waveguide dispersion, in which case a wave's phase velocity in a structure depends on its frequency simply due to the structure's geometry. More generally, \"waveguide\" dispersion can occur for waves propagating through any inhomogeneous structure (e.g., a photonic crystal), whether or not the waves are confined to some region. In a waveguide, both types of dispersion will generally be present, although they are not strictly additive. For example, in fiber optics the material and waveguide dispersion can effectively cancel each other out to produce a zero-dispersion wavelength, important for fast fiber-optic communication.\n\n\n== Material dispersion in optics ==\n\nMaterial dispersion can be a desirable or undesirable effect in optical applications. The dispersion of light by glass prisms is used to construct spectrometers and spectroradiometers. However, in lenses, dispersion causes chromatic aberration, an undesired effect that may degrade images in microscopes, telescopes, and photographic objectives.\nThe phase velocity v of a wave in a given uniform medium is given by\n\n  \n    \n      \n        v\n        =\n        \n          \n            c\n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle v={\\frac {c}{n}},}\n  where c is the speed of light in vacuum, and n is the refractive index of the medium.\nIn general, the refractive index is some function of the frequency f of the light, thus n = n(f), or alternatively, with respect to the wave's wavelength n = n(\u03bb). The wavelength dependence of a material's refractive index is usually quantified by its Abbe number or its coefficients in an empirical formula such as the Cauchy or Sellmeier equations.\nBecause of the Kramers\u2013Kronig relations, the wavelength dependence of the real part of the refractive index is related to the material absorption, described by the imaginary part of the refractive index (also called the extinction coefficient). In particular, for non-magnetic materials (\u03bc = \u03bc0), the susceptibility \u03c7 that appears in the Kramers\u2013Kronig relations is the electric susceptibility \u03c7e = n2 \u2212 1.\nThe most commonly seen consequence of dispersion in optics is the separation of white light into a color spectrum by a prism. From Snell's law it can be seen that the angle of refraction of light in a prism depends on the refractive index of the prism material. Since that refractive index varies with wavelength, it follows that the angle that the light is refracted by will also vary with wavelength, causing an angular separation of the colors known as angular dispersion.\nFor visible light, refraction indices n of most transparent materials (e.g., air, glasses) decrease with increasing wavelength \u03bb:\n\n  \n    \n      \n        1\n        <\n        n\n        (\n        \n          \u03bb\n          \n            red\n          \n        \n        )\n        <\n        n\n        (\n        \n          \u03bb\n          \n            yellow\n          \n        \n        )\n        <\n        n\n        (\n        \n          \u03bb\n          \n            blue\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle 1<n(\\lambda _{\\text{red}})<n(\\lambda _{\\text{yellow}})<n(\\lambda _{\\text{blue}}),}\n  or generally,\n\n  \n    \n      \n        \n          \n            \n              d\n              n\n            \n            \n              d\n              \u03bb\n            \n          \n        \n        <\n        0.\n      \n    \n    {\\displaystyle {\\frac {dn}{d\\lambda }}<0.}\n  In this case, the medium is said to have normal dispersion. Whereas if the index increases with increasing wavelength (which is typically the case in the ultraviolet), the medium is said to have anomalous dispersion.\nAt the interface of such a material with air or vacuum (index of ~1), Snell's law predicts that light incident at an angle \u03b8 to the normal will be refracted at an angle arcsin(sin \u03b8/n). Thus, blue light, with a higher refractive index, will be bent more strongly than red light, resulting in the well-known rainbow pattern.\n\n\n== Group-velocity dispersion ==\n\nBeyond simply describing a change in the phase velocity over wavelength, a more serious consequence of dispersion in many applications is termed  group-velocity dispersion (GVD). While phase velocity v is defined as v = c/n, this describes only one frequency component. When different frequency components are combined, as when considering a signal or a pulse, one is often more interested in the group velocity, which describes the speed at which a pulse or information superimposed on a wave (modulation) propagates. In the accompanying animation, it can be seen that the wave itself (orange-brown) travels at a phase velocity much faster than the speed of the envelope (black), which corresponds to the group velocity. This pulse might be a communications signal, for instance, and its information only travels at the group velocity rate, even though it consists of wavefronts advancing at a faster rate (the phase velocity).\nIt is possible to calculate the group velocity from the refractive-index curve n(\u03c9) or more directly from the wavenumber k = \u03c9n/c, where \u03c9 is the radian frequency \u03c9 = 2\u03c0f. Whereas one expression for the phase velocity is vp = \u03c9/k, the group velocity can be expressed using the derivative: vg = d\u03c9/dk. Or in terms of the phase velocity vp,\n\n  \n    \n      \n        \n          v\n          \n            g\n          \n        \n        =\n        \n          \n            \n              v\n              \n                p\n              \n            \n            \n              1\n              \u2212\n              \n                \n                  \n                    \u03c9\n                    \n                      v\n                      \n                        p\n                      \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      d\n                      \n                        v\n                        \n                          p\n                        \n                      \n                    \n                    \n                      d\n                      \u03c9\n                    \n                  \n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle v_{\\text{g}}={\\frac {v_{\\text{p}}}{1-{\\dfrac {\\omega }{v_{\\text{p}}}}{\\dfrac {dv_{\\text{p}}}{d\\omega }}}}.}\n  When dispersion is present, not only the group velocity is not equal to the phase velocity, but generally it itself varies with wavelength. This is known as group-velocity dispersion and causes a short pulse of light to be broadened, as the different-frequency components within the pulse travel at different velocities. Group-velocity dispersion is quantified as the derivative of the reciprocal of the group velocity with respect to angular frequency, which results in group-velocity dispersion = d2k/d\u03c92.\nIf a light pulse is propagated through a material with positive group-velocity dispersion, then the shorter-wavelength components travel slower than the longer-wavelength components. The pulse therefore becomes positively chirped, or up-chirped, increasing in frequency with time. On the other hand, if a pulse travels through a material with negative group-velocity dispersion, shorter-wavelength components travel faster than the longer ones, and the pulse becomes negatively chirped, or down-chirped, decreasing in frequency with time.\nAn everyday example of a negatively chirped signal in the acoustic domain is that of an approaching train hitting deformities on a welded track. The sound caused by the train itself is impulsive and travels much faster in the metal tracks than in air, so that the train can be heard well before it arrives. However, from afar it isn't heard as causing impulses, but leads to a distinctive descending chirp, amidst reverberation caused by the complexity of the vibrational modes of the track. Group-velocity dispersion can be heard in that the volume of the sounds stays audible for a surprisingly long time, up to several seconds.\nThe group-velocity dispersion parameter\n\n  \n    \n      \n        D\n        =\n        \n          \n            1\n            c\n          \n        \n        \n        \n          \n            \n              d\n              n\n            \n            \n              d\n              \u03bb\n            \n          \n        \n      \n    \n    {\\displaystyle D={\\frac {1}{c}}\\,{\\frac {dn}{d\\lambda }}}\n  is often used to quantify GVD, which is proportional to D through a negative factor:\n\n  \n    \n      \n        D\n        =\n        \u2212\n        \n          \n            \n              2\n              \u03c0\n              c\n            \n            \n              \u03bb\n              \n                2\n              \n            \n          \n        \n        \n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              k\n            \n            \n              d\n              \n                \u03c9\n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle D=-{\\frac {2\\pi c}{\\lambda ^{2}}}\\,{\\frac {d^{2}k}{d\\omega ^{2}}}.}\n  According to some authors, a medium is said to have normal dispersion/anomalous dispersion for a certain vacuum wavelength \u03bb0 if the second derivative of the refraction index calculated in \u03bb0 is positive/negative or, equivalently, if D(\u03bb0) is negative/positive. This definition concerns group-velocity dispersion and should not be confused with the one given in previous section. The two definitions do not coincide in general, so the reader has to understand the context.\n\n\n== Dispersion control ==\nThe result of GVD, whether negative or positive, is ultimately temporal spreading of the pulse. This makes dispersion management extremely important in optical communications systems based on optical fiber, since if dispersion is too high, a group of pulses representing a bit-stream will spread in time and merge, rendering the bit-stream unintelligible. This limits the length of fiber that a signal can be sent down without regeneration. One possible answer to this problem is to send signals down the optical fibre at a wavelength where the GVD is zero (e.g., around 1.3\u20131.5 \u03bcm in silica fibres), so pulses at this wavelength suffer minimal spreading from dispersion. In practice, however, this approach causes more problems than it solves because zero GVD unacceptably amplifies other nonlinear effects (such as four-wave mixing). Another possible option is to use soliton pulses in the regime of negative dispersion, a form of optical pulse which uses a nonlinear optical effect to self-maintain its shape. Solitons have the practical problem, however, that they require a certain power level to be maintained in the pulse for the nonlinear effect to be of the correct strength. Instead, the solution that is currently used in practice is to perform dispersion compensation, typically by matching the fiber with another fiber of opposite-sign dispersion so that the dispersion effects cancel; such compensation is ultimately limited by nonlinear effects such as self-phase modulation, which interact with dispersion to make it very difficult to undo.\nDispersion control is also important in lasers that produce short pulses. The overall dispersion of the optical resonator is a major factor in determining the duration of the pulses emitted by the laser. A pair of prisms can be arranged to produce net negative dispersion, which can be used to balance the usually positive dispersion of the laser medium. Diffraction gratings can also be used to produce dispersive effects; these are often used in high-power laser amplifier systems. Recently, an alternative to prisms and gratings has been developed: chirped mirrors. These dielectric mirrors are coated so that different wavelengths have different penetration lengths, and therefore different group delays. The coating layers can be tailored to achieve a net negative dispersion.\n\n\n== In waveguides ==\nWaveguides are highly dispersive due to their geometry (rather than just to their material composition). Optical fibers are a sort of waveguide for optical frequencies (light) widely used in modern telecommunications systems. The rate at which data can be transported on a single fiber is limited by pulse broadening due to chromatic dispersion among other phenomena.\nIn general, for a waveguide mode with an angular frequency \u03c9(\u03b2) at a propagation constant \u03b2 (so that the electromagnetic fields in the propagation direction z oscillate proportional to ei(\u03b2z\u2212\u03c9t)), the group-velocity dispersion parameter D is defined as\n\n  \n    \n      \n        D\n        =\n        \u2212\n        \n          \n            \n              2\n              \u03c0\n              c\n            \n            \n              \u03bb\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              \u03b2\n            \n            \n              d\n              \n                \u03c9\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              2\n              \u03c0\n              c\n            \n            \n              \n                v\n                \n                  g\n                \n                \n                  2\n                \n              \n              \n                \u03bb\n                \n                  2\n                \n              \n            \n          \n        \n        \n          \n            \n              d\n              \n                v\n                \n                  g\n                \n              \n            \n            \n              d\n              \u03c9\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle D=-{\\frac {2\\pi c}{\\lambda ^{2}}}{\\frac {d^{2}\\beta }{d\\omega ^{2}}}={\\frac {2\\pi c}{v_{g}^{2}\\lambda ^{2}}}{\\frac {dv_{g}}{d\\omega }},}\n  where \u03bb = 2\u03c0c/\u03c9 is the vacuum wavelength, and vg = d\u03c9/d\u03b2 is the group velocity. This formula generalizes the one in the previous section for homogeneous media and includes both waveguide dispersion and material dispersion. The reason for defining the dispersion in this way is that |D| is the (asymptotic) temporal pulse spreading \u0394t per unit bandwidth\n\u0394\u03bb per unit distance travelled, commonly reported in ps/(nm\u22c5km) for optical fibers.\nIn the case of multi-mode optical fibers, so-called modal dispersion will also lead to pulse  broadening. Even in single-mode fibers, pulse broadening can occur as a result of polarization mode dispersion (since there are still two polarization modes). These are not examples of chromatic dispersion, as they are not dependent on the wavelength or bandwidth of the pulses propagated.\n\n\n== Higher-order dispersion over broad bandwidths ==\nWhen a broad range of frequencies (a broad bandwidth) is present in a single wavepacket, such as in an ultrashort pulse or a chirped pulse or other forms of spread spectrum transmission, it may not be accurate to approximate the dispersion by a constant over the entire bandwidth, and more complex calculations are required to compute effects such as pulse spreading.\nIn particular, the dispersion parameter D defined above is obtained from only one derivative of the group velocity. Higher derivatives are known as higher-order dispersion. These terms are simply a Taylor series expansion of the dispersion relation \u03b2(\u03c9) of the medium or waveguide around some particular frequency. Their effects can be computed via numerical evaluation of Fourier transforms of the waveform, via integration of higher-order slowly varying envelope approximations, by a split-step method (which can use the exact dispersion relation rather than a Taylor series), or by direct simulation of the full Maxwell's equations rather than an approximate envelope equation.\n\n\n== Generalized formulation of the high orders of dispersion \u2013 Lah-Laguerre optics ==\nThe description of the chromatic dispersion in a perturbative manner through Taylor coefficients is advantageous for optimization problems where the dispersion from several different systems needs to be balanced. For example, in chirp pulse laser amplifiers, the pulses are first stretched in time by a stretcher to avoid optical damage. Then in the amplification process, the pulses accumulate inevitably linear and nonlinear phase passing through materials. And lastly, the pulses are compressed in various types of compressors. To cancel any residual higher orders in the accumulated phase, usually individual orders are measured and balanced. However, for uniform systems, such perturbative description is often not needed (i.e., propagation in waveguides). \nThe dispersion orders have been generalized in a computationally friendly manner, in the form of Lah-Laguerre type transforms.The dispersion orders are defined by the Taylor expansion of the phase or the wavevector.\n\n  \n    \n      \n        \n          \n            \n              \n                \u03c6\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \u03c6\n                \n                  \n                    \n                     \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \n                    \n                       \n                      \n                        \n                          \n                            \u2202\n                            \u03c6\n                          \n                          \n                            \u2202\n                            \u03c9\n                          \n                        \n                      \n                    \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  (\n                  \n                    \u03c9\n                    \u2212\n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                  )\n                \n                +\n                \n                  \n                    1\n                    2\n                  \n                \n                \n                  \n                    \n                    \n                       \n                      \n                        \n                          \n                            \n                              \u2202\n                              \n                                2\n                              \n                            \n                            \u03c6\n                          \n                          \n                            \u2202\n                            \n                              \u03c9\n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  \n                    (\n                    \n                      \u03c9\n                      \u2212\n                      \n                        \u03c9\n                        \n                          0\n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n                 \n                +\n                \u2026\n                +\n                \n                  \n                    1\n                    \n                      p\n                      !\n                    \n                  \n                \n                \n                  \n                    \n                    \n                       \n                      \n                        \n                          \n                            \n                              \u2202\n                              \n                                p\n                              \n                            \n                            \u03c6\n                          \n                          \n                            \u2202\n                            \n                              \u03c9\n                              \n                                p\n                              \n                            \n                          \n                        \n                      \n                    \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  \n                    (\n                    \n                      \u03c9\n                      \u2212\n                      \n                        \u03c9\n                        \n                          0\n                        \n                      \n                    \n                    )\n                  \n                  \n                    p\n                  \n                \n                +\n                \u2026\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{c}\\varphi \\mathrm {(} \\omega \\mathrm {)} =\\varphi \\left.\\ \\right|_{\\omega _{0}}+\\left.\\ {\\frac {\\partial \\varphi }{\\partial \\omega }}\\right|_{\\omega _{0}}\\left(\\omega -\\omega _{0}\\right)+{\\frac {1}{2}}\\left.\\ {\\frac {\\partial ^{2}\\varphi }{\\partial \\omega ^{2}}}\\right|_{\\omega _{0}}\\left(\\omega -\\omega _{0}\\right)^{2}\\ +\\ldots +{\\frac {1}{p!}}\\left.\\ {\\frac {\\partial ^{p}\\varphi }{\\partial \\omega ^{p}}}\\right|_{\\omega _{0}}\\left(\\omega -\\omega _{0}\\right)^{p}+\\ldots \\end{array}}}\n    \n\n  \n    \n      \n        \n          \n            \n              \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                k\n                \n                  \n                    \n                     \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \n                    \n                       \n                      \n                        \n                          \n                            \u2202\n                            k\n                          \n                          \n                            \u2202\n                            \u03c9\n                          \n                        \n                      \n                    \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  (\n                  \n                    \u03c9\n                    \u2212\n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                  )\n                \n                +\n                \n                  \n                    1\n                    2\n                  \n                \n                \n                  \n                    \n                    \n                       \n                      \n                        \n                          \n                            \n                              \u2202\n                              \n                                2\n                              \n                            \n                            k\n                          \n                          \n                            \u2202\n                            \n                              \u03c9\n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  \n                    (\n                    \n                      \u03c9\n                      \u2212\n                      \n                        \u03c9\n                        \n                          0\n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n                 \n                +\n                \u2026\n                +\n                \n                  \n                    1\n                    \n                      p\n                      !\n                    \n                  \n                \n                \n                  \n                    \n                    \n                       \n                      \n                        \n                          \n                            \n                              \u2202\n                              \n                                p\n                              \n                            \n                            k\n                          \n                          \n                            \u2202\n                            \n                              \u03c9\n                              \n                                p\n                              \n                            \n                          \n                        \n                      \n                    \n                    |\n                  \n                  \n                    \n                      \u03c9\n                      \n                        0\n                      \n                    \n                  \n                \n                \n                  \n                    (\n                    \n                      \u03c9\n                      \u2212\n                      \n                        \u03c9\n                        \n                          0\n                        \n                      \n                    \n                    )\n                  \n                  \n                    p\n                  \n                \n                +\n                \u2026\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{c}k\\mathrm {(} \\omega \\mathrm {)} =k\\left.\\ \\right|_{\\omega _{0}}+\\left.\\ {\\frac {\\partial k}{\\partial \\omega }}\\right|_{\\omega _{0}}\\left(\\omega -\\omega _{0}\\right)+{\\frac {1}{2}}\\left.\\ {\\frac {\\partial ^{2}k}{\\partial \\omega ^{2}}}\\right|_{\\omega _{0}}\\left(\\omega -\\omega _{0}\\right)^{2}\\ +\\ldots +{\\frac {1}{p!}}\\left.\\ {\\frac {\\partial ^{p}k}{\\partial \\omega ^{p}}}\\right|_{\\omega _{0}}\\left(\\omega -\\omega _{0}\\right)^{p}+\\ldots \\end{array}}}\n  \nThe dispersion relations for the wavector \n  \n    \n      \n        k\n        \n          (\n        \n        \u03c9\n        \n          )\n        \n        =\n        \n          \n            \u03c9\n            c\n          \n        \n        n\n        \n          (\n        \n        \u03c9\n        \n          )\n        \n      \n    \n    {\\displaystyle k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\omega }{c}}n\\mathrm {(} \\omega \\mathrm {)} }\n   and the phase \n  \n    \n      \n        \u03c6\n        \n          (\n        \n        \u03c9\n        \n          )\n        \n        =\n        \n          \n            \u03c9\n            c\n          \n        \n        \n          \n            O\n            P\n          \n        \n        \n          (\n        \n        \u03c9\n        \n          )\n        \n      \n    \n    {\\displaystyle \\varphi \\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\omega }{c}}{\\it {OP}}\\mathrm {(} \\omega \\mathrm {)} }\n   can be expressed as:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    1\n                    c\n                  \n                \n                \n                  (\n                  \n                    p\n                    \n                      \n                        \n                          \n                            \u2202\n                          \n                          \n                            p\n                            \u2212\n                            1\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              p\n                              \u2212\n                              1\n                            \n                          \n                        \n                      \n                    \n                    n\n                    \n                      (\n                    \n                    \u03c9\n                    \n                      )\n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \u2202\n                          \n                          \n                            p\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              p\n                            \n                          \n                        \n                      \n                    \n                    n\n                    \n                      (\n                    \n                    \u03c9\n                    \n                      )\n                    \n                  \n                  )\n                \n                 \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{c}{\\frac {{\\partial }^{p}}{\\partial {\\omega }^{p}}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {1}{c}}\\left(p{\\frac {{\\partial }^{p-1}}{\\partial {\\omega }^{p-1}}}n\\mathrm {(} \\omega \\mathrm {)} +\\omega {\\frac {{\\partial }^{p}}{\\partial {\\omega }^{p}}}n\\mathrm {(} \\omega \\mathrm {)} \\right)\\ \\end{array}}}\n  , \n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                \u03c6\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    1\n                    c\n                  \n                \n                \n                  (\n                  \n                    p\n                    \n                      \n                        \n                          \n                            \u2202\n                          \n                          \n                            p\n                            \u2212\n                            1\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              p\n                              \u2212\n                              1\n                            \n                          \n                        \n                      \n                    \n                    \n                      \n                        O\n                        P\n                      \n                    \n                    \n                      (\n                    \n                    \u03c9\n                    \n                      )\n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \u2202\n                          \n                          \n                            p\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              p\n                            \n                          \n                        \n                      \n                    \n                    \n                      \n                        O\n                        P\n                      \n                    \n                    \n                      (\n                    \n                    \u03c9\n                    \n                      )\n                    \n                  \n                  )\n                \n              \n            \n          \n        \n        (\n        1\n        )\n      \n    \n    {\\displaystyle {\\begin{array}{c}{\\frac {{\\partial }^{p}}{\\partial {\\omega }^{p}}}\\varphi \\mathrm {(} \\omega \\mathrm {)} ={\\frac {1}{c}}\\left(p{\\frac {{\\partial }^{p-1}}{\\partial {\\omega }^{p-1}}}{\\it {OP}}\\mathrm {(} \\omega \\mathrm {)} +\\omega {\\frac {{\\partial }^{p}}{\\partial {\\omega }^{p}}}{\\it {OP}}\\mathrm {(} \\omega \\mathrm {)} \\right)\\end{array}}(1)}\n  \nThe derivatives of any differentiable function \n  \n    \n      \n        f\n        \n          (\n        \n        \u03c9\n        \n          \n            |\n          \n        \n        \u03bb\n        \n          )\n        \n      \n    \n    {\\displaystyle f\\mathrm {(} \\omega \\mathrm {|} \\lambda \\mathrm {)} }\n   in the wavelength or the frequency space is specified through a Lah transform as:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \u2202\n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                f\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u2212\n                        \n                        \n                          1\n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \u2211\n                  \n                    m\n                    =\n                    \n                      0\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      A\n                    \n                  \n                  \n                    (\n                  \n                  p\n                  ,\n                  m\n                  \n                    )\n                  \n                  \n                    \n                      \u03bb\n                    \n                    \n                      m\n                    \n                  \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          m\n                        \n                      \n                      \n                        \u2202\n                        \n                          \n                            \u03bb\n                          \n                          \n                            m\n                          \n                        \n                      \n                    \n                  \n                  f\n                  \n                    (\n                  \n                  \u03bb\n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {\\partial {p}}{\\partial {\\omega }^{p}}}f\\mathrm {(} \\omega \\mathrm {)} ={}{\\left(\\mathrm {-} \\mathrm {1} \\right)}^{p}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{p}\\sum \\limits _{m={0}}^{p}{{\\mathcal {A}}\\mathrm {(} p,m\\mathrm {)} {\\lambda }^{m}{\\frac {{\\partial }^{m}}{\\partial {\\lambda }^{m}}}f\\mathrm {(} \\lambda \\mathrm {)} }\\end{array}}}\n    \n  \n    \n      \n        ,\n      \n    \n    {\\displaystyle ,}\n     \n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                f\n                \n                  (\n                \n                \u03bb\n                \n                  )\n                \n                =\n                \n\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u2212\n                        \n                        \n                          1\n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03c9\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \u2211\n                  \n                    m\n                    =\n                    \n                      0\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      A\n                    \n                  \n                  \n                    (\n                  \n                  p\n                  ,\n                  m\n                  \n                    )\n                  \n                  \n                    \n                      \u03c9\n                    \n                    \n                      m\n                    \n                  \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          m\n                        \n                      \n                      \n                        \u2202\n                        \n                          \n                            \u03c9\n                          \n                          \n                            m\n                          \n                        \n                      \n                    \n                  \n                  f\n                  \n                    (\n                  \n                  \u03c9\n                  \n                    )\n                  \n                \n              \n            \n          \n        \n        (\n        2\n        )\n      \n    \n    {\\displaystyle {\\begin{array}{c}{\\frac {{\\partial }^{p}}{\\partial {\\lambda }^{p}}}f\\mathrm {(} \\lambda \\mathrm {)} ={}{\\left(\\mathrm {-} \\mathrm {1} \\right)}^{p}{\\left({\\frac {\\omega }{\\mathrm {2} \\pi c}}\\right)}^{p}\\sum \\limits _{m={0}}^{p}{{\\mathcal {A}}\\mathrm {(} p,m\\mathrm {)} {\\omega }^{m}{\\frac {{\\partial }^{m}}{\\partial {\\omega }^{m}}}f\\mathrm {(} \\omega \\mathrm {)} }\\end{array}}(2)}\n      \nThe matrix elements of the transformation are the Lah coefficients: \n  \n    \n      \n        \n          \n            A\n          \n        \n        \n          (\n        \n        p\n        ,\n        m\n        \n          )\n        \n        =\n        \n          \n            \n              p\n              \n                !\n              \n            \n            \n              \n                (\n                \n                  p\n                  \n                    \u2212\n                  \n                  m\n                \n                )\n              \n              \n                !\n              \n              m\n              \n                !\n              \n            \n          \n        \n        \n          \n            \n              \n                (\n              \n              p\n              \n                \u2212\n              \n              \n                1\n                )\n                !\n              \n            \n            \n              \n                (\n              \n              m\n              \n                \u2212\n              \n              \n                1\n                )\n                !\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {A}}\\mathrm {(} p,m\\mathrm {)} ={\\frac {p\\mathrm {!} }{\\left(p\\mathrm {-} m\\right)\\mathrm {!} m\\mathrm {!} }}{\\frac {\\mathrm {(} p\\mathrm {-} \\mathrm {1)!} }{\\mathrm {(} m\\mathrm {-} \\mathrm {1)!} }}}\n   \nWritten for the GDD the above expression states that a constant with wavelength GGD, will have zero higher orders. The higher orders evaluated from the GDD are:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                G\n                D\n                D\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u2212\n                        \n                        \n                          1\n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \u2211\n                  \n                    m\n                    =\n                    \n                      0\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      A\n                    \n                  \n                  \n                    (\n                  \n                  p\n                  ,\n                  m\n                  \n                    )\n                  \n                  \n                    \n                      \u03bb\n                    \n                    \n                      m\n                    \n                  \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          m\n                        \n                      \n                      \n                        \u2202\n                        \n                          \n                            \u03bb\n                          \n                          \n                            m\n                          \n                        \n                      \n                    \n                  \n                  G\n                  D\n                  D\n                  \n                    (\n                  \n                  \u03bb\n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{c}{\\frac {{\\partial }^{p}}{\\partial {\\omega }^{p}}}GDD\\mathrm {(} \\omega \\mathrm {)} ={}{\\left(\\mathrm {-} \\mathrm {1} \\right)}^{p}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{p}\\sum \\limits _{m={0}}^{p}{{\\mathcal {A}}\\mathrm {(} p,m\\mathrm {)} {\\lambda }^{m}{\\frac {{\\partial }^{m}}{\\partial {\\lambda }^{m}}}GDD\\mathrm {(} \\lambda \\mathrm {)} }\\end{array}}}\n     \n\nSubstituting equation (2) expressed for the refractive index \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   or optical path \n  \n    \n      \n        O\n        P\n      \n    \n    {\\displaystyle OP}\n   into equation (1) results in closed-form expressions for the dispersion orders. In general, the \n  \n    \n      \n        \n          p\n          \n            t\n            h\n          \n        \n      \n    \n    {\\displaystyle p^{th}}\n    order dispersion POD is a Laguerre type transform of negative order two:\n\n  \n    \n      \n        P\n        O\n        D\n        =\n        \n          \n            \n              \n                d\n                \n                  p\n                \n              \n              \u03c6\n              (\n              \u03c9\n              )\n            \n            \n              d\n              \n                \u03c9\n                \n                  p\n                \n              \n            \n          \n        \n        =\n        (\n        \u2212\n        1\n        \n          )\n          \n            p\n          \n        \n        (\n        \n          \n            \u03bb\n            \n              2\n              \u03c0\n              c\n            \n          \n        \n        \n          )\n          \n            (\n            p\n            \u2212\n            1\n            )\n          \n        \n        \n          \u2211\n          \n            m\n            =\n            0\n          \n          \n            p\n          \n        \n        \n          \n            B\n            (\n            p\n            ,\n            m\n            )\n          \n        \n        (\n        \u03bb\n        \n          )\n          \n            m\n          \n        \n        \n          \n            \n              \n                d\n                \n                  m\n                \n              \n              O\n              P\n              (\n              \u03bb\n              )\n            \n            \n              d\n              \n                \u03bb\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle POD={\\frac {d^{p}\\varphi (\\omega )}{d\\omega ^{p}}}=(-1)^{p}({\\frac {\\lambda }{2\\pi c}})^{(p-1)}\\sum _{m=0}^{p}{\\mathcal {B(p,m)}}(\\lambda )^{m}{\\frac {d^{m}OP(\\lambda )}{d\\lambda ^{m}}}}\n   \n  \n    \n      \n        ,\n      \n    \n    {\\displaystyle ,}\n     \n\n  \n    \n      \n        P\n        O\n        D\n        =\n        \n          \n            \n              \n                d\n                \n                  p\n                \n              \n              k\n              (\n              \u03c9\n              )\n            \n            \n              d\n              \n                \u03c9\n                \n                  p\n                \n              \n            \n          \n        \n        =\n        (\n        \u2212\n        1\n        \n          )\n          \n            p\n          \n        \n        (\n        \n          \n            \u03bb\n            \n              2\n              \u03c0\n              c\n            \n          \n        \n        \n          )\n          \n            (\n            p\n            \u2212\n            1\n            )\n          \n        \n        \n          \u2211\n          \n            m\n            =\n            0\n          \n          \n            p\n          \n        \n        \n          \n            B\n            (\n            p\n            ,\n            m\n            )\n          \n        \n        (\n        \u03bb\n        \n          )\n          \n            m\n          \n        \n        \n          \n            \n              \n                d\n                \n                  m\n                \n              \n              n\n              (\n              \u03bb\n              )\n            \n            \n              d\n              \n                \u03bb\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle POD={\\frac {d^{p}k(\\omega )}{d\\omega ^{p}}}=(-1)^{p}({\\frac {\\lambda }{2\\pi c}})^{(p-1)}\\sum _{m=0}^{p}{\\mathcal {B(p,m)}}(\\lambda )^{m}{\\frac {d^{m}n(\\lambda )}{d\\lambda ^{m}}}}\n         \n\n\t\nThe matrix elements of the transforms are the unsigned Laguerre coefficients of order minus 2, and are given as: \n  \n    \n      \n        \n          \n            B\n          \n        \n        \n          (\n        \n        p\n        ,\n        m\n        \n          )\n        \n        =\n        \n          \n            \n              p\n              \n                !\n              \n            \n            \n              \n                (\n                \n                  p\n                  \n                    \u2212\n                  \n                  m\n                \n                )\n              \n              \n                !\n              \n              m\n              \n                !\n              \n            \n          \n        \n        \n          \n            \n              \n                (\n              \n              p\n              \n                \u2212\n              \n              \n                2\n                )\n                !\n              \n            \n            \n              \n                (\n              \n              m\n              \n                \u2212\n              \n              \n                2\n                )\n                !\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {B}}\\mathrm {(} p,m\\mathrm {)} ={\\frac {p\\mathrm {!} }{\\left(p\\mathrm {-} m\\right)\\mathrm {!} m\\mathrm {!} }}{\\frac {\\mathrm {(} p\\mathrm {-} \\mathrm {2)!} }{\\mathrm {(} m\\mathrm {-} \\mathrm {2)!} }}}\n      \nThe first ten dispersion orders, explicitly written for the wavevector, are:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    G\n                    D\n                  \n                \n                =\n                \n                  \n                    \u2202\n                    \n                      \u2202\n                      \u03c9\n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    n\n                    \n                      (\n                    \n                    \u03c9\n                    \n                      )\n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \u2202\n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \u03c9\n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    n\n                    \n                      (\n                    \n                    \u03bb\n                    \n                      )\n                    \n                    \u2212\n                    \u03bb\n                    \n                      \n                        \n                          \u2202\n                          n\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \u03bb\n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  v\n                  \n                    g\n                    r\n                  \n                  \n                    \n                      \u2212\n                    \n                    \n                      1\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {GD}}}={\\frac {\\partial }{\\partial \\omega }}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(n\\mathrm {(} \\omega \\mathrm {)} +\\omega {\\frac {\\partial n\\mathrm {(} \\omega \\mathrm {)} }{\\partial \\omega }}\\right)={\\frac {\\mathrm {1} }{c}}\\left(n\\mathrm {(} \\lambda \\mathrm {)} -\\lambda {\\frac {\\partial n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}\\right)=v_{gr}^{\\mathrm {-} \\mathrm {1} }\\end{array}}}\n     \nThe group refractive index \n  \n    \n      \n        \n          n\n          \n            g\n          \n        \n      \n    \n    {\\displaystyle n_{g}}\n   is defined as: \n  \n    \n      \n        \n          n\n          \n            g\n          \n        \n        =\n        c\n        \n          v\n          \n            g\n            r\n          \n          \n            \n              \u2212\n            \n            \n              1\n            \n          \n        \n      \n    \n    {\\displaystyle n_{g}=cv_{gr}^{\\mathrm {-} \\mathrm {1} }}\n  .\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    G\n                    D\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        2\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      2\n                    \n                    \n                      \n                        \n                          \u2202\n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \u03c9\n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              2\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      \u03bb\n                      \n                        \n                          2\n                        \n                        \u03c0\n                        c\n                      \n                    \n                  \n                  )\n                \n                \n                  (\n                  \n                    \n                      \n                        \u03bb\n                      \n                      \n                        \n                          2\n                        \n                      \n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              2\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03bb\n                            \n                            \n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {GDD}}}={\\frac {{\\partial }^{2}}{\\partial {\\omega }^{\\mathrm {2} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {2} {\\frac {\\partial n\\mathrm {(} \\omega \\mathrm {)} }{\\partial \\omega }}+\\omega {\\frac {{\\partial }^{2}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {2} }}}\\right)={\\frac {\\mathrm {1} }{c}}\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)\\left({\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}\\right)\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    T\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        3\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      3\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              2\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              3\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                3\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  3\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {TOD}}}={\\frac {{\\partial }^{3}}{\\partial {\\omega }^{\\mathrm {3} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {3} {\\frac {{\\partial }^{2}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {2} }}}+\\omega {\\frac {{\\partial }^{3}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {3} }}}\\right)={-}{\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {2} }{\\Bigl (}\\mathrm {3} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+{\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}{\\Bigr )}\\end{array}}}\n   \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    F\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        4\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      4\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              3\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                3\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              4\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                4\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  12\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  8\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {FOD}}}={\\frac {{\\partial }^{4}}{\\partial {\\omega }^{\\mathrm {4} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {4} {\\frac {{\\partial }^{3}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {3} }}}+\\omega {\\frac {{\\partial }^{4}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {4} }}}\\right)={\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {3} }{\\Bigl (}\\mathrm {12} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {8} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+{\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}{\\Bigr )}\\end{array}}}\n     \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    F\n                    i\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        5\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      5\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              4\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                4\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              5\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                5\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  60\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  60\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  15\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {FiOD}}}={\\frac {{\\partial }^{5}}{\\partial {\\omega }^{\\mathrm {5} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {5} {\\frac {{\\partial }^{4}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {4} }}}+\\omega {\\frac {{\\partial }^{5}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {5} }}}\\right)={-}{\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {4} }{\\Bigl (}\\mathrm {60} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {60} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {15} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+{\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}{\\Bigr )}\\end{array}}}\n    \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    S\n                    i\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        6\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      6\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              5\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                5\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              6\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                6\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  360\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  480\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  180\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  24\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {SiOD}}}={\\frac {{\\partial }^{6}}{\\partial {\\omega }^{\\mathrm {6} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {6} {\\frac {{\\partial }^{5}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {5} }}}+\\omega {\\frac {{\\partial }^{6}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {6} }}}\\right)={\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {5} }{\\Bigl (}\\mathrm {360} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {480} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {180} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {24} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+{\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}{\\Bigr )}\\end{array}}}\n     \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    S\n                    e\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        7\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      7\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              6\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \n                            \u2202\n                            \u03c9\n                          \n                          \n                            \n                              6\n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              7\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \n                            \u2202\n                            \u03c9\n                          \n                          \n                            \n                              7\n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  2520\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  4200\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  2100\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  420\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  35\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {SeOD}}}={\\frac {{\\partial }^{7}}{\\partial {\\omega }^{\\mathrm {7} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {7} {\\frac {{\\partial }^{6}n\\mathrm {(} \\omega \\mathrm {)} }{{\\partial \\omega }^{\\mathrm {6} }}}+\\omega {\\frac {{\\partial }^{7}n\\mathrm {(} \\omega \\mathrm {)} }{{\\partial \\omega }^{\\mathrm {7} }}}\\right)={-}{\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {6} }{\\Bigl (}\\mathrm {2520} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {4200} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {2100} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {420} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {35} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+{\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}{\\Bigr )}\\end{array}}}\n     \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    E\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        8\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      8\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              7\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \n                            \u2202\n                            \u03c9\n                          \n                          \n                            \n                              7\n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              8\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                8\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  20160\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  40320\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  25200\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  6720\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  840\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n              \n            \n            \n              \n                +\n                \n                  48\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          8\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {EOD}}}={\\frac {{\\partial }^{8}}{\\partial {\\omega }^{\\mathrm {8} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {8} {\\frac {{\\partial }^{7}n\\mathrm {(} \\omega \\mathrm {)} }{{\\partial \\omega }^{\\mathrm {7} }}}+\\omega {\\frac {{\\partial }^{8}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {8} }}}\\right)={\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {7} }{\\Bigl (}\\mathrm {20160} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {40320} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {25200} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {6720} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {840} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+\\\\+\\mathrm {48} {\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}+{\\lambda }^{\\mathrm {8} }{\\frac {{\\partial }^{8}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {8} }}}{\\Bigr )}\\end{array}}}\n    \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    N\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        9\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            9\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      9\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              8\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                8\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              9\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                9\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  181440\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  423360\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  317520\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  105840\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  17640\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n              \n            \n            \n              \n                +\n                \n                  1512\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  63\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          8\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          9\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            9\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {NOD}}}={\\frac {{\\partial }^{9}}{\\partial {\\omega }^{\\mathrm {9} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {9} {\\frac {{\\partial }^{8}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {8} }}}+\\omega {\\frac {{\\partial }^{9}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {9} }}}\\right)={-}{\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {8} }{\\Bigl (}\\mathrm {181440} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {423360} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {317520} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {105840} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {17640} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+\\\\+\\mathrm {1512} {\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}+\\mathrm {63} {\\lambda }^{\\mathrm {8} }{\\frac {{\\partial }^{8}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {8} }}}+{\\lambda }^{\\mathrm {9} }{\\frac {{\\partial }^{9}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {9} }}}{\\Bigr )}\\end{array}}}\n          \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    T\n                    e\n                    O\n                    D\n                  \n                \n                =\n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        10\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            10\n                          \n                        \n                      \n                    \n                  \n                \n                k\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  (\n                  \n                    \n                      10\n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              9\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                9\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \u03c9\n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              10\n                            \n                          \n                          n\n                          \n                            (\n                          \n                          \u03c9\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03c9\n                            \n                            \n                              \n                                10\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      1\n                    \n                    c\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  1814400\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  4838400\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  4233600\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  1693440\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n              \n            \n            \n              \n                +\n                \n                  352800\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  40320\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  2520\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          8\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  80\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          9\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            9\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      10\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          10\n                        \n                      \n                      n\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            10\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\boldsymbol {\\it {TeOD}}}={\\frac {{\\partial }^{10}}{\\partial {\\omega }^{\\mathrm {10} }}}k\\mathrm {(} \\omega \\mathrm {)} ={\\frac {\\mathrm {1} }{c}}\\left(\\mathrm {10} {\\frac {{\\partial }^{9}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {9} }}}+\\omega {\\frac {{\\partial }^{10}n\\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {10} }}}\\right)={\\frac {\\mathrm {1} }{c}}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {9} }{\\Bigl (}\\mathrm {1814400} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {4838400} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {4233600} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+{1693440}{\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\\\+\\mathrm {352800} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+\\mathrm {40320} {\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}+\\mathrm {2520} {\\lambda }^{\\mathrm {8} }{\\frac {{\\partial }^{8}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {8} }}}+\\mathrm {80} {\\lambda }^{\\mathrm {9} }{\\frac {{\\partial }^{9}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {9} }}}+{\\lambda }^{\\mathrm {10} }{\\frac {{\\partial }^{10}n\\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {10} }}}{\\Bigr )}\\end{array}}}\n  \n\nExplicitly,  written for the phase \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n  , the first ten dispersion orders can be expressed as a function of wavelength using the Lah transforms (equation (2)) as:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \u2202\n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                f\n                \n                  (\n                \n                \u03c9\n                \n                  )\n                \n                =\n                \n\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u2212\n                        \n                        \n                          1\n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \u2211\n                  \n                    m\n                    =\n                    \n                      0\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      A\n                    \n                  \n                  \n                    (\n                  \n                  p\n                  ,\n                  m\n                  \n                    )\n                  \n                  \n                    \n                      \u03bb\n                    \n                    \n                      m\n                    \n                  \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          m\n                        \n                      \n                      \n                        \u2202\n                        \n                          \n                            \u03bb\n                          \n                          \n                            m\n                          \n                        \n                      \n                    \n                  \n                  f\n                  \n                    (\n                  \n                  \u03bb\n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {\\partial {p}}{\\partial {\\omega }^{p}}}f\\mathrm {(} \\omega \\mathrm {)} ={}{\\left(\\mathrm {-} \\mathrm {1} \\right)}^{p}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{p}\\sum \\limits _{m={0}}^{p}{{\\mathcal {A}}\\mathrm {(} p,m\\mathrm {)} {\\lambda }^{m}{\\frac {{\\partial }^{m}}{\\partial {\\lambda }^{m}}}f\\mathrm {(} \\lambda \\mathrm {)} }\\end{array}}}\n    \n  \n    \n      \n        ,\n      \n    \n    {\\displaystyle ,}\n     \n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \u2202\n                      \n                      \n                        p\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          p\n                        \n                      \n                    \n                  \n                \n                f\n                \n                  (\n                \n                \u03bb\n                \n                  )\n                \n                =\n                \n\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u2212\n                        \n                        \n                          1\n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03c9\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \u2211\n                  \n                    m\n                    =\n                    \n                      0\n                    \n                  \n                  \n                    p\n                  \n                \n                \n                  \n                    \n                      A\n                    \n                  \n                  \n                    (\n                  \n                  p\n                  ,\n                  m\n                  \n                    )\n                  \n                  \n                    \n                      \u03c9\n                    \n                    \n                      m\n                    \n                  \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          m\n                        \n                      \n                      \n                        \u2202\n                        \n                          \n                            \u03c9\n                          \n                          \n                            m\n                          \n                        \n                      \n                    \n                  \n                  f\n                  \n                    (\n                  \n                  \u03c9\n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{c}{\\frac {{\\partial }^{p}}{\\partial {\\lambda }^{p}}}f\\mathrm {(} \\lambda \\mathrm {)} ={}{\\left(\\mathrm {-} \\mathrm {1} \\right)}^{p}{\\left({\\frac {\\omega }{\\mathrm {2} \\pi c}}\\right)}^{p}\\sum \\limits _{m={0}}^{p}{{\\mathcal {A}}\\mathrm {(} p,m\\mathrm {)} {\\omega }^{m}{\\frac {{\\partial }^{m}}{\\partial {\\omega }^{m}}}f\\mathrm {(} \\omega \\mathrm {)} }\\end{array}}}\n      \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03c9\n                    \n                  \n                \n                =\n                \n                  \u2212\n                \n                \n                  (\n                  \n                    \n                      \n                        \n                          2\n                        \n                        \u03c0\n                        c\n                      \n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                =\n                \n                  \u2212\n                \n                \n                  (\n                  \n                    \n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                      \n                        \n                          2\n                        \n                        \u03c0\n                        c\n                      \n                    \n                  \n                  )\n                \n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {\\partial \\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial \\omega }}={-}\\left({\\frac {\\mathrm {2} \\pi c}{{\\omega }^{\\mathrm {2} }}}\\right){\\frac {\\partial \\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial \\lambda }}={-}\\left({\\frac {{\\lambda }^{\\mathrm {2} }}{\\mathrm {2} \\pi c}}\\right){\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \n                    \u2202\n                    \n                      \u2202\n                      \u03c9\n                    \n                  \n                \n                \n                  (\n                  \n                    \n                      \n                        \u2202\n                        \u03c6\n                        \n                          (\n                        \n                        \u03c9\n                        \n                          )\n                        \n                      \n                      \n                        \u2202\n                        \u03c9\n                      \n                    \n                  \n                  )\n                \n                =\n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  (\n                  \n                    \n                      2\n                    \n                    \u03bb\n                    \n                      \n                        \n                          \u2202\n                          \u03c6\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \u03bb\n                        \n                      \n                    \n                    +\n                    \n                      \n                        \u03bb\n                      \n                      \n                        \n                          2\n                        \n                      \n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              2\n                            \n                          \n                          \u03c6\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03bb\n                            \n                            \n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {2} }}}={\\frac {\\partial }{\\partial \\omega }}\\left({\\frac {\\partial \\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial \\omega }}\\right)={\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {2} }\\left(\\mathrm {2} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+{\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}\\right)\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  (\n                  \n                    \n                      6\n                    \n                    \u03bb\n                    \n                      \n                        \n                          \u2202\n                          \u03c6\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \u03bb\n                        \n                      \n                    \n                    +\n                    \n                      6\n                    \n                    \n                      \n                        \u03bb\n                      \n                      \n                        \n                          2\n                        \n                      \n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              2\n                            \n                          \n                          \u03c6\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03bb\n                            \n                            \n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                    \n                    +\n                    \n                      \n                        \u03bb\n                      \n                      \n                        \n                          3\n                        \n                      \n                    \n                    \n                      \n                        \n                          \n                            \n                              \u2202\n                            \n                            \n                              3\n                            \n                          \n                          \u03c6\n                          \n                            (\n                          \n                          \u03bb\n                          \n                            )\n                          \n                        \n                        \n                          \u2202\n                          \n                            \n                              \u03bb\n                            \n                            \n                              \n                                3\n                              \n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {3} }}}={-}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {3} }\\left(\\mathrm {6} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {6} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+{\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}\\right)\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  24\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  36\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  12\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {4} }}}={\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {4} }{\\Bigl (}\\mathrm {24} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {36} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {12} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+{\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}{\\Bigr )}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  120\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  240\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  120\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  20\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{\\mathrm {5} }\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {5} }}}={-}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {5} }{\\Bigl (}\\mathrm {120} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {240} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {120} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {20} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+{\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}{\\Bigr )}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  720\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  1800\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  1200\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  300\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  30\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                \n                   \n                  +\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{6}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {6} }}}={\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {6} }{\\Bigl (}\\mathrm {720} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {1800} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {1200} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {300} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {30} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}\\mathrm {\\ +} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}{\\Bigr )}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  5040\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  15120\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  12600\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  4200\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  630\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  42\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{7}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {7} }}}={-}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {7} }{\\Bigl (}\\mathrm {5040} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {15120} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {12600} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {4200} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {630} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {42} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+{\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}{\\Bigr )}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          8\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  40320\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  141120\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  141120\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  58800\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  11760\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  1176\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  56\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                +\n              \n            \n            \n              \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \u2202\n                        \n                          8\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{8}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {8} }}}={\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {8} }{\\Bigl (}\\mathrm {40320} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {141120} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {141120} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {58800} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {11760} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {1176} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+\\mathrm {56} {\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}+\\\\+{\\lambda }^{\\mathrm {8} }{\\frac {\\partial ^{8}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {8} }}}{\\Bigr )}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          9\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            9\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \u2212\n                \n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  362880\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  1451520\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  1693440\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  846720\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  211680\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  28224\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n              \n            \n            \n              \n                +\n                \n                  2016\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  72\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          8\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \u2202\n                        \n                          \n                            9\n                          \n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            9\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{9}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {9} }}}={-}{\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {9} }{\\Bigl (}\\mathrm {362880} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {1451520} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {1693440} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {846720} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {211680} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {28224} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+\\\\+\\mathrm {2016} {\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}+\\mathrm {72} {\\lambda }^{\\mathrm {8} }{\\frac {{\\partial }^{8}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {8} }}}+{\\lambda }^{\\mathrm {9} }{\\frac {\\partial ^{\\mathrm {9} }\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {9} }}}{\\Bigr )}\\end{array}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          10\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03c9\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03c9\n                        \n                        \n                          \n                            10\n                          \n                        \n                      \n                    \n                  \n                \n                =\n                \n                  \n                    \n                      (\n                      \n                        \n                          \u03bb\n                          \n                            \n                              2\n                            \n                            \u03c0\n                            c\n                          \n                        \n                      \n                      )\n                    \n                  \n                  \n                    \n                      10\n                    \n                  \n                \n                \n                  \n                    (\n                  \n                \n                \n                  3628800\n                \n                \u03bb\n                \n                  \n                    \n                      \u2202\n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \u03bb\n                    \n                  \n                \n                +\n                \n                  16329600\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          2\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  21772800\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          3\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  12700800\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          4\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            4\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  3810240\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          5\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            5\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  635040\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          6\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            6\n                          \n                        \n                      \n                    \n                  \n                \n                +\n              \n            \n            \n              \n                +\n                \n                  60480\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          7\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            7\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  3240\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          8\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            8\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  90\n                \n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          9\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            9\n                          \n                        \n                      \n                    \n                  \n                \n                +\n                \n                  \n                    \u03bb\n                  \n                  \n                    \n                      10\n                    \n                  \n                \n                \n                  \n                    \n                      \n                        \n                          \u2202\n                        \n                        \n                          10\n                        \n                      \n                      \u03c6\n                      \n                        (\n                      \n                      \u03bb\n                      \n                        )\n                      \n                    \n                    \n                      \u2202\n                      \n                        \n                          \u03bb\n                        \n                        \n                          \n                            10\n                          \n                        \n                      \n                    \n                  \n                \n                \n                  \n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{array}{l}{\\frac {{\\partial }^{10}\\varphi \\mathrm {(} \\omega \\mathrm {)} }{\\partial {\\omega }^{\\mathrm {10} }}}={\\left({\\frac {\\lambda }{\\mathrm {2} \\pi c}}\\right)}^{\\mathrm {10} }{\\Bigl (}\\mathrm {3628800} \\lambda {\\frac {\\partial \\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial \\lambda }}+\\mathrm {16329600} {\\lambda }^{\\mathrm {2} }{\\frac {{\\partial }^{2}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {2} }}}+\\mathrm {21772800} {\\lambda }^{\\mathrm {3} }{\\frac {{\\partial }^{3}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {3} }}}+\\mathrm {12700800} {\\lambda }^{\\mathrm {4} }{\\frac {{\\partial }^{4}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {4} }}}+\\mathrm {3810240} {\\lambda }^{\\mathrm {5} }{\\frac {{\\partial }^{5}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {5} }}}+\\mathrm {635040} {\\lambda }^{\\mathrm {6} }{\\frac {{\\partial }^{6}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {6} }}}+\\\\+\\mathrm {60480} {\\lambda }^{\\mathrm {7} }{\\frac {{\\partial }^{7}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {7} }}}+\\mathrm {3240} {\\lambda }^{\\mathrm {8} }{\\frac {{\\partial }^{8}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {8} }}}+\\mathrm {90} {\\lambda }^{\\mathrm {9} }{\\frac {{\\partial }^{9}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {9} }}}+{\\lambda }^{\\mathrm {10} }{\\frac {{\\partial }^{10}\\varphi \\mathrm {(} \\lambda \\mathrm {)} }{\\partial {\\lambda }^{\\mathrm {10} }}}{\\Bigr )}\\end{array}}}\n  \n\n\n== Spatial dispersion ==\n\nIn electromagnetics and optics, the term dispersion generally refers to aforementioned temporal or frequency dispersion. Spatial dispersion refers to the non-local response of the medium to the space; this can be reworded as the wavevector dependence of the permittivity. For an exemplary anisotropic medium, the spatial relation between electric and electric displacement field can be expressed as a convolution:\n\n  \n    \n      \n        \n          D\n          \n            i\n          \n        \n        (\n        t\n        ,\n        r\n        )\n        =\n        \n          E\n          \n            i\n          \n        \n        (\n        t\n        ,\n        r\n        )\n        +\n        \n          \u222b\n          \n            0\n          \n          \n            \u221e\n          \n        \n        \u222b\n        \n          f\n          \n            i\n            k\n          \n        \n        (\n        \u03c4\n        ;\n        r\n        ,\n        \n          r\n          \u2032\n        \n        )\n        \n          E\n          \n            k\n          \n        \n        (\n        t\n        \u2212\n        \u03c4\n        ,\n        \n          r\n          \u2032\n        \n        )\n        \n        d\n        \n          V\n          \u2032\n        \n        \n        d\n        \u03c4\n        ,\n      \n    \n    {\\displaystyle D_{i}(t,r)=E_{i}(t,r)+\\int _{0}^{\\infty }\\int f_{ik}(\\tau ;r,r')E_{k}(t-\\tau ,r')\\,dV'\\,d\\tau ,}\n  where the kernel \n  \n    \n      \n        \n          f\n          \n            i\n            k\n          \n        \n      \n    \n    {\\displaystyle f_{ik}}\n   is dielectric response (susceptibility); its indices make it in general a tensor to account for the anisotropy of the medium. Spatial dispersion is negligible in most macroscopic cases, where the scale of variation of \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        (\n        t\n        \u2212\n        \u03c4\n        ,\n        \n          r\n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle E_{k}(t-\\tau ,r')}\n   is much larger than atomic dimensions, because the dielectric kernel dies out at macroscopic distances. Nevertheless, it can result in non-negligible macroscopic effects, particularly in conducting media such as metals, electrolytes and plasmas. Spatial dispersion also plays role in optical activity and Doppler broadening, as well as in the theory of metamaterials.\n\n\n== In gemology ==\nIn the technical terminology of gemology, dispersion is the difference in the refractive index of a material at the B and G (686.7 nm and 430.8 nm) or C and F (656.3 nm and 486.1 nm) Fraunhofer wavelengths, and is meant to express the degree to which a prism cut from the gemstone demonstrates \"fire\".  Fire is a colloquial term used by gemologists to describe a gemstone's dispersive nature or lack thereof. Dispersion is a material property. The amount of fire demonstrated by a given gemstone is a function of the gemstone's facet angles, the polish quality, the lighting environment, the material's refractive index, the saturation of color, and the orientation of the viewer relative to the gemstone.\n\n\n== In imaging ==\nIn photographic and microscopic lenses, dispersion causes chromatic aberration, which causes the different colors in the image not to overlap properly. Various techniques have been developed to counteract this, such as the use of achromats, multielement lenses with glasses of different dispersion. They are constructed in such a way that the chromatic aberrations of the different parts cancel out.\n\n\n== Pulsar emissions ==\nPulsars are spinning neutron stars that emit pulses at very regular intervals ranging from milliseconds to seconds. Astronomers believe that the pulses are emitted simultaneously over a wide range of frequencies. However, as observed on Earth, the components of each pulse emitted at higher radio frequencies arrive before those emitted at lower frequencies. This dispersion occurs because of the ionized component of the interstellar medium, mainly the free electrons, which make the group velocity frequency-dependent. The extra delay added at a frequency \u03bd is\n\n  \n    \n      \n        t\n        =\n        \n          k\n          \n            DM\n          \n        \n        \u22c5\n        \n          (\n          \n            \n              DM\n              \n                \u03bd\n                \n                  2\n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle t=k_{\\text{DM}}\\cdot \\left({\\frac {\\text{DM}}{\\nu ^{2}}}\\right),}\n  where the dispersion constant kDM is given by\n\n  \n    \n      \n        \n          k\n          \n            DM\n          \n        \n        =\n        \n          \n            \n              e\n              \n                2\n              \n            \n            \n              2\n              \u03c0\n              \n                m\n                \n                  e\n                \n              \n              c\n            \n          \n        \n        \u2248\n        4.149\n         \n        \n          \n            GHz\n          \n          \n            2\n          \n        \n        \n        \n          \n            pc\n          \n          \n            \u2212\n            1\n          \n        \n        \n        \n          \n            cm\n          \n          \n            3\n          \n        \n        \n        \n          ms\n        \n        ,\n      \n    \n    {\\displaystyle k_{\\text{DM}}={\\frac {e^{2}}{2\\pi m_{\\text{e}}c}}\\approx 4.149~{\\text{GHz}}^{2}\\,{\\text{pc}}^{-1}\\,{\\text{cm}}^{3}\\,{\\text{ms}},}\n  and the dispersion measure (DM) is the column density of free electrons (total electron content) \u2013  i.e. the number density of electrons ne integrated along the path traveled by the photon from the pulsar to the Earth \u2013  and is given by\n\n  \n    \n      \n        \n          DM\n        \n        =\n        \n          \u222b\n          \n            0\n          \n          \n            d\n          \n        \n        \n          n\n          \n            e\n          \n        \n        \n        d\n        l\n      \n    \n    {\\displaystyle {\\text{DM}}=\\int _{0}^{d}n_{e}\\,dl}\n  with units of parsecs per cubic centimetre (1 pc/cm3 = 30.857\u00d71021 m\u22122).Typically for astronomical observations, this delay cannot be measured directly, since the emission time is unknown. What can be measured is the difference in arrival times at two different frequencies. The delay \u0394t between a high-frequency \u03bdhi and a low-frequency \u03bdlo component of a pulse will be\n\n  \n    \n      \n        \u0394\n        t\n        =\n        \n          k\n          \n            DM\n          \n        \n        \u22c5\n        \n          DM\n        \n        \u22c5\n        \n          (\n          \n            \n              \n                1\n                \n                  \u03bd\n                  \n                    lo\n                  \n                  \n                    2\n                  \n                \n              \n            \n            \u2212\n            \n              \n                1\n                \n                  \u03bd\n                  \n                    hi\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle \\Delta t=k_{\\text{DM}}\\cdot {\\text{DM}}\\cdot \\left({\\frac {1}{\\nu _{\\text{lo}}^{2}}}-{\\frac {1}{\\nu _{\\text{hi}}^{2}}}\\right).}\n  Rewriting the above equation in terms of \u0394t allows one to determine the DM by measuring pulse arrival times at multiple frequencies. This in turn can be used to study the interstellar medium, as well as allow observations of pulsars at different frequencies to be combined.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nDispersive Wiki \u2013 discussing the mathematical aspects of dispersion.\nDispersion \u2013 Encyclopedia of Laser Physics and Technology\nAnimations demonstrating optical dispersion by QED\nInteractive webdemo for chromatic dispersion Institute of Telecommunications, University of Stuttgart", "Light": "Light or visible light is electromagnetic radiation that can be perceived by the human eye. Visible light is usually defined as having wavelengths in the range of 400\u2013700 nanometres (nm), corresponding to frequencies of 750\u2013420 terahertz, between the infrared (with longer wavelengths) and the ultraviolet (with shorter wavelengths).In physics, the term \"light\" may refer more broadly to electromagnetic radiation of any wavelength, whether visible or not. In this sense, gamma rays, X-rays, microwaves and radio waves are also light. The primary properties of light are intensity, propagation direction, frequency or wavelength spectrum and polarization. Its speed in vacuum, 299792458 m/s, is one of the fundamental constants of nature. Like all types of electromagnetic radiation, visible light propagates by massless elementary particles called photons that represents the quanta of electromagnetic field, and can be analyzed as both waves and particles. The study of light, known as optics, is an important research area in modern physics.\nThe main source of natural light on Earth is the Sun.  Historically, another important source of light for humans has been fire, from ancient campfires to modern kerosene lamps. With the development of electric lights and power systems, electric lighting has effectively replaced firelight.\n\n\n== Electromagnetic spectrum and visible light ==\n\nGenerally, electromagnetic radiation (EMR)  is classified by wavelength into radio waves, microwaves, infrared, the visible spectrum that we perceive as light, ultraviolet, X-rays and gamma rays. The designation \"radiation\" excludes static electric, magnetic and near fields.\nThe behavior of EMR depends on its wavelength. Higher frequencies have shorter wavelengths and lower frequencies have longer wavelengths.  When EMR interacts with single atoms and molecules, its behavior depends on the amount of energy per quantum it carries.\nEMR in the visible light region consists of quanta (called photons) that are at the lower end of the energies that are capable of causing electronic excitation within molecules, which leads to changes in the bonding or chemistry of the molecule. At the lower end of the visible light spectrum, EMR becomes invisible to humans (infrared) because its photons no longer have enough individual energy to cause a lasting molecular change (a change in conformation) in the visual molecule retinal in the human retina, which change triggers the sensation of vision.\nThere exist animals that are sensitive to various types of infrared, but not by means of quantum-absorption. Infrared sensing in snakes depends on a kind of natural thermal imaging, in which tiny packets of cellular water are raised in temperature by the infrared radiation. EMR in this range causes molecular vibration and heating effects, which is how these animals detect it.\nAbove the range of visible light, ultraviolet light becomes invisible to humans, mostly because it is absorbed by the cornea below 360 nm and the internal lens below 400 nm. Furthermore, the rods and cones located in the retina of the human eye cannot detect the very short (below 360 nm) ultraviolet wavelengths and are in fact damaged by ultraviolet. Many animals with eyes that do not require lenses (such as insects and shrimp) are able to detect ultraviolet, by quantum photon-absorption mechanisms, in much the same chemical way that humans detect visible light.\nVarious sources define visible light as narrowly as 420\u2013680 nm to as broadly as 380\u2013800 nm. Under ideal laboratory conditions, people can see infrared up to at least 1,050 nm; children and young adults may perceive ultraviolet wavelengths down to about 310\u2013313 nm.Plant growth is also affected by the colour spectrum of light, a process known as photomorphogenesis.\n\n\n== Speed of light ==\n\nThe speed of light in vacuum is defined to be exactly 299 792 458 m/s (approx. 186,282 miles per second). The fixed value of the speed of light in SI units results from the fact that the metre is now defined in terms of the speed of light. All forms of electromagnetic radiation move at exactly this same speed in vacuum.\nDifferent physicists have attempted to measure the speed of light throughout history. Galileo attempted to measure the speed of light in the seventeenth century. An early experiment to measure the speed of light was conducted by Ole R\u00f8mer, a Danish physicist, in 1676. Using a telescope, R\u00f8mer observed the motions of Jupiter and one of its moons, Io. Noting discrepancies in the apparent period of Io's orbit, he calculated that light takes about 22 minutes to traverse the diameter of Earth's orbit. However, its size was not known at that time. If R\u00f8mer had known the diameter of the Earth's orbit, he would have calculated a speed of 227000000 m/s.\nAnother more accurate measurement of the speed of light was performed in Europe by Hippolyte Fizeau in 1849. Fizeau directed a beam of light at a mirror several kilometers away. A rotating cog wheel was placed in the path of the light beam as it traveled from the source, to the mirror and then returned to its origin.  Fizeau found that at a certain rate of rotation, the beam would pass through one gap in the wheel on the way out and the next gap on the way back. Knowing the distance to the mirror, the number of teeth on the wheel and the rate of rotation, Fizeau was able to calculate the speed of light as 313000000 m/s.\nL\u00e9on Foucault carried out an experiment which used rotating mirrors to obtain a value of 298 000 000 m/s in 1862. Albert A. Michelson conducted experiments on the speed of light from 1877 until his death in 1931. He refined Foucault's methods in 1926 using improved rotating mirrors to measure the time it took light to make a round trip from Mount Wilson to Mount San Antonio in California. The precise measurements yielded a speed of  299 796 000 m/s.The effective velocity of light in various transparent substances containing ordinary matter, is less than in vacuum. For example, the speed of light in water is about 3/4 of that in vacuum.\nTwo independent teams of physicists were said to bring light to a \"complete standstill\" by passing it through a Bose\u2013Einstein condensate of the element rubidium, one team at Harvard University and the Rowland Institute for Science in Cambridge, Massachusetts and the other at the Harvard\u2013Smithsonian Center for Astrophysics, also in Cambridge. However, the popular description of light being \"stopped\" in these experiments refers only to light being stored in the excited states of atoms, then re-emitted at an arbitrary later time, as stimulated by a second laser pulse. During the time it had \"stopped\", it had ceased to be light.\n\n\n== Optics ==\n\nThe study of light and the interaction of light and matter is termed optics. The observation and study of optical phenomena such as rainbows and the aurora borealis offer many clues as to the nature of light.\nA transparent object allows light to transmit or pass through. Conversely, an opaque object does not allow light to transmit through and instead reflecting or absorbing the light it receives. Most objects do not reflect or transmit light specularly and to some degree scatters the incoming light, which is called glossiness. Surface scatterance is caused by the surface roughness of the reflecting surfaces, and internal scatterance is caused by the difference of refractive index between the particles and medium inside the object. Like transparent objects, translucent objects allow light to transmit through, but translucent objects also scatter certain wavelength of light via internal scatterance.\n\n\n=== Refraction ===\n\nRefraction is the bending of light rays when passing through a surface between one transparent material and another. It is described by Snell's Law:\n\n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n         \n        .\n      \n    \n    {\\displaystyle n_{1}\\sin \\theta _{1}=n_{2}\\sin \\theta _{2}\\ .}\n  where \u03b81 is the angle between the ray and the surface normal in the first medium, \u03b82 is the angle between the ray and the surface normal in the second medium and n1 and n2 are the indices of refraction, n = 1 in a vacuum and n > 1 in a transparent substance.\nWhen a beam of light crosses the boundary between a vacuum and another medium, or between two different media, the wavelength of the light changes, but the frequency remains constant. If the beam of light is not orthogonal (or rather normal) to the boundary, the change in wavelength results in a change in the direction of the beam. This change of direction is known as refraction.\nThe refractive quality of lenses is frequently used to manipulate light in order to change the apparent size of images. Magnifying glasses, spectacles, contact lenses, microscopes and refracting telescopes are all examples of this manipulation.\n\n\n== Light sources ==\n\nThere are many sources of light. A body at a given temperature emits a characteristic spectrum of black-body radiation. A simple thermal source is sunlight, the radiation emitted by the chromosphere of the Sun at around 6,000 K (5,730 \u00b0C; 10,340 \u00b0F). Solar radiation peaks in the visible region of the electromagnetic spectrum when plotted in wavelength units, and roughly 44% of the radiation that reaches the ground is visible. Another example is incandescent light bulbs, which emit only around 10% of their energy as visible light and the remainder as infrared. A common thermal light source in history is the glowing solid particles in flames, but these also emit most of their radiation in the infrared and only a fraction in the visible spectrum.\nThe peak of the black-body spectrum is in the deep infrared, at about 10 micrometre wavelength, for relatively cool objects like human beings. As the temperature increases, the peak shifts to shorter wavelengths, producing first a red glow, then a white one and finally a blue-white colour as the peak moves out of the visible part of the spectrum and into the ultraviolet. These colours can be seen when metal is heated to \"red hot\" or \"white hot\". Blue-white thermal emission is not often seen, except in stars (the commonly seen pure-blue colour in a gas flame or a welder's torch is in fact due to molecular emission, notably by CH radicals emitting a wavelength band around 425 nm and is not seen in stars or pure thermal radiation).\nAtoms emit and absorb light at characteristic energies. This produces \"emission lines\" in the spectrum of each atom. Emission can be spontaneous, as in light-emitting diodes, gas discharge lamps (such as neon lamps and neon signs, mercury-vapor lamps, etc.) and flames (light from the hot gas itself\u2014so, for example, sodium in a gas flame emits characteristic yellow light). Emission can also be stimulated, as in a laser or a microwave maser.\nDeceleration of a free charged particle, such as an electron, can produce visible radiation: cyclotron radiation, synchrotron radiation and bremsstrahlung radiation are all examples of this. Particles moving through a medium faster than the speed of light in that medium can produce visible Cherenkov radiation. Certain chemicals produce visible radiation by chemoluminescence. In living things, this process is called bioluminescence. For example, fireflies produce light by this means and boats moving through water can disturb plankton which produce a glowing wake.\nCertain substances produce light when they are illuminated by more energetic radiation, a process known as fluorescence. Some substances emit light slowly after excitation by more energetic radiation. This is known as phosphorescence. Phosphorescent materials can also be excited by bombarding them with subatomic particles. Cathodoluminescence is one example. This mechanism is used in cathode-ray tube television sets and computer monitors.\n\nCertain other mechanisms can produce light:\n\nBioluminescence\nCherenkov radiation\nElectroluminescence\nScintillation\nSonoluminescence\nTriboluminescenceWhen the concept of light is intended to include very-high-energy photons (gamma rays), additional generation mechanisms include:\n\nParticle\u2013antiparticle annihilation\nRadioactive decay\n\n\n== Measurement ==\n\nLight is measured with two main alternative sets of units: radiometry consists of measurements of light power at all wavelengths, while photometry measures light with wavelength weighted with respect to a standardized model of human brightness perception.  Photometry is useful, for example, to quantify Illumination (lighting) intended for human use.\nThe photometry units are different from most systems of physical units in that they take into account how the human eye responds to light. The cone cells in the human eye are of three types which respond differently across the visible spectrum and the cumulative response peaks at a wavelength of around 555 nm. Therefore, two sources of light which produce the same intensity (W/m2) of visible light do not necessarily appear equally bright. The photometry units are designed to take this into account and therefore are a better representation of how \"bright\" a light appears to be than raw intensity. They relate to raw power by a quantity called luminous efficacy and are used for purposes like determining how to best achieve sufficient illumination for various tasks in indoor and outdoor settings. The illumination measured by a photocell sensor does not necessarily correspond to what is perceived by the human eye and without filters which may be costly, photocells and charge-coupled devices (CCD) tend to respond to some infrared, ultraviolet or both.\n\n\n== Light pressure ==\n\nLight exerts physical pressure on objects in its path, a phenomenon which can be deduced by Maxwell's equations, but can be more easily explained by the particle nature of light: photons strike and transfer their momentum. Light pressure is equal to the power of the light beam divided by c, the speed of light.  Due to the magnitude of c, the effect of light pressure is negligible for everyday objects.  For example, a one-milliwatt laser pointer exerts a force of about 3.3 piconewtons on the object being illuminated; thus, one could lift a U.S. penny with laser pointers, but doing so would require about 30 billion 1-mW laser pointers.  However, in nanometre-scale applications such as nanoelectromechanical systems (NEMS), the effect of light pressure is more significant and exploiting light pressure to drive NEMS mechanisms and to flip nanometre-scale physical switches in integrated circuits is an active area of research. At larger scales, light pressure can cause asteroids to spin faster, acting on their irregular shapes as on the vanes of a windmill.  The possibility of making solar sails that would accelerate spaceships in space is also under investigation.Although the motion of the Crookes radiometer was originally attributed to light pressure, this interpretation is incorrect; the characteristic Crookes rotation is the result of a partial vacuum. This should not be confused with the Nichols radiometer, in which the (slight) motion caused by torque (though not enough for full rotation against friction) is directly caused by light pressure.\nAs a consequence of light pressure, Einstein in 1909 predicted the existence of \"radiation friction\" which would oppose the movement of matter. He wrote, \"radiation will exert pressure on both sides of the plate. The forces of pressure exerted on the two sides are equal if the plate is at rest. However, if it is in motion, more radiation will be reflected on the surface that is ahead during the motion (front surface) than on the back surface. The backwardacting force of pressure exerted on the front surface is thus larger than the force of pressure acting on the back. Hence, as the resultant of the two forces, there remains a force that counteracts the motion of the plate and that increases with the velocity of the plate. We will call this resultant 'radiation friction' in brief.\"\nUsually light momentum is aligned with its direction of motion. However, for example in evanescent waves momentum is transverse to direction of propagation.\n\n\n== Historical theories about light, in chronological order ==\n\n\n=== Classical Greece and Hellenism ===\nIn the fifth century BC, Empedocles postulated that everything was composed of four elements; fire, air, earth and water. He believed that Aphrodite made the human eye out of the four elements and that she lit the fire in the eye which shone out from the eye making sight possible. If this were true, then one could see during the night just as well as during the day, so Empedocles postulated an interaction between rays from the eyes and rays from a source such as the sun.In about 300 BC, Euclid wrote Optica, in which he studied the properties of light. Euclid postulated that light travelled in straight lines and he described the laws of reflection and studied them mathematically. He questioned that sight is the result of a beam from the eye, for he asks how one sees the stars immediately, if one closes one's eyes, then opens them at night. If the beam from the eye travels infinitely fast this is not a problem.In 55 BC, Lucretius, a Roman who carried on the ideas of earlier Greek atomists, wrote that \"The light & heat of the sun; these are composed of minute atoms which, when they are shoved off, lose no time in shooting right across the interspace of air in the direction imparted by the shove.\" (from On the nature of the Universe). Despite being similar to later particle theories, Lucretius's views were not generally accepted. Ptolemy (c. second century) wrote about the refraction of light in his book Optics.\n\n\n=== Classical India ===\nIn ancient India, the Hindu schools of Samkhya and Vaisheshika, from around the early centuries AD developed theories on light. According to the Samkhya school, light is one of the five fundamental \"subtle\" elements (tanmatra) out of which emerge the gross elements. The atomicity of these elements is not specifically mentioned and it appears that they were actually taken to be continuous.\nOn the other hand, the Vaisheshika school gives an atomic theory of the physical world on the non-atomic ground of ether, space and time. (See Indian atomism.) The basic atoms are those of earth (prthivi), water (pani), fire (agni) and air (vayu) Light rays are taken to be a stream of high velocity of tejas (fire) atoms. The particles of light can exhibit different characteristics depending on the speed and the arrangements of the tejas atoms.\nThe Vishnu Purana refers to sunlight as \"the seven rays of the sun\".The Indian Buddhists, such as Dign\u0101ga in the fifth century and Dharmakirti in the seventh century, developed a type of atomism that is a philosophy about reality being composed of atomic entities that are momentary flashes of light or energy. They viewed light as being an atomic entity equivalent to energy.\n\n\n=== Descartes ===\nRen\u00e9 Descartes (1596\u20131650) held that light was a mechanical property of the luminous body, rejecting the \"forms\" of Ibn al-Haytham and Witelo as well as the \"species\" of Bacon, Grosseteste and Kepler. In 1637 he published a theory of the refraction of light that assumed, incorrectly, that light travelled faster in a denser medium than in a less dense medium. Descartes arrived at this conclusion by analogy with the behaviour of sound waves. Although Descartes was incorrect about the relative speeds, he was correct in assuming that light behaved like a wave and in concluding that refraction could be explained by the speed of light in different media.\nDescartes is not the first to use the mechanical analogies but because he clearly asserts that light is only a mechanical property of the luminous body and the transmitting medium, Descartes's theory of light is regarded as the start of modern physical optics.\n\n\n=== Particle theory ===\n\nPierre Gassendi (1592\u20131655), an atomist, proposed a particle theory of light which was published posthumously in the 1660s.  Isaac Newton studied Gassendi's work at an early age and preferred his view to Descartes's theory of the plenum. He stated in his Hypothesis of Light of 1675 that light was composed of corpuscles (particles of matter) which were emitted in all directions from a source. One of Newton's arguments against the wave nature of light was that waves were known to bend around obstacles, while light travelled only in straight lines. He did, however, explain the phenomenon of the diffraction of light (which had been observed by Francesco Grimaldi) by allowing that a light particle could create a localised wave in the aether.\nNewton's theory could be used to predict the reflection of light, but could only explain refraction by incorrectly assuming that light accelerated upon entering a denser medium because the gravitational pull was greater. Newton published the final version of his theory in his Opticks of 1704. His reputation helped the particle theory of light to hold sway during the eighteenth century. The particle theory of light led Laplace to argue that a body could be so massive that light could not escape from it. In other words, it would become what is now called a black hole. Laplace withdrew his suggestion later, after a wave theory of light became firmly established as the model for light (as has been explained, neither a particle or wave theory is fully correct). A translation of Newton's essay on light appears in The large scale structure of space-time, by Stephen Hawking and George F. R. Ellis.\nThe fact that light could be polarized was for the first time qualitatively explained by Newton using the particle theory. \u00c9tienne-Louis Malus in 1810 created a mathematical particle theory of polarization. Jean-Baptiste Biot in 1812 showed that this theory explained all known phenomena of light polarization. At that time the polarization was considered as the proof of the particle theory.\n\n\n=== Wave theory ===\nTo explain the origin of colours, Robert Hooke (1635\u20131703) developed a \"pulse theory\" and compared the spreading of light to that of waves in water in his 1665 work Micrographia (\"Observation IX\"). In 1672 Hooke suggested that light's vibrations could be perpendicular to the direction of propagation. Christiaan Huygens (1629\u20131695) worked out a mathematical wave theory of light in 1678 and published it in his Treatise on Light in 1690. He proposed that light was emitted in all directions as a series of waves in a medium called the luminiferous aether. As waves are not affected by gravity, it was assumed that they slowed down upon entering a denser medium.\n\nThe wave theory predicted that light waves could interfere with each other like sound waves (as noted around 1800 by Thomas Young). Young showed by means of a diffraction experiment that light behaved as waves. He also proposed that different colours were caused by different wavelengths of light and explained colour vision in terms of three-coloured receptors in the eye. Another supporter of the wave theory was Leonhard Euler. He argued in Nova theoria lucis et colorum (1746) that diffraction could more easily be explained by a wave theory. In 1816 Andr\u00e9-Marie Amp\u00e8re gave Augustin-Jean Fresnel an idea that the polarization of light can be explained by the wave theory if light were a transverse wave.Later, Fresnel independently worked out his own wave theory of light and presented it to the Acad\u00e9mie des Sciences in 1817. Sim\u00e9on Denis Poisson added to Fresnel's mathematical work to produce a convincing argument in favor of the wave theory, helping to overturn Newton's corpuscular theory. By the year 1821, Fresnel was able to show via mathematical methods that polarization could be explained by the wave theory of light if and only if light was entirely transverse, with no longitudinal vibration whatsoever.The weakness of the wave theory was that light waves, like sound waves, would need a medium for transmission. The existence of the hypothetical substance luminiferous aether proposed by Huygens in 1678 was cast into strong doubt in the late nineteenth century by the Michelson\u2013Morley experiment.\nNewton's corpuscular theory implied that light would travel faster in a denser medium, while the wave theory of Huygens and others implied the opposite. At that time, the speed of light could not be measured accurately enough to decide which theory was correct. The first to make a sufficiently accurate measurement was L\u00e9on Foucault, in 1850. His result supported the wave theory and the classical particle theory was finally abandoned, only to partly re-emerge in the twentieth century.\n\n\n=== Electromagnetic theory ===\n\nIn 1845, Michael Faraday discovered that the plane of polarization of linearly polarized light is rotated when the light rays travel along the magnetic field direction in the presence of a transparent dielectric, an effect now known as Faraday rotation. This was the first evidence that light was related to electromagnetism. In 1846 he speculated that light might be some form of disturbance propagating along magnetic field lines. Faraday proposed in 1847 that light was a high-frequency electromagnetic vibration, which could propagate even in the absence of a medium such as the ether.Faraday's work inspired James Clerk Maxwell to study electromagnetic radiation and light. Maxwell discovered that self-propagating electromagnetic waves would travel through space at a constant speed, which happened to be equal to the previously measured speed of light. From this, Maxwell concluded that light was a form of electromagnetic radiation: he first stated this result in 1862 in On Physical Lines of Force. In 1873, he published A Treatise on Electricity and Magnetism, which contained a full mathematical description of the behavior of electric and magnetic fields, still known as Maxwell's equations. Soon after, Heinrich Hertz confirmed Maxwell's theory experimentally by generating and detecting radio waves in the laboratory and demonstrating that these waves behaved exactly like visible light, exhibiting properties such as reflection, refraction, diffraction and interference. Maxwell's theory and Hertz's experiments led directly to the development of modern radio, radar, television, electromagnetic imaging and wireless communications.\nIn the quantum theory, photons are seen as wave packets of the waves described in the classical theory of Maxwell. The quantum theory was needed to explain effects even with visual light that Maxwell's classical theory could not (such as spectral lines).\n\n\n=== Quantum theory ===\nIn 1900 Max Planck, attempting to explain black-body radiation, suggested that although light was a wave, these waves could gain or lose energy only in finite amounts related to their frequency. Planck called these \"lumps\" of light energy \"quanta\" (from a Latin word for \"how much\"). In 1905, Albert Einstein used the idea of light quanta to explain the photoelectric effect and suggested that these light quanta had a \"real\" existence. In 1923 Arthur Holly Compton showed that the wavelength shift seen when low intensity X-rays scattered from electrons (so called Compton scattering) could be explained by a particle-theory of X-rays, but not a wave theory. In 1926 Gilbert N. Lewis named these light quanta particles photons.Eventually the modern theory of quantum mechanics came to picture light as (in some sense) both a particle and a wave and (in another sense), as a phenomenon which is neither a particle nor a wave (which actually are macroscopic phenomena, such as baseballs or ocean waves). Instead, modern physics sees light as something that can be described sometimes with mathematics appropriate to one type of macroscopic metaphor (particles) and sometimes another macroscopic metaphor (water waves), but is actually something that cannot be fully imagined. As in the case for radio waves and the X-rays involved in Compton scattering, physicists have noted that electromagnetic radiation tends to behave more like a classical wave at lower frequencies, but more like a classical particle at higher frequencies, but never completely loses all qualities of one or the other. Visible light, which occupies a middle ground in frequency, can easily be shown in experiments to be describable using either a wave or particle model, or sometimes both.\nIn February 2018, scientists reported, for the first time, the discovery of a new form of light, which may involve polaritons, that could be useful in the development of quantum computers.\n\n\n== Use for light on Earth ==\nSunlight provides the energy that green plants use to create sugars mostly in the form of starches, which release energy into the living things that digest them. This process of photosynthesis provides virtually all the energy used by living things. Some species of animals generate their own light, a process called bioluminescence. For example, fireflies use light to locate mates and vampire squid use it to hide themselves from prey.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n Media related to Light at Wikimedia Commons\n The dictionary definition of light at Wiktionary\n Quotations related to Light at Wikiquote", "Telescope": "A telescope is a device used to observe distant objects by their emission, absorption, or reflection of electromagnetic radiation. Originally meaning only an optical instrument using lenses, curved mirrors, or a combination of both to observe distant objects, the word telescope now refers to a wide range of instruments capable of detecting different regions of the electromagnetic spectrum, and in some cases other types of detectors.\nThe first known practical telescopes were refracting telescopes with glass lenses and were invented in the Netherlands at the beginning of the 17th century. They were used for both terrestrial applications and astronomy.\nThe reflecting telescope, which uses mirrors to collect and focus light, was invented within a few decades of the first refracting telescope.\nIn the 20th century, many new types of telescopes were invented, including radio telescopes in the 1930s and infrared telescopes in the 1960s.\n\n\n== Etymology ==\nThe word telescope was coined in 1611 by the Greek mathematician Giovanni Demisiani for one of Galileo Galilei's instruments presented at a banquet at the Accademia dei Lincei. In the Starry Messenger, Galileo had used the Latin term perspicillum. The root of the word is from the Ancient Greek \u03c4\u1fc6\u03bb\u03b5, romanized tele 'far' and \u03c3\u03ba\u03bf\u03c0\u03b5\u1fd6\u03bd, skopein 'to look or see'; \u03c4\u03b7\u03bb\u03b5\u03c3\u03ba\u03cc\u03c0\u03bf\u03c2, teleskopos 'far-seeing'.\n\n\n== History ==\n\nThe earliest existing record of a telescope was a 1608 patent submitted to the government in the Netherlands by Middelburg spectacle maker Hans Lipperhey for a refracting telescope. The actual inventor is unknown but word of it spread through Europe. Galileo heard about it and, in 1609, built his own version, and made his telescopic observations of celestial objects.The idea that the objective, or light-gathering element, could be a mirror instead of a lens was being investigated soon after the invention of the refracting telescope. The potential advantages of using parabolic mirrors\u2014reduction of spherical aberration and no chromatic aberration\u2014led to many proposed designs and several attempts to build reflecting telescopes. In 1668, Isaac Newton built the first practical reflecting telescope, of a design which now bears his name, the Newtonian reflector.The invention of the achromatic lens in 1733 partially corrected color aberrations present in the simple lens and enabled the construction of shorter, more functional refracting telescopes. Reflecting telescopes, though not limited by the color problems seen in refractors, were hampered by the use of fast tarnishing speculum metal mirrors employed during the 18th and early 19th century\u2014a problem alleviated by the introduction of silver coated glass mirrors in 1857, and aluminized mirrors in 1932. The maximum physical size limit for refracting telescopes is about 1 meter (39 inches), dictating that the vast majority of large optical researching telescopes built since the turn of the 20th century have been reflectors. The largest reflecting telescopes currently have objectives larger than 10 meters (33 feet), and work is underway on several 30-40m designs.The 20th century also saw the development of telescopes that worked in a wide range of wavelengths from radio to gamma-rays. The first purpose-built radio telescope went into operation in 1937. Since then, a large variety of complex astronomical instruments have been developed.\n\n\n== In space ==\n\nSince the atmosphere is opaque for most of the electromagnetic spectrum, only a few bands can be observed from the Earth's surface. These bands are visible \u2013 near-infrared and a portion of the radio-wave part of the spectrum. For this reason there are no X-ray or far-infrared ground-based telescopes as these have to be observed from orbit. Even if a wavelength is observable from the ground, it might still be advantageous to place a telescope on a satellite due to issues such as clouds, astronomical seeing and light pollution.The disadvantages of launching a space telescope include cost, size, maintainability and upgradability.\n\n\n== By electromagnetic spectrum ==\n\nThe name \"telescope\" covers a wide range of instruments. Most detect electromagnetic radiation, but there are major differences in how astronomers must go about collecting light (electromagnetic radiation) in different frequency bands.\nAs wavelengths become longer, it becomes easier to use antenna technology to interact with electromagnetic radiation (although it is possible to make very tiny antenna). The near-infrared can be collected much like visible light, however in the far-infrared and submillimetre range, telescopes can operate more like a radio telescope. For example, the James Clerk Maxwell Telescope observes from wavelengths from 3 \u03bcm (0.003 mm) to 2000 \u03bcm (2 mm), but uses a parabolic aluminum antenna. On the other hand, the Spitzer Space Telescope, observing from about 3 \u03bcm (0.003 mm) to 180 \u03bcm (0.18 mm) uses a mirror (reflecting optics). Also using reflecting optics, the Hubble Space Telescope with Wide Field Camera 3 can observe in the frequency range from about 0.2 \u03bcm (0.0002 mm) to 1.7 \u03bcm (0.0017 mm) (from ultra-violet to infrared light).With photons of the shorter wavelengths, with the higher frequencies, glancing-incident optics, rather than fully reflecting optics are used. Telescopes such as TRACE and SOHO use special mirrors to reflect extreme ultraviolet, producing higher resolution and brighter images than are otherwise possible. A larger aperture does not just mean that more light is collected, it also enables a finer angular resolution.\nTelescopes may also be classified by location: ground telescope, space telescope, or flying telescope. They may also be classified by whether they are operated by professional astronomers or amateur astronomers. A vehicle or permanent campus containing one or more telescopes or other instruments is called an observatory.\n\n\n=== Radio and submilimeter ===\n\nRadio telescopes are directional radio antennas that typically employ a large dish to collect radio waves. The dishes are sometimes constructed of a conductive wire mesh whose openings are smaller than the wavelength being observed.\nUnlike an optical telescope, which produces a magnified image of the patch of sky being observed, a traditional radio telescope dish contains a single receiver and records a single time-varying signal characteristic of the observed region; this signal may be sampled at various frequencies. In some newer radio telescope designs, a single dish contains an array of several receivers; this is known as a focal-plane array.\nBy collecting and correlating signals simultaneously received by several dishes, high-resolution images can be computed. Such multi-dish arrays are known as astronomical interferometers and the technique is called aperture synthesis. The 'virtual' apertures of these arrays are similar in size to the distance between the telescopes. As of 2005, the record array size is many times the diameter of the Earth \u2013 using space-based very-long-baseline-interferometry (VLBI) telescopes such as the Japanese HALCA (Highly Advanced Laboratory for Communications and Astronomy) VSOP (VLBI Space Observatory Program) satellite.Aperture synthesis is now also being applied to optical telescopes using optical interferometers (arrays of optical telescopes) and aperture masking interferometry at single reflecting telescopes.\nRadio telescopes are also used to collect microwave radiation, which has the advantage of being able to pass through the atmosphere and interstellar gas and dust clouds.\nSome radio telescopes such as the Allen Telescope Array are used by programs such as SETI and the Arecibo Observatory to search for extraterrestrial life.\n\n\n=== Infrared ===\n\n\n=== Visible light ===\n\nAn optical telescope gathers and focuses light mainly from the visible part of the electromagnetic spectrum. Optical telescopes increase the apparent angular size of distant objects as well as their apparent brightness. For the image to be observed, photographed, studied, and sent to a computer, telescopes work by employing one or more curved optical elements, usually made from glass lenses and/or mirrors, to gather light and other electromagnetic radiation to bring that light or radiation to a focal point. Optical telescopes are used for astronomy and in many non-astronomical instruments, including: theodolites (including transits), spotting scopes, monoculars, binoculars, camera lenses, and spyglasses. There are three main optical types:\n\nThe refracting telescope which uses lenses to form an image.\nThe reflecting telescope which uses an arrangement of mirrors to form an image.\nThe catadioptric telescope which uses mirrors combined with lenses to form an image.A Fresnel imager is a proposed ultra-lightweight design for a space telescope that uses a Fresnel lens to focus light.Beyond these basic optical types there are many sub-types of varying optical design classified by the task they perform such as astrographs, comet seekers and solar telescopes.\n\n\n=== Ultraviolet ===\n\nMost ultraviolet light is absorbed by the Earth's atmosphere, so observations at these wavelengths must be performed from the upper atmosphere or from space.\n\n\n=== X-ray ===\n\nX-rays are much harder to collect and focus than electromagnetic radiation of longer wavelengths. X-ray telescopes can use X-ray optics, such as Wolter telescopes composed of ring-shaped 'glancing' mirrors made of heavy metals that are able to reflect the rays just a few degrees. The mirrors are usually a section of a rotated parabola and a hyperbola, or ellipse. In 1952, Hans Wolter outlined 3 ways a telescope could be built using only this kind of mirror. Examples of space observatories using this type of telescope are the Einstein Observatory, ROSAT, and the Chandra X-ray Observatory. In 2012 the NuSTAR X-ray Telescope was launched which uses Wolter telescope design optics at the end of a long deployable mast to enable photon energies of 79 keV.\n\n\n=== Gamma ray ===\n\nHigher energy X-ray and gamma ray telescopes refrain from focusing completely and use coded aperture masks: the patterns of the shadow the mask creates can be reconstructed to form an image.\nX-ray and Gamma-ray telescopes are usually installed on high-flying balloons or Earth-orbiting satellites since the Earth's atmosphere is opaque to this part of the electromagnetic spectrum. An example of this type of telescope is the Fermi Gamma-ray Space Telescope which was launched in June 2008.The detection of very high energy gamma rays, with shorter wavelength and higher frequency than regular gamma rays, requires further specialization. An example of this type of observatory is the ground based telescope VERITAS.A discovery in 2012 may allow focusing gamma-ray telescopes. At photon energies greater than 700 keV, the index of refraction starts to increase again.\n\n\n== Lists of telescopes ==\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nElliott, Robert S. (1966), Electromagnetics, McGraw-Hill\nKing, Henry C. (1979). The history of the telescope. H. Spencer Jones. New York: Dover Publications. ISBN 0-486-23893-8. OCLC 6025190.\nPasachoff, Jay M. (1981). Contemporary astronomy (2nd ed.). Philadelphia: Saunders College Pub. ISBN 0-03-057861-2. OCLC 7734917.\nRashed, Roshdi; Morelon, R\u00e9gis (1996), Encyclopedia of the History of Arabic Science, vol. 1 & 3, Routledge, ISBN 978-0-415-12410-2\nSabra, A.I.; Hogendijk, J.P. (2003). The Enterprise of Science in Islam: New Perspectives. MIT Press. pp. 85\u2013118. ISBN 978-0-262-19482-2.\nWade, Nicholas J.; Finger, Stanley (2001), \"The eye as an optical instrument: from camera obscura to Helmholtz's perspective\", Perception, 30 (10): 1157\u20131177, doi:10.1068/p3210, PMID 11721819, S2CID 8185797\nWatson, Fred (2007). Stargazer : the life and times of the telescope. Crows Nest, NSW: Allen & Unwin. ISBN 978-1-74176-392-8. OCLC 173996168.\n\n\n== External links ==\n\nGalileo to Gamma Cephei \u2013 The History of the Telescope\nThe Galileo Project \u2013 The Telescope by Al Van Helden\n\"The First Telescopes\". Part of an exhibit from Cosmic Journey: A History of Scientific Cosmology Archived 9 April 2008 at the Wayback Machine by the American Institute of Physics\nTaylor, Harold Dennis; Gill, David (1911). \"Telescope\" . Encyclop\u00e6dia Britannica. Vol. 26 (11th ed.). pp. 557\u2013573.\nOutside the Optical: Other Kinds of Telescopes\nGray, Meghan; Merrifield, Michael (2009). \"Telescope Diameter\". Sixty Symbols. Brady Haran for the University of Nottingham.", "Magnet": "A magnet is a material or object that produces a magnetic field. This magnetic field is invisible but is responsible for the most notable property of a magnet: a force that pulls on other ferromagnetic materials, such as iron, steel, nickel, cobalt, etc. and attracts or repels other magnets. \nA permanent magnet is an object made from a material that is magnetized and creates its own persistent magnetic field. An everyday example is a refrigerator magnet used to hold notes on a refrigerator door. Materials that can be magnetized, which are also the ones that are strongly attracted to a magnet, are called ferromagnetic (or ferrimagnetic). These include the elements iron, nickel and cobalt and their alloys, some alloys of rare-earth metals, and some naturally occurring minerals such as lodestone. Although ferromagnetic (and ferrimagnetic) materials are the only ones attracted to a magnet strongly enough to be commonly considered magnetic, all other substances respond weakly to a magnetic field, by one of several other types of magnetism.\nFerromagnetic materials can be divided into magnetically \"soft\" materials like annealed iron, which can be magnetized but do not tend to stay magnetized, and magnetically \"hard\" materials, which do. Permanent magnets are made from \"hard\" ferromagnetic materials such as alnico and ferrite that are subjected to special processing in a strong magnetic field during manufacture to align their internal microcrystalline structure, making them very hard to demagnetize. To demagnetize a saturated magnet, a certain magnetic field must be applied, and this threshold depends on coercivity of the respective material. \"Hard\" materials have high coercivity, whereas \"soft\" materials have low coercivity. The overall strength of a magnet is measured by its magnetic moment or, alternatively, the total magnetic flux it produces. The local strength of magnetism in a material is measured by its magnetization.\nAn electromagnet is made from a coil of wire that acts as a magnet when an electric current passes through it but stops being a magnet when the current stops. Often, the coil is wrapped around a core of \"soft\" ferromagnetic material such as mild steel, which greatly enhances the magnetic field produced by the coil.\n\n\n== Discovery and development ==\n\nAncient people learned about magnetism from lodestones (or magnetite) which are naturally magnetized pieces of iron ore. The word magnet was adopted in Middle English from Latin magnetum \"lodestone\", ultimately from Greek \u03bc\u03b1\u03b3\u03bd\u1fc6\u03c4\u03b9\u03c2 [\u03bb\u03af\u03b8\u03bf\u03c2] (magn\u0113tis [lithos]) meaning \"[stone] from Magnesia\", a place in Anatolia where lodestones were found (today Manisa in modern-day Turkey). Lodestones, suspended so they could turn, were the first magnetic compasses. The earliest known surviving descriptions of magnets and their properties are from Anatolia, India, and China around 2500 years ago. The properties of lodestones and their affinity for iron were written of by Pliny the Elder in his encyclopedia Naturalis Historia.In the 11th century in China, it was discovered that quenching red hot iron in the Earth's magnetic field would leave the iron permanently magnetized. This led to the development of the navigational compass, as described in Dream Pool Essays in 1088. By the 12th to 13th centuries AD, magnetic compasses were used in navigation in China, Europe, the Arabian Peninsula and elsewhere.A straight iron magnet tends to demagnetize itself by its own magnetic field. To overcome this, the horseshoe magnet was invented by Daniel Bernoulli in 1743. A horseshoe magnet avoids demagnetization by returning the magnetic field lines to the opposite pole.In 1820, Hans Christian \u00d8rsted discovered that a compass needle is deflected by a nearby electric current. In the same year Andr\u00e9-Marie Amp\u00e8re showed that iron can be magnetized by inserting it in an electrically fed solenoid. This led William Sturgeon to develop an iron-cored electromagnet in 1824. Joseph Henry further developed the electromagnet into a commercial product in 1830\u20131831, giving people access to strong magnetic fields for the first time. In 1831 he built an ore separator with an electromagnet capable of lifting 750 pounds (340 kg).\n\n\n== Physics ==\n\n\n=== Magnetic field ===\n\nThe magnetic flux density (also called magnetic B field or just magnetic field, usually denoted B) is a vector field. The magnetic B field vector at a given point in space is specified by two properties:\n\nIts direction, which is along the orientation of a compass needle.\nIts magnitude (also called strength), which is proportional to how strongly the compass needle orients along that direction.In SI units, the strength of the magnetic B field is given in teslas.\n\n\n=== Magnetic moment ===\n\nA magnet's magnetic moment (also called magnetic dipole moment and usually denoted \u03bc) is a vector that characterizes the magnet's overall magnetic properties. For a bar magnet, the direction of the magnetic moment points from the magnet's south pole to its north pole, and the magnitude relates to how strong and how far apart these poles are. In SI units, the magnetic moment is specified in terms of A\u00b7m2 (amperes times meters squared).\nA magnet both produces its own magnetic field and responds to magnetic fields. The strength of the magnetic field it produces is at any given point proportional to the magnitude of its magnetic moment. In addition, when the magnet is put into an external magnetic field, produced by a different source, it is subject to a torque tending to orient the magnetic moment parallel to the field. The amount of this torque is proportional both to the magnetic moment and the external field. A magnet may also be subject to a force driving it in one direction or another, according to the positions and orientations of the magnet and source. If the field is uniform in space, the magnet is subject to no net force, although it is subject to a torque.A wire in the shape of a circle with area A and carrying current I has a magnetic moment of magnitude equal to IA.\n\n\n=== Magnetization ===\n\nThe magnetization of a magnetized material is the local value of its magnetic moment per unit volume, usually denoted M, with units A/m. It is a vector field, rather than just a vector (like the magnetic moment), because different areas in a magnet can be magnetized with different directions and strengths (for example, because of domains, see below). A good bar magnet may have a magnetic moment of magnitude 0.1 A\u00b7m2 and a volume of 1 cm3, or 1\u00d710\u22126 m3, and therefore an average magnetization magnitude is 100,000 A/m. Iron can have a magnetization of around a million amperes per meter. Such a large value explains why iron magnets are so effective at producing magnetic fields.\n\n\n=== Modelling magnets ===\n\nTwo different models exist for magnets: magnetic poles and atomic currents.\nAlthough for many purposes it is convenient to think of a magnet as having distinct north and south magnetic poles, the concept of poles should not be taken literally: it is merely a way of referring to the two different ends of a magnet. The magnet does not have distinct north or south particles on opposing sides. If a bar magnet is broken into two pieces, in an attempt to separate the north and south poles, the result will be two bar magnets, each of which has both a north and south pole. However, a version of the magnetic-pole approach is used by professional magneticians to design permanent magnets.In this approach, the divergence of the magnetization \u2207\u00b7M inside a magnet is treated as a distribution of magnetic monopoles. This is a mathematical convenience and does not imply that there are actually monopoles in the magnet. If the magnetic-pole distribution is known, then the pole model gives the magnetic field H. Outside the magnet, the field B is proportional to H, while inside the magnetization must be added to H. An extension of this method that allows for internal magnetic charges is used in theories of ferromagnetism.\nAnother model is the Amp\u00e8re model, where all magnetization is due to the effect of microscopic, or atomic, circular bound currents, also called Amp\u00e8rian currents, throughout the material. For a uniformly magnetized cylindrical bar magnet, the net effect of the microscopic bound currents is to make the magnet behave as if there is a macroscopic sheet of electric current flowing around the surface, with local flow direction normal to the cylinder axis. Microscopic currents in atoms inside the material are generally canceled by currents in neighboring atoms, so only the surface makes a net contribution; shaving off the outer layer of a magnet will not destroy its magnetic field, but will leave a new surface of uncancelled currents from the circular currents throughout the material. The right-hand rule tells which direction positively-charged current flows. However, current due to negatively-charged electricity is far more prevalent in practice.\n\n\n=== Polarity ===\nThe north pole of a magnet is defined as the pole that, when the magnet is freely suspended, points towards the Earth's North Magnetic Pole in the Arctic (the magnetic and geographic poles do not coincide, see magnetic declination). Since opposite poles (north and south) attract, the North Magnetic Pole is actually the south pole of the Earth's magnetic field. As a practical matter, to tell which pole of a magnet is north and which is south, it is not necessary to use the Earth's magnetic field at all. For example, one method would be to compare it to an electromagnet, whose poles can be identified by the right-hand rule. The magnetic field lines of a magnet are considered by convention to emerge from the magnet's north pole and reenter at the south pole.\n\n\n=== Magnetic materials ===\n\nThe term magnet is typically reserved for objects that produce their own persistent magnetic field even in the absence of an applied magnetic field. Only certain classes of materials can do this. Most materials, however, produce a magnetic field in response to an applied magnetic field \u2013 a phenomenon known as magnetism. There are several types of magnetism, and all materials exhibit at least one of them.\nThe overall magnetic behavior of a material can vary widely, depending on the structure of the material, particularly on its electron configuration. Several forms of magnetic behavior have been observed in different materials, including:\n\nFerromagnetic and ferrimagnetic materials are the ones normally thought of as magnetic; they are attracted to a magnet strongly enough that the attraction can be felt. These materials are the only ones that can retain magnetization and become magnets; a common example is a traditional refrigerator magnet. Ferrimagnetic materials, which include ferrites and the oldest magnetic materials magnetite and lodestone, are similar to but weaker than ferromagnetics. The difference between ferro- and ferrimagnetic materials is related to their microscopic structure, as explained in Magnetism.\nParamagnetic substances, such as platinum, aluminum, and oxygen, are weakly attracted to either pole of a magnet. This attraction is hundreds of thousands of times weaker than that of ferromagnetic materials, so it can only be detected by using sensitive instruments or using extremely strong magnets. Magnetic ferrofluids, although they are made of tiny ferromagnetic particles suspended in liquid, are sometimes considered paramagnetic since they cannot be magnetized.\nDiamagnetic means repelled by both poles. Compared to paramagnetic and ferromagnetic substances, diamagnetic substances, such as carbon, copper, water, and plastic, are even more weakly repelled by a magnet. The permeability of diamagnetic materials is less than the permeability of a vacuum. All substances not possessing one of the other types of magnetism are diamagnetic; this includes most substances. Although force on a diamagnetic object from an ordinary magnet is far too weak to be felt, using extremely strong superconducting magnets, diamagnetic objects such as pieces of lead and even mice can be levitated, so they float in mid-air. Superconductors repel magnetic fields from their interior and are strongly diamagnetic.There are various other types of magnetism, such as spin glass, superparamagnetism, superdiamagnetism, and metamagnetism.\n\n\n== Common uses ==\n\nMagnetic recording media: VHS tapes contain a reel of magnetic tape. The information that makes up the video and sound is encoded on the magnetic coating on the tape. Common audio cassettes also rely on magnetic tape. Similarly, in computers, floppy disks and hard disks record data on a thin magnetic coating.\nCredit, debit, and automatic teller machine cards: All of these cards have a magnetic strip on one side. This strip encodes the information to contact an individual's financial institution and connect with their account(s).\nOlder types of televisions (non flat screen) and older large computer monitors: TV and computer screens containing a cathode ray tube employ an electromagnet to guide electrons to the screen.\nSpeakers and microphones: Most speakers employ a permanent magnet and a current-carrying coil to convert electric energy (the signal) into mechanical energy (movement that creates the sound). The coil is wrapped around a bobbin attached to the speaker cone and carries the signal as changing current that interacts with the field of the permanent magnet. The voice coil feels a magnetic force and in response, moves the cone and pressurizes the neighboring air, thus generating sound. Dynamic microphones employ the same concept, but in reverse. A microphone has a diaphragm or membrane attached to a coil of wire. The coil rests inside a specially shaped magnet. When sound vibrates the membrane, the coil is vibrated as well. As the coil moves through the magnetic field, a voltage is induced across the coil. This voltage drives a current in the wire that is characteristic of the original sound.\nElectric guitars use magnetic pickups to transduce the vibration of guitar strings into electric current that can then be amplified. This is different from the principle behind the speaker and dynamic microphone because the vibrations are sensed directly by the magnet, and a diaphragm is not employed. The Hammond organ used a similar principle, with rotating tonewheels instead of strings.\nElectric motors and generators: Some electric motors rely upon a combination of an electromagnet and a permanent magnet, and, much like loudspeakers, they convert electric energy into mechanical energy. A generator is the reverse: it converts mechanical energy into electric energy by moving a conductor through a magnetic field.\nMedicine: Hospitals use magnetic resonance imaging to spot problems in a patient's organs without invasive surgery.\nChemistry: Chemists use nuclear magnetic resonance to characterize synthesized compounds.\nChucks are used in the metalworking field to hold objects. Magnets are also used in other types of fastening devices, such as the magnetic base, the magnetic clamp and the refrigerator magnet.\nCompasses: A compass (or mariner's compass) is a magnetized pointer free to align itself with a magnetic field, most commonly Earth's magnetic field.\nArt: Vinyl magnet sheets may be attached to paintings, photographs, and other ornamental articles, allowing them to be attached to refrigerators and other metal surfaces. Objects and paint can be applied directly to the magnet surface to create collage pieces of art. Metal magnetic boards, strips, doors, microwave ovens, dishwashers, cars, metal I beams, and any metal surface can be used magnetic vinyl art.\nScience projects: Many topic questions are based on magnets, including the repulsion of current-carrying wires, the effect of temperature, and motors involving magnets.\nToys: Given their ability to counteract the force of gravity at close range, magnets are often employed in children's toys, such as the Magnet Space Wheel and Levitron, to amusing effect.\nRefrigerator magnets are used to adorn kitchens, as a souvenir, or simply to hold a note or photo to the refrigerator door.\nMagnets can be used to make jewelry. Necklaces and bracelets can have a magnetic clasp, or may be constructed entirely from a linked series of magnets and ferrous beads.\nMagnets can pick up magnetic items (iron nails, staples, tacks, paper clips) that are either too small, too hard to reach, or too thin for fingers to hold. Some screwdrivers are magnetized for this purpose.\nMagnets can be used in scrap and salvage operations to separate magnetic metals (iron, cobalt, and nickel) from non-magnetic metals (aluminum, non-ferrous alloys, etc.). The same idea can be used in the so-called \"magnet test\", in which a car chassis is inspected with a magnet to detect areas repaired using fiberglass or plastic putty.\nMagnets are found in process industries, food manufacturing especially, in order to remove metal foreign bodies from materials entering the process (raw materials) or to detect a possible contamination at the end of the process and prior to packaging. They constitute an important layer of protection for the process equipment and for the final consumer.\nMagnetic levitation transport, or maglev, is a form of transportation that suspends, guides and propels vehicles (especially trains) through electromagnetic force. Eliminating rolling resistance increases efficiency. The maximum recorded speed of a maglev train is 581 kilometers per hour (361 mph).\nMagnets may be used to serve as a fail-safe device for some cable connections. For example, the power cords of some laptops are magnetic to prevent accidental damage to the port when tripped over. The MagSafe power connection to the Apple MacBook is one such example.\n\n\n== Medical issues and safety ==\nBecause human tissues have a very low level of susceptibility to static magnetic fields, there is little mainstream scientific evidence showing a health effect associated with exposure to static fields. Dynamic magnetic fields may be a different issue, however; correlations between electromagnetic radiation and cancer rates have been postulated due to demographic correlations (see Electromagnetic radiation and health).\nIf a ferromagnetic foreign body is present in human tissue, an external magnetic field interacting with it can pose a serious safety risk.A different type of indirect magnetic health risk exists involving pacemakers. If a pacemaker has been embedded in a patient's chest (usually for the purpose of monitoring and regulating the heart for steady electrically induced beats), care should be taken to keep it away from magnetic fields. It is for this reason that a patient with the device installed cannot be tested with the use of a magnetic resonance imaging device.\nChildren sometimes swallow small magnets from toys, and this can be hazardous if two or more magnets are swallowed, as the magnets can pinch or puncture internal tissues.Magnetic imaging devices (e.g. MRIs) generate enormous magnetic fields, and therefore rooms intended to hold them exclude ferrous metals. Bringing objects made of ferrous metals (such as oxygen canisters) into such a room creates a severe safety risk, as those objects may be powerfully thrown about by the intense magnetic fields.\n\n\n== Magnetizing ferromagnets ==\n\nFerromagnetic materials can be magnetized in the following ways:\n\nHeating the object higher than its Curie temperature, allowing it to cool in a magnetic field and hammering it as it cools. This is the most effective method and is similar to the industrial processes used to create permanent magnets.\nPlacing the item in an external magnetic field will result in the item retaining some of the magnetism on removal. Vibration has been shown to increase the effect. Ferrous materials aligned with the Earth's magnetic field that are subject to vibration (e.g., frame of a conveyor) have been shown to acquire significant residual magnetism. Likewise, striking a steel nail held by fingers in a N-S direction with a hammer will temporarily magnetize the nail.\nStroking: An existing magnet is moved from one end of the item to the other repeatedly in the same direction (single touch method) or two magnets are moved outwards from the center of a third (double touch method).\nElectric Current: The magnetic field produced by passing an electric current through a coil can get domains to line up. Once all of the domains are lined up, increasing the current will not increase the magnetization.\n\n\n== Demagnetizing ferromagnets ==\nMagnetized ferromagnetic materials can be demagnetized (or degaussed) in the following ways:\n\nHeating a magnet past its Curie temperature; the molecular motion destroys the alignment of the magnetic domains. This always removes all magnetization.\nPlacing the magnet in an alternating magnetic field with intensity above the material's coercivity and then either slowly drawing the magnet out or slowly decreasing the magnetic field to zero. This is the principle used in commercial demagnetizers to demagnetize tools, erase credit cards, hard disks, and degaussing coils used to demagnetize CRTs.\nSome demagnetization or reverse magnetization will occur if any part of the magnet is subjected to a reverse field above the magnetic material's coercivity.\nDemagnetization progressively occurs if the magnet is subjected to cyclic fields sufficient to move the magnet away from the linear part on the second quadrant of the B\u2013H curve of the magnetic material (the demagnetization curve).\nHammering or jarring: mechanical disturbance tends to randomize the magnetic domains and reduce magnetization of an object, but may cause unacceptable damage.\n\n\n== Types of permanent magnets ==\n\n\n=== Magnetic metallic elements ===\nMany materials have unpaired electron spins, and the majority of these materials are paramagnetic. When the spins interact with each other in such a way that the spins align spontaneously, the materials are called ferromagnetic (what is often loosely termed as magnetic). Because of the way their regular crystalline atomic structure causes their spins to interact, some metals are ferromagnetic when found in their natural states, as ores. These include iron ore (magnetite or lodestone), cobalt and nickel, as well as the rare earth metals gadolinium and dysprosium (when at a very low temperature). Such naturally occurring ferromagnets were used in the first experiments with magnetism. Technology has since expanded the availability of magnetic materials to include various man-made products, all based, however, on naturally magnetic elements.\n\n\n=== Composites ===\n\nCeramic, or ferrite, magnets are made of a sintered composite of powdered iron oxide and barium/strontium carbonate ceramic. Given the low cost of the materials and manufacturing methods, inexpensive magnets (or non-magnetized ferromagnetic cores, for use in electronic components such as portable AM radio antennas) of various shapes can be easily mass-produced. The resulting magnets are non-corroding but brittle and must be treated like other ceramics.\nAlnico magnets are made by casting or sintering a combination of aluminium, nickel and cobalt with iron and small amounts of other elements added to enhance the properties of the magnet. Sintering offers superior mechanical characteristics, whereas casting delivers higher magnetic fields and allows for the design of intricate shapes. Alnico magnets resist corrosion and have physical properties more forgiving than ferrite, but not quite as desirable as a metal. Trade names for alloys in this family include: Alni, Alcomax, Hycomax, Columax, and Ticonal.Injection-molded magnets are a composite of various types of resin and magnetic powders, allowing parts of complex shapes to be manufactured by injection molding. The physical and magnetic properties of the product depend on the raw materials, but are generally lower in magnetic strength and resemble plastics in their physical properties.\n\n\n=== Flexible magnet ===\nFlexible magnets are composed of a high-coercivity ferromagnetic compound (usually ferric oxide) mixed with a resinous polymer binder. This is extruded as a sheet and passed over a line of powerful cylindrical permanent magnets. These magnets are arranged in a stack with alternating magnetic poles facing up (N, S, N, S...) on a rotating shaft. This impresses the plastic sheet with the magnetic poles in an alternating line format. No electromagnetism is used to generate the magnets. The pole-to-pole distance is on the order of 5 mm, but varies with manufacturer. These magnets are lower in magnetic strength but can be very flexible, depending on the binder used.For magnetic compounds (e.g. Nd2Fe14B) that are vulnerable to a grain boundary corrosion problem it gives additional protection.\n\n\n=== Rare-earth magnets ===\n\nRare earth (lanthanoid) elements have a partially occupied f electron shell (which can accommodate up to 14 electrons). The spin of these electrons can be aligned, resulting in very strong magnetic fields, and therefore, these elements are used in compact high-strength magnets where their higher price is not a concern. The most common types of rare-earth magnets are samarium\u2013cobalt and neodymium\u2013iron\u2013boron (NIB) magnets.\n\n\n=== Single-molecule magnets (SMMs) and single-chain magnets (SCMs) ===\n\nIn the 1990s, it was discovered that certain molecules containing paramagnetic metal ions are capable of storing a magnetic moment at very low temperatures. These are very different from conventional magnets that store information at a magnetic domain level and theoretically could provide a far denser storage medium than conventional magnets. In this direction, research on monolayers of SMMs is currently under way. Very briefly, the two main attributes of an SMM are:\n\na large ground state spin value (S), which is provided by ferromagnetic or ferrimagnetic coupling between the paramagnetic metal centres\na negative value of the anisotropy of the zero field splitting (D)Most SMMs contain manganese but can also be found with vanadium, iron, nickel and cobalt clusters. More recently, it has been found that some chain systems can also display a magnetization that persists for long times at higher temperatures. These systems have been called single-chain magnets.\n\n\n=== Nano-structured magnets ===\nSome nano-structured materials exhibit energy waves, called magnons, that coalesce into a common ground state in the manner of a Bose\u2013Einstein condensate.\n\n\n=== Rare-earth-free permanent magnets ===\nThe United States Department of Energy has identified a need to find substitutes for rare-earth metals in permanent-magnet technology, and has begun funding such research. The Advanced Research Projects Agency-Energy (ARPA-E) has sponsored a Rare Earth Alternatives in Critical Technologies (REACT) program to develop alternative materials. In 2011, ARPA-E awarded 31.6 million dollars to fund Rare-Earth Substitute projects.\n\n\n=== Costs ===\nThe current cheapest permanent magnets, allowing for field strengths, are flexible and ceramic magnets, but these are also among the weakest types. The ferrite magnets are mainly low-cost magnets since they are made from cheap raw materials: iron oxide and Ba- or Sr-carbonate. However, a new low cost magnet, Mn\u2013Al alloy, has been developed and is now dominating the low-cost magnets field. It has a higher saturation magnetization than the ferrite magnets. It also has more favorable temperature coefficients, although it can be thermally unstable.\nNeodymium\u2013iron\u2013boron (NIB) magnets are among the strongest. These cost more per kilogram than most other magnetic materials but, owing to their intense field, are smaller and cheaper in many applications.\n\n\n=== Temperature ===\nTemperature sensitivity varies, but when a magnet is heated to a temperature known as the Curie point, it loses all of its magnetism, even after cooling below that temperature. The magnets can often be remagnetized, however.\nAdditionally, some magnets are brittle and can fracture at high temperatures.\nThe maximum usable temperature is highest for alnico magnets at over 540 \u00b0C (1,000 \u00b0F), around 300 \u00b0C (570 \u00b0F) for ferrite and SmCo, about 140 \u00b0C (280 \u00b0F) for NIB and lower for flexible ceramics, but the exact numbers depend on the grade of material.\n\n\n== Electromagnets ==\n\nAn electromagnet, in its simplest form, is a wire that has been coiled into one or more loops, known as a solenoid. When electric current flows through the wire, a magnetic field is generated. It is concentrated near (and especially inside) the coil, and its field lines are very similar to those of a magnet. The orientation of this effective magnet is determined by the right hand rule. The magnetic moment and the magnetic field of the electromagnet are proportional to the number of loops of wire, to the cross-section of each loop, and to the current passing through the wire.If the coil of wire is wrapped around a material with no special magnetic properties (e.g., cardboard), it will tend to generate a very weak field. However, if it is wrapped around a soft ferromagnetic material, such as an iron nail, then the net field produced can result in a several hundred- to thousandfold increase of field strength.\nUses for electromagnets include particle accelerators, electric motors, junkyard cranes, and magnetic resonance imaging machines. Some applications involve configurations more than a simple magnetic dipole; for example, quadrupole and sextupole magnets are used to focus particle beams.\n\n\n== Units and calculations ==\n\nFor most engineering applications, MKS (rationalized) or SI (Syst\u00e8me International) units are commonly used. Two other sets of units, Gaussian and CGS-EMU, are the same for magnetic properties and are commonly used in physics.In all units, it is convenient to employ two types of magnetic field, B and H, as well as the magnetization M, defined as the magnetic moment per unit volume.\n\nThe magnetic induction field B is given in SI units of teslas (T). B is the magnetic field whose time variation produces, by Faraday's Law, circulating electric fields (which the power companies sell). B also produces a deflection force on moving charged particles (as in TV tubes). The tesla is equivalent to the magnetic flux (in webers) per unit area (in meters squared), thus giving B the unit of a flux density. In CGS, the unit of B is the gauss (G). One tesla equals 104 G.\nThe magnetic field H is given in SI units of ampere-turns per meter (A-turn/m). The turns appear because when H is produced by a current-carrying wire, its value is proportional to the number of turns of that wire. In CGS, the unit of H is the oersted (Oe). One A-turn/m equals 4\u03c0\u00d710\u22123 Oe.\nThe magnetization M is given in SI units of amperes per meter (A/m). In CGS, the unit of M is the oersted (Oe). One A/m equals 10\u22123 emu/cm3. A good permanent magnet can have a magnetization as large as a million amperes per meter.\nIn SI units, the relation B = \u03bc0(H + M) holds, where \u03bc0 is the permeability of space, which equals 4\u03c0\u00d710\u22127 T\u2022m/A. In CGS, it is written as B = H + 4\u03c0M. (The pole approach gives \u03bc0H in SI units. A \u03bc0M term in SI must then supplement this \u03bc0H to give the correct field within B, the magnet. It will agree with the field B calculated using Amp\u00e8rian currents).Materials that are not permanent magnets usually satisfy the relation M = \u03c7H in SI, where \u03c7 is the (dimensionless) magnetic susceptibility. Most non-magnetic materials have a relatively small \u03c7 (on the order of a millionth), but soft magnets can have \u03c7 on the order of hundreds or thousands. For materials satisfying M = \u03c7H, we can also write B = \u03bc0(1 + \u03c7)H = \u03bc0\u03bcrH = \u03bcH, where \u03bcr = 1 + \u03c7 is the (dimensionless) relative permeability and \u03bc =\u03bc0\u03bcr is the magnetic permeability. Both hard and soft magnets have a more complex, history-dependent, behavior described by what are called hysteresis loops, which give either B vs. H or M vs. H. In CGS, M = \u03c7H, but \u03c7SI = 4\u03c0\u03c7CGS, and \u03bc = \u03bcr.\nCaution: in part because there are not enough Roman and Greek symbols, there is no commonly agreed-upon symbol for magnetic pole strength and magnetic moment. The symbol m has been used for both pole strength (unit A\u2022m, where here the upright m is for meter) and for magnetic moment (unit A\u2022m2). The symbol \u03bc has been used in some texts for magnetic permeability and in other texts for magnetic moment. We will use \u03bc for magnetic permeability and m for magnetic moment. For pole strength, we will employ qm. For a bar magnet of cross-section A with uniform magnetization M along its axis, the pole strength is given by qm = MA, so that M can be thought of as a pole strength per unit area.\n\n\n=== Fields of a magnet ===\n\nFar away from a magnet, the magnetic field created by that magnet is almost always described (to a good approximation) by a dipole field characterized by its total magnetic moment. This is true regardless of the shape of the magnet, so long as the magnetic moment is non-zero. One characteristic of a dipole field is that the strength of the field falls off inversely with the cube of the distance from the magnet's center.\nCloser to the magnet, the magnetic field becomes more complicated and more dependent on the detailed shape and magnetization of the magnet. Formally, the field can be expressed as a multipole expansion: A dipole field, plus a quadrupole field, plus an octupole field, etc.\nAt close range, many different fields are possible. For example, for a long, skinny bar magnet with its north pole at one end and south pole at the other, the magnetic field near either end falls off inversely with the square of the distance from that pole.\n\n\n=== Calculating the magnetic force ===\n\n\n==== Pull force of a single magnet ====\nThe strength of a given magnet is sometimes given in terms of its pull force \u2014 its ability to pull ferromagnetic objects. The pull force exerted by either an electromagnet or a permanent magnet with no air gap (i.e., the ferromagnetic object is in direct contact with the pole of the magnet) is given by the Maxwell equation:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                B\n                \n                  2\n                \n              \n              A\n            \n            \n              2\n              \n                \u03bc\n                \n                  0\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={{B^{2}A} \\over {2\\mu _{0}}}}\n  ,where\n\nF is force (SI unit: newton)\nA is the cross section of the area of the pole in square meters\nB is the magnetic induction exerted by the magnetThis result can be easily derived using Gilbert model, which assumes that the pole of magnet is charged with magnetic monopoles that induces the same in the ferromagnetic object. \nIf a magnet is acting vertically, it can lift a mass m in kilograms given by the simple equation:\n\n  \n    \n      \n        m\n        =\n        \n          \n            \n              \n                B\n                \n                  2\n                \n              \n              A\n            \n            \n              2\n              \n                \u03bc\n                \n                  0\n                \n              \n              g\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle m={{B^{2}A} \\over {2\\mu _{0}g}},}\n  where g is the gravitational acceleration.\n\n\n==== Force between two magnetic poles ====\n\nClassically, the force between two magnetic poles is given by:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \u03bc\n              \n                q\n                \n                  m\n                  1\n                \n              \n              \n                q\n                \n                  m\n                  2\n                \n              \n            \n            \n              4\n              \u03c0\n              \n                r\n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={{\\mu q_{m1}q_{m2}} \\over {4\\pi r^{2}}}}\n  where\n\nF is force (SI unit: newton)\nqm1 and qm2 are the magnitudes of magnetic poles (SI unit: ampere-meter)\n\u03bc is the permeability of the intervening medium (SI unit: tesla meter per ampere, henry per meter or newton per ampere squared)\nr is the separation (SI unit: meter).The pole description is useful to the engineers designing real-world magnets, but real magnets have a pole distribution more complex than a single north and south. Therefore, implementation of the pole idea is not simple. In some cases, one of the more complex formulae given below will be more useful.\n\n\n==== Force between two nearby magnetized surfaces of area A ====\nThe mechanical force between two nearby magnetized surfaces can be calculated with the following equation. The equation is valid only for cases in which the effect of fringing is negligible and the volume of the air gap is much smaller than that of the magnetized material:\n\n  \n    \n      \n        F\n        =\n        \n          \n            \n              \n                \u03bc\n                \n                  0\n                \n              \n              \n                H\n                \n                  2\n                \n              \n              A\n            \n            2\n          \n        \n        =\n        \n          \n            \n              \n                B\n                \n                  2\n                \n              \n              A\n            \n            \n              2\n              \n                \u03bc\n                \n                  0\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle F={\\frac {\\mu _{0}H^{2}A}{2}}={\\frac {B^{2}A}{2\\mu _{0}}}}\n  where:\n\nA is the area of each surface, in m2\nH is their magnetizing field, in A/m\n\u03bc0 is the permeability of space, which equals 4\u03c0\u00d710\u22127 T\u2022m/A\nB is the flux density, in T.\n\n\n==== Force between two bar magnets ====\nThe force between two identical cylindrical bar magnets placed end to end at large distance \n  \n    \n      \n        z\n        \u226b\n        R\n      \n    \n    {\\displaystyle z\\gg R}\n   is approximately:,\n\n  \n    \n      \n        F\n        \u2243\n        \n          [\n          \n            \n              \n                \n                  B\n                  \n                    0\n                  \n                  \n                    2\n                  \n                \n                \n                  A\n                  \n                    2\n                  \n                \n                \n                  (\n                  \n                    \n                      L\n                      \n                        2\n                      \n                    \n                    +\n                    \n                      R\n                      \n                        2\n                      \n                    \n                  \n                  )\n                \n              \n              \n                \u03c0\n                \n                  \u03bc\n                  \n                    0\n                  \n                \n                \n                  L\n                  \n                    2\n                  \n                \n              \n            \n          \n          ]\n        \n        \n          [\n          \n            \n              \n                1\n                \n                  z\n                  \n                    2\n                  \n                \n              \n            \n            +\n            \n              \n                1\n                \n                  (\n                  z\n                  +\n                  2\n                  L\n                  \n                    )\n                    \n                      2\n                    \n                  \n                \n              \n            \n            \u2212\n            \n              \n                2\n                \n                  (\n                  z\n                  +\n                  L\n                  \n                    )\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle F\\simeq \\left[{\\frac {B_{0}^{2}A^{2}\\left(L^{2}+R^{2}\\right)}{\\pi \\mu _{0}L^{2}}}\\right]\\left[{\\frac {1}{z^{2}}}+{\\frac {1}{(z+2L)^{2}}}-{\\frac {2}{(z+L)^{2}}}\\right]}\n  where:\n\nB0 is the magnetic flux density very close to each pole, in T,\nA is the area of each pole, in m2,\nL is the length of each magnet, in m,\nR is the radius of each magnet, in m, and\nz is the separation between the two magnets, in m.\n  \n    \n      \n        \n          B\n          \n            0\n          \n        \n        \n        =\n        \n        \n          \n            \n              \u03bc\n              \n                0\n              \n            \n            2\n          \n        \n        M\n      \n    \n    {\\displaystyle B_{0}\\,=\\,{\\frac {\\mu _{0}}{2}}M}\n   relates the flux density at the pole to the magnetization of the magnet.Note that all these formulations are based on Gilbert's model, which is usable in relatively great distances. In other models (e.g., Amp\u00e8re's model), a more complicated formulation is used that sometimes cannot be solved analytically. In these cases, numerical methods must be used.\n\n\n==== Force between two cylindrical magnets ====\nFor two cylindrical magnets with radius \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   and length \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  , with their magnetic dipole aligned, the force can be asymptotically approximated at large distance \n  \n    \n      \n        z\n        \u226b\n        R\n      \n    \n    {\\displaystyle z\\gg R}\n   by,\n\n  \n    \n      \n        F\n        (\n        z\n        )\n        \u2243\n        \n          \n            \n              \u03c0\n              \n                \u03bc\n                \n                  0\n                \n              \n            \n            4\n          \n        \n        \n          M\n          \n            2\n          \n        \n        \n          R\n          \n            4\n          \n        \n        \n          [\n          \n            \n              \n                1\n                \n                  z\n                  \n                    2\n                  \n                \n              \n            \n            +\n            \n              \n                1\n                \n                  (\n                  z\n                  +\n                  2\n                  L\n                  \n                    )\n                    \n                      2\n                    \n                  \n                \n              \n            \n            \u2212\n            \n              \n                2\n                \n                  (\n                  z\n                  +\n                  L\n                  \n                    )\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle F(z)\\simeq {\\frac {\\pi \\mu _{0}}{4}}M^{2}R^{4}\\left[{\\frac {1}{z^{2}}}+{\\frac {1}{(z+2L)^{2}}}-{\\frac {2}{(z+L)^{2}}}\\right]}\n  where \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is the magnetization of the magnets and \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n   is the gap between the magnets.\nA measurement of the magnetic flux density very close to the magnet \n  \n    \n      \n        \n          B\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle B_{0}}\n   is related to \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   approximately by the formula\n\n  \n    \n      \n        \n          B\n          \n            0\n          \n        \n        =\n        \n          \n            \n              \u03bc\n              \n                0\n              \n            \n            2\n          \n        \n        M\n      \n    \n    {\\displaystyle B_{0}={\\frac {\\mu _{0}}{2}}M}\n  The effective magnetic dipole can be written as\n\n  \n    \n      \n        m\n        =\n        M\n        V\n      \n    \n    {\\displaystyle m=MV}\n  Where \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the volume of the magnet. For a cylinder, this is \n  \n    \n      \n        V\n        =\n        \u03c0\n        \n          R\n          \n            2\n          \n        \n        L\n      \n    \n    {\\displaystyle V=\\pi R^{2}L}\n  .\nWhen \n  \n    \n      \n        z\n        \u226b\n        L\n      \n    \n    {\\displaystyle z\\gg L}\n  , the point dipole approximation is obtained,\n\n  \n    \n      \n        F\n        (\n        x\n        )\n        =\n        \n          \n            \n              3\n              \u03c0\n              \n                \u03bc\n                \n                  0\n                \n              \n            \n            2\n          \n        \n        \n          M\n          \n            2\n          \n        \n        \n          R\n          \n            4\n          \n        \n        \n          L\n          \n            2\n          \n        \n        \n          \n            1\n            \n              z\n              \n                4\n              \n            \n          \n        \n        =\n        \n          \n            \n              3\n              \n                \u03bc\n                \n                  0\n                \n              \n            \n            \n              2\n              \u03c0\n            \n          \n        \n        \n          M\n          \n            2\n          \n        \n        \n          V\n          \n            2\n          \n        \n        \n          \n            1\n            \n              z\n              \n                4\n              \n            \n          \n        \n        =\n        \n          \n            \n              3\n              \n                \u03bc\n                \n                  0\n                \n              \n            \n            \n              2\n              \u03c0\n            \n          \n        \n        \n          m\n          \n            1\n          \n        \n        \n          m\n          \n            2\n          \n        \n        \n          \n            1\n            \n              z\n              \n                4\n              \n            \n          \n        \n      \n    \n    {\\displaystyle F(x)={\\frac {3\\pi \\mu _{0}}{2}}M^{2}R^{4}L^{2}{\\frac {1}{z^{4}}}={\\frac {3\\mu _{0}}{2\\pi }}M^{2}V^{2}{\\frac {1}{z^{4}}}={\\frac {3\\mu _{0}}{2\\pi }}m_{1}m_{2}{\\frac {1}{z^{4}}}}\n  which matches the expression of the force between two magnetic dipoles.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\nHow magnets are made Archived 2013-03-16 at the Wayback Machine (video)\nFloating Ring Magnets, Bulletin of the IAPT, Volume 4, No. 6, 145 (June 2012). (Publication of the Indian Association of Physics Teachers).\nA brief history of electricity and magnetism", "Inertial_frame_of_reference": "In classical physics and special relativity, an inertial frame of reference  (also called inertial reference frame, inertial frame, inertial space or Galilean reference frame) is a frame of reference that has no acceleration. It is a frame in which an isolated physical object,an object with zero net force acting on it,is perceived to move with a constant velocity (it might be zero velocity) or, equivalently, it is a frame of reference in which Newton's first law of motion holds. \nAll inertial frames are in a state of constant, rectilinear motion with respect to one another; in other words, an accelerometer moving with any of them would detect zero acceleration.\nIt has been observed that celestial objects which are far away from other objects and which are in uniform motion with respect to the cosmic microwave background radiation maintain such uniform motion.Measurements in one inertial frame can be converted to measurements in another by a simple transformation the Galilean transformation in Newtonian physics and the Lorentz transformation in special relativity.In analytical mechanics, an inertial frame of reference can be defined as a frame of reference that describes time and space homogeneously, isotropically and in a time-independent manner.In general relativity \n\nin any region small enough for the curvature of spacetime and tidal forces to be negligible, one can find a set of inertial frames that approximately describes that region.<ref name=\"Giulini\"><nowiki>{{Cite book|title=Special Relativity |author= Domenico Giulini |page =19 |url=https://books.google.com/books?id=4U1bizA_0gsC&pg=PA19 |isbn=0-19-856746-4 |date=2005 |publisher=Oxford University Press}}</nowiki></ref><-->\n\nthe physics of a system can be described in terms of an inertial frame without causes external to the respective system, with the exception of an apparent effect due to so-called distant masses.In a non-inertial reference frame, viewed from a classical physics and special relativity perspective, the interactions between the fundamental constituents of the observable universe (the   physics of a system) vary depending on the acceleration of that frame with respect to an inertial frame. Viewed from this perspective and due to the phenomenon of inertia the 'usual' physical forces between two bodies have to be supplemented by apparently sourceless inertial forces. \nViewed from a general relativity theory perspective appearing inertial forces (the supplementary external causes) are attributed to geodesic motion in spacetime.\nIn classical physics, for example, a ball dropped towards the ground does not move exactly straight down because the Earth is rotating. This means the frame of reference of an observer on Earth is not inertial. As a consequence the science of physics has to take into account the Coriolis effect,an apparent force, to predict the respective small horizontal motion. Another example of an apparent force appearing in rotating reference frames that concerns the centrifugal effect, is the  centrifugal force.\n\n\n== A set of frames where the laws of physics are simple ==\nThe motion of a body can only be described relative to something else\u2014other bodies, observers, or a set of spacetime coordinates. These are called frames of reference. If the coordinates are chosen badly, the laws of motion may appear to be more complex than necessary. For example, suppose a free body that has no external forces acting on it is at rest at some instant. In many coordinate systems, it would begin to move at the next instant, even though there are no forces on it. However, a frame of reference can always be chosen in which it remains stationary. Similarly, if space is not described uniformly or time independently, a coordinate system could describe the simple flight of a free body in space as a complicated zig-zag in its coordinate system. Indeed, an intuitive summary of inertial frames can be given: in an inertial reference frame, the laws of mechanics take their simplest form.\nAccording to the first postulate of special relativity, all physical laws take their simplest form in an inertial frame, and there exist multiple inertial frames interrelated by uniform translation: Special principle of relativity: If a system of coordinates K is chosen so that, in relation to it, physical laws hold good in their simplest form, the same laws hold good in relation to any other system of coordinates K' moving in uniform translation relatively to K.\nThis simplicity manifests itself in that inertial frames have self-contained physics without the need for external causes, while physics in non-inertial frames have external causes. The principle of simplicity can be used within Newtonian physics as well as in special relativity; see Nagel and also Blagojevi\u0107.\nThe laws of Newtonian mechanics do not always hold in their simplest form...If, for instance, an observer is placed on a disc rotating relative to the earth, he/she will sense a 'force' pushing him/her toward the periphery of the disc, which is not caused by any interaction with other bodies. Here, the acceleration is not the consequence of the usual force, but of the so-called inertial force. Newton's laws hold in their simplest form only in a family of reference frames, called inertial frames. This fact represents the essence of the Galilean principle of relativity:\u2002\u2002\u2002The laws of mechanics have the same form in all inertial frames.\nIn practical terms, the equivalence of inertial reference frames means that scientists within a box moving uniformly cannot determine their absolute velocity by any experiment. Otherwise, the differences would set up an absolute standard reference frame. According to this definition, supplemented with the constancy of the speed of light, inertial frames of reference transform among themselves according to the Poincar\u00e9 group of symmetry transformations, of which the Lorentz transformations are a subgroup. In Newtonian mechanics, which can be viewed as a limiting case of special relativity in which the speed of light is infinite, inertial frames of reference are related by the Galilean group of symmetries.\n\n\n== Newton's inertial frame of reference ==\n\n\n=== Absolute space ===\n\nNewton posited an absolute space considered well approximated by a frame of reference stationary relative to the fixed stars. An inertial frame was then one in uniform translation relative to absolute space. However, some scientists (called \"relativists\" by Mach), even at the time of Newton, felt that absolute space was a defect of the formulation, and should be replaced.\nIndeed, the expression inertial frame of reference (German: Inertialsystem) was coined by Ludwig Lange in 1885, to replace Newton's definitions of \"absolute space and time\" by a more operational definition. As translated by Iro, Lange proposed the following definition:\nA reference frame in which a mass point thrown from the same point in three different (non co-planar) directions follows rectilinear paths each time it is thrown, is called an inertial frame.\nA discussion of Lange's proposal can be found in Mach.The inadequacy of the notion of \"absolute space\" in Newtonian mechanics is spelled out by Blagojevi\u0107:\n\nThe existence of absolute space contradicts the internal logic of classical mechanics since, according to the Galilean principle of relativity, none of the inertial frames can be singled out.\nAbsolute space does not explain inertial forces since they are related to acceleration with respect to any one of the inertial frames.\nAbsolute space acts on physical objects by inducing their resistance to acceleration but it cannot be acted upon.\nThe utility of operational definitions was carried much further in the special theory of relativity. Some historical background including Lange's definition is provided by DiSalle, who says in summary:\nThe original question, \"relative to what frame of reference do the laws of motion hold?\" is revealed to be wrongly posed. For the laws of motion essentially determine a class of reference frames, and (in principle) a procedure for constructing them.\n\n\n=== Newtonian mechanics ===\nClassical theories that use the Galilean transformation postulate the equivalence of all inertial reference frames. Some theories may even postulate the existence of a privileged frame which provides absolute space and absolute time. The Galilean transformation transforms coordinates from one inertial reference frame, \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n  , to another, \n  \n    \n      \n        \n          \n            s\n          \n          \n            \u2032\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {s} ^{\\prime }}\n  , by simple addition or subtraction of coordinates:\n\n  \n    \n      \n        \n          \n            r\n          \n          \n            \u2032\n          \n        \n        =\n        \n          r\n        \n        \u2212\n        \n          \n            r\n          \n          \n            0\n          \n        \n        \u2212\n        \n          v\n        \n        t\n      \n    \n    {\\displaystyle \\mathbf {r} ^{\\prime }=\\mathbf {r} -\\mathbf {r} _{0}-\\mathbf {v} t}\n  \n  \n    \n      \n        \n          t\n          \n            \u2032\n          \n        \n        =\n        t\n        \u2212\n        \n          t\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle t^{\\prime }=t-t_{0}}\n  where r0 and t0 represent shifts in the origin of space and time, and v is the relative velocity of the two inertial reference frames. Under Galilean transformations, the time t2 \u2212 t1 between two events is the same for all reference frames and the distance between two simultaneous events (or, equivalently, the length of any object, |r2 \u2212 r1|) is also the same.\n\nWithin the realm of Newtonian mechanics, an inertial frame of reference, or inertial reference frame, is one in which Newton's first law of motion is valid. However, the principle of special relativity generalizes the notion of inertial frame to include all physical laws, not simply Newton's first law.\nNewton viewed the first law as valid in any reference frame that is in uniform motion relative to the fixed stars; that is, neither rotating nor accelerating relative to the stars. Today the notion of \"absolute space\" is abandoned, and an inertial frame in the field of classical mechanics is defined as:\nAn inertial frame of reference is one in which the motion of a particle not subject to forces is in a straight line at constant speed.\nHence, with respect to an inertial frame, an object or body accelerates only when a physical force is applied, and (following Newton's first law of motion), in the absence of a net force, a body at rest will remain at rest and a body in motion will continue to move uniformly\u2014that is, in a straight line and at constant speed. Newtonian inertial frames transform among each other according to the Galilean group of symmetries.\nIf this rule is interpreted as saying that straight-line motion is an indication of zero net force, the rule does not identify inertial reference frames because straight-line motion can be observed in a variety of frames. If the rule is interpreted as defining an inertial frame, then we have to be able to determine when zero net force is applied. The problem was summarized by Einstein:\nThe weakness of the principle of inertia lies in this, that it involves an argument in a circle: a mass moves without acceleration if it is sufficiently far from other bodies; we know that it is sufficiently far from other bodies only by the fact that it moves without acceleration.\nThere are several approaches to this issue. One approach is to argue that all real forces drop off with distance from their sources in a known manner, so we have only to be sure that a body is far enough away from all sources to ensure that no force is present. A possible issue with this approach is the historically long-lived view that the distant universe might affect matters (Mach's principle). Another approach is to identify all real sources for real forces and account for them. A possible issue with this approach is that we might miss something, or account inappropriately for their influence, perhaps, again, due to Mach's principle and an incomplete understanding of the universe. A third approach is to look at the way the forces transform when we shift reference frames. Fictitious forces, those that arise due to the acceleration of a frame, disappear in inertial frames, and have complicated rules of transformation in general cases. On the basis of universality of physical law and the request for frames where the laws are most simply expressed, inertial frames are distinguished by the absence of such fictitious forces.\n\nNewton enunciated a principle of relativity himself in one of his corollaries to the laws of motion: The motions of bodies included in a given space are the same among themselves, whether that space is at rest or moves uniformly forward in a straight line.\nThis principle differs from the special principle in two ways: first, it is restricted to mechanics, and second, it makes no mention of simplicity. It shares with the special principle the invariance of the form of the description among mutually translating reference frames. The role of fictitious forces in classifying reference frames is pursued further below.\n\n\n=== Remarks ===\n\nIt is important to note some assumptions made above about the various inertial frames of reference. Newton, for instance, employed universal time, as explained by the following example. Suppose that you own two clocks, which both tick at exactly the same rate. You synchronize them so that they both display exactly the same time. The two clocks are now separated and one clock is on a fast moving train, traveling at constant velocity towards the other. According to Newton, these two clocks will still tick at the same rate and will both show the same time. Newton says that the rate of time as measured in one frame of reference should be the same as the rate of time in another. That is, there exists a \"universal\" time and all other times in all other frames of reference will run at the same rate as this universal time irrespective of their position and velocity. This concept of time and simultaneity was later generalized by Einstein in his special theory of relativity (1905) where he developed transformations between inertial frames of reference based upon the universal nature of physical laws and their economy of expression (Lorentz transformations).\nFrames of reference are especially important in special relativity, because when a frame of reference is moving at some significant fraction of the speed of light, then the flow of time in that frame does not necessarily apply in another frame. The speed of light is considered to be the only true constant between moving frames of reference.\nThe definition of inertial reference frame can also be extended beyond three-dimensional Euclidean space. Newton's assumed a Euclidean space, but general relativity uses a more general geometry. As an example of why this is important, consider the geometry of an ellipsoid. In this geometry, a \"free\" particle is defined as one at rest or traveling at constant speed on a geodesic path. Two free particles may begin at the same point on the surface, traveling with the same constant speed in different directions. After a length of time, the two particles collide on the opposite side of the ellipsoid. Both \"free\" particles traveled with a constant speed, satisfying the definition that no forces were acting. No acceleration occurred and so Newton's first law held true. This means that the particles were in inertial frames of reference. Since no forces were acting, it was the geometry of the situation which caused the two particles to meet each other again. In a similar way, it is now common to describe that we exist in a four-dimensional geometry known as spacetime. In this picture, the curvature of this 4D space is responsible for the way in which two bodies with mass are drawn together even if no forces are acting. This curvature of spacetime replaces the force known as gravity in Newtonian mechanics and special relativity.\n\n\n== Special relativity ==\n\nEinstein's theory of special relativity, like Newtonian mechanics, postulates the equivalence of all inertial reference frames. However, because special relativity postulates that the speed of light in free space is invariant, the transformation between inertial frames is the Lorentz transformation, not the Galilean transformation which is used in Newtonian mechanics. The invariance of the speed of light leads to counter-intuitive phenomena, such as time dilation and length contraction, and the relativity of simultaneity, which have been extensively verified experimentally. The Lorentz transformation reduces to the Galilean transformation as the speed of light approaches infinity or as the relative velocity between frames approaches zero.\n\n\n== Non-inertial frames ==\n\nHere the relation between inertial and non-inertial observational frames of reference is considered. The basic difference between these frames is the need in non-inertial frames for fictitious forces, as described below.\n\n\n=== General relativity ===\n\nGeneral relativity is based upon the principle of equivalence:There is no experiment observers can perform to distinguish whether an acceleration arises because of a gravitational force or because their reference frame is accelerating.\nThis idea was introduced in Einstein's 1907 article \"Principle of Relativity and Gravitation\" and later developed in 1911. Support for this principle is found in the E\u00f6tv\u00f6s experiment, which determines whether the ratio of inertial to gravitational mass is the same for all bodies, regardless of size or composition. To date no difference has been found to a few parts in 1011. For some discussion of the subtleties of the E\u00f6tv\u00f6s experiment, such as the local mass distribution around the experimental site (including a quip about the mass of E\u00f6tv\u00f6s himself), see Franklin.Einstein's general theory modifies the distinction between nominally \"inertial\" and \"non-inertial\" effects by replacing special relativity's \"flat\" Minkowski Space with a metric that produces non-zero curvature. In general relativity, the principle of inertia is replaced with the principle of geodesic motion, whereby objects move in a way dictated by the curvature of spacetime. As a consequence of this curvature, it is not a given in general relativity that inertial objects moving at a particular rate with respect to each other will continue to do so. This phenomenon of geodesic deviation means that inertial frames of reference do not exist globally as they do in Newtonian mechanics and special relativity.\nHowever, the general theory reduces to the special theory over sufficiently small regions of spacetime, where curvature effects become less important and the earlier inertial frame arguments can come back into play. Consequently, modern special relativity is now sometimes described as only a \"local theory\". \"Local\" can encompass, for example, the entire Milky Way galaxy: The astronomer Karl Schwarzschild observed the motion of pairs of stars orbiting each other. He found that the two orbits of the stars of such a system lie in a plane, and the perihelion of the orbits of the two stars remains pointing in the same direction with respect to the solar system. Schwarzschild pointed out that that was invariably seen: the direction of the angular momentum of all observed double star systems remains fixed with respect to the direction of the angular momentum of the Solar System. These observations allowed him to conclude that inertial frames inside the galaxy do not rotate with respect to one another, and that the space of the Milky Way is approximately Galilean or Minkowskian.\n\n\n=== Inertial frames and rotation ===\nIn an inertial frame, Newton's first law, the law of inertia, is satisfied: Any free motion has a constant magnitude and direction. Newton's second law for a particle takes the form:\n\n  \n    \n      \n        \n          F\n        \n        =\n        m\n        \n          a\n        \n         \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =m\\mathbf {a} \\ ,}\n  with F the net force (a vector), m the mass of a particle and a the acceleration of the particle (also a vector) which would be measured by an observer at rest in the frame. The force F is the vector sum of all \"real\" forces on the particle, such as contact forces, electromagnetic, gravitational, and nuclear forces.\nIn contrast, Newton's second law in a rotating frame of reference (a non-inertial frame of reference), rotating at angular rate \u03a9 about an axis, takes the form:\n\n  \n    \n      \n        \n          \n            F\n          \n          \u2032\n        \n        =\n        m\n        \n          a\n        \n         \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} '=m\\mathbf {a} \\ ,}\n  which looks the same as in an inertial frame, but now the force F\u2032 is the resultant of not only F, but also additional terms (the paragraph following this equation presents the main points without detailed mathematics):\n\n  \n    \n      \n        \n          \n            F\n          \n          \u2032\n        \n        =\n        \n          F\n        \n        \u2212\n        2\n        m\n        \n          \u03a9\n        \n        \u00d7\n        \n          \n            v\n          \n          \n            B\n          \n        \n        \u2212\n        m\n        \n          \u03a9\n        \n        \u00d7\n        (\n        \n          \u03a9\n        \n        \u00d7\n        \n          \n            x\n          \n          \n            B\n          \n        \n        )\n        \u2212\n        m\n        \n          \n            \n              d\n              \n                \u03a9\n              \n            \n            \n              d\n              t\n            \n          \n        \n        \u00d7\n        \n          \n            x\n          \n          \n            B\n          \n        \n         \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} '=\\mathbf {F} -2m\\mathbf {\\Omega } \\times \\mathbf {v} _{B}-m\\mathbf {\\Omega } \\times (\\mathbf {\\Omega } \\times \\mathbf {x} _{B})-m{\\frac {d\\mathbf {\\Omega } }{dt}}\\times \\mathbf {x} _{B}\\ ,}\n  where the angular rotation of the frame is expressed by the vector \u03a9 pointing in the direction of the axis of rotation, and with magnitude equal to the angular rate of rotation \u03a9, symbol \u00d7 denotes the vector cross product, vector xB locates the body and vector vB is the velocity of the body according to a rotating observer (different from the velocity seen by the inertial observer).\nThe extra terms in the force F\u2032 are the \"fictitious\" forces for this frame, whose causes are external to the system in the frame. The first extra term is the Coriolis force, the second the centrifugal force, and the third the Euler force. These terms all have these properties: they vanish when \u03a9 = 0; that is, they are zero for an inertial frame (which, of course, does not rotate); they take on a different magnitude and direction in every rotating frame, depending upon its particular value of \u03a9; they are ubiquitous in the rotating frame (affect every particle, regardless of circumstance); and they have no apparent source in identifiable physical sources, in particular, matter. Also, fictitious forces do not drop off with distance (unlike, for example, nuclear forces or electrical forces). For example, the centrifugal force that appears to emanate from the axis of rotation in a rotating frame increases with distance from the axis.\nAll observers agree on the real forces, F; only non-inertial observers need fictitious forces. The laws of physics in the inertial frame are simpler because unnecessary forces are not present.\nIn Newton's time the fixed stars were invoked as a reference frame, supposedly at rest relative to absolute space. In reference frames that were either at rest with respect to the fixed stars or in uniform translation relative to these stars, Newton's laws of motion were supposed to hold. In contrast, in frames accelerating with respect to the fixed stars, an important case being frames rotating relative to the fixed stars, the laws of motion did not hold in their simplest form, but had to be supplemented by the addition of fictitious forces, for example, the Coriolis force and the centrifugal force. Two experiments were devised by Newton to demonstrate how these forces could be discovered, thereby revealing to an observer that they were not in an inertial frame: the example of the tension in the cord linking two spheres rotating about their center of gravity, and the example of the curvature of the surface of water in a rotating bucket. In both cases, application of Newton's second law would not work for the rotating observer without invoking centrifugal and Coriolis forces to account for their observations (tension in the case of the spheres; parabolic water surface in the case of the rotating bucket).\nAs we now know, the fixed stars are not fixed. Those that reside in the Milky Way turn with the galaxy, exhibiting proper motions. Those that are outside our galaxy (such as nebulae once mistaken to be stars) participate in their own motion as well, partly due to expansion of the universe, and partly due to peculiar velocities. For instance, the Andromeda Galaxy is on collision course with the Milky Way at a speed of 117 km/s. The concept of inertial frames of reference is no longer tied to either the fixed stars or to absolute space. Rather, the identification of an inertial frame is based on the simplicity of the laws of physics in the frame. \nJohn Stachel wrote: once one gave up the existence of a privileged frame of reference (the ether frame) there was no reason why one should stop at the relativity of inertial frames. The conventional answer to such doubts was that the laws of nature took a simpler form in the inertial frames of reference because in these frames one did not have to introduce inertial forces when writing down Newton's law of motion. \nIn practice, although not a requirement, using a frame of reference based upon the fixed stars as though it were an inertial frame of reference introduces very little discrepancy. For example, the centrifugal acceleration of the Earth because of its rotation about the Sun is about thirty million times greater than that of the Sun about the galactic center.To illustrate further, consider the question: \"Does our Universe rotate?\" To answer, we might attempt to explain the shape of the Milky Way galaxy using the laws of physics, although other observations might be more definitive; that is, provide larger discrepancies or less measurement uncertainty, like the anisotropy of the microwave background radiation or Big Bang nucleosynthesis. The flatness of the Milky Way depends on its rate of rotation in an inertial frame of reference. If we attribute its apparent rate of rotation entirely to rotation in an inertial frame, a different \"flatness\" is predicted than if we suppose part of this rotation actually is due to rotation of the universe and should not be included in the rotation of the galaxy itself. Based upon the laws of physics, a model is set up in which one parameter is the rate of rotation of the Universe. If the laws of physics agree more accurately with observations in a model with rotation than without it, we are inclined to select the best-fit value for rotation, subject to all other pertinent experimental observations. If no value of the rotation parameter is successful and theory is not within observational error, a modification of physical law is considered, for example, dark matter is invoked to explain the galactic rotation curve. So far, observations show any rotation of the universe is very slow, no faster than once every 6\u00d71013 years (10\u221213 rad/yr), and debate persists over whether there is any rotation. However, if rotation were found, interpretation of observations in a frame tied to the universe would have to be corrected for the fictitious forces inherent in such rotation in classical physics and special relativity, or interpreted as the curvature of spacetime and the motion of matter along the geodesics in general relativity.When quantum effects are important, there are additional conceptual complications that arise in quantum reference frames.\n\n\n=== Primed frames ===\nAn accelerated frame of reference is often delineated as being the \"primed\" frame, and all variables that are dependent on that frame are notated with primes, e.g. x\u2032, y\u2032, a\u2032.\nThe vector from the origin of an inertial reference frame to the origin of an accelerated reference frame is commonly notated as R. Given a point of interest that exists in both frames, the vector from the inertial origin to the point is called r, and the vector from the accelerated origin to the point is called r\u2032.\nFrom the geometry of the situation, we get\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          R\n        \n        +\n        \n          \n            r\n          \n          \u2032\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {r} =\\mathbf {R} +\\mathbf {r} '.}\n  Taking the first and second derivatives of this with respect to time, we obtain\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          V\n        \n        +\n        \n          \n            v\n          \n          \u2032\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} =\\mathbf {V} +\\mathbf {v} ',}\n  \n\n  \n    \n      \n        \n          a\n        \n        =\n        \n          A\n        \n        +\n        \n          \n            a\n          \n          \u2032\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {a} =\\mathbf {A} +\\mathbf {a} '.}\n  where V and A are the velocity and acceleration of the accelerated system with respect to the inertial system and v and a are the velocity and acceleration of the point of interest with respect to the inertial frame.\nThese equations allow transformations between the two coordinate systems; for example, we can now write Newton's second law as\n\n  \n    \n      \n        \n          F\n        \n        =\n        m\n        \n          a\n        \n        =\n        m\n        \n          A\n        \n        +\n        m\n        \n          \n            a\n          \n          \u2032\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {F} =m\\mathbf {a} =m\\mathbf {A} +m\\mathbf {a} '.}\n  When there is accelerated motion due to a force being exerted there is manifestation of inertia. If an electric car designed to recharge its battery system when decelerating is switched to braking, the batteries are recharged, illustrating the physical strength of manifestation of inertia. However, the manifestation of inertia does not prevent acceleration (or deceleration), for manifestation of inertia occurs in response to change in velocity due to a force. Seen from the perspective of a rotating frame of reference the manifestation of inertia appears to exert a force (either in centrifugal direction, or in a direction orthogonal to an object's motion, the Coriolis effect).\nA common sort of accelerated reference frame is a frame that is both rotating and translating (an example is a frame of reference attached to a CD which is playing while the player is carried). This arrangement leads to the equation (see Fictitious force for a derivation):\n\n  \n    \n      \n        \n          a\n        \n        =\n        \n          \n            a\n          \n          \u2032\n        \n        +\n        \n          \n            \n              \u03c9\n              \u02d9\n            \n          \n        \n        \u00d7\n        \n          \n            r\n          \n          \u2032\n        \n        +\n        2\n        \n          \u03c9\n        \n        \u00d7\n        \n          \n            v\n          \n          \u2032\n        \n        +\n        \n          \u03c9\n        \n        \u00d7\n        (\n        \n          \u03c9\n        \n        \u00d7\n        \n          \n            r\n          \n          \u2032\n        \n        )\n        +\n        \n          \n            A\n          \n          \n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {a} =\\mathbf {a} '+{\\dot {\\boldsymbol {\\omega }}}\\times \\mathbf {r} '+2{\\boldsymbol {\\omega }}\\times \\mathbf {v} '+{\\boldsymbol {\\omega }}\\times ({\\boldsymbol {\\omega }}\\times \\mathbf {r} ')+\\mathbf {A} _{0},}\n  or, to solve for the acceleration in the accelerated frame,\n\n  \n    \n      \n        \n          \n            a\n          \n          \u2032\n        \n        =\n        \n          a\n        \n        \u2212\n        \n          \n            \n              \u03c9\n              \u02d9\n            \n          \n        \n        \u00d7\n        \n          \n            r\n          \n          \u2032\n        \n        \u2212\n        2\n        \n          \u03c9\n        \n        \u00d7\n        \n          \n            v\n          \n          \u2032\n        \n        \u2212\n        \n          \u03c9\n        \n        \u00d7\n        (\n        \n          \u03c9\n        \n        \u00d7\n        \n          \n            r\n          \n          \u2032\n        \n        )\n        \u2212\n        \n          \n            A\n          \n          \n            0\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {a} '=\\mathbf {a} -{\\dot {\\boldsymbol {\\omega }}}\\times \\mathbf {r} '-2{\\boldsymbol {\\omega }}\\times \\mathbf {v} '-{\\boldsymbol {\\omega }}\\times ({\\boldsymbol {\\omega }}\\times \\mathbf {r} ')-\\mathbf {A} _{0}.}\n  Multiplying through by the mass m gives\n\n  \n    \n      \n        \n          \n            F\n          \n          \u2032\n        \n        =\n        \n          \n            F\n          \n          \n            \n              p\n              h\n              y\n              s\n              i\n              c\n              a\n              l\n            \n          \n        \n        +\n        \n          \n            F\n          \n          \n            \n              E\n              u\n              l\n              e\n              r\n            \n          \n          \u2032\n        \n        +\n        \n          \n            F\n          \n          \n            \n              C\n              o\n              r\n              i\n              o\n              l\n              i\n              s\n            \n          \n          \u2032\n        \n        +\n        \n          \n            F\n          \n          \n            \n              c\n              e\n              n\n              t\n              r\n              i\n              p\n              e\n              t\n              a\n              l\n            \n          \n          \u2032\n        \n        \u2212\n        m\n        \n          \n            A\n          \n          \n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} '=\\mathbf {F} _{\\mathrm {physical} }+\\mathbf {F} '_{\\mathrm {Euler} }+\\mathbf {F} '_{\\mathrm {Coriolis} }+\\mathbf {F} '_{\\mathrm {centripetal} }-m\\mathbf {A} _{0},}\n  where\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            \n              E\n              u\n              l\n              e\n              r\n            \n          \n          \u2032\n        \n        =\n        \u2212\n        m\n        \n          \n            \n              \u03c9\n              \u02d9\n            \n          \n        \n        \u00d7\n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {F} '_{\\mathrm {Euler} }=-m{\\dot {\\boldsymbol {\\omega }}}\\times \\mathbf {r} '}\n   (Euler force),\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            \n              C\n              o\n              r\n              i\n              o\n              l\n              i\n              s\n            \n          \n          \u2032\n        \n        =\n        \u2212\n        2\n        m\n        \n          \u03c9\n        \n        \u00d7\n        \n          \n            v\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {F} '_{\\mathrm {Coriolis} }=-2m{\\boldsymbol {\\omega }}\\times \\mathbf {v} '}\n   (Coriolis force),\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            \n              c\n              e\n              n\n              t\n              r\n              i\n              f\n              u\n              g\n              a\n              l\n            \n          \n          \u2032\n        \n        =\n        \u2212\n        m\n        \n          \u03c9\n        \n        \u00d7\n        (\n        \n          \u03c9\n        \n        \u00d7\n        \n          \n            r\n          \n          \u2032\n        \n        )\n        =\n        m\n        (\n        \n          \u03c9\n          \n            2\n          \n        \n        \n          \n            r\n          \n          \u2032\n        \n        \u2212\n        (\n        \n          \u03c9\n        \n        \u22c5\n        \n          \n            r\n          \n          \u2032\n        \n        )\n        \n          \u03c9\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {F} '_{\\mathrm {centrifugal} }=-m{\\boldsymbol {\\omega }}\\times ({\\boldsymbol {\\omega }}\\times \\mathbf {r} ')=m(\\omega ^{2}\\mathbf {r} '-({\\boldsymbol {\\omega }}\\cdot \\mathbf {r} '){\\boldsymbol {\\omega }})}\n   (centrifugal force).\n\n\n== Separating non-inertial from inertial reference frames ==\n\n\n=== Theory ===\n\nInertial and non-inertial reference frames can be distinguished by the absence or presence of fictitious forces, as explained shortly. The effect of this being in the noninertial frame is to require the observer to introduce a fictitious force into his calculations\u2026.\nThe presence of fictitious forces indicates the physical laws are not the simplest laws available so, in terms of the special principle of relativity, a frame where fictitious forces are present is not an inertial frame:\nThe equations of motion in a non-inertial system differ from the equations in an inertial system by additional terms called inertial forces. This allows us to detect experimentally the non-inertial nature of a system.\nBodies in non-inertial reference frames are subject to so-called fictitious forces (pseudo-forces); that is, forces that result from the acceleration of the reference frame itself and not from any physical force acting on the body. Examples of fictitious forces are the centrifugal force and the Coriolis force in rotating reference frames.\nHow then, are \"fictitious\" forces to be separated from \"real\" forces? It is hard to apply the Newtonian definition of an inertial frame without this separation. For example, consider a stationary object in an inertial frame. Being at rest, no net force is applied. But in a frame rotating about a fixed axis, the object appears to move in a circle, and is subject to centripetal force (which is made up of the Coriolis force and the centrifugal force). How can we decide that the rotating frame is a non-inertial frame? There are two approaches to this resolution: one approach is to look for the origin of the fictitious forces (the Coriolis force and the centrifugal force). We will find there are no sources for these forces, no associated force carriers, no originating bodies. A second approach is to look at a variety of frames of reference. For any inertial frame, the Coriolis force and the centrifugal force disappear, so application of the principle of special relativity would identify these frames where the forces disappear as sharing the same and the simplest physical laws, and hence rule that the rotating frame is not an inertial frame.\nNewton examined this problem himself using rotating spheres, as shown in Figure 2 and Figure 3. He pointed out that if the spheres are not rotating, the tension in the tying string is measured as zero in every frame of reference. If the spheres only appear to rotate (that is, we are watching stationary spheres from a rotating frame), the zero tension in the string is accounted for by observing that the centripetal force is supplied by the centrifugal and Coriolis forces in combination, so no tension is needed. If the spheres really are rotating, the tension observed is exactly the centripetal force required by the circular motion. Thus, measurement of the tension in the string identifies the inertial frame: it is the one where the tension in the string provides exactly the centripetal force demanded by the motion as it is observed in that frame, and not a different value. That is, the inertial frame is the one where the fictitious forces vanish.\nSo much for fictitious forces due to rotation. However, for linear acceleration, Newton expressed the idea of undetectability of straight-line accelerations held in common:\nIf bodies, any how moved among themselves, are urged in the direction of parallel lines by equal accelerative forces, they will continue to move among themselves, after the same manner as if they had been urged by no such forces. \nThis principle generalizes the notion of an inertial frame. For example, an observer confined in a free-falling lift will assert that he himself is a valid inertial frame, even if he is accelerating under gravity, so long as he has no knowledge about anything outside the lift. So, strictly speaking, inertial frame is a relative concept. With this in mind, we can define inertial frames collectively as a set of frames which are stationary or moving at constant velocity with respect to each other, so that a single inertial frame is defined as an element of this set.\nFor these ideas to apply, everything observed in the frame has to be subject to a base-line, common acceleration shared by the frame itself. That situation would apply, for example, to the elevator example, where all objects are subject to the same gravitational acceleration, and the elevator itself accelerates at the same rate.\n\n\n=== Applications ===\nInertial navigation systems used a cluster of gyroscopes and accelerometers to determine accelerations relative to inertial space. After a gyroscope is spun up in a particular orientation in inertial space, the law of conservation of angular momentum requires that it retain that orientation as long as no external forces are applied to it.:\u200a59\u200a  Three orthogonal gyroscopes establish an inertial reference frame, and the accelerators measure acceleration relative to that frame. The accelerations, along with a clock, can then be used to calculate the change in position. Thus, inertial navigation is a form of dead reckoning that requires no external input, and therefore cannot be jammed by any external or internal signal source.A gyrocompass, employed for navigation of seagoing vessels, finds the geometric north. It does so, not by sensing the Earth's magnetic field, but by using inertial space as its reference. The outer casing of the gyrocompass device is held in such a way that it remains aligned with the local plumb line. When the gyroscope wheel inside the gyrocompass device is spun up, the way the gyroscope wheel is suspended causes the gyroscope wheel to gradually align its spinning axis with the Earth's axis. Alignment with the Earth's axis is the only direction for which the gyroscope's spinning axis can be stationary with respect to the Earth and not be required to change direction with respect to inertial space. After being spun up, a gyrocompass can reach the direction of alignment with the Earth's axis in as little as a quarter of an hour.\n\n\n== Examples ==\n\n\n=== Simple example ===\n\nConsider a situation common in everyday life. Two cars travel along a road, both moving at constant velocities. See Figure 1. At some particular moment, they are separated by 200 metres. The car in front is travelling at 22 metres per second and the car behind is travelling at 30 metres per second. If we want to find out how long it will take the second car to catch up with the first, there are three obvious \"frames of reference\" that we could choose.First, we could observe the two cars from the side of the road. We define our \"frame of reference\" S as follows. We stand on the side of the road and start a stop-clock at the exact moment that the second car passes us, which happens to be when they are a distance d = 200 m apart. Since neither of the cars is accelerating, we can determine their positions by the following formulas, where \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle x_{1}(t)}\n   is the position in meters of car one after time t in seconds and \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle x_{2}(t)}\n   is the position of car two after time t.\n\n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        (\n        t\n        )\n        =\n        d\n        +\n        \n          v\n          \n            1\n          \n        \n        t\n        =\n        200\n        +\n        22\n        t\n        ,\n        \n        \n          x\n          \n            2\n          \n        \n        (\n        t\n        )\n        =\n        \n          v\n          \n            2\n          \n        \n        t\n        =\n        30\n        t\n        .\n      \n    \n    {\\displaystyle x_{1}(t)=d+v_{1}t=200+22t,\\quad x_{2}(t)=v_{2}t=30t.}\n  Notice that these formulas predict at t = 0 s the first car is 200 m down the road and the second car is right beside us, as expected. We want to find the time at which \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        =\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{1}=x_{2}}\n  . Therefore, we set \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        =\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x_{1}=x_{2}}\n   and solve for \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  , that is:\n\n  \n    \n      \n        200\n        +\n        22\n        t\n        =\n        30\n        t\n        ,\n      \n    \n    {\\displaystyle 200+22t=30t,}\n  \n\n  \n    \n      \n        8\n        t\n        =\n        200\n        ,\n      \n    \n    {\\displaystyle 8t=200,}\n  \n\n  \n    \n      \n        t\n        =\n        25\n         \n        \n          s\n          e\n          c\n          o\n          n\n          d\n          s\n        \n        .\n      \n    \n    {\\displaystyle t=25\\ \\mathrm {seconds} .}\n  Alternatively, we could choose a frame of reference S\u2032 situated in the first car. In this case, the first car is stationary and the second car is approaching from behind at a speed of v2 \u2212 v1 = 8 m/s. In order to catch up to the first car, it will take a time of d/v2 \u2212 v1 = 200/8 s, that is, 25 seconds, as before. Note how much easier the problem becomes by choosing a suitable frame of reference. The third possible frame of reference would be attached to the second car. That example resembles the case just discussed, except the second car is stationary and the first car moves backward towards it at 8 m/s.\nIt would have been possible to choose a rotating, accelerating frame of reference, moving in a complicated manner, but this would have served to complicate the problem unnecessarily. It is also necessary to note that one is able to convert measurements made in one coordinate system to another. For example, suppose that your watch is running five minutes fast compared to the local standard time. If you know that this is the case, when somebody asks you what time it is, you are able to deduct five minutes from the time displayed on your watch in order to obtain the correct time. The measurements that an observer makes about a system depend therefore on the observer's frame of reference (you might say that the bus arrived at 5 past three, when in fact it arrived at three).\n\n\n=== Additional example ===\n\nFor a simple example involving only the orientation of two observers, consider two people standing, facing each other on either side of a north-south street. See Figure 2. A car drives past them heading south. For the person facing east, the car was moving towards the right. However, for the person facing west, the car was moving toward the left. This discrepancy is because the two people used two different frames of reference from which to investigate this system.\nFor a more complex example involving observers in relative motion, consider Alfred, who is standing on the side of a road watching a car drive past him from left to right. In his frame of reference, Alfred defines the spot where he is standing as the origin, the road as the x-axis and the direction in front of him as the positive y-axis. To him, the car moves along the x axis with some velocity v in the positive x-direction. Alfred's frame of reference is considered an inertial frame of reference because he is not accelerating (ignoring effects such as Earth's rotation and gravity).\nNow consider Betsy, the person driving the car. Betsy, in choosing her frame of reference, defines her location as the origin, the direction to her right as the positive x-axis, and the direction in front of her as the positive y-axis. In this frame of reference, it is Betsy who is stationary and the world around her that is moving \u2013 for instance, as she drives past Alfred, she observes him moving with velocity v in the negative y-direction. If she is driving north, then north is the positive y-direction; if she turns east, east becomes the positive y-direction.\nFinally, as an example of non-inertial observers, assume Candace is accelerating her car. As she passes by him, Alfred measures her acceleration and finds it to be a in the negative x-direction. Assuming Candace's acceleration is constant, what acceleration does Betsy measure? If Betsy's velocity v is constant, she is in an inertial frame of reference, and she will find the acceleration to be the same as Alfred in her frame of reference, a in the negative y-direction. However, if she is accelerating at rate A in the negative y-direction (in other words, slowing down), she will find Candace's acceleration to be a\u2032 = a \u2212 A in the negative y-direction\u2014a smaller value than Alfred has measured. Similarly, if she is accelerating at rate A in the positive y-direction (speeding up), she will observe Candace's acceleration as a\u2032 = a + A in the negative y-direction\u2014a larger value than Alfred's measurement.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nEdwin F. Taylor and John Archibald Wheeler, Spacetime Physics, 2nd ed. (Freeman, NY, 1992)\nAlbert Einstein, Relativity, the special and the general theories, 15th ed. (1954)\nPoincar\u00e9, Henri (1900). \"La th\u00e9orie de Lorentz et le Principe de R\u00e9action\". Archives Neerlandaises. V: 253\u201378.\nAlbert Einstein, On the Electrodynamics of Moving Bodies, included in The Principle of Relativity, page 38. Dover 1923Rotation of the UniverseJulian B. Barbour; Herbert Pfister (1998). Mach's Principle: From Newton's Bucket to Quantum Gravity. Birkh\u00e4user. p. 445. ISBN 0-8176-3823-7.\nPJ Nahin (1999). Time Machines. Springer. p. 369; Footnote 12. ISBN 0-387-98571-9.\nB Ciobanu, I Radinchi Modeling the electric and magnetic fields in a rotating universe Rom. Journ. Phys., Vol. 53, Nos. 1\u20132, P. 405\u2013415, Bucharest, 2008\nYuri N. Obukhov, Thoralf Chrobok, Mike Scherfner Shear-free rotating inflation Phys. Rev. D 66, 043518 (2002) [5 pages]\nYuri N. Obukhov On physical foundations and observational effects of cosmic rotation (2000)\nLi-Xin Li Effect of the Global Rotation of the Universe on the Formation of Galaxies General Relativity and Gravitation, 30 (1998) doi:10.1023/A:1018867011142\nP Birch Is the Universe rotating? Nature 298, 451 \u2013 454 (29 July 1982)\nKurt G\u00f6del An example of a new type of cosmological solutions of Einstein's field equations of gravitation Rev. Mod. Phys., Vol. 21, p. 447, 1949.\n\n\n== External links ==\nStanford Encyclopedia of Philosophy entry\nAnimation clip on YouTube showing scenes as viewed from both an inertial frame and a rotating frame of reference, visualizing the Coriolis and centrifugal forces.\n\"Is Gravity An Illusion?\". PBS Space Time. 3 June 2015. Archived from the original on 13 November 2021 \u2013 via YouTube.", "Magnification": "Magnification is the process of enlarging the apparent size, not physical size, of something. This enlargement is quantified by a calculated number also called \"magnification\". When this number is less than one, it refers to a reduction in size, sometimes called magnification or de-magnification.\nTypically, magnification is related to scaling up visuals or images to be able to see more detail, increasing resolution, using microscope, printing techniques, or digital processing. In all cases, the magnification of the image does not change the perspective of the image.\n\n\n== Examples of magnification ==\nSome optical instruments provide visual aid by magnifying small or distant subjects.\n\nA magnifying glass, which uses a positive (convex) lens to make things look bigger by allowing the user to hold them closer to their eye.\nA telescope, which uses its large objective lens or primary mirror to create an image of a distant object and then allows the user to examine the image closely with a smaller eyepiece lens, thus making the object look larger.A microscope, which makes a small object appear as a much larger image at a comfortable distance for viewing. A microscope is similar in layout to a telescope except that the object being viewed is close to the objective, which is usually much smaller than the eyepiece.\nA slide projector, which projects a large image of a small slide on a screen. A photographic enlarger is similar.\n\n\n== Magnification as a number (optical magnification) ==\nOptical magnification is the ratio between the apparent size of an object (or its size in an image) and its true size, and thus it is a dimensionless number. Optical magnification is sometimes referred to as \"power\" (for example \"10\u00d7 power\"), although this can lead to confusion with optical power.\n\n\n=== Linear or Transverse magnification ===\nFor real images, such as images projected on a screen, size means a linear dimension (measured, for example, in millimeters or inches).\n\n\n=== Angular magnification ===\nFor optical instruments with an eyepiece, the linear dimension of the image seen in the eyepiece (virtual image at infinite distance) cannot be given, thus size means the angle subtended by the object at the focal point (angular size). Strictly speaking, one should take the tangent of that angle (in practice, this makes a difference only if the angle is larger than a few degrees). Thus, angular magnification is given by:\n\nwhere \n  \n    \n      \n        \u03b5\n        \n          0\n        \n      \n    \n    {\\varepsilon _{0}}\n   is the angle subtended by the object at the front focal point of the objective and \n  \n    \n      \u03b5\n    \n    {\\varepsilon }\n   is the angle subtended by the image at the rear focal point of the eyepiece.\nFor example, the mean angular size of the Moon's disk as viewed from Earth's surface is about 0.52\u00b0. Thus, through binoculars with 10\u00d7 magnification, the Moon appears to subtend an angle of about 5.2\u00b0.\nBy convention, for magnifying glasses and optical microscopes, where the size of the object is a linear dimension and the apparent size is an angle, the magnification is the ratio between the apparent (angular) size as seen in the eyepiece and the angular size of the object when placed at the conventional closest distance of distinct vision: 25 cm from the eye.\n\n\n=== By instrument ===\n\n\n==== Single lens ====\nThe linear magnification of a thin lens is\n\nwhere \n  \n    \n      \n        f\n      \n    \n    {\\textstyle f}\n   is the focal length and \n  \n    \n      \n        \n          d\n          \n            o\n          \n        \n      \n    \n    {\\textstyle d_{o}}\n   is the distance from the lens to the object. For real images, \n  \n    \n      \n        M\n      \n    \n    {\\textstyle M}\n   is negative and the image is inverted. For virtual images, \n  \n    \n      \n        M\n      \n    \n    {\\textstyle M}\n   is positive and the image is upright.\nWith \n  \n    \n      d\n      \n        i\n      \n    \n    d_{i}\n   being the distance from the lens to the image, \n  \n    \n      h\n      \n        i\n      \n    \n    h_{i}\n   the height of the image and \n  \n    \n      h\n      \n        o\n      \n    \n    h_{o}\n   the height of the object, the magnification can also be written as:\n\nNote again that a negative magnification implies an inverted image.\n\n\n==== Photography ====\nThe image recorded by a photographic film or image sensor is always a real image and is usually inverted. When measuring the height of an inverted image using the cartesian sign convention (where the x-axis is the optical axis) the value for hi will be negative, and as a result M will also be negative. However, the traditional sign convention used in photography is \"real is positive, virtual is negative\". Therefore, in photography: Object height and distance are always real and positive. When the focal length is positive the image's height, distance and magnification are real and positive. Only if the focal length is negative, the image's height, distance and magnification are virtual and negative. Therefore, the photographic magnification formulae are traditionally presented as\nIn Photography, magnification rate often present in 1X, 2X, etc. Or sometimes would be in form of ratio(0.5:1, 1:1, 2:1, etc.). Same lens may react different in magnification rate when using different sensors.\n\n\n==== Magnifying glass ====\nThe maximum angular magnification (compared to the naked eye) of a magnifying glass depends on how the glass and the object are held, relative to the eye. If the lens is held at a distance from the object such that its front focal point is on the object being viewed, the relaxed eye (focused to infinity) can view the image with angular magnification\n\nHere, \n  \n    f\n    f\n   is the focal length of the lens in centimeters. The constant 25 cm is an estimate of the \"near point\" distance of the eye\u2014the closest distance at which the healthy naked eye can focus. In this case the angular magnification is independent from the distance kept between the eye and the magnifying glass.\nIf instead the lens is held very close to the eye and the object is placed closer to the lens than its focal point so that the observer focuses on the near point, a larger angular magnification can be obtained, approaching\n\nA different interpretation of the working of the latter case is that the magnifying glass changes the diopter of the eye (making it myopic) so that the object can be placed closer to the eye resulting in a larger angular magnification.\n\n\n==== Microscope ====\nThe angular magnification of a microscope is given by\n\nwhere \n  \n    \n      M\n      \n        o\n      \n    \n    M_{o}\n   is the magnification of the objective and \n  \n    \n      M\n      \n        e\n      \n    \n    M_{e}\n   the magnification of the eyepiece. The magnification of the objective depends on its focal length \n  \n    \n      f\n      \n        o\n      \n    \n    f_{o}\n   and on the distance \n  \n    d\n    d\n   between objective back focal plane and the focal plane of the eyepiece (called the tube length):\n\nThe magnification of the eyepiece depends upon its focal length \n  \n    \n      f\n      \n        e\n      \n    \n    f_{e}\n   and is calculated by the same equation as that of a magnifying glass (above).\nNote that both astronomical telescopes as well as simple microscopes produce an inverted image, thus the equation for the magnification of a telescope or microscope is often given with a minus sign.\n\n\n==== Telescope ====\nThe angular magnification of an optical telescope is given by\n\nin which \n  \n    \n      f\n      \n        o\n      \n    \n    f_{o}\n   is the focal length of the objective lens in a refractor or of the primary mirror in a reflector, and \n  \n    \n      f\n      \n        e\n      \n    \n    f_{e}\n   is the focal length of the eyepiece.\n\n\n===== Measurement of telescope magnification =====\nMeasuring the actual angular magnification of a telescope is difficult, but it is possible to use the reciprocal relationship between the linear magnification and the angular magnification, since the linear magnification is constant for all objects.\nThe telescope is focused correctly for viewing objects at the distance for which the angular magnification is to be determined and then the object glass is used as an object the image of which is known as the exit pupil. The diameter of this may be measured using an instrument known as a Ramsden dynameter which consists of a Ramsden eyepiece with micrometer hairs in the back focal plane. This is mounted in front of the telescope eyepiece and used to evaluate the diameter of the exit pupil. This will be much smaller than the object glass diameter, which gives the linear magnification (actually a reduction), the angular magnification can be determined from\n\n  \n    \n      \n        M\n        \n          A\n        \n      \n      =\n      1\n      \n        /\n      \n      M\n      =\n      \n        D\n        \n          \n            O\n            b\n            j\n            e\n            c\n            t\n            i\n            v\n            e\n          \n        \n      \n      \n        /\n      \n      \n        \n          D\n          \n            \n              R\n              a\n              m\n              s\n              d\n              e\n              n\n            \n          \n        \n      \n    \n    M_{A}=1/M=D_{\\mathrm {Objective} }/{D_{\\mathrm {Ramsden} }}\n  .\n\n\n=== Maximum usable magnification ===\nWith any telescope or microscope, or a lens\na maximum magnification exists beyond which the image looks bigger but shows no more detail.  It occurs when the finest detail the instrument can resolve is magnified to match the finest detail the eye can see.  Magnification beyond this maximum is sometimes called \"empty magnification\".\nFor a good quality telescope operating in good atmospheric conditions, the maximum usable magnification is limited by diffraction.  In practice it is considered to be 2\u00d7 the aperture in millimetres or 50\u00d7 the aperture in inches; so, a 60mm diameter telescope has a maximum usable magnification of 120\u00d7.With an optical microscope having a high numerical aperture and using oil immersion, the best possible resolution is 200 nm corresponding to a magnification of around 1200\u00d7. Without oil immersion, the maximum usable magnification is around 800\u00d7.  For details, see limitations of optical microscopes.\nSmall, cheap telescopes and microscopes are sometimes supplied with the eyepieces that give magnification far higher than is usable.\n\n\n== \"Magnification\" of displayed images ==\nMagnification figures on pictures displayed in print or online can be misleading.  Editors of journals and magazines routinely resize images to fit the page, making any magnification number provided in the figure legend incorrect. Images displayed on a computer screen change size based on the size of the screen.  A scale bar (or micron bar) is a bar of stated length superimposed on a picture. When the picture is resized the bar will be resized in proportion.  If a picture has a scale bar, the actual magnification can easily be calculated.  Where the scale (magnification) of an image is important or relevant, including a scale bar is preferable to stating magnification.\n\n\n== See also ==\nLens\nMagnifying glass\nMicroscope\nOptical telescope\nScreen magnifier\n\n\n== References ==", "Joule": "The joule (symbol: J) is the unit of energy in the International System of Units (SI). It is equal to the amount of work done when a force of 1 newton displaces a mass through a distance of 1 metre in the direction of the force applied. It is also the energy dissipated as heat when an electric current of one ampere passes through a resistance of one ohm for one second. It is named after the English physicist James Prescott Joule (1818\u20131889).\n\n\n== Definition ==\nIn terms of SI base units and in terms of SI derived units with special names, the joule is defined as\n\nOne joule can also be defined by any of the following:\n\nThe work required to move an electric charge of one coulomb through an electrical potential difference of one volt, or one coulomb-volt (C\u22c5V). This relationship can be used to define the volt.\nThe work required to produce one watt of power for one second, or one watt-second (W\u22c5s) (compare kilowatt-hour, which is 3.6 megajoules). This relationship can be used to define the watt.The joule is named after James Prescott Joule. As with every SI unit named for a person, its symbol starts with an upper case letter (J), but when written in full it follows the rules for capitalisation of a common noun; i.e., \"joule\" becomes capitalised at the beginning of a sentence and in titles, but is otherwise in lower case.\n\n\n=== Pronunciation ===\n\"Joule\" is pronounced  JEWEL or  JOWL;.\n\n\n== History ==\nThe cgs system had been declared official in 1881, at the first International Electrical Congress.\nThe erg was adopted as its unit of energy in 1882. Wilhelm Siemens, in his inauguration speech as chairman of the British Association for the Advancement of Science (23 August 1882) first proposed the Joule as unit of heat, to be derived from the electromagnetic units Ampere and Ohm, in cgs units equivalent to 107 erg.\nThe naming of the unit in honour of James Prescott Joule (1818\u20131889), at the time retired but still living (aged 63), is due to Siemens:\n\n\"Such a heat unit, if found acceptable, might with great propriety, I think, be called the Joule, after the man who has done so much to develop the dynamical theory of heat.\"At the second International Electrical Congress, on 31 August 1889, the joule was officially adopted alongside the watt and the quadrant (later renamed to henry).\nJoule died in the same year, on 11 October 1889.\nAt the fourth congress (1893), the \"international ampere\" and \"international ohm\" were defined, with slight changes in the specifications for their measurement, with the \"international joule\" being the unit derived from them.In 1935, the International Electrotechnical Commission (as the successor organisation of the International Electrical Congress) adopted the \"Giorgi system\", which by virtue of assuming a defined value for the magnetic constant also implied a redefinition of the Joule. The Giorgi system was approved by the International Committee for Weights and Measures in 1946. The joule was now no longer defined based on electromagnetic unit, but instead as the unit of work performed by one unit of force (at the time not yet named newton)\nover the distance of 1 metre. The joule was explicitly intended as the unit of energy to be used in both electromagnetic and mechanical contexts. The ratification of the definition at the ninth General Conference on Weights and Measures, in 1948,\nadded the specification that the joule was also to be preferred as the unit of heat in the context of calorimetry, thereby officially deprecating the use of the calorie. \nThis definition was the direct precursor of the joule as adopted in the modern International System of Units in 1960.\nThe definition of the joule as J = kg\u22c5m2\u22c5s\u22122 has remained unchanged since 1946, but the joule as a derived unit has inherited changes in the definitions of the   second (in 1960 and 1967), the metre (in 1983) and the kilogram (in 2019).\n\n\n== Practical examples ==\nOne joule represents (approximately):\n\nThe amount of electricity required to run a 1 W device for 1 s.\nThe energy required to accelerate a 1 kg mass at 1 m/s2 through a distance of 1 m.\nThe kinetic energy of a 2 kg mass travelling at 1 m/s, or a 1 kg mass travelling at 1.41 m/s.\nThe energy required to lift an apple up 1 metre (3 ft 3 in), assuming the apple has a mass of 101.97 grams (3.597 oz).\nThe heat required to raise the temperature of 0.239 g of water from 0 \u00b0C to 1 \u00b0C, or from 32 \u00b0F to 33.8 \u00b0F.\nThe typical energy released as heat by a person at rest every 1/60 s (17 ms).\nThe kinetic energy of a 50 kg human moving very slowly (0.2 m/s or 0.72 km/h).\nThe kinetic energy of a 56 g tennis ball moving at 6 m/s (22 km/h).\nThe food energy (kcal) in slightly more than half of a sugar crystal (0.102 mg/crystal).\n\n\n== Multiples ==\n\nZeptojoule\n160 zeptojoule is about one electronvolt. The minimal energy needed to change a bit at around room temperature \u2013 approximately 2.75 zJ \u2013 is given by the Landauer limit.\nNanojoule\n160 nanojoule is about the kinetic energy of a flying mosquito.\nMicrojoule\nThe Large Hadron Collider (LHC) produces collisions of the microjoule order (7 TeV) per particle.\nKilojoule\nNutritional food labels in most countries express energy in kilojoules (kJ). One square metre of the Earth receives about 1.4 kilojoules of solar radiation every second in full daylight. A human in a sprint has approximately 3 kJ of kinetic energy, while a cheetah in a 122 km/h (76 mph) sprint has approximately 20 kJ. One watt-hour of electricity is 3.6 kilojoules.\nMegajoule\nThe megajoule is approximately the kinetic energy of a one megagram (tonne) vehicle moving at 161 km/h (100 mph). The energy required to heat 10 L of liquid water at constant pressure from 0 \u00b0C (32 \u00b0F) to 100 \u00b0C (212 \u00b0F) is approximately 4.2 MJ. One kilowatt-hour of electricity is 3.6 megajoules.\nGigajoule\n6 gigajoule is about the chemical energy of combusting 1 barrel (159 L) of petroleum. 2 GJ is about the Planck energy unit. One megawatt-hour of electricity is 3.6 gigajoules.\nTerajoule\nThe terajoule is about 0.278 GWh (which is often used in energy tables). About 63 TJ of energy was released by Little Boy. The International Space Station, with a mass of approximately 450 megagrams and orbital velocity of 7700 m/s, has a kinetic energy of roughly 13 TJ. In 2017, Hurricane Irma was estimated to have a peak wind energy of 112 TJ. One gigawatt-hour of electricity is 3.6 terajoules.\nPetajoule\n210 petajoule is about 50 megatons of TNT, which is the amount of energy released by the Tsar Bomba, the largest man-made explosion ever. One terawatt-hour of electricity is 3.6 petajoules.\nExajoule\nThe 2011 T\u014dhoku earthquake and tsunami in Japan had 1.41 EJ of energy according to its rating of 9.0 on the moment magnitude scale. Yearly U.S. energy consumption amounts to roughly 94 EJ. One petawatt-hour of electricity is 3.6 exajoules.\nZettajoule\nThe zettajoule is somewhat more than the amount of energy required to heat the Baltic sea by 1 \u00b0C, assuming properties similar to those of pure water. Human annual world energy consumption is approximately 0.5 ZJ.  The energy to raise the temperature of Earth's atmosphere 1 \u00b0C is approximately 2.2 ZJ.\nYottajoule\nThe yottajoule is a little less than the amount of energy required to heat the Indian Ocean by 1 \u00b0C, assuming properties similar to those of pure water. The thermal output of the Sun is approximately 400 YJ per second.\n\n\n== Conversions ==\n\n1 joule is equal to (approximately unless otherwise stated):\n\n107 erg (exactly)\n6.24150974\u00d71018 eV\n0.2390 cal (gram calories)\n2.390\u00d710\u22124 kcal (food calories)\n9.4782\u00d710\u22124 BTU\n0.7376 ft\u22c5lb (foot-pound)\n23.7 ft\u22c5pdl (foot-poundal)\n2.7778\u00d710\u22127 kW\u22c5h (kilowatt-hour)\n2.7778\u00d710\u22124 W\u22c5h (watt-hour)\n9.8692\u00d710\u22123 latm (litre-atmosphere)\n11.1265\u00d710\u221215 g (by way of mass\u2013energy equivalence)\n10\u221244 foe (exactly)Units defined exactly in terms of the joule include:\n\n1 thermochemical calorie = 4.184 J\n1 International Table calorie = 4.1868 J\n1 W\u22c5h = 3600 J (or 3.6 kJ)\n1 kW\u22c5h = 3.6\u00d7106 J (or 3.6 MJ)\n1 W\u22c5s = 1 J\n1 ton TNT = 4.184 GJ\n\n\n== Newton-metre and torque ==\n\nIn mechanics, the concept of force (in some direction) has a close analogue in the concept of torque (about some angle):\n\nA result of this similarity is that the SI unit for torque is the newton-metre, which works out algebraically to have the same dimensions as the joule, but they are not interchangeable. The General Conference on Weights and Measures has given the unit of energy the name joule, but has not given the unit of torque any special name, hence it is simply the newton-metre (N\u22c5m) \u2013 a compound name derived from its constituent parts. The use of newton-metres for torque and joules for energy is helpful to avoid misunderstandings and miscommunications.The distinction may be seen also in the fact that energy is a scalar quantity \u2013 the dot product of a force vector and a displacement vector. By contrast, torque is a vector \u2013 the cross product of a force vector and a distance vector. Torque and energy are related to one another by the equation\n\nwhere E is energy, \u03c4 is (the vector magnitude of) torque, and \u03b8 is the angle swept (in radians). Since plane angles are dimensionless, it follows that torque and energy have the same dimensions.\n\n\n== Watt-second ==\nA watt-second (symbol W s or W\u22c5s) is a derived unit of energy equivalent to the joule. The watt-second is the energy equivalent to the power of one watt sustained for one second.  While the watt-second is equivalent to the joule in both units and meaning, there are some contexts in which the term \"watt-second\" is used instead of \"joule\", such as in the rating of photographic electronic flash units. \n\n\n== See also ==\nFluence\nReciprocal joules\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n The dictionary definition of joule at Wiktionary", "Virtual_image": "In optics, an image is defined as the collection of focus points of light rays coming from an object. A real image is the collection of focus points made by converging rays, while a virtual image is the collection of focus points made by extensions of diverging rays. In other words, a virtual image is found by tracing real rays that emerge from an optical device (lens, mirror, or some combination) backward to perceived or apparent origins of ray divergences. In diagrams of optical systems, virtual rays are conventionally represented by dotted lines, to contrast with the solid lines of real rays.\nBecause the rays never really converge, a virtual image cannot be projected onto a screen. In contrast, a real image can be projected on the screen as it is formed by rays that converge on a real location. A real image can be projected onto a diffusely reflecting screen so people can see the image (the image on the screen plays as an object to be imaged by human eyes).\nA plane mirror forms a virtual image positioned behind the mirror. Although the rays of light seem to come from behind the mirror, light from the source only exists in front of the mirror. The image in a plane mirror is not magnified (that is, the image is the same size as the object) and appears to be as far behind the mirror as the object is in front of the mirror.\nA diverging lens (one that is thicker at the edges than the middle) or a convex mirror forms a virtual image. Such an image is reduced in size when compared to the original object. A converging lens (one that is thicker in the middle than at the edges) or a concave mirror is also capable of producing a virtual image if the object is within the focal length. Such an image will be magnified. In contrast, an object placed in front of a converging lens or concave mirror at a position beyond the focal length produces a real image. Such an image will be magnified if the position of the object is within twice the focal length, or else the image will be reduced if the object is further than twice the focal length. It can be obtained on screen....\n\n\n== See also ==\nFocal plane\nImage plane\nLens\nReal image\n\n\n== References ==", "Electric_field": "An electric field (sometimes E-field) is the physical field that surrounds electrically charged particles and exerts force on all other charged particles in the field, either attracting or repelling them. It also refers to the physical field for a system of charged particles. Electric fields originate from electric charges and time-varying electric currents. Electric fields and magnetic fields are both manifestations of the electromagnetic field, one of the four fundamental interactions (also called forces) of nature.\nElectric fields are important in many areas of physics, and are exploited in electrical technology. In atomic physics and chemistry, for instance, the electric field is the attractive force holding the atomic nucleus and electrons together in atoms. It is also the force responsible for chemical bonding between atoms that result in molecules.\nThe electric field is defined as a vector field that associates to each point in space the electrostatic (Coulomb) force per unit of charge exerted on an infinitesimal positive test charge at rest at that point. The derived SI unit for the electric field is the volt per meter (V/m), which is equal to the newton per coulomb (N/C).\n\n\n== Description ==\n\nThe electric field is defined at each point in space as the force per unit charge that would be experienced by a vanishingly small positive test charge if held stationary at that point.:\u200a469\u201370\u200a As the electric field is defined in terms of force, and force is a vector (i.e. having both magnitude and direction), it follows that an electric field is a vector field.:\u200a469\u201370\u200a Fields that may be defined in this manner are sometimes referred to as force fields. The electric field acts between two charges similarly to the way the gravitational field acts between two masses, as they both obey an inverse-square law with distance. This is the basis for Coulomb's law, which states that, for stationary charges, the electric field varies with the source charge and varies inversely with the square of the distance from the source. This means that if the source charge were doubled, the electric field would double, and if you move twice as far away from the source, the field at that point would be only one-quarter its original strength.\nThe electric field can be visualized with a set of lines whose direction at each point is the same as the field's, a concept introduced by Michael Faraday, whose term 'lines of force' is still sometimes used. This illustration has the useful property that the field's strength is proportional to the density of the lines. Field lines due to stationary charges have several important properties, including always originating from positive charges and terminating at negative charges, they enter all good conductors at right angles, and they never cross or close in on themselves.:\u200a479\u200a The field lines are a representative concept; the field actually permeates all the intervening space between the lines. More or fewer lines may be drawn depending on the precision to which it is desired to represent the field. The study of electric fields created by stationary charges is called electrostatics.\nFaraday's law describes the relationship between a time-varying magnetic field and the electric field. One way of stating Faraday's law is that the curl of the electric field is equal to the negative time derivative of the magnetic field.:\u200a327\u200a In the absence of time-varying magnetic field, the electric field is therefore called conservative (i.e. curl-free).:\u200a24,\u200a90\u201391\u200a This implies there are two kinds of electric fields: electrostatic fields and fields arising from time-varying magnetic fields.:\u200a305\u2013307\u200a While the curl-free nature of the static electric field allows for a simpler treatment using electrostatics, time-varying magnetic fields are generally treated as a component of a unified electromagnetic field. The study of time varying magnetic and electric fields is called electrodynamics.\n\n\n== Mathematical formulation ==\n\nElectric fields are caused by electric charges, described by Gauss's law, and time varying magnetic fields, described by Faraday's law of induction. Together, these laws are enough to define the behavior of the electric field. However, since the magnetic field is described as a function of electric field, the equations of both fields are coupled and together form Maxwell's equations that describe both fields as a function of charges and currents.\n\n\n=== Electrostatics ===\n\nIn the special case of a steady state (stationary charges and currents), the Maxwell-Faraday inductive effect disappears. The resulting two equations (Gauss's law \n  \n    \n      \n        \u2207\n        \u22c5\n        \n          E\n        \n        =\n        \n          \n            \u03c1\n            \n              \u03b5\n              \n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\nabla \\cdot \\mathbf {E} ={\\frac {\\rho }{\\varepsilon _{0}}}}\n   and Faraday's law with no induction term \n  \n    \n      \n        \u2207\n        \u00d7\n        \n          E\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\times \\mathbf {E} =0}\n  ), taken together, are equivalent to Coulomb's law, which states that a particle with electric charge \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n   at position \n  \n    \n      \n        \n          \n            x\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{1}}\n   exerts a force on a particle with charge \n  \n    \n      \n        \n          q\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle q_{0}}\n   at position \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n   of:\nwhere \n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                ^\n              \n            \n          \n          \n            1\n            ,\n            0\n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {r} }}_{1,0}}\n   is the unit vector in the direction from point \n  \n    \n      \n        \n          \n            x\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{1}}\n   to point \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n  , and \u03b50 is the electric constant (also known as \"the absolute permittivity of free space\") with the unit C2\u22c5m\u22122\u22c5N\u22121.\nNote that \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n  , the vacuum electric permittivity, must be substituted with \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  , permittivity, when charges are in non-empty media.\nWhen the charges \n  \n    \n      \n        \n          q\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle q_{0}}\n   and \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n   have the same sign this force is positive, directed away from the other charge, indicating the particles repel each other. When the charges have unlike signs the force is negative, indicating the particles attract.\nTo make it easy to calculate the Coulomb force on any charge at position \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n   this expression can be divided by \n  \n    \n      \n        \n          q\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle q_{0}}\n   leaving an expression that only depends on the other charge (the source charge)\nThis is the electric field at point \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n   due to the point charge \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n  ; it is a vector-valued function equal to the Coulomb force per unit charge that a positive point charge would experience at the position \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n  .\nSince this formula gives the electric field magnitude and direction at any point \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n   in space (except at the location of the charge itself, \n  \n    \n      \n        \n          \n            x\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{1}}\n  , where it becomes infinite) it defines a vector field.\nFrom the above formula it can be seen that the electric field due to a point charge is everywhere directed away from the charge if it is positive, and toward the charge if it is negative, and its magnitude decreases with the inverse square of the distance from the charge.\nThe Coulomb force on a charge of magnitude \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   at any point in space is equal to the product of the charge and the electric field at that point\n\nThe SI unit of the electric field is the newton per coulomb (N/C), or volt per meter (V/m); in terms of the SI base units it is kg\u22c5m\u22c5s\u22123\u22c5A\u22121.\n\n\n=== Superposition principle ===\nDue to the linearity of Maxwell's equations, electric fields satisfy the superposition principle, which states that the total electric field, at a point, due to a collection of charges is equal to the vector sum of the electric fields at that point due to the individual charges. This principle is useful in calculating the field created by multiple point charges. If charges \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n        ,\n        \n          q\n          \n            2\n          \n        \n        ,\n        \u2026\n        ,\n        \n          q\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle q_{1},q_{2},\\dots ,q_{n}}\n   are stationary in space at points \n  \n    \n      \n        \n          \n            x\n          \n          \n            1\n          \n        \n        ,\n        \n          \n            x\n          \n          \n            2\n          \n        \n        ,\n        \u2026\n        ,\n        \n          \n            x\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{1},\\mathbf {x} _{2},\\dots ,\\mathbf {x} _{n}}\n  , in the absence of currents, the superposition principle says that the resulting field is the sum of fields generated by each particle as described by Coulomb's law:\n\nwhere \n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                  ^\n                \n              \n            \n            \n              k\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {{\\hat {r}}_{k}} }\n   is the unit vector in the direction from point \n  \n    \n      \n        \n          \n            x\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{k}}\n   to point \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n  .\n\n\n=== Continuous charge distributions ===\nThe superposition principle allows for the calculation of the electric field due to a continuous distribution of charge \n  \n    \n      \n        \u03c1\n        (\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle \\rho (\\mathbf {x} )}\n   (where \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is the charge density in coulombs per cubic meter). By considering the charge \n  \n    \n      \n        \u03c1\n        (\n        \n          \n            x\n          \n          \u2032\n        \n        )\n        d\n        V\n      \n    \n    {\\displaystyle \\rho (\\mathbf {x} ')dV}\n   in each small volume of space \n  \n    \n      \n        d\n        V\n      \n    \n    {\\displaystyle dV}\n   at point \n  \n    \n      \n        \n          \n            x\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {x} '}\n   as a point charge, the resulting electric field, \n  \n    \n      \n        d\n        \n          E\n        \n        (\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle d\\mathbf {E} (\\mathbf {x} )}\n  , at point \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n   can be calculated as \n\nwhere \n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                ^\n              \n            \n          \n          \u2032\n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {r} }}'}\n   is the unit vector pointing from \n  \n    \n      \n        \n          \n            x\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {x} '}\n   to \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n  . The total field is then found by \"adding up\" the contributions from all the increments of volume by integrating over the volume of the charge distribution \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  :\n\nSimilar equations follow for a surface charge with continuous charge distribution \n  \n    \n      \n        \u03c3\n        (\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle \\sigma (\\mathbf {x} )}\n   where \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   is the charge density in coulombs per square meter\n\nand for line charges with continuous charge distribution \n  \n    \n      \n        \u03bb\n        (\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle \\lambda (\\mathbf {x} )}\n   where \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is the charge density in coulombs per meter.\n\n\n=== Electric potential ===\n\nIf a system is static, such that magnetic fields are not time-varying, then by Faraday's law, the electric field is curl-free. In this case, one can define an electric potential, that is, a function \n  \n    \n      \n        \u03a6\n      \n    \n    {\\displaystyle \\Phi }\n   such that \n  \n    \n      \n        \n          E\n        \n        =\n        \u2212\n        \u2207\n        \u03a6\n      \n    \n    {\\displaystyle \\mathbf {E} =-\\nabla \\Phi }\n  . This is analogous to the gravitational potential. The difference between the electric potential at two points in space is called the potential difference (or voltage) between the two points.\nIn general, however, the electric field cannot be described independently of the magnetic field. Given the magnetic vector potential, A, defined so that \n  \n    \n      \n        \n          B\n        \n        =\n        \u2207\n        \u00d7\n        \n          A\n        \n      \n    \n    {\\displaystyle \\mathbf {B} =\\nabla \\times \\mathbf {A} }\n  , one can still define an electric potential \n  \n    \n      \n        \u03a6\n      \n    \n    {\\displaystyle \\Phi }\n   such that:\n\nwhere \n  \n    \n      \n        \u2207\n        \u03a6\n      \n    \n    {\\displaystyle \\nabla \\Phi }\n   is the gradient of the electric potential and \n  \n    \n      \n        \n          \n            \n              \u2202\n              \n                A\n              \n            \n            \n              \u2202\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\partial \\mathbf {A} }{\\partial t}}}\n   is the partial derivative of A with respect to time.\nFaraday's law of induction can be recovered by taking the curl of that equation \nwhich justifies, a posteriori, the previous form for E.\n\n\n=== Continuous vs. discrete charge representation ===\n\nThe equations of electromagnetism are best described in a continuous description. However, charges are sometimes best described as discrete points; for example, some models may describe electrons as point sources where charge density is infinite on an infinitesimal section of space.\nA charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   located at \n  \n    \n      \n        \n          \n            r\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{0}}\n   can be described mathematically as a charge density \n  \n    \n      \n        \u03c1\n        (\n        \n          r\n        \n        )\n        =\n        q\n        \u03b4\n        (\n        \n          r\n        \n        \u2212\n        \n          \n            r\n          \n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle \\rho (\\mathbf {r} )=q\\delta (\\mathbf {r} -\\mathbf {r} _{0})}\n  , where the Dirac delta function (in three dimensions) is used. Conversely, a charge distribution can be approximated by many small point charges.\n\n\n== Electrostatic fields ==\n\nElectrostatic fields are electric fields that do not change with time. Such fields are present when systems of charged matter are stationary, or when  electric currents are unchanging. In that case, Coulomb's law fully describes the field.\n\n\n=== Parallels between electrostatic and gravitational fields ===\nCoulomb's law, which describes the interaction of electric charges:\n\nis similar to Newton's law of universal gravitation:\n\n(where \n  \n    \n      \n        \n          \n            \n              r\n              ^\n            \n          \n        \n        =\n        \n          \n            r\n            \n              \n                |\n              \n              r\n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\textstyle \\mathbf {\\hat {r}} =\\mathbf {\\frac {r}{|r|}} }\n  ).\nThis suggests similarities between the electric field E and the gravitational field g, or their associated potentials. Mass is sometimes called \"gravitational charge\".Electrostatic and gravitational forces both are central, conservative and obey an inverse-square law.\n\n\n=== Uniform fields ===\n\nA uniform field is one in which the electric field is constant at every point. It can be approximated by placing two conducting plates parallel to each other and maintaining a voltage (potential difference) between them; it is only an approximation because of boundary effects (near the edge of the planes, electric field is distorted because the plane does not continue). Assuming infinite planes, the magnitude of the electric field E is:\n\nwhere \u0394V is the potential difference between the plates and d is the distance separating the plates. The negative sign arises as positive charges repel, so a positive charge will experience a force away from the positively charged plate, in the opposite direction to that in which the voltage increases. In micro- and nano-applications, for instance in relation to semiconductors, a typical magnitude of an electric field is in the order of 106 V\u22c5m\u22121, achieved by applying a voltage of the order of 1 volt between conductors spaced 1 \u00b5m apart.\n\n\n== Electrodynamic fields ==\n\nElectrodynamic fields are electric fields which do change with time, for instance when charges are in motion. In this case, a magnetic field is produced in accordance with Amp\u00e8re's circuital law (with Maxwell's addition), which, along with Maxwell's other equations, defines the magnetic field, \n  \n    \n      \n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {B} }\n  , in terms of its curl:\n\nwhere \n  \n    \n      \n        \n          J\n        \n      \n    \n    {\\displaystyle \\mathbf {J} }\n   is the current density, \n  \n    \n      \n        \n          \u03bc\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mu _{0}}\n   is the vacuum permeability, and \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   is the vacuum permittivity.\nThat is, both electric currents (i.e. charges in uniform motion) and the (partial) time derivative of the electric field directly contributes to the magnetic field. In addition, the Maxwell\u2013Faraday equation states \n\nThese represent two of Maxwell's four equations and they intricately link the electric and magnetic fields together, resulting in the electromagnetic field. The equations represent a set of four coupled multi-dimensional partial differential equations which, when solved for a system, describe the combined behavior of the electromagnetic fields. In general, the force experienced by a test charge in an electromagnetic field is given by the Lorentz force law:\n\n\n== Energy in the electric field ==\nThe total energy per unit volume stored by the electromagnetic field is\nwhere \u03b5 is the permittivity of the medium in which the field exists, \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   its magnetic permeability, and E and B are the electric and magnetic field vectors.\nAs E and B fields are coupled, it would be misleading to split this expression into \"electric\" and \"magnetic\" contributions. In particular, an electrostatic field in any given frame of reference in general transforms into a field with a magnetic component in a relatively moving frame. Accordingly, decomposing the electromagnetic field into an electric and magnetic component is frame-specific, and similarly for the associated energy.\nThe total energy UEM stored in the electromagnetic field in a given volume V is\n\n\n== The electric displacement field ==\n\n\n=== Definitive equation of vector fields ===\n\nIn the presence of matter, it is helpful to extend the notion of the electric field into three vector fields:\nwhere P is the electric polarization \u2013 the volume density of electric dipole moments, and D is the electric displacement field. Since E and P are defined separately, this equation can be used to define D. The physical interpretation of D is not as clear as E (effectively the field applied to the material) or P (induced field due to the dipoles in the material), but still serves as a convenient mathematical simplification, since Maxwell's equations can be simplified in terms of free charges and currents.\n\n\n=== Constitutive relation ===\n\nThe E and D fields are related by the permittivity of the material, \u03b5.For linear, homogeneous, isotropic materials E and D are proportional and constant throughout the region, there is no position dependence: \n\nFor inhomogeneous materials, there is a position dependence throughout the material:\nFor anisotropic materials the E and D fields are not parallel, and so E and D are related by the permittivity tensor (a 2nd order tensor field), in component form:\n\nFor non-linear media, E and D are not proportional. Materials can have varying extents of linearity, homogeneity and isotropy.\n\n\n== Relativistic Effects on electric field ==\n\n\n=== Point charge in uniform motion ===\nThe invariance of the form of Maxwell's equations under Lorentz transformation can be used to derive the electric field of a uniformly moving point charge. The charge of a particle is considered frame invariant, as supported by experimental evidence. Alternatively the electric field of uniformly moving point charges can be derived from the Lorentz transformation of four-force experienced by test charges in the source's rest frame given by Coulomb's law and assigning electric field and magnetic field by their definition given by the form of Lorentz force. However the following equation is only applicable when no acceleration is involved in the particle's history where Coulomb's law can be considered or symmetry arguments can be used for solving Maxwell's equations in a simple manner. The electric field of such a uniformly moving point charge is hence given by:\nwhere \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the charge of the point source, \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is the position vector from the point source to the point in space, \n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is the ratio of observed speed of the charge particle to the speed of light and \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   and the observed velocity of the charged particle. \nThe above equation reduces to that given by Coulomb's law for non-relativistic speeds of the point charge. Spherically symmetry is not satisfied due to breaking of symmetry in the problem by specification of direction of velocity for calculation of field. To illustrate this, field lines of moving charges are sometimes represented as unequally spaced radial lines which would appear equally spaced in a co-moving reference frame.\n\n\n=== Propagation of disturbances in electric fields ===\n\nSpecial theory of relativity imposes the principle of locality, that requires cause and effect to be time-like separated events where the causal efficacy does not travel faster than the speed of light. Maxwell's laws are found to confirm to this view since the general solutions of fields are given in terms of retarded time which indicate that electromagnetic disturbances travel at the speed of light. Advanced time, which also provides a solution for Maxwell's law are ignored as an unphysical solution.For the motion of a charged particle, considering for example the case of a moving particle with the above described electric field coming to an abrupt stop, the electric fields at points far from it do not immediately revert to that classically given for a stationary charge. On stopping, the field around the stationary points begin to revert to the expected state and this effect propagates outwards at the speed of light while the electric field lines far away from this will continue to point radially towards an assumed moving charge. This virtual particle will never be outside the range of propagation of the disturbance in electromagnetic field, since charged particles are restricted to have speeds slower than that of light, which makes it impossible to construct a Gaussian surface in this region that violates Gauss' law. Another technical difficulty that supports this is that charged particles travelling faster than or equal to speed of light no longer have a unique retarded time. Since electric field lines are continuous, an electromagnetic pulse of radiation is generated that connects at the boundary of this disturbance travelling outwards at the speed of light. In general, any accelerating point charge radiates electromagnetic waves however, non-radiating acceleration is possible in a systems of charges.\n\n\n=== Arbitrarily moving point charge ===\n\nFor arbitrarily moving point charges, propagation of potential fields such as Lorenz gauge fields at the speed of light needs to be accounted for by using Li\u00e9nard\u2013Wiechert potential. Since the potentials satisfy Maxwell's equations, the fields derived for point charge also satisfy Maxwell's equations. The electric field is expressed as:\nwhere \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the charge of the point source, \n  \n    \n      \n        \n          \n            t\n            \n              r\n            \n          \n        \n      \n    \n    {\\textstyle {t_{r}}}\n   is retarded time or the time at which the source's contribution of the electric field originated, \n  \n    \n      \n        \n          \n            r\n          \n          \n            s\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\textstyle {r}_{s}(t)}\n   is the position vector of the particle, \n  \n    \n      \n        \n          \n            n\n          \n          \n            s\n          \n        \n        (\n        \n          r\n        \n        ,\n        t\n        )\n      \n    \n    {\\textstyle {n}_{s}(\\mathbf {r} ,t)}\n   is a unit vector pointing from charged particle to the point in space, \n  \n    \n      \n        \n          \n            \u03b2\n          \n          \n            s\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\textstyle {\\boldsymbol {\\beta }}_{s}(t)}\n   is the velocity of the particle divided by the speed of light, and \n  \n    \n      \n        \u03b3\n        (\n        t\n        )\n      \n    \n    {\\textstyle \\gamma (t)}\n   is the corresponding Lorentz factor. The retarded time is given as solution of:\n\n  \n    \n      \n        \n          t\n          \n            r\n          \n        \n        =\n        \n          t\n        \n        \u2212\n        \n          \n            \n              \n                |\n              \n              \n                r\n              \n              \u2212\n              \n                \n                  r\n                \n                \n                  s\n                \n              \n              (\n              \n                t\n                \n                  r\n                \n              \n              )\n              \n                |\n              \n            \n            c\n          \n        \n      \n    \n    {\\displaystyle t_{r}=\\mathbf {t} -{\\frac {|\\mathbf {r} -\\mathbf {r} _{s}(t_{r})|}{c}}}\n  \nThe uniqueness of solution for \n  \n    \n      \n        \n          \n            t\n            \n              r\n            \n          \n        \n      \n    \n    {\\textstyle {t_{r}}}\n   for given \n  \n    \n      \n        \n          t\n        \n      \n    \n    {\\displaystyle \\mathbf {t} }\n  , \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   and \n  \n    \n      \n        \n          r\n          \n            s\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle r_{s}(t)}\n   is valid for charged particles moving slower than speed of light. Electromagnetic radiation of accelerating charges is known to be caused by the acceleration dependent term in the electric field from which relativistic correction for Larmor formula is obtained.There exist yet another set of solutions for Maxwell's equation of the same form but for advanced time \n  \n    \n      \n        \n          \n            t\n            \n              a\n            \n          \n        \n      \n    \n    {\\textstyle {t_{a}}}\n   instead of retarded time given as a solution of:\n\n  \n    \n      \n        \n          t\n          \n            a\n          \n        \n        =\n        \n          t\n        \n        +\n        \n          \n            \n              \n                |\n              \n              \n                r\n              \n              \u2212\n              \n                \n                  r\n                \n                \n                  s\n                \n              \n              (\n              \n                t\n                \n                  a\n                \n              \n              )\n              \n                |\n              \n            \n            c\n          \n        \n      \n    \n    {\\displaystyle t_{a}=\\mathbf {t} +{\\frac {|\\mathbf {r} -\\mathbf {r} _{s}(t_{a})|}{c}}}\n  \nSince the physical interpretation of this indicates that the electric field at a point is governed by the particle's state at a point of time in the future, it is considered as an unphysical solution and hence neglected. However, there have been theories exploring the advanced time solutions of Maxwell's equations, such as Feynman Wheeler absorber theory.\nThe above equation, although consistent with that of uniformly moving point charges as well as its non-relativistic limit, are not corrected for quantum-mechanical effects.\n\n\n== Some common electric field values ==\nInfinite wire having uniform charge density \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   from it as \n  \n    \n      \n        \n          \n            \n              2\n              K\n              \u03bb\n            \n            x\n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {2K\\lambda }{x}}{\\hat {x}}}\n  \nInfinitely large surface having charge density \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   from it as \n  \n    \n      \n        \n          \n            \u03c3\n            \n              2\n              \n                \u03f5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sigma }{2\\epsilon _{0}}}{\\hat {x}}}\n  \nInfinitely long cylinder having Uniform charge density \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   that is charge contained along unit length of the cylinder has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   from it as \n  \n    \n      \n        \n          \n            \n              2\n              K\n              \u03bb\n            \n            x\n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {2K\\lambda }{x}}{\\hat {x}}}\n   while it is \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n   everywhere inside the cylinder\nUniformly charged non-conducting sphere of radius \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  , volume charge density \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   and total charge \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   from it as \n  \n    \n      \n        \n          \n            \n              K\n              Q\n            \n            \n              x\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {KQ}{x^{2}}}{\\hat {x}}}\n   while the electric field at a point \n  \n    \n      \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}}\n   inside sphere from its center is given by \n  \n    \n      \n        \n          \n            \n              K\n              Q\n            \n            \n              R\n              \n                3\n              \n            \n          \n        \n        \n          \n            \n              r\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {KQ}{R^{3}}}{\\vec {r}}}\n  \nUniformly charged conducting sphere of radius \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  , surface charge density \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   and total charge \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   from it as \n  \n    \n      \n        \n          \n            \n              K\n              Q\n            \n            \n              x\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {KQ}{x^{2}}}{\\hat {x}}}\n   while the electric field inside is \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \nElectric field infinitely close to a conducting surface in electrostatic equilibrium having charge density \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   at that point is \n  \n    \n      \n        \n          \n            \u03c3\n            \n              \u03f5\n              \n                0\n              \n            \n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sigma }{\\epsilon _{0}}}{\\hat {x}}}\n  \nUniformly charged ring having total charge \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   along its axis as \n  \n    \n      \n        \n          \n            \n              K\n              Q\n              x\n            \n            \n              (\n              \n                R\n                \n                  2\n                \n              \n              +\n              \n                x\n                \n                  2\n                \n              \n              \n                )\n                \n                  3\n                  \n                    /\n                  \n                  2\n                \n              \n            \n          \n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {KQx}{(R^{2}+x^{2})^{3/2}}}{\\hat {x}}}\n  '\nUniformly charged disc of radius \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   and charge density \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   has electric field at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   along its axis from it as \n  \n    \n      \n        \n          \n            \u03c3\n            \n              2\n              \n                \u03f5\n                \n                  0\n                \n              \n            \n          \n        \n        \n          [\n          \n            1\n            \u2212\n            \n              \n                (\n                \n                  \n                    \n                      \n                        R\n                        \n                          2\n                        \n                      \n                      \n                        x\n                        \n                          2\n                        \n                      \n                    \n                  \n                  \u2212\n                  1\n                \n                )\n              \n              \n                \u2212\n                1\n                \n                  /\n                \n                2\n              \n            \n          \n          ]\n        \n        \n          \n            \n              x\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sigma }{2\\epsilon _{0}}}\\left[1-\\left({\\frac {R^{2}}{x^{2}}}-1\\right)^{-1/2}\\right]{\\hat {x}}}\n  \nElectric field due to dipole of dipole moment \n  \n    \n      \n        \n          \n            \n              p\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {p}}}\n   at a distance \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   from their center along equatorial plane is given as \n  \n    \n      \n        \u2212\n        \n          \n            \n              K\n              \n                \n                  \n                    p\n                    \u2192\n                  \n                \n              \n            \n            \n              x\n              \n                3\n              \n            \n          \n        \n      \n    \n    {\\displaystyle -{\\frac {K{\\vec {p}}}{x^{3}}}}\n   and the same along the axial line is approximated to \n  \n    \n      \n        \n          \n            \n              2\n              K\n              \n                \n                  \n                    p\n                    \u2192\n                  \n                \n              \n            \n            \n              x\n              \n                3\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {2K{\\vec {p}}}{x^{3}}}}\n   for \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   much bigger than the distance between dipoles. Further generalization is given by multipole expansion.\n\n\n== See also ==\nClassical electromagnetism\nRelativistic electromagnetism\nElectricity\nHistory of electromagnetic theory\nElectromagnetic field\nMagnetism\nTeltron tube\nTeledeltos, a conductive paper that may be used as a simple analog computer for modelling fields\n\n\n== References ==\n\nPurcell, Edward; Morin, David (2013). Electricity and Magnetism (3rd ed.). Cambridge University Press, New York. ISBN 978-1-107-01402-2.\nBrowne, Michael (2011). Physics for Engineering and Science (2nd ed.). McGraw-Hill, Schaum, New York. ISBN 978-0-07-161399-6.\n\n\n== External links ==\n\nElectric field in \"Electricity and Magnetism\", R Nave \u2013 Hyperphysics, Georgia State University\nFrank Wolfs's lectures at University of Rochester, chapters 23 and 24\nFields \u2013 a chapter from an online textbook", "Field_line": "A field line is a graphical visual aid for visualizing vector fields. It consists of an imaginary integral curve which is tangent to the field vector at each point along its length.   A diagram showing a representative set of neighboring field lines is a common way of depicting a vector field in scientific and mathematical literature; this is called a field line diagram.  They are used to show electric fields, magnetic fields, and gravitational fields among many other types.  In fluid mechanics field lines showing the velocity field of a fluid flow are called streamlines.\n\n\n== Definition and description ==\n\nA vector field defines a direction and magnitude at each point in space.  A field line is an integral curve for that vector field and may be constructed by starting at a point and tracing a line through space that follows the direction of the vector field, by making the field line tangent to the field vector at each point.  A field line is usually shown as a directed line segment, with an arrowhead indicating the direction of the vector field.  For two-dimensional fields the field lines are plane curves; since a plane drawing of a 3-dimensional set of field lines can be visually confusing most field line diagrams are of this type.  Since at each point where it is nonzero and finite the vector field has a unique direction, field lines can never intersect, so there is exactly one field line passing through each point at which the vector field is nonzero and finite.  Points where the field is zero or infinite have no field line through them, since direction cannot be defined there, but can be the endpoints of field lines.  \nSince there are an infinite number of points in any region, an infinite number of field lines can be drawn; but only a limited number can be shown on a field line diagram.  Therefore which field lines are shown is a choice made by the person or computer program which draws the diagram, and a single vector field may be depicted by different sets of field lines.  A field line diagram is necessarily an incomplete description of a vector field, since it gives no information about the field between the drawn field lines, and the choice of how many and which lines to show determines how much useful information the diagram gives. \nAn individual field line shows the direction of the vector field but not the magnitude. In order to also depict the magnitude of the field, field line diagrams are often drawn so that each line represents the same quantity of flux.  Then the density of field lines (number of field lines per unit perpendicular area) at any location is proportional to the magnitude of the vector field at that point.  Areas in which neighboring field lines are converging (getting closer together) indicates that the field is getting stronger in that direction. \nIn vector fields which have nonzero divergence, field lines begin on points of positive divergence (sources) and end on points of negative divergence (sinks), or extend to infinity.  For example, electric field lines begin on positive charges and end on negative charges.  In fields which are divergenceless (solenoidal), such as magnetic fields, field lines have no endpoints; they are either closed loops or are endless.In physics, drawings of field lines are mainly useful in cases where the sources and sinks, if any, have a physical meaning, as opposed to e.g. the case of a force field of a radial harmonic. For example, Gauss's law states that an electric field has sources at positive charges, sinks at negative charges, and neither elsewhere, so electric field lines start at positive charges and end at negative charges. A gravitational field has no sources, it has sinks at masses, and it has neither elsewhere, gravitational field lines come from infinity and end at masses. A magnetic field has no sources or sinks (Gauss's law for magnetism), so its field lines have no start or end: they can only form closed loops, extend to infinity in both directions, or continue indefinitely without ever crossing itself. However, as stated above, a special situation may occur around points where the field is zero (that cannot be intersected by field lines, because their direction would not be defined) and the simultaneous begin and end of field lines takes place. This situation happens, for instance, in the middle between two identical positive electric point charges. There, the field vanishes and the lines coming axially from the charges end. At the same time, in the transverse plane passing through the middle point, an infinite number of field lines diverge radially. The concomitant presence of the lines that end and begin preserves the divergence-free character of the field in the point.Note that for this kind of drawing, where the field-line density is intended to be proportional to the field magnitude, it is important to represent all three dimensions. For example, consider the electric field arising from a single, isolated point charge. The electric field lines in this case are straight lines that emanate from the charge uniformly in all directions in three-dimensional space. This means that their density is proportional to \n  \n    \n      \n        1\n        \n          /\n        \n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 1/r^{2}}\n  , the correct result consistent with Coulomb's law for this case. However, if the electric field lines for this setup were just drawn on a two-dimensional plane, their two-dimensional density would be proportional to \n  \n    \n      \n        1\n        \n          /\n        \n        r\n      \n    \n    {\\displaystyle 1/r}\n  , an incorrect result for this situation.\n\n\n== Construction ==\n\nGiven a vector field \n  \n    \n      \n        \n          F\n        \n        (\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {x} )}\n   and a starting point \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{\\text{0}}}\n   a field line can be constructed iteratively by finding the field vector at that point \n  \n    \n      \n        \n          F\n        \n        (\n        \n          \n            x\n          \n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {x} _{\\text{0}})}\n  . The unit tangent vector at that point is: \n  \n    \n      \n        \n          F\n        \n        (\n        \n          \n            x\n          \n          \n            0\n          \n        \n        )\n        \n          /\n        \n        \n          |\n        \n        \n          F\n        \n        (\n        \n          \n            x\n          \n          \n            0\n          \n        \n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {x} _{\\text{0}})/|\\mathbf {F} (\\mathbf {x} _{\\text{0}})|}\n  .  By moving a short distance \n  \n    \n      \n        d\n        s\n      \n    \n    {\\displaystyle ds}\n   along the field direction a new point on the line can be found\n\nThen the field at that point \n  \n    \n      \n        \n          F\n        \n        (\n        \n          \n            x\n          \n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {x} _{\\text{1}})}\n   is found and moving a further distance \n  \n    \n      \n        d\n        s\n      \n    \n    {\\displaystyle ds}\n   in that direction the next point \n  \n    \n      \n        \n          F\n        \n        (\n        \n          \n            x\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {x} _{\\text{2}})}\n   of the field line is found.  At each point \n  \n    \n      \n        \n          \n            x\n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{\\text{i}}}\n   the next point can be found by\n\nBy repeating this and connecting the points, the field line can be extended as far as desired.  This is only an approximation to the actual field line, since each straight segment isn't actually tangent to the field along its length, just at its starting point.   But by using a small enough value for \n  \n    \n      \n        d\n        s\n      \n    \n    {\\displaystyle ds}\n  , taking a greater number of shorter steps, the field line can be approximated as closely as desired.  The field line can be extended in the opposite direction from \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{\\text{0}}}\n   by taking each step in the opposite direction by using a negative step \n  \n    \n      \n        \u2212\n        d\n        s\n      \n    \n    {\\displaystyle -ds}\n  .\n\n\n== Examples ==\n\nIf the vector field describes a velocity field, then the field lines follow stream lines in the flow.  Perhaps the most familiar example of a vector field described by field lines is the magnetic field, which is often depicted using field lines emanating from a magnet.\n\n\n== Divergence and curl ==\nField lines can be used to trace familiar quantities from vector calculus:\n\nDivergence may be easily seen through field lines, assuming the lines are drawn such that the density of field lines is proportional to the magnitude of the field (see above). In this case, the divergence may be seen as the beginning and ending of field lines. If the vector field is the resultant of radial inverse-square law fields with respect to one or more sources then this corresponds to the fact that the divergence of such a field is zero outside the sources. In a solenoidal vector field (i.e., a vector field where the divergence is zero everywhere), the field lines neither begin nor end; they either form closed loops, or go off to infinity in both directions. If a vector field has positive divergence in some area, there will be field lines starting from points in that area. If a vector field has negative divergence in some area, there will be field lines ending at points in that area.\nThe Kelvin\u2013Stokes theorem shows that field lines of a vector field with zero curl (i.e., a conservative vector field, e.g. a gravitational field or an electrostatic field) cannot be closed loops. In other words, curl is always present when a field line forms a closed loop. It may be present in other situations too, such as a helical shape of field lines.\n\n\n== Physical significance ==\n\nWhile field lines are a \"mere\" mathematical construction, in some circumstances they take on physical significance.  In fluid mechanics, the velocity field lines (streamlines) in steady flow represent the paths of particles of the fluid. In the context of plasma physics, electrons or ions that happen to be on the same field line interact strongly, while particles on different field lines in general do not interact. This is the same behavior that the particles of iron filings exhibit in a magnetic field.\nThe iron filings in the photo appear to be aligning themselves with discrete field lines, but the situation is more complex. It is easy to visualize as a two-stage-process: first, the filings are spread evenly over the magnetic field but all aligned in the direction of the field. Then, based on the scale and ferromagnetic properties of the filings they damp the field to either side, creating the apparent spaces between the lines that we see.  Of course the two stages described here happen concurrently until an equilibrium is achieved. Because the intrinsic magnetism of the filings modifies the field, the lines shown by the filings are only an approximation of the field lines of the original magnetic field. Magnetic fields are continuous, and do not have discrete lines.\n\n\n== See also ==\nForce field (physics)\nField lines of Julia sets\nExternal ray \u2014 field lines of Douady\u2013Hubbard potential of Mandelbrot set or filled-in Julia sets\nLine of force\nVector field\nLine integral convolution\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\n\nInteractive Java applet showing the electric field lines of selected pairs of charges Archived 2011-08-13 at the Wayback Machine by Wolfgang Bauer\n\"Visualization of Fields and the Divergence and Curl\" course notes from a course at the Massachusetts Institute of Technology.", "Equations_of_motion": "In physics, equations of motion are equations that describe the behavior of a physical system in terms of its motion as a function of time. More specifically, the equations of motion describe the behavior of a physical system as a set of mathematical functions in terms of dynamic variables. These variables are usually spatial coordinates and time, but may include momentum components. The most general choice are generalized coordinates which can be any convenient variables characteristic of the physical system. The functions are defined in a Euclidean space in classical mechanics, but are replaced by curved spaces in relativity. If the dynamics of a system is known, the equations are the solutions for the differential equations describing the motion of the dynamics.\n\n\n== Types ==\nThere are two main descriptions of motion: dynamics and kinematics. Dynamics is general, since the momenta, forces and energy of the particles are taken into account. In this instance, sometimes the term dynamics refers to the differential equations that the system satisfies (e.g., Newton's second law or Euler\u2013Lagrange equations), and sometimes to the solutions to those equations.\nHowever, kinematics is simpler. It concerns only variables derived from the positions of objects and time. In circumstances of constant acceleration, these simpler equations of motion are usually referred to as the SUVAT equations, arising from the definitions of kinematic quantities: displacement (s), initial velocity (u), final velocity (v), acceleration (a), and time (t).\nA differential equation of motion, usually identified as some physical law and applying definitions of physical quantities, is used to set up an equation for the problem. Solving the differential equation will lead to a general solution with arbitrary constants, the arbitrariness corresponding to a family of solutions. A particular solution can be obtained by setting the initial values, which fixes the values of the constants.\nTo state this formally, in general an equation of motion M is a function of the position r of the object, its velocity (the first time derivative of r, v = dr/dt), and its acceleration (the second derivative of r, a = d2r/dt2), and time t. Euclidean vectors in 3D are denoted throughout in bold. This is equivalent to saying an equation of motion in r is a second-order ordinary differential equation (ODE) in r,\n\nwhere t is time, and each overdot denotes one time derivative. The initial conditions are given by the constant values at t = 0,\n\nThe solution r(t) to the equation of motion, with specified initial values, describes the system for all times t after t = 0. Other dynamical variables like the momentum p of the object, or quantities derived from r and p like angular momentum, can be used in place of r as the quantity to solve for from some equation of motion, although the position of the object at time t is by far the most sought-after quantity.\nSometimes, the equation will be linear and is more likely to be exactly solvable. In general, the equation will be non-linear, and cannot be solved exactly so a variety of approximations must be used. The solutions to nonlinear equations may show chaotic behavior depending on how sensitive the system is to the initial conditions.\n\n\n== History ==\nKinematics, dynamics and the mathematical models of the universe developed incrementally over three millennia, thanks to many thinkers, only some of whose names we know. In antiquity, priests, astrologers and astronomers predicted solar and lunar eclipses, the solstices and the equinoxes of the Sun and the period of the Moon. But they had nothing other than a set of algorithms to guide them. Equations of motion were not written down for another thousand years.\nMedieval scholars in the thirteenth century \u2014 for example at the relatively new universities in Oxford and Paris \u2014 drew on ancient mathematicians (Euclid and Archimedes) and philosophers (Aristotle) to develop a new body of knowledge, now called physics.\nAt Oxford, Merton College sheltered a group of scholars devoted to natural science, mainly physics, astronomy and mathematics, who were of similar stature to the intellectuals at the University of Paris. Thomas Bradwardine extended Aristotelian quantities such as distance and velocity, and assigned intensity and extension to them. Bradwardine suggested an exponential law involving force, resistance, distance, velocity and time. Nicholas Oresme further extended Bradwardine's arguments. The Merton school proved that the quantity of motion of a body undergoing a uniformly accelerated motion is equal to the quantity of a uniform motion at the speed achieved halfway through the accelerated motion.\nFor writers on kinematics before Galileo, since small time intervals could not be measured, the affinity between time and motion was obscure. They used time as a function of distance, and in free fall, greater velocity as a result of greater elevation. Only Domingo de Soto, a Spanish theologian, in his commentary on Aristotle's Physics published in 1545, after defining \"uniform difform\" motion (which is uniformly accelerated motion) \u2013 the word velocity wasn't used \u2013 as proportional to time, declared correctly that this kind of motion was identifiable with freely falling bodies and projectiles, without his proving these propositions or suggesting a formula relating time, velocity and distance. De Soto's comments are remarkably correct regarding the definitions of acceleration (acceleration was a rate of change of motion (velocity) in time) and the observation that acceleration would be negative during ascent.\nDiscourses such as these spread throughout Europe, shaping the work of Galileo Galilei and others, and helped in laying the foundation of kinematics. Galileo deduced the equation s = 1/2gt2 in his work geometrically, using the Merton rule, now known as a special case of one of the equations of kinematics.\nGalileo was the first to show that the path of a projectile is a parabola. Galileo had an understanding of centrifugal force and gave a correct definition of momentum. This emphasis of momentum as a fundamental quantity in dynamics is of prime importance. He measured momentum by the product of velocity and weight; mass is a later concept, developed by Huygens and Newton. In the swinging of a simple pendulum, Galileo says in Discourses that \"every momentum acquired in the descent along an arc is equal to that which causes the same moving body to ascend through the same arc.\" His analysis on projectiles indicates that Galileo had grasped the first law and the second law of motion. He did not generalize and make them applicable to bodies not subject to the earth's gravitation. That step was Newton's contribution.\nThe term \"inertia\" was used by Kepler who applied it to bodies at rest. (The first law of motion is now often called the law of inertia.)\nGalileo did not fully grasp the third law of motion, the law of the equality of action and reaction, though he corrected some errors of Aristotle. With Stevin and others Galileo also wrote on statics. He formulated the principle of the parallelogram of forces, but he did not fully recognize its scope.\nGalileo also was interested by the laws of the pendulum, his first observations of which were as a young man. In 1583, while he was praying in the cathedral at Pisa, his attention was arrested by the motion of the great lamp lighted and left swinging, referencing his own pulse for time keeping. To him the period appeared the same, even after the motion had greatly diminished, discovering the isochronism of the pendulum.\nMore careful experiments carried out by him later, and described in his Discourses, revealed the period of oscillation varies with the square root of length but is independent of the mass the pendulum.\nThus we arrive at Ren\u00e9 Descartes, Isaac Newton, Gottfried Leibniz, et al.; and the evolved forms of the equations of motion that begin to be recognized as the modern ones.\nLater the equations of motion also appeared in electrodynamics, when describing the motion of charged particles in electric and magnetic fields, the Lorentz force is the general equation which serves as the definition of what is meant by an electric field and magnetic field. With the advent of special relativity and general relativity, the theoretical modifications to spacetime meant the classical equations of motion were also modified to account for the finite speed of light, and curvature of spacetime. In all these cases the differential equations were in terms of a function describing the particle's trajectory in terms of space and time coordinates, as influenced by forces or energy transformations.However, the equations of quantum mechanics can also be considered \"equations of motion\", since they are differential equations of the wavefunction, which describes how a quantum state behaves analogously using the space and time coordinates of the particles. There are analogs of equations of motion in other areas of physics, for collections of physical phenomena that can be considered waves, fluids, or fields.\n\n\n== Kinematic equations for one particle ==\n\n\n=== Kinematic quantities ===\n\nFrom the instantaneous position r = r(t), instantaneous meaning at an instant value of time t, the instantaneous velocity v = v(t) and acceleration a = a(t) have the general, coordinate-independent definitions;\nNotice that velocity always points in the direction of motion, in other words for a curved path it is the tangent vector. Loosely speaking, first order derivatives are related to tangents of curves. Still for curved paths, the acceleration is directed towards the center of curvature of the path. Again, loosely speaking, second order derivatives are related to curvature.\nThe rotational analogues are the \"angular vector\" (angle the particle rotates about some axis) \u03b8 = \u03b8(t), angular velocity \u03c9 = \u03c9(t), and angular acceleration \u03b1 = \u03b1(t):\n\nwhere n\u0302 is a unit vector in the direction of the axis of rotation, and \u03b8 is the angle the object turns through about the axis.\nThe following relation holds for a point-like particle, orbiting about some axis with angular velocity \u03c9:\nwhere r is the position vector of the particle (radial from the rotation axis) and v the tangential velocity of the particle. For a rotating continuum rigid body, these relations hold for each point in the rigid body.\n\n\n=== Uniform acceleration ===\nThe differential equation of motion for a particle of constant or uniform acceleration in a straight line is simple: the acceleration is constant, so the second derivative of the position of the object is constant. The results of this case are summarized below.\n\n\n==== Constant translational acceleration in a straight line ====\nThese equations apply to a particle moving linearly, in three dimensions in a straight line with constant acceleration. Since the position, velocity, and acceleration are collinear (parallel, and lie on the same line) \u2013 only the magnitudes of these vectors are necessary, and because the motion is along a straight line, the problem effectively reduces from three dimensions to one.\n\nwhere:\n\nr0 is the particle's initial position\nr is the particle's final position\nv0 is the particle's initial velocity\nv is the particle's final velocity\na is the particle's acceleration\nt is the time interval\nHere a is constant acceleration, or in the case of bodies moving under the influence of gravity, the standard gravity g is used. Note that each of the equations contains four of the five variables, so in this situation it is sufficient to know three out of the five variables to calculate the remaining two.\nIn elementary physics the same formulae are frequently written in different notation as:\n\nwhere u has replaced v0, s replaces r - r0. They are often referred to as the SUVAT equations, where \"SUVAT\" is an acronym from the variables: s = displacement, u = initial velocity, v = final velocity, a = acceleration, t = time.\n\n\n==== Constant linear acceleration in any direction ====\n\nThe initial position, initial velocity, and acceleration vectors need not be collinear, and take an almost identical form. The only difference is that the square magnitudes of the velocities require the dot product. The derivations are essentially the same as in the collinear case,\n\nalthough the Torricelli equation [4] can be derived using the distributive property of the dot product as follows:\n\n\n==== Applications ====\nElementary and frequent examples in kinematics involve projectiles, for example a ball thrown upwards into the air. Given initial speed u, one can calculate how high the ball will travel before it begins to fall. The acceleration is local acceleration of gravity g. While these quantities appear to be scalars, the direction of displacement, speed and acceleration is important. They could in fact be considered as unidirectional vectors. Choosing s to measure up from the ground, the acceleration a must be in fact \u2212g, since the force of gravity acts downwards and therefore also the acceleration on the ball due to it.\nAt the highest point, the ball will be at rest: therefore v = 0. Using equation [4] in the set above, we have:\n\nSubstituting and cancelling minus signs gives:\n\n\n==== Constant circular acceleration ====\nThe analogues of the above equations can be written for rotation. Again these axial vectors must all be parallel to the axis of rotation, so only the magnitudes of the vectors are necessary,\n\nwhere \u03b1 is the constant angular acceleration, \u03c9 is the angular velocity, \u03c90 is the initial angular velocity, \u03b8 is the angle turned through (angular displacement), \u03b80 is the initial angle, and t is the time taken to rotate from the initial state to the final state.\n\n\n=== General planar motion ===\n\nThese are the kinematic equations for a particle traversing a path in a plane, described by position r = r(t). They are simply the time derivatives of the position vector in plane polar coordinates using the definitions of physical quantities above for angular velocity \u03c9 and angular acceleration \u03b1. These are instantaneous quantities which change with time.\nThe position of the particle is\n\nwhere \u00ear and \u00ea\u03b8 are the polar unit vectors. Differentiating with respect to time gives the velocity\n\nwith radial component dr/dt and an additional component r\u03c9 due to the rotation. Differentiating with respect to time again obtains the acceleration \n\nwhich breaks into the radial acceleration d2r/dt2, centripetal acceleration \u2013r\u03c92, Coriolis acceleration 2\u03c9dr/dt, and angular acceleration r\u03b1.\nSpecial cases of motion described by these equations are summarized qualitatively in the table below. Two have already been discussed above, in the cases that either the radial components or the angular components are zero, and the non-zero component of motion describes uniform acceleration.\n\n\n=== General 3D motions ===\n\nIn 3D space, the equations in spherical coordinates (r, \u03b8, \u03c6) with corresponding unit vectors \u00ear, \u00ea\u03b8 and \u00ea\u03c6, the position, velocity, and acceleration generalize respectively to\n\nIn the case of a constant \u03c6 this reduces to the planar equations above.\n\n\n== Dynamic equations of motion ==\n\n\n=== Newtonian mechanics ===\n\nThe first general equation of motion developed was Newton's second law of motion.  In its most general form it states the rate of change of momentum p = p(t) = mv(t) of an object equals the force F = F(x(t), v(t), t) acting on it,:\u200a1112\u200a\nThe force in the equation is not the force the object exerts. Replacing momentum by mass times velocity, the law is also written more famously as\n\nsince m is a constant in Newtonian mechanics.\nNewton's second law applies to point-like particles, and to all points in a rigid body. They also apply to each point in a mass continuum, like deformable solids or fluids, but the motion of the system must be accounted for; see material derivative. In the case the mass is not constant, it is not sufficient to use the product rule for the time derivative on the mass and velocity, and Newton's second law requires some modification consistent with conservation of momentum; see variable-mass system.\nIt may be simple to write down the equations of motion in vector form using Newton's laws of motion, but the components may vary in complicated ways with spatial coordinates and time, and solving them is not easy. Often there is an excess of variables to solve for the problem completely, so Newton's laws are not always the most efficient way to determine the motion of a system. In simple cases of rectangular geometry, Newton's laws work fine in Cartesian coordinates, but in other coordinate systems can become dramatically complex.\nThe momentum form is preferable since this is readily generalized to more complex systems, such as special and general relativity (see four-momentum).:\u200a112\u200a It can also be used with the momentum conservation. However, Newton's laws are not more fundamental than momentum conservation, because Newton's laws are merely consistent with the fact that zero resultant force acting on an object implies constant momentum, while a resultant force implies the momentum is not constant. Momentum conservation is always true for an isolated system not subject to resultant forces.\nFor a number of particles (see many body problem), the equation of motion for one particle i influenced by other particles is\nwhere pi is the momentum of particle i, Fij is the force on particle i by particle j, and FE is the resultant external force due to any agent not part of system. Particle i does not exert a force on itself.\nEuler's laws of motion are similar to Newton's laws, but they are applied specifically to the motion of rigid bodies. The Newton\u2013Euler equations combine the forces and torques acting on a rigid body into a single equation.\nNewton's second law for rotation takes a similar form to the translational case,\nby equating the torque acting on the body to the rate of change of its angular momentum L. Analogous to mass times acceleration, the moment of inertia tensor I depends on the distribution of mass about the axis of rotation, and the angular acceleration is the rate of change of angular velocity,\n\nAgain, these equations apply to point like particles, or at each point of a rigid body.\nLikewise, for a number of particles, the equation of motion for one particle i is\nwhere Li is the angular momentum of particle i, \u03c4ij the torque on particle i by particle j, and \u03c4E is resultant external torque (due to any agent not part of system). Particle i does not exert a torque on itself.\n\n\n=== Applications ===\nSome examples of Newton's law include describing the motion of a simple pendulum,\n\nand a damped, sinusoidally driven harmonic oscillator,\n\nFor describing the motion of masses due to gravity, Newton's law of gravity can be combined with Newton's second law. For two examples, a ball of mass m thrown in the air, in air currents (such as wind) described by a vector field of resistive forces R = R(r, t),\n\nwhere G is the gravitational constant, M the mass of the Earth, and A = R/m is the acceleration of the projectile due to the air currents at position r and time t.\nThe classical N-body problem for N particles each interacting with each other due to gravity is a set of N nonlinear coupled second order ODEs,\n\nwhere i = 1, 2, ..., N labels the quantities (mass, position, etc.) associated with each particle.\n\n\n== Analytical mechanics ==\n\nUsing all three coordinates of 3D space is unnecessary if there are constraints on the system. If the system has N degrees of freedom, then one can use a set of N generalized coordinates q(t) = [q1(t), q2(t) ... qN(t)], to define the configuration of the system. They can be in the form of arc lengths or angles. They are a considerable simplification to describe motion, since they take advantage of the intrinsic constraints that limit the system's motion, and the number of coordinates is reduced to a minimum. The time derivatives of the generalized coordinates are the generalized velocities\n\nThe Euler\u2013Lagrange equations are\nwhere the Lagrangian is a function of the configuration q and its time rate of change dq/dt (and possibly time t)\n\nSetting up the Lagrangian of the system, then substituting into the equations and evaluating the partial derivatives and simplifying, a set of coupled N second order ODEs in the coordinates are obtained.\nHamilton's equations are\nwhere the Hamiltonian\n\nis a function of the configuration q and conjugate \"generalized\" momenta\n\nin which \u2202/\u2202q = (\u2202/\u2202q1, \u2202/\u2202q2, \u2026, \u2202/\u2202qN) is a shorthand notation for a vector of partial derivatives with respect to the indicated variables (see for example matrix calculus for this denominator notation), and possibly time t,\nSetting up the Hamiltonian of the system, then substituting into the equations and evaluating the partial derivatives and simplifying, a set of coupled 2N first order ODEs in the coordinates qi and momenta pi are obtained.\nThe Hamilton\u2013Jacobi equation is\nwhere\n\nis Hamilton's principal function, also called the classical action is a functional of L. In this case, the momenta are given by\n\nAlthough the equation has a simple general form, for a given Hamiltonian it is actually a single first order non-linear PDE, in N + 1 variables. The action S allows identification of conserved quantities for mechanical systems, even when the mechanical problem itself cannot be solved fully, because any differentiable symmetry of the action of a physical system has a corresponding conservation law, a theorem due to Emmy Noether.\nAll classical equations of motion can be derived from the variational principle known as Hamilton's principle of least action\n\nstating the path the system takes through the configuration space is the one with the least action S.\n\n\n== Electrodynamics ==\n\nIn electrodynamics, the force on a charged particle of charge q is the Lorentz force:\nCombining with Newton's second law gives a first order differential equation of motion, in terms of position of the particle:\n\nor its momentum:\n\nThe same equation can be obtained using the Lagrangian (and applying Lagrange's equations above) for a charged particle of mass m and charge q:\nwhere A and \u03d5 are the electromagnetic scalar and vector potential fields. The Lagrangian indicates an additional detail: the canonical momentum in Lagrangian mechanics is given by:\n\ninstead of just mv, implying the motion of a charged particle is fundamentally determined by the mass and charge of the particle. The Lagrangian expression was first used to derive the force equation.\nAlternatively the Hamiltonian (and substituting into the equations):\ncan derive the Lorentz force equation.\n\n\n== General relativity ==\n\n\n=== Geodesic equation of motion ===\n\nThe above equations are valid in flat spacetime. In curved spacetime, things become mathematically more complicated since there is no straight line; this is generalized and replaced by a geodesic of the curved spacetime (the shortest length of curve between two points). For curved manifolds with a metric tensor g, the metric provides the notion of arc length (see line element for details).  The differential arc length is given by::\u200a1199\u200a\nand the geodesic equation is a second-order differential equation in the coordinates.  The general solution is a family of geodesics::\u200a1200\u200a\nwhere \u0393\u2009\u03bc\u03b1\u03b2 is a Christoffel symbol of the second kind, which contains the metric (with respect to the coordinate system).\nGiven the mass-energy distribution provided by the stress\u2013energy tensor T\u2009\u03b1\u03b2, the Einstein field equations are a set of non-linear second-order partial differential equations in the metric, and imply the curvature of spacetime is equivalent to a gravitational field (see equivalence principle). Mass falling in curved spacetime is equivalent to a mass falling in a gravitational field - because gravity is a fictitious force. The relative acceleration of one geodesic to another in curved spacetime is given by the geodesic deviation equation:\n\nwhere \u03be\u03b1 = x2\u03b1 \u2212 x1\u03b1 is the separation vector between two geodesics, D/ds (not just d/ds) is the covariant derivative, and R\u03b1\u03b2\u03b3\u03b4 is the Riemann curvature tensor, containing the Christoffel symbols. In other words, the geodesic deviation equation is the equation of motion for masses in curved spacetime, analogous to the Lorentz force equation for charges in an electromagnetic field.:\u200a34\u201335\u200aFor flat spacetime, the metric is a constant tensor so the Christoffel symbols vanish, and the geodesic equation has the solutions of straight lines. This is also the limiting case when masses move according to Newton's law of gravity.\n\n\n=== Spinning objects ===\nIn general relativity, rotational motion is described by the relativistic angular momentum tensor, including the spin tensor, which enter the equations of motion under covariant derivatives with respect to proper time. The Mathisson\u2013Papapetrou\u2013Dixon equations describe the motion of spinning objects moving in a gravitational field.\n\n\n== Analogues for waves and fields ==\nUnlike the equations of motion for describing particle mechanics, which are systems of coupled ordinary differential equations, the analogous equations governing the dynamics of waves and fields are always partial differential equations, since the waves or fields are functions of space and time. For a particular solution, boundary conditions along with initial conditions need to be specified.\nSometimes in the following contexts, the wave or field equations are also called \"equations of motion\".\n\n\n=== Field equations ===\nEquations that describe the spatial dependence and time evolution of fields are called field equations. These include\n\nMaxwell's equations for the electromagnetic field,\nPoisson's equation for Newtonian gravitational or electrostatic field potentials,\nthe Einstein field equation for gravitation (Newton's law of gravity is a special case for weak gravitational fields and low velocities of particles).This terminology is not universal: for example although the Navier\u2013Stokes equations govern the velocity field of a fluid, they are not usually called \"field equations\", since in this context they represent the momentum of the fluid and are called the \"momentum equations\" instead.\n\n\n=== Wave equations ===\nEquations of wave motion are called wave equations. The solutions to a wave equation give the time-evolution and spatial dependence of the amplitude. Boundary conditions determine if the solutions describe traveling waves or standing waves.\nFrom classical equations of motion and field equations; mechanical, gravitational wave, and electromagnetic wave equations can be derived. The general linear wave equation in 3D is:\n\nwhere X = X(r, t) is any mechanical or electromagnetic field amplitude, say:\nthe transverse or longitudinal displacement of a vibrating rod, wire, cable, membrane etc.,\nthe fluctuating pressure of a medium, sound pressure,\nthe electric fields E or D, or the magnetic fields B or H,\nthe voltage V or current I in an alternating current circuit,and v is the phase velocity. Nonlinear equations model the dependence of phase velocity on amplitude, replacing v by v(X). There are other linear and nonlinear wave equations for very specific applications, see for example the Korteweg\u2013de Vries equation.\n\n\n=== Quantum theory ===\nIn quantum theory, the wave and field concepts both appear.\nIn quantum mechanics, in which particles also have wave-like properties according to wave\u2013particle duality, the analogue of the classical equations of motion (Newton's law, Euler\u2013Lagrange equation, Hamilton\u2013Jacobi equation, etc.) is the Schr\u00f6dinger equation in its most general form:\n\nwhere \u03a8 is the wavefunction of the system, \u0124 is the quantum Hamiltonian operator, rather than a function as in classical mechanics, and \u0127 is the Planck constant divided by 2\u03c0. Setting up the Hamiltonian and inserting it into the equation results in a wave equation, the solution is the wavefunction as a function of space and time. The Schr\u00f6dinger equation itself reduces to the Hamilton\u2013Jacobi equation when one considers the correspondence principle, in the limit that \u0127 becomes zero.\nThroughout all aspects of quantum theory, relativistic or non-relativistic, there are various formulations alternative to the Schr\u00f6dinger equation that govern the time evolution and behavior of a quantum system, for instance: \n\nthe Heisenberg equation of motion resembles the time evolution of classical observables as functions of position, momentum, and time, if one replaces dynamical observables by their quantum operators and the classical Poisson bracket by the commutator,\nthe phase space formulation closely follows classical Hamiltonian mechanics, placing position and momentum on equal footing,\nthe Feynman path integral formulation extends the principle of least action to quantum mechanics and field theory, placing emphasis on the use of a Lagrangians rather than Hamiltonians.\n\n\n== See also ==\n\n\n== References ==", "Frequency": "Frequency is the number of occurrences of a repeating event per unit of time. It is also occasionally referred to as temporal frequency for clarity, and is distinct from angular frequency. Frequency is measured in hertz (Hz) which is equal to one event per second.  The period is the interval of time between events, so the period is the reciprocal of the frequency.For example, if a heart beats at a frequency of 120 times a minute (2 hertz), the period, T\u2014the interval at which the beats repeat\u2014is half a second (60 seconds divided by 120 beats). Frequency is an important parameter used in science and engineering to specify the rate of oscillatory and vibratory phenomena, such as mechanical vibrations, audio signals (sound), radio waves, and light.\n\n\n== Definitions and units ==\n\nFor cyclical phenomena such as oscillations, waves, or for examples of simple harmonic motion, the term frequency is defined as the number of cycles or vibrations per unit of time. The conventional symbol for frequency is f; the Greek letter \u03bd (nu) is also used. The period T is the time taken to complete one cycle of an oscillation or rotation. The relation between the frequency and the period is given by the equation\nThe term temporal frequency is used to emphasise that the frequency is characterised by the number of occurrences of a repeating event per unit time.\nThe SI unit of frequency is the hertz (Hz), named after the German physicist Heinrich Hertz by the International Electrotechnical Commission in 1930. It was adopted by the CGPM (Conf\u00e9rence g\u00e9n\u00e9rale des poids et mesures) in 1960, officially replacing the previous name, cycle per second (cps). The SI unit for the period, as for all measurements of time, is the second. A traditional unit of frequency used with rotating mechanical devices, where it is termed rotational frequency, is revolution per minute, abbreviated r/min or rpm. 60 rpm is equivalent to one hertz.\n\n\n== Period versus frequency ==\nAs a matter of convenience, longer and slower waves, such as ocean surface waves, are more typically described by wave period rather than frequency. Short and fast waves, like audio and radio, are usually described by their frequency. Some commonly used conversions are listed below:\n\n\n== Related quantities ==\n\nAngular frequency, usually denoted by the Greek letter \u03c9 (omega), is defined as the rate of change of angular displacement (during rotation), \u03b8 (theta), or the rate of change of the phase of a sinusoidal waveform (notably in oscillations and waves), or as the rate of change of the argument to the sine function:   The unit of angular frequency is the radian per second (rad/s) but, for discrete-time signals, can also be expressed as radians per sampling interval, which is a dimensionless quantity. Angular frequency is frequency multiplied by 2\u03c0.\nSpatial frequency, denoted here by \u03be, is analogous to temporal frequency, but with a spatial measurement replacing time measurement, e.g.:  \n\n\n== In wave propagation ==\n\nFor periodic waves in nondispersive media (that is, media in which the wave speed is independent of frequency), frequency has an inverse relationship to the wavelength, \u03bb (lambda). Even in dispersive media, the frequency f of a sinusoidal wave is equal to the phase velocity v of the wave divided by the wavelength \u03bb of the wave:\n\nIn the special case of electromagnetic waves in vacuum, then v = c, where c is the speed of light in vacuum, and this expression becomes\n\nWhen monochromatic waves travel from one medium to another, their frequency remains the same\u2014only their wavelength and speed change.\n\n\n== Measurement ==\n\nMeasurement of frequency can be done in the following ways:\n\n\n=== Counting ===\nCalculating the frequency of a repeating event is accomplished by counting the number of times that event occurs within a specific time period, then dividing the count by the period. For example, if 71 events occur within 15 seconds the frequency is:\n\nIf the number of counts is not very large, it is more accurate to measure the time interval for a predetermined number of occurrences, rather than the number of occurrences within a specified time.  The latter method introduces a random error into the count of between zero and one count, so on average half a count. This is called gating error and causes an average error in the calculated frequency of \n  \n    \n      \n        \u0394\n        f\n        =\n        \n          \n            1\n            \n              2\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\textstyle \\Delta f={\\frac {1}{2T_{\\text{m}}}}}\n  , or a fractional error of \n  \n    \n      \n        \n          \n            \n              \u0394\n              f\n            \n            f\n          \n        \n        =\n        \n          \n            1\n            \n              2\n              f\n              \n                T\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\textstyle {\\frac {\\Delta f}{f}}={\\frac {1}{2fT_{\\text{m}}}}}\n   where \n  \n    \n      \n        \n          T\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle T_{\\text{m}}}\n   is the timing interval and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the measured frequency. This error decreases with frequency, so it is generally a problem at low frequencies where the number of counts N is small.\n\n\n=== Stroboscope ===\nAn old method of measuring the frequency of rotating or vibrating objects is to use a stroboscope. This is an intense repetitively flashing light (strobe light) whose frequency can be adjusted with a calibrated timing circuit. The strobe light is pointed at the rotating object and the frequency adjusted up and down. When the frequency of the strobe equals the frequency of the rotating or vibrating object, the object completes one cycle of oscillation and returns to its original position between the flashes of light, so when illuminated by the strobe the object appears stationary. Then the frequency can be read from the calibrated readout on the stroboscope. A downside of this method is that an object rotating at an integer multiple of the strobing frequency will also appear stationary.\n\n\n=== Frequency counter ===\n\nHigher frequencies are usually measured with a frequency counter. This is an electronic instrument which measures the frequency of an applied repetitive electronic signal and displays the result in hertz on a digital display. It uses digital logic to count the number of cycles during a time interval established by a precision quartz time base. Cyclic processes that are not electrical, such as the rotation rate of a shaft, mechanical vibrations, or sound waves, can be converted to a repetitive electronic signal by transducers and the signal applied to a frequency counter. As of 2018, frequency counters can cover the range up to about 100 GHz. This represents the limit of direct counting methods; frequencies above this must be measured by indirect methods.\n\n\n=== Heterodyne methods ===\nAbove the range of frequency counters, frequencies of electromagnetic signals are often measured indirectly utilizing heterodyning (frequency conversion). A reference signal of a known frequency near the unknown frequency is mixed with the unknown frequency in a nonlinear mixing device such as a diode. This creates a heterodyne or \"beat\" signal at the difference between the two frequencies.  If the two signals are close together in frequency the heterodyne is low enough to be measured by a frequency counter. This process only measures the difference between the unknown frequency and the reference frequency. To reach higher frequencies, several stages of heterodyning can be used. Current research is extending this method to infrared and light frequencies (optical heterodyne detection).\n\n\n== Examples ==\n\n\n=== Light ===\n\nVisible light is an electromagnetic wave, consisting of oscillating electric and magnetic fields traveling through space. The frequency of the wave determines its color: 400 THz (4\u00d71014 Hz) is red light, 800 THz (8\u00d71014 Hz) is violet light, and between these (in the range 400\u2013800 THz) are all the other colors of the visible spectrum. An electromagnetic wave with a frequency less than 4\u00d71014 Hz will be invisible to the human eye; such waves are called infrared (IR) radiation. At even lower frequency, the wave is called a microwave, and at still lower frequencies it is called a radio wave. Likewise, an electromagnetic wave with a frequency higher than 8\u00d71014 Hz will also be invisible to the human eye; such waves are called ultraviolet (UV) radiation. Even higher-frequency waves are called X-rays, and higher still are gamma rays.\nAll of these waves, from the lowest-frequency radio waves to the highest-frequency gamma rays, are fundamentally the same, and they are all called electromagnetic radiation. They all travel through vacuum at the same speed (the speed of light), giving them wavelengths inversely proportional to their frequencies.\n\nwhere c is the speed of light (c in vacuum or less in other media), f is the frequency and \u03bb is the wavelength.\nIn dispersive media, such as glass, the speed depends somewhat on frequency, so the wavelength is not quite inversely proportional to frequency.\n\n\n=== Sound ===\n\nSound propagates as mechanical vibration waves of pressure and displacement, in air or other substances. In general, frequency components of a sound determine its \"color\", its timbre. When speaking about the frequency (in singular) of a sound, it means the property that most determines its pitch.The frequencies an ear can hear are limited to a specific range of frequencies.  The audible frequency range for humans is typically given as being between about 20 Hz and 20,000 Hz (20 kHz), though the high frequency limit usually reduces with age. Other species have different hearing ranges. For example, some dog breeds can perceive vibrations up to 60,000 Hz.In many media, such as air, the speed of sound is approximately independent of frequency, so the wavelength of the sound waves (distance between repetitions) is approximately inversely proportional to frequency.\n\n\n=== Line current ===\n\nIn Europe, Africa, Australia, southern South America, most of Asia, and Russia, the frequency of the alternating current in household electrical outlets is 50 Hz (close to the tone G), whereas in North America and northern South America, the frequency of the alternating current in household electrical outlets is 60 Hz (between the tones B\u266d and B; that is, a minor third above the European frequency). The frequency of the 'hum' in an audio recording can show where the recording was made, in countries using a European, or an American, grid frequency.\n\n\n== Aperiodic frequency ==\nAperiodic frequency is the rate of incidence or occurrence of non-cyclic phenomena, including random processes such as radioactive decay. It is expressed with the unit of reciprocal second (s\u22121) or, in the case of radioactivity, becquerels.It is defined as a ratio, f = N/T, involving the number of times an event happened (N) during a given time duration (T); it is a physical quantity of type temporal rate.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Sources ==\nDavies, A. (1997). Handbook of Condition Monitoring: Techniques and Methodology. New York: Springer. ISBN 978-0-412-61320-3.\nSerway, Raymond A.; Faughn, Jerry S. (1989). College Physics. London: Thomson/Brooks-Cole. ISBN 978-05344-0-814-5.\nYoung, Ian R. (1999). Wind Generated Ocean Waves. Elsevere Ocean Engineering. Vol. 2. Oxford: Elsevier. ISBN 978-0-08-043317-2.\n\n\n== Further reading ==\nGiancoli, D.C. (1988). Physics for Scientists and Engineers (2nd ed.). Prentice Hall. ISBN 978-0-13-669201-0.\n\n\n== External links ==\n\nKeyboard frequencies = naming of notes \u2013 The English and American system versus the German system\nA frequency generator with sound, useful for hearing tests", "Lever": "A lever is a simple machine consisting of a beam or rigid rod pivoted at a fixed hinge, or fulcrum. A lever is a rigid body capable of rotating on a point on itself. On the basis of the locations of fulcrum, load and effort, the lever is divided into three types. It is one of the six simple machines identified by Renaissance scientists. A lever amplifies an input force to provide a greater output force, which is said to provide leverage, which is mechanical advantage gained in the system, equal to the ratio of the output force to the input force. As such, the lever is a mechanical advantage device, trading off force against movement.\n\n\n== Etymology ==\nThe word \"lever\" entered English around 1300 from Old French: levier. This sprang from the stem of the verb lever, meaning \"to raise\". The verb, in turn, goes back to Latin: levare, itself from the adjective levis, meaning \"light\" (as in \"not heavy\"). The word's primary origin is the Proto-Indo-European stem legwh-, meaning \"light\", \"easy\" or \"nimble\", among other things. The  PIE stem also gave rise to the English word \"light\".\n\n\n== History ==\nThe earliest evidence of the lever mechanism dates back to the ancient Near East circa 5000 BC, when it was first used in a simple balance scale. In ancient Egypt circa 4400 BC, a foot pedal was used for the earliest horizontal frame loom. In Mesopotamia (modern Iraq) circa 3000 BC, the shadouf, a crane-like device that uses a lever mechanism, was invented. In ancient Egypt technology, workmen used the lever to move and uplift obelisks weighing more than 100 tons. This is evident from the recesses in the large blocks and the handling bosses which could not be used for any purpose other than for levers.The earliest remaining writings regarding levers date from the 3rd century BC and were provided by the Greek mathematician Archimedes, who famously stated \"Give me a lever long enough and a fulcrum on which to place it, and I shall move the world.\"\n\n\n== Force and levers ==\n\nA lever is a beam connected to ground by a hinge, or pivot, called a fulcrum. The ideal lever does not dissipate or store energy, which means there is no friction in the hinge or bending in the beam. In this case, the power into the lever equals the power out, and the ratio of output to input force is given by the ratio of the distances from the fulcrum to the points of application of these forces. This is known as the law of the lever.\nThe mechanical advantage of a lever can be determined by considering the balance of moments or torque, T, about the fulcrum. If the distance traveled is greater, then the output force is lessened.\n\nwhere F1 is the input force to the lever and F2 is the output force. The distances a and b are the perpendicular distances between the forces and the fulcrum.\nSince the moments of torque must be balanced, \n  \n    \n      \n        \n          T\n          \n            1\n          \n        \n        =\n        \n          T\n          \n            2\n          \n        \n        \n      \n    \n    {\\displaystyle T_{1}=T_{2}\\!}\n  . So, \n  \n    \n      \n        \n          F\n          \n            1\n          \n        \n        a\n        =\n        \n          F\n          \n            2\n          \n        \n        b\n        \n      \n    \n    {\\displaystyle F_{1}a=F_{2}b\\!}\n  .\nThe mechanical advantage of the lever is the ratio of output force to input force.\n\nThis relationship shows that the mechanical advantage can be computed from ratio of the distances from the fulcrum to where the input and output forces are applied to the lever, assuming no losses due to friction, flexibility or wear. This remains true even though the \"horizontal\" distance (perpendicular to the pull of gravity) of both a and b change (diminish) as the lever changes to any position away from the horizontal.\n\n\n== Classes of levers ==\n\nLevers are classified by the relative positions of the fulcrum, effort and resistance (or load). It is common to call the input force \"effort\" and the output force \"load\" or \"resistance\". This allows the identification of three classes of levers by the relative locations of the fulcrum, the resistance and the effort:\n Class I \u2013 Fulcrum is located between the effort and the resistance: The effort is applied on one side of the fulcrum and the resistance (or load) on the other side. For example, a seesaw, a crowbar or a pair of scissors, a balance scale, a claw hammer. With the fulcrum in the middle, the lever's mechanical advantage may be greater than, less than, or equal to 1.\n Class II \u2013 Resistance (or load) is located between the effort and the fulcrum: The effort is applied on one side of the resistance and the fulcrum is located on the other side, e.g. a wheelbarrow, a nutcracker, a bottle opener or the brake pedal of a car. Since the load arm is smaller than the effort arm, the lever's mechanical advantage is always greater than 1. It is also called a force multiplier lever.\n Class III \u2013 Effort is located between the resistance and the fulcrum: The resistance (or load) is applied on one side of the effort and the fulcrum is located on the other side, e.g. a pair of tweezers, a hammer, a pair of tongs, a fishing rod, or the mandible of a human skull. Since the effort arm is smaller than the load arm, the lever's mechanical advantage is always less than 1. It is also called a speed multiplier lever.These cases are described by the mnemonic fre 123 where the f fulcrum is between r and e for the 1st class lever, the r resistance is between f and e for the 2nd class lever, and the e effort is between f and r for the 3rd class lever.\n\n\n== Compound lever ==\n \nA compound lever comprises several levers acting in series: the resistance from one lever in a system of levers acts as effort for the next, and thus the applied force is transferred from one lever to the next. Examples of compound levers include scales, nail clippers and piano keys.\nThe malleus, incus and stapes are small bones in the middle ear, connected as compound levers, that transfer sound waves from the eardrum to the oval window of the cochlea.\n\n\n== Law of the lever ==\n\nThe lever is a movable bar that pivots on a fulcrum attached to a fixed point. The lever operates by applying forces at different distances from the fulcrum, or a pivot.\nAs the lever rotates around the fulcrum, points farther from this pivot move faster than points closer to the pivot. Therefore, a force applied to a point farther from the pivot must be less than the force located at a point closer in, because power is the product of force and velocity.If a and b are distances from the fulcrum to points A and B and the force FA applied to A is the input and the force FB applied at B is the output, the ratio of the velocities of points A and B is given by a/b, so we have the ratio of the output force to the input force, or mechanical advantage, is given by:\n\nThis is the law of the lever, which was proven by Archimedes using geometric reasoning. It shows that if the distance a from the fulcrum to where the input force is applied (point A) is greater than the distance b from fulcrum to where the output force is applied (point B), then the lever amplifies the input force. On the other hand, if the distance a from the fulcrum to the input force is less than the distance b from the fulcrum to the output force, then the lever reduces the input force.\nThe use of velocity in the static analysis of a lever is an application of the principle of virtual work.\n\n\n== Virtual work and the law of the lever ==\nA lever is modeled as a rigid bar connected to a ground frame by a hinged joint called a fulcrum. The lever is operated by applying an input force FA at a point A located by the coordinate vector rA on the bar. The lever then exerts an output force FB at the point B located by rB. The rotation of the lever about the fulcrum P is defined by the rotation angle \u03b8 in radians.\n\nLet the coordinate vector of the point P that defines the fulcrum be rP, and introduce the lengths\n\nwhich are the distances from the fulcrum to the input point A and to the output point B, respectively.\nNow introduce the unit vectors eA and eB from the fulcrum to the point A and B, so\n\nThe velocity of the points A and B are obtained as\n\nwhere eA\u22a5 and eB\u22a5 are unit vectors perpendicular to eA and eB, respectively.\nThe angle \u03b8 is the generalized coordinate that defines the configuration of the lever, and the generalized force associated with this coordinate is given by\n\nwhere FA and FB are components of the forces that are perpendicular to the radial segments PA and PB. The principle of virtual work states that at equilibrium the generalized force is zero, that is\n\nThus, the ratio of the output force FB to the input force FA is obtained as\n\nwhich is the mechanical advantage of the lever.\nThis equation shows that if the distance a from the fulcrum to the point A where the input force is applied is greater than the distance b from fulcrum to the point B where the output force is applied, then the lever amplifies the input force. If the opposite is true that the distance from the fulcrum to the input point A is less than from the fulcrum to the output point B, then the lever reduces the magnitude of the input force.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nLever at Diracdelta science and engineering encyclopedia\nA Simple Lever by Stephen Wolfram, Wolfram Demonstrations Project.\nLevers: Simple Machines at EnchantedLearning.com", "Tension_(physics)": "In physics, tension is described as the pulling force transmitted axially by the means of a string, a rope, chain, or similar object, or by each end of a rod, truss member, or similar three-dimensional object; tension might also be described as the action-reaction pair of forces acting at each end of said elements. Tension could be the opposite of compression.\nAt the atomic level, when atoms or molecules are pulled apart from each other and gain potential energy with a restoring force still existing, the restoring force might create what is also called tension. Each end of a string or rod under such tension could pull on the object it is attached to, in order to restore the string/rod to its relaxed length.\nTension (as a transmitted force, as an action-reaction pair of forces, or as a restoring force) is measured in newtons in the International System of Units (or pounds-force in Imperial units). The ends of a string or other object transmitting tension will exert forces on the objects to which the string or rod is connected, in the direction of the string at the point of attachment. These forces due to tension are also called \"passive forces\". There are two basic possibilities for systems of objects held by strings: either acceleration is zero and the system is therefore in equilibrium, or there is acceleration, and therefore a net force is present in the system.\n\n\n== Tension in one dimension ==\n\nTension in a string is a non-negative vector quantity. Zero tension is slack. A string or rope is often idealized as one dimension, having length but being massless with zero cross section. If there are no bends in the string, as occur with vibrations or pulleys, then tension is a constant along the string, equal to the magnitude of the forces applied by the ends of the string. By Newton's third law, these are the same forces exerted on the ends of the string by the objects to which the ends are attached. If the string curves around one or more pulleys, it will still have constant tension along its length in the idealized situation that the pulleys are massless and frictionless. A vibrating string vibrates with a set of frequencies that depend on the string's tension. These frequencies can be derived from Newton's laws of motion. Each microscopic segment of the string pulls on and is pulled upon by its neighboring segments, with a force equal to the tension at that position along the string.\nIf the string has curvature, then the two pulls on a segment by its two neighbors will not add to zero, and there will be a net force on that segment of the string, causing an acceleration. This net force is a restoring force, and the motion of the string can include transverse waves that solve the equation central to Sturm\u2013Liouville theory:\n\nwhere \n  \n    \n      \n        v\n        (\n        x\n        )\n      \n    \n    {\\displaystyle v(x)}\n   is the force constant per unit length [units force per area] and \n  \n    \n      \n        \n          \u03c9\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\omega ^{2}}\n   are the eigenvalues for resonances of transverse displacement \n  \n    \n      \n        \u03c1\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\rho (x)}\n   on the string, with solutions that include the various harmonics on a stringed instrument.\n\n\n== Tension of three dimensions ==\nTension is also used to describe the force exerted by the ends of a three-dimensional, continuous material such as a rod or truss member.  In this context, tension is analogous to negative pressure. A rod under tension elongates. The amount of elongation and the load that will cause failure both depend on the force per cross-sectional area rather than the force alone, so stress = axial force / cross sectional area is more useful for engineering purposes than tension. Stress is a 3x3 matrix called a tensor, and the \n  \n    \n      \n        \n          \u03c3\n          \n            11\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{11}}\n   element of the stress tensor is tensile force per area, or compression force per area, denoted as a negative number for this element, if the rod is being compressed rather than elongated.\nThus, one can obtain a scalar analogous to tension by taking the trace of the stress tensor.\n\n\n== System in equilibrium ==\nA system is in equilibrium when the sum of all forces is zero.\nFor example, consider a system consisting of an object that is being lowered vertically by a string with tension, T, at a constant velocity. The system has a constant velocity and is therefore in equilibrium because the tension in the string, which is pulling up on the object, is equal to the weight force, mg (\"m\" is mass, \"g\" is the acceleration caused by the gravity of Earth), which is pulling down on the object.\n\n\n== System under net force ==\nA system has a net force when an unbalanced force is exerted on it, in other words the sum of all forces is not zero. Acceleration and net force always exist together.\nFor example, consider the same system as above but suppose the object is now being lowered with an increasing velocity downwards (positive acceleration) therefore there exists a net force somewhere in the system. In this case, negative acceleration would indicate that \n  \n    \n      \n        \n          |\n        \n        m\n        g\n        \n          |\n        \n        >\n        \n          |\n        \n        T\n        \n          |\n        \n      \n    \n    {\\displaystyle |mg|>|T|}\n  .\nIn another example, suppose that two bodies A and B having masses \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle m_{1}}\n   and \n  \n    \n      \n        \n          m\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle m_{2}}\n  , respectively, are connected with each other by an inextensible string over a frictionless pulley. There are two forces acting on the body A: its weight (\n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        =\n        \n          m\n          \n            1\n          \n        \n        g\n      \n    \n    {\\displaystyle w_{1}=m_{1}g}\n  ) pulling down, and the tension \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n   in the string pulling up. Therefore, the net force \n  \n    \n      \n        \n          F\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle F_{1}}\n   on body A is \n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        \u2212\n        T\n      \n    \n    {\\displaystyle w_{1}-T}\n  , so \n  \n    \n      \n        \n          m\n          \n            1\n          \n        \n        a\n        =\n        \n          m\n          \n            1\n          \n        \n        g\n        \u2212\n        T\n      \n    \n    {\\displaystyle m_{1}a=m_{1}g-T}\n  . In an extensible string, Hooke's law applies.\n\n\n== Strings in modern physics ==\nString-like objects in relativistic theories, such as the strings used in some models of interactions between quarks, or those used in the modern string theory, also possess tension. These strings are analyzed in terms of their world sheet, and the energy is then typically proportional to the length of the string. As a result, the tension in such                                                strings is independent of the amount of stretching.\n\n\n== See also ==\n\nContinuum mechanics\nFall factor\nSurface tension\nTensile strength\nHydrostatic pressure\n\n\n== References ==", "Interference_(wave_propagation)": "In physics, interference is a phenomenon in which two coherent waves are combined by adding their intensities or displacements with due consideration for their phase difference. The resultant wave may have greater intensity (constructive interference) or lower amplitude (destructive interference) if the two waves are in phase or out of phase, respectively.\nInterference effects can be observed with all types of waves, for example, light, radio, acoustic, surface water waves, gravity waves, or matter waves as well as in loudspeakers as electrical waves.\n\n\n== Etymology ==\nThe word interference is derived from the Latin words inter which means \"between\" and fere which means \"hit or strike\", and was coined by Thomas Young in 1801.\n\n\n== Mechanisms ==\n\nThe principle of superposition of waves states that when two or more propagating waves of the same type are incident on the same point, the resultant amplitude at that point is equal to the vector sum of the amplitudes of the individual waves. If a crest of a wave meets a crest of another wave of the same frequency at the same point, then the amplitude is the sum of the individual amplitudes\u2014this is constructive interference. If a crest of one wave meets a trough of another wave, then the amplitude is equal to the difference in the individual amplitudes\u2014this is known as destructive interference. In ideal mediums (water, air are almost ideal) energy is always conserved, at points of destructive interference energy is stored in the elasticity of the medium.  For example when we drop 2 pebbles in a pond we see a pattern but eventually waves continue and only when they reach the shore is energy absorbed away from the medium.\n\nConstructive interference occurs when the phase difference between the waves is an even multiple of \u03c0 (180\u00b0), whereas destructive interference occurs when the difference is an odd multiple of \u03c0. If the difference between the phases is intermediate between these two extremes, then the magnitude of the displacement of the summed waves lies between the minimum and maximum values.\nConsider, for example, what happens when two identical stones are dropped into a still pool of water at different locations. Each stone generates a circular wave propagating outwards from the point where the stone was dropped. When the two waves overlap, the net displacement at a particular point is the sum of the displacements of the individual waves. At some points, these will be in phase, and will produce a maximum displacement. In other places, the waves will be in anti-phase, and there will be no net displacement at these points. Thus, parts of the surface will be stationary\u2014these are seen in the figure above and to the right as stationary blue-green lines radiating from the centre.\nInterference of light is a unique phenomenon in that we can never observe superposition of the EM field directly as we can for example in water. Superposition in the EM field is an assumed and necessary requirement, fundamentally 2 light beam pass through each other and continue on their respective paths. Light can be explained classically by the superposition of waves, however a deeper understanding of light interference requires knowledge of    wave-particle duality of light which is due to quantum mechanics.  Prime examples of light interference are the famous double-slit experiment, laser speckle, anti-reflective coatings and interferometers.    Traditionally the classical wave model is taught as a basis for understanding optical interference, based on the Huygens\u2013Fresnel principle however an explanation based on the Feynman path integral exists which takes into account quantum mechanical considerations.\n\n\n=== Derivation ===\nThe above can be demonstrated in one dimension by deriving the formula for the sum of two waves.  The equation for the amplitude of a sinusoidal wave traveling to the right along the x-axis is\n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is the peak amplitude, \n  \n    \n      \n        k\n        =\n        2\n        \u03c0\n        \n          /\n        \n        \u03bb\n      \n    \n    {\\displaystyle k=2\\pi /\\lambda }\n   is the wavenumber and \n  \n    \n      \n        \u03c9\n        =\n        2\n        \u03c0\n        f\n      \n    \n    {\\displaystyle \\omega =2\\pi f}\n   is the angular frequency of the wave.  Suppose a second wave of the same frequency and amplitude but with a different phase is also traveling to the right\n\nwhere \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n   is the phase difference between the waves in radians.  The two waves will superpose and add: the sum of the two waves is\n\nUsing the trigonometric identity for the sum of two cosines: \n  \n    \n      \n        cos\n        \u2061\n        a\n        +\n        cos\n        \u2061\n        b\n        =\n        2\n        cos\n        \u2061\n        \n          (\n          \n            \n              \n                a\n                \u2212\n                b\n              \n              2\n            \n          \n          )\n        \n        cos\n        \u2061\n        \n          (\n          \n            \n              \n                a\n                +\n                b\n              \n              2\n            \n          \n          )\n        \n        ,\n      \n    \n    {\\textstyle \\cos a+\\cos b=2\\cos \\left({a-b \\over 2}\\right)\\cos \\left({a+b \\over 2}\\right),}\n   this can be written\n\nThis represents a wave at the original frequency, traveling to the right like its components, whose amplitude is proportional to the cosine of \n  \n    \n      \n        \u03c6\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle \\varphi /2}\n  .\n\nConstructive interference: If the phase difference is an even multiple of \u03c0: \n  \n    \n      \n        \u03c6\n        =\n        \u2026\n        ,\n        \u2212\n        4\n        \u03c0\n        ,\n        \u2212\n        2\n        \u03c0\n        ,\n        0\n        ,\n        2\n        \u03c0\n        ,\n        4\n        \u03c0\n        ,\n        \u2026\n      \n    \n    {\\displaystyle \\varphi =\\ldots ,-4\\pi ,-2\\pi ,0,2\\pi ,4\\pi ,\\ldots }\n   then \n  \n    \n      \n        \n          |\n          \n            cos\n            \u2061\n            (\n            \u03c6\n            \n              /\n            \n            2\n            )\n          \n          |\n        \n        =\n        1\n      \n    \n    {\\displaystyle \\left|\\cos(\\varphi /2)\\right|=1}\n  , so the sum of the two waves is a wave with twice the amplitude \nDestructive interference: If the phase difference is an odd multiple of \u03c0: \n  \n    \n      \n        \u03c6\n        =\n        \u2026\n        ,\n        \u2212\n        3\n        \u03c0\n        ,\n        \n        \u2212\n        \u03c0\n        ,\n        \n        \u03c0\n        ,\n        \n        3\n        \u03c0\n        ,\n        \n        5\n        \u03c0\n        ,\n        \u2026\n      \n    \n    {\\displaystyle \\varphi =\\ldots ,-3\\pi ,\\,-\\pi ,\\,\\pi ,\\,3\\pi ,\\,5\\pi ,\\ldots }\n   then \n  \n    \n      \n        cos\n        \u2061\n        (\n        \u03c6\n        \n          /\n        \n        2\n        )\n        =\n        0\n        \n      \n    \n    {\\displaystyle \\cos(\\varphi /2)=0\\,}\n  , so the sum of the two waves is zero \n\n\n=== Between two plane waves ===\n \n\nA simple form of interference pattern is obtained if two plane waves of the same frequency intersect at an angle.\nInterference is essentially an energy redistribution process. The energy which is lost at the destructive interference is regained at the constructive interference.\nOne wave is travelling horizontally, and the other is travelling downwards at an angle \u03b8 to the first wave.  Assuming that the two waves are in phase at the point B, then the relative phase changes along the x-axis. The phase difference at the point A is given by\n\nIt can be seen that the two waves are in phase when\n\nand are half a cycle out of phase when\n\nConstructive interference occurs when the waves are in phase, and destructive interference when they are half a cycle out of phase.  Thus, an interference fringe pattern is produced, where the separation of the maxima is\n\nand df is known as the fringe spacing.  The fringe spacing increases with increase in wavelength, and with decreasing angle \u03b8.\nThe fringes are observed wherever the two waves overlap and the fringe spacing is uniform throughout.\n\n\n=== Between two spherical waves ===\n\nA point source produces a spherical wave.  If the light from two point sources overlaps, the interference pattern maps out the way in which the phase difference between the two waves varies in space. This depends on the wavelength and on the separation of the point sources.  The figure to the right shows interference between two spherical waves.  The wavelength increases from top to bottom, and the distance between the sources increases from left to right.\nWhen the plane of observation is far enough away, the fringe pattern will be a series of almost straight lines, since the waves will then be almost planar.\n\n\n=== Multiple beams ===\nInterference occurs when several waves are added together provided that the phase differences between them remain constant over the observation time.\nIt is sometimes desirable for several waves of the same frequency and amplitude to sum to zero (that is, interfere destructively, cancel). This is the principle behind, for example, 3-phase power and the diffraction grating.  In both of these cases, the result is achieved by uniform spacing of the phases.\nIt is easy to see that a set of waves will cancel if they have the same amplitude and their phases are spaced equally in angle.  Using phasors, each wave can be represented as \n  \n    \n      \n        A\n        \n          e\n          \n            i\n            \n              \u03c6\n              \n                n\n              \n            \n          \n        \n      \n    \n    {\\displaystyle Ae^{i\\varphi _{n}}}\n   for \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n   waves from \n  \n    \n      \n        n\n        =\n        0\n      \n    \n    {\\displaystyle n=0}\n   to \n  \n    \n      \n        n\n        =\n        N\n        \u2212\n        1\n      \n    \n    {\\displaystyle n=N-1}\n  , where\n\nTo show that\n\none merely assumes the converse, then multiplies both sides by \n  \n    \n      \n        \n          e\n          \n            i\n            \n              \n                \n                  2\n                  \u03c0\n                \n                N\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle e^{i{\\frac {2\\pi }{N}}}.}\n  \nThe Fabry\u2013P\u00e9rot interferometer uses interference between multiple reflections.\nA diffraction grating can be considered to be a multiple-beam interferometer; since the peaks which it produces are generated by interference between the light transmitted by each of the elements in the grating; see interference vs. diffraction for further discussion.\n\n\n== Optical interference ==\n\nBecause the frequency of light waves (~1014 Hz) is too high for currently available detectors to detect the variation of the electric field of the light, it is possible to observe only the intensity of an optical interference pattern. The intensity of the light at a given point is proportional to the square of the average amplitude of the wave.  This can be expressed mathematically as follows. The displacement of the two waves at a point r is:\n\nwhere A represents the magnitude of the displacement, \u03c6 represents the phase and \u03c9 represents the angular frequency.\nThe displacement of the summed waves is\n\nThe intensity of the light at r is given by\n\nThis can be expressed in terms of the intensities of the individual waves as\n\nThus, the interference pattern maps out the difference in phase between the two waves, with maxima occurring when the phase difference is a multiple of 2\u03c0. If the two beams are of equal intensity, the maxima are four times as bright as the individual beams, and the minima have zero intensity.\nClassically the two waves must have the same polarization to give rise to interference fringes since it is not possible for waves of different polarizations to cancel one another out or add together. Instead, when waves of different polarization are added together, they give rise to a wave of a different polarization state.\nQuantum mechanically the theories of Paul Dirac and Richard Feynman offer a more modern approach.  Dirac showed that every quanta or photon of light acts on its own which he famously stated as \"every photon interferes with itself\". Richard Feynman showed that by evaluating a path integral where all possible paths are considered, that a number of higher probability paths will emerge.  In thin films for example, film thickness which is not a multiple of light wavelength will not allow the quanta to traverse, only reflection is possible.  \n\n\n=== Light source requirements ===\nThe discussion above assumes that the waves which interfere with one another are monochromatic, i.e. have a single frequency\u2014this requires that they are infinite in time.  This is not, however, either practical or necessary. Two identical waves of finite duration whose frequency is fixed over that period will give rise to an interference pattern while they overlap.  Two identical waves which consist of a narrow spectrum of frequency waves of finite duration (but shorter than their coherence time), will give a series of fringe patterns of slightly differing spacings, and provided the spread of spacings is significantly less than the average fringe spacing, a fringe pattern will again be observed during the time when the two waves overlap.\nConventional light sources emit waves of differing frequencies and at different times from different points in the source. If the light is split into two waves and then re-combined, each individual light wave may generate an interference pattern with its other half, but the individual fringe patterns generated will have different phases and spacings, and normally no overall fringe pattern will be observable.  However, single-element light sources, such as sodium- or mercury-vapor lamps have emission lines with quite narrow frequency spectra.  When these are spatially and colour filtered, and then split into two waves, they can be superimposed to generate interference fringes. All interferometry prior to the invention of the laser was done using such sources and had a wide range of successful applications.\nA laser beam generally approximates much more closely to a monochromatic source, and thus it is much more straightforward to generate interference fringes using a laser. The ease with which interference fringes can be observed with a laser beam can sometimes cause problems in that stray reflections may give spurious interference fringes which can result in errors.\nNormally, a single laser beam is used in interferometry, though interference has been observed using two independent lasers whose frequencies were sufficiently matched  to satisfy the phase requirements.\nThis has also been observed for widefield interference between two incoherent laser sources.\n\nIt is also possible to observe interference fringes using white light.  A white light fringe pattern can be considered to be made up of a 'spectrum' of fringe patterns each of slightly different spacing. If all the fringe patterns are in phase in the centre, then the fringes will increase in size as the wavelength decreases and the summed intensity will show three to four fringes of varying colour.  Young describes this very elegantly in his discussion of two slit interference. Since white light fringes are obtained only when the two waves have travelled equal distances from the light source, they can be very useful in interferometry, as they allow the zero path difference fringe to be identified.\n\n\n=== Optical arrangements ===\nTo generate interference fringes, light from the source has to be divided into two waves which then have to be re-combined. Traditionally, interferometers have been classified as either amplitude-division or wavefront-division systems.\nIn an amplitude-division system, a beam splitter is used to divide the light into two beams travelling in different directions, which are then superimposed to produce the interference pattern. The Michelson interferometer and the Mach\u2013Zehnder interferometer are examples of amplitude-division systems.\nIn wavefront-division systems, the wave is divided in space\u2014examples are Young's double slit interferometer and Lloyd's mirror.\nInterference can also be seen in everyday phenomena such as iridescence and structural coloration.  For example, the colours seen in a soap bubble arise from interference of light reflecting off the front and back surfaces of the thin soap film.  Depending on the thickness of the film, different colours interfere constructively and destructively.\n\n\n== Applications ==\n\n\n=== Beat ===\n\nIn acoustics, a beat is an interference pattern between two sounds of slightly different frequencies, perceived as a periodic variation in volume whose rate is the difference of the two frequencies.\nWith tuning instruments that can produce sustained tones, beats can be readily recognized. Tuning two tones to a unison will present a peculiar effect: when the two tones are close in pitch but not identical, the difference in frequency generates the beating. The volume varies like in a tremolo as the sounds alternately interfere constructively and destructively. As the two tones gradually approach unison, the beating slows down and may become so slow as to be imperceptible. As the two tones get further apart, their beat frequency starts to approach the range of human pitch perception, the beating starts to sound like a note, and a combination tone is produced. This combination tone can also be referred to as a missing fundamental, as the beat frequency of any two tones is equivalent to the frequency of their implied fundamental frequency.\n\n\n=== Optical interferometry ===\n\nInterferometry has played an important role in the advancement of physics, and also has a wide range of applications in physical and engineering measurement.\nThomas Young's double slit interferometer in 1803 demonstrated interference fringes when two small holes were illuminated by light from another small hole which was illuminated by sunlight.  Young was able to estimate the wavelength of different colours in the spectrum from the spacing of the fringes.  The experiment played a major role in the general acceptance of the wave theory of light.\nIn quantum mechanics, this experiment is considered to demonstrate the inseparability of the wave and particle natures of light and other quantum particles (wave\u2013particle duality). Richard Feynman was fond of saying that all of quantum mechanics can be gleaned from carefully thinking through the implications of this single experiment.The results of the Michelson\u2013Morley experiment are generally considered to be the first strong evidence against the theory of a luminiferous aether and in favor of special relativity.\nInterferometry has been used in defining and calibrating length standards.  When the metre was defined as the distance between two marks on a platinum-iridium bar, Michelson and Beno\u00eet used interferometry to measure the wavelength of the red cadmium line in the new standard, and also showed that it could be used as a length standard. Sixty years later, in 1960, the metre in the new SI system was defined to be equal to 1,650,763.73 wavelengths of the orange-red emission line in the electromagnetic spectrum of the krypton-86 atom in a vacuum.  This definition was replaced in 1983 by defining the metre as the distance travelled by light in vacuum during a specific time interval. Interferometry is still fundamental in establishing the calibration chain in length measurement.\nInterferometry is used in the calibration of slip gauges (called gauge blocks in the US) and in coordinate-measuring machines. It is also used in the testing of optical components.\n\n\n=== Radio interferometry ===\n\nIn 1946, a technique called astronomical interferometry was developed. Astronomical radio interferometers usually consist either of arrays of parabolic dishes or two-dimensional arrays of omni-directional antennas. All of the telescopes in the array are widely separated and are usually connected together using coaxial cable, waveguide, optical fiber, or other type of transmission line. Interferometry increases the total signal collected, but its primary purpose is to vastly increase the resolution through a process called Aperture synthesis. This technique works by superposing (interfering) the signal waves from the different telescopes on the principle that waves that coincide with the same phase will add to each other while two waves that have opposite phases will cancel each other out. This creates a combined telescope that is equivalent in resolution (though not in sensitivity) to a single antenna whose diameter is equal to the spacing of the antennas farthest apart in the array.\n\n\n=== Acoustic interferometry ===\nAn acoustic interferometer is an instrument for measuring the physical characteristics of sound waves in a gas or liquid, such velocity, wavelength, absorption, or impedance. A vibrating crystal creates ultrasonic waves that are radiated into the medium. The waves strike a reflector placed  parallel to the crystal, reflected back to the source and measured.\n\n\n== Quantum interference ==\n\nQuantum interference is quite different from the classical wave interference described above. Below, an enumeration of the important differences is provided. Quantum interference is, however, similar to optical interference.\nLet \n  \n    \n      \n        \u03a8\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi (x,t)}\n   be a wavefunction solution of the Schr\u00f6dinger equation for a quantum mechanical object. Then the probability \n  \n    \n      \n        P\n        (\n        x\n        )\n      \n    \n    {\\displaystyle P(x)}\n   of observing the object at position \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is \n  \n    \n      \n        P\n        (\n        x\n        )\n        =\n        \n          |\n        \n        \u03a8\n        (\n        x\n        ,\n        t\n        )\n        \n          \n            |\n          \n          \n            2\n          \n        \n        =\n        \n          \u03a8\n          \n            \u2217\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        \u03a8\n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle P(x)=|\\Psi (x,t)|^{2}=\\Psi ^{*}(x,t)\\Psi (x,t)}\n   where * indicates complex conjugation. Quantum interference concerns the issue of this probability when the wavefunction is expressed as a sum or linear superposition of two terms \n  \n    \n      \n        \u03a8\n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        +\n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi (x,t)=\\Psi _{A}(x,t)+\\Psi _{B}(x,t)}\n  :\n\nUsually, \n  \n    \n      \n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{A}(x,t)}\n   and \n  \n    \n      \n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{B}(x,t)}\n   correspond to distinct situations A and B. When this is the case, the equation  \n  \n    \n      \n        \u03a8\n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        +\n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi (x,t)=\\Psi _{A}(x,t)+\\Psi _{B}(x,t)}\n   indicates that the object can be in situation A or situation B. The above equation can then be interpreted as: The probability of finding the object at \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is the probability of finding the object at \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   when it is in situation A plus the probability of finding the object at \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   when it is in situation B plus an extra term. This extra term, which is called the quantum interference term, is \n  \n    \n      \n        \n          \u03a8\n          \n            A\n          \n          \n            \u2217\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        +\n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        \n          \u03a8\n          \n            B\n          \n          \n            \u2217\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{A}^{*}(x,t)\\Psi _{B}(x,t)+\\Psi _{A}(x,t)\\Psi _{B}^{*}(x,t)}\n   in the above equation. As in the classical wave case above, the quantum interference term can add (constructive interference) or subtract (destructive interference) from \n  \n    \n      \n        \n          |\n        \n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        \n          \n            |\n          \n          \n            2\n          \n        \n        +\n        \n          |\n        \n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        \n          \n            |\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle |\\Psi _{A}(x,t)|^{2}+|\\Psi _{B}(x,t)|^{2}}\n   in the above equation depending on whether the quantum interference term is positive or negative. If this term is absent for all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , then there is no quantum mechanical interference associated with situations A and B.\nThe best known example of quantum interference is the double-slit experiment. In this experiment, electrons, atoms or other quantum mechanical objects approach a barrier with two slits in it. If the quantum object succeeds in passing through the slits, its position is measured with a detection screen a certain distance beyond and behind the barrier. For this system, one lets \n  \n    \n      \n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{A}(x,t)}\n   be that part of the wavefunction that passes through one of the slits and lets \n  \n    \n      \n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{B}(x,t)}\n   be that part of the wavefunction that passes through the other slit. When the object almost reaches the screen, the probability of where it is located is given by the above equation. In this context, the equation says that the probability of finding the object at some point just before it hits the screen is the probability that would be obtained if it went through the first slit plus the probability that would be obtained if it went through the second slit plus the quantum interference term, which has no counterpart in classical physics. The quantum  interference term can significantly change the pattern observed on the detection screen.\nThe separation of \n  \n    \n      \n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        +\n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{A}(x,t)+\\Psi _{B}(x,t)}\n   is particularly clear in the path integral formulation of quantum mechanics in the context of the double-slit experiment. \n  \n    \n      \n        \n          \u03a8\n          \n            A\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{A}(x,t)}\n   consists of the path integral contributions in which the paths pass through the first slit;  \n  \n    \n      \n        \n          \u03a8\n          \n            B\n          \n        \n        (\n        x\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Psi _{B}(x,t)}\n   consists of the path integral contributions in which they pass through the second slit.\nHere is a list of some of the differences between classical wave interference and quantum interference:\n\nIn classical interference, two different waves interfere; In quantum interference, the wavefunction interferes with itself.\nClassical interference is obtained simply by adding the displacements from equilibrium (or amplitudes) of the two waves; In quantum interference, the effect occurs for the probability function associated with the wavefunction and therefore the modulus of the wavefunction squared.\nThe interference involves different types of mathematical functions: A classical wave is a real function representing the displacement from an equilibrium position; a quantum wavefunction is a complex function. A classical wave at any point can be positive or negative; the quantum probability function is non-negative.\nIn classical optical interference the energy conservation principle is violated as it requires quanta to cancel. In quantum interference energy conservation is not violated, the quanta merely assume paths per the path integral. All quanta for example terminate in bright areas of the pattern.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nEasy JavaScript Simulation Model of One Dimensional Wave Interference\nExpressions of position and fringe spacing\nJava simulation of interference of water waves 1\nJava simulation of interference of water waves 2\nFlash animations demonstrating interference", "Contact_force": "A contact force is any force that occurs as a result of two objects making contact with each other. Contact forces are ubiquitous and are responsible for most visible interactions between macroscopic collections of matter. Pushing a car or kicking a ball are some of the everyday examples where contact forces are at work. In the first case the force is continuously applied to the car by a person, while in the second case the force is delivered in a short impulse.\nContact forces are often decomposed into orthogonal components, one perpendicular to the surface(s) in contact called the normal force, and one parallel to the surface(s) in contact, called the friction force.Not all forces are contact forces; for example, the weight of an object is the force between the object and the Earth, even though the two do not need to make contact. Gravitational forces, electrical forces and magnetic forces are body forces and can exist without contact occurring.\n\n\n== Origin of contact forces ==\nThe microscopic origin of contact forces is diverse. Normal force is directly a result of Pauli exclusion principle and not a true force per se: Everyday objects do not actually touch each other; rather, contact forces are the result of the interactions of the electrons at or near the surfaces of the objects. The atoms in the two surfaces cannot penetrate one another without a large investment of energy because there is no low energy state for which the electron wavefunctions from the two surfaces overlap; thus no microscopic force is needed to prevent this penetration. On the more macroscopic level, such surfaces can be treated as a single object, and two bodies do not penetrate each other due to the stability of matter, which is again a consequence of Pauli exclusion principle, but also of the fundamental forces of nature: Cracks in the bodies do not widen due to electromagnetic forces that create the chemical bonds between the atoms; the atoms themselves do not disintegrate because of the electromagnetic forces between the electrons and the nuclei; and the nuclei do not disintegrate due to the nuclear forces.As for friction, it is a result of both microscopic adhesion and chemical bond formation due to the electromagnetic force, and of microscopic structures stressing into each other; in the latter phenomena, in order to allow motion, the microscopic structures must either slide one above the other, or must acquire enough energy to break one another. Thus the force acting against motion is a combination of the normal force and of the force required to widen microscopic cracks within matter; the latter force is again due to electromagnetic interaction. Additionally, strain is created inside matter, and this strain is due to a combination of electromagnetic interactions (as electrons are attracted to nuclei and repelled from each other) and of Pauli exclusion principle, the latter working similarly to the case of normal force.\n\n\n== See also ==\nNon-contact force\nBody force\nSurface force\nAction at a distance (physics)\nSpring force\n\n\n== References ==", "Standing_wave": "In physics, a standing wave, also known as a stationary wave, is a wave that oscillates in time but whose peak amplitude profile does not move in space.  The peak amplitude of the wave oscillations at any point in space is constant with respect to time, and the oscillations at different points throughout the wave are in phase.   The locations at which the absolute value of the amplitude is minimum are called nodes, and the locations where the absolute value of the amplitude is maximum are called antinodes.\nStanding waves were first described scientifically by Michael Faraday in 1831.  Faraday observed standing waves on the surface of a liquid in a vibrating container.  Franz Melde coined the term \"standing wave\" (German: stehende Welle or Stehwelle) around 1860 and demonstrated the phenomenon in his classic experiment with vibrating strings.This phenomenon can occur because the medium is moving in the direction opposite to the movement of the wave, or it can arise in a stationary medium as a result of interference between two waves traveling in opposite directions. The most common cause of standing waves is the phenomenon of resonance, in which standing waves occur inside a resonator due to interference between waves reflected back and forth at the resonator's resonant frequency.\nFor waves of equal amplitude traveling in opposing directions, there is on average no net propagation of energy.\n\n\n== Moving medium ==\n\nAs an example of the first type, under certain meteorological conditions standing waves form in the atmosphere in the lee of mountain ranges.  Such waves are often exploited by glider pilots.\nStanding waves and hydraulic jumps also form on fast flowing river rapids and tidal currents such as the Saltstraumen maelstrom. A requirement for this in river currents is a flowing water with shallow depth in which the inertia of the water overcomes its gravity due to the supercritical flow speed (Froude number: 1.7 \u2013 4.5, surpassing 4.5 results in direct standing wave) and is therefore neither significantly slowed down by the obstacle nor pushed to the side. Many standing river waves are popular river surfing breaks.\n\n\n== Opposing waves ==\nAs an example of the second type, a standing wave in a transmission line is a wave in which the distribution of current, voltage, or field strength is formed by the superposition of two waves of the same frequency propagating in opposite directions.  The effect is a series of nodes (zero displacement) and anti-nodes (maximum displacement) at fixed points along the transmission line.  Such a standing wave may be formed when a wave is transmitted into one end of a transmission line and is reflected from the other end by an impedance mismatch, i.e., discontinuity, such as an open circuit or a short.  The failure of the line to transfer power at the standing wave frequency will usually result in attenuation distortion.\nIn practice, losses in the transmission line and other components mean that a perfect reflection and a pure standing wave are never achieved.  The result is a partial standing wave, which is a superposition of a standing wave and a traveling wave.  The degree to which the wave resembles either a pure standing wave or a pure traveling wave is measured by the standing wave ratio (SWR).Another example is standing waves in the open ocean formed by waves with the same wave period moving in opposite directions. These may form near storm centres, or from reflection of a swell at the shore, and are the source of microbaroms and microseisms.\n\n\n== Mathematical description ==\nThis section considers representative one- and two-dimensional cases of standing waves. First, an example of an infinite length string shows how identical waves traveling in opposite directions interfere to produce standing waves. Next, two finite length string examples with different boundary conditions demonstrate how the boundary conditions restrict the frequencies that can form standing waves. Next, the example of sound waves in a pipe demonstrates how the same principles can be applied to longitudinal waves with analogous boundary conditions.\nStanding waves can also occur in two- or three-dimensional resonators.  With standing waves on two-dimensional membranes such as drumheads, illustrated in the animations above, the nodes become nodal lines, lines on the surface at which there is no movement, that separate regions vibrating with opposite phase.  These nodal line patterns are called Chladni figures.  In three-dimensional resonators, such as musical instrument sound boxes and microwave cavity resonators, there are nodal surfaces. This section includes a two-dimensional standing wave example with a rectangular boundary to illustrate how to extend the concept to higher dimensions.\n\n\n=== Standing wave on an infinite length string ===\nTo begin, consider a string of infinite length along the x-axis that is free to be stretched transversely in the y direction.\nFor a harmonic wave traveling to the right along the string, the string's displacement in the y direction as a function of position x and time t is\n\n  \n    \n      \n        \n          y\n          \n            R\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          y\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                  x\n                \n                \u03bb\n              \n            \n            \u2212\n            \u03c9\n            t\n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle y_{\\text{R}}(x,t)=y_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }-\\omega t\\right).}\n  The displacement in the y-direction for an identical harmonic wave traveling to the left is\n\n  \n    \n      \n        \n          y\n          \n            L\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          y\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                  x\n                \n                \u03bb\n              \n            \n            +\n            \u03c9\n            t\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle y_{\\text{L}}(x,t)=y_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }+\\omega t\\right),}\n  where\n\nymax is the amplitude of the displacement of the string for each wave,\n\u03c9 is the angular frequency or equivalently 2\u03c0 times the frequency f,\n\u03bb is the wavelength of the wave.For identical right- and left-traveling waves on the same string, the total displacement of the string is the sum of yR and yL,\n\n  \n    \n      \n        y\n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          y\n          \n            R\n          \n        \n        +\n        \n          y\n          \n            L\n          \n        \n        =\n        \n          y\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                  x\n                \n                \u03bb\n              \n            \n            \u2212\n            \u03c9\n            t\n          \n          )\n        \n        +\n        \n          y\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                  x\n                \n                \u03bb\n              \n            \n            +\n            \u03c9\n            t\n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle y(x,t)=y_{\\text{R}}+y_{\\text{L}}=y_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }-\\omega t\\right)+y_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }+\\omega t\\right).}\n  Using the trigonometric sum-to-product identity \n  \n    \n      \n        sin\n        \u2061\n        a\n        +\n        sin\n        \u2061\n        b\n        =\n        2\n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                a\n                +\n                b\n              \n              2\n            \n          \n          )\n        \n        cos\n        \u2061\n        \n          (\n          \n            \n              \n                a\n                \u2212\n                b\n              \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\sin a+\\sin b=2\\sin \\left({a+b \\over 2}\\right)\\cos \\left({a-b \\over 2}\\right)}\n  ,\n\nNote that Equation (1) does not describe a traveling wave. At any position x, y(x,t) simply oscillates in time with an amplitude that varies in the x-direction as \n  \n    \n      \n        2\n        \n          y\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                2\n                \u03c0\n                x\n              \n              \u03bb\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle 2y_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }\\right)}\n  . The animation at the beginning of this article depicts what is happening. As the left-traveling blue wave and right-traveling green wave interfere, they form the standing red wave that does not travel and instead oscillates in place.\nBecause the string is of infinite length, it has no boundary condition for its displacement at any point along the x-axis. As a result, a standing wave can form at any frequency.\nAt locations on the x-axis that are even multiples of a quarter wavelength,\n\n  \n    \n      \n        x\n        =\n        \u2026\n        ,\n        \u2212\n        \n          \n            \n              3\n              \u03bb\n            \n            2\n          \n        \n        ,\n        \n        \u2212\n        \u03bb\n        ,\n        \n        \u2212\n        \n          \n            \u03bb\n            2\n          \n        \n        ,\n        \n        0\n        ,\n        \n        \n          \n            \u03bb\n            2\n          \n        \n        ,\n        \n        \u03bb\n        ,\n        \n        \n          \n            \n              3\n              \u03bb\n            \n            2\n          \n        \n        ,\n        \u2026\n      \n    \n    {\\displaystyle x=\\ldots ,-{3\\lambda  \\over 2},\\;-\\lambda ,\\;-{\\lambda  \\over 2},\\;0,\\;{\\lambda  \\over 2},\\;\\lambda ,\\;{3\\lambda  \\over 2},\\ldots }\n  the amplitude is always zero. These locations are called nodes. At locations on the x-axis that are odd multiples of a quarter wavelength\n\n  \n    \n      \n        x\n        =\n        \u2026\n        ,\n        \u2212\n        \n          \n            \n              5\n              \u03bb\n            \n            4\n          \n        \n        ,\n        \n        \u2212\n        \n          \n            \n              3\n              \u03bb\n            \n            4\n          \n        \n        ,\n        \n        \u2212\n        \n          \n            \u03bb\n            4\n          \n        \n        ,\n        \n        \n          \n            \u03bb\n            4\n          \n        \n        ,\n        \n        \n          \n            \n              3\n              \u03bb\n            \n            4\n          \n        \n        ,\n        \n        \n          \n            \n              5\n              \u03bb\n            \n            4\n          \n        \n        ,\n        \u2026\n      \n    \n    {\\displaystyle x=\\ldots ,-{5\\lambda  \\over 4},\\;-{3\\lambda  \\over 4},\\;-{\\lambda  \\over 4},\\;{\\lambda  \\over 4},\\;{3\\lambda  \\over 4},\\;{5\\lambda  \\over 4},\\ldots }\n  the amplitude is maximal, with a value of twice the amplitude of the right- and left-traveling waves that interfere to produce this standing wave pattern. These locations are called anti-nodes.  The distance between two consecutive nodes or anti-nodes is half the wavelength, \u03bb/2.\n\n\n=== Standing wave on a string with two fixed ends ===\nNext, consider a string with fixed ends at x = 0 and x = L. The string will have some damping as it is stretched by traveling waves, but assume the damping is very small. Suppose that at the x = 0 fixed end a sinusoidal force is applied that drives the string up and down in the y-direction with a small amplitude at some frequency f. In this situation, the driving force produces a right-traveling wave. That wave reflects off the right fixed end and travels back to the left, reflects again off the left fixed end and travels back to the right, and so on. Eventually, a steady state is reached where the string has identical right- and left-traveling waves as in the infinite-length case and the power dissipated by damping in the string equals the power supplied by the driving force so the waves have constant amplitude.\nEquation (1) still describes the standing wave pattern that can form on this string, but now Equation (1) is subject to boundary conditions where y = 0 at x = 0 and x = L because the string is fixed at x = L and because we assume the driving force at the fixed x = 0 end has small amplitude. Checking the values of y at the two ends,\n\n  \n    \n      \n        y\n        (\n        0\n        ,\n        t\n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle y(0,t)=0,}\n  \n\n  \n    \n      \n        y\n        (\n        L\n        ,\n        t\n        )\n        =\n        2\n        \n          y\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                2\n                \u03c0\n                L\n              \n              \u03bb\n            \n          \n          )\n        \n        cos\n        \u2061\n        (\n        \u03c9\n        t\n        )\n        =\n        0.\n      \n    \n    {\\displaystyle y(L,t)=2y_{\\text{max}}\\sin \\left({2\\pi L \\over \\lambda }\\right)\\cos(\\omega t)=0.}\n  \nThis boundary condition is in the form of the Sturm\u2013Liouville formulation. The latter boundary condition is satisfied when \n  \n    \n      \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                2\n                \u03c0\n                L\n              \n              \u03bb\n            \n          \n          )\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\sin \\left({2\\pi L \\over \\lambda }\\right)=0}\n  . L is given, so the boundary condition restricts the wavelength of the standing waves to\n\n  \n    \n      \n        n\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n      \n    \n    {\\displaystyle n=1,2,3,\\ldots }\n  Waves can only form standing waves on this string if they have a wavelength that satisfies this relationship with L. If waves travel with speed v along the string, then equivalently the frequency of the standing waves is restricted to\n\n  \n    \n      \n        f\n        =\n        \n          \n            v\n            \u03bb\n          \n        \n        =\n        \n          \n            \n              n\n              v\n            \n            \n              2\n              L\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {v}{\\lambda }}={\\frac {nv}{2L}}.}\n  The standing wave with n = 1 oscillates at the fundamental frequency and has a wavelength that is twice the length of the string. Higher integer values of n correspond to modes of oscillation called harmonics or overtones. Any standing wave on the string will have n + 1 nodes including the fixed ends and n anti-nodes.\nTo compare this example's nodes to the description of nodes for standing waves in the infinite length string, note that Equation (2) can be rewritten as\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              4\n              L\n            \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {4L}{n}},}\n  \n\n  \n    \n      \n        n\n        =\n        2\n        ,\n        4\n        ,\n        6\n        ,\n        \u2026\n      \n    \n    {\\displaystyle n=2,4,6,\\ldots }\n  In this variation of the expression for the wavelength, n must be even. Cross multiplying we see that because L is a node, it is an even multiple of a quarter wavelength,\n\n  \n    \n      \n        L\n        =\n        \n          \n            \n              n\n              \u03bb\n            \n            4\n          \n        \n        ,\n      \n    \n    {\\displaystyle L={\\frac {n\\lambda }{4}},}\n  \n\n  \n    \n      \n        n\n        =\n        2\n        ,\n        4\n        ,\n        6\n        ,\n        \u2026\n      \n    \n    {\\displaystyle n=2,4,6,\\ldots }\n  This example demonstrates a type of resonance and the frequencies that produce standing waves can be referred to as resonant frequencies.\n\n\n=== Standing wave on a string with one fixed end ===\n\nNext, consider the same string of length L, but this time it is only fixed at x = 0. At x = L, the string is free to move in the y direction. For example, the string might be tied at x = L to a ring that can slide freely up and down a pole. The string again has small damping and is driven by a small driving force at x = 0.\nIn this case, Equation (1) still describes the standing wave pattern that can form on the string, and the string has the same boundary condition of y = 0 at x = 0. However, at x = L where the string can move freely there should be an anti-node with maximal amplitude of y. Equivalently, this boundary condition of the \"free end\" can be stated as \u2202y/\u2202x = 0 at x = L, which is in the form of the Sturm\u2013Liouville formulation. The intuition for this boundary condition \u2202y/\u2202x = 0 at x = L is that the motion of the \"free end\" will follow that of the point to its left.\nReviewing Equation (1), for x = L the largest amplitude of y occurs when \u2202y/\u2202x = 0, or\n\n  \n    \n      \n        cos\n        \u2061\n        \n          (\n          \n            \n              \n                2\n                \u03c0\n                L\n              \n              \u03bb\n            \n          \n          )\n        \n        =\n        0.\n      \n    \n    {\\displaystyle \\cos \\left({2\\pi L \\over \\lambda }\\right)=0.}\n  This leads to a different set of wavelengths than in the two-fixed-ends example. Here, the wavelength of the standing waves is restricted to\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              4\n              L\n            \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {4L}{n}},}\n  \n\n  \n    \n      \n        n\n        =\n        1\n        ,\n        3\n        ,\n        5\n        ,\n        \u2026\n      \n    \n    {\\displaystyle n=1,3,5,\\ldots }\n  Equivalently, the frequency is restricted to\n\n  \n    \n      \n        f\n        =\n        \n          \n            \n              n\n              v\n            \n            \n              4\n              L\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {nv}{4L}}.}\n  Note that in this example n only takes odd values. Because L is an anti-node, it is an odd multiple of a quarter wavelength. Thus the fundamental mode in this example only has one quarter of a complete sine cycle\u2013zero at x = 0 and the first peak at x = L\u2013the first harmonic has three quarters of a complete sine cycle, and so on.\nThis example also demonstrates a type of resonance and the frequencies that produce standing waves are called resonant frequencies.\n\n\n=== Standing wave in a pipe ===\n\nConsider a standing wave in a pipe of length L. The air inside the pipe serves as the medium for longitudinal sound waves traveling to the right or left through the pipe. While the transverse waves on the string from the previous examples vary in their displacement perpendicular to the direction of wave motion, the waves traveling through the air in the pipe vary in terms of their pressure and longitudinal displacement along the direction of wave motion. The wave propagates by alternately compressing and expanding air in segments of the pipe, which displaces the air slightly from its rest position and transfers energy to neighboring segments through the forces exerted by the alternating high and low air pressures. Equations resembling those for the wave on a string can be written for the change in pressure \u0394p due to a right- or left-traveling wave in the pipe.\n\n  \n    \n      \n        \u0394\n        \n          p\n          \n            R\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          p\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                  x\n                \n                \u03bb\n              \n            \n            \u2212\n            \u03c9\n            t\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\Delta p_{\\text{R}}(x,t)=p_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }-\\omega t\\right),}\n  \n\n  \n    \n      \n        \u0394\n        \n          p\n          \n            L\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        \n          p\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                \n                  2\n                  \u03c0\n                  x\n                \n                \u03bb\n              \n            \n            +\n            \u03c9\n            t\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\Delta p_{\\text{L}}(x,t)=p_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }+\\omega t\\right),}\n  where\n\npmax is the pressure amplitude or the maximum increase or decrease in air pressure due to each wave,\n\u03c9 is the angular frequency or equivalently 2\u03c0 times the frequency f,\n\u03bb is the wavelength of the wave.If identical right- and left-traveling waves travel through the pipe, the resulting superposition is described by the sum\n\n  \n    \n      \n        \u0394\n        p\n        (\n        x\n        ,\n        t\n        )\n        =\n        \u0394\n        \n          p\n          \n            R\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        +\n        \u0394\n        \n          p\n          \n            L\n          \n        \n        (\n        x\n        ,\n        t\n        )\n        =\n        2\n        \n          p\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                2\n                \u03c0\n                x\n              \n              \u03bb\n            \n          \n          )\n        \n        cos\n        \u2061\n        (\n        \u03c9\n        t\n        )\n        .\n      \n    \n    {\\displaystyle \\Delta p(x,t)=\\Delta p_{\\text{R}}(x,t)+\\Delta p_{\\text{L}}(x,t)=2p_{\\text{max}}\\sin \\left({2\\pi x \\over \\lambda }\\right)\\cos(\\omega t).}\n  Note that this formula for the pressure is of the same form as Equation (1), so a stationary pressure wave forms that is fixed in space and oscillates in time.\nIf the end of a pipe is closed, the pressure is maximal since the closed end of the pipe exerts a force that restricts the movement of air. This corresponds to a pressure anti-node (which is a node for molecular motions, because the molecules near the closed end can't move). If the end of the pipe is open, the pressure variations are very small, corresponding to a pressure node (which is an anti-node for molecular motions, because the molecules near the open end can move freely). The exact location of the pressure node at an open end is actually slightly beyond the open end of the pipe, so the effective length of the pipe for the purpose of determining resonant frequencies is slightly longer than its physical length. This difference in length is ignored in this example. In terms of reflections, open ends partially reflect waves back into the pipe, allowing some energy to be released into the outside air. Ideally, closed ends reflect the entire wave back in the other direction.First consider a pipe that is open at both ends, for example an open organ pipe or a recorder. Given that the pressure must be zero at both open ends, the boundary conditions are analogous to the string with two fixed ends,\n\n  \n    \n      \n        \u0394\n        p\n        (\n        0\n        ,\n        t\n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\Delta p(0,t)=0,}\n  \n\n  \n    \n      \n        \u0394\n        p\n        (\n        L\n        ,\n        t\n        )\n        =\n        2\n        \n          p\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                2\n                \u03c0\n                L\n              \n              \u03bb\n            \n          \n          )\n        \n        cos\n        \u2061\n        (\n        \u03c9\n        t\n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\Delta p(L,t)=2p_{\\text{max}}\\sin \\left({2\\pi L \\over \\lambda }\\right)\\cos(\\omega t)=0,}\n  which only occurs when the wavelength of standing waves is\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              2\n              L\n            \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {2L}{n}},}\n  \n\n  \n    \n      \n        n\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n        ,\n      \n    \n    {\\displaystyle n=1,2,3,\\ldots ,}\n  or equivalently when the frequency is\n\n  \n    \n      \n        f\n        =\n        \n          \n            \n              n\n              v\n            \n            \n              2\n              L\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle f={\\frac {nv}{2L}},}\n  where v is the speed of sound.\nNext, consider a pipe that is open at x = 0 (and therefore has a pressure node) and closed at x = L (and therefore has a pressure anti-node). The closed \"free end\" boundary condition for the pressure at x = L can be stated as \u2202(\u0394p)/\u2202x = 0, which is in the form of the Sturm\u2013Liouville formulation. The intuition for this boundary condition \u2202(\u0394p)/\u2202x = 0 at x = L is that the pressure of the closed end will follow that of the point to its left. Examples of this setup include a bottle and a clarinet. This pipe has boundary conditions analogous to the string with only one fixed end. Its standing waves have wavelengths restricted to\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              4\n              L\n            \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {4L}{n}},}\n  \n\n  \n    \n      \n        n\n        =\n        1\n        ,\n        3\n        ,\n        5\n        ,\n        \u2026\n        ,\n      \n    \n    {\\displaystyle n=1,3,5,\\ldots ,}\n  or equivalently the frequency of standing waves is restricted to\n\n  \n    \n      \n        f\n        =\n        \n          \n            \n              n\n              v\n            \n            \n              4\n              L\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {nv}{4L}}.}\n  Note that for the case where one end is closed, n only takes odd values just like in the case of the string fixed at only one end.\n\nSo far, the wave has been written in terms of its pressure as a function of position x and time. Alternatively, the wave can be written in terms of its longitudinal displacement of air, where air in a segment of the pipe moves back and forth slightly in the x-direction as the pressure varies and waves travel in either or both directions. The change in pressure \u0394p and longitudinal displacement s are related as\n\n  \n    \n      \n        \u0394\n        p\n        =\n        \u2212\n        \u03c1\n        \n          v\n          \n            2\n          \n        \n        \n          \n            \n              \u2202\n              s\n            \n            \n              \u2202\n              x\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\Delta p=-\\rho v^{2}{\\frac {\\partial s}{\\partial x}},}\n  where \u03c1 is the density of the air. In terms of longitudinal displacement, closed ends of pipes correspond to nodes since air movement is restricted and open ends correspond to anti-nodes since the air is free to move. A similar, easier to visualize phenomenon occurs in longitudinal waves propagating along a spring.We can also consider a pipe that is closed at both ends. In this case, both ends will be pressure anti-nodes or equivalently both ends will be displacement nodes. This example is analogous to the case where both ends are open, except the standing wave pattern has a \u03c0\u20442 phase shift along the x-direction to shift the location of the nodes and anti-nodes. For example, the longest wavelength that resonates\u2013the fundamental mode\u2013is again twice the length of the pipe, except that the ends of the pipe have pressure anti-nodes instead of pressure nodes. Between the ends there is one pressure node. In the case of two closed ends, the wavelength is again restricted to\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            \n              2\n              L\n            \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lambda ={\\frac {2L}{n}},}\n  \n\n  \n    \n      \n        n\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n        ,\n      \n    \n    {\\displaystyle n=1,2,3,\\ldots ,}\n  and the frequency is again restricted to\n\n  \n    \n      \n        f\n        =\n        \n          \n            \n              n\n              v\n            \n            \n              2\n              L\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle f={\\frac {nv}{2L}}.}\n  A Rubens tube provides a way to visualize the pressure variations of the standing waves in a tube with two closed ends.\n\n\n=== 2D standing wave with a rectangular boundary ===\nNext, consider transverse waves that can move along a two dimensional surface within a rectangular boundary of length Lx in the x-direction and length Ly in the y-direction. Examples of this type of wave are water waves in a pool or waves on a rectangular sheet that has been pulled taut. The waves displace the surface in the z-direction, with z = 0 defined as the height of the surface when it is still.\nIn two dimensions and Cartesian coordinates, the wave equation is\n\n  \n    \n      \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              z\n            \n            \n              \u2202\n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        \n        =\n        \n        \n          c\n          \n            2\n          \n        \n        \n          (\n          \n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  z\n                \n                \n                  \u2202\n                  \n                    x\n                    \n                      2\n                    \n                  \n                \n              \n            \n            +\n            \n              \n                \n                  \n                    \u2202\n                    \n                      2\n                    \n                  \n                  z\n                \n                \n                  \u2202\n                  \n                    y\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {\\partial ^{2}z}{\\partial t^{2}}}\\;=\\;c^{2}\\left({\\frac {\\partial ^{2}z}{\\partial x^{2}}}+{\\frac {\\partial ^{2}z}{\\partial y^{2}}}\\right),}\n  where\n\nz(x,y,t) is the displacement of the surface,\nc is the speed of the wave.To solve this differential equation, let's first solve for its Fourier transform, with\n\n  \n    \n      \n        Z\n        (\n        x\n        ,\n        y\n        ,\n        \u03c9\n        )\n        =\n        \n          \u222b\n          \n            \u2212\n            \u221e\n          \n          \n            \u221e\n          \n        \n        z\n        (\n        x\n        ,\n        y\n        ,\n        t\n        )\n        \n          e\n          \n            \u2212\n            i\n            \u03c9\n            t\n          \n        \n        d\n        t\n        .\n      \n    \n    {\\displaystyle Z(x,y,\\omega )=\\int _{-\\infty }^{\\infty }z(x,y,t)e^{-i\\omega t}dt.}\n  Taking the Fourier transform of the wave equation,\n\n  \n    \n      \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              Z\n            \n            \n              \u2202\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              Z\n            \n            \n              \u2202\n              \n                y\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              \u03c9\n              \n                2\n              \n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n        Z\n        (\n        x\n        ,\n        y\n        ,\n        \u03c9\n        )\n        .\n      \n    \n    {\\displaystyle {\\frac {\\partial ^{2}Z}{\\partial x^{2}}}+{\\frac {\\partial ^{2}Z}{\\partial y^{2}}}=-{\\frac {\\omega ^{2}}{c^{2}}}Z(x,y,\\omega ).}\n  This is an eigenvalue problem where the frequencies correspond to eigenvalues that then correspond to frequency-specific modes or eigenfunctions. Specifically, this is a form of the Helmholtz equation and it can be solved using separation of variables. Assume\n\n  \n    \n      \n        Z\n        =\n        X\n        (\n        x\n        )\n        Y\n        (\n        y\n        )\n        .\n      \n    \n    {\\displaystyle Z=X(x)Y(y).}\n  Dividing the Helmholtz equation by Z,\n\n  \n    \n      \n        \n          \n            1\n            \n              X\n              (\n              x\n              )\n            \n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              X\n            \n            \n              \u2202\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              Y\n              (\n              y\n              )\n            \n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              Y\n            \n            \n              \u2202\n              \n                y\n                \n                  2\n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              \u03c9\n              \n                2\n              \n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n        =\n        0.\n      \n    \n    {\\displaystyle {\\frac {1}{X(x)}}{\\frac {\\partial ^{2}X}{\\partial x^{2}}}+{\\frac {1}{Y(y)}}{\\frac {\\partial ^{2}Y}{\\partial y^{2}}}+{\\frac {\\omega ^{2}}{c^{2}}}=0.}\n  This leads to two coupled ordinary differential equations. The x term equals a constant with respect to x that we can define as\n\n  \n    \n      \n        \n          \n            1\n            \n              X\n              (\n              x\n              )\n            \n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              X\n            \n            \n              \u2202\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        (\n        i\n        \n          k\n          \n            x\n          \n        \n        \n          )\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {1}{X(x)}}{\\frac {\\partial ^{2}X}{\\partial x^{2}}}=(ik_{x})^{2}.}\n  Solving for X(x),\n\n  \n    \n      \n        X\n        (\n        x\n        )\n        =\n        \n          A\n          \n            \n              k\n              \n                x\n              \n            \n          \n        \n        \n          e\n          \n            i\n            \n              k\n              \n                x\n              \n            \n            x\n          \n        \n        +\n        \n          B\n          \n            \n              k\n              \n                x\n              \n            \n          \n        \n        \n          e\n          \n            \u2212\n            i\n            \n              k\n              \n                x\n              \n            \n            x\n          \n        \n        .\n      \n    \n    {\\displaystyle X(x)=A_{k_{x}}e^{ik_{x}x}+B_{k_{x}}e^{-ik_{x}x}.}\n  This x-dependence is sinusoidal\u2013recalling Euler's formula\u2013with constants Akx and Bkx determined by the boundary conditions. Likewise, the y term equals a constant with respect to y that we can define as\n\n  \n    \n      \n        \n          \n            1\n            \n              Y\n              (\n              y\n              )\n            \n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              Y\n            \n            \n              \u2202\n              \n                y\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        (\n        i\n        \n          k\n          \n            y\n          \n        \n        \n          )\n          \n            2\n          \n        \n        =\n        \n          k\n          \n            x\n          \n          \n            2\n          \n        \n        \u2212\n        \n          \n            \n              \u03c9\n              \n                2\n              \n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {1}{Y(y)}}{\\frac {\\partial ^{2}Y}{\\partial y^{2}}}=(ik_{y})^{2}=k_{x}^{2}-{\\frac {\\omega ^{2}}{c^{2}}},}\n  and the dispersion relation for this wave is therefore\n\n  \n    \n      \n        \u03c9\n        =\n        c\n        \n          \n            \n              k\n              \n                x\n              \n              \n                2\n              \n            \n            +\n            \n              k\n              \n                y\n              \n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\omega =c{\\sqrt {k_{x}^{2}+k_{y}^{2}}}.}\n  Solving the differential equation for the y term,\n\n  \n    \n      \n        Y\n        (\n        y\n        )\n        =\n        \n          C\n          \n            \n              k\n              \n                y\n              \n            \n          \n        \n        \n          e\n          \n            i\n            \n              k\n              \n                y\n              \n            \n            y\n          \n        \n        +\n        \n          D\n          \n            \n              k\n              \n                y\n              \n            \n          \n        \n        \n          e\n          \n            \u2212\n            i\n            \n              k\n              \n                y\n              \n            \n            y\n          \n        \n        .\n      \n    \n    {\\displaystyle Y(y)=C_{k_{y}}e^{ik_{y}y}+D_{k_{y}}e^{-ik_{y}y}.}\n  Multiplying these functions together and applying the inverse Fourier transform, z(x,y,t) is a superposition of modes where each mode is the product of sinusoidal functions for x, y, and t,\n\n  \n    \n      \n        z\n        (\n        x\n        ,\n        y\n        ,\n        t\n        )\n        \u223c\n        \n          e\n          \n            \u00b1\n            i\n            \n              k\n              \n                x\n              \n            \n            x\n          \n        \n        \n          e\n          \n            \u00b1\n            i\n            \n              k\n              \n                y\n              \n            \n            y\n          \n        \n        \n          e\n          \n            \u00b1\n            i\n            \u03c9\n            t\n          \n        \n        .\n      \n    \n    {\\displaystyle z(x,y,t)\\sim e^{\\pm ik_{x}x}e^{\\pm ik_{y}y}e^{\\pm i\\omega t}.}\n  The constants that determine the exact sinusoidal functions depend on the boundary conditions and initial conditions. To see how the boundary conditions apply, consider an example like the sheet that has been pulled taut where z(x,y,t) must be zero all around the rectangular boundary. For the x dependence, z(x,y,t) must vary in a way that it can be zero at both x = 0 and x = Lx for all values of y and t. As in the one dimensional example of the string fixed at both ends, the sinusoidal function that satisfies this boundary condition is\n\n  \n    \n      \n        sin\n        \u2061\n        \n          \n            k\n            \n              x\n            \n          \n          x\n        \n        ,\n      \n    \n    {\\displaystyle \\sin {k_{x}x},}\n  with kx restricted to\n\n  \n    \n      \n        \n          k\n          \n            x\n          \n        \n        =\n        \n          \n            \n              n\n              \u03c0\n            \n            \n              L\n              \n                x\n              \n            \n          \n        \n        ,\n        \n        n\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n      \n    \n    {\\displaystyle k_{x}={\\frac {n\\pi }{L_{x}}},\\quad n=1,2,3,\\dots }\n  Likewise, the y dependence of z(x,y,t) must be zero at both y = 0 and y = Ly, which is satisfied by\n\n  \n    \n      \n        sin\n        \u2061\n        \n          \n            k\n            \n              y\n            \n          \n          y\n        \n        ,\n        \n        \n          k\n          \n            y\n          \n        \n        =\n        \n          \n            \n              m\n              \u03c0\n            \n            \n              L\n              \n                y\n              \n            \n          \n        \n        ,\n        \n        m\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n      \n    \n    {\\displaystyle \\sin {k_{y}y},\\quad k_{y}={\\frac {m\\pi }{L_{y}}},\\quad m=1,2,3,\\dots }\n  Restricting the wave numbers to these values also restricts the frequencies that resonate to\n\n  \n    \n      \n        \u03c9\n        =\n        c\n        \u03c0\n        \n          \n            \n              \n                (\n                \n                  \n                    n\n                    \n                      L\n                      \n                        x\n                      \n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n            +\n            \n              \n                (\n                \n                  \n                    m\n                    \n                      L\n                      \n                        y\n                      \n                    \n                  \n                \n                )\n              \n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\omega =c\\pi {\\sqrt {\\left({\\frac {n}{L_{x}}}\\right)^{2}+\\left({\\frac {m}{L_{y}}}\\right)^{2}}}.}\n  If the initial conditions for z(x,y,0) and its time derivative \u017c(x,y,0) are chosen so the t-dependence is a cosine function, then standing waves for this system take the form\n\n  \n    \n      \n        z\n        (\n        x\n        ,\n        y\n        ,\n        t\n        )\n        =\n        \n          z\n          \n            max\n          \n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                n\n                \u03c0\n                x\n              \n              \n                L\n                \n                  x\n                \n              \n            \n          \n          )\n        \n        sin\n        \u2061\n        \n          (\n          \n            \n              \n                m\n                \u03c0\n                y\n              \n              \n                L\n                \n                  y\n                \n              \n            \n          \n          )\n        \n        cos\n        \u2061\n        \n          (\n          \n            \u03c9\n            t\n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle z(x,y,t)=z_{\\text{max}}\\sin \\left({\\frac {n\\pi x}{L_{x}}}\\right)\\sin \\left({\\frac {m\\pi y}{L_{y}}}\\right)\\cos \\left(\\omega t\\right).}\n  \n\n  \n    \n      \n        n\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n        \n        m\n        =\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        \u2026\n      \n    \n    {\\displaystyle n=1,2,3,\\dots \\quad m=1,2,3,\\dots }\n  So, standing waves inside this fixed rectangular boundary oscillate in time at certain resonant frequencies parameterized by the integers n and m. As they oscillate in time, they do not travel and their spatial variation is sinusoidal in both the x- and y-directions such that they satisfy the boundary conditions. The fundamental mode, n = 1 and m = 1, has a single antinode in the middle of the rectangle. Varying n and m gives complicated but predictable two-dimensional patterns of nodes and antinodes inside the rectangle.Note from the dispersion relation that in certain situations different modes\u2013meaning different combinations of n and m\u2013may resonate at the same frequency even though they have different shapes for their x- and y-dependence. For example if the boundary is square, Lx = Ly, the modes n = 1 and m = 7, n = 7 and m = 1, and n = 5 and m = 5 all resonate at\n\n  \n    \n      \n        \u03c9\n        =\n        \n          \n            \n              c\n              \u03c0\n            \n            \n              L\n              \n                x\n              \n            \n          \n        \n        \n          \n            50\n          \n        \n        .\n      \n    \n    {\\displaystyle \\omega ={\\frac {c\\pi }{L_{x}}}{\\sqrt {50}}.}\n  Recalling that \u03c9 determines the eigenvalue in the Helmholtz equation above, the number of modes corresponding to each frequency relates to the frequency's multiplicity as an eigenvalue.\n\n\n== Standing wave ratio, phase, and energy transfer ==\n\nIf the two oppositely moving traveling waves are not of the same amplitude, they will not cancel completely at the nodes, the points where the waves are 180\u00b0 out of phase, so the amplitude of the standing wave will not be zero at the nodes, but merely a minimum.  Standing wave ratio (SWR) is the ratio of the amplitude at the antinode (maximum) to the amplitude at the node (minimum).  A pure standing wave will have an infinite SWR.  It will also have a constant phase at any point in space (but it may undergo a 180\u00b0 inversion every half cycle).  A finite, non-zero SWR indicates a wave that is partially stationary and partially travelling.  Such waves can be decomposed into a superposition of two waves: a travelling wave component and a stationary wave component.  An SWR of one indicates that the wave does not have a stationary component \u2013 it is purely a travelling wave, since the ratio of amplitudes is equal to 1.A pure standing wave does not transfer energy from the source to the destination.  However, the wave is still subject to losses in the medium.  Such losses will manifest as a finite SWR, indicating a travelling wave component leaving the source to supply the losses.  Even though the SWR is now finite, it may still be the case that no energy reaches the destination because the travelling component is purely supplying the losses.  However, in a lossless medium, a finite SWR implies a definite transfer of energy to the destination.\n\n\n== Examples ==\nOne easy example to understand standing waves is two people shaking either end of a jump rope.  If they shake in sync the rope can form a regular pattern of waves oscillating up and down, with stationary points along the rope where the rope is almost still (nodes) and points where the arc of the rope is maximum (antinodes).\n\n\n=== Acoustic resonance ===\n\nStanding waves are also observed in physical media such as strings and columns of air. Any waves traveling along the medium will reflect back when they reach the end. This effect is most noticeable in musical instruments where, at various multiples of a vibrating string or air column's natural frequency, a standing wave is created, allowing harmonics to be identified. Nodes occur at fixed ends and anti-nodes at open ends. If fixed at only one end, only odd-numbered harmonics are available. At the open end of a pipe the anti-node will not be exactly at the end as it is altered by its contact with the air and so end correction is used to place it exactly. The density of a string will affect the frequency at which harmonics will be produced; the greater the density the lower the frequency needs to be to produce a standing wave of the same harmonic.\n\n\n=== Visible light ===\nStanding waves are also observed in optical media such as optical waveguides and optical cavities. Lasers use optical cavities in the form of a pair of facing mirrors, which constitute a Fabry\u2013P\u00e9rot interferometer. The gain medium in the cavity (such as a crystal) emits light coherently, exciting standing waves of light in the cavity. The wavelength of light is very short (in the range of nanometers, 10\u22129 m) so the standing waves are microscopic in size. One use for standing light waves is to measure small distances, using optical flats.\n\n\n=== X-rays ===\nInterference between X-ray beams can form an X-ray standing wave (XSW) field. Because of the short wavelength of X-rays (less than 1 nanometer), this phenomenon can be exploited for measuring atomic-scale events at material surfaces. The XSW is generated in the region where an X-ray beam interferes with a diffracted beam from a nearly perfect single crystal surface or a reflection from an X-ray mirror. By tuning the crystal geometry or X-ray wavelength, the XSW can be translated in space, causing a shift in the X-ray fluorescence or photoelectron yield from the atoms near the surface. This shift can be analyzed to pinpoint the location of a particular atomic species relative to the underlying crystal structure or mirror surface. The XSW method has been used to clarify the atomic-scale details of dopants in semiconductors, atomic and molecular adsorption on surfaces, and chemical transformations involved in catalysis.\n\n\n=== Mechanical waves ===\nStanding waves can be mechanically induced into a solid medium using resonance.  One easy to understand example is two people shaking either end of a jump rope.  If they shake in sync, the rope will form a regular pattern with nodes and antinodes and appear to be stationary, hence the name standing wave.  Similarly a cantilever beam can have a standing wave imposed on it by applying a base excitation. In this case the free end moves the greatest distance laterally compared to any location along the beam.  Such a device can be used as a sensor to track changes in frequency or phase of the resonance of the fiber. One application is as a measurement device for dimensional metrology.\n\n\n=== Seismic waves ===\nStanding surface waves on the Earth are observed as free oscillations of the Earth.\n\n\n=== Faraday waves ===\nThe Faraday wave is a non-linear standing wave at the air-liquid interface induced by hydrodynamic instability. It can be used as a liquid-based template to assemble microscale materials.\n\n\n=== Seiches ===\nA seiche is an example of a standing wave in an enclosed body of water. It is characterised by the oscillatory behaviour of the water level at either end of the body and typically has a nodal point near the middle of the body where very little change in water level is observed. It should be distinguished from a simple storm surge where no oscillation is present. In sizeable lakes, the period of such oscillations may be between minutes and hours, for example Lake Geneva's longitudinal period is 73 minutes and its transversal seiche has a period of around 10 minutes, while Lake Huron can be seen to have resonances with periods between 1 and 2 hours. See Lake seiches.\n\n\n== See also ==\n\n\n=== Waves ===\n\n\n=== Electronics ===\n\n\n== Notes ==\n\n\n== References ==\nHalliday, David; Resnick, Robert; Walker, Jearl (2005). Fundamentals of Physics (7th ed.). John Wiley & Sons. ISBN 0-471-42959-7.\nSerway, Raymond A.; Faughn, Jerry S. (1992). College Physics (3rd ed.). Saunders College Publishing. ISBN 0-03-076377-0.\nStreets, J. (2010). \"Chapter 16 \u2013 Superposition and Standing Waves\" (PDF). Department of Physics. PHYS122 Fundamentals of Physics II. University of Maryland. Retrieved August 23, 2020.\n\n\n== External links ==\n Media related to Standing waves at Wikimedia Commons", "Sonic_boom": "A sonic boom is a sound associated with shock waves created when an object travels through the air faster than the speed of sound. Sonic booms generate enormous amounts of sound energy, sounding similar to an explosion or a thunderclap to the human ear. A decibel is the primary unit measurement of sound. \"A thunderclap is incredibly loud, producing levels between 100 and 120 dBA (decibels A)- the equivalent of standing near a jet during take-off.\"The crack of a supersonic bullet passing overhead or the crack of a bullwhip are examples of a sonic boom in miniature.Sonic booms due to large supersonic aircraft can be particularly loud and startling, tend to awaken people, and may cause minor damage to some structures. This led to prohibition of routine supersonic flight overland. Although they cannot be completely prevented, research suggests that with careful shaping of the vehicle, the nuisance due to the sonic booms may be reduced to the point that overland supersonic flight may become a feasible option.A sonic boom does not occur only at the moment an object crosses the sound barrier and neither is it heard in all directions emanating from the supersonic object. Rather, the boom is a continuous effect that occurs while the object is travelling at supersonic speeds and affects only observers that are positioned at a point that intersects a region in the shape of a geometrical cone behind the object. As the object moves, this conical region also moves behind it and when the cone passes over the observer, they will briefly experience the \"boom\".\n\n\n== Causes ==\nWhen an aircraft passes through the air, it creates a series of pressure waves in front of the aircraft and behind it, similar to the bow and stern waves created by a boat. These waves travel at the speed of sound and, as the speed of the object increases, the waves are forced together, or compressed, because they cannot get out of each other's way quickly enough. Eventually they merge into a single shock wave, which travels at the speed of sound, a critical speed known as Mach 1, and is approximately 1,192 km/h (741 mph) at sea level and 20 \u00b0C (68 \u00b0F).\nIn smooth flight, the shock wave starts at the nose of the aircraft and ends at the tail.  Because the different radial directions around the aircraft's direction of travel are equivalent (given the \"smooth flight\" condition), the shock wave forms a Mach cone, similar to a vapour cone, with the aircraft at its tip. The half-angle \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   between the direction of flight and the shock wave is given by:\n\n  \n    \n      \n        sin\n        \u2061\n        (\n        \u03b1\n        )\n        =\n        \n          \n            \n              v\n              \n                sound\n              \n            \n            \n              v\n              \n                object\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sin(\\alpha )={\\frac {v_{\\text{sound}}}{v_{\\text{object}}}}}\n  ,where  \n  \n    \n      \n        \n          \n            \n              v\n              \n                sound\n              \n            \n            \n              v\n              \n                object\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {v_{\\text{sound}}}{v_{\\text{object}}}}}\n   is the inverse \n  \n    \n      \n        \n          \n            (\n          \n        \n        \n          \n            1\n            \n              M\n              a\n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\Big (}{\\frac {1}{Ma}}{\\Big )}}\n   of the plane's Mach number (\n  \n    \n      \n        M\n        a\n        =\n        \n          \n            \n              v\n              \n                object\n              \n            \n            \n              v\n              \n                sound\n              \n            \n          \n        \n      \n    \n    {\\displaystyle Ma={\\frac {v_{\\text{object}}}{v_{\\text{sound}}}}}\n  ).  Thus the faster the plane travels, the finer and more pointed the cone is.\nThere is a rise in pressure at the nose, decreasing steadily to a negative pressure at the tail, followed by a sudden return to normal pressure after the object passes. This \"overpressure profile\" is known as an N-wave because of its shape. The \"boom\" is experienced when there is a sudden change in pressure; therefore, an N-wave causes two booms \u2013 one when the initial pressure-rise reaches an observer, and another when the pressure returns to normal. This leads to a distinctive \"double boom\" from a supersonic aircraft. When the aircraft is maneuvering, the pressure distribution changes into different forms, with a characteristic U-wave shape.\nSince the boom is being generated continually as long as the aircraft is supersonic, it fills out a narrow path on the ground following the aircraft's flight path, a bit like an unrolling red carpet, and hence known as the boom carpet.  Its width depends on the altitude of the aircraft. The distance from the point on the ground where the boom is heard to the aircraft depends on its altitude and the angle \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  .\nFor today's supersonic aircraft in normal operating conditions, the peak overpressure varies from less than 50 to 500 Pa (1 to 10 psf (pound per square foot)) for an N-wave boom. Peak overpressures for U-waves are amplified two to five times the N-wave, but this amplified overpressure impacts only a very small area when compared to the area exposed to the rest of the sonic boom. The strongest sonic boom ever recorded was 7,000 Pa (144 psf) and it did not cause injury to the researchers who were exposed to it. The boom was produced by an F-4 flying just above the speed of sound at an altitude of 100 feet (30 m). In recent tests, the maximum boom measured during more realistic flight conditions was 1,010 Pa (21 psf). There is a probability that some damage\u2014shattered glass, for example\u2014will result from a sonic boom. Buildings in good condition should suffer no damage by pressures of 530 Pa (11 psf) or less. And, typically, community exposure to sonic boom is below 100 Pa (2 psf). Ground motion resulting from sonic boom is rare and is well below structural damage thresholds accepted by the U.S. Bureau of Mines and other agencies.The power, or volume, of the shock wave depends on the quantity of air that is being accelerated, and thus the size and shape of the aircraft. As the aircraft increases speed the shock cone gets tighter around the craft and becomes weaker to the point that at very high speeds and altitudes no boom is heard.  The \"length\" of the boom from front to back depends on the length of the aircraft to a power of 3/2. Longer aircraft therefore \"spread out\" their booms more than smaller ones, which leads to a less powerful boom.Several smaller shock waves can and usually do form at other points on the aircraft, primarily at any convex points, or curves, the leading wing edge, and especially the inlet to engines. These secondary shockwaves are caused by the air being forced to turn around these convex points, which generates a shock wave in supersonic flow.\nThe later shock waves are somewhat faster than the first one, travel faster and add to the main shockwave at some distance away from the aircraft to create a much more defined N-wave shape. This maximizes both the magnitude and the \"rise time\" of the shock which makes the boom seem louder. On most aircraft designs the characteristic distance is about 40,000 feet (12,000 m), meaning that below this altitude the sonic boom will be \"softer\". However, the drag at this altitude or below makes supersonic travel particularly inefficient, which poses a serious problem.\n\n\n== Supersonic aircraft ==\nSupersonic aircraft are any aircraft that can achieve flight faster than Mach 1, which is supersonic. \"Supersonic includes speeds up to five times Mach than the speed of sound, or Mach 5.\" (Dunbar, 2015) The top mileage per hour for a Supersonic Aircraft normally ranges anywhere from 700 to 1,500 miles per hour (1,100 to 2,400 km/h). Typically, most aircraft do not exceed 1,500 mph (2,414 km/h). There are many variations of supersonic aircraft. Some models of a supersonic aircraft make use of better engineered aerodynamics that allow a few sacrifices in the aerodynamics of the model for thruster power. Other models use the efficiency and power of the thruster to allow a less aerodynamic model to achieve greater speeds. Typical model found in United States military use ranges from an average of $13 million to $35 million U.S dollars.\n\n\n== Measurement and examples ==\nThe pressure from sonic booms caused by aircraft is often a few pounds per square foot. A vehicle flying at greater altitude will generate lower pressures on the ground, because the shock wave reduces in intensity as it spreads out away from the vehicle, but the sonic booms are less affected by vehicle speed.\n\n\n== Abatement ==\n\nIn the late 1950s when supersonic transport (SST) designs were being actively pursued, it was thought that although the boom would be very large, the problems could be avoided by flying higher. This assumption was proven false when the North American XB-70 Valkyrie first flew, and it was found that the boom was a problem even at 70,000 feet (21,000 m). It was during these tests that the N-wave was first characterized.\nRichard Seebass and his colleague Albert George at Cornell University studied the problem extensively and eventually defined a \"figure of merit\" (FM) to characterize the sonic boom levels of different aircraft. FM is a function of the aircraft weight and the aircraft length. The lower this value, the less boom the aircraft generates, with figures of about 1 or lower being considered acceptable. Using this calculation, they found FMs of about 1.4 for Concorde and 1.9 for the Boeing 2707. This eventually doomed most SST projects as public resentment, mixed with politics, eventually resulted in laws that made any such aircraft less useful (flying supersonically only over water for instance). Small aeroplane designs like business jets are favoured and tend to produce minimal to no audible booms.Seebass and George also worked on the problem from a different angle, trying to spread out the N-wave laterally and temporally (longitudinally), by producing a strong and downwards-focused (SR-71 Blackbird, Boeing X-43) shock at a sharp, but wide angle nose cone, which will travel at slightly supersonic speed (bow shock), and using a swept back flying wing or an oblique flying wing to smooth out this shock along the direction of flight (the tail of the shock travels at sonic speed). To adapt this principle to existing planes, which generate a shock at their nose cone and an even stronger one at their wing leading edge, the fuselage below the wing is shaped according to the area rule. Ideally this would raise the characteristic altitude from 40,000 feet (12,000 m) to 60,000 feet (from 12,000 m to 18,000 m), which is where most SST aircraft were expected to fly.\n\nThis remained untested for decades, until DARPA started the Quiet Supersonic Platform project and funded the Shaped Sonic Boom Demonstration (SSBD) aircraft to test it. SSBD used an F-5 Freedom Fighter.  The F-5E was modified with a highly refined shape which lengthened the nose to that of the F-5F model.  The fairing extended from the nose all the way back to the inlets on the underside of the aircraft.  The SSBD was tested over a two-year period culminating in 21 flights and was an extensive study on sonic boom characteristics. After measuring the 1,300 recordings, some taken inside the shock wave by a chase plane, the SSBD demonstrated a reduction in boom by about one-third. Although one-third is not a huge reduction, it could have reduced Concorde's boom to an acceptable level below FM = 1.\nAs a follow-on to SSBD, in 2006 a NASA-Gulfstream Aerospace team tested the Quiet Spike on NASA-Dryden's F-15B aircraft 836.  The Quiet Spike is a telescoping boom fitted to the nose of an aircraft specifically designed to weaken the strength of the shock waves forming on the nose of the aircraft at supersonic speeds. Over 50 test flights were performed.  Several flights included probing of the shockwaves by a second F-15B, NASA's Intelligent Flight Control System testbed, aircraft 837.\nThere are theoretical designs that do not appear to create sonic booms at all, such as the Busemann biplane. However, creating a shockwave is inescapable if they generate aerodynamic lift.NASA and Lockheed Martin Aeronautics Co. are working together to build an experimental aircraft called the Low Boom Flight Demonstrator (LBFD), which will reduce the sonic boom synonymous with high-speed flight to the sound of a car door closing. The agency has awarded a $247.5 million contract to construct a working version of the sleek, single-pilot plane by summer 2021 and should begin testing over the following years to determine whether the design could eventually be adapted to commercial aircraft.\n\n\n== Perception, noise and other concerns ==\n\nThe sound of a sonic boom depends largely on the distance between the observer and the aircraft shape producing the sonic boom. A sonic boom is usually heard as a deep double \"boom\" as the aircraft is usually some distance away. The sound is much like that of mortar bombs, commonly used in firework displays. It is a common misconception that only one boom is generated during the subsonic to supersonic transition; rather, the boom is continuous along the boom carpet for the entire supersonic flight. As a former Concorde pilot puts it, \"You don't actually hear anything on board. All we see is the pressure wave moving down the aeroplane \u2013 it gives an indication on the instruments. And that's what we see around Mach 1. But we don't hear the sonic boom or anything like that. That's rather like the wake of a ship \u2013 it's behind us.\"In 1964, NASA and the Federal Aviation Administration began the Oklahoma City sonic boom tests, which caused eight sonic booms per day over a period of six months. Valuable data was gathered from the experiment, but 15,000 complaints were generated and ultimately entangled the government in a class-action lawsuit, which it lost on appeal in 1969.\nSonic booms were also a nuisance in North Cornwall and North Devon in the UK as these areas were underneath the flight path of Concorde. Windows would rattle and in some cases the \"torching\" (pointing underneath roof slates) would be dislodged with the vibration.\nThere has been recent work in this area, notably under DARPA's Quiet Supersonic Platform studies.  Research by acoustics experts under this program began looking more closely at the composition of sonic booms, including the frequency content.  Several characteristics of the traditional sonic boom \"N\" wave can influence how loud and irritating it can be perceived by listeners on the ground.  Even strong N-waves such as those generated by Concorde or military aircraft can be far less objectionable if the rise time of the over-pressure is sufficiently long.  A new metric has emerged, known as perceived loudness, measured in PLdB. This takes into account the frequency content, rise time, etc. A well-known example is the snapping of one's fingers in which the \"perceived\" sound is nothing more than an annoyance.\nThe energy range of sonic boom is concentrated in the 0.1\u2013100 hertz frequency range that is considerably below that of subsonic aircraft, gunfire and most industrial noise. Duration of sonic boom is brief; less than a second, 100 milliseconds (0.1 second) for most fighter-sized aircraft and 500 milliseconds for the space shuttle or Concorde jetliner. The intensity and width of a sonic boom path depends on the physical characteristics of the aircraft and how it is operated. In general, the greater an aircraft's altitude, the lower the over-pressure on the ground. Greater altitude also increases the boom's lateral spread, exposing a wider area to the boom. Over-pressures in the sonic boom impact area, however, will not be uniform. Boom intensity is greatest directly under the flight path, progressively weakening with greater horizontal distance away from the aircraft flight track.  Ground width of the boom exposure area is approximately 1 statute mile (1.6 km) for each 1,000 feet (300 m) of altitude (the width is about five times the altitude); that is, an aircraft flying supersonic at 30,000 feet (9,100 m) will create a lateral boom spread of about 30 miles (48 km). For steady supersonic flight, the boom is described as a carpet boom since it moves with the aircraft as it maintains supersonic speed and altitude. Some maneuvers, diving, acceleration or turning, can cause focusing of the boom. Other maneuvers, such as deceleration and climbing, can reduce the strength of the shock. In some instances weather conditions can distort sonic booms.Depending on the aircraft's altitude, sonic booms reach the ground 2 to 60 seconds after flyover. However, not all booms are heard at ground level. The speed of sound at any altitude is a function of air temperature. A decrease or increase in temperature results in a corresponding decrease or increase in sound speed. Under standard atmospheric conditions, air temperature decreases with increased altitude. For example, when sea-level temperature is 59 degrees Fahrenheit (15 \u00b0C), the temperature at 30,000 feet (9,100 m) drops to minus 49 degrees Fahrenheit (\u221245 \u00b0C). This temperature gradient helps bend the sound waves upward. Therefore, for a boom to reach the ground, the aircraft speed relative to the ground must be greater than the speed of sound at the ground. For example, the speed of sound at 30,000 feet (9,100 m) is about 670 miles per hour (1,080 km/h), but an aircraft must travel at least 750 miles per hour (1,210 km/h) (Mach 1.12) for a boom to be heard on the ground.The composition of the atmosphere is also a factor. Temperature variations, humidity, atmospheric pollution, and winds can all have an effect on how a sonic boom is perceived on the ground.  Even the ground itself can influence the sound of a sonic boom. Hard surfaces such as concrete, pavement, and large buildings can cause reflections which may amplify the sound of a sonic boom. Similarly, grassy fields and profuse foliage can help attenuate the strength of the over-pressure of a sonic boom.\nCurrently there are no industry-accepted standards for the acceptability of a sonic boom. However, work is underway to create metrics that will help in understanding how humans respond to the noise generated by sonic booms.  Until such metrics can be established, either through further study or supersonic overflight testing, it is doubtful that legislation will be enacted to remove the current prohibition on supersonic overflight in place in several countries, including the United States.\n\n\n== Bullwhip ==\n\nThe cracking sound a bullwhip makes when properly wielded is, in fact, a small sonic boom. The end of the whip, known as the \"cracker\", moves faster than the speed of sound, thus creating a sonic boom.A bullwhip tapers down from the handle section to the cracker. The cracker has much less mass than the handle section. When the whip is sharply swung, the momentum is transferred down the length of the tapering whip, the declining mass being made up for with increasing speed.  Goriely and McMillen showed that the physical explanation is complex, involving the way that a loop travels down a tapered filament under tension.\n\n\n== See also ==\nCherenkov radiation\nHypersonic\nSupershear earthquake\nGround vibration boom\n\n\n== References ==\n\nBanse, Tom. \"Supersonic Jets Could Return To Inland Northwest Skies\". OPB. Oregon Public Broadcasting. Retrieved 8 February 2022.\nV\u00e1zquez, M.; Dervieux, A.; Koobus, B. (September 2004). \"Multilevel optimization of a supersonic aircraft\". Finite Elements in Analysis and Design. 40 (15): 2101\u20132124. doi:10.1016/j.finel.2004.01.010.\nFox, Chris (4 June 2021). \"United plans supersonic passenger flights by 2029\". BBC News. Retrieved 30 November 2022.\nCooper, J.E. (2001), \"Aeroelastic Response\", Encyclopedia of Vibration, Elsevier, pp. 87\u201397, doi:10.1006/rwvb.2001.0125, ISBN 978-0-12-227085-7, retrieved 30 November 2022\nSmith, Heather R. (7 August 2017).  May, Sandra (ed.). \"What Is Supersonic Flight?\". NASA.\nF.S., Billig (August 1993). \"Research on Supersonic Combustion\". Journal of Propulsion and Power. Johns Hopkins University: John Hopkin University. 9 (4): 4. doi:10.2514/3.23652. Retrieved 6 February 2022.\n\n\n== External links ==\n\nArchived at Ghostarchive and the Wayback Machine: \"Audio Recording of SR-71 Blackbird Sonic Booms \u2013 YouTube\". YouTube. Retrieved 12 February 2015.\nBoston Globe profile of Spike Aerospace planned S-521 supersonic jet", "Frame_of_reference": "In physics and astronomy, a frame of reference (or reference frame) is an abstract coordinate system whose origin, orientation, and scale are specified by a set of reference points\u2015geometric points whose position is identified both mathematically (with numerical coordinate values) and physically (signaled by conventional markers).For n dimensions, n + 1 reference points are sufficient to fully define a reference frame. Using rectangular Cartesian coordinates, a reference frame may be defined with a reference point at the origin and a reference point at one unit distance along each of the n coordinate axes.In Einsteinian relativity, reference frames are used to specify the relationship between a moving observer and the phenomenon under observation. In this context, the term often becomes observational frame of reference (or observational reference frame), which implies that the observer is at rest in the frame, although not necessarily located at its origin. A relativistic reference frame includes (or implies) the coordinate time, which does not equate across different reference frames moving relatively to each other. The situation thus differs from Galilean relativity, in which all possible coordinate times are essentially equivalent.\n\n\n== Definition ==\nThe need to distinguish between the various meanings of \"frame of reference\" has led to a variety of terms. For example, sometimes the type of coordinate system is attached as a modifier, as in Cartesian frame of reference. Sometimes the state of motion is emphasized, as in rotating frame of reference. Sometimes the way it transforms to frames considered as related is emphasized as in Galilean frame of reference. Sometimes frames are distinguished by the scale of their observations, as in macroscopic and microscopic frames of reference.In this article, the term observational frame of reference is used when emphasis is upon the state of motion rather than upon the coordinate choice or the character of the observations or observational apparatus. In this sense, an observational frame of reference allows study of the effect of motion upon an entire family of coordinate systems that could be attached to this frame. On the other hand, a coordinate system may be employed for many purposes where the state of motion is not the primary concern. For example, a coordinate system may be adopted to take advantage of the symmetry of a system. In a still broader perspective, the formulation of many problems in physics employs generalized coordinates, normal modes or eigenvectors, which are only indirectly related to space and time. It seems useful to divorce the various aspects of a reference frame for the discussion below. We therefore take observational frames of reference, coordinate systems, and observational equipment as independent concepts, separated as below:\n\nAn observational frame (such as an inertial frame or non-inertial frame of reference) is a physical concept related to state of motion.\nA coordinate system is a mathematical concept, amounting to a choice of language used to describe observations. Consequently, an observer in an observational frame of reference can choose to employ any coordinate system (Cartesian, polar, curvilinear, generalized, \u2026) to describe observations made from that frame of reference. A change in the choice of this coordinate system does not change an observer's state of motion, and so does not entail a change in the observer's observational frame of reference. This viewpoint can be found elsewhere as well. Which is not to dispute that some coordinate systems may be a better choice for some observations than are others.Choice of what to measure and with what observational apparatus is a matter separate from the observer's state of motion and choice of coordinate system.\n\n\n== Coordinate systems ==\n\nAlthough the term \"coordinate system\" is often used (particularly by physicists) in a nontechnical sense, the term \"coordinate system\" does have a precise meaning in mathematics, and sometimes that is what the physicist means as well.\nA coordinate system in mathematics is a facet of geometry or of algebra, in particular, a property of manifolds (for example, in physics, configuration spaces or phase spaces). The coordinates of a point r in an n-dimensional space are simply an ordered set of n numbers:\n\n  \n    \n      \n        \n          r\n        \n        =\n        [\n        \n          x\n          \n            1\n          \n        \n        ,\n         \n        \n          x\n          \n            2\n          \n        \n        ,\n         \n        \u2026\n        ,\n         \n        \n          x\n          \n            n\n          \n        \n        ]\n        .\n      \n    \n    {\\displaystyle \\mathbf {r} =[x^{1},\\ x^{2},\\ \\dots ,\\ x^{n}].}\n  In a general Banach space, these numbers could be (for example) coefficients in a functional expansion like a Fourier series. In a physical problem, they could be spacetime coordinates or normal mode amplitudes. In a robot design, they could be angles of relative rotations, linear displacements, or deformations of joints. Here we will suppose these coordinates can be related to a Cartesian coordinate system by a set of functions:\n\n  \n    \n      \n        \n          x\n          \n            j\n          \n        \n        =\n        \n          x\n          \n            j\n          \n        \n        (\n        x\n        ,\n         \n        y\n        ,\n         \n        z\n        ,\n         \n        \u2026\n        )\n        ,\n        \n        j\n        =\n        1\n        ,\n         \n        \u2026\n        ,\n         \n        n\n        ,\n      \n    \n    {\\displaystyle x^{j}=x^{j}(x,\\ y,\\ z,\\ \\dots ),\\quad j=1,\\ \\dots ,\\ n,}\n  where x, y, z, etc. are the n Cartesian coordinates of the point. Given these functions, coordinate surfaces are defined by the relations:\n\n  \n    \n      \n        \n          x\n          \n            j\n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        \u2026\n        )\n        =\n        \n          c\n          o\n          n\n          s\n          t\n          a\n          n\n          t\n        \n        ,\n        \n        j\n        =\n        1\n        ,\n         \n        \u2026\n        ,\n         \n        n\n        .\n      \n    \n    {\\displaystyle x^{j}(x,y,z,\\dots )=\\mathrm {constant} ,\\quad j=1,\\ \\dots ,\\ n.}\n  The intersection of these surfaces define coordinate lines. At any selected point, tangents to the intersecting coordinate lines at that point define a set of basis vectors {e1, e2, \u2026, en} at that point. That is:\n\n  \n    \n      \n        \n          \n            e\n          \n          \n            i\n          \n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          lim\n          \n            \u03f5\n            \u2192\n            0\n          \n        \n        \n          \n            \n              \n                r\n              \n              \n                (\n                \n                  \n                    x\n                    \n                      1\n                    \n                  \n                  ,\n                   \n                  \u2026\n                  ,\n                   \n                  \n                    x\n                    \n                      i\n                    \n                  \n                  +\n                  \u03f5\n                  ,\n                   \n                  \u2026\n                  ,\n                   \n                  \n                    x\n                    \n                      n\n                    \n                  \n                \n                )\n              \n              \u2212\n              \n                r\n              \n              \n                (\n                \n                  \n                    x\n                    \n                      1\n                    \n                  \n                  ,\n                   \n                  \u2026\n                  ,\n                   \n                  \n                    x\n                    \n                      i\n                    \n                  \n                  ,\n                   \n                  \u2026\n                  ,\n                   \n                  \n                    x\n                    \n                      n\n                    \n                  \n                \n                )\n              \n            \n            \u03f5\n          \n        \n        ,\n        \n        i\n        =\n        1\n        ,\n         \n        \u2026\n        ,\n         \n        n\n        ,\n      \n    \n    {\\displaystyle \\mathbf {e} _{i}(\\mathbf {r} )=\\lim _{\\epsilon \\rightarrow 0}{\\frac {\\mathbf {r} \\left(x^{1},\\ \\dots ,\\ x^{i}+\\epsilon ,\\ \\dots ,\\ x^{n}\\right)-\\mathbf {r} \\left(x^{1},\\ \\dots ,\\ x^{i},\\ \\dots ,\\ x^{n}\\right)}{\\epsilon }},\\quad i=1,\\ \\dots ,\\ n,}\n  which can be normalized to be of unit length. For more detail see curvilinear coordinates.\nCoordinate surfaces, coordinate lines, and basis vectors are components of a coordinate system. If the basis vectors are orthogonal at every point, the coordinate system is an orthogonal coordinate system.\nAn important aspect of a coordinate system is its metric tensor gik, which determines the arc length ds in the coordinate system in terms of its coordinates:\n\n  \n    \n      \n        (\n        d\n        s\n        \n          )\n          \n            2\n          \n        \n        =\n        \n          g\n          \n            i\n            k\n          \n        \n         \n        d\n        \n          x\n          \n            i\n          \n        \n         \n        d\n        \n          x\n          \n            k\n          \n        \n        ,\n      \n    \n    {\\displaystyle (ds)^{2}=g_{ik}\\ dx^{i}\\ dx^{k},}\n  where repeated indices are summed over.\nAs is apparent from these remarks, a coordinate system is a mathematical construct, part of an axiomatic system. There is no necessary connection between coordinate systems and physical motion (or any other aspect of reality). However, coordinate systems can include time as a coordinate, and can be used to describe motion. Thus, Lorentz transformations and Galilean transformations may be viewed as coordinate transformations.\n\n\n== Observational frame of reference ==\n\nAn observational frame of reference, often referred to as a physical frame of reference, a frame of reference, or simply a frame, is a physical concept related to an observer and the observer's state of motion. Here we adopt the view expressed by Kumar and Barve: an observational frame of reference is characterized only by its state of motion. However, there is lack of unanimity on this point. In special relativity, the distinction is sometimes made between an observer and a frame. According to this view, a frame is an observer plus a coordinate lattice constructed to be an orthonormal right-handed set of spacelike vectors perpendicular to a timelike vector. See Doran. This restricted view is not used here, and is not universally adopted even in discussions of relativity. In general relativity the use of general coordinate systems is common (see, for example, the Schwarzschild solution for the gravitational field outside an isolated sphere).\nThere are two types of observational reference frame: inertial and non-inertial. An inertial frame of reference is defined as one in which all laws of physics take on their simplest form. In special relativity these frames are related by Lorentz transformations, which are parametrized by rapidity. In Newtonian mechanics, a more restricted definition requires only that Newton's first law holds true; that is, a Newtonian inertial frame is one in which a free particle travels in a straight line at constant speed, or is at rest. These frames are related by Galilean transformations. These relativistic and Newtonian transformations are expressed in spaces of general dimension in terms of representations of the Poincar\u00e9 group and of the Galilean group.\nIn contrast to the inertial frame, a non-inertial frame of reference is one in which fictitious forces must be invoked to explain observations. An example is an observational frame of reference centered at a point on the Earth's surface. This frame of reference orbits around the center of the Earth, which introduces the fictitious forces known as the Coriolis force, centrifugal force, and gravitational force. (All of these forces including gravity disappear in a truly inertial reference frame, which is one of free-fall.)\n\n\n== Measurement apparatus ==\nA further aspect of a frame of reference is the role of the measurement apparatus (for example, clocks and rods) attached to the frame (see Norton quote above). This question is not addressed in this article, and is of particular interest in quantum mechanics, where the relation between observer and measurement is still under discussion (see measurement problem).\nIn physics experiments, the frame of reference in which the laboratory measurement devices are at rest is usually referred to as the laboratory frame or simply \"lab frame.\" An example would be the frame in which the detectors for a particle accelerator are at rest. The lab frame in some experiments is an inertial frame, but it is not required to be (for example the laboratory on the surface of the Earth in many physics experiments is not inertial). In particle physics experiments, it is often useful to transform energies and momenta of particles from the lab frame where they are measured, to the center of momentum frame \"COM frame\" in which calculations are sometimes simplified, since potentially all kinetic energy still present in the COM frame may be used for making new particles.\nIn this connection it may be noted that the clocks and rods often used to describe observers' measurement equipment in thought, in practice are replaced by a much more complicated and indirect metrology that is connected to the nature of the vacuum, and uses atomic clocks that operate according to the standard model and that must be corrected for gravitational time dilation. (See second, meter and kilogram).\nIn fact, Einstein felt that clocks and rods were merely expedient measuring devices and they should be replaced by more fundamental entities based upon, for example, atoms and molecules.\n\n\n== Generalization ==\nThe discussion is taken beyond simple space-time coordinate systems by Brading and Castellani. Extension to coordinate systems using generalized coordinates underlies the Hamiltonian and Lagrangian formulations of quantum field theory, classical relativistic mechanics, and quantum gravity.\n\n\n== Instances ==\nInternational Terrestrial Reference Frame\nInternational Celestial Reference Frame\nIn fluid mechanics, Lagrangian and Eulerian specification of the flow fieldOther framesFrame fields in general relativity\nMoving frame in mathematics\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==", "Capacitor": "A capacitor is a device that stores electrical energy in an electric field by virtue of accumulating electric charges on two close surfaces insulated from each other. It is a passive electronic component with two terminals.\nThe effect of a capacitor is known as capacitance. While some capacitance exists between any two electrical conductors in proximity in a circuit, a capacitor is a component designed to add capacitance to a circuit.  The capacitor was originally known as the condenser, a term still encountered in a few compound names, such as the condenser microphone.\nThe physical form and construction of practical capacitors vary widely and many types of capacitor are in common use. Most capacitors contain at least two electrical conductors often in the form of metallic plates or surfaces separated by a dielectric medium. A conductor may be a foil, thin film, sintered bead of metal, or an electrolyte. The nonconducting dielectric acts to increase the capacitor's charge capacity. Materials commonly used as dielectrics include glass, ceramic, plastic film, paper, mica, air, and oxide layers. Capacitors are widely used as parts of electrical circuits in many common electrical devices. Unlike a resistor, an ideal capacitor does not dissipate energy, although real-life capacitors do dissipate a small amount (see Non-ideal behavior). When an electric potential difference (a voltage) is applied across the terminals of a capacitor, for example when a capacitor is connected across a battery, an electric field develops across the dielectric, causing a net positive charge to collect on one plate and net negative charge to collect on the other plate. No current actually flows through the dielectric. However, there is a flow of charge through the source circuit. If the condition is maintained sufficiently long, the current through the source circuit ceases. If a time-varying voltage is applied across the leads of the capacitor, the source experiences an ongoing current due to the charging and discharging cycles of the capacitor.\nThe earliest forms of capacitors were created in the 1740s, when European experimenters discovered that electric charge could be stored in water-filled glass jars that came to be known as Leyden jars. Today, capacitors are widely used in electronic circuits for blocking direct current while allowing alternating current to pass. In analog filter networks, they smooth the output of power supplies. In resonant circuits they tune radios to particular frequencies. In electric power transmission systems, they stabilize voltage and power flow. The property of energy storage in capacitors was exploited as dynamic memory in early digital computers, and still is in modern DRAM.\n\n\n== History ==\n\nIn October 1745, Ewald Georg von Kleist of Pomerania, Germany, found that charge could be stored by connecting a high-voltage electrostatic generator by a wire to a volume of water in a hand-held glass jar. Von Kleist's hand and the water acted as conductors and the jar as a dielectric (although details of the mechanism were incorrectly identified at the time). Von Kleist found that touching the wire resulted in a powerful spark, much more painful than that obtained from an electrostatic machine. The following year, the Dutch physicist Pieter van Musschenbroek invented a similar capacitor, which was named the Leyden jar, after the University of Leiden where he worked. He also was impressed by the power of the shock he received, writing, \"I would not take a second shock for the kingdom of France.\"Daniel Gralath was the first to combine several jars in parallel to increase the charge storage capacity. Benjamin Franklin investigated the Leyden jar and came to the conclusion that the charge was stored on the glass, not in the water as others had assumed. He also adopted the term \"battery\", (denoting the increase of power with a row of similar units as in a battery of cannon), subsequently applied to clusters of electrochemical cells. Leyden jars were later made by coating the inside and outside of jars with metal foil, leaving a space at the mouth to prevent arcing between the foils. The earliest unit of capacitance was the jar, equivalent to about 1.11 nanofarads.Leyden jars or more powerful devices employing flat glass plates alternating with foil conductors were used exclusively up until about 1900, when the invention of wireless (radio) created a demand for standard capacitors, and the steady move to higher frequencies required capacitors with lower inductance. More compact construction methods began to be used, such as a flexible dielectric sheet (like oiled paper) sandwiched between sheets of metal foil, rolled or folded into a small package.\n\nEarly capacitors were known as condensers, a term that is still occasionally used today, particularly in high power applications, such as automotive systems. The term was first used for this purpose by Alessandro Volta in 1782, with reference to the device's ability to store a higher density of electric charge than was possible with an isolated conductor.  The term became deprecated because of the ambiguous meaning of steam condenser, with capacitor becoming the recommended term in the UK from 1926, while the change occurred considerably later in the United States. In other countries, the term condensator has been in common use.Since the beginning of the study of electricity, non-conductive materials like glass, porcelain, paper and mica have been used as insulators. Decades later, these materials were also well-suited for use as the dielectric for the first capacitors.\nPaper capacitors, made by sandwiching a strip of impregnated paper between strips of metal and rolling the result into a cylinder, were commonly used in the late 19th century; their manufacture started in 1876, and they were used from the early 20th century as decoupling capacitors in telephony.\nPorcelain was used in the first ceramic capacitors. In the early years of Marconi's wireless transmitting apparatus, porcelain capacitors were used for high voltage and high frequency application in the transmitters. On the receiver side, smaller mica capacitors were used for resonant circuits. Mica capacitors were invented in 1909 by William Dubilier. Prior to World War II, mica was the most common dielectric for capacitors in the United States.Charles Pollak (born Karol Pollak), the inventor of the first electrolytic capacitors, found out that the oxide layer on an aluminum anode remained stable in a neutral or alkaline electrolyte, even when the power was switched off. In 1896 he was granted U.S. Patent No. 672,913 for an \"Electric liquid capacitor with aluminum electrodes\". Solid electrolyte tantalum capacitors were invented by Bell Laboratories in the early 1950s as a miniaturized and more reliable low-voltage support capacitor to complement their newly invented transistor.\nWith the development of plastic materials by organic chemists during the Second World War, the capacitor industry began to replace paper with thinner polymer films. One very early development in film capacitors was described in British Patent 587,953 in 1944.Electric double-layer capacitors (now supercapacitors) were invented in 1957 when H. Becker developed a \"Low voltage electrolytic capacitor with porous carbon electrodes\". He believed that the energy was stored as a charge in the carbon pores used in his capacitor as in the pores of the etched foils of electrolytic capacitors. Because the double layer mechanism was not known by him at the time, he wrote in the patent: \"It is not known exactly what is taking place in the component if it is used for energy storage, but it leads to an extremely high capacity.\"\nThe metal\u2013oxide\u2013semiconductor capacitor (MOS capacitor) originates from the metal\u2013oxide\u2013semiconductor field-effect transistor (MOSFET) structure, where the MOS capacitor is flanked by two doped regions. The MOSFET structure was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959. The MOS capacitor was later widely adopted as a storage capacitor in memory chips, and as the basic building block of the charge-coupled device (CCD) in image sensor technology. In dynamic random-access memory (DRAM), each memory cell typically consists of a MOSFET and MOS capacitor.\n\n\n== Theory of operation ==\n\n\n=== Overview ===\n\nA capacitor consists of two conductors separated by a non-conductive region. The non-conductive region can either be a vacuum or an electrical insulator material known as a dielectric. Examples of dielectric media are glass, air, paper, plastic, ceramic, and even a semiconductor depletion region chemically identical to the conductors. From Coulomb's law a charge on one conductor will exert a force on the charge carriers within the other conductor, attracting opposite polarity charge and repelling like polarity charges, thus an opposite polarity charge will be induced on the surface of the other conductor. The conductors thus hold equal and opposite charges on their facing surfaces, and the dielectric develops an electric field.\nAn ideal capacitor is characterized by a constant capacitance C, in farads in the SI system of units, defined as the ratio of the positive or negative charge Q on each conductor to the voltage V between them:\nA capacitance of one farad (F) means that one coulomb of charge on each conductor causes a voltage of one volt across the device. Because the conductors (or plates) are close together, the opposite charges on the conductors attract one another due to their electric fields, allowing the capacitor to store more charge for a given voltage than when the conductors are separated, yielding a larger capacitance.\nIn practical devices, charge build-up sometimes affects the capacitor mechanically, causing its capacitance to vary. In this case, capacitance is defined in terms of incremental changes:\n\n\n=== Hydraulic analogy ===\n\nIn the hydraulic analogy, charge carriers flowing through a wire are analogous to water flowing through a pipe. A capacitor is like a rubber membrane sealed inside a pipe. Water molecules cannot pass through the membrane, but some water can move by stretching the membrane. The pressure differential is analogous to voltage, while the rate of flow is analogous to electric current:\n\nThe current alters the charge on a capacitor: just as the flow of water changes the position of the membrane. More specifically, the effect of an electric current is to increase the charge of one plate of the capacitor, and decrease the charge of the other plate by an equal amount. This is just as when water flow moves the rubber membrane, it increases the amount of water on one side of the membrane, and decreases the amount of water on the other side.\nThe more a capacitor is charged, the larger its voltage drop: as the membrane stretches, allowing more water to flow in from the high pressure side, the membrane \"pushes back\" against the charging current, increasing the pressure differential between the two sides.\nCharge can flow \"through\" a capacitor even though no individual electron can get from one side to the other.  As more water flows into the high pressure side, the expanding membrane pushes an equal quantity of water out of the low pressure side. The flow cannot continue in the same direction forever; the capacitor experiences dielectric breakdown, and analogously the membrane will eventually break.\nThe capacitance describes how much charge can be stored on one plate of a capacitor for a given voltage drop.  The elasticity of the membrane is analogous to capacitance.  A very stretchy, flexible membrane will expand more with a given pressure differential, allowing a greater volume of water to flow into the high pressure side.  This corresponds to a higher capacitance than a stiff membrane.\nA charged capacitor stores potential energy, analogously to a stretched membrane.\n\n\n=== Circuit equivalence at short-time limit and long-time limit ===\nIn a circuit, a capacitor can behave differently at different time instants. However, it is usually easy to think about the short-time limit and long-time limit:\n\nIn the long-time limit, after the charging/discharging current has saturated the capacitor, no current would come into (or get out of) either side of the capacitor; Therefore, the long-time equivalence of capacitor is an open circuit.\nIn the short-time limit, if the capacitor starts with a certain voltage V, since the voltage drop on the capacitor is known at this instant, we can replace it with an ideal voltage source of voltage V. Specifically, if V=0 (capacitor is uncharged), the short-time equivalence of a capacitor is a short circuit.\n\n\n=== Parallel-plate capacitor ===\n\nThe simplest model of a capacitor consists of two thin parallel conductive plates each with an area of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   separated by a uniform gap of thickness \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   filled with a dielectric with permittivity \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n  .  It is assumed the gap \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   is much smaller than the dimensions of the plates.  This model applies well to many practical capacitors which are constructed of metal sheets separated by a thin layer of insulating dielectric, since manufacturers try to keep the dielectric very uniform in thickness to avoid thin spots which can cause failure of the capacitor.\nSince the separation between the plates is uniform over the plate area, the electric field between the plates \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is constant, and directed perpendicularly to the plate surface, except for an area near the edges of the plates where the field decreases because the electric field lines \"bulge\" out of the sides of the capacitor. This \"fringing field\" area is approximately the same width as the plate separation, \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  , and assuming \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   is small compared to the plate dimensions, it is small enough to be ignored.  Therefore, if a charge of \n  \n    \n      \n        +\n        Q\n      \n    \n    {\\displaystyle +Q}\n   is placed on one plate and \n  \n    \n      \n        \u2212\n        Q\n      \n    \n    {\\displaystyle -Q}\n   on the other plate (the situation for unevenly charged plates is discussed below), the charge on each plate will be spread evenly in a surface charge layer of constant charge density \n  \n    \n      \n        \u03c3\n        =\n        \u00b1\n        Q\n        \n          /\n        \n        A\n      \n    \n    {\\displaystyle \\sigma =\\pm Q/A}\n   coulombs per square meter, on the inside surface of each plate.  From Gauss's law the magnitude of the electric field between the plates is \n  \n    \n      \n        E\n        =\n        \u03c3\n        \n          /\n        \n        \u03b5\n      \n    \n    {\\displaystyle E=\\sigma /\\varepsilon }\n  .  The voltage(difference) \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   between the plates is defined as the line integral of the electric field over a line (in the z-direction) from one plate to another\n\nThe capacitance is defined as \n  \n    \n      \n        C\n        =\n        Q\n        \n          /\n        \n        V\n      \n    \n    {\\displaystyle C=Q/V}\n  .  Substituting \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   above into this equation\n\nTherefore, in a capacitor the highest capacitance is achieved with a high permittivity dielectric material, large plate area, and small separation between the plates.\nSince the area \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   of the plates increases with the square of the linear dimensions and the separation \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   increases linearly, the capacitance scales with the linear dimension of a capacitor (\n  \n    \n      \n        C\n        \u221d\n        L\n      \n    \n    {\\displaystyle C\\varpropto L}\n  ), or as the cube root of the volume.\nA parallel plate capacitor can only store a finite amount of energy before dielectric breakdown occurs. The capacitor's dielectric material has a dielectric strength Ud which sets the capacitor's breakdown voltage at V = Vbd = Udd. The maximum energy that the capacitor can store is therefore\n\nThe maximum energy is a function of dielectric volume, permittivity, and dielectric strength. Changing the plate area and the separation between the plates while maintaining the same volume causes no change of the maximum amount of energy that the capacitor can store, so long as the distance between plates remains much smaller than both the length and width of the plates. In addition, these equations assume that the electric field is entirely concentrated in the dielectric between the plates. In reality there are fringing fields outside the dielectric, for example between the sides of the capacitor plates, which increase the effective capacitance of the capacitor. This is sometimes called parasitic capacitance. For some simple capacitor geometries this additional capacitance term can be calculated analytically. It becomes negligibly small when the ratios of plate width to separation and length to separation are large.\nFor unevenly charged plates:\n\nIf one plate is charged with \n  \n    \n      \n        \n          Q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle Q_{1}}\n   while the other is charged with \n  \n    \n      \n        \n          Q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle Q_{2}}\n  , and if both plates are separated from other materials in the environment, then the inner surface of the first plate will have \n  \n    \n      \n        \n          \n            \n              \n                Q\n                \n                  1\n                \n              \n              \u2212\n              \n                Q\n                \n                  2\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {Q_{1}-Q_{2}}{2}}}\n  , and the inner surface of the second plated will have \n  \n    \n      \n        \u2212\n        \n          \n            \n              \n                Q\n                \n                  1\n                \n              \n              \u2212\n              \n                Q\n                \n                  2\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\textstyle -{\\frac {Q_{1}-Q_{2}}{2}}}\n   charge. Therefore, the voltage \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   between the plates is \n  \n    \n      \n        V\n        =\n        \n          \n            \n              \n                Q\n                \n                  1\n                \n              \n              \u2212\n              \n                Q\n                \n                  2\n                \n              \n            \n            \n              2\n              C\n            \n          \n        \n      \n    \n    {\\textstyle V={\\frac {Q_{1}-Q_{2}}{2C}}}\n  . Note that the outer surface of both plates will have \n  \n    \n      \n        \n          \n            \n              \n                Q\n                \n                  1\n                \n              \n              +\n              \n                Q\n                \n                  2\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {Q_{1}+Q_{2}}{2}}}\n  , but those charges don't affect the voltage between the plates.\nIf one plate is charged with \n  \n    \n      \n        \n          Q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle Q_{1}}\n   while the other is charged with \n  \n    \n      \n        \n          Q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle Q_{2}}\n  , and if the second plate is connected to ground, then the inner surface of the first plate will have \n  \n    \n      \n        \n          Q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle Q_{1}}\n  , and the inner surface of the second plated will have \n  \n    \n      \n        \u2212\n        \n          Q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle -Q_{1}}\n  . Therefore, the voltage \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   between the plates is \n  \n    \n      \n        V\n        =\n        \n          \n            \n              Q\n              \n                1\n              \n            \n            C\n          \n        \n      \n    \n    {\\textstyle V={\\frac {Q_{1}}{C}}}\n  . Note that the outer surface of both plates will have zero charge.\n\n\n=== Interleaved capacitor ===\n\nFor \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   number of plates in a capacitor, the total capacitance would be\n\nwhere \n  \n    \n      \n        C\n        =\n        \n          \u03b5\n          \n            o\n          \n        \n        A\n        \n          /\n        \n        d\n      \n    \n    {\\displaystyle C=\\varepsilon _{o}A/d}\n   is the capacitance for a single plate and \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is the number of interleaved plates.\nAs shown to the figure on the right, the interleaved plates can be seen as parallel plates connected to each other. Every pair of adjacent plates acts as a separate capacitor; the number of pairs is always one less than the number of plates, hence the \n  \n    \n      \n        (\n        n\n        \u2212\n        1\n        )\n      \n    \n    {\\displaystyle (n-1)}\n   multiplier.\n\n\n=== Energy stored in a capacitor ===\nTo increase the charge and voltage on a capacitor, work must be done by an external power source to move charge from the negative to the positive plate against the opposing force of the electric field. If the voltage on the capacitor is \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  , the work \n  \n    \n      \n        d\n        W\n      \n    \n    {\\displaystyle dW}\n   required to move a small increment of charge \n  \n    \n      \n        d\n        q\n      \n    \n    {\\displaystyle dq}\n   from the negative to the positive plate is \n  \n    \n      \n        d\n        W\n        =\n        V\n        d\n        q\n      \n    \n    {\\displaystyle dW=Vdq}\n  . The energy is stored in the increased electric field between the plates.  The total energy \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n   stored in a capacitor (expressed in joules) is equal to the total work done in establishing the electric field from an uncharged state.\nwhere \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   is the charge stored in the capacitor, \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the voltage across the capacitor, and \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   is the capacitance.  This potential energy will remain in the capacitor until the charge is removed. If charge is allowed to move back from the positive to the negative plate, for example by connecting a circuit with resistance between the plates, the charge moving under the influence of the electric field will do work on the external circuit.\nIf the gap between the capacitor plates \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   is constant, as in the parallel plate model above, the electric field between the plates will be uniform (neglecting fringing fields) and will have a constant value \n  \n    \n      \n        E\n        =\n        V\n        \n          /\n        \n        d\n      \n    \n    {\\displaystyle E=V/d}\n  .  In this case the stored energy can be calculated from the electric field strength\n\nThe last formula above is equal to the energy density per unit volume in the electric field multiplied by the volume of field between the plates, confirming that the energy in the capacitor is stored in its electric field.\n\n\n=== Current\u2013voltage relation ===\nThe current I(t) through any component in an electric circuit is defined as the rate of flow of a charge Q(t) passing through it. Actual charges \u2013 electrons \u2013 cannot pass through the dielectric layer of a capacitor. Rather, one electron accumulates on the negative plate for each one that leaves the positive plate, resulting in an electron depletion and consequent positive charge on one electrode that is equal and opposite to the accumulated negative charge on the other. Thus the charge on the electrodes is equal to the integral of the current as well as proportional to the voltage, as discussed above. As with any antiderivative, a constant of integration is added to represent the initial voltage V(t0). This is the integral form of the capacitor equation:\nTaking the derivative of this and multiplying by C yields the derivative form:\nfor C independent of time, voltage and electric charge.\nThe dual of the capacitor is the inductor, which stores energy in a magnetic field rather than an electric field. Its current-voltage relation is obtained by exchanging current and voltage in the capacitor equations and replacing C with the inductance L.\n\n\n=== DC circuits ===\n\nA series circuit containing only a resistor, a capacitor, a switch and a constant DC source of voltage V0 is known as a charging circuit. If the capacitor is initially uncharged while the switch is open, and the switch is closed at t = 0, it follows from Kirchhoff's voltage law that\n\nTaking the derivative and multiplying by C, gives a first-order differential equation:\n\nAt t = 0, the voltage across the capacitor is zero and the voltage across the resistor is V0. The initial current is then I(0) = V0/R. With this assumption, solving the differential equation yields\n\nwhere \u03c40 = RC is the time constant of the system. As the capacitor reaches equilibrium with the source voltage, the voltages across the resistor and the current through the entire circuit decay exponentially. In the case of a discharging capacitor, the capacitor's initial voltage (VCi) replaces V0. The equations become\n\n\n=== AC circuits ===\n\nImpedance, the vector sum of reactance and resistance, describes the phase difference and the ratio of amplitudes between sinusoidally varying voltage and sinusoidally varying current at a given frequency. Fourier analysis allows any signal to be constructed from a spectrum of frequencies, whence the circuit's reaction to the various frequencies may be found. The reactance and impedance of a capacitor are respectively\n\nwhere j is the imaginary unit and \u03c9 is the angular frequency of the sinusoidal signal. The \u2212j phase indicates that the AC voltage V = ZI lags the AC current by 90\u00b0: the positive current phase corresponds to increasing voltage as the capacitor charges; zero current corresponds to instantaneous constant voltage, etc.\nImpedance decreases with increasing capacitance and increasing frequency. This implies that a higher-frequency signal or a larger capacitor results in a lower voltage amplitude per current amplitude \u2013 an AC \"short circuit\" or AC coupling. Conversely, for very low frequencies, the reactance is high, so that a capacitor is nearly an open circuit in AC analysis \u2013 those frequencies have been \"filtered out\".\nCapacitors are different from resistors and inductors in that the impedance is inversely proportional to the defining characteristic; i.e., capacitance.\nA capacitor connected to a sinusoidal voltage source causes a displacement current to flow through it. In the case that the voltage source is V0cos(\u03c9t), the displacement current can be expressed as:\n\nAt sin(\u03c9t) = \u22121, the capacitor has a maximum (or peak) current whereby I0 = \u03c9CV0. The ratio of peak voltage to peak current is due to capacitive reactance (denoted XC).\n\nXC approaches zero as \u03c9 approaches infinity. If XC approaches 0, the capacitor resembles a short wire that strongly passes current at high frequencies. XC approaches infinity as \u03c9 approaches zero. If XC approaches infinity, the capacitor resembles an open circuit that poorly passes low frequencies.\nThe current of the capacitor may be expressed in the form of cosines to better compare with the voltage of the source:\n\nIn this situation, the current is out of phase with the voltage by +\u03c0/2 radians or +90 degrees, i.e. the current leads the voltage by 90\u00b0.\n\n\n=== Laplace circuit analysis (s-domain) ===\nWhen using the Laplace transform in circuit analysis, the impedance of an ideal capacitor with no initial charge is represented in the s domain by:\n\nwhere\n\nC is the capacitance, and\ns is the complex frequency.\n\n\n=== Circuit analysis ===\n\nFor capacitors in parallel\n\nCapacitors in a parallel configuration each have the same applied voltage. Their capacitances add up. Charge is apportioned among them by size. Using the schematic diagram to visualize parallel plates, it is apparent that each capacitor contributes to the total surface area.  \nFor capacitors in series\n\nConnected in series, the schematic diagram reveals that the separation distance, not the plate area, adds up. The capacitors each store instantaneous charge build-up equal to that of every other capacitor in the series. The total voltage difference from end to end is apportioned to each capacitor according to the inverse of its capacitance. The entire series acts as a capacitor smaller than any of its components. \nCapacitors are combined in series to achieve a higher working voltage, for example for smoothing a high voltage power supply. The voltage ratings, which are based on plate separation, add up, if capacitance and leakage currents for each capacitor are identical. In such an application, on occasion, series strings are connected in parallel, forming a matrix. The goal is to maximize the energy storage of the network without overloading any capacitor. For high-energy storage with capacitors in series, some safety considerations must be applied to ensure one capacitor failing and leaking current does not apply too much voltage to the other series capacitors.\nSeries connection is also sometimes used to adapt polarized electrolytic capacitors for bipolar AC use. \nVoltage distribution in parallel-to-series networks.\nTo model the distribution of voltages from a single charged capacitor \n  \n    \n      \n        \n          (\n          A\n          )\n        \n      \n    \n    {\\displaystyle \\left(A\\right)}\n   connected in parallel to a chain of capacitors in series \n  \n    \n      \n        \n          (\n          \n            B\n            \n              n\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left(B_{\\text{n}}\\right)}\n  : \nNote: This is only correct if all capacitance values are equal.\nThe power transferred in this arrangement is: \n\n\n== Non-ideal behavior ==\n\nIn practice, capacitors deviate from the ideal capacitor equation in several aspects. Some of these, such as leakage current and parasitic effects are linear, or can be analyzed as nearly linear, and can be accounted for by adding virtual components to the equivalent circuit of an ideal capacitor. The usual methods of network analysis can then be applied. In other cases, such as with breakdown voltage, the effect is non-linear and ordinary (normal, e.g., linear) network analysis cannot be used, the effect must be considered separately. Yet another group of artifacts may exist, including temperature dependence, that may be linear but invalidates the assumption in the analysis that capacitance is a constant. Finally, combined parasitic effects such as inherent inductance, resistance, or dielectric losses can exhibit non-uniform behavior at varying frequencies of operation.\n\n\n=== Breakdown voltage ===\n\nAbove a particular electric field strength, known as the dielectric strength Eds, the dielectric in a capacitor becomes conductive. The voltage at which this occurs is called the breakdown voltage of the device, and is given by the product of the dielectric strength and the separation between the conductors,\nThe maximum energy that can be stored safely in a capacitor is limited by the breakdown voltage. Due to the scaling of capacitance and breakdown voltage with dielectric thickness, all capacitors made with a particular dielectric have approximately equal maximum energy density, to the extent that the dielectric dominates their volume.For air dielectric capacitors the breakdown field strength is of the order 2\u20135 MV/m (or kV/mm); for mica the breakdown is 100\u2013300 MV/m; for oil, 15\u201325 MV/m; it can be much less when other materials are used for the dielectric. The dielectric is used in very thin layers and so absolute breakdown voltage of capacitors is limited. Typical ratings for capacitors used for general electronics applications range from a few volts to 1 kV. As the voltage increases, the dielectric must be thicker, making high-voltage capacitors larger per capacitance than those rated for lower voltages.\nThe breakdown voltage is critically affected by factors such as the geometry of the capacitor conductive parts; sharp edges or points increase the electric field strength at that point and can lead to a local breakdown. Once this starts to happen, the breakdown quickly tracks through the dielectric until it reaches the opposite plate, leaving carbon behind and causing a short (or relatively low resistance) circuit. The results can be explosive, as the short in the capacitor draws current from the surrounding circuitry and dissipates the energy. However, in capacitors with particular dielectrics and thin metal electrodes shorts are not formed after breakdown. It happens because a metal melts or evaporates in a breakdown vicinity, isolating it from the rest of the capacitor.The usual breakdown route is that the field strength becomes large enough to pull electrons in the dielectric from their atoms thus causing conduction. Other scenarios are possible, such as impurities in the dielectric, and, if the dielectric is of a crystalline nature, imperfections in the crystal structure can result in an avalanche breakdown as seen in semi-conductor devices. Breakdown voltage is also affected by pressure, humidity and temperature.\n\n\n=== Equivalent circuit ===\n\nAn ideal capacitor only stores and releases electrical energy, without dissipation. In practice, all capacitors have imperfections within the capacitor's materials that permit leakage current, and represent resistance. This is specified as the equivalent series resistance (ESR) of the device. It add a real-valued component to the impedance:\n\nAs frequency approaches infinity, the capacitive impedance (reactance) approaches zero and the ESR becomes significant. As the reactance becomes negligible, power dissipation approaches PRMS = VRMS2 /RESR.\nSimilarly to ESR, the capacitor's leads add equivalent series inductance (ESL) to the component. This is usually significant only at relatively high frequencies. As inductive reactance is positive and increases with frequency, capacitance is canceled by inductance above a certain frequency. High-frequency engineering involves accounting for the inductance of all connections and components.\nIf the conductors are separated by a material with a small conductivity rather than a perfect dielectric, then a small leakage current flows directly between them. The capacitor therefore has a finite parallel resistance, and slowly discharges over time, which may vary greatly depending on the capacitor material and quality.\n\n\n=== Q factor ===\nThe quality factor (or Q) of a capacitor is the ratio of its reactance to its resistance at a given frequency, and is a measure of its efficiency. The higher the Q factor of the capacitor, the closer it approaches the behavior of an ideal capacitor.\nThe Q factor of a capacitor can be found through the following formula:\n\nwhere \n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   is angular frequency, \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   is the capacitance, \n  \n    \n      \n        \n          X\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle X_{C}}\n   is the capacitive reactance, and \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   is the equivalent series resistance (ESR) of the capacitor.\n\n\n=== Ripple current ===\nRipple current is the AC component of an applied source (often a switched-mode power supply) whose frequency may be constant or varying. Ripple current causes heat to be generated within the capacitor due to the dielectric losses caused by the changing field strength together with the current flow across the slightly resistive supply lines or the electrolyte in the capacitor. The equivalent series resistance (ESR) is the amount of internal series resistance one would add to a perfect capacitor to model this.\nSome types of capacitors, primarily tantalum and aluminum electrolytic capacitors, as well as some film capacitors have a specified rating value for maximum ripple current.\n\nTantalum electrolytic capacitors with solid manganese dioxide electrolyte are limited by ripple current and generally have the highest ESR ratings in the capacitor family. Exceeding their ripple limits can lead to shorts and burning parts.\nAluminum electrolytic capacitors, the most common type of electrolytic, suffer a shortening of life expectancy at higher ripple currents. If ripple current exceeds the rated value of the capacitor, it tends to result in explosive failure.\nCeramic capacitors generally have no ripple current limitation and have some of the lowest ESR ratings.\nFilm capacitors have very low ESR ratings but exceeding rated ripple current may cause degradation failures.\n\n\n=== Capacitance instability ===\nThe capacitance of certain capacitors decreases as the component ages. In ceramic capacitors, this is caused by degradation of the dielectric. The type of dielectric, ambient operating and storage temperatures are the most significant aging factors, while the operating voltage usually has a smaller effect, i.e., usual capacitor design is to minimize voltage coefficient. The aging process may be reversed by heating the component above the Curie point. Aging is fastest near the beginning of life of the component, and the device stabilizes over time. Electrolytic capacitors age as the electrolyte evaporates. In contrast with ceramic capacitors, this occurs towards the end of life of the component.\nTemperature dependence of capacitance is usually expressed in parts per million (ppm) per \u00b0C. It can usually be taken as a broadly linear function but can be noticeably non-linear at the temperature extremes. The temperature coefficient can be either positive or negative, sometimes even amongst different samples of the same type. In other words, the spread in the range of temperature coefficients can encompass zero.\nCapacitors, especially ceramic capacitors, and older designs such as paper capacitors, can absorb sound waves resulting in a microphonic effect. Vibration moves the plates, causing the capacitance to vary, in turn inducing AC current. Some dielectrics also generate piezoelectricity. The resulting interference is especially problematic in audio applications, potentially causing feedback or unintended recording. In the reverse microphonic effect, the varying electric field between the capacitor plates exerts a physical force, moving them as a speaker. This can generate audible sound, but drains energy and stresses the dielectric and the electrolyte, if any.\n\n\n=== Current and voltage reversal ===\nCurrent reversal occurs when the current changes direction. Voltage reversal is the change of polarity in a circuit. Reversal is generally described as the percentage of the maximum rated voltage that reverses polarity. In DC circuits, this is usually less than 100%, often in the range of 0 to 90%, whereas AC circuits experience 100% reversal.\nIn DC circuits and pulsed circuits, current and voltage reversal are affected by the damping of the system. Voltage reversal is encountered in RLC circuits that are underdamped. The current and voltage reverse direction, forming a harmonic oscillator between the inductance and capacitance. The current and voltage tends to oscillate and may reverse direction several times, with each peak being lower than the previous, until the system reaches an equilibrium. This is often referred to as ringing. In comparison, critically damped or overdamped systems usually do not experience a voltage reversal. Reversal is also encountered in AC circuits, where the peak current is equal in each direction.\nFor maximum life, capacitors usually need to be able to handle the maximum amount of reversal that a system may experience. An AC circuit experiences 100% voltage reversal, while underdamped DC circuits experience less than 100%. Reversal creates excess electric fields in the dielectric, causes excess heating of both the dielectric and the conductors, and can dramatically shorten the life expectancy of the capacitor. Reversal ratings often affect the design considerations for the capacitor, from the choice of dielectric materials and voltage ratings to the types of internal connections used.\n\n\n=== Dielectric absorption ===\nCapacitors made with any type of dielectric material show some level of \"dielectric absorption\" or \"soakage\". On discharging a capacitor and disconnecting it, after a short time it may develop a voltage due to hysteresis in the dielectric. This effect is objectionable in applications such as precision sample and hold circuits or timing circuits. The level of absorption depends on many factors, from design considerations to charging time, since the absorption is a time-dependent process. However, the primary factor is the type of dielectric material. Capacitors such as tantalum electrolytic or polysulfone film exhibit relatively high absorption, while polystyrene or Teflon allow very small levels of absorption. In some capacitors where dangerous voltages and energies exist, such as in flashtubes, television sets, microwave ovens and defibrillators, the dielectric absorption can recharge the capacitor to hazardous voltages after it has been shorted or discharged. Any capacitor containing over 10 joules of energy is generally considered hazardous, while 50 joules or higher is potentially lethal. A capacitor may regain anywhere from 0.01 to 20% of its original charge over a period of several minutes, allowing a seemingly safe capacitor to become surprisingly dangerous.\n\n\n=== Leakage ===\nLeakage is equivalent to a resistor in parallel with the capacitor. Constant exposure to heat can cause dielectric breakdown and excessive leakage, a problem often seen in older vacuum tube circuits, particularly where oiled paper and foil capacitors were used. In many vacuum tube circuits, interstage coupling capacitors are used to conduct a varying signal from the plate of one tube to the grid circuit of the next stage. A leaky capacitor can cause the grid circuit voltage to be raised from its normal bias setting, causing excessive current or signal distortion in the downstream tube. In power amplifiers this can cause the plates to glow red, or current limiting resistors to overheat, even fail. Similar considerations apply to component fabricated solid-state (transistor) amplifiers, but owing to lower heat production and the use of modern polyester dielectric barriers this once-common problem has become relatively rare.\n\n\n=== Electrolytic failure from disuse ===\nAluminum electrolytic capacitors are conditioned when manufactured by applying a voltage sufficient to initiate the proper internal chemical state. This state is maintained by regular use of the equipment. If a system using electrolytic capacitors is unused for a long period of time it can lose its conditioning. Sometimes they fail with a short circuit when next operated.\n\n\n=== Lifespan ===\nAll capacitors have varying lifespans, depending upon their construction, operational conditions, and environmental conditions. Solid-state ceramic capacitors generally have very long lives under normal use, which has little dependency on factors such as vibration or ambient temperature, but factors like humidity, mechanical stress, and fatigue play a primary role in their failure. Failure modes may differ. Some capacitors may experience a gradual loss of capacitance, increased leakage or an increase in equivalent series resistance (ESR), while others may fail suddenly or even catastrophically. For example, metal-film capacitors are more prone to damage from stress and humidity, but will self-heal when a breakdown in the dielectric occurs. The formation of a glow discharge at the point of failure prevents arcing by vaporizing the metallic film in that spot, neutralizing any short circuit with minimal loss in capacitance. When enough pinholes accumulate in the film, a total failure occurs in a metal-film capacitor, generally happening suddenly without warning.\nElectrolytic capacitors generally have the shortest lifespans. Electrolytic capacitors are affected very little by vibration or humidity, but factors such as ambient and operational temperatures play a large role in their failure, which gradually occur as an increase in ESR (up to 300%) and as much as a 20% decrease in capacitance. The capacitors contain electrolytes which will eventually diffuse through the seals and evaporate. An increase in temperature also increases internal pressure, and increases the reaction rate of the chemicals. Thus, the life of an electrolytic capacitor is generally defined by a modification of the Arrhenius equation, which is used to determine chemical-reaction rates:\n\nManufacturers often use this equation to supply an expected lifespan, in hours, for electrolytic capacitors when used at their designed operating temperature, which is affected by both ambient temperature, ESR, and ripple current. However, these ideal conditions may not exist in every use. The rule of thumb for predicting lifespan under different conditions of use is determined by:\n\nThis says that the capacitor's life decreases by half for every 10 degrees Celsius that the temperature is increased, where:\n\n  \n    \n      \n        \n          L\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle L_{0}}\n   is the rated life under rated conditions, e.g. 2000 hours\n\n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n   is the rated max/min operational temperature\n\n  \n    \n      \n        \n          T\n          \n            a\n          \n        \n      \n    \n    {\\displaystyle T_{a}}\n   is the average operational temperature\n\n  \n    \n      \n        \n          L\n          \n            a\n          \n        \n      \n    \n    {\\displaystyle L_{a}}\n   is the expected lifespan under given conditions\n\n\n== Capacitor types ==\n\nPractical capacitors are available commercially in many different forms. The type of internal dielectric, the structure of the plates and the device packaging all strongly affect the characteristics of the capacitor, and its applications.\nValues available range from very low (picofarad range; while arbitrarily low values are in principle possible, stray (parasitic) capacitance in any circuit is the limiting factor) to about 5 kF supercapacitors.\nAbove approximately 1 microfarad electrolytic capacitors are usually used because of their small size and low cost compared with other types, unless their relatively poor stability, life and polarised nature make them unsuitable. Very high capacity supercapacitors use a porous carbon-based electrode material.\n\n\n=== Dielectric materials ===\n\nMost capacitors have a dielectric spacer, which increases their capacitance compared to air or a vacuum. In order to maximise the charge that a capacitor can hold, the dielectric material needs to have as high a permittivity as possible, while also having as high a breakdown voltage as possible. The dielectric also needs to have as low a loss with frequency as possible.\nHowever, low value capacitors are available with a vacuum between their plates to allow extremely high voltage operation and low losses. Variable capacitors with their plates open to the atmosphere were commonly used in radio tuning circuits. Later designs use polymer foil dielectric between the moving and stationary plates, with no significant air space between the plates.\nSeveral solid dielectrics are available, including paper, plastic, glass, mica and ceramic.Paper was used extensively in older capacitors and offers relatively high voltage performance. However, paper absorbs moisture, and has been largely replaced by plastic film capacitors.\nMost of the plastic films now used offer better stability and ageing performance than such older dielectrics such as oiled paper, which makes them useful in timer circuits, although they may be limited to relatively low operating temperatures and frequencies, because of the limitations of the plastic film being used. Large plastic film capacitors are used extensively in suppression circuits, motor start circuits, and power-factor correction circuits.\nCeramic capacitors are generally small, cheap and useful for high frequency applications, although their capacitance varies strongly with voltage and temperature and they age poorly. They can also suffer from the piezoelectric effect. Ceramic capacitors are broadly categorized as class 1 dielectrics, which have predictable variation of capacitance with temperature or class 2 dielectrics, which can operate at higher voltage.  Modern multilayer ceramics are usually quite small, but some types have inherently wide value tolerances, microphonic issues, and are usually physically brittle.\nGlass and mica capacitors are extremely reliable, stable and tolerant to high temperatures and voltages, but are too expensive for most mainstream applications.\nElectrolytic capacitors and supercapacitors are used to store small and larger amounts of energy, respectively, ceramic capacitors are often used in resonators, and parasitic capacitance occurs in circuits wherever the simple conductor-insulator-conductor structure is formed unintentionally by the configuration of the circuit layout.\n\nElectrolytic capacitors use an aluminum or tantalum plate with an oxide dielectric layer. The second electrode is a liquid electrolyte, connected to the circuit by another foil plate. Electrolytic capacitors offer very high capacitance but suffer from poor tolerances, high instability, gradual loss of capacitance especially when subjected to heat, and high leakage current. Poor quality capacitors may leak electrolyte, which is harmful to printed circuit boards. The conductivity of the electrolyte drops at low temperatures, which increases equivalent series resistance. While widely used for power-supply conditioning, poor high-frequency characteristics make them unsuitable for many applications. Electrolytic capacitors suffer from self-degradation if unused for a period (around a year), and when full power is applied may short circuit, permanently damaging the capacitor and usually blowing a fuse or causing failure of rectifier diodes. For example, in older equipment, this may cause arcing in rectifier tubes. They can be restored before use by gradually applying the operating voltage, often performed on antique vacuum tube equipment over a period of thirty minutes by using a variable transformer to supply AC power.  The use of this technique may be less satisfactory for some solid state equipment, which may be damaged by operation below its normal power range, requiring that the power supply first be isolated from the consuming circuits. Such remedies may not be applicable to modern high-frequency power supplies as these produce full output voltage even with reduced input.Tantalum capacitors offer better frequency and temperature characteristics than aluminum, but higher dielectric absorption and leakage.Polymer capacitors (OS-CON, OC-CON, KO, AO) use solid conductive polymer (or polymerized organic semiconductor) as electrolyte and offer longer life and lower ESR at higher cost than standard electrolytic capacitors.\nA feedthrough capacitor is a component that, while not serving as its main use, has capacitance and is used to conduct signals through a conductive sheet.\nSeveral other types of capacitor are available for specialist applications. Supercapacitors store large amounts of energy. Supercapacitors made from carbon aerogel, carbon nanotubes, or highly porous electrode materials, offer extremely high capacitance (up to 5 kF as of 2010) and can be used in some applications instead of rechargeable batteries. Alternating current capacitors are specifically designed to work on line (mains) voltage AC power circuits. They are commonly used in electric motor circuits and are often designed to handle large currents, so they tend to be physically large. They are usually ruggedly packaged, often in metal cases that can be easily grounded/earthed. They also are designed with direct current breakdown voltages of at least five times the maximum AC voltage.\n\n\n=== Voltage-dependent capacitors ===\nThe dielectric constant for a number of very useful dielectrics changes as a function of the applied electrical field, for example ferroelectric materials, so the capacitance for these devices is more complex. For example, in charging such a capacitor the differential increase in voltage with charge is governed by:\n\nwhere the voltage dependence of capacitance, C(V), suggests that the capacitance is a function of the electric field strength, which in a large area parallel plate device is given by \u03b5 = V/d. This field polarizes the dielectric, which polarization, in the case of a ferroelectric, is a nonlinear S-shaped function of the electric field, which, in the case of a large area parallel plate device, translates into a capacitance that is a nonlinear function of the voltage.Corresponding to the voltage-dependent capacitance, to charge the capacitor to voltage V an integral relation is found:\n\nwhich agrees with Q = CV only when C does not depend on voltage V.\nBy the same token, the energy stored in the capacitor now is given by\n\nIntegrating:\n\nwhere interchange of the order of integration is used.\nThe nonlinear capacitance of a microscope probe scanned along a ferroelectric surface is used to study the domain structure of ferroelectric materials.Another example of voltage dependent capacitance occurs in semiconductor devices such as semiconductor diodes, where the voltage dependence stems not from a change in dielectric constant but in a voltage dependence of the spacing between the charges on the two sides of the capacitor. This effect is intentionally exploited in diode-like devices known as varicaps.\n\n\n=== Frequency-dependent capacitors ===\nIf a capacitor is driven with a time-varying voltage that changes rapidly enough, at some frequency the polarization of the dielectric cannot follow the voltage. As an example of the origin of this mechanism, the internal microscopic dipoles contributing to the dielectric constant cannot move instantly, and so as frequency of an applied alternating voltage increases, the dipole response is limited and the dielectric constant diminishes. A changing dielectric constant with frequency is referred to as dielectric dispersion, and is governed by dielectric relaxation processes, such as Debye relaxation. Under transient conditions, the displacement field can be expressed as (see electric susceptibility):\n\nindicating the lag in response by the time dependence of \u03b5r, calculated in principle from an underlying microscopic analysis, for example, of the dipole behavior in the dielectric. See, for example, linear response function. The integral extends over the entire past history up to the present time. A Fourier transform in time then results in:\n\nwhere \u03b5r(\u03c9) is now a complex function, with an imaginary part related to absorption of energy from the field by the medium. See permittivity. The capacitance, being proportional to the dielectric constant, also exhibits this frequency behavior. Fourier transforming Gauss's law with this form for displacement field:\n\nwhere j is the imaginary unit, V(\u03c9) is the voltage component at angular frequency \u03c9, G(\u03c9) is the real part of the current, called the conductance, and C(\u03c9) determines the imaginary part of the current and is the capacitance. Z(\u03c9) is the complex impedance.\nWhen a parallel-plate capacitor is filled with a dielectric, the measurement of dielectric properties of the medium is based upon the relation:\n\nwhere a single prime denotes the real part and a double prime the imaginary part, Z(\u03c9) is the complex impedance with the dielectric present, Ccmplx(\u03c9) is the so-called complex capacitance with the dielectric present, and C0 is the capacitance without the dielectric. (Measurement \"without the dielectric\" in principle means measurement in free space, an unattainable goal inasmuch as even the quantum vacuum is predicted to exhibit nonideal behavior, such as dichroism. For practical purposes, when measurement errors are taken into account, often a measurement in terrestrial vacuum, or simply a calculation of C0, is sufficiently accurate.)\nUsing this measurement method, the dielectric constant may exhibit a resonance at certain frequencies corresponding to characteristic response frequencies (excitation energies) of contributors to the dielectric constant. These resonances are the basis for a number of experimental techniques for detecting defects. The conductance method measures absorption as a function of frequency. Alternatively, the time response of the capacitance can be used directly, as in deep-level transient spectroscopy.Another example of frequency dependent capacitance occurs with MOS capacitors, where the slow generation of minority carriers means that at high frequencies the capacitance measures only the majority carrier response, while at low frequencies both types of carrier respond.At optical frequencies, in semiconductors the dielectric constant exhibits structure related to the band structure of the solid. Sophisticated modulation spectroscopy measurement methods based upon modulating the crystal structure by pressure or by other stresses and observing the related changes in absorption or reflection of light have advanced our knowledge of these materials.\n\n\n=== Styles ===\n\nThe arrangement of plates and dielectric has many variations in different styles depending on the desired ratings of the capacitor. For small values of capacitance (microfarads and less), ceramic disks use metallic coatings, with wire leads bonded to the coating. Larger values can be made by multiple stacks of plates and disks. Larger value capacitors usually use a metal foil or metal film layer deposited on the surface of a dielectric film to make the plates, and a dielectric film of impregnated paper or plastic \u2013 these are rolled up to save space. To reduce the series resistance and inductance for long plates, the plates and dielectric are staggered so that connection is made at the common edge of the rolled-up plates, not at the ends of the foil or metalized film strips that comprise the plates.\nThe assembly is encased to prevent moisture entering the dielectric \u2013 early radio equipment used a cardboard tube sealed with wax. Modern paper or film dielectric capacitors are dipped in a hard thermoplastic. Large capacitors for high-voltage use may have the roll form compressed to fit into a rectangular metal case, with bolted terminals and bushings for connections. The dielectric in larger capacitors is often impregnated with a liquid to improve its properties.\n\nCapacitors may have their connecting leads arranged in many configurations, for example axially or radially. \"Axial\" means that the leads are on a common axis, typically the axis of the capacitor's cylindrical body \u2013 the leads extend from opposite ends. Radial leads are rarely aligned along radii of the body's circle, so the term is conventional. The leads (until bent) are usually in planes parallel to that of the flat body of the capacitor, and extend in the same direction; they are often parallel as manufactured.\nSmall, cheap discoidal ceramic capacitors have existed from the 1930s onward, and remain in widespread use. After the 1980s, surface mount packages for capacitors have been widely used. These packages are extremely small and lack connecting leads, allowing them to be soldered directly onto the surface of printed circuit boards. Surface mount components avoid undesirable high-frequency effects due to the leads and simplify automated assembly, although manual handling is made difficult due to their small size.\nMechanically controlled variable capacitors allow the plate spacing to be adjusted, for example by rotating or sliding a set of movable plates into alignment with a set of stationary plates. Low cost variable capacitors squeeze together alternating layers of aluminum and plastic with a screw. Electrical control of capacitance is achievable with varactors (or varicaps), which are reverse-biased semiconductor diodes whose depletion region width varies with applied voltage. They are used in phase-locked loops, amongst other applications.\n\n\n== Capacitor markings ==\n\n\n=== Marking codes for larger parts ===\nMost capacitors have designations printed on their bodies to indicate their electrical characteristics. Larger capacitors, such as electrolytic types usually display the capacitance as value with explicit unit, for example, 220 \u03bcF.\nFor typographical reasons, some manufacturers print MF on capacitors to indicate microfarads (\u03bcF).\n\n\n=== Three-/four-character marking code for small capacitors ===\nSmaller capacitors, such as ceramic types, often use a shorthand-notation consisting of three digits and an optional letter, where the digits (XYZ) denote the capacitance in picofarad (pF), calculated as XY \u00d7 10Z, and the letter indicating the tolerance. Common tolerances are \u00b15%, \u00b110%, and \u00b120%, denotes as J, K, and M, respectively.\nA capacitor may also be labeled with its working voltage, temperature, and other relevant characteristics.\nExample:\nA capacitor labeled or designated as 473K 330V has a capacitance of 47\u00d7103 pF = 47 nF (\u00b110%) with a maximum working voltage of 330 V. The working voltage of a capacitor is nominally the highest voltage that may be applied across it without undue risk of breaking down the dielectric layer.\n\n\n=== Two-character marking code for small capacitors ===\nFor capacitances following the E3, E6, E12 or E24 series of preferred values, the former ANSI/EIA-198-D:1991, ANSI/EIA-198-1-E:1998 and ANSI/EIA-198-1-F:2002 as well as the amendment IEC 60062:2016/AMD1:2019 to IEC 60062 define a special two-character marking code for capacitors for very small parts which leave no room to print the above mentioned three-/four-character code onto them. The code consists of an uppercase letter denoting the two significant digits of the value followed by a digit indicating the multiplier. The EIA standard also defines a number of lowercase letters to specify a number of values not found in E24.\n\n\n=== RKM code ===\nThe notation to state a capacitor's value in a circuit diagram varies. The RKM code following IEC 60062 and BS 1852 avoids using a decimal separator and replaces the decimal separator with the SI prefix symbol for the particular value (and the letter F for weight 1). The code is also used for part markings. Example: 4n7 for 4.7 nF or 2F2 for 2.2 F.\n\n\n=== Historical ===\n\nIn texts prior to the 1960s and on some capacitor packages until more recently, obsolete capacitance units were utilized in electronic books, magazines, and electronics catalogs. The old units \"mfd\" and \"mf\" meant microfarad (\u03bcF); and the old units \"mmfd\", \"mmf\", \"uuf\", \"\u03bc\u03bcf\", \"pfd\" meant picofarad (pF); but they are rarely used any more.  Also, \"Micromicrofarad\" or \"micro-microfarad\" are obsolete units that are found in some older texts that is equivalent to picofarad (pF).Summary of obsolete capacitance units: (upper/lower case variations aren't shown)\n\n\u03bcF (microfarad) = mf, mfd\npF (picofarad) = mmf, mmfd, pfd, \u03bc\u03bcF\n\n\n== Applications ==\n\n\n=== Energy storage ===\nA capacitor can store electric energy when disconnected from its charging circuit, so it can be used like a temporary battery, or like other types of rechargeable energy storage system. Capacitors are commonly used in electronic devices to maintain power supply while batteries are being changed. (This prevents loss of information in volatile memory.)\nA capacitor can facilitate conversion of kinetic energy of charged particles into electric energy and store it.Conventional capacitors provide less than 360 joules per kilogram of specific energy, whereas a conventional alkaline battery has a density of 590 kJ/kg. There is\nan intermediate solution: supercapacitors, which can accept and deliver charge much faster than batteries, and tolerate many more charge and discharge cycles than rechargeable batteries. They are, however, 10 times larger than conventional batteries for a given charge. On the other hand, it has been shown that the amount of charge stored in the dielectric\nlayer of the thin film capacitor can be equal to, or can even exceed, the amount of charge stored on its plates.In car audio systems, large capacitors store energy for the amplifier to use on demand. Also, for a flash tube, a capacitor is used to hold the high voltage.\n\n\n=== Digital memory ===\nIn the 1930s, John Atanasoff applied the principle of energy storage in capacitors to construct dynamic digital memories for the first binary computers that used electron tubes for logic.\n\n\n=== Pulsed power and weapons ===\nGroups of large, specially constructed, low-inductance high-voltage capacitors (capacitor banks) are used to supply huge pulses of current for many pulsed power applications. These include electromagnetic forming, Marx generators, pulsed lasers (especially TEA lasers), pulse forming networks, radar, fusion research, and particle accelerators.\nLarge capacitor banks (reservoir) are used as energy sources for the exploding-bridgewire detonators or slapper detonators in nuclear weapons and other specialty weapons. Experimental work is under way using banks of capacitors as power sources for electromagnetic armour and electromagnetic railguns and coilguns.\n\n\n=== Power conditioning ===\n\nReservoir capacitors are used in power supplies where they smooth the output of a full or half wave rectifier. They can also be used in charge pump circuits as the energy storage element in the generation of higher voltages than the input voltage.\nCapacitors are connected in parallel with the power circuits of most electronic devices and larger systems (such as factories) to shunt away and conceal current fluctuations from the primary power source to provide a \"clean\" power supply for signal or control circuits. Audio equipment, for example, uses several capacitors in this way, to shunt away power line hum before it gets into the signal circuitry. The capacitors act as a local reserve for the DC power source, and bypass AC currents from the power supply. This is used in car audio applications, when a stiffening capacitor compensates for the inductance and resistance of the leads to the lead-acid car battery.\n\n\n==== Power-factor correction ====\n\nIn electric power distribution, capacitors are used for power-factor correction. Such capacitors often come as three capacitors connected as a three phase load. Usually, the values of these capacitors are not given in farads but rather as a reactive power in volt-amperes reactive (var). The purpose is to counteract inductive loading from devices like electric motors and transmission lines to make the load appear to be mostly resistive. Individual motor or lamp loads may have capacitors for power-factor correction, or larger sets of capacitors (usually with automatic switching devices) may be installed at a load center within a building or in a large utility substation.\n\n\n=== Suppression and coupling ===\n\n\n==== Signal coupling ====\n\nBecause capacitors pass AC but block DC signals (when charged up to the applied DC voltage), they are often used to separate the AC and DC components of a signal. This method is known as AC coupling or \"capacitive coupling\". Here, a large value of capacitance, whose value need not be accurately controlled, but whose reactance is small at the signal frequency, is employed.\n\n\n==== Decoupling ====\n\nA decoupling capacitor is a capacitor used to protect one part of a circuit from the effect of another, for instance to suppress noise or transients. Noise caused by other circuit elements is shunted through the capacitor, reducing the effect they have on the rest of the circuit. It is most commonly used between the power supply and ground.\nAn alternative name is bypass capacitor as it is used to bypass the power supply or other high impedance component of a circuit.\nDecoupling capacitors need not always be discrete components. Capacitors used in these applications may be built into a printed circuit board, between the various layers. These are often referred to as embedded capacitors. The layers in the board contributing to the capacitive properties also function as power and ground planes, and have a dielectric in between them, enabling them to operate as a parallel plate capacitor.\n\n\n==== High-pass and low-pass filters ====\n\n\n==== Noise suppression, spikes, and snubbers ====\n\nWhen an inductive circuit is opened, the current through the inductance collapses quickly, creating a large voltage across the open circuit of the switch or relay. If the inductance is large enough, the energy may generate a spark, causing the contact points to oxidize, deteriorate, or sometimes weld together, or destroying a solid-state switch. A snubber capacitor across the newly opened circuit creates a path for this impulse to bypass the contact points, thereby preserving their life; these were commonly found in contact breaker ignition systems, for instance. Similarly, in smaller scale circuits, the spark may not be enough to damage the switch but may still radiate undesirable radio frequency interference (RFI), which a filter capacitor absorbs. Snubber capacitors are usually employed with a low-value resistor in series, to dissipate energy and minimize RFI. Such resistor-capacitor combinations are available in a single package.\nCapacitors are also used in parallel with interrupting units of a high-voltage circuit breaker to equally distribute the voltage between these units. These are called \"grading capacitors\".\nIn schematic diagrams, a capacitor used primarily for DC charge storage is often drawn vertically in circuit diagrams with the lower, more negative, plate drawn as an arc. The straight plate indicates the positive terminal of the device, if it is polarized (see electrolytic capacitor).\n\n\n=== Motor starters ===\n\nIn single phase squirrel cage motors, the primary winding within the motor housing is not capable of starting a rotational motion on the rotor, but is capable of sustaining one. To start the motor, a secondary \"start\" winding has a series non-polarized starting capacitor to introduce a lead in the sinusoidal current. When the secondary (start) winding is placed at an angle with respect to the primary (run) winding, a rotating electric field is created. The force of the rotational field is not constant, but is sufficient to start the rotor spinning. When the rotor comes close to operating speed, a centrifugal switch (or current-sensitive relay in series with the main winding) disconnects the capacitor. The start capacitor is typically mounted to the side of the motor housing. These are called capacitor-start motors, that have relatively high starting torque. Typically they can have up-to four times as much starting torque as a split-phase motor and are used on applications such as compressors, pressure washers and any small device requiring high starting torques.\nCapacitor-run induction motors have a permanently connected phase-shifting capacitor in series with a second winding. The motor is much like a two-phase induction motor.\nMotor-starting capacitors are typically non-polarized electrolytic types, while running capacitors are conventional paper or plastic film dielectric types.\n\n\n=== Signal processing ===\nThe energy stored in a capacitor can be used to represent information, either in binary form, as in DRAMs, or in analogue form, as in analog sampled filters and CCDs. Capacitors can be used in analog circuits as components of integrators or more complex filters and in negative feedback loop stabilization. Signal processing circuits also use capacitors to integrate a current signal.\n\n\n==== Tuned circuits ====\nCapacitors and inductors are applied together in tuned circuits to select information in particular frequency bands. For example, radio receivers rely on variable capacitors to tune the station frequency. Speakers use passive analog crossovers, and analog equalizers use capacitors to select different audio bands.\nThe resonant frequency f of a tuned circuit is a function of the inductance (L) and capacitance (C) in series, and is given by:\n\nwhere L is in henries and C is in farads.\n\n\n=== Sensing ===\n\nMost capacitors are designed to maintain a fixed physical structure. However, various factors can change the structure of the capacitor, and the resulting change in capacitance can be used to sense those factors.\n\nChanging the dielectric\n\nThe effects of varying the characteristics of the dielectric can be used for sensing purposes. Capacitors with an exposed and porous dielectric can be used to measure humidity in air. Capacitors are used to accurately measure the fuel level in airplanes; as the fuel covers more of a pair of plates, the circuit capacitance increases. Squeezing the dielectric can change a capacitor at a few tens of bar pressure sufficiently that it can be used as a pressure sensor. A selected, but otherwise standard, polymer dielectric capacitor, when immersed in a compatible gas or liquid, can work usefully as a very low cost pressure sensor up to many hundreds of bar.\nChanging the distance between the plates\n\nCapacitors with a flexible plate can be used to measure strain or pressure. Industrial pressure transmitters used for process control use pressure-sensing diaphragms, which form a capacitor plate of an oscillator circuit. Capacitors are used as the sensor in condenser microphones, where one plate is moved by air pressure, relative to the fixed position of the other plate. Some accelerometers use MEMS capacitors etched on a chip to measure the magnitude and direction of the acceleration vector. They are used to detect changes in acceleration, in tilt sensors, or to detect free fall, as sensors triggering airbag deployment, and in many other applications. Some fingerprint sensors use capacitors. Additionally, a user can adjust the pitch of a theremin musical instrument by moving their hand since this changes the effective capacitance between the user's hand and the antenna.\nChanging the effective area of the plates\n\nCapacitive touch switches are now used on many consumer electronic products.\n\n\n=== Oscillators ===\n\nA capacitor can possess spring-like qualities in an oscillator circuit. In the image example, a capacitor acts to influence the biasing voltage at the npn transistor's base. The resistance values of the voltage-divider resistors and the capacitance value of the capacitor together control the oscillatory frequency.\n\n\n=== Producing light ===\n\nA light-emitting capacitor is made from a dielectric that uses phosphorescence to produce light. If one of the conductive plates is made with a transparent material, the light is visible. Light-emitting capacitors are used in the construction of electroluminescent panels, for applications such as backlighting for laptop computers. In this case, the entire panel is a capacitor used for the purpose of generating light.\n\n\n== Hazards and safety ==\nThe hazards posed by a capacitor are usually determined, foremost, by the amount of energy stored, which is the cause of things like electrical burns or heart fibrillation. Factors such as voltage and chassis material are of secondary consideration, which are more related to how easily a shock can be initiated rather than how much damage can occur. Under certain conditions, including conductivity of the surfaces, preexisting medical conditions, the humidity of the air, or the pathways it takes through the body (i.e.: shocks that travel across the core of the body and, especially, the heart are more dangerous than those limited to the extremities), shocks as low as one joule have been reported to cause death, although in most instances they may not even leave a burn. Shocks over ten joules will generally damage skin, and are usually considered hazardous. Any capacitor that can store 50 joules or more should be considered potentially lethal.Capacitors may retain a charge long after power is removed from a circuit; this charge can cause dangerous or even potentially fatal shocks or damage connected equipment. For example, even a seemingly innocuous device such as a disposable-camera flash unit, powered by a 1.5 volt AA battery, has a capacitor which may contain over 15 joules of energy and be charged to over 300 volts. This is easily capable of delivering a shock. Service procedures for electronic devices usually include instructions to discharge large or high-voltage capacitors, for instance using a Brinkley stick. Capacitors may also have built-in discharge resistors to dissipate stored energy to a safe level within a few seconds after power is removed. High-voltage capacitors are stored with the terminals shorted, as protection from potentially dangerous voltages due to dielectric absorption or from transient voltages the capacitor may pick up from static charges or passing weather events.Some old, large oil-filled paper or plastic film capacitors contain polychlorinated biphenyls (PCBs). It is known that waste PCBs can leak into groundwater under landfills. Capacitors containing PCB were labelled as containing \"Askarel\" and several other trade names. PCB-filled paper capacitors are found in very old (pre-1975) fluorescent lamp ballasts, and other applications.\nCapacitors may catastrophically fail when subjected to voltages or currents beyond their rating, or as they reach their normal end of life. Dielectric or metal interconnection failures may create arcing that vaporizes the dielectric fluid, resulting in case bulging, rupture, or even an explosion. Capacitors used in RF or sustained high-current applications can overheat, especially in the center of the capacitor rolls. Capacitors used within high-energy capacitor banks can violently explode when a short in one capacitor causes sudden dumping of energy stored in the rest of the bank into the failing unit. High voltage vacuum capacitors can generate soft X-rays even during normal operation. Proper containment, fusing, and preventive maintenance can help to minimize these hazards.\nHigh-voltage capacitors may benefit from a pre-charge to limit in-rush currents at power-up of high voltage direct current (HVDC) circuits. This extends the life of the component and may mitigate high-voltage hazards.\n\n\t\t\n\t\t\n\n\n== See also ==\nCapacitance meter\nCapacitor plague\nElectric displacement field\nElectroluminescence\nList of capacitor manufacturers\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Bibliography ===\nDorf, Richard C.; Svoboda, James A. (2001). Introduction to Electric Circuits (5th ed.). New York: John Wiley & Sons. ISBN 978-0-47138689-6.\nPhilosophical Transactions of the Royal Society LXXII, Appendix 8, 1782 (Volta coins the word condenser)\nUlaby, Fawwaz Tayssir (1999). Fundamentals of Applied Electromagnetics (2nd ed.). Upper Saddle River, New Jersey, USA: Prentice Hall. ISBN 978-0-13011554-6.\nSchroder, Dieter K. (2006). Semiconductor Material and Device Characterization (3rd ed.). Wiley. p. 270 ff. ISBN 978-0-47173906-7.\nSze, Simon M.; Ng, Kwok K. (2006). Physics of Semiconductor Devices (3rd ed.). Wiley. ISBN 978-0-47006830-4.\n\n\n== Further reading ==\nTantalum and Niobium-Based Capacitors \u2013 Science, Technology, and Applications; 1st Ed; Yuri Freeman; Springer; 120 pages; 2018; ISBN 978-3-31967869-6.\nCapacitors; 1st Ed; R. P. D. Eshpande; McGraw-Hill; 342 pages; 2014; ISBN 978-0-07184856-5.\nThe Capacitor Handbook; 1st Ed; Cletus Kaiser; Van Nostrand Reinhold; 124 pages; 1993; ISBN 978-9-40118092-4.\nUnderstanding Capacitors and their Uses; 1st Ed; William Mullin; Sams Publishing; 96 pages; 1964. (archive)\nFixed and Variable Capacitors; 1st Ed; G. W. A. Dummer and Harold Nordenberg; Maple Press; 288 pages; 1960. (archive)\nThe Electrolytic Capacitor; 1st Ed; Alexander Georgiev; Murray Hill Books; 191 pages; 1945. (archive)\n\n\n== External links ==\n\nThe First Condenser \u2013 A Beer Glass \u2013 SparkMuseum\nHow Capacitors Work \u2013 Howstuffworks\nCapacitor Tutorial", "Ohm": "The ohm (symbol: \u03a9) is the unit of electrical resistance in the International System of Units (SI). It is named after German physicist Georg Simon Ohm. Various empirically derived standard units for electrical resistance were developed in connection with early telegraphy practice, and the British Association for the Advancement of Science proposed a unit derived from existing units of mass, length and time, and of a convenient scale for practical work as early as 1861.Following the 2019 redefinition of the SI base units, in which the ampere and the kilogram were redefined in terms of fundamental constants, the ohm is now also defined as an exact value in terms of these constants.\n\n\n== Definition ==\n\nThe ohm is defined as an electrical resistance between two points of a conductor when a constant potential difference of one volt, applied to these points, produces in the conductor a current of one ampere, the conductor not being the seat of any electromotive force.\n\n  \n    \n      \n        \u03a9\n        =\n        \n          \n            \n              V\n              A\n            \n          \n        \n        =\n        \n          \n            \n              1\n              S\n            \n          \n        \n        =\n        \n          \n            \n              W\n              \n                \n                  A\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  V\n                \n                \n                  2\n                \n              \n              W\n            \n          \n        \n        =\n        \n          \n            \n              s\n              F\n            \n          \n        \n        =\n        \n          \n            \n              H\n              s\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  J\n                \n                \n                  \u22c5\n                \n                \n                  s\n                \n              \n              \n                \n                  C\n                \n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  kg\n                \n                \n                  \u22c5\n                \n                \n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  s\n                \n                \n                  \u22c5\n                \n                \n                  \n                    C\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              J\n              \n                \n                  s\n                \n                \n                  \u22c5\n                \n                \n                  \n                    A\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  kg\n                \n                \n                  \u22c5\n                \n                \n                  \n                    m\n                  \n                  \n                    2\n                  \n                \n              \n              \n                \n                  \n                    s\n                  \n                  \n                    3\n                  \n                \n                \n                  \u22c5\n                \n                \n                  \n                    A\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\Omega ={\\dfrac {\\text{V}}{\\text{A}}}={\\dfrac {1}{\\text{S}}}={\\dfrac {\\text{W}}{{\\text{A}}^{2}}}={\\dfrac {{\\text{V}}^{2}}{\\text{W}}}={\\dfrac {\\text{s}}{\\text{F}}}={\\dfrac {\\text{H}}{\\text{s}}}={\\dfrac {{\\text{J}}{\\cdot }{\\text{s}}}{{\\text{C}}^{2}}}={\\dfrac {{\\text{kg}}{\\cdot }{\\text{m}}^{2}}{{\\text{s}}{\\cdot }{\\text{C}}^{2}}}={\\dfrac {\\text{J}}{{\\text{s}}{\\cdot }{\\text{A}}^{2}}}={\\dfrac {{\\text{kg}}{\\cdot }{\\text{m}}^{2}}{{\\text{s}}^{3}{\\cdot }{\\text{A}}^{2}}}}\n  in which the following units appear: volt (V), ampere (A), siemens (S), watt (W), second (s), farad (F), henry (H), joule (J), coulomb (C), kilogram (kg), and meter (m).\nIn many cases the resistance of a conductor is approximately constant within a certain range of voltages, temperatures, and other parameters. These are called linear resistors. In other cases resistance varies, such as in the case of the thermistor, which exhibits a strong dependence of its resistance with temperature.\nIn the US, a vowel of the prefixed units kiloohm and megaohm is commonly omitted, producing kilohm and megohm.In alternating current circuits, electrical impedance is also measured in ohms.\n\n\n== Conversions ==\nThe siemens (symbol: S) is the SI derived unit of electric conductance and admittance, historically known as the mho (ohm spelled backwards, symbol is \u2127); it is the reciprocal of the ohm (\u03a9).\n\n\n== Power as a function of resistance ==\nThe power dissipated by a resistor may be calculated from its resistance, and the voltage or current involved. The formula is a combination of Ohm's law and Joule's law:\n\nwhere P is the power, R is the resistance, V is the voltage across the resistor, and I is the current through the resistor.\nA linear resistor has a constant resistance value over all applied voltages or currents; many practical resistors are linear over a useful range of currents. Non-linear resistors have a value that may vary depending on the applied voltage (or current). Where alternating current is applied to the circuit (or where the resistance value is a function of time), the relation above is true at any instant, but calculation of average power over an interval of time requires integration of \"instantaneous\" power over that interval.\nSince the ohm belongs to a coherent system of units, when each of these quantities has its corresponding SI unit (watt for P, ohm for R, volt for V and ampere for I, which are related as in \u00a7 Definition) this formula remains valid numerically when these units are used (and thought of as being cancelled or omitted).\n\n\n== History ==\nThe rapid rise of electrotechnology in the last half of the 19th century created a demand for a rational, coherent, consistent, and international system of units for electrical quantities. Telegraphers and other early users of electricity in the 19th century needed a practical standard unit of measurement for resistance. Resistance was often expressed as a multiple of the resistance of a standard length of telegraph wires; different agencies used different bases for a standard, so units were not readily interchangeable. Electrical units so defined were not a coherent system with the units for energy, mass, length, and time, requiring conversion factors to be used in calculations relating energy or power to resistance.Two different methods of establishing a system of electrical units can be chosen. Various artifacts, such as a length of wire or a standard electrochemical cell, could be specified as producing defined quantities for resistance, voltage, and so on. Alternatively, the electrical units can be related to the mechanical units by defining, for example, a unit of current that gives a specified force between two wires, or a unit of charge that gives a unit of force between two unit charges. This latter method ensures coherence with the units of energy. Defining a unit for resistance that is coherent with units of energy and time in effect also requires defining units for potential and current. It is desirable that one unit of electrical potential will force one unit of electric current through one unit of electrical resistance, doing one unit of work in one unit of time, otherwise, all electrical calculations will require conversion factors.\nSince so-called \"absolute\" units of charge and current are expressed as combinations of units of mass, length, and time, dimensional analysis of the relations between potential, current, and resistance show that resistance is expressed in units of length per time \u2013 a velocity. Some early definitions of a unit of resistance, for example, defined a unit resistance as one quadrant of the Earth per second.\nThe absolute-unit system related magnetic and electrostatic quantities to metric base units of mass, time, and length. These units had the great advantage of simplifying the equations used in the solution of electromagnetic problems, and eliminated conversion factors in calculations about electrical quantities. However, the centimeter\u2013gram\u2013second, CGS, units turned out to have impractical sizes for practical measurements.\nVarious artifact standards were proposed as the definition of the unit of resistance. In 1860 Werner Siemens (1816\u20131892) published a suggestion for a reproducible resistance standard in Poggendorff's Annalen der Physik und Chemie. He proposed a column of pure mercury, of one square millimeter cross section, one meter long: Siemens mercury unit. However, this unit was not coherent with other units. One proposal was to devise a unit based on a mercury column that would be coherent \u2013 in effect, adjusting the length to make the resistance one ohm. Not all users of units had the resources to carry out metrology experiments to the required precision, so working standards notionally based on the physical definition were required.\nIn 1861, Latimer Clark (1822\u20131898) and Sir Charles Bright (1832\u20131888) presented a paper at the British Association for the Advancement of Science meeting  suggesting that standards for electrical units be established and suggesting names for these units derived from eminent philosophers, 'Ohma', 'Farad' and 'Volt'. The BAAS in 1861 appointed a committee including Maxwell and Thomson to report upon standards of electrical resistance. Their objectives were to devise a unit that was of convenient size, part of a complete system for electrical measurements, coherent with the units for energy, stable, reproducible and based on the French metrical system. In the third report of the committee, 1864, the resistance unit is referred to as \"B.A. unit, or Ohmad\". By 1867 the unit is referred to as simply ohm.The B.A. ohm was intended to be 109 CGS units but owing to an error in calculations the definition was 1.3% too small. The error was significant for preparation of working standards.\nOn 21 September 1881 the Congr\u00e8s internationale des \u00e9lectriciens (international conference of electricians) defined a practical unit of ohm for the resistance, based on CGS units, using a mercury column 1 mm2 in cross-section, approximately 104.9 cm in length at 0 \u00b0C, similar to the apparatus suggested by Siemens.\nA legal ohm, a reproducible standard, was defined by the international conference of electricians at Paris in 1884 as the resistance of a mercury column of specified weight and 106 cm long; this was a compromise value between the B. A. unit (equivalent to 104.7 cm), the Siemens unit (100 cm by definition), and the CGS unit. Although called \"legal\", this standard was not adopted by any national legislation. The \"international\" ohm was recommended by unanimous resolution at the International Electrical Congress 1893 in Chicago. The unit was based upon the ohm equal to 109 units of resistance of the C.G.S. system of electromagnetic units. The international ohm is represented by the resistance offered to an unvarying electric current in a mercury column of constant cross-sectional area 106.3 cm long of mass 14.4521 grams and 0 \u00b0C.  This definition became the basis for the legal definition of the ohm in several countries. In 1908, this definition was adopted by scientific representatives from several countries at the International Conference on Electric Units and Standards in London. The mercury column standard was maintained until the 1948 General Conference on Weights and Measures, at which the ohm was redefined in absolute terms instead of as an artifact standard.\nBy the end of the 19th century, units were well understood and consistent. Definitions would change with little effect on commercial uses of the units. Advances in metrology allowed definitions to be formulated with a high degree of precision and repeatability.\n\n\n=== Historical units of resistance ===\n\n\n== Realization of standards ==\nThe mercury column method of realizing a physical standard ohm turned out to be difficult to reproduce, owing to the effects of non-constant cross section of the glass tubing. Various resistance coils were constructed by the British Association and others, to serve as physical artifact standards for the unit of resistance. The long-term stability and reproducibility of these artifacts was an ongoing field of research, as the effects of temperature, air pressure, humidity, and time on the standards were detected and analyzed.\nArtifact standards are still used, but metrology experiments relating accurately dimensioned inductors and capacitors provided a more fundamental basis for the definition of the ohm. Since 1990 the quantum Hall effect has been used to define the ohm with high precision and repeatability. The quantum Hall experiments are used to check the stability of working standards that have convenient values for comparison.Following the 2019 redefinition of the SI base units, in which the ampere and the kilogram were redefined in terms of fundamental constants, the ohm is now also defined in terms of these constants.\n\n\n== Symbol ==\nThe symbol \u03a9 was suggested, because of the similar sound of ohm and omega, by William Henry Preece in 1867. In documents printed before WWII the unit symbol often consisted of the raised lowercase omega (\u03c9), such that 56 \u03a9 was written as 56\u03c9.\nHistorically, some document editing software applications have used the Symbol typeface to render the character \u03a9. Where the font is not supported, a W is displayed instead (\"10 W\" instead of \"10 \u03a9\", for instance). As W represents the watt, the SI unit of power, this can lead to confusion, making the use of the correct Unicode code point preferable.\nWhere the character set is limited to ASCII, the IEEE 260.1 standard recommends substituting the symbol ohm for \u03a9.\nIn the electronics industry it is common to use the character R instead of the \u03a9 symbol, thus, a 10 \u03a9 resistor may be represented as 10R. This is part of the RKM code. It is used in many instances where the value has a decimal place. For example, 5.6 \u03a9 is listed as 5R6, or 2200 \u03a9 is listed as 2K2. This method avoids overlooking the decimal point, which may not be rendered reliably on components or when duplicating documents.\nUnicode encodes the symbol as U+2126 \u03a9 OHM SIGN, distinct from Greek omega among letterlike symbols, but it is only included for backward compatibility and the Greek uppercase omega character U+03A9 \u03a9 GREEK CAPITAL LETTER OMEGA (&ohm;, &Omega;) is preferred. In MS-DOS and Microsoft Windows, the alt code ALT 234 may produce the \u03a9 symbol. In Mac OS, \u2325 Opt+Z does the same.\n\n\n== See also ==\nElectronic color code\nHistory of measurement\nInternational Committee for Weights and Measures\nOrders of magnitude (resistance)\nResistivity\n\n\n== Notes and references ==\n\n\n== External links ==\nScanned books of Georg Simon Ohm at the library of the University of Applied Sciences Nuernberg\nOfficial SI brochure\nNIST Special Publication 811\nHistory of the ohm at sizes.com\nHistory of the electrical units.", "Geometrical_optics": "Geometrical optics, or ray optics, is a model of optics that describes light propagation in terms of rays. The ray in geometrical optics is an abstraction useful for approximating the paths along which light propagates under certain circumstances.\nThe simplifying assumptions of geometrical optics include that light rays:\n\npropagate in straight-line paths as they travel in a homogeneous medium\nbend, and in particular circumstances may split in two, at the interface between two dissimilar media\nfollow curved paths in a medium in which the refractive index changes\nmay be absorbed or reflected.Geometrical optics does not account for certain optical effects such as diffraction and interference. This simplification is useful in practice; it is an excellent approximation when the wavelength is small compared to the size of structures with which the light interacts. The techniques are particularly useful in describing geometrical aspects of imaging, including optical aberrations.\n\n\n== Explanation ==\n\nA light ray is a line or curve that is perpendicular to the light's wavefronts (and is therefore collinear with the wave vector).\nA slightly more rigorous definition of a light ray follows from Fermat's principle, which states that the path taken between two points by a ray of light is the path that can be traversed in the least time.Geometrical optics is often simplified by making the paraxial approximation, or \"small angle approximation\". The mathematical behavior then becomes linear, allowing optical components and systems to be described by simple matrices. This leads to the techniques  of Gaussian optics and paraxial ray tracing, which are used to find basic properties of optical systems, such as approximate image and object positions and magnifications.\n\n\n== Reflection ==\n\nGlossy surfaces such as mirrors reflect light in a simple, predictable way. This allows for production of reflected images that can be associated with an actual (real) or extrapolated (virtual) location in space.\nWith such surfaces, the direction of the reflected ray is determined by the angle the incident ray makes with the surface normal, a line perpendicular to the surface at the point where the ray hits. The incident and reflected rays lie in a single plane, and the angle between the reflected ray and the surface normal is the same as that between the incident ray and the normal. This is known as the Law of Reflection.\nFor flat mirrors, the law of reflection implies that images of objects are upright and the same distance behind the mirror as the objects are in front of the mirror. The image size is the same as the object size. (The magnification of a flat mirror is equal to one.) The law also implies that mirror images are parity inverted, which is perceived as a left-right inversion.\nMirrors with curved surfaces can be modeled by ray tracing and using the law of reflection at each point on the surface. For mirrors with parabolic surfaces, parallel rays incident on the mirror produce reflected rays that converge at a common focus. Other curved surfaces may also focus light, but with aberrations due to the diverging shape causing the focus to be smeared out in space. In particular, spherical mirrors exhibit spherical aberration. Curved mirrors can form images with magnification greater than or less than one, and the image can be upright or inverted. An upright image formed by reflection in a mirror is always virtual, while an inverted image is real and can be projected onto a screen.\n\n\n== Refraction ==\n\nRefraction occurs when light travels through an area of space that has a changing index of refraction. The simplest case of refraction occurs when there is an interface between a uniform medium with index of refraction \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle n_{1}}\n   and another medium with index of refraction \n  \n    \n      \n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle n_{2}}\n  . In such situations, Snell's Law describes the resulting deflection of the light ray:\n\n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n         \n      \n    \n    {\\displaystyle n_{1}\\sin \\theta _{1}=n_{2}\\sin \\theta _{2}\\ }\n  where \n  \n    \n      \n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\theta _{1}}\n   and \n  \n    \n      \n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta _{2}}\n   are the angles between the normal (to the interface) and the incident and refracted waves, respectively. This phenomenon is also associated with a changing speed of light as seen from the definition of index of refraction provided above which implies:\n\n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n         \n        =\n        \n          v\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}\\sin \\theta _{2}\\ =v_{2}\\sin \\theta _{1}}\n  where \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle v_{1}}\n   and \n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle v_{2}}\n   are the wave velocities through the respective media.Various consequences of Snell's Law include the fact that for light rays traveling from a material with a high index of refraction to a material with a low index of refraction, it is possible for the interaction with the interface to result in zero transmission. This phenomenon is called total internal reflection and allows for fiber optics technology. As light signals travel down a fiber optic cable, they undergo total internal reflection allowing for essentially no light lost over the length of the cable. It is also possible to produce polarized light rays using a combination of reflection and refraction: When a refracted ray and the reflected ray form a right angle, the reflected ray has the property of \"plane polarization\". The angle of incidence required for such a scenario is known as Brewster's angle.Snell's Law can be used to predict the deflection of light rays as they pass through \"linear media\" as long as the indexes of refraction and the geometry of the media are known. For example, the propagation of light through a prism results in the light ray being deflected depending on the shape and orientation of the prism. Additionally, since different frequencies of light have slightly different indexes of refraction in most materials, refraction can be used to produce dispersion spectra that appear as rainbows. The discovery of this phenomenon when passing light through a prism is famously attributed to Isaac Newton.Some media have an index of refraction which varies gradually with position and, thus, light rays curve through the medium rather than travel in straight lines. This effect is what is responsible for mirages seen on hot days where the changing index of refraction of the air causes the light rays to bend creating the appearance of specular reflections in the distance (as if on the surface of a pool of water). Material that has a varying index of refraction is called a gradient-index (GRIN) material and has many useful properties used in modern optical scanning technologies including photocopiers and scanners. The phenomenon is studied in the field of gradient-index optics.\n\nA device which produces converging or diverging light rays due to refraction is known as a lens. Thin lenses produce focal points on either side that can be modeled using the lensmaker's equation. In general, two types of lenses exist: convex lenses, which cause parallel light rays to converge, and concave lenses, which cause parallel light rays to diverge. The detailed prediction of how images are produced by these lenses can be made using ray-tracing similar to curved mirrors. Similarly to curved mirrors, thin lenses follow a simple equation that determines the location of the images given a particular focal length (\n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  ) and object distance (\n  \n    \n      \n        \n          S\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle S_{1}}\n  ):\n\n  \n    \n      \n        \n          \n            1\n            \n              S\n              \n                1\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              S\n              \n                2\n              \n            \n          \n        \n        =\n        \n          \n            1\n            f\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{S_{1}}}+{\\frac {1}{S_{2}}}={\\frac {1}{f}}}\n  where \n  \n    \n      \n        \n          S\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle S_{2}}\n   is the distance associated with the image and is considered by convention to be negative if on the same side of the lens as the object and positive if on the opposite side of the lens. The focal length f is considered negative for concave lenses.\n\nIncoming parallel rays are focused by a convex lens into an inverted real image one focal length from the lens, on the far side of the lens. \nRays from an object at finite distance are focused further from the lens than the focal distance; the closer the object is to the lens, the further the image is from the lens. With concave lenses, incoming parallel rays diverge after going through the lens, in such a way that they seem to have originated at an upright virtual image one focal length from the lens, on the same side of the lens that the parallel rays are approaching on. \nRays from an object at finite distance are associated with a virtual image that is closer to the lens than the focal length, and on the same side of the lens as the object. The closer the object is to the lens, the closer the virtual image is to the lens. \nLikewise, the magnification of a lens is given by\n\n  \n    \n      \n        M\n        =\n        \u2212\n        \n          \n            \n              S\n              \n                2\n              \n            \n            \n              S\n              \n                1\n              \n            \n          \n        \n        =\n        \n          \n            f\n            \n              f\n              \u2212\n              \n                S\n                \n                  1\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle M=-{\\frac {S_{2}}{S_{1}}}={\\frac {f}{f-S_{1}}}}\n  where the negative sign is given, by convention, to indicate an upright object for positive values and an inverted object for negative values. Similar to mirrors, upright images produced by single lenses are virtual while inverted images are real.Lenses suffer from aberrations that distort images and focal points. These are due to both to geometrical imperfections and due to the changing index of refraction for different wavelengths of light (chromatic aberration).\n\n\n== Underlying mathematics ==\nAs a mathematical study, geometrical optics emerges as a short-wavelength limit for solutions to hyperbolic partial differential equations (Sommerfeld\u2013Runge method) or as a property of propagation of field discontinuities according to Maxwell's equations (Luneburg method).  In this short-wavelength limit, it is possible to approximate the solution locally by\n\n  \n    \n      \n        u\n        (\n        t\n        ,\n        x\n        )\n        \u2248\n        a\n        (\n        t\n        ,\n        x\n        )\n        \n          e\n          \n            i\n            (\n            k\n            \u22c5\n            x\n            \u2212\n            \u03c9\n            t\n            )\n          \n        \n      \n    \n    {\\displaystyle u(t,x)\\approx a(t,x)e^{i(k\\cdot x-\\omega t)}}\n  where \n  \n    \n      \n        k\n        ,\n        \u03c9\n      \n    \n    {\\displaystyle k,\\omega }\n   satisfy a dispersion relation, and the amplitude \n  \n    \n      \n        a\n        (\n        t\n        ,\n        x\n        )\n      \n    \n    {\\displaystyle a(t,x)}\n   varies slowly.  More precisely, the leading order solution takes the form\n\n  \n    \n      \n        \n          a\n          \n            0\n          \n        \n        (\n        t\n        ,\n        x\n        )\n        \n          e\n          \n            i\n            \u03c6\n            (\n            t\n            ,\n            x\n            )\n            \n              /\n            \n            \u03b5\n          \n        \n        .\n      \n    \n    {\\displaystyle a_{0}(t,x)e^{i\\varphi (t,x)/\\varepsilon }.}\n  The phase \n  \n    \n      \n        \u03c6\n        (\n        t\n        ,\n        x\n        )\n        \n          /\n        \n        \u03b5\n      \n    \n    {\\displaystyle \\varphi (t,x)/\\varepsilon }\n   can be linearized to recover large wavenumber \n  \n    \n      \n        k\n        :=\n        \n          \u2207\n          \n            x\n          \n        \n        \u03c6\n      \n    \n    {\\displaystyle k:=\\nabla _{x}\\varphi }\n  , and frequency \n  \n    \n      \n        \u03c9\n        :=\n        \u2212\n        \n          \u2202\n          \n            t\n          \n        \n        \u03c6\n      \n    \n    {\\displaystyle \\omega :=-\\partial _{t}\\varphi }\n  .  The amplitude \n  \n    \n      \n        \n          a\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle a_{0}}\n   satisfies a transport equation.  The small parameter \n  \n    \n      \n        \u03b5\n        \n      \n    \n    {\\displaystyle \\varepsilon \\,}\n   enters the scene due to highly oscillatory initial conditions.  Thus, when initial conditions oscillate much faster than the coefficients of the differential equation, solutions will be highly oscillatory, and transported along rays.  Assuming coefficients in the differential equation are smooth, the rays will be too.  In other words, refraction does not take place.  The motivation for this technique comes from studying the typical scenario of light propagation where short wavelength light travels along rays that minimize (more or less) its travel time.  Its full application requires tools from microlocal analysis.\n\n\n=== Sommerfeld\u2013Runge method ===\nThe method of obtaining equations of geometrical optics by taking the limit of zero wavelength was first described by Arnold Sommerfeld and J. Runge in 1911. Their derivation was based on an oral remark by Peter Debye. Consider a monochromatic scalar field \n  \n    \n      \n        \u03c8\n        (\n        \n          r\n        \n        ,\n        t\n        )\n        =\n        \u03d5\n        (\n        \n          r\n        \n        )\n        \n          e\n          \n            i\n            \u03c9\n            t\n          \n        \n      \n    \n    {\\displaystyle \\psi (\\mathbf {r} ,t)=\\phi (\\mathbf {r} )e^{i\\omega t}}\n  , where \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n   could be any of the components of electric or magnetic field and hence the function \n  \n    \n      \n        \u03d5\n      \n    \n    {\\displaystyle \\phi }\n   satisfy the wave equation\n\n  \n    \n      \n        \n          \u2207\n          \n            2\n          \n        \n        \u03d5\n        +\n        \n          k\n          \n            o\n          \n          \n            2\n          \n        \n        n\n        (\n        \n          r\n        \n        \n          )\n          \n            2\n          \n        \n        \u03d5\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla ^{2}\\phi +k_{o}^{2}n(\\mathbf {r} )^{2}\\phi =0}\n  where \n  \n    \n      \n        \n          k\n          \n            o\n          \n        \n        =\n        \u03c9\n        \n          /\n        \n        c\n        =\n        2\n        \u03c0\n        \n          /\n        \n        \n          \u03bb\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle k_{o}=\\omega /c=2\\pi /\\lambda _{o}}\n   with \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   being the speed of light in vacuum. Here, \n  \n    \n      \n        n\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle n(\\mathbf {r} )}\n   is the refractive index of the medium. Without loss of generality, let us introduce \n  \n    \n      \n        \u03d5\n        =\n        A\n        (\n        \n          k\n          \n            o\n          \n        \n        ,\n        \n          r\n        \n        )\n        \n          e\n          \n            i\n            \n              k\n              \n                o\n              \n            \n            S\n            (\n            \n              r\n            \n            )\n          \n        \n      \n    \n    {\\displaystyle \\phi =A(k_{o},\\mathbf {r} )e^{ik_{o}S(\\mathbf {r} )}}\n   to convert the equation to\n\n  \n    \n      \n        \u2212\n        \n          k\n          \n            o\n          \n          \n            2\n          \n        \n        A\n        [\n        (\n        \u2207\n        S\n        \n          )\n          \n            2\n          \n        \n        \u2212\n        \n          n\n          \n            2\n          \n        \n        ]\n        +\n        2\n        i\n        \n          k\n          \n            o\n          \n        \n        (\n        \u2207\n        S\n        \u22c5\n        \u2207\n        A\n        )\n        +\n        i\n        \n          k\n          \n            o\n          \n        \n        A\n        \n          \u2207\n          \n            2\n          \n        \n        S\n        +\n        \n          \u2207\n          \n            2\n          \n        \n        A\n        =\n        0.\n      \n    \n    {\\displaystyle -k_{o}^{2}A[(\\nabla S)^{2}-n^{2}]+2ik_{o}(\\nabla S\\cdot \\nabla A)+ik_{o}A\\nabla ^{2}S+\\nabla ^{2}A=0.}\n  Since the underlying principle of geometrical optics lies in the limit \n  \n    \n      \n        \n          \u03bb\n          \n            o\n          \n        \n        \u223c\n        \n          k\n          \n            o\n          \n          \n            \u2212\n            1\n          \n        \n        \u2192\n        0\n      \n    \n    {\\displaystyle \\lambda _{o}\\sim k_{o}^{-1}\\rightarrow 0}\n  , the following asymptotic series is assumed,\n\n  \n    \n      \n        A\n        (\n        \n          k\n          \n            o\n          \n        \n        ,\n        \n          r\n        \n        )\n        =\n        \n          \u2211\n          \n            m\n            =\n            0\n          \n          \n            \u221e\n          \n        \n        \n          \n            \n              \n                A\n                \n                  m\n                \n              \n              (\n              \n                r\n              \n              )\n            \n            \n              (\n              i\n              \n                k\n                \n                  o\n                \n              \n              \n                )\n                \n                  m\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle A(k_{o},\\mathbf {r} )=\\sum _{m=0}^{\\infty }{\\frac {A_{m}(\\mathbf {r} )}{(ik_{o})^{m}}}}\n  For large but finite value of \n  \n    \n      \n        \n          k\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle k_{o}}\n  , the series diverges, and one has to be careful in keeping only appropriate first few terms. For each value of \n  \n    \n      \n        \n          k\n          \n            o\n          \n        \n      \n    \n    {\\displaystyle k_{o}}\n  , \none can find an optimum number of terms to be kept  and adding more terms than the optimum number might result in a poorer approximation. Substituting the series into the equation and collecting terms of different orders, one finds\n\n  \n    \n      \n        \n          \n            \n              \n                O\n                (\n                \n                  k\n                  \n                    o\n                  \n                  \n                    2\n                  \n                \n                )\n                :\n              \n              \n                \n                \n                (\n                \u2207\n                S\n                \n                  )\n                  \n                    2\n                  \n                \n                =\n                \n                  n\n                  \n                    2\n                  \n                \n                ,\n              \n            \n            \n              \n                O\n                (\n                \n                  k\n                  \n                    o\n                  \n                \n                )\n                :\n              \n              \n                \n                2\n                \u2207\n                S\n                \u22c5\n                \u2207\n                \n                  A\n                  \n                    0\n                  \n                \n                +\n                \n                  A\n                  \n                    0\n                  \n                \n                \n                  \u2207\n                  \n                    2\n                  \n                \n                S\n                =\n                0\n                ,\n              \n            \n            \n              \n                O\n                (\n                1\n                )\n                :\n              \n              \n                \n                2\n                \u2207\n                S\n                \u22c5\n                \u2207\n                \n                  A\n                  \n                    1\n                  \n                \n                +\n                \n                  A\n                  \n                    1\n                  \n                \n                \n                  \u2207\n                  \n                    2\n                  \n                \n                S\n                =\n                \u2212\n                \n                  \u2207\n                  \n                    2\n                  \n                \n                \n                  A\n                  \n                    0\n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}O(k_{o}^{2}):&\\quad (\\nabla S)^{2}=n^{2},\\\\O(k_{o}):&\\quad 2\\nabla S\\cdot \\nabla A_{0}+A_{0}\\nabla ^{2}S=0,\\\\O(1):&\\quad 2\\nabla S\\cdot \\nabla A_{1}+A_{1}\\nabla ^{2}S=-\\nabla ^{2}A_{0},\\end{aligned}}}\n  in general,\n\n  \n    \n      \n        O\n        (\n        \n          k\n          \n            o\n          \n          \n            1\n            \u2212\n            m\n          \n        \n        )\n        :\n        \n        2\n        \u2207\n        S\n        \u22c5\n        \u2207\n        \n          A\n          \n            m\n          \n        \n        +\n        \n          A\n          \n            m\n          \n        \n        \n          \u2207\n          \n            2\n          \n        \n        S\n        =\n        \u2212\n        \n          \u2207\n          \n            2\n          \n        \n        \n          A\n          \n            m\n            \u2212\n            1\n          \n        \n        .\n      \n    \n    {\\displaystyle O(k_{o}^{1-m}):\\quad 2\\nabla S\\cdot \\nabla A_{m}+A_{m}\\nabla ^{2}S=-\\nabla ^{2}A_{m-1}.}\n  The first equation is known as the eikonal equation, which determines the eikonal \n  \n    \n      \n        S\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle S(\\mathbf {r} )}\n   is a Hamilton\u2013Jacobi equation, written for example in Cartesian coordinates becomes\n\n  \n    \n      \n        \n          \n            (\n            \n              \n                \n                  \u2202\n                  S\n                \n                \n                  \u2202\n                  x\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        +\n        \n          \n            (\n            \n              \n                \n                  \u2202\n                  S\n                \n                \n                  \u2202\n                  y\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        +\n        \n          \n            (\n            \n              \n                \n                  \u2202\n                  S\n                \n                \n                  \u2202\n                  z\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle \\left({\\frac {\\partial S}{\\partial x}}\\right)^{2}+\\left({\\frac {\\partial S}{\\partial y}}\\right)^{2}+\\left({\\frac {\\partial S}{\\partial z}}\\right)^{2}=n^{2}.}\n  The remaining equations determine the functions \n  \n    \n      \n        \n          A\n          \n            m\n          \n        \n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle A_{m}(\\mathbf {r} )}\n  .\n\n\n=== Luneburg method ===\nThe method of obtaining equations of geometrical optics by analysing surfaces of discontinuities of solutions to Maxwell's equations was first described by Rudolf Karl Luneburg in 1944. It does not restrict the electromagnetic field to have a special form required by the Sommerfeld-Runge method which assumes the amplitude \n  \n    \n      \n        A\n        (\n        \n          k\n          \n            o\n          \n        \n        ,\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle A(k_{o},\\mathbf {r} )}\n   and phase \n  \n    \n      \n        S\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle S(\\mathbf {r} )}\n   satisfy the equation \n  \n    \n      \n        \n          lim\n          \n            \n              k\n              \n                0\n              \n            \n            \u2192\n            \u221e\n          \n        \n        \n          \n            1\n            \n              k\n              \n                0\n              \n            \n          \n        \n        \n          (\n          \n            \n              \n                1\n                A\n              \n            \n            \n            \u2207\n            S\n            \u22c5\n            \u2207\n            A\n            +\n            \n              \n                1\n                2\n              \n            \n            \n              \u2207\n              \n                2\n              \n            \n            S\n          \n          )\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\lim _{k_{0}\\to \\infty }{1 \\over k_{0}}\\left({1 \\over A}\\,\\nabla S\\cdot \\nabla A+{1 \\over 2}\\nabla ^{2}S\\right)=0}\n  . This condition is satisfied by e.g. plane waves but is not additive.\nThe main conclusion of Luneburg's approach is the following:\nTheorem. Suppose the fields \n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {E}} (x,y,z,t)}\n   and \n  \n    \n      \n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {H}} (x,y,z,t)}\n   (in a linear isotropic medium described by dielectric constants \n  \n    \n      \n        \u03b5\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle \\varepsilon (x,y,z)}\n   and \n  \n    \n      \n        \u03bc\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle \\mu (x,y,z)}\n  ) have finite discontinuities along a (moving) surface in \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {R} ^{3}}\n   described by the equation \n  \n    \n      \n        \u03c8\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        \u2212\n        c\n        t\n        =\n        0\n      \n    \n    {\\displaystyle \\psi (x,y,z)-ct=0}\n  . Then Maxwell's equations in the integral form imply that \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n   satisfies the eikonal equation:\n\n  \n    \n      \n        \n          \u03c8\n          \n            x\n          \n          \n            2\n          \n        \n        +\n        \n          \u03c8\n          \n            y\n          \n          \n            2\n          \n        \n        +\n        \n          \u03c8\n          \n            z\n          \n          \n            2\n          \n        \n        =\n        \u03b5\n        \u03bc\n        =\n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\psi _{x}^{2}+\\psi _{y}^{2}+\\psi _{z}^{2}=\\varepsilon \\mu =n^{2}}\n  ,where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is the index of refraction of the medium (Gaussian units).\nAn example of such surface of discontinuity is the initial wave front emanating from a source that starts radiating at a certain instant of time.\nThe surfaces of field discontinuity thus become geometrical optics wave fronts with the corresponding geometrical optics fields defined as:\n\n  \n    \n      \n        \n          \n            \n              \n                E\n                \u2192\n              \n            \n          \n          \n            \u2217\n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        =\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        \u03c8\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        \n          /\n        \n        c\n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {E}} ^{*}(x,y,z)=\\mathbf {\\vec {E}} (x,y,z,\\psi (x,y,z)/c)}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                H\n                \u2192\n              \n            \n          \n          \n            \u2217\n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        =\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        \u03c8\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        \n          /\n        \n        c\n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {H}} ^{*}(x,y,z)=\\mathbf {\\vec {H}} (x,y,z,\\psi (x,y,z)/c)}\n  Those fields obey transport equations consistent with the transport equations of the Sommerfeld-Runge approach. Light rays in Luneburg's theory are defined as trajectories orthogonal to the discontinuity surfaces and can be shown to obey Fermat's principle of least time thus establishing the identity of those rays with light rays of standard optics.\nThe above developments can be generalised to anisotropic media.The proof of Luneburg's theorem is based on investigating how Maxwell's equations govern the propagation of discontinuities of solutions. The basic technical lemma is as follows:\nA technical lemma. Let \n  \n    \n      \n        \u03c6\n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        t\n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\varphi (x,y,z,t)=0}\n   be a hypersurface (a 3-dimensional manifold) in spacetime \n  \n    \n      \n        \n          \n            R\n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {R} ^{4}}\n   on which one or more of: \n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {E}} (x,y,z,t)}\n  , \n  \n    \n      \n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {H}} (x,y,z,t)}\n  , \n  \n    \n      \n        \u03b5\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle \\varepsilon (x,y,z)}\n  , \n  \n    \n      \n        \u03bc\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle \\mu (x,y,z)}\n  , have a finite discontinuity. Then at each point of the hypersurface the following formulas hold:\n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u22c5\n        [\n        \u03b5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\cdot [\\varepsilon \\mathbf {\\vec {E}} ]=0}\n  \n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u22c5\n        [\n        \u03bc\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\cdot [\\mu \\mathbf {\\vec {H}} ]=0}\n  \n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u00d7\n        [\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        +\n        \n          \n            1\n            c\n          \n        \n        \n        \n          \u03c6\n          \n            t\n          \n        \n        \n        [\n        \u03bc\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\times [\\mathbf {\\vec {E}} ]+{1 \\over c}\\,\\varphi _{t}\\,[\\mu \\mathbf {\\vec {H}} ]=0}\n  \n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u00d7\n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        \u2212\n        \n          \n            1\n            c\n          \n        \n        \n        \n          \u03c6\n          \n            t\n          \n        \n        \n        [\n        \u03b5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\times [\\mathbf {\\vec {H}} ]-{1 \\over c}\\,\\varphi _{t}\\,[\\varepsilon \\mathbf {\\vec {E}} ]=0}\n  where the \n  \n    \n      \n        \u2207\n      \n    \n    {\\displaystyle \\nabla }\n   operator acts in the \n  \n    \n      \n        x\n        y\n        z\n      \n    \n    {\\displaystyle xyz}\n  -space (for every fixed \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  ) and the square brackets denote the difference in values on both sides of the discontinuity surface (set up according to an arbitrary but fixed convention, e.g. the gradient \n  \n    \n      \n        \u2207\n        \u03c6\n      \n    \n    {\\displaystyle \\nabla \\varphi }\n   pointing in the direction of the quantities being subtracted from).\nSketch of proof. Start with Maxwell's equations away from the sources (Gaussian units):\n\n  \n    \n      \n        \u2207\n        \u22c5\n        \u03b5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\cdot \\varepsilon \\mathbf {\\vec {E}} =0}\n  \n\n  \n    \n      \n        \u2207\n        \u22c5\n        \u03bc\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\cdot \\mu \\mathbf {\\vec {H}} =0}\n  \n\n  \n    \n      \n        \u2207\n        \u00d7\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        +\n        \n          \n            \u03bc\n            c\n          \n        \n        \n        \n          \n            \n              \n                H\n                \u2192\n              \n            \n          \n          \n            t\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\times \\mathbf {\\vec {E}} +{\\mu  \\over c}\\,\\mathbf {\\vec {H}} _{t}=0}\n  \n\n  \n    \n      \n        \u2207\n        \u00d7\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        \u2212\n        \n          \n            \u03b5\n            c\n          \n        \n        \n        \n          \n            \n              \n                E\n                \u2192\n              \n            \n          \n          \n            t\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\times \\mathbf {\\vec {H}} -{\\varepsilon  \\over c}\\,\\mathbf {\\vec {E}} _{t}=0}\n  Using Stokes' theorem in \n  \n    \n      \n        \n          \n            R\n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {R} ^{4}}\n   one can conclude from the first of the above equations that for any domain \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n   in \n  \n    \n      \n        \n          \n            R\n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {R} ^{4}}\n   with a piecewise smooth (3-dimensional) boundary \n  \n    \n      \n        \u0393\n      \n    \n    {\\displaystyle \\Gamma }\n   the following is true:\n\n  \n    \n      \n        \n          \u222e\n          \n            \u0393\n          \n        \n        (\n        \n          \n            \n              M\n              \u2192\n            \n          \n        \n        \u22c5\n        \u03b5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        S\n        =\n        0\n      \n    \n    {\\displaystyle \\oint _{\\Gamma }(\\mathbf {\\vec {M}} \\cdot \\varepsilon \\mathbf {\\vec {E}} )\\,dS=0}\n  where \n  \n    \n      \n        \n          \n            \n              M\n              \u2192\n            \n          \n        \n        =\n        (\n        \n          x\n          \n            N\n          \n        \n        ,\n        \n          y\n          \n            N\n          \n        \n        ,\n        \n          z\n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {\\vec {M}} =(x_{N},y_{N},z_{N})}\n   is the projection of the outward unit normal \n  \n    \n      \n        (\n        \n          x\n          \n            N\n          \n        \n        ,\n        \n          y\n          \n            N\n          \n        \n        ,\n        \n          z\n          \n            N\n          \n        \n        ,\n        \n          t\n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{N},y_{N},z_{N},t_{N})}\n   of \n  \n    \n      \n        \u0393\n      \n    \n    {\\displaystyle \\Gamma }\n   onto the 3D slice \n  \n    \n      \n        t\n        =\n        \n          \n            c\n            o\n            n\n            s\n            t\n          \n        \n      \n    \n    {\\displaystyle t={\\rm {const}}}\n  , and \n  \n    \n      \n        d\n        S\n      \n    \n    {\\displaystyle dS}\n   is the volume 3-form on \n  \n    \n      \n        \u0393\n      \n    \n    {\\displaystyle \\Gamma }\n  . Similarly, one establishes the following from the remaining Maxwell's equations:\n\n  \n    \n      \n        \n          \u222e\n          \n            \u0393\n          \n        \n        (\n        \n          \n            \n              M\n              \u2192\n            \n          \n        \n        \u22c5\n        \u03bc\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        S\n        =\n        0\n      \n    \n    {\\displaystyle \\oint _{\\Gamma }(\\mathbf {\\vec {M}} \\cdot \\mu \\mathbf {\\vec {H}} )\\,dS=0}\n  \n\n  \n    \n      \n        \n          \u222e\n          \n            \u0393\n          \n        \n        (\n        \n          \n            \n              M\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        +\n        \n          \n            \u03bc\n            c\n          \n        \n        \n        \n          t\n          \n            N\n          \n        \n        \n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        S\n        =\n        0\n      \n    \n    {\\displaystyle \\oint _{\\Gamma }(\\mathbf {\\vec {M}} \\times \\mathbf {\\vec {E}} +{\\mu  \\over c}\\,t_{N}\\,\\mathbf {\\vec {H}} )\\,dS=0}\n  \n\n  \n    \n      \n        \n          \u222e\n          \n            \u0393\n          \n        \n        (\n        \n          \n            \n              M\n              \u2192\n            \n          \n        \n        \u00d7\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        \u2212\n        \n          \n            \u03b5\n            c\n          \n        \n        \n        \n          t\n          \n            N\n          \n        \n        \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        )\n        \n        d\n        S\n        =\n        0\n      \n    \n    {\\displaystyle \\oint _{\\Gamma }(\\mathbf {\\vec {M}} \\times \\mathbf {\\vec {H}} -{\\varepsilon  \\over c}\\,t_{N}\\,\\mathbf {\\vec {E}} )\\,dS=0}\n  Now by considering arbitrary small sub-surfaces \n  \n    \n      \n        \n          \u0393\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\Gamma _{0}}\n   of \n  \n    \n      \n        \u0393\n      \n    \n    {\\displaystyle \\Gamma }\n   and setting up small neighbourhoods surrounding \n  \n    \n      \n        \n          \u0393\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\Gamma _{0}}\n   in \n  \n    \n      \n        \n          \n            R\n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {R} ^{4}}\n  , and subtracting the above integrals accordingly, one obtains:\n\n  \n    \n      \n        \n          \u222b\n          \n            \n              \u0393\n              \n                0\n              \n            \n          \n        \n        (\n        \u2207\n        \u03c6\n        \u22c5\n        [\n        \u03b5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        )\n        \n        \n          \n            \n              d\n              S\n            \n            \n              \u2016\n              \n                \u2207\n                \n                  4\n                  D\n                \n              \n              \u03c6\n              \u2016\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\int _{\\Gamma _{0}}(\\nabla \\varphi \\cdot [\\varepsilon \\mathbf {\\vec {E}} ])\\,{dS \\over \\|\\nabla ^{4D}\\varphi \\|}=0}\n  \n\n  \n    \n      \n        \n          \u222b\n          \n            \n              \u0393\n              \n                0\n              \n            \n          \n        \n        (\n        \u2207\n        \u03c6\n        \u22c5\n        [\n        \u03bc\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        )\n        \n        \n          \n            \n              d\n              S\n            \n            \n              \u2016\n              \n                \u2207\n                \n                  4\n                  D\n                \n              \n              \u03c6\n              \u2016\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\int _{\\Gamma _{0}}(\\nabla \\varphi \\cdot [\\mu \\mathbf {\\vec {H}} ])\\,{dS \\over \\|\\nabla ^{4D}\\varphi \\|}=0}\n  \n\n  \n    \n      \n        \n          \u222b\n          \n            \n              \u0393\n              \n                0\n              \n            \n          \n        \n        \n          (\n          \n            \u2207\n            \u03c6\n            \u00d7\n            [\n            \n              \n                \n                  E\n                  \u2192\n                \n              \n            \n            ]\n            +\n            \n              \n                1\n                c\n              \n            \n            \n            \n              \u03c6\n              \n                t\n              \n            \n            \n            [\n            \u03bc\n            \n              \n                \n                  H\n                  \u2192\n                \n              \n            \n            ]\n          \n          )\n        \n        \n        \n          \n            \n              d\n              S\n            \n            \n              \u2016\n              \n                \u2207\n                \n                  4\n                  D\n                \n              \n              \u03c6\n              \u2016\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\int _{\\Gamma _{0}}\\left(\\nabla \\varphi \\times [\\mathbf {\\vec {E}} ]+{1 \\over c}\\,\\varphi _{t}\\,[\\mu \\mathbf {\\vec {H}} ]\\right)\\,{dS \\over \\|\\nabla ^{4D}\\varphi \\|}=0}\n  \n\n  \n    \n      \n        \n          \u222b\n          \n            \n              \u0393\n              \n                0\n              \n            \n          \n        \n        \n          (\n          \n            \u2207\n            \u03c6\n            \u00d7\n            [\n            \n              \n                \n                  H\n                  \u2192\n                \n              \n            \n            ]\n            \u2212\n            \n              \n                1\n                c\n              \n            \n            \n            \n              \u03c6\n              \n                t\n              \n            \n            \n            [\n            \u03b5\n            \n              \n                \n                  E\n                  \u2192\n                \n              \n            \n            ]\n          \n          )\n        \n        \n        \n          \n            \n              d\n              S\n            \n            \n              \u2016\n              \n                \u2207\n                \n                  4\n                  D\n                \n              \n              \u03c6\n              \u2016\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\int _{\\Gamma _{0}}\\left(\\nabla \\varphi \\times [\\mathbf {\\vec {H}} ]-{1 \\over c}\\,\\varphi _{t}\\,[\\varepsilon \\mathbf {\\vec {E}} ]\\right)\\,{dS \\over \\|\\nabla ^{4D}\\varphi \\|}=0}\n  where \n  \n    \n      \n        \n          \u2207\n          \n            4\n            D\n          \n        \n      \n    \n    {\\displaystyle \\nabla ^{4D}}\n   denotes the gradient in the 4D \n  \n    \n      \n        x\n        y\n        z\n        t\n      \n    \n    {\\displaystyle xyzt}\n  -space. And since \n  \n    \n      \n        \n          \u0393\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\Gamma _{0}}\n   is arbitrary, the integrands must be equal to 0 which proves the lemma.\nIt's now easy to show that as they propagate through a continuous medium, the discontinuity surfaces obey the eikonal equation. Specifically, if \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n   and \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   are continuous, then the discontinuities of \n  \n    \n      \n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\vec {E}} }\n   and \n  \n    \n      \n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\vec {H}} }\n   satisfy: \n  \n    \n      \n        [\n        \u03b5\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        =\n        \u03b5\n        [\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n      \n    \n    {\\displaystyle [\\varepsilon \\mathbf {\\vec {E}} ]=\\varepsilon [\\mathbf {\\vec {E}} ]}\n   and \n  \n    \n      \n        [\n        \u03bc\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        =\n        \u03bc\n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n      \n    \n    {\\displaystyle [\\mu \\mathbf {\\vec {H}} ]=\\mu [\\mathbf {\\vec {H}} ]}\n  . In this case the last two equations of the lemma can be written as:\n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u00d7\n        [\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        +\n        \n          \n            \u03bc\n            c\n          \n        \n        \n        \n          \u03c6\n          \n            t\n          \n        \n        \n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\times [\\mathbf {\\vec {E}} ]+{\\mu  \\over c}\\,\\varphi _{t}\\,[\\mathbf {\\vec {H}} ]=0}\n  \n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u00d7\n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        \u2212\n        \n          \n            \u03b5\n            c\n          \n        \n        \n        \n          \u03c6\n          \n            t\n          \n        \n        \n        [\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\times [\\mathbf {\\vec {H}} ]-{\\varepsilon  \\over c}\\,\\varphi _{t}\\,[\\mathbf {\\vec {E}} ]=0}\n  Taking the cross product of the second equation with \n  \n    \n      \n        \u2207\n        \u03c6\n      \n    \n    {\\displaystyle \\nabla \\varphi }\n   and substituting the first yields:\n\n  \n    \n      \n        \u2207\n        \u03c6\n        \u00d7\n        (\n        \u2207\n        \u03c6\n        \u00d7\n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        )\n        \u2212\n        \n          \n            \u03b5\n            c\n          \n        \n        \n        \n          \u03c6\n          \n            t\n          \n        \n        \n        (\n        \u2207\n        \u03c6\n        \u00d7\n        [\n        \n          \n            \n              E\n              \u2192\n            \n          \n        \n        ]\n        )\n        =\n        (\n        \u2207\n        \u03c6\n        \u22c5\n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        )\n        \n        \u2207\n        \u03c6\n        \u2212\n        \u2016\n        \u2207\n        \u03c6\n        \n          \u2016\n          \n            2\n          \n        \n        \n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        +\n        \n          \n            \n              \u03b5\n              \u03bc\n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n        \n          \u03c6\n          \n            t\n          \n          \n            2\n          \n        \n        \n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\times (\\nabla \\varphi \\times [\\mathbf {\\vec {H}} ])-{\\varepsilon  \\over c}\\,\\varphi _{t}\\,(\\nabla \\varphi \\times [\\mathbf {\\vec {E}} ])=(\\nabla \\varphi \\cdot [\\mathbf {\\vec {H}} ])\\,\\nabla \\varphi -\\|\\nabla \\varphi \\|^{2}\\,[\\mathbf {\\vec {H}} ]+{\\varepsilon \\mu  \\over c^{2}}\\varphi _{t}^{2}\\,[\\mathbf {\\vec {H}} ]=0}\n  The continuity of \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n   and the second equation of the lemma imply: \n  \n    \n      \n        \u2207\n        \u03c6\n        \u22c5\n        [\n        \n          \n            \n              H\n              \u2192\n            \n          \n        \n        ]\n        =\n        0\n      \n    \n    {\\displaystyle \\nabla \\varphi \\cdot [\\mathbf {\\vec {H}} ]=0}\n  , hence, for points lying on the surface \n  \n    \n      \n        \u03c6\n        =\n        0\n      \n    \n    {\\displaystyle \\varphi =0}\n   only:\n\n  \n    \n      \n        \u2016\n        \u2207\n        \u03c6\n        \n          \u2016\n          \n            2\n          \n        \n        =\n        \n          \n            \n              \u03b5\n              \u03bc\n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n        \n          \u03c6\n          \n            t\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\|\\nabla \\varphi \\|^{2}={\\varepsilon \\mu  \\over c^{2}}\\varphi _{t}^{2}}\n  (Notice the presence of the discontinuity is essential in this step as we'd be dividing by zero otherwise.)\nBecause of the physical considerations one can assume without loss of generality that \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n   is of the following form:\n\n  \n    \n      \n        \u03c6\n        (\n        x\n        ,\n        y\n        ,\n        z\n        ,\n        t\n        )\n        =\n        \u03c8\n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n        \u2212\n        c\n        t\n      \n    \n    {\\displaystyle \\varphi (x,y,z,t)=\\psi (x,y,z)-ct}\n  , i.e. a 2D surface moving through space, modelled as level surfaces of \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n  . (Mathematically \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n   exists if \n  \n    \n      \n        \n          \u03c6\n          \n            t\n          \n        \n        \u2260\n        0\n      \n    \n    {\\displaystyle \\varphi _{t}\\neq 0}\n   by the implicit function theorem.)\nThe above equation written in terms of \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n   becomes:\n\n  \n    \n      \n        \u2016\n        \u2207\n        \u03c8\n        \n          \u2016\n          \n            2\n          \n        \n        =\n        \n          \n            \n              \u03b5\n              \u03bc\n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n        \n        (\n        \u2212\n        c\n        \n          )\n          \n            2\n          \n        \n        =\n        \u03b5\n        \u03bc\n        =\n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\|\\nabla \\psi \\|^{2}={\\varepsilon \\mu  \\over c^{2}}\\,(-c)^{2}=\\varepsilon \\mu =n^{2}}\n  i.e.,\n\n  \n    \n      \n        \n          \u03c8\n          \n            x\n          \n          \n            2\n          \n        \n        +\n        \n          \u03c8\n          \n            y\n          \n          \n            2\n          \n        \n        +\n        \n          \u03c8\n          \n            z\n          \n          \n            2\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\psi _{x}^{2}+\\psi _{y}^{2}+\\psi _{z}^{2}=n^{2}}\n  which is the eikonal equation and it holds for all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  , \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  , since the variable \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n   is absent. Other laws of optics like Snell's law and Fresnel formulae can be similarly obtained by considering discontinuities in \n  \n    \n      \n        \u03b5\n      \n    \n    {\\displaystyle \\varepsilon }\n   and \n  \n    \n      \n        \u03bc\n      \n    \n    {\\displaystyle \\mu }\n  .\n\n\n=== General equation using four-vector notation ===\nIn four-vector notation used in special relativity, the wave equation can be written as\n\n  \n    \n      \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              \u03c8\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle {\\frac {\\partial ^{2}\\psi }{\\partial x_{i}\\partial x^{i}}}=0}\n  and the substitution \n  \n    \n      \n        \u03c8\n        =\n        A\n        \n          e\n          \n            i\n            S\n            \n              /\n            \n            \u03f5\n          \n        \n      \n    \n    {\\displaystyle \\psi =Ae^{iS/\\epsilon }}\n   leads to\n\n  \n    \n      \n        \u2212\n        \n          \n            A\n            \n              \u03f5\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \u2202\n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        \n          \n            \n              \u2202\n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              2\n              i\n            \n            \u03f5\n          \n        \n        \n          \n            \n              \u2202\n              A\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        \n          \n            \n              \u2202\n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              i\n              A\n            \n            \u03f5\n          \n        \n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        +\n        \n          \n            \n              \n                \u2202\n                \n                  2\n                \n              \n              A\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        =\n        0.\n      \n    \n    {\\displaystyle -{\\frac {A}{\\epsilon ^{2}}}{\\frac {\\partial S}{\\partial x_{i}}}{\\frac {\\partial S}{\\partial x^{i}}}+{\\frac {2i}{\\epsilon }}{\\frac {\\partial A}{\\partial x_{i}}}{\\frac {\\partial S}{\\partial x^{i}}}+{\\frac {iA}{\\epsilon }}{\\frac {\\partial ^{2}S}{\\partial x_{i}\\partial x^{i}}}+{\\frac {\\partial ^{2}A}{\\partial x_{i}\\partial x^{i}}}=0.}\n  Therefore the eikonal equation is given by\n\n  \n    \n      \n        \n          \n            \n              \u2202\n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        \n          \n            \n              \u2202\n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        =\n        0.\n      \n    \n    {\\displaystyle {\\frac {\\partial S}{\\partial x_{i}}}{\\frac {\\partial S}{\\partial x^{i}}}=0.}\n  Once eikonal is found by solving the above equation, the wave four-vector can be found from\n\n  \n    \n      \n        \n          k\n          \n            i\n          \n        \n        =\n        \u2212\n        \n          \n            \n              \u2202\n              S\n            \n            \n              \u2202\n              \n                x\n                \n                  i\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle k_{i}=-{\\frac {\\partial S}{\\partial x^{i}}}.}\n  \n\n\n== See also ==\nHamiltonian optics\nGeometrical acoustics\n\n\n== References ==\n\n\n== Further reading ==\nRobert Alfred Herman (1900) A Treatise on Geometrical optics from Archive.org.\n\"The Light of the Eyes and the Enlightened Landscape of Vision\" is a manuscript, in Arabic, about geometrical optics, dating from the 16th century.\nTheory of Systems of Rays \u2013 W.R. Hamilton in Transactions of the Royal Irish Academy, Vol. XV, 1828.\n\n\n=== English translations of some early books and papers ===\nH. Bruns, \"Das Eikonal\"\nM. Malus, \"Optique\"\nJ. Plucker, \"Discussion of the general form for light waves\"\nE. Kummer, \"General theory of rectilinear ray systems\"\nE. Kummer, presentation on optically-realizable rectilinear ray systems\nR. Meibauer, \"Theory of rectilinear systems of light rays\"\nM. Pasch, \"On the focal surfaces of ray systems and the singularity surfaces of complexes\"\nA. Levistal, \"Research in geometrical optics\"\nF. Klein, \"On the Bruns eikonal\"\nR. Dontot, \"On integral invariants and some points of geometrical optics\"\nT. de Donder, \"On the integral invariants of optics\"\n\n\n== External links ==\nFeynman's lecture on Geometrical Optics", "Ohm's_law": "Ohm's law states that the current through a conductor between two points is directly proportional to the voltage across the two points. Introducing the constant of proportionality, the resistance, one arrives at the usual mathematical equation that describes this relationship:\n\n  \n    \n      \n        I\n        =\n        \n          \n            V\n            R\n          \n        \n        ,\n      \n    \n    {\\displaystyle I={\\frac {V}{R}},}\n  where I is the current through the conductor, V is the voltage measured across the conductor and R is the resistance of the conductor.  More specifically, Ohm's law states that the R in this relation is constant, independent of the current.  If the resistance is not constant, the previous equation cannot be called Ohm's law, but it can still be used as a definition of static/DC resistance.  Ohm's law is an empirical relation which accurately describes the conductivity of the vast majority of electrically conductive materials over many orders of magnitude of current.  However some materials do not obey Ohm's law; these are called non-ohmic.\nThe law was named after the German physicist Georg Ohm, who, in a treatise published in 1827, described measurements of applied voltage and current through simple electrical circuits containing various lengths of wire. Ohm explained his experimental results by a slightly more complex equation than the modern form above (see \u00a7 History below).\nIn physics, the term Ohm's law is also used to refer to various generalizations of the law; for example the vector form of the law used in electromagnetics and material science:\n\n  \n    \n      \n        \n          J\n        \n        =\n        \u03c3\n        \n          E\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {J} =\\sigma \\mathbf {E} ,}\n  where J is the current density at a given location in a resistive material, E is the electric field at that location, and \u03c3 (sigma) is a material-dependent parameter called the conductivity.  This reformulation of Ohm's law is due to Gustav Kirchhoff.\n\n\n== History ==\n\nIn January 1781, before Georg Ohm's work, Henry Cavendish experimented with Leyden jars and glass tubes of varying diameter and length filled with salt solution.  He measured the current by noting how strong a shock he felt as he completed the circuit with his body.  Cavendish wrote that the \"velocity\" (current) varied directly as the \"degree of electrification\" (voltage). He did not communicate his results to other scientists at the time, and his results were unknown until Maxwell published them in 1879.Francis Ronalds delineated \"intensity\" (voltage) and \"quantity\" (current) for the dry pile\u2014a high voltage source\u2014in 1814 using a gold-leaf electrometer.  He found for a dry pile that the relationship between the two parameters was not proportional under certain meteorological conditions.Ohm did his work on resistance in the years 1825 and 1826, and published his results in 1827 as the book Die galvanische Kette, mathematisch bearbeitet (\"The galvanic circuit investigated mathematically\"). He drew considerable inspiration from Fourier's work on heat conduction in the theoretical explanation of his work.  For experiments, he initially used voltaic piles, but later used a thermocouple as this provided a more stable voltage source in terms of internal resistance and constant voltage.  He used a galvanometer to measure current, and knew that the voltage between the thermocouple terminals was proportional to the junction temperature.  He then added test wires of varying length, diameter, and material to complete the circuit.  He found that his data could be modeled through the equation\n\n  \n    \n      \n        x\n        =\n        \n          \n            a\n            \n              b\n              +\n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle x={\\frac {a}{b+l}},}\n  where x was the reading from the galvanometer, l was the length of the test conductor, a depended on the thermocouple junction temperature, and b was a constant of the entire setup.  From this, Ohm determined his law of proportionality and published his results.\n\nIn modern notation we would write,\n\n  \n    \n      \n        I\n        =\n        \n          \n            \n              E\n            \n            \n              r\n              +\n              R\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle I={\\frac {\\mathcal {E}}{r+R}},}\n  where \n  \n    \n      \n        \n          \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}}\n   is the open-circuit emf of the thermocouple, \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n   is the internal resistance of the thermocouple and \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   is the resistance of the test wire.  In terms of the length of the wire this becomes,\n\n  \n    \n      \n        I\n        =\n        \n          \n            \n              E\n            \n            \n              r\n              +\n              \n                \n                  R\n                \n              \n              l\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle I={\\frac {\\mathcal {E}}{r+{\\mathcal {R}}l}},}\n  where \n  \n    \n      \n        \n          \n            R\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {R}}}\n   is the resistance of the test wire per unit length.  Thus, Ohm's coefficients are,\n\n  \n    \n      \n        a\n        =\n        \n          \n            \n              E\n            \n            \n              R\n            \n          \n        \n        ,\n        \n        b\n        =\n        \n          \n            \n              r\n            \n            \n              R\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle a={\\frac {\\mathcal {E}}{\\mathcal {R}}},\\quad b={\\frac {\\mathcal {r}}{\\mathcal {R}}}.}\n  \nOhm's law was probably the most important of the early quantitative descriptions of the physics of electricity.  We consider it almost obvious today. When Ohm first published his work, this was not the case; critics reacted to his treatment of the subject with hostility.  They called his work a \"web of naked fancies\" and the Minister of Education proclaimed that \"a professor who preached such heresies was unworthy to teach science.\" The prevailing scientific philosophy in Germany at the time asserted that experiments need not be performed to develop an understanding of nature because nature is so well ordered, and that scientific truths may be deduced through reasoning alone.  Also, Ohm's brother Martin, a mathematician, was battling the German educational system. These factors hindered the acceptance of Ohm's work, and his work did not become widely accepted until the 1840s.  However, Ohm received recognition for his contributions to science well before he died.\nIn the 1850s, Ohm's law was widely known and considered proved. Alternatives such as \"Barlow's law\", were discredited, in terms of real applications to telegraph system design, as discussed by Samuel F. B. Morse in 1855.The electron was discovered in 1897 by J. J. Thomson, and it was quickly realized that it is the particle (charge carrier) that carries electric currents in electric circuits.  In 1900 the first (classical) model of electrical conduction, the Drude model, was proposed by Paul Drude, which finally gave a scientific explanation for Ohm's law.  In this model, a solid conductor consists of a stationary lattice of atoms (ions), with conduction electrons moving randomly in it.  A voltage across a conductor causes an electric field, which accelerates the electrons in the direction of the electric field, causing a drift of electrons which is the electric current. However the electrons collide with atoms which causes them to scatter and randomizes their motion, thus converting kinetic energy to heat (thermal energy).  Using statistical distributions, it can be shown that the average drift velocity of the electrons, and thus the current, is proportional to the electric field, and thus the voltage, over a wide range of voltages.\nThe development of quantum mechanics in the 1920s modified this picture somewhat, but in modern theories the average drift velocity of electrons can still be shown to be proportional to the electric field, thus deriving Ohm's law. In 1927 Arnold Sommerfeld applied the quantum Fermi-Dirac distribution of electron energies to the Drude model, resulting in the free electron model. A year later, Felix Bloch showed that electrons move in waves (Bloch electrons) through a solid crystal lattice, so scattering off the lattice atoms as postulated in the Drude model is not a major process; the electrons scatter off impurity atoms and defects in the material. The final successor, the modern quantum band theory of solids, showed that the electrons in a solid cannot take on any energy as assumed in the Drude model but are restricted to energy bands, with gaps between them of energies that electrons are forbidden to have.   The size of the band gap is a characteristic of a particular substance which has a great deal to do with its electrical resistivity, explaining why some substances are electrical conductors, some semiconductors, and some insulators.\nWhile the old term for electrical conductance, the mho (the inverse of the resistance unit ohm), is still used, a new name, the siemens, was adopted in 1971, honoring Ernst Werner von Siemens.  The siemens is preferred in formal papers.\nIn the 1920s, it was discovered that the current through a practical resistor actually has statistical fluctuations, which depend on temperature, even when voltage and resistance are exactly constant; this fluctuation, now known as Johnson\u2013Nyquist noise, is due to the discrete nature of charge.  This thermal effect implies that measurements of current and voltage that are taken over sufficiently short periods of time will yield ratios of V/I that fluctuate from the value of R implied by the time average or ensemble average of the measured current; Ohm's law remains correct for the average current, in the case of ordinary resistive materials.\nOhm's work long preceded Maxwell's equations and any understanding of frequency-dependent effects in AC circuits. Modern developments in electromagnetic theory and circuit theory do not contradict Ohm's law when they are evaluated within the appropriate limits.\n\n\n== Scope ==\nOhm's law is an empirical law, a generalization from many experiments that have shown that current is approximately proportional to electric field for most materials. It is less fundamental than Maxwell's equations and is not always obeyed. Any given material will break down under a strong-enough electric field, and some materials of interest in electrical engineering are \"non-ohmic\" under weak fields.Ohm's law has been observed on a wide range of length scales. In the early 20th century, it was thought that Ohm's law would fail at the atomic scale, but experiments have not borne out this expectation. As of 2012, researchers have demonstrated that Ohm's law works for silicon wires as small as four atoms wide and one atom high.\n\n\n== Microscopic origins ==\n\nThe dependence of the current density on the applied electric field is essentially quantum mechanical in nature;  (see Classical and quantum conductivity.)  A qualitative description leading to Ohm's law can be based upon classical mechanics using the Drude model developed by Paul Drude in 1900.The Drude model treats electrons (or other charge carriers) like pinballs bouncing among the ions that make up the structure of the material.  Electrons will be accelerated in the opposite direction to the electric field by the average electric field at their location. With each collision, though, the electron is deflected in a random direction with a velocity that is much larger than the velocity gained by the electric field.  The net result is that electrons take a zigzag path due to the collisions, but generally drift in a direction opposing the electric field.\nThe drift velocity then determines the electric current density and its relationship to E and is independent of the collisions.  Drude calculated the average drift velocity from p = \u2212eE\u03c4 where p is the average momentum, \u2212e is the charge of the electron and \u03c4 is the average time between the collisions.   Since both the momentum and the current density are proportional to the drift velocity, the current density becomes proportional to the applied electric field; this leads to Ohm's law.\n\n\n== Hydraulic analogy ==\nA hydraulic analogy is sometimes used to describe Ohm's law.  Water pressure, measured by pascals (or PSI), is the analog of voltage because establishing a water pressure difference between two points along a (horizontal) pipe causes water to flow.  The water volume flow rate, as in liters per second, is the analog of current, as in coulombs per second. Finally, flow restrictors\u2014such as apertures placed in pipes between points where the water pressure is measured\u2014are the analog of resistors. We say that the rate of water flow through an aperture restrictor is proportional to the difference in water pressure across the restrictor. Similarly, the rate of flow of electrical charge, that is, the electric current, through an electrical resistor is proportional to the difference in voltage measured across the resistor. More generally, the hydraulic head may be taken as the analog of voltage, and Ohm's law is then analogous to Darcy's law which relates hydraulic head to the volume flow rate via the hydraulic conductivity.\nFlow and pressure variables can be calculated in fluid flow network with the use of the hydraulic ohm analogy.  The method can be applied to both steady and transient flow situations.  In the linear laminar flow region, Poiseuille's law describes the hydraulic resistance of a pipe, but in the turbulent flow region the pressure\u2013flow relations become nonlinear.\nThe hydraulic analogy to Ohm's law has been used, for example, to approximate blood flow through the circulatory system.\n\n\n== Circuit analysis ==\n\nIn circuit analysis, three equivalent expressions of Ohm's law are used interchangeably:\n\n  \n    \n      \n        I\n        =\n        \n          \n            V\n            R\n          \n        \n        \n        \n          or\n        \n        \n        V\n        =\n        I\n        R\n        \n        \n          or\n        \n        \n        R\n        =\n        \n          \n            V\n            I\n          \n        \n        .\n      \n    \n    {\\displaystyle I={\\frac {V}{R}}\\quad {\\text{or}}\\quad V=IR\\quad {\\text{or}}\\quad R={\\frac {V}{I}}.}\n  Each equation is quoted by some sources as the defining relationship of Ohm's law,\nor all three are quoted, or derived from a proportional form,\nor even just the two that do not correspond to Ohm's original statement may sometimes be given.The interchangeability of the equation may be represented by a triangle, where V (voltage) is placed on the top section, the I (current) is placed to the left section, and the R (resistance) is placed to the right. The divider between the top and bottom sections indicates division (hence the division bar).\n\n\n=== Resistive circuits ===\nResistors are circuit elements that impede the passage of electric charge in agreement with Ohm's law, and are designed to have a specific resistance value R. In schematic diagrams, a resistor is shown as a long rectangle or zig-zag symbol. An element (resistor or conductor) that behaves according to Ohm's law over some operating range is referred to as an ohmic device (or an ohmic resistor) because Ohm's law and a single value for the resistance suffice to describe the behavior of the device over that range.\nOhm's law holds for circuits containing only resistive elements (no capacitances or inductances) for all forms of driving voltage or current, regardless of whether the driving voltage or current is constant (DC) or time-varying such as AC.  At any instant of time Ohm's law is valid for such circuits.\nResistors which are in series or in parallel may be grouped together into a single \"equivalent resistance\" in order to apply Ohm's law in analyzing the circuit.\n\n\n=== Reactive circuits with time-varying signals ===\nWhen reactive elements such as capacitors, inductors, or transmission lines are involved in a circuit to which AC or time-varying voltage or current is applied, the relationship between voltage and current becomes the solution to a differential equation, so Ohm's law (as defined above) does not directly apply since that form contains only resistances having value R, not complex impedances which may contain capacitance (C) or inductance (L).\nEquations for time-invariant AC circuits take the same form as Ohm's law. However, the variables are generalized to complex numbers and the current and voltage waveforms are complex exponentials.In this approach, a voltage or current waveform takes the form Aest, where t is time, s is a complex parameter, and A is a complex scalar.  In any linear time-invariant system, all of the currents and voltages can be expressed with the same s parameter as the input to the system, allowing the time-varying complex exponential term to be canceled out and the system described algebraically in terms of the complex scalars in the current and voltage waveforms.\nThe complex generalization of resistance is impedance, usually denoted Z; it can be shown that for an inductor,\n\n  \n    \n      \n        Z\n        =\n        s\n        L\n      \n    \n    {\\displaystyle Z=sL}\n  and for a capacitor,\n\n  \n    \n      \n        Z\n        =\n        \n          \n            1\n            \n              s\n              C\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle Z={\\frac {1}{sC}}.}\n  We can now write,\n\n  \n    \n      \n        V\n        =\n        Z\n        \n        I\n      \n    \n    {\\displaystyle V=Z\\,I}\n  where V and I are the complex scalars in the voltage and current respectively and Z is the complex impedance.\nThis form of Ohm's law, with Z taking the place of R, generalizes the simpler form.  When Z is complex, only the real part is responsible for dissipating heat.\nIn a general AC circuit, Z varies strongly with the frequency parameter s, and so also will the relationship between voltage and current.\nFor the common case of a steady sinusoid, the s parameter is taken to be \n  \n    \n      \n        j\n        \u03c9\n      \n    \n    {\\displaystyle j\\omega }\n  , corresponding to a complex sinusoid \n  \n    \n      \n        A\n        \n          e\n          \n            \n              \n                 \n              \n            \n            j\n            \u03c9\n            t\n          \n        \n      \n    \n    {\\displaystyle Ae^{{\\mbox{ }}j\\omega t}}\n  .  The real parts of such complex current and voltage waveforms describe the actual sinusoidal currents and voltages in a circuit, which can be in different phases due to the different complex scalars.\n\n\n=== Linear approximations ===\n\nOhm's law is one of the basic equations used in the analysis of electrical circuits.  It applies to both metal conductors and circuit components (resistors) specifically made for this behaviour.  Both are ubiquitous in electrical engineering.  Materials and components that obey Ohm's law are described as \"ohmic\" which means they produce the same value for resistance (R = V/I) regardless of the value of V or I which is applied and whether the applied voltage or current is DC (direct current) of either positive or negative polarity or AC (alternating current).\nIn a true ohmic device, the same value of resistance will be calculated from R = V/I regardless of the value of the applied voltage V.  That is, the ratio of V/I is constant, and when current is plotted as a function of voltage the curve is linear (a straight line).  If voltage is forced to some value V, then that voltage V divided by measured current I will equal R.  Or if the current is forced to some value I, then the measured voltage V divided by that current I is also R.  Since the plot of I versus V is a straight line, then it is also true that for any set of two different voltages V1 and V2 applied across a given device of resistance R, producing currents I1 = V1/R and I2 = V2/R, that the ratio (V1 \u2212 V2)/(I1 \u2212 I2) is also a constant equal to R.  The operator \"delta\" (\u0394) is used to represent a difference in a quantity, so we can write \u0394V = V1 \u2212 V2 and \u0394I = I1 \u2212 I2.  Summarizing, for any truly ohmic device having resistance R, V/I = \u0394V/\u0394I = R for any applied voltage or current or for the difference between any set of applied voltages or currents.\n\nThere are, however, components of electrical circuits which do not obey Ohm's law; that is, their relationship between current and voltage (their I\u2013V curve) is nonlinear (or non-ohmic).  An example is the p\u2013n junction diode (curve at right).  As seen in the figure, the current does not increase linearly with applied voltage for a diode.  One can determine a value of current (I) for a given value of applied voltage (V) from the curve, but not from Ohm's law, since the value of \"resistance\" is not constant as a function of applied voltage.  Further, the current only increases significantly if the applied voltage is positive, not negative.  The ratio V/I for some point along the nonlinear curve is sometimes called the static, or chordal, or DC, resistance, but as seen in the figure the value of total V over total I varies depending on the particular point along the nonlinear curve which is chosen.  This means the \"DC resistance\" V/I at some point on the curve is not the same as what would be determined by applying an AC signal having peak amplitude \u0394V volts or \u0394I amps centered at that same point along the curve and measuring \u0394V/\u0394I. However, in some diode applications, the AC signal applied to the device is small and it is possible to analyze the circuit in terms of the dynamic, small-signal, or incremental resistance, defined as the one over the slope of the V\u2013I curve at the average value (DC operating point) of the voltage (that is, one over the derivative of current with respect to voltage).  For sufficiently small signals, the dynamic resistance allows the Ohm's law small signal resistance to be calculated as approximately one over the slope of a line drawn tangentially to the V\u2013I curve at the DC operating point.\n\n\n== Temperature effects ==\nOhm's law has sometimes been stated as, \"for a conductor in a given state, the electromotive force is proportional to the current produced.\"  That is, that the resistance, the ratio of the applied electromotive force (or voltage) to the current, \"does not vary with the current strength .\"  The qualifier \"in a given state\" is usually interpreted as meaning \"at a constant temperature,\" since the resistivity of materials is usually temperature dependent. Because the conduction of current is related to Joule heating of the conducting body, according to Joule's first law, the temperature of a conducting body may change when it carries a current.  The dependence of resistance on temperature therefore makes resistance depend upon the current in a typical experimental setup, making the law in this form difficult to directly verify.  Maxwell and others worked out several methods to test the law experimentally in 1876, controlling for heating effects.\n\n\n== Relation to heat conductions ==\n\nOhm's principle predicts the flow of electrical charge (i.e. current) in electrical conductors when subjected to the influence of voltage differences; Jean-Baptiste-Joseph Fourier's principle predicts the flow of heat in heat conductors when subjected to the influence of temperature differences.\nThe same equation describes both phenomena, the equation's variables taking on different meanings in the two cases. Specifically, solving a heat conduction (Fourier) problem with temperature (the driving \"force\") and flux of heat (the rate of flow of the driven \"quantity\", i.e. heat energy) variables also solves an analogous electrical conduction (Ohm) problem having electric potential (the driving \"force\") and electric current (the rate of flow of the driven \"quantity\", i.e. charge) variables.\nThe basis of Fourier's work was his clear conception and definition of thermal conductivity. He assumed that, all else being the same, the flux of heat is strictly proportional to the gradient of temperature. Although undoubtedly true for small temperature gradients, strictly proportional behavior will be lost when real materials (e.g. ones having a thermal conductivity that is a function of temperature) are subjected to large temperature gradients.\nA similar assumption is made in the statement of Ohm's law: other things being alike, the strength of the current at each point is proportional to the gradient of electric potential. The accuracy of the assumption that flow is proportional to the gradient is more readily tested, using modern measurement methods, for the electrical case than for the heat case.\n\n\n== Other versions ==\nOhm's law, in the form above, is an extremely useful equation in the field of electrical/electronic engineering because it describes how voltage, current and resistance are interrelated on a \"macroscopic\" level, that is, commonly, as circuit elements in an electrical circuit. Physicists who study the electrical properties of matter at the microscopic level use a closely related and more general vector equation, sometimes also referred to as Ohm's law, having variables that are closely related to the V, I, and R scalar variables of Ohm's law, but which are each functions of position within the conductor.  Physicists often use this continuum form of Ohm's Law:\n\n  \n    \n      \n        \n          E\n        \n        =\n        \u03c1\n        \n          J\n        \n      \n    \n    {\\displaystyle \\mathbf {E} =\\rho \\mathbf {J} }\n  where \"E\" is the electric field vector with units of volts per meter (analogous to \"V\" of Ohm's law which has units of volts), \"J\" is the current density vector with units of amperes per unit area (analogous to \"I\" of Ohm's law which has units of amperes), and \"\u03c1\" (Greek \"rho\") is the resistivity with units of ohm\u00b7meters (analogous to \"R\" of Ohm's law which has units of ohms).  The above equation is sometimes written as J = \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n  E where \"\u03c3\" (Greek \"sigma\") is the conductivity which is the reciprocal of \u03c1.\n\nThe voltage between two points is defined as:\n\n  \n    \n      \n        \n          \u0394\n          V\n        \n        =\n        \u2212\n        \u222b\n        \n          \n            E\n          \n          \u22c5\n          d\n          \n            l\n          \n        \n      \n    \n    {\\displaystyle {\\Delta V}=-\\int {\\mathbf {E} \\cdot d\\mathbf {l} }}\n  with \n  \n    \n      \n        d\n        \n          l\n        \n      \n    \n    {\\displaystyle d\\mathbf {l} }\n   the element of path along the integration of electric field vector E. If the applied E field is uniform and oriented along the length of the conductor as shown in the figure, then defining the voltage V in the usual convention of being opposite in direction to the field (see figure), and with the understanding that the voltage V is measured differentially across the length of the conductor allowing us to drop the \u0394 symbol, the above vector equation reduces to the scalar equation:\n\n  \n    \n      \n        V\n        =\n        \n          E\n        \n        \n          l\n        \n         \n         \n        \n          or\n        \n         \n         \n        E\n        =\n        \n          \n            V\n            l\n          \n        \n        .\n      \n    \n    {\\displaystyle V={E}{l}\\ \\ {\\text{or}}\\ \\ E={\\frac {V}{l}}.}\n  Since the E field is uniform in the direction of wire length, for a conductor having uniformly consistent resistivity \u03c1, the current density J will also be uniform in any cross-sectional area and oriented in the direction of wire length, so we may write:\n\n  \n    \n      \n        J\n        =\n        \n          \n            I\n            a\n          \n        \n        .\n      \n    \n    {\\displaystyle J={\\frac {I}{a}}.}\n  Substituting the above 2 results (for E and J respectively) into the continuum form shown at the beginning of this section:\n\n  \n    \n      \n        \n          \n            V\n            l\n          \n        \n        =\n        \n          \n            I\n            a\n          \n        \n        \u03c1\n        \n        \n          or\n        \n        \n        V\n        =\n        I\n        \u03c1\n        \n          \n            l\n            a\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {V}{l}}={\\frac {I}{a}}\\rho \\qquad {\\text{or}}\\qquad V=I\\rho {\\frac {l}{a}}.}\n  The electrical resistance of a uniform conductor is given in terms of resistivity by:\n\n  \n    \n      \n        \n          R\n        \n        =\n        \u03c1\n        \n          \n            l\n            a\n          \n        \n      \n    \n    {\\displaystyle {R}=\\rho {\\frac {l}{a}}}\n  where l is the length of the conductor in SI units of meters, a is the cross-sectional area (for a round wire a = \u03c0r2 if r is radius) in units of meters squared, and \u03c1 is the resistivity in units of ohm\u00b7meters.\nAfter substitution of R from the above equation into the equation preceding it, the continuum form of Ohm's law for a uniform field (and uniform current density) oriented along the length of the conductor reduces to the more familiar form:\n\n  \n    \n      \n        \n          V\n        \n        =\n        \n          I\n        \n        \n          R\n        \n        .\n         \n      \n    \n    {\\displaystyle {V}={I}{R}.\\ }\n  A perfect crystal lattice, with low enough thermal motion and no deviations from periodic structure, would have no resistivity, but a real metal has crystallographic defects, impurities, multiple isotopes, and thermal motion of the atoms. Electrons scatter from all of these, resulting in resistance to their flow.\nThe more complex generalized forms of Ohm's law are important to condensed matter physics, which studies the properties of matter and, in particular, its electronic structure. In broad terms, they fall under the topic of constitutive equations and the theory of transport coefficients.\n\n\n=== Magnetic effects ===\nIf an external B-field is present and the conductor is not at rest but moving at velocity v, then an extra term must be added to account for the current induced by the Lorentz force on the charge carriers.\n\n  \n    \n      \n        \n          J\n        \n        =\n        \u03c3\n        (\n        \n          E\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {J} =\\sigma (\\mathbf {E} +\\mathbf {v} \\times \\mathbf {B} )}\n  In the rest frame of the moving conductor this term drops out because v= 0. There is no contradiction because the electric field in the rest frame differs from the E-field in the lab frame: E\u2032  = E + v\u00d7B.\nElectric and magnetic fields are relative, see Lorentz transformation.\nIf the current J is alternating because the applied voltage or E-field varies in time, then reactance must be added to resistance to account for self-inductance, see electrical impedance. The reactance may be strong if the frequency is high or the conductor is coiled.\n\n\n=== Conductive fluids ===\nIn a conductive fluid, such as a plasma, there is a similar effect. Consider a fluid moving with the velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   in a magnetic field \n  \n    \n      \n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {B} }\n  . The relative motion induces an electric field \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\displaystyle \\mathbf {E} }\n   which exerts electric force on the charged particles giving rise to an electric current \n  \n    \n      \n        \n          J\n        \n      \n    \n    {\\displaystyle \\mathbf {J} }\n  . The equation of motion for the electron gas, with a number density \n  \n    \n      \n        \n          n\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle n_{e}}\n  , is written as\n\n  \n    \n      \n        \n          m\n          \n            e\n          \n        \n        \n          n\n          \n            e\n          \n        \n        \n          \n            \n              d\n              \n                \n                  v\n                \n                \n                  e\n                \n              \n            \n            \n              d\n              t\n            \n          \n        \n        =\n        \u2212\n        \n          n\n          \n            e\n          \n        \n        e\n        \n          E\n        \n        +\n        \n          n\n          \n            e\n          \n        \n        \n          m\n          \n            e\n          \n        \n        \u03bd\n        (\n        \n          \n            v\n          \n          \n            i\n          \n        \n        \u2212\n        \n          \n            v\n          \n          \n            e\n          \n        \n        )\n        \u2212\n        e\n        \n          n\n          \n            e\n          \n        \n        \n          \n            v\n          \n          \n            e\n          \n        \n        \u00d7\n        \n          B\n        \n        ,\n      \n    \n    {\\displaystyle m_{e}n_{e}{d\\mathbf {v} _{e} \\over dt}=-n_{e}e\\mathbf {E} +n_{e}m_{e}\\nu (\\mathbf {v} _{i}-\\mathbf {v} _{e})-en_{e}\\mathbf {v} _{e}\\times \\mathbf {B} ,}\n  where \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  , \n  \n    \n      \n        \n          m\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle m_{e}}\n   and \n  \n    \n      \n        \n          \n            v\n          \n          \n            e\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{e}}\n   are the charge, mass and velocity of the electrons, respectively. Also, \n  \n    \n      \n        \u03bd\n      \n    \n    {\\displaystyle \\nu }\n   is the frequency of collisions of the electrons with ions which have a velocity field \n  \n    \n      \n        \n          \n            v\n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{i}}\n  . Since, the electron has a very small mass compared with that of ions, we can ignore the left hand side of the above equation to write\n\n  \n    \n      \n        \u03c3\n        (\n        \n          E\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        )\n        =\n        \n          J\n        \n        ,\n      \n    \n    {\\displaystyle \\sigma (\\mathbf {E} +\\mathbf {v} \\times \\mathbf {B} )=\\mathbf {J} ,}\n  where we have used the definition of the current density, and also put \n  \n    \n      \n        \u03c3\n        =\n        \n          \n            \n              \n                n\n                \n                  e\n                \n              \n              \n                e\n                \n                  2\n                \n              \n            \n            \n              \u03bd\n              \n                m\n                \n                  e\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma ={n_{e}e^{2} \\over \\nu m_{e}}}\n   which is the electrical conductivity. This equation can also be equivalently written as\n\n  \n    \n      \n        \n          E\n        \n        +\n        \n          v\n        \n        \u00d7\n        \n          B\n        \n        =\n        \u03c1\n        \n          J\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {E} +\\mathbf {v} \\times \\mathbf {B} =\\rho \\mathbf {J} ,}\n  where \n  \n    \n      \n        \u03c1\n        =\n        \n          \u03c3\n          \n            \u2212\n            1\n          \n        \n      \n    \n    {\\displaystyle \\rho =\\sigma ^{-1}}\n   is the electrical resistivity. It is also common to write \n  \n    \n      \n        \u03b7\n      \n    \n    {\\displaystyle \\eta }\n   instead of \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   which can be confusing since it is the same notation used for the magnetic diffusivity defined as \n  \n    \n      \n        \u03b7\n        =\n        1\n        \n          /\n        \n        \n          \u03bc\n          \n            0\n          \n        \n        \u03c3\n      \n    \n    {\\displaystyle \\eta =1/\\mu _{0}\\sigma }\n  .\n\n\n== See also ==\nFick's law of diffusion\nHopkinson's law (\"Ohm's law for magnetics\")\nMaximum power transfer theorem\nNorton's theorem\nSheet resistance\nSuperposition theorem\nThermal noise\nTh\u00e9venin's theorem\n\n\n== References ==\n\n\n== External links and further reading ==\n\nOhm's Law chapter from Lessons In Electric Circuits Vol 1 DC book and series.\nJohn C. Shedd and Mayo D. Hershey,\"The History of Ohm's Law\",  Popular Science, December 1913, pp. 599\u2013614, Bonnier Corporation ISSN 0161-7370, gives the history of Ohm's investigations, prior work, Ohm's false equation in the first paper, illustration of Ohm's experimental apparatus.\nSchagrin, Morton L. (1963). \"Resistance to Ohm's Law\". American Journal of Physics. 31 (7): 536\u2013547. Bibcode:1963AmJPh..31..536S. doi:10.1119/1.1969620. S2CID 120421759. Explores the conceptual change underlying Ohm's experimental work.\nKenneth L. Caneva, \"Ohm, Georg Simon.\" Complete Dictionary of Scientific Biography. 2008\ns:Scientific Memoirs/2/The Galvanic Circuit investigated Mathematically, a translation of Ohm's original paper.", "Motion_(physics)": "In physics, motion is the phenomenon in which an object changes its position with respect to time. Motion is mathematically described in terms of displacement, distance, velocity, acceleration, speed and frame of reference to an observer and measuring the change in position of the body relative to that frame with change in time. The branch of physics describing the motion of objects without reference to its cause is called kinematics, while the branch studying forces and their effect on motion is called dynamics.\nIf an object is not moving relative to a given frame of reference, the object is said to be at rest, motionless, immobile, stationary, or to have a constant or time-invariant position with reference to its surroundings. Modern physics holds that, as there is no absolute frame of reference, Newton's concept of absolute motion cannot be determined. As such, everything in the universe can be considered to be in motion.:\u200a20\u201321\u200aMotion applies to various physical systems: objects, bodies, matter particles, matter fields, radiation, radiation fields, radiation particles, curvature, and space-time. One can also speak on the motion of images, shapes, and boundaries. In general, the term motion signifies a continuous change in the positions or configuration of a physical system in space. For example, one can talk about the motion of a wave or the motion of a quantum particle, where the configuration consists of probabilities of the wave or particle occupying specific positions.\n\n\n== Equations of motion ==\n\n\n== Laws of motion ==\nIn physics, the motion of massive bodies is described through two related sets of laws of mechanics. Classical mechanics for super atomic (larger than an atom) objects (such as cars, projectiles, planets, cells, and humans) and quantum mechanics for atomic and sub-atomic objects (such as helium, protons, and electrons). Historically, Newton and Euler formulated three laws of classical mechanics:\n\n\n=== Classical mechanics ===\n\nClassical mechanics is used for describing the motion of macroscopic objects moving at speeds significantly slower than the speed of light, from projectiles to parts of machinery, as well as astronomical objects, such as spacecraft, planets, stars, and galaxies. It produces very accurate results within these domains and is one of the oldest and largest scientific descriptions in science, engineering, and technology.\nClassical mechanics is fundamentally based on Newton's laws of motion. These laws describe the relationship between the forces acting on a body and the motion of that body. They were first compiled by Sir Isaac Newton in his work Philosophi\u00e6 Naturalis Principia Mathematica, which was first published on July 5, 1687. Newton's three laws are:\n\nA body at rest will remain at rest, and a body in motion will remain in motion unless it is acted upon by an external force. (This is known as the law of inertia.)\nForce (\n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n  ) is equal to the change in momentum per change in time (\n  \n    \n      \n        \n          \n            \n              \u0394\n              m\n              \n                \n                  \n                    v\n                    \u2192\n                  \n                \n              \n            \n            \n              \u0394\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\Delta m{\\vec {v}}}{\\Delta t}}}\n  ). For a constant mass, force equals mass times acceleration (\n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        =\n        m\n        \n          \n            \n              a\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}=m{\\vec {a}}}\n   ).\nFor every action, there is an equal and opposite reaction. (In other words, whenever one body exerts a force \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   onto a second body, (in some cases, which is standing still) the second body exerts the force \n  \n    \n      \n        \u2212\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle -{\\vec {F}}}\n   back onto the first body. \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   and \n  \n    \n      \n        \u2212\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle -{\\vec {F}}}\n   are equal in magnitude and opposite in direction. So, the body which exerts \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   will be pushed backward.)Newton's three laws of motion were the first to accurately provide a mathematical model for understanding orbiting bodies in outer space. This explanation unified the motion of celestial bodies and the motion of objects on Earth.\n\n\n=== Relativistic mechanics ===\nModern kinematics developed with study of electromagnetism and refers all velocities \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   to their ratio to speed of light \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  . Velocity is then interpreted as rapidity, the hyperbolic angle \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n   for which the hyperbolic tangent function \n  \n    \n      \n        tanh\n        \u2061\n        \u03c6\n        =\n        v\n        \u00f7\n        c\n      \n    \n    {\\displaystyle \\tanh \\varphi =v\\div c}\n  . Acceleration, the change of velocity over time, then changes rapidity according to Lorentz transformations. This part of mechanics is special relativity. Efforts to incorporate gravity into relativistic mechanics were made by W. K. Clifford and Albert Einstein. The development used differential geometry to describe a curved universe with gravity; the study is called general relativity.\n\n\n=== Quantum mechanics ===\nQuantum mechanics is a set of principles describing physical reality at the atomic level of matter (molecules and atoms) and the subatomic particles (electrons, protons, neutrons, and even smaller elementary particles such as quarks). These descriptions include the simultaneous wave-like and particle-like behavior of both matter and radiation energy as described in the wave\u2013particle duality.In classical mechanics, accurate measurements and predictions of the state of objects can be calculated, such as location and velocity. In quantum mechanics, due to the Heisenberg uncertainty principle, the complete state of a subatomic particle, such as its location and velocity, cannot be simultaneously determined.In addition to describing the motion of atomic level phenomena, quantum mechanics is useful in understanding some large-scale phenomena such as superfluidity, superconductivity, and biological systems, including the function of smell receptors and the structures of protein.\n\n\n== Orders of magnitude ==\nHumans, like all known things in the universe, are in constant motion;:\u200a8\u20139\u200a however, aside from obvious movements of the various external body parts and locomotion, humans are in motion in a variety of ways which are more difficult to perceive.  Many of these \"imperceptible motions\" are only perceivable with the help of special tools and careful observation. The larger scales of imperceptible motions are difficult for humans to perceive for two reasons: Newton's laws of motion (particularly the third) which prevents the feeling of motion on a mass to which the observer is connected, and the lack of an obvious frame of reference which would allow individuals to easily see that they are moving. The smaller scales of these motions are too small to be detected conventionally with human senses.\n\n\n=== Universe ===\nSpacetime (the fabric of the universe) is expanding, meaning everything in the universe is stretching, like a rubber band. This motion is the most obscure as it is not physical motion, but rather a change in the very nature of the universe. The primary source of verification of this expansion was provided by Edwin Hubble who demonstrated that all galaxies and distant astronomical objects were moving away from Earth, known as Hubble's law, predicted by a universal expansion.\n\n\n=== Galaxy ===\nThe Milky Way Galaxy is moving through space and many astronomers believe the velocity of this motion to be approximately 600 kilometres per second (1,340,000 mph) relative to the observed locations of other nearby galaxies. Another reference frame is provided by the Cosmic microwave background. This frame of reference indicates that the Milky Way is moving at around 582 kilometres per second (1,300,000 mph).\n\n\n=== Sun and Solar System ===\n\nThe Milky Way is rotating around its dense Galactic Center, thus the Sun is moving in a circle within the galaxy's gravity. Away from the central bulge, or outer rim, the typical stellar velocity is between 210 and 240 kilometres per second (470,000 and 540,000 mph). All planets and their moons move with the Sun. Thus, the Solar System is in motion.\n\n\n=== Earth ===\nThe Earth is rotating or spinning around its axis. This is evidenced by day and night, at the equator the earth has an eastward velocity of 0.4651 kilometres per second (1,040 mph). The Earth is also orbiting around the Sun in an orbital revolution. A complete orbit around the sun takes one year, or about 365 days; it averages a speed of about 30 kilometres per second (67,000 mph).\n\n\n=== Continents ===\nThe Theory of Plate tectonics tells us that the continents are drifting on convection currents within the mantle, causing them to move across the surface of the planet at the slow speed of approximately 2.54 centimetres (1 in) per year. However, the velocities of plates range widely. The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of 75 millimetres (3.0 in) per year and the Pacific Plate moving 52\u201369 millimetres (2.0\u20132.7 in) per year. At the other extreme, the slowest-moving plate is the Eurasian Plate, progressing at a typical rate of about 21 millimetres (0.83 in) per year.\n\n\n=== Internal body ===\nThe human heart is constantly contracting to move blood throughout the body. Through larger veins and arteries in the body, blood has been found to travel at approximately 0.33 m/s. Though considerable variation exists, and peak flows in the venae cavae have been found between 0.1 and 0.45 metres per second (0.33 and 1.48 ft/s). additionally, the smooth muscles of hollow internal organs are moving. The most familiar would be the occurrence of peristalsis which is where digested food is forced throughout the digestive tract. Though different foods travel through the body at different rates, an average speed through the human small intestine is 3.48 kilometres per hour (2.16 mph). The human lymphatic system is also constantly causing movements of excess fluids, lipids, and immune system related products around the body. The lymph fluid has been found to move through a lymph capillary of the skin at approximately 0.0000097 m/s.\n\n\n=== Cells ===\nThe cells of the human body have many structures and organelles which move throughout them. Cytoplasmic streaming is a way in which cells move molecular substances throughout the cytoplasm, various motor proteins work as molecular motors within a cell and move along the surface of various cellular substrates such as microtubules, and motor proteins are typically powered by the hydrolysis of adenosine triphosphate (ATP), and convert chemical energy into mechanical work. Vesicles propelled by motor proteins have been found to have a velocity of approximately 0.00000152 m/s.\n\n\n=== Particles ===\nAccording to the laws of thermodynamics, all particles of matter are in constant random motion as long as the temperature is above absolute zero. Thus the molecules and atoms which make up the human body are vibrating, colliding, and moving. This motion can be detected as temperature; higher temperatures, which represent greater kinetic energy in the particles, feel warm to humans who sense the thermal energy transferring from the object being touched to their nerves. Similarly, when lower temperature objects are touched, the senses perceive the transfer of heat away from the body as a feeling of cold.\n\n\n=== Subatomic particles ===\nWithin the standard atomic orbital model, electrons exist in a region around the nucleus of each atom.  This region is called the electron cloud.  According to Bohr's model of the atom, electrons have a high velocity, and the larger the nucleus they are orbiting the faster they would need to move.  If electrons were to move about the electron cloud in strict paths the same way planets orbit the sun, then electrons would be required to do so at speeds which would far exceed the speed of light.  However, there is no reason that one must confine oneself to this strict conceptualization (that electrons move in paths the same way macroscopic objects do), rather one can conceptualize electrons to be 'particles' that capriciously exist within the bounds of the electron cloud. Inside the atomic nucleus, the protons and neutrons are also probably moving around due to the electrical repulsion of the protons and the presence of angular momentum of both particles.\n\n\n== Light ==\n\nLight moves at a speed of 299,792,458 m/s, or 299,792.458 kilometres per second (186,282.397 mi/s), in a vacuum. The speed of light in vacuum (or \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  ) is also the speed of all massless particles and associated fields in a vacuum, and it is the upper limit on the speed at which energy, matter, information or causation can travel. The speed of light in vacuum is thus the upper limit for speed for all physical systems.\nIn addition, the speed of light is an invariant quantity: it has the same value, irrespective of the position or speed of the observer. This property makes the speed of light c a natural measurement unit for speed and a fundamental constant of nature.\nIn 2011, the speed of light was redefined alongside all seven SI base units using what it calls \"the explicit-constant formulation\", where each \"unit is defined indirectly by specifying explicitly an exact value for a well-recognized fundamental constant\", as was done for the speed of light. A new, but completely equivalent, wording of the metre's definition was proposed: \"The metre, symbol m, is the unit of length; its magnitude is set by fixing the numerical value of the speed of light in vacuum to be equal to exactly 299792458 when it is expressed in the SI unit m s\u22121.\"  This implicit change to the speed of light was one of the changes that was incorporated in the 2019 redefinition of the SI base units, also termed the New SI.\n\n\n=== Superluminal motion ===\nSome motion appears to an observer to exceed the speed of light. Bursts of energy moving out along the relativistic jets emitted from these objects can have a proper motion that appears greater than the speed of light. All of these sources are thought to contain a black hole, responsible for the ejection of mass at high velocities. Light echoes can also produce apparent superluminal motion. This occurs owing to how motion is often calculated at long distances; oftentimes calculations fail to account for the fact that the speed of light is finite. When measuring the movement of distant objects across the sky, there is a large time delay between what has been observed and what has occurred, due to the large distance the light from the distant object has to travel to reach us. The error in the above naive calculation comes from the fact that when an object has a component of velocity directed towards the Earth, as the object moves closer to the Earth that time delay becomes smaller. This means that the apparent speed as calculated above is greater than the actual speed. Correspondingly, if the object is moving away from the Earth, the above calculation underestimates the actual speed.\n\n\n== Types of motion ==\nSimple harmonic motion \u2013 motion in which the body oscillates in such a way that the restoring force acting on it is directly proportional to the body's displacement. Mathematically Force is directly proportional to the negative of displacement. Negative sign signifies the restoring nature of the force. (e.g., that of a pendulum).\nLinear motion \u2013 motion which follows a straight linear path, and whose displacement is exactly the same as its trajectory. [Also known as rectilinear motion]\nReciprocal motion\nBrownian motion (i.e. the random movement of particles)\nCircular motion\nRotatory motion \u2013 a motion about a fixed point. (e.g. Ferris wheel).\nCurvilinear motion \u2013 It is defined as the motion along a curved path that may be planar or in three dimensions.\nRolling motion \u2013 (as of the wheel of a bicycle)\nOscillatory \u2013 (swinging from side to side)\nVibratory motion\nCombination (or simultaneous) motions \u2013 Combination of two or more above listed motions\nProjectile motion \u2013  uniform horizontal motion + vertical accelerated motion\n\n\n== Fundamental motions ==\nLinear motion\nCircular motion\nOscillation\nWave\nRelative motion\nFundamental motions\n\n\n== See also ==\nDeflection (physics) \u2013 change in an object's velocity as a consequence of collision with a surfacePages displaying wikidata descriptions as a fallback\nKinematics \u2013 Branch of physics describing the motion of objects without considering forces\nSimple machines \u2013 Mechanical device that changes the direction or magnitude of a forcePages displaying short descriptions of redirect targets\nKinematic chain \u2013 Mathematical model for a mechanical system\nPower \u2013 Amount of energy transferred or converted per unit time\nMachine \u2013 Powered mechanical devicePages displaying short descriptions of redirect targets\nMicroswimmer \u2013 artificial or natural microorganisms that can move in a fluid environmentPages displaying wikidata descriptions as a fallback\nMotion (geometry) \u2013 Transformation of a geometric space preserving structure\nMotion capture \u2013 Process of recording the movement of objects or people\nDisplacement \u2013 Vector relating the initial and the final positions of a moving pointPages displaying short descriptions of redirect targets\nTranslatory motion \u2013 Type of motion in which the path of the moving object is a straight linePages displaying short descriptions of redirect targets\n\n\n== References ==\n\n\n== External links ==\n\nFeynman's lecture on motion\n Media related to Motion at Wikimedia Commons", "Fatigue_(material)": "In materials science, fatigue is the initiation and propagation of cracks in a material due to cyclic loading. Once a fatigue crack has initiated, it grows a small amount with each loading cycle, typically producing striations on some parts of the fracture surface. The crack will continue to grow until it reaches a critical size, which occurs when the stress intensity factor of the crack exceeds the fracture toughness of the material, producing rapid propagation and typically complete fracture of the structure.\nFatigue has traditionally been associated with the failure of metal components which led to the term metal fatigue. In the nineteenth century, the sudden failing of metal railway axles was thought to be caused by the metal crystallising because of the brittle appearance of the fracture surface, but this has since been disproved. Most materials, such as composites, plastics and ceramics, seem to experience some sort of fatigue-related failure.To aid in predicting the fatigue life of a component, fatigue tests are carried out using coupons to measure the rate of crack growth by applying constant amplitude cyclic loading and averaging the measured growth of a crack over thousands of cycles. However, there are also a number of special cases that need to be considered where the rate of crack growth is significantly different compared to that obtained from constant amplitude testing. Such as the reduced rate of growth that occurs for small loads near the threshold or after the application of an overload; and the increased rate of crack growth associated with short cracks or after the application of an underload.If the loads are above a certain threshold, microscopic cracks will begin to initiate at stress concentrations such as holes, persistent slip bands (PSBs), composite interfaces or grain boundaries in metals. The stress values that cause fatigue damage are typically much less than the yield strength of the material.\n\n\n== Stages of fatigue ==\nHistorically, fatigue has been separated into regions of high cycle fatigue that require more than 104 cycles to failure where stress is low and primarily elastic and low cycle fatigue where there is significant plasticity. Experiments have shown that low cycle fatigue is also crack growth.Fatigue failures, both for high and low cycles, all follow the same basic steps: crack initiation, crack growth stages I and II, and finally ultimate failure. To begin the process, cracks must nucleate within a material. This process can occur either at stress risers in metallic samples or at areas with a high void density in polymer samples. These cracks propagate slowly at first during stage I crack growth along crystallographic planes, where shear stresses are highest. Once the cracks reach a critical size they propagate quickly during stage II crack growth in a direction perpendicular to the applied force. These cracks can eventually lead to the ultimate failure of the material, often in a brittle catastrophic fashion.\n\n\n=== Crack initiation ===\nThe formation of initial cracks preceding fatigue failure is a separate process consisting of four discrete steps in metallic samples. The material will develop cell structures and harden in response to the applied load. This causes the amplitude of the applied stress to increase given the new restraints on strain. These newly formed cell structures will eventually break down with the formation of persistent slip bands (PSBs). Slip in the material is localized at these PSBs, and the exaggerated slip can now serve as a stress concentrator for a crack to form. Nucleation and growth of a crack to a detectable size accounts for most of the cracking process. It is for this reason that cyclic fatigue failures seem to occur so suddenly where the bulk of the changes in the material are not visible without destructive testing. Even in normally ductile materials, fatigue failures will resemble sudden brittle failures.\nPSB-induced slip planes result in intrusions and extrusions along the surface of a material, often occurring in pairs. This slip is not a microstructural change within the material, but rather a propagation of dislocations within the material. Instead of a smooth interface, the intrusions and extrusions will cause the surface of the material to resemble the edge of a deck of cards, where not all cards are perfectly aligned. Slip-induced intrusions and extrusions create extremely fine surface structures on the material. With surface structure size inversely related to stress concentration factors, PSB-induced surface slip can cause fractures to initiate.\nThese steps can also be bypassed entirely if the cracks form at a pre-existing stress concentrator such as from an inclusion in the material or from a geometric stress concentrator caused by a sharp internal corner or fillet.\n\n\n=== Crack growth ===\n\nMost of the fatigue life is generally consumed in the crack growth phase. The rate of growth is primarily driven by the range of cyclic loading although additional factors such as mean stress, environment, overloads and underloads can also affect the rate of growth. Crack growth may stop if the loads are small enough to fall below a critical threshold.\nFatigue cracks can grow from material or manufacturing defects from as small as 10 \u03bcm.\nWhen the rate of growth becomes large enough, fatigue striations can be seen on the fracture surface. Striations mark the position of the crack tip and the width of each striation represents the growth from one loading cycle. Striations are a result of plasticity at the crack tip.\nWhen the stress intensity exceeds a critical value known as the fracture toughness, unsustainable fast fracture will occur, usually by a process of microvoid coalescence. Prior to final fracture, the fracture surface may contain a mixture of areas of fatigue and fast fracture.\n\n\n==== Acceleration and retardation ====\nThe following effects change the rate of growth:\nMean stress effect: Higher mean stress increases the rate of crack growth.\nEnvironment: Increased moisture increases the rate of crack growth. In the case of aluminium, cracks generally grow from the surface, where water vapour from the atmosphere is able to reach the tip of the crack and dissociate into atomic hydrogen which causes hydrogen embrittlement. Cracks growing internally are isolated from the atmosphere and grow in a vacuum where the rate of growth is typically an order of magnitude slower than a surface crack.\nShort crack effect: In 1975, Pearson observed that short cracks grow faster than expected. Possible reasons for the short crack effect include the presence of the T-stress, the tri-axial stress state at the crack tip, the lack of crack closure associated with short cracks and the large plastic zone in comparison to the crack length. In addition, long cracks typically experience a threshold which short cracks do not have. There are a number of criteria for short cracks:cracks are typically smaller than 1 mm,\ncracks are smaller than the material microstructure size such as the grain size, or\ncrack length is small compared to the plastic zone.\nUnderloads: Small numbers of underloads increase the rate of growth and may counteract the effect of overloads.\nOverloads: Initially overloads (> 1.5 the maximum load in a sequence) lead to a small increase in the rate of growth followed by a long reduction in the rate of growth.\n\n\n== Characteristics of fatigue ==\nIn metal alloys, and for the simplifying case when there are no macroscopic or microscopic discontinuities, the process starts with dislocation movements at the microscopic level, which eventually form persistent slip bands that become the nucleus of short cracks.\nMacroscopic and microscopic discontinuities (at the crystalline grain scale) as well as component design features which cause stress concentrations (holes, keyways, sharp changes of load direction etc.) are common locations at which the fatigue process begins.\nFatigue is a process that has a degree of randomness (stochastic), often showing considerable scatter even in seemingly identical samples in well controlled environments.\nFatigue is usually associated with tensile stresses but fatigue cracks have been reported due to compressive loads.\nThe greater the applied stress range, the shorter the life.\nFatigue life scatter tends to increase for longer fatigue lives.\nDamage is irreversible. Materials do not recover when rested.\nFatigue life is influenced by a variety of factors, such as temperature, surface finish, metallurgical microstructure, presence of oxidizing or inert chemicals, residual stresses, scuffing contact (fretting), etc.\nSome materials (e.g., some steel and titanium alloys) exhibit a theoretical fatigue limit below which continued loading does not lead to fatigue failure.\nHigh cycle fatigue strength (about 104 to 108 cycles) can be described by stress-based parameters. A load-controlled servo-hydraulic test rig is commonly used in these tests, with frequencies of around 20\u201350 Hz. Other sorts of machines\u2014like resonant magnetic machines\u2014can also be used, to achieve frequencies up to 250 Hz.\nLow-cycle fatigue (loading that typically causes failure in less than 104 cycles) is associated with localized plastic behavior in metals; thus, a strain-based parameter should be used for fatigue life prediction in metals. Testing is conducted with constant strain amplitudes typically at 0.01\u20135 Hz.\n\n\n== Timeline of research history ==\n\n1837: Wilhelm Albert publishes the first article on fatigue. He devised a test machine for conveyor chains used in the Clausthal mines.\n1839: Jean-Victor Poncelet describes metals as being 'tired' in his lectures at the military school at Metz.\n1842: William John Macquorn Rankine recognises the importance of stress concentrations in his investigation of railroad axle failures. The Versailles train wreck was caused by fatigue failure of a locomotive axle.\n1843: Joseph Glynn reports on the fatigue of an axle on a locomotive tender. He identifies the keyway as the crack origin.\n1848: The Railway Inspectorate reports one of the first tyre failures, probably from a rivet hole in tread of railway carriage wheel. It was likely a fatigue failure.\n1849: Eaton Hodgkinson is granted a \"small sum of money\" to report to the UK Parliament on his work in \"ascertaining by direct experiment, the effects of continued changes of load upon iron structures and to what extent they could be loaded without danger to their ultimate security\".\n1854: F. Braithwaite reports on common service fatigue failures and coins the term fatigue.\n1860: Systematic fatigue testing undertaken by Sir William Fairbairn and August W\u00f6hler.\n1870: A. W\u00f6hler summarises his work on railroad axles. He concludes that cyclic stress range is more important than peak stress and introduces the concept of endurance limit.\n1903: Sir James Alfred Ewing demonstrates the origin of fatigue failure in microscopic cracks.\n1910: O. H. Basquin proposes a log-log relationship for S-N curves, using W\u00f6hler's test data.\n1940: Sidney M. Cadwell publishes first rigorous study of fatigue in rubber.\n1945: A. M. Miner popularises Palmgren's (1924) linear damage hypothesis as a practical design tool.\n1952: W. Weibull An S-N curve model.\n1954: The world's first commercial jetliner, the de Havilland Comet, suffers disaster as three planes break up in mid-air, causing de Havilland and all other manufacturers to redesign high altitude aircraft and in particular replace square apertures like windows with oval ones.\n1954: L. F. Coffin and S. S. Manson explain fatigue crack-growth in terms of plastic strain in the tip of cracks.\n1961: P. C. Paris proposes methods for predicting the rate of growth of individual fatigue cracks in the face of initial scepticism and popular defence of Miner's phenomenological approach.\n1968: Tatsuo Endo and M. Matsuishi devise the rainflow-counting algorithm and enable the reliable application of Miner's rule to random loadings.\n1970: W. Elber elucidates the mechanisms and importance of crack closure in slowing the growth of a fatigue crack due to the wedging effect of plastic deformation left behind the tip of the crack.\n1973: M. W. Brown and K. J. Miller observe that fatigue life under multiaxial conditions is governed by the experience of the plane receiving the most damage, and that both tension and shear loads on the critical plane must be considered.\n\n\n== Predicting fatigue life ==\n\nThe American Society for Testing and Materials defines fatigue life, Nf, as the number of stress cycles of a specified character that a specimen sustains before failure of a specified nature occurs. For some materials, notably steel and titanium, there is a theoretical value for stress amplitude below which the material will not fail for any number of cycles, called a fatigue limit or endurance limit. However, in practice, several bodies of work done at greater numbers of cycles suggest that fatigue limits do not exist for any metals.Engineers have used a number of methods to determine the fatigue life of a material:\nthe stress-life method,\nthe strain-life method,\nthe crack growth method and\nprobabilistic methods, which can be based on either life or crack growth methods.Whether using stress/strain-life approach or using crack growth approach, complex or variable amplitude loading is reduced to a series of fatigue equivalent simple cyclic loadings using a technique such as the rainflow-counting algorithm.\n\n\n=== Stress-life and strain-life methods ===\nA mechanical part is often exposed to a complex, often random, sequence of loads, large and small. In order to assess the safe life of such a part using the fatigue damage or stress/strain-life methods the following series of steps is usually performed:\n\nComplex loading is reduced to a series of simple cyclic loadings using a technique such as rainflow analysis;\nA histogram of cyclic stress is created from the rainflow analysis to form a fatigue damage spectrum;\nFor each stress level, the degree of cumulative damage is calculated from the S-N curve; and\nThe effect of the individual contributions are combined using an algorithm such as Miner's rule.Since S-N curves are typically generated for uniaxial loading, some equivalence rule is needed whenever the loading is multiaxial. For simple, proportional loading histories (lateral load in a constant ratio with the axial), Sines rule may be applied. For more complex situations, such as non-proportional loading, critical plane analysis must be applied.\n\n\n==== Miner's rule ====\nIn 1945, M.A. Miner popularised a rule that had first been proposed by A. Palmgren in 1924. The rule, variously called Miner's rule or the Palmgren-Miner linear damage hypothesis, states that where there are k different stress magnitudes in a spectrum, Si (1 \u2264 i \u2264 k), each contributing ni(Si) cycles, then if Ni(Si) is the number of cycles to failure of a constant stress reversal Si (determined by uni-axial fatigue tests), failure occurs when:\n\n  \n    \n      \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            k\n          \n        \n        \n          \n            \n              n\n              \n                i\n              \n            \n            \n              N\n              \n                i\n              \n            \n          \n        \n        =\n        C\n      \n    \n    {\\displaystyle \\sum _{i=1}^{k}{\\frac {n_{i}}{N_{i}}}=C}\n  Usually, for design purposes, C is assumed to be 1. This can be thought of as assessing what proportion of life is consumed by a linear combination of stress reversals at varying magnitudes.\nAlthough Miner's rule may be a useful approximation in many circumstances, it has several major limitations:\n\nIt fails to recognize the probabilistic nature of fatigue and there is no simple way to relate life predicted by the rule with the characteristics of a probability distribution. Industry analysts often use design curves, adjusted to account for scatter, to calculate Ni(Si).\nThe sequence in which high vs. low stress cycles are applied to a sample in fact affect the fatigue life, for which Miner's Rule does not account. In some circumstances, cycles of low stress followed by high stress cause more damage than would be predicted by the rule. It does not consider the effect of an overload or high stress which may result in a compressive residual stress that may retard crack growth. High stress followed by low stress may have less damage due to the presence of compressive residual stress (or localized plastic damages around crack tip).\n\n\n==== Stress-life (S-N) method ====\n\nMaterials fatigue performance is commonly characterized by an S-N curve, also known as a W\u00f6hler curve. This is often plotted with the cyclic stress (S) against the cycles to failure (N) on a logarithmic scale. S-N curves are derived from tests on samples of the material to be characterized (often called coupons or specimens) where a regular sinusoidal stress is applied by a testing machine which also counts the number of cycles to failure. This process is sometimes known as coupon testing. For greater accuracy but lower generality component testing is used. Each coupon or component test generates a point on the plot though in some cases there is a runout where the time to failure exceeds that available for the test (see censoring). Analysis of fatigue data requires techniques from statistics, especially survival analysis and linear regression.\nThe progression of the S-N curve can be influenced by many factors such as stress ratio (mean stress), loading frequency, temperature, corrosion, residual stresses, and the presence of notches. A constant fatigue life (CFL) diagram is useful for the study of stress ratio effect. The Goodman line is a method used to estimate the influence of the mean stress on the fatigue strength.\nA Constant Fatigue Life (CFL) diagram is useful for stress ratio effect on S-N curve. Also, in the presence of a steady stress superimposed on the cyclic loading, the Goodman relation can be used to estimate a failure condition. It plots stress amplitude against mean stress with the fatigue limit and the ultimate tensile strength of the material as the two extremes. Alternative failure criteria include Soderberg and Gerber.As coupons sampled from a homogeneous frame will display a variation in their number of cycles to failure, the S-N curve should more properly be a Stress-Cycle-Probability (S-N-P) curve to capture the probability of failure after a given number of cycles of a certain stress.\nWith body-centered cubic materials (bcc), the W\u00f6hler curve often becomes a horizontal line with decreasing stress amplitude, i.e. there is a fatigue strength that can be assigned to these materials. With face-centered cubic metals (fcc), the W\u00f6hler curve generally drops continuously, so that only a fatigue limit can be assigned to these materials.\n\n\n==== Strain-life (\u03b5-N) method ====\n\nWhen strains are no longer elastic, such as in the presence of stress concentrations, the total strain can be used instead of stress as a similitude parameter. This is known as the strain-life method. The total strain amplitude \n  \n    \n      \n        \u0394\n        \u03b5\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle \\Delta \\varepsilon /2}\n   is the sum of the elastic strain amplitude \n  \n    \n      \n        \u0394\n        \n          \u03b5\n          \n            e\n          \n        \n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle \\Delta \\varepsilon _{\\text{e}}/2}\n   and the plastic strain amplitude \n  \n    \n      \n        \u0394\n        \n          \u03b5\n          \n            p\n          \n        \n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle \\Delta \\varepsilon _{\\text{p}}/2}\n   and is given by\n\n  \n    \n      \n        \n          \n            \n              \u0394\n              \u03b5\n            \n            2\n          \n        \n        =\n        \n          \n            \n              \u0394\n              \n                \u03b5\n                \n                  e\n                \n              \n            \n            2\n          \n        \n        +\n        \n          \n            \n              \u0394\n              \n                \u03b5\n                \n                  p\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\Delta \\varepsilon  \\over 2}={\\Delta \\varepsilon _{\\text{e}} \\over 2}+{\\Delta \\varepsilon _{\\text{p}} \\over 2}}\n  .Basquin's equation for the elastic strain amplitude is\n\n  \n    \n      \n        \n          \n            \n              \u0394\n              \n                \u03b5\n                \n                  e\n                \n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              \u0394\n              \u03c3\n            \n            \n              2\n              E\n            \n          \n        \n        =\n        \n          \n            \n              \u03c3\n              \n                a\n              \n            \n            E\n          \n        \n      \n    \n    {\\displaystyle {\\Delta \\varepsilon _{\\text{e}} \\over 2}={\\frac {\\Delta \\sigma }{2E}}={\\frac {\\sigma _{\\text{a}}}{E}}}\n  where \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is Young's modulus.\nThe relation for high cycle fatigue can be expressed using the elastic strain amplitude\n\n  \n    \n      \n        \n          \n            \n              \u0394\n              \n                \u03b5\n                \n                  e\n                \n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              \u03c3\n              \n                f\n              \n              \n                \u2032\n              \n            \n            E\n          \n        \n        (\n        2\n        \n          N\n          \n            f\n          \n        \n        \n          )\n          \n            b\n          \n        \n      \n    \n    {\\displaystyle {\\Delta \\varepsilon _{\\text{e}} \\over 2}={\\frac {\\sigma _{\\text{f}}^{\\prime }}{E}}(2N_{\\text{f}})^{b}}\n  where \n  \n    \n      \n        \n          \u03c3\n          \n            f\n          \n          \n            \u2032\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{\\text{f}}^{\\prime }}\n   is a parameter that scales with tensile strength obtained by fitting experimental data, \n  \n    \n      \n        \n          N\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle N_{\\text{f}}}\n   is the number of cycles to failure and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n   is the slope of the log-log curve again determined by curve fitting.\nIn 1954, Coffin and Manson proposed that the fatigue life of a component was related to the plastic strain amplitude using\n\n  \n    \n      \n        \n          \n            \n              \u0394\n              \n                \u03b5\n                \n                  p\n                \n              \n            \n            2\n          \n        \n        =\n        \n          \u03b5\n          \n            f\n          \n          \n            \u2032\n          \n        \n        (\n        2\n        \n          N\n          \n            f\n          \n        \n        \n          )\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle {\\Delta \\varepsilon _{\\text{p}} \\over 2}=\\varepsilon _{\\text{f}}^{\\prime }(2N_{\\text{f}})^{c}}\n  .Combining the elastic and plastic portions gives the total strain amplitude accounting for both low and high cycle fatigue\n\n  \n    \n      \n        \n          \n            \n              \u0394\n              \u03b5\n            \n            2\n          \n        \n        =\n        \n          \n            \n              \u03c3\n              \n                f\n              \n              \n                \u2032\n              \n            \n            E\n          \n        \n        (\n        2\n        \n          N\n          \n            f\n          \n        \n        \n          )\n          \n            b\n          \n        \n        +\n        \n          \u03b5\n          \n            f\n          \n          \n            \u2032\n          \n        \n        (\n        2\n        \n          N\n          \n            f\n          \n        \n        \n          )\n          \n            c\n          \n        \n      \n    \n    {\\displaystyle {\\Delta \\varepsilon  \\over 2}={\\frac {\\sigma _{\\text{f}}^{\\prime }}{E}}(2N_{\\text{f}})^{b}+\\varepsilon _{\\text{f}}^{\\prime }(2N_{\\text{f}})^{c}}\n  .where \n  \n    \n      \n        \n          \u03c3\n          \n            f\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\sigma _{f}'}\n   is the fatigue strength coefficient, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n   is the fatigue strength exponent, \n  \n    \n      \n        \n          \u03b5\n          \n            f\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\varepsilon _{f}'}\n   is the fatigue ductility coefficient, \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n   is the fatigue ductility exponent, and \n  \n    \n      \n        \n          N\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle N_{f}}\n   is the number of cycles to failure (\n  \n    \n      \n        2\n        \n          N\n          \n            f\n          \n        \n      \n    \n    {\\displaystyle 2N_{f}}\n   being the number of reversals to failure).\n\n\n=== Crack growth methods ===\nAn estimate of the fatigue life of a component can be made using a crack growth equation by summing up the width of each increment of crack growth for each loading cycle.  Safety or scatter factors are applied to the calculated life to account for any uncertainty and variability associated with fatigue. The rate of growth used in crack growth predictions is typically measured by applying thousands of constant amplitude cycles to a coupon and measuring the rate of growth from the change in compliance of the coupon or by measuring the growth of the crack on the surface of the coupon. Standard methods for measuring the rate of growth have been developed by ASTM International.Crack growth equations such as the Paris\u2013Erdo\u011fan equation are used to predict the life of a component. They can be used to predict the growth of a crack from 10 um to failure. For normal manufacturing finishes this may cover most of the fatigue life of a component where growth can start from the first cycle. The conditions at the crack tip of a component are usually related to the conditions of test coupon using a characterising parameter such as the stress intensity, J-integral or crack tip opening displacement. All these techniques aim to match the crack tip conditions on the component to that of test coupons which give the rate of crack growth.\nAdditional models may be necessary to include retardation and acceleration effects associated with overloads or underloads in the loading sequence. In addition, small crack growth data may be needed to match the increased rate of growth seen with small cracks.Typically, a cycle counting technique such as rainflow-cycle counting is used to extract the cycles from a complex sequence. This technique, along with others, has been shown to work with crack growth methods.Crack growth methods have the advantage that they can predict the intermediate size of cracks. This information can be used to schedule inspections on a structure to ensure safety whereas strain/life methods only give a life until failure.\n\n\n== Dealing with fatigue ==\n\n\n=== Design ===\nDependable design against fatigue-failure requires thorough education and supervised experience in structural engineering, mechanical engineering, or materials science. There are at least five principal approaches to life assurance for mechanical parts that display increasing degrees of sophistication:\nDesign to keep stress below threshold of fatigue limit (infinite lifetime concept);\nFail-safe, graceful degradation, and fault-tolerant design: Instruct the user to replace parts when they fail. Design in such a way that there is no single point of failure, and so that when any one part completely fails, it does not lead to catastrophic failure of the entire system.\nSafe-life design: Design (conservatively) for a fixed life after which the user is instructed to replace the part with a new one (a so-called lifed part, finite lifetime concept, or \"safe-life\" design practice); planned obsolescence and disposable product are variants that design for a fixed life after which the user is instructed to replace the entire device;\nDamage tolerance: Is an approach that ensures aircraft safety by assuming the presence of cracks or defects even in new aircraft. Crack growth calculations, periodic inspections and component repair or replacement can be used to ensure critical components that may contain cracks, remain safe. Inspections usually use nondestructive testing to limit or monitor the size of possible cracks and require an accurate prediction of the rate of crack-growth between inspections. The designer sets some aircraft maintenance checks schedule frequent enough that parts are replaced while the crack is still in the \"slow growth\" phase. This is often referred to as damage tolerant design or \"retirement-for-cause\".\nRisk Management: Ensures the probability of failure remains below an acceptable level. This approach is typically used for aircraft where acceptable levels may be based on probability of failure during a single flight or taken over the lifetime of an aircraft. A component is assumed to have a crack with a probability distribution of crack sizes. This approach can consider variability in values such as crack growth rates, usage and critical crack size. It is also useful for considering damage at multiple locations that may interact to produce multi-site or widespread fatigue damage. Probability distributions that are common in data analysis and in design against fatigue include the log-normal distribution, extreme value distribution, Birnbaum\u2013Saunders distribution, and Weibull distribution.\n\n\n=== Testing ===\nFatigue testing can be used for components such as a coupon or a full-scale test article to determine:\n\nthe rate of crack growth and fatigue life of components such as a coupon or a full-scale test article.\nlocation of critical regions\ndegree of fail-safety when part of the structure fails\nthe origin and cause of the crack initiating defect from fractographic examination of the crack.These tests may form part of the certification process such as for airworthiness certification.\n\n\n=== Repair ===\nStop drill Fatigue cracks that have begun to propagate can sometimes be stopped by drilling holes, called drill stops, at the tip of the crack. The possibility remains of a new crack starting in the side of the hole.\nBlend. Small cracks can be blended away and the surface cold worked or shot peened.\nOversize holes. Holes with cracks growing from them can be drilled out to a larger hole to remove cracking and bushed to restore the original hole. Bushes can be cold shrink Interference fit bushes to induce beneficial compressive residual stresses. The oversized hole can also be cold worked by drawing an oversized mandrel through the hole.\nPatch. Cracks may be repaired by installing a patch or repair fitting. Composite patches have been used to restore the strength of aircraft wings after cracks have been detected or to lower the stress prior to cracking in order to improve the fatigue life. Patches may restrict the ability to monitor fatigue cracks and may need to be removed and replaced for inspections.\n\n\n=== Life improvement ===\n\nChange material. Changes in the materials used in parts can also improve fatigue life. For example, parts can be made from better fatigue rated metals. Complete replacement and redesign of parts can also reduce if not eliminate fatigue problems. Thus helicopter rotor blades and propellers in metal are being replaced by composite equivalents. They are not only lighter, but also much more resistant to fatigue. They are more expensive, but the extra cost is amply repaid by their greater integrity, since loss of a rotor blade usually leads to total loss of the aircraft. A similar argument has been made for replacement of metal fuselages, wings and tails of aircraft.\nInduce residual stresses Peening a surface can reduce such tensile stresses and create compressive residual stress, which prevents crack initiation.  Forms of peening include: shot peening, using high-speed projectiles, high-frequency impact treatment (also called high-frequency mechanical impact) using a mechanical hammer, and laser peening which uses high-energy laser pulses. Low plasticity burnishing can also be used to induce compresses stress in fillets and cold work mandrels can be used for holes. Increases in fatigue life and strength are proportionally related to the depth of the compressive residual stresses imparted.  Shot peening imparts compressive residual stresses approximately 0.005 inches (0.1 mm) deep, while laser peening can go 0.040 to 0.100 inches (1 to 2.5 mm) deep, or deeper.\nDeep cryogenic treatment. The use of Deep Cryogenic treatment has been shown to increase resistance to fatigue failure. Springs used in industry, auto racing and firearms have been shown to last up to six times longer when treated. Heat checking, which is a form of thermal cyclic fatigue has been greatly delayed.\nRe-profiling. Changing the shape of a stress concentration such as a hole or cutout may be used to extend the life of a component. Shape optimisation using numerical optimisation algorithms have been used to lower the stress concentration in wings and increase their life.\n\n\n== Fatigue of composites ==\nComposite materials can offer excellent resistance to fatigue loading. In general, composites exhibit good fracture toughness and, unlike metals, increase fracture toughness with increasing strength. The critical damage size in composites is also greater than that for metals.The primary mode of damage in a metal structure is cracking. For metal, cracks propagate in a relatively well-defined manner with respect to the applied stress, and the critical crack size and rate of crack propagation can be related to specimen data through analytical fracture mechanics. However, with composite structures, there is no single damage mode which dominates. Matrix cracking, delamination, debonding, voids, fiber fracture, and composite cracking can all occur separately and in combination, and the predominance of one or more is highly dependent on the laminate orientations and loading conditions. In addition, the unique joints and attachments used for composite structures often introduce modes of failure different from those typified by the laminate itself.The composite damage propagates in a less regular manner and damage modes can change. Experience with composites indicates that the rate of damage propagation in does not exhibit the two distinct regions of initiation and propagation like metals. The crack initiation range in metals is propagation, and there is a significant quantitative difference in rate while the difference appears to be less apparent with composites. Fatigue cracks of composites may form in the matrix and propagate slowly since the matrix carries such a small fraction of the applied stress. And the fibers in the wake of the crack experience fatigue damage. In many cases, the damage rate is accelerated by deleterious interactions with the environment like oxidation or corrosion of fibers.\n\n\n== Notable fatigue failures ==\n\n\n=== Versailles train crash ===\n\nFollowing the King Louis-Philippe I's celebrations at the Palace of Versailles, a train returning to Paris crashed in May 1842 at Meudon after the leading locomotive broke an axle. The carriages behind piled into the wrecked engines and caught fire. At least 55 passengers were killed trapped in the locked carriages, including the explorer Jules Dumont d'Urville. This accident is known in France as the \"Catastrophe ferroviaire de Meudon\". The accident was witnessed by the British locomotive engineer Joseph Locke and widely reported in Britain. It was discussed extensively by engineers, who sought an explanation.\nThe derailment had been the result of a broken locomotive axle. Rankine's investigation of broken axles in Britain highlighted the importance of stress concentration, and the mechanism of crack growth with repeated loading. His and other papers suggesting a crack growth mechanism through repeated stressing, however, were ignored, and fatigue failures occurred at an ever-increasing rate on the expanding railway system. Other spurious theories seemed to be more acceptable, such as the idea that the metal had somehow \"crystallized\". The notion was based on the crystalline appearance of the fast fracture region of the crack surface, but ignored the fact that the metal was already highly crystalline.\n\n\n=== de Havilland Comet ===\n\nTwo de Havilland Comet passenger jets broke up in mid-air and crashed within a few months of each other in 1954. As a result, systematic tests were conducted on a fuselage immersed and pressurised in a water tank. After the equivalent of 3,000 flights, investigators at the Royal Aircraft Establishment (RAE) were able to conclude that the crash had been due to failure of the pressure cabin at the forward Automatic Direction Finder window in the roof. This 'window' was in fact one of two apertures for the aerials of an electronic navigation system in which opaque fibreglass panels took the place of the window 'glass'. The failure was a result of metal fatigue caused by the repeated pressurisation and de-pressurisation of the aircraft cabin. Also, the supports around the windows were riveted, not bonded, as the original specifications for the aircraft had called for. The problem was exacerbated by the punch rivet construction technique employed. Unlike drill riveting, the imperfect nature of the hole created by punch riveting caused manufacturing defect cracks which may have caused the start of fatigue cracks around the rivet.\n\nThe Comet's pressure cabin had been designed to a safety factor comfortably in excess of that required by British Civil Airworthiness Requirements (2.5 times the cabin proof test pressure as opposed to the requirement of 1.33 times and an ultimate load of 2.0 times the cabin pressure) and the accident caused a revision in the estimates of the safe loading strength requirements of airliner pressure cabins.\nIn addition, it was discovered that the stresses around pressure cabin apertures were considerably higher than had been anticipated, especially around sharp-cornered cut-outs, such as windows. As a result, all future jet airliners would feature windows with rounded corners, greatly reducing the stress concentration. This was a noticeable distinguishing feature of all later models of the Comet. Investigators from the RAE told a public inquiry that the sharp corners near the Comets' window openings acted as initiation sites for cracks. The skin of the aircraft was also too thin, and cracks from manufacturing stresses were present at the corners.\n\n\n=== Alexander L. Kielland oil platform capsizing ===\n\nThe Alexander L. Kielland was a Norwegian semi-submersible drilling rig that capsized whilst working in the Ekofisk oil field in March 1980, killing 123 people. The capsizing was the worst disaster in Norwegian waters since World War II. The rig, located approximately 320 km east of Dundee, Scotland, was owned by the Stavanger Drilling Company of Norway and was on hire to the United States company Phillips Petroleum at the time of the disaster. In driving rain and mist, early in the evening of 27 March 1980 more than 200 men were off duty in the accommodation on the Alexander L. Kielland. The wind was gusting to 40 knots with waves up to 12 m high. The rig had just been winched away from the Edda production platform. Minutes before 18:30 those on board felt a 'sharp crack' followed by 'some kind of trembling'. Suddenly the rig heeled over 30\u00b0 and then stabilised. Five of the six anchor cables had broken, with one remaining cable preventing the rig from capsizing. The list continued to increase and at 18:53 the remaining anchor cable snapped and the rig turned upside down.\nA year later in March 1981, the investigative report concluded that the rig collapsed owing to a fatigue crack in one of its six bracings (bracing D-6), which connected the collapsed D-leg to the rest of the rig. This was traced to a small 6 mm fillet weld which joined a non-load-bearing flange plate to this D-6 bracing. This flange plate held a sonar device used during drilling operations. The poor profile of the fillet weld contributed to a reduction in its fatigue strength. Further, the investigation found considerable amounts of lamellar tearing in the flange plate and cold cracks in the butt weld. Cold cracks in the welds, increased stress concentrations due to the weakened flange plate, the poor weld profile, and cyclical stresses (which would be common in the North Sea), seemed to collectively play a role in the rig's collapse.\n\n\n=== Others ===\nThe 1862 Hartley Colliery Disaster was caused by the fracture of a steam engine beam and killed 204 people.\nThe 1919 Boston Great Molasses Flood has been attributed to a fatigue failure.\nThe 1948 Northwest Airlines Flight 421 crash due to fatigue failure in a wing spar root\nThe 1957 \"Mt. Pinatubo\", presidential plane of Philippine President Ramon Magsaysay, crashed due to engine failure caused by metal fatigue.\nThe 1965 capsize of the UK's first offshore oil platform, the Sea Gem, was due to fatigue in part of the suspension system linking the hull to the legs.\nThe 1968 Los Angeles Airways Flight 417 lost one of its main rotor blades due to fatigue failure.\nThe 1968 MacRobertson Miller Airlines Flight 1750 lost a wing due to improper maintenance leading to fatigue failure.\nThe 1969 F-111A crash due to a fatigue failure of the wing pivot fitting from a material defect resulted in the development of the damage- tolerant approach for fatigue design.\nThe 1977 Dan-Air Boeing 707 crash caused by fatigue failure resulting in the loss of the right horizontal stabilizer.\nThe 1979 American Airlines Flight 191 crashed after engine separation attributed to fatigue damage in the pylon structure holding the engine to the wing, caused by improper maintenance procedures.\nThe 1980 LOT Flight 7 crashed due to fatigue in an engine turbine shaft resulting in engine disintegration leading to loss of control.\nThe 1985 Japan Airlines Flight 123 crashed after the aircraft lost its vertical stabilizer due to faulty repairs on the rear bulkhead.\nThe 1988 Aloha Airlines Flight 243 suffered an explosive decompression at 24,000 feet (7,300 m) after a fatigue failure.\nThe 1989 United Airlines Flight 232 lost its tail engine due to fatigue failure in a fan disk hub.\nThe 1992 El Al Flight 1862 lost both engines on its right-wing due to fatigue failure in the pylon mounting of the #3 Engine.\nThe 1998 Eschede train disaster was caused by fatigue failure of a single composite wheel.\nThe 2000 Hatfield rail crash was likely caused by rolling contact fatigue.\nThe 2000 recall of 6.5 million Firestone tires on Ford Explorers originated from fatigue crack growth leading to separation of the tread from the tire.\nThe 2002 China Airlines Flight 611 disintegrated in-flight due to fatigue failure.\nThe 2005 Chalk's Ocean Airways Flight 101 lost its right wing due to fatigue failure brought about by inadequate maintenance practices.\nThe 2009 Viareggio train derailment due to fatigue failure.\nThe 2009 Sayano\u2013Shushenskaya power station accident due to metal fatigue of turbine mountings.\nThe 2017 Air France Flight 66 had in-flight engine failure due to cold dwell fatigue fracture in the fan hub.\n\n\n== See also ==\nAviation safety \u2013 State in which risks associated with aviation are at an acceptable level\nCritical plane analysis \u2013 Analysis of multiaxial stresses and strains\nEmbedment\nForensic materials engineering \u2013 branch of forensic engineeringPages displaying wikidata descriptions as a fallback\nFractography \u2013 Study of the fracture surfaces of materials\nSolder fatigue \u2013 Degradation of solder due to deformation under cyclic loading\nThermo-mechanical fatigue\nVibration fatigue\nInternational Journal of Fatigue\n\n\n== References ==\n\n\n== Further reading ==\nPDL Staff (1995). Fatigue and Tribological Properties of Plastics and Elastomers. Plastics Design Library. ISBN 978-1-884207-15-0.\nLeary, M.; Burvill, C. (2009). \"Applicability of published data for fatigue-limited design\". Quality and Reliability Engineering International. 25 (8): 921\u2013932. doi:10.1002/qre.1010. S2CID 206432498.\nDieter, G. E. (2013). Mechanical Metallurgy. McGraw-Hill. ISBN 978-1259064791.\nLittle, R.E.; Jebe, E.H. (1975). Statistical Design of Fatigue Experiments. John Wiley & Sons. ISBN 978-0-470-54115-9.\nSchijve, J. (2009). Fatigue of Structures and Materials. Springer. ISBN 978-1-4020-6807-2.\nLalanne, C. (2009). Fatigue Damage. ISTE - Wiley. ISBN 978-1-84821-125-4.\nPook, L. (2007). Metal Fatigue, What it is, Why it matters. Springer. ISBN 978-1-4020-5596-6.\nDraper, J. (2008). Modern Metal Fatigue Analysis. EMAS. ISBN 978-0-947817-79-4.\nSuresh, S. (2004). Fatigue of Materials. Cambridge University Press. ISBN 978-0-521-57046-6.\nKim, H. S. (2018). Mechanics of Solids and Fracture, 3rd ed. Bookboon, London. ISBN 978-87-403-2393-1.\n\n\n== External links ==\n\nFatigue Shawn M. Kelly\nApplication note on fatigue crack propagation in UHMWPE Archived 2013-11-04 at the Wayback Machine\nfatigue test video Karlsruhe University of Applied Sciences\nStrain life method G. Glinka\nFatigue from variable amplitude loading A. Fatemi", "Electric_charge": "Electric charge is the physical property of matter that causes matter to experience a force when placed in an electromagnetic field. Electric charge can be positive or negative (commonly carried by protons and electrons respectively, by convention). Like charges repel each other and unlike charges attract each other. An object with an absence of net charge is referred to as neutral. Early knowledge of how charged substances interact is now called classical electrodynamics, and is still accurate for problems that do not require consideration of quantum effects.\nElectric charge is a conserved property; the net charge of an isolated system, the amount of positive charge minus the amount of negative charge, cannot change. Electric charge is carried by subatomic particles. In ordinary matter, negative charge is carried by electrons, and positive charge is carried by the protons in the nuclei of atoms. If there are more electrons than protons in a piece of matter, it will have a negative charge, if there are fewer it will have a positive charge, and if there are equal numbers it will be neutral. Charge is quantized; it comes in integer multiples of individual small units called the elementary charge, e, about 1.602\u00d710\u221219 C, which is the smallest charge that can exist freely (particles called quarks have smaller charges, multiples of 1/3e, but they are found only in combination, and always combine to form particles that have a charge that is an integer multiple of e). The proton has a charge of +e, and the electron has a charge of \u2212e.\nElectric charges produce electric fields. A moving charge also produces a magnetic field. The interaction of electric charges with an electromagnetic field (a combination of an electric and a magnetic field) is the source of the electromagnetic (or Lorentz) force, which is one of the four fundamental interactions in physics. The study of photon-mediated interactions among charged particles is called quantum electrodynamics.The SI derived unit of electric charge is the coulomb (C) named after French physicist Charles-Augustin de Coulomb. In electrical engineering it is also common to use the ampere-hour (A\u22c5h). In physics and chemistry it is common to use the elementary charge (e) as a unit. Chemistry also uses the Faraday constant, which is the charge of one mole of elementary charges. The lowercase symbol q often denotes charge.\n\n\n== Overview ==\n\nCharge is the fundamental property of matter that exhibits electrostatic attraction or repulsion in the presence of other matter with charge. Electric charge is a characteristic property of many subatomic particles. The charges of free-standing particles are integer multiples of the elementary charge e; we say that electric charge is quantized. Michael Faraday, in his electrolysis experiments, was the first to note the discrete nature of electric charge. Robert Millikan's oil drop experiment demonstrated this fact directly, and measured the elementary charge. It has been discovered that one type of particle, quarks, have fractional charges of either \u22121/3 or +2/3, but it is believed they always occur in multiples of integral charge; free-standing quarks have never been observed.\nBy convention, the charge of an electron is negative, \u2212e, while that of a proton is positive, +e. Charged particles whose charges have the same sign repel one another, and particles whose charges have different signs attract. Coulomb's law quantifies the electrostatic force between two particles by asserting that the force is proportional to the product of their charges, and inversely proportional to the square of the distance between them. The charge of an antiparticle equals that of the corresponding particle, but with opposite sign.\nThe electric charge of a macroscopic object is the sum of the electric charges of the particles that it's made up of. This charge is often small, because matter is made of atoms, and atoms typically have equal numbers of protons and electrons, in which case their charges cancel out, yielding a net charge of zero, thus making the atom neutral.\nAn ion is an atom (or group of atoms) that has lost one or more electrons, giving it a net positive charge (cation), or that has gained one or more electrons, giving it a net negative charge (anion). Monatomic ions are formed from single atoms, while polyatomic ions are formed from two or more atoms that have been bonded together, in each case yielding an ion with a positive or negative net charge.\n\nDuring the formation of macroscopic objects, constituent atoms and ions usually combine to form structures composed of neutral ionic compounds electrically bound to neutral atoms. Thus macroscopic objects tend toward being neutral overall, but macroscopic objects are rarely perfectly net neutral.\nSometimes macroscopic objects contain ions distributed throughout the material, rigidly bound in place, giving an overall net positive or negative charge to the object. Also, macroscopic objects made of conductive elements can more or less easily (depending on the element) take on or give off electrons, and then maintain a net negative or positive charge indefinitely. When the net electric charge of an object is non-zero and motionless, the phenomenon is known as static electricity. This can easily be produced by rubbing two dissimilar materials together, such as rubbing amber with fur or glass with silk. In this way, non-conductive materials can be charged to a significant degree, either positively or negatively. Charge taken from one material is moved to the other material, leaving an opposite charge of the same magnitude behind. The law of conservation of charge always applies, giving the object from which a negative charge is taken a positive charge of the same magnitude, and vice versa.\nEven when an object's net charge is zero, the charge can be distributed non-uniformly in the object (e.g., due to an external electromagnetic field, or bound polar molecules). In such cases, the object is said to be polarized. The charge due to polarization is known as bound charge, while the charge on an object produced by electrons gained or lost from outside the object is called free charge. The motion of electrons in conductive metals in a specific direction is known as electric current.\n\n\n== Unit ==\nThe SI derived unit of quantity of electric charge is the coulomb (symbol: C). The coulomb is defined as the quantity of charge that passes through the cross section of an electrical conductor carrying one ampere for one second. This unit was proposed in 1946 and ratified in 1948. The lowercase symbol q is often used to denote a quantity of electric charge. The quantity of electric charge can be directly measured with an electrometer, or indirectly measured with a ballistic galvanometer.\nThe elementary charge (the electric charge of the proton) is defined as a fundamental constant in the SI system of units. The value for elementary charge, when expressed in the SI units, is exactly 1.602176634\u00d710\u221219 C.After discovering the quantized character of charge, in 1891 George Stoney proposed the unit 'electron' for this fundamental unit of electrical charge. J. J. Thomson subsequently discovered the particle that we now call the electron in 1897. The unit is today referred to as elementary charge, fundamental unit of charge, or simply denoted e, with the charge of an electron being \u2212e. The charge of an isolated system should be a multiple of the elementary charge e, even if at large scales charge seems to behave as a continuous quantity. In some contexts it is meaningful to speak of fractions of an elementary charge; for example, in the fractional quantum Hall effect.\nThe unit faraday is sometimes used in electrochemistry. One faraday is the magnitude of the charge of one mole of elementary charges, i.e. 9.648533212...\u00d7104 C.\nIn the CGS system, electric charge is expressed as a combination of three mechanical quantities: length, mass, and time, unlike in the SI, which incorporates an independent electromagnetic dimension.\n\n\n== History ==\n\nFrom ancient times, people were familiar with four types of phenomena that today would all be explained using the concept of electric charge: (a) lightning, (b) the torpedo fish (or electric ray), (c) St Elmo's Fire, and (d) that amber rubbed with fur would attract small, light objects. The first account of the amber effect is often attributed to the ancient Greek mathematician Thales of Miletus, who lived from c. 624 to c. 546 BC, but there are doubts about whether Thales left any writings; his account about amber is known from an account from early 200s. This account can be taken as evidence that the phenomenon was known since at least c. 600 BC, but Thales explained this phenomenon as evidence for inanimate objects having a soul. In other words, there was no indication of any conception of electric charge. More generally, the ancient Greeks did not understand the connections among these four kinds of phenomena. The Greeks observed that the charged amber buttons could attract light objects such as hair. They also found that if they rubbed the amber for long enough, they could even get an electric spark to jump, but there is also a claim that no mention of electric sparks appeared until late 17th century. This property derives from the triboelectric effect.\nIn late 1100s, the substance jet, a compacted form of coal, was noted to have an amber effect, and in the middle of the 1500s, Girolamo Fracastoro, discovered that diamond also showed this effect. Some efforts were made by Fracastoro and others, especially Gerolamo Cardano to develop explanations for this phenomenon.In contrast to astronomy, mechanics, and optics, which had been studied quantitatively since antiquity, the start of ongoing qualitative and quantitative research into electrical phenomena can be marked with the publication of De Magnete by the English scientist William Gilbert in 1600. In this book, there was a small section where Gilbert returned to the amber effect (as he called it) in addressing many of the earlier theories, and coined the New Latin word electrica (from \u1f24\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd (\u0113lektron), the Greek word for amber). The Latin word was translated into English as electrics. Gilbert is also credited with the term electrical, while the term electricity came later, first attributed to Sir Thomas Browne in his Pseudodoxia Epidemica from 1646. (For more linguistic details see Etymology of electricity.) Gilbert hypothesized that this amber effect could be explained by an effluvium (a small stream of particles that flows from the electric object, without diminishing its bulk or weight) that acts on other objects. This idea of a material electrical effluvium was influential in the 17th and 18th centuries. It was a precursor to ideas developed in the 18th century about \"electric fluid\" (Dufay, Nollet, Franklin) and \"electric charge\".Around 1663 Otto von Guericke invented what was probably the first electrostatic generator, but he did not recognize it primarily as an electrical device and only conducted minimal electrical experiments with it. Other European pioneers were Robert Boyle, who in 1675 published the first book in English that was devoted solely to electrical phenomena. His work was largely a repetition of Gilbert's studies, but he also identified several more \"electrics\", and noted mutual attraction between two bodies.In 1729 Stephen Gray was experimenting with static electricity, which he generated using a glass tube.  He noticed that a cork, used to protect the tube from dust and moisture, also became electrified (charged).  Further experiments (e.g., extending the cork by putting thin sticks into it) showed\u2014for the first time\u2014that electrical effluvia (as Gray called it) could be transmitted (conducted) over a distance.  Gray managed to transmit charge with twine (765 feet) and wire (865 feet).   Through these experiments, Gray discovered the importance of different materials, which facilitated or hindered the conduction of electrical effluvia.  John Theophilus Desaguliers, who repeated many of Gray's experiments, is credited with coining the terms conductors and insulators to refer to the effects of different materials in these experiments. Gray also discovered electrical induction (i.e., where charge could be transmitted from one object to another without any direct physical contact).   For example, he showed that by bringing a charged glass tube close to, but not touching, a lump of lead that was sustained by a thread, it was possible to make the lead become electrified (e.g., to attract and repel brass filings). He attempted to explain this phenomenon with the idea of electrical effluvia.Gray's discoveries introduced an important shift in the historical development of knowledge about electric charge.  The fact that electrical effluvia could be transferred from one object to another, opened the theoretical possibility that this property was not inseparably connected to the bodies that were electrified by rubbing. In 1733 Charles Fran\u00e7ois de Cisternay du Fay, inspired by Gray's work, made a series of experiments (reported in M\u00e9moires de l'Acad\u00e9mie Royale des Sciences), showing that more or less all substances could be 'electrified' by rubbing, except for metals and fluids and proposed that electricity comes in two varieties that cancel each other, which he expressed in terms of a two-fluid theory. When glass was rubbed with silk, du Fay said that the glass was charged with vitreous electricity, and, when amber was rubbed with fur, the amber was charged with resinous electricity. In contemporary understanding, positive charge is now defined as the charge of a glass rod after being rubbed with a silk cloth, but it is arbitrary which type of charge is called positive and which is called negative. Another important two-fluid theory from this time was proposed by Jean-Antoine Nollet (1745).Up until about 1745, the main explanation for electrical attraction and repulsion was the idea that electrified bodies gave off an effluvium.Benjamin Franklin started electrical experiments in late 1746, and by 1750 had developed a one-fluid theory of electricity, based on an experiment that showed that a rubbed glass received the same, but opposite, charge strength as the cloth used to rub the glass. Franklin imagined electricity as being a type of invisible fluid present in all matter; for example, he believed that it was the glass in a Leyden jar that held the accumulated charge. He posited that rubbing insulating surfaces together caused this fluid to change location, and that a flow of this fluid constitutes an electric current. He also posited that when matter contained an excess of the fluid it was positively charged and when it had a deficit it was negatively charged.  He identified the term positive with vitreous electricity and negative with resinous electricity after performing an experiment with a glass tube he had received from his overseas colleague Peter Collinson. The experiment had participant A charge the glass tube and participant B receive a shock to the knuckle from the charged tube. Franklin identified participant B to be positively charged after having been shocked by the tube. There is some ambiguity about whether William Watson independently arrived at the same one-fluid explanation around the same time (1747). Watson, after seeing Franklin's letter to Collinson, claims that he had presented the same explanation as Franklin in spring 1747. Franklin had studied some of Watson's works prior to making his own experiments and analysis, which was probably significant for Franklin's own theorizing. One physicist suggests that Watson first proposed a one-fluid theory, which Franklin then elaborated further and more influentially. A historian of science argues that Watson missed a subtle difference between his ideas and Franklin's, so that Watson misinterpreted his ideas as being similar to Franklin's. In any case, there was no animosity between Watson and Franklin, and the Franklin model of electrical action, formulated in early 1747, eventually became widely accepted at that time. After Franklin's work, effluvia-based explanations were rarely put forward.It is now known that the Franklin model was fundamentally correct. There is only one kind of electrical charge, and only one variable is required to keep track of the amount of charge.Until 1800 it was only possible to study conduction of electric charge by using an electrostatic discharge.  In 1800 Alessandro Volta was the first to show that charge could be maintained in continuous motion through a closed path.In 1833, Michael Faraday sought to remove any doubt that electricity is identical, regardless of the source by which it is produced.  He discussed a variety of known forms, which he characterized as common electricity (e.g., static electricity, piezoelectricity, magnetic induction),  voltaic electricity (e.g., electric current from a voltaic pile), and animal electricity (e.g.,  bioelectricity).\nIn 1838, Faraday raised a question about whether electricity was a fluid or fluids or a property of matter, like gravity. He investigated whether matter could be charged with one kind of charge independently of the other. He came to the conclusion that electric charge was a relation between two or more bodies, because he could not charge one body without having an opposite charge in another body.In 1838, Faraday also put forth a theoretical explanation of electric force, while expressing neutrality about whether it originates from one, two, or no fluids.  He focused on the idea that the normal state of particles is to be nonpolarized, and that when polarized, they seek to return to their natural, nonpolarized state.\nIn developing a field theory approach to electrodynamics (starting in the mid-1850s), James Clerk Maxwell stops considering electric charge as a special substance that accumulates in objects, and starts to understand electric charge as a consequence of the transformation of energy in the field. This pre-quantum understanding considered magnitude of electric charge to be a continuous quantity, even at the microscopic level.\n\n\n== The role of charge in static electricity ==\nStatic electricity refers to the electric charge of an object and the related electrostatic discharge when two objects are brought together that are not at equilibrium. An electrostatic discharge creates a change in the charge of each of the two objects.\n\n\n=== Electrification by friction ===\n\nWhen a piece of glass and a piece of resin\u2014neither of which exhibit any electrical properties\u2014are rubbed together and left with the rubbed surfaces in contact, they still exhibit no electrical properties. When separated, they attract each other.\nA second piece of glass rubbed with a second piece of resin, then separated and suspended near the former pieces of glass and resin causes these phenomena:\n\nThe two pieces of glass repel each other.\nEach piece of glass attracts each piece of resin.\nThe two pieces of resin repel each other.This attraction and repulsion is an electrical phenomenon, and the bodies that exhibit them are said to be electrified, or electrically charged. Bodies may be electrified in many other ways, as well as by friction. The electrical properties of the two pieces of glass are similar to each other but opposite to those of the two pieces of resin: The glass attracts what the resin repels and repels what the resin attracts.\nIf a body electrified in any manner whatsoever behaves as the glass does, that is, if it repels the glass and attracts the resin, the body is said to be vitreously electrified, and if it attracts the glass and repels the resin it is said to be resinously electrified. All electrified bodies are either vitreously or resinously electrified.\nAn established convention in the scientific community defines vitreous electrification as positive, and resinous electrification as negative. The exactly opposite properties of the two kinds of electrification justify our indicating them by opposite signs, but the application of the positive sign to one rather than to the other kind must be considered as a matter of arbitrary convention\u2014just as it is a matter of convention in mathematical diagram to reckon positive distances towards the right hand.\nNo force, either of attraction or of repulsion, can be observed between an electrified body and a body not electrified.\n\n\n== The role of charge in electric current ==\nElectric current is the flow of electric charge through an object. The most common charge carriers are the positively charged proton and the negatively charged electron. The movement of any of these charged particles constitutes an electric current. In many situations, it suffices to speak of the conventional current without regard to whether it is carried by positive charges moving in the direction of the conventional current or by negative charges moving in the opposite direction. This macroscopic viewpoint is an approximation that simplifies electromagnetic concepts and calculations.\nAt the opposite extreme, if one looks at the microscopic situation, one sees there are many ways of carrying an electric current, including: a flow of electrons; a flow of electron holes that act like positive particles; and both negative and positive particles (ions or other charged particles) flowing in opposite directions in an electrolytic solution or a plasma.\nBeware that, in the common and important case of metallic wires, the direction of the conventional current is opposite to the drift velocity of the actual charge carriers; i.e., the electrons. This is a source of confusion for beginners.\n\n\n== Conservation of electric charge ==\n\nThe total electric charge of an isolated system remains constant regardless of changes within the system itself. This law is inherent to all processes known to physics and can be derived in a local form from gauge invariance of the wave function. The conservation of charge results in the charge-current continuity equation. More generally, the rate of change in charge density \u03c1 within a volume of integration V is equal to the area integral over the current density J through the closed surface S = \u2202V, which is in turn equal to the net current I:\n\n  \n    \n      \n        \u2212\n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        \n          \u222b\n          \n            V\n          \n        \n        \u03c1\n        \n        \n          d\n        \n        V\n        =\n      \n    \n    {\\displaystyle -{\\frac {d}{dt}}\\int _{V}\\rho \\,\\mathrm {d} V=}\n   \n  \n    \n      \n        \n          \u2202\n          V\n        \n      \n    \n    {\\displaystyle \\scriptstyle \\partial V}\n   \n  \n    \n      \n        \n          J\n        \n        \u22c5\n        \n          d\n        \n        \n          S\n        \n        =\n        \u222b\n        J\n        \n          d\n        \n        S\n        cos\n        \u2061\n        \u03b8\n        =\n        I\n        .\n      \n    \n    {\\displaystyle \\mathbf {J} \\cdot \\mathrm {d} \\mathbf {S} =\\int J\\mathrm {d} S\\cos \\theta =I.}\n  Thus, the conservation of electric charge, as expressed by the continuity equation, gives the result:\n\n  \n    \n      \n        I\n        =\n        \u2212\n        \n          \n            \n              \n                d\n              \n              q\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle I=-{\\frac {\\mathrm {d} q}{\\mathrm {d} t}}.}\n  The charge transferred between times \n  \n    \n      \n        \n          t\n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle t_{\\mathrm {i} }}\n   and \n  \n    \n      \n        \n          t\n          \n            \n              f\n            \n          \n        \n      \n    \n    {\\displaystyle t_{\\mathrm {f} }}\n   is obtained by integrating both sides:\n\n  \n    \n      \n        q\n        =\n        \n          \u222b\n          \n            \n              t\n              \n                \n                  i\n                \n              \n            \n          \n          \n            \n              t\n              \n                \n                  f\n                \n              \n            \n          \n        \n        I\n        \n        \n          d\n        \n        t\n      \n    \n    {\\displaystyle q=\\int _{t_{\\mathrm {i} }}^{t_{\\mathrm {f} }}I\\,\\mathrm {d} t}\n  where I is the net outward current through a closed surface and q is the electric charge contained within the volume defined by the surface.\n\n\n== Relativistic invariance ==\nAside from the properties described in articles about electromagnetism, charge is a relativistic invariant. This means that any particle that has charge q has the same charge regardless of how fast it is travelling. This property has been experimentally verified by showing that the charge of one helium nucleus (two protons and two neutrons bound together in a nucleus and moving around at high speeds) is the same as two deuterium nuclei (one proton and one neutron bound together, but moving much more slowly than they would if they were in a helium nucleus).\n\n\n== See also ==\nSI electromagnetism units\nColor charge\nPartial charge\n\n\n== References ==\n\n\n== External links ==\n Media related to Electric charge at Wikimedia Commons\nHow fast does a charge decay?", "Refraction": "In physics, refraction is the redirection of a wave as it passes from one medium to another. The redirection can be caused by the wave's change in speed or by a change in the medium. Refraction of light is the most commonly observed phenomenon, but other waves such as sound waves and water waves also experience refraction. How much a wave is refracted is determined by the change in wave speed and the initial direction of wave propagation relative to the direction of change in speed.\nFor light, refraction follows Snell's law, which states that, for a given pair of media, the ratio of the sines of the angle of incidence \u03b81 and angle of refraction \u03b82 is equal to the ratio of phase velocities (v1 / v2) in the two media, or equivalently, to the refractive indices (n2 / n1) of the two media.\n\n  \n    \n      \n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                1\n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n        =\n        \n          \n            \n              n\n              \n                2\n              \n            \n            \n              n\n              \n                1\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sin \\theta _{1}}{\\sin \\theta _{2}}}={\\frac {v_{1}}{v_{2}}}={\\frac {n_{2}}{n_{1}}}}\n   \nOptical prisms and lenses use refraction to redirect light, as does the human eye. The refractive index of materials varies with the wavelength of light, and thus the angle of the refraction also varies correspondingly. This is called dispersion and causes prisms and rainbows to divide white light into its constituent spectral colors.\n\n\n== Light ==\n\nRefraction of light can be seen in many places in our everyday life. It makes objects under a water surface appear closer than they really are. It is what optical lenses are based on, allowing for instruments such as glasses, cameras, binoculars, microscopes, and the human eye. Refraction is also responsible for some natural optical phenomena including rainbows and mirages.\n\n\n=== General explanation ===\n\nA correct explanation of refraction involves two separate parts, both a result of the wave nature of light.\n\nLight slows as it travels through a medium other than vacuum (such as air, glass or water). This is not because of scattering or absorption. Rather it is because, as an electromagnetic oscillation, light itself causes other electrically charged particles such as electrons, to oscillate. The oscillating electrons emit their own electromagnetic waves  which interact with the original light. The resulting \"combined\" wave has wave packets that pass an observer at a slower rate. The light has effectively been slowed. When light returns to a vacuum and there are no electrons nearby, this slowing effect ends and its speed returns to c.\nWhen light enters a slower medium at an angle, one side of the wavefront is slowed before the other. This asymmetrical slowing of the light causes it to change the angle of its travel. Once light is within the new medium with constant properties, it travels in a straight line again.\n\n\n==== Explanation for slowing of light in a medium ====\nAs described above, the speed of light is slower in a medium other than vacuum. This slowing applies to any medium such as air, water, or glass, and is responsible for phenomena such as refraction. When light leaves the medium and returns to a vacuum, and ignoring any effects of gravity, its speed returns to the usual speed of light in vacuum,  c.\nCommon explanations for this slowing, based upon the idea of light scattering from, or being absorbed and re-emitted by atoms, are both incorrect. Explanations like these would cause a \"blurring\" effect in the resulting light, as it would no longer be travelling in just one direction. But this effect is not seen in nature.\nA correct explanation rests on light's nature as an electromagnetic wave. Because light is an oscillating electrical/magnetic wave, light traveling in a medium causes the electrically charged electrons of the material to also oscillate. (The material's protons also oscillate but as they are around 2000 times more massive, their movement and therefore their effect, is far smaller). A moving electrical charge emits electromagnetic waves of its own. The electromagnetic waves emitted by the oscillating electrons, interact with the electromagnetic waves that make up the original light, similar to water waves on a pond, a process known as constructive interference. When two waves interfere in this way, the resulting \"combined\" wave may have wave packets that pass an observer at a slower rate. The light has effectively been slowed. When the light leaves the material, this interaction with electrons no longer happens, and therefore the wave packet rate (and therefore its speed) return to normal.\n\n\n==== Explanation for bending of light as it enters and exits a medium ====\nConsider a wave going from one material to another where its speed is slower as in the figure. If it reaches the interface between the materials at an angle one side of the wave will reach the second material first, and therefore slow down earlier. With one side of the wave going slower the whole wave will pivot towards that side. This is why a wave will bend away from the surface or toward the normal when going into a slower material. In the opposite case of a wave reaching a material where the speed is higher, one side of the wave will speed up and the wave will pivot away from that side.\nAnother way of understanding the same thing is to consider the change in wavelength at the interface. When the wave goes from one material to another where the wave has a different speed v, the frequency f of the wave will stay the same, but the distance between wavefronts or wavelength \u03bb=v/f will change. If the speed is decreased, such as in the figure to the right, the wavelength will also decrease. With an angle between the wave fronts and the interface and change in distance between the wave fronts the angle must change over the interface to keep the wave fronts intact. From these considerations the relationship between the angle of incidence \u03b81, angle of transmission \u03b82 and the wave speeds v1 and v2 in the two materials can be derived. This is the law of refraction or Snell's law and can be written as\n\n  \n    \n      \n        \n          \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  1\n                \n              \n            \n            \n              sin\n              \u2061\n              \n                \u03b8\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              v\n              \n                1\n              \n            \n            \n              v\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sin \\theta _{1}}{\\sin \\theta _{2}}}={\\frac {v_{1}}{v_{2}}}}\n  .The phenomenon of refraction can in a more fundamental way be derived from the 2 or 3-dimensional wave equation. The boundary condition at the interface will then require the tangential component of the wave vector to be identical on the two sides of the interface. Since the magnitude of the wave vector depend on the wave speed this requires a change in direction of the wave vector.\nThe relevant wave speed in the discussion above is the phase velocity of the wave. This is typically close to the group velocity which can be seen as the truer speed of a wave, but when they differ it is important to use the phase velocity in all calculations relating to refraction.\nA wave traveling perpendicular to a boundary, i.e. having its wavefronts parallel to the boundary, will not change direction even if the speed of the wave changes.\n\n\n=== Law of refraction ===\nFor light, the refractive index n of a material is more often used than the wave phase speed v in the material. They are, however, directly related through the speed of light in vacuum c as\n\n  \n    \n      \n        n\n        =\n        \n          \n            c\n            v\n          \n        \n      \n    \n    {\\displaystyle n={\\frac {c}{v}}}\n  .In optics, therefore, the law of refraction is typically written as\n\n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            1\n          \n        \n        =\n        \n          n\n          \n            2\n          \n        \n        sin\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle n_{1}\\sin \\theta _{1}=n_{2}\\sin \\theta _{2}}\n  .\n\n\n=== Refraction in a water surface ===\n\nRefraction occurs when light goes through a water surface since water has a refractive index of 1.33 and air has a refractive index of about 1. Looking at a straight object, such as a pencil in the figure here, which is placed at a slant, partially in the water, the object appears to bend at the water's surface. This is due to the bending of light rays as they move from the water to the air. Once the rays reach the eye, the eye traces them back as straight lines (lines of sight). The lines of sight (shown as dashed lines) intersect at a higher position than where the actual rays originated. This causes the pencil to appear higher and the water to appear shallower than it really is.\nThe depth that the water appears to be when viewed from above is known as the apparent depth. This is an important consideration for spearfishing from the surface because it will make the target fish appear to be in a different place, and the fisher must aim lower to catch the fish. Conversely, an object above the water has a higher apparent height when viewed from below the water. The opposite correction must be made by an archer fish.For small angles of incidence (measured from the normal, when sin \u03b8 is approximately the same as tan \u03b8), the ratio of apparent to real depth is the ratio of the refractive indexes of air to that of water. But, as the angle of incidence approaches 90o, the apparent depth approaches zero, albeit reflection increases, which limits observation at high angles of incidence. Conversely, the apparent height approaches infinity as the angle of incidence (from below) increases, but even earlier, as the angle of total internal reflection is approached, albeit the image also fades from view as this limit is approached.\n\n\n=== Dispersion ===\nRefraction is also responsible for rainbows and for the splitting of white light into a rainbow-spectrum as it passes through a glass prism. Glass has a higher refractive index than air. When a beam of white light passes from air into a material having an index of refraction that varies with frequency, a phenomenon known as dispersion occurs, in which different coloured components of the white light are refracted at different angles, i.e., they bend by different amounts at the interface, so that they become separated. The different colors correspond to different frequencies.\n\n\n=== Atmospheric refraction ===\n\nThe refractive index of air depends on the air density and thus vary with air temperature and pressure. Since the pressure is lower at higher altitudes, the refractive index is also lower, causing light rays to refract towards the earth surface when traveling long distances through the atmosphere. This shifts the apparent positions of stars slightly when they are close to the horizon and makes the sun visible before it geometrically rises above the horizon during a sunrise.\n\nTemperature variations in the air can also cause refraction of light. This can be seen as a heat haze when hot and cold air is mixed e.g. over a fire, in engine exhaust, or when opening a window on a cold day. This makes objects viewed through the mixed air appear to shimmer or move around randomly as the hot and cold air moves. This effect is also visible from normal variations in air temperature during a sunny day when using high magnification telephoto lenses and is often limiting the image quality in these cases.\n In a similar way, atmospheric turbulence gives rapidly varying distortions in the images of astronomical telescopes limiting the resolution of terrestrial telescopes not using adaptive optics or other techniques for overcoming these atmospheric distortions.\n\nAir temperature variations close to the surface can give rise to other optical phenomena, such as mirages and Fata Morgana. Most commonly, air heated by a hot road on a sunny day deflects light approaching at a shallow angle towards a viewer. This makes the road appear reflecting, giving an illusion of water covering the road.\n\n\n=== Clinical significance ===\nIn medicine, particularly optometry, ophthalmology and orthoptics, refraction (also known as refractometry) is a clinical test in which a phoropter may be used by the appropriate eye care professional to determine the eye's refractive error and the best corrective lenses to be prescribed. A series of test lenses in graded optical powers or focal lengths are presented to determine which provides the sharpest, clearest vision.\n\n\n=== Gallery ===\n\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n== Mechanical waves ==\n\n\n=== Water waves ===\n\nWater waves travel slower in shallower water. This can be used to demonstrate refraction in ripple tanks and also explains why waves on a shoreline tend to strike the shore close to a perpendicular angle. As the waves travel from deep water into shallower water near the shore, they are refracted from their original direction of travel to an angle more normal to the shoreline.\n\n\n=== Sound waves ===\n\nIn underwater acoustics, refraction is the bending or curving of a sound ray that results when the ray passes through a sound speed gradient from a region of one sound speed to a region of a different speed. The amount of ray bending is dependent on the amount of difference between sound speeds, that is, the variation in temperature, salinity, and pressure of the water.\nSimilar acoustics effects are also found in the Earth's atmosphere. The phenomenon of refraction of sound in the atmosphere has been known for centuries; however, beginning in the early 1970s, widespread analysis of this effect came into vogue through the designing of urban highways and noise barriers to address the meteorological effects of bending of sound rays in the lower atmosphere.\n\n\n== See also ==\nBirefringence (double refraction)\nGeometrical optics\nHuygens\u2013Fresnel principle\nList of indices of refraction\nNegative refraction\nReflection\nSchlieren photography\nSeismic refraction\nSuper refraction\n\n\n== References ==\n\n\n== External links ==\n\nReflections and Refractions in Ray Tracing, a simple but thorough discussion of the mathematics behind refraction and reflection.\nFlash refraction simulation- includes source, Explains refraction and Snell's Law.", "Electric_potential_energy": "Electric potential energy is a potential energy (measured in joules) that results from conservative Coulomb forces and is associated with the configuration of a particular set of point charges within a defined system. An object may be said to have electric potential energy by virtue of either its own electric charge or its relative position to other electrically charged objects.\nThe term \"electric potential energy\" is used to describe the potential energy in systems with time-variant electric fields, while the term \"electrostatic potential energy\" is used to describe the potential energy in systems with time-invariant electric fields.\n\n\n== Definition ==\nThe electric potential energy of a system of point charges is defined as the work required to assemble this system of charges by bringing them close together, as in the system from an infinite distance. Alternatively, the electric potential energy of any given charge or system of charges is termed as the total work done by an external agent in bringing the charge or the system of charges from infinity to the present configuration without undergoing any acceleration.\n\nThe electrostatic potential energy can also be defined from the electric potential as follows:\n\n\n== Units ==\nThe SI unit of electric potential energy is  joule (named after the English physicist James Prescott Joule). In the CGS system the erg is the unit of energy, being equal to 10\u22127 Joules. Also electronvolts may be used, 1 eV = 1.602\u00d710\u221219 Joules.\n\n\n== Electrostatic potential energy of one point charge ==\n\n\n=== One point charge q in the presence of another point charge Q ===\n\nThe electrostatic potential energy, UE, of one point charge q at position r in the presence of a point charge Q, taking an infinite separation between the charges as the reference position, is:\n\nwhere \n  \n    \n      \n        \n          k\n          \n            e\n          \n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle k_{\\text{e}}={\\frac {1}{4\\pi \\varepsilon _{0}}}}\n   is the Coulomb constant, r is the distance between the point charges q and Q, and q and Q are the charges (not the absolute values of the charges\u2014i.e., an electron would have a negative value of charge when placed in the formula). The following outline of proof states the derivation from the definition of electric potential energy and Coulomb's law to this formula.\n\n\n=== One point charge q in the presence of n point charges Qi ===\n\nThe electrostatic potential energy, UE, of one point charge q in the presence of n point charges Qi, taking an infinite separation between the charges as the reference position, is:\n\nwhere \n  \n    \n      \n        \n          k\n          \n            e\n          \n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle k_{\\text{e}}={\\frac {1}{4\\pi \\varepsilon _{0}}}}\n   is the Coulomb constant, ri is the distance between the point charges q and Qi, and q and Qi are the assigned values of the charges.\n\n\n== Electrostatic potential energy stored in a system of point charges ==\nThe electrostatic potential energy UE stored in a system of N charges q1, q2, \u2026, qN at positions r1, r2, \u2026, rN respectively, is:\n\nwhere, for each i value, \u03a6(ri) is the electrostatic potential due to all point charges except the one at ri, and is equal to:\n\nwhere rij is the distance between qi and qj.\n\n\n=== Energy stored in a system of one point charge ===\nThe electrostatic potential energy of a system containing only one point charge is zero, as there are no other sources of electrostatic force against which an external agent must do work in moving the point charge from infinity to its final location.\nA common question arises concerning the interaction of a point charge with its own electrostatic potential. Since this interaction doesn't act to move the point charge itself, it doesn't contribute to the stored energy of the system.\n\n\n=== Energy stored in a system of two point charges ===\nConsider bringing a point charge, q, into its final position near a point charge, Q1. The electric potential \u03a6(r) due to Q1 is\n\nHence we obtain, the electrostatic potential energy of q in the potential of Q1 as\n\nwhere r1 is the separation between the two point charges.\n\n\n=== Energy stored in a system of three point charges ===\nThe electrostatic potential energy of a system of three charges should not be confused with the electrostatic potential energy of Q1 due to two charges Q2 and Q3, because the latter doesn't include the electrostatic potential energy of the system of the two charges Q2 and Q3.\nThe electrostatic potential energy stored in the system of three charges is:\n\n\n== Energy stored in an electrostatic field distribution in vacuum ==\nThe energy density, or energy per unit volume, \n  \n    \n      \n        \n          \n            \n              d\n              U\n            \n            \n              d\n              V\n            \n          \n        \n      \n    \n    {\\textstyle {\\frac {dU}{dV}}}\n  , of the electrostatic field of a continuous charge distribution is:\n\n\n== Energy stored in electronic elements ==\n\nSome elements in a circuit can convert energy from one form to another. For example, a resistor converts electrical energy to heat. This is known as the Joule effect. A capacitor stores it in its electric field. The total electrostatic potential energy stored in a capacitor is given by\n\nwhere C is the capacitance, V is the electric potential difference, and Q the charge stored in the capacitor.\n\nThe total electrostatic potential energy may also be expressed in terms of the electric field in the form\n\nwhere \n  \n    \n      \n        \n          D\n        \n      \n    \n    {\\displaystyle \\mathrm {D} }\n   is the electric displacement field within a dielectric material and integration is over the entire volume of the dielectric.\n(A virtual experiment based on the energy transfert between capacitor plates reveals that an additional term must be taken into account when the electrostatic energy is expressed in terms of the electric field and displacement vectors .  \nWhile this extra energy cancels when dealing with insulators, in general it cannot be ignored, as for instance with semiconductors.) \nThe total electrostatic potential energy stored within a charged dielectric may also be expressed in terms of a continuous volume charge, \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n  ,\n\nwhere integration is over the entire volume of the dielectric.\nThese latter two expressions are valid only for cases when the smallest increment of charge is zero (\n  \n    \n      \n        d\n        q\n        \u2192\n        0\n      \n    \n    {\\displaystyle dq\\to 0}\n  ) such as dielectrics in the presence of metallic electrodes or dielectrics containing many charges.\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n Media related to Electric potential energy at Wikimedia Commons", "Coulomb's_law": "Coulomb's inverse-square law, or simply Coulomb's law, is an experimental law of physics that quantifies the amount of force between two stationary, electrically charged particles. The electric force between charged bodies at rest is conventionally called electrostatic force or Coulomb force. Although the law was known earlier, it was first published in 1785 by French physicist Charles-Augustin de Coulomb, hence the name. Coulomb's law was essential to the development of the theory of electromagnetism, maybe even its starting point, as it made it possible to discuss the quantity of electric charge in a meaningful way.The law states that the magnitude of the electrostatic force of attraction or repulsion between two point charges is directly proportional to the product of the magnitudes of charges and inversely proportional to the square of the distance between them. Coulomb studied the repulsive force between bodies having electrical charges of the same sign:\n\nIt follows therefore from these three tests, that the repulsive force that the two balls \u2013 [that were] electrified with the same kind of electricity \u2013 exert on each other, follows the inverse proportion of the square of the distance.\nCoulomb also showed that oppositely charged bodies obey an inverse-square law of attraction:\n\nHere, ke is the Coulomb constant (ke \u2248 8.988\u00d7109 N\u22c5m2\u22c5C\u22122), q1 and q2 are the assigned magnitudes of the charges, and the scalar r is the distance between the charges.\nThe force is along the straight line joining the two charges. If the charges have the same sign, the electrostatic force between them is repulsive; if they have different signs, the force between them is attractive.\nBeing an inverse-square law, the law is analogous to Isaac Newton's inverse-square law of universal gravitation, but gravitational forces are always attractive, while electrostatic forces can be attractive or repulsive. Coulomb's law can be used to derive Gauss's law, and vice versa. In the case of a single stationary point charge, the two laws are equivalent, expressing the same physical law in different ways. The law has been tested extensively, and observations have upheld the law on the scale from 10\u221216 m to 108 m.\n\n\n== History ==\n\nAncient cultures around the Mediterranean knew that certain objects, such as rods of amber, could be rubbed with cat's fur to attract light objects like feathers and pieces of paper. Thales of Miletus made the first recorded description of static electricity around 600 BC, when he noticed that friction could render a piece of amber magnetic.In 1600, English scientist William Gilbert made a careful study of electricity and magnetism, distinguishing the lodestone effect from static electricity produced by rubbing amber. He coined the New Latin word electricus (\"of amber\" or \"like amber\", from \u1f24\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd [elektron], the Greek word for \"amber\") to refer to the property of attracting small objects after being rubbed. This association gave rise to the English words \"electric\" and \"electricity\", which made their first appearance in print in Thomas Browne's Pseudodoxia Epidemica of 1646.Early investigators of the 18th century who suspected that the electrical force diminished with distance as the force of gravity did (i.e., as the inverse square of the distance) included Daniel Bernoulli and Alessandro Volta, both of whom measured the force between plates of a capacitor, and Franz Aepinus who supposed the inverse-square law in 1758.Based on experiments with electrically charged spheres, Joseph Priestley of England was among the first to propose that electrical force followed an inverse-square law, similar to Newton's law of universal gravitation. However, he did not generalize or elaborate on this. In 1767, he conjectured that the force between charges varied as the inverse square of the distance.\n\nIn 1769, Scottish physicist John Robison announced that, according to his measurements, the force of repulsion between two spheres with charges of the same sign varied as x\u22122.06.In the early 1770s, the dependence of the force between charged bodies upon both distance and charge had already been discovered, but not published, by Henry Cavendish of England. In his notes, Cavendish wrote, \"We may therefore conclude that the electric attraction and repulsion must be inversely as some power of the distance between that of the 2 + 1\u204450 th and that of the 2 \u2212 1\u204450 th, and there is no reason to think that it differs at all from the inverse duplicate ratio\".\nFinally, in 1785, the French physicist Charles-Augustin de Coulomb published his first three reports of electricity and magnetism where he stated his law. This publication was essential to the development of the theory of electromagnetism. He used a torsion balance to study the repulsion and attraction forces of charged particles, and determined that the magnitude of the electric force between two point charges is directly proportional to the product of the charges and inversely proportional to the square of the distance between them.\nThe torsion balance consists of a bar suspended from its middle by a thin fiber. The fiber acts as a very weak torsion spring. In Coulomb's experiment, the torsion balance was an insulating rod with a metal-coated ball attached to one end, suspended by a silk thread. The ball was charged with a known charge of static electricity, and a second charged ball of the same polarity was brought near it. The two charged balls repelled one another, twisting the fiber through a certain angle, which could be read from a scale on the instrument. By knowing how much force it took to twist the fiber through a given angle, Coulomb was able to calculate the force between the balls and derive his inverse-square proportionality law.\n\n\n== Scalar form ==\nCoulomb's law can be stated as a simple mathematical expression. The scalar form gives the magnitude of the vector of the electrostatic force F between two point charges q1 and q2, but not its direction. If r is the distance between the charges, the magnitude of the force is\n\nThe constant ke is called the Coulomb constant and is equal to 1/4\u03c0\u03b50, where \u03b50 is the electric constant; ke \u2248 8.988\u00d7109 N\u22c5m2\u22c5C\u22122. If the product q1q2 is positive, the force between the two charges is repulsive; if the product is negative, the force between them is attractive.\n\n\n== Vector form ==\n\nCoulomb's law in vector form states that the electrostatic force \n  \n    \n      \n        \n          \n            F\n          \n          \n            1\n          \n        \n      \n    \n    {\\textstyle \\mathbf {F} _{1}}\n   experienced by a charge, \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n   at position \n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{1}}\n  , in the vicinity of another charge, \n  \n    \n      \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{2}}\n   at position \n  \n    \n      \n        \n          \n            r\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{2}}\n  , in a vacuum is equal to\nwhere \n  \n    \n      \n        \n          \n            r\n          \n          \n            12\n          \n        \n        =\n        \n          \n            r\n          \n          \n            1\n          \n        \n        \u2212\n        \n          \n            r\n          \n          \n            2\n          \n        \n      \n    \n    {\\textstyle {\\boldsymbol {r}}_{12}={\\boldsymbol {r}}_{1}-{\\boldsymbol {r}}_{2}}\n   is the vectorial distance between the charges, \n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                ^\n              \n            \n          \n          \n            12\n          \n        \n        =\n        \n          \n            \n              \n                r\n              \n              \n                12\n              \n            \n            \n              \n                |\n              \n              \n                \n                  r\n                \n                \n                  12\n                \n              \n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\textstyle {\\widehat {\\mathbf {r} }}_{12}={\\frac {\\mathbf {r} _{12}}{|\\mathbf {r} _{12}|}}}\n   a unit vector pointing from \n  \n    \n      \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\textstyle q_{2}}\n   to \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\textstyle q_{1}}\n  , and \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   the electric constant. Here, \n  \n    \n      \n        \n          \n            \n              \n                r\n                ^\n              \n            \n          \n          \n            12\n          \n        \n      \n    \n    {\\textstyle \\mathbf {\\hat {r}} _{12}}\n   is used for the vector notation.\nThe vector form of Coulomb's law is simply the scalar definition of the law with the direction given by the unit vector, \n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                ^\n              \n            \n          \n          \n            12\n          \n        \n      \n    \n    {\\textstyle {\\widehat {\\mathbf {r} }}_{12}}\n  , parallel with the line from charge \n  \n    \n      \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{2}}\n   to charge \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n  . If both charges have the same sign (like charges) then the product \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{1}q_{2}}\n   is positive and the direction of the force on \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n   is given by \n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                ^\n              \n            \n          \n          \n            12\n          \n        \n      \n    \n    {\\textstyle {\\widehat {\\mathbf {r} }}_{12}}\n  ; the charges repel each other. If the charges have opposite signs then the product \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{1}q_{2}}\n   is negative and the direction of the force on \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle q_{1}}\n   is \n  \n    \n      \n        \u2212\n        \n          \n            \n              \n                \n                  r\n                \n                ^\n              \n            \n          \n          \n            12\n          \n        \n      \n    \n    {\\textstyle -{\\hat {\\mathbf {r} }}_{12}}\n  ; the charges attract each other.\nThe electrostatic force \n  \n    \n      \n        \n          \n            F\n          \n          \n            2\n          \n        \n      \n    \n    {\\textstyle \\mathbf {F} _{2}}\n   experienced by \n  \n    \n      \n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{2}}\n  , according to Newton's third law, is \n  \n    \n      \n        \n          \n            F\n          \n          \n            2\n          \n        \n        =\n        \u2212\n        \n          \n            F\n          \n          \n            1\n          \n        \n      \n    \n    {\\textstyle \\mathbf {F} _{2}=-\\mathbf {F} _{1}}\n  .\n\n\n=== System of discrete charges ===\nThe law of superposition allows Coulomb's law to be extended to include any number of point charges. The force acting on a point charge due to a system of point charges is simply the vector addition of the individual forces acting alone on that point charge due to each one of the charges. The resulting force vector is parallel to the electric field vector at that point, with that point charge removed.\nForce \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\textstyle \\mathbf {F} }\n   on a small charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   at position \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\textstyle \\mathbf {r} }\n  , due to a system of \n  \n    \n      \n        N\n      \n    \n    {\\textstyle N}\n   discrete charges in vacuum is\nwhere \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n   and \n  \n    \n      \n        \n          \n            r\n          \n          \n            i\n          \n        \n      \n    \n    {\\textstyle \\mathbf {r} _{i}}\n   are the magnitude and position respectively of the ith charge, \n  \n    \n      \n        \n          \n            \n              \n                \n                  R\n                \n                ^\n              \n            \n          \n          \n            i\n          \n        \n      \n    \n    {\\textstyle {\\hat {\\mathbf {R} }}_{i}}\n   is a unit vector in the direction of \n  \n    \n      \n        \n          \n            R\n          \n          \n            i\n          \n        \n        =\n        \n          r\n        \n        \u2212\n        \n          \n            r\n          \n          \n            i\n          \n        \n      \n    \n    {\\textstyle \\mathbf {R} _{i}=\\mathbf {r} -\\mathbf {r} _{i}}\n  , a vector pointing from charges \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n   to \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  .\n\n\n=== Continuous charge distribution ===\nIn this case, the principle of linear superposition is also used. For a continuous charge distribution, an integral over the region containing the charge is equivalent to an infinite summation, treating each infinitesimal element of space as a point charge \n  \n    \n      \n        d\n        q\n      \n    \n    {\\displaystyle dq}\n  . The distribution of charge is usually linear, surface or volumetric.\nFor a linear charge distribution (a good approximation for charge in a wire) where \n  \n    \n      \n        \u03bb\n        (\n        \n          \n            r\n          \n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle \\lambda (\\mathbf {r} ')}\n   gives the charge per unit length at position \n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {r} '}\n  , and \n  \n    \n      \n        d\n        \n          \u2113\n          \u2032\n        \n      \n    \n    {\\displaystyle d\\ell '}\n   is an infinitesimal element of length,\nFor a surface charge distribution (a good approximation for charge on a plate in a parallel plate capacitor) where \n  \n    \n      \n        \u03c3\n        (\n        \n          \n            r\n          \n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle \\sigma (\\mathbf {r} ')}\n   gives the charge per unit area at position \n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {r} '}\n  , and \n  \n    \n      \n        d\n        \n          A\n          \u2032\n        \n      \n    \n    {\\displaystyle dA'}\n   is an infinitesimal element of area,\n\nFor a volume charge distribution (such as charge within a bulk metal) where \n  \n    \n      \n        \u03c1\n        (\n        \n          \n            r\n          \n          \u2032\n        \n        )\n      \n    \n    {\\displaystyle \\rho (\\mathbf {r} ')}\n   gives the charge per unit volume at position \n  \n    \n      \n        \n          \n            r\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {r} '}\n  , and \n  \n    \n      \n        d\n        \n          V\n          \u2032\n        \n      \n    \n    {\\displaystyle dV'}\n   is an infinitesimal element of volume,\nThe force on a small test charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   at position \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {r}}}\n   in vacuum is given by the integral over the distribution of charge\n\nwhere it the \"continuous charge\" version of Coulomb's law is never supposed to be applied to locations for which \n  \n    \n      \n        \n          |\n        \n        \n          r\n        \n        \u2212\n        \n          \n            r\n            \u2032\n          \n        \n        \n          |\n        \n        =\n        0\n      \n    \n    {\\displaystyle |\\mathbf {r} -\\mathbf {r'} |=0}\n   because that location would directly overlap with the location of a charged particle (e.g. electron or proton) which is not a valid location to analyze the electric field or potential classically. Charge is always discrete in reality, and the \"continuous charge\" assumption is just an approximation that is not supposed to allow \n  \n    \n      \n        \n          |\n        \n        \n          r\n        \n        \u2212\n        \n          \n            r\n            \u2032\n          \n        \n        \n          |\n        \n        =\n        0\n      \n    \n    {\\displaystyle |\\mathbf {r} -\\mathbf {r'} |=0}\n   to be analyzed.\n\n\n== Coulomb constant ==\n\nThe Coulomb constant is a proportionality factor that appears in Coulomb's law as well as in other electric-related formulas. Denoted \n  \n    \n      \n        \n          k\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle k_{\\text{e}}}\n  , it is also called the electric force constant or electrostatic constant hence the subscript \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  . When the electromagnetic theory is expressed in the International System of Units, force is measured in newtons, charge in coulombs and distance in meters. The Coulomb constant is given by \n  \n    \n      \n        \n          k\n          \n            e\n          \n        \n        =\n        \n          \n            1\n            \n              4\n              \u03c0\n              \n                \u03b5\n                \n                  0\n                \n              \n            \n          \n        \n      \n    \n    {\\textstyle k_{\\text{e}}={\\frac {1}{4\\pi \\varepsilon _{0}}}}\n  . The constant \n  \n    \n      \n        \n          \u03b5\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n   is the vacuum electric permittivity (also known as electric constant). It should not be confused with \n  \n    \n      \n        \n          \u03b5\n          \n            r\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{r}}\n  , which is the dimensionless relative permittivity of the material in which the charges are immersed, or with their product \n  \n    \n      \n        \n          \u03b5\n          \n            a\n          \n        \n        =\n        \n          \u03b5\n          \n            0\n          \n        \n        \n          \u03b5\n          \n            r\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{a}=\\varepsilon _{0}\\varepsilon _{r}}\n  , which is called \"absolute permittivity of the material\" and is still used in electrical engineering.\nPrior to the 2019 redefinition of the SI base units, the Coulomb constant was considered to have an exact value:\n\nSince the 2019 redefinition, the Coulomb constant is no longer exactly defined and is subject to the measurement error in the fine structure constant. As calculated from CODATA 2018 recommended values, the Coulomb constant is\nWith electric charge defined as in the Gaussian and Heaviside\u2013Lorentz systems, the corresponding constant has different, dimensionless values.\nIn the Gaussian system (as for the electrostatic system), the unit charge (esu or statcoulomb) is defined in such a way that the Coulomb constant disappears, as it has the value of one and becomes dimensionless:\nIn the Heaviside\u2013Lorentz system, also called rationalized units, the Coulomb constant is dimensionless:\n\n\n== Limitations ==\nThere are three conditions to be fulfilled for the validity of Coulomb's inverse square law:\nThe charges must have a spherically symmetric distribution (e.g. be point charges, or a charged metal sphere).\nThe charges must not overlap (e.g. they must be distinct point charges).\nThe charges must be stationary with respect to each other.The last of these is known as the electrostatic approximation. When movement takes place, Einstein's theory of relativity must be taken into consideration, and a result, an extra factor is introduced, which alters the force produced on the two objects. This extra part of the force is called the magnetic force, and is described by magnetic fields. For slow movement, the magnetic force is minimal and Coulomb's law can still be considered approximately correct, but when the charges are moving more quickly in relation to each other, the full electrodynamics rules (incorporating the magnetic force) must be considered.\n\n\n== Electric field ==\n\nAn electric field is a vector field that associates to each point in space the Coulomb force experienced by a unit test charge. The strength and direction of the Coulomb force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\textstyle \\mathbf {F} }\n   on a charge \n  \n    \n      \n        \n          q\n          \n            t\n          \n        \n      \n    \n    {\\textstyle q_{t}}\n   depends on the electric field \n  \n    \n      \n        \n          E\n        \n      \n    \n    {\\textstyle \\mathbf {E} }\n   established by other charges that it finds itself in, such that \n  \n    \n      \n        \n          F\n        \n        =\n        \n          q\n          \n            t\n          \n        \n        \n          E\n        \n      \n    \n    {\\textstyle \\mathbf {F} =q_{t}\\mathbf {E} }\n  . In the simplest case, the field is considered to be generated solely by a single source point charge. More generally, the field can be generated by a distribution of charges who contribute to the overall by the principle of superposition.\nIf the field is generated by a positive source point charge \n  \n    \n      \n        q\n      \n    \n    {\\textstyle q}\n  , the direction of the electric field points along lines directed radially outwards from it, i.e. in the direction that a positive point test charge \n  \n    \n      \n        \n          q\n          \n            t\n          \n        \n      \n    \n    {\\textstyle q_{t}}\n   would move if placed in the field. For a negative point source charge, the direction is radially inwards.\nThe magnitude of the electric field E can be derived from Coulomb's law. By choosing one of the point charges to be the source, and the other to be the test charge, it follows from Coulomb's law that the magnitude of the electric field E created by a single source point charge Q at a certain distance from it r in vacuum is given by\n\nA system N of charges \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n   stationed at \n  \n    \n      \n        \n          \n            r\n          \n          \n            i\n          \n        \n      \n    \n    {\\textstyle \\mathbf {r} _{i}}\n   produces an electric field whose magnitude and direction is, by superposition\n\n\n== Atomic forces ==\n\nCoulomb's law holds even within atoms, correctly describing the force between the positively charged atomic nucleus and each of the negatively charged electrons. This simple law also correctly accounts for the forces that bind atoms together to form molecules and for the forces that bind atoms and molecules together to form solids and liquids. Generally, as the distance between ions increases, the force of attraction, and binding energy, approach zero and ionic bonding is less favorable. As the magnitude of opposing charges increases, energy increases and ionic bonding is more favorable.\n\n\n== Relation to Gauss's law ==\n\n\n=== Deriving Gauss's law from Coulomb's law ===\nGauss's law can be derived from Coulomb's law and the assumption that electric field obeys the superposition principle, which says that the resulting field is the vector sum of fields generated by each particle (or the integral, if the charges are distributed in a region of space).\n\nNote that since Coulomb's law only applies to stationary charges, there is no reason to expect Gauss's law to hold for moving charges based on this derivation alone. In fact, Gauss's law does hold for moving charges, and in this respect Gauss's law is more general than Coulomb's law.\n\n\n=== Deriving Coulomb's law from Gauss's law ===\nStrictly speaking, Coulomb's law cannot be derived from Gauss's law alone, since Gauss's law does not give any information regarding the curl of E (see Helmholtz decomposition and Faraday's law). However, Coulomb's law can be proven from Gauss's law if it is assumed, in addition, that the electric field from a point charge is spherically symmetric (this assumption, like Coulomb's law itself, is exactly true if the charge is stationary, and approximately true if the charge is in motion).\n\n\n== In relativity ==\nCoulomb's law can be used to gain insight into the form of the magnetic field generated by moving charges since by special relativity, in certain cases the magnetic field can be shown to be a transformation of forces caused by the electric field. When no acceleration is involved in a particle's history, Coulomb's law can be assumed on any test particle in its own inertial frame, supported by symmetry arguments in solving Maxwell's equation, shown above. Coulomb's law can be expanded to moving test particles to be of the same form. This assumption can be justified by obtaining the correct form of field equations, that is with respect to agreement with Maxwell's equations. Considering the charge to be invariant of observer, the electric and magnetic fields of a uniformly moving point charge can hence be derived by the Lorentz transformation of the four force on the test charge in the charge's frame of reference, given by Coulomb's law and attributing magnetic and electric fields by their definitions given by the form of Lorentz force. The fields hence found for uniformly moving point charges are given by:where \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the charge of the point source, \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is the position vector from the point source to the point in space, \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   is the velocity vector of the charged particle, \n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n   is the ratio of speed of the charged particle divided by the speed of light and \n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   and \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n  .\nThis form of solutions need not obey Newton's third law as is the case in the framework of special relativity (yet without violating relativistic-energy momentum conservation). Note that the expression for electric field reduces to Coulomb's law for non-relativistic speeds of the point charge and that the magnetic field in non-relativistic limit (approximating \n  \n    \n      \n        \u03b2\n        \u226a\n        1\n      \n    \n    {\\displaystyle \\beta \\ll 1}\n  ) can be applied to electric currents to get the Biot\u2013Savart law. These solutions, when expressed in retarded time also correspond to the general solution of Maxwell's equations given by solutions of Li\u00e9nard\u2013Wiechert potential, due to the validity of Coulomb's law within its specific range of application. Also note that the spherical symmetry for gauss law on stationary charges is not valid for moving charges owing to the breaking of symmetry by the specification of direction of velocity in the problem. Agreement with Maxwell's equations can also be manually verified for the above two equations.\n\n\n== Coulomb potential ==\n\n\n=== Quantum field theory ===\n\nThe Coulomb potential admits continuum states (with E > 0), describing electron-proton scattering, as well as discrete bound states, representing the hydrogen atom. It can also be derived within the non-relativistic limit between two charged particles, as follows:\nUnder Born approximation, in non-relativistic quantum mechanics, the scattering amplitude \n  \n    \n      \n        \n          \n            A\n          \n        \n        (\n        \n          |\n        \n        \n          p\n        \n        \u27e9\n        \u2192\n        \n          |\n        \n        \n          \n            p\n          \n          \u2032\n        \n        \u27e9\n        )\n      \n    \n    {\\textstyle {\\mathcal {A}}(|\\mathbf {p} \\rangle \\to |\\mathbf {p} '\\rangle )}\n   is:\n\nThis is to be compared to the:\n\nwhere we look at the (connected) S-matrix entry for two electrons scattering off each other, treating one with \"fixed\" momentum as the source of the potential, and the other scattering off that potential.\nUsing the Feynman rules to compute the S-matrix element, we obtain in the non-relativistic limit with \n  \n    \n      \n        \n          m\n          \n            0\n          \n        \n        \u226b\n        \n          |\n        \n        \n          p\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle m_{0}\\gg |\\mathbf {p} |}\n  \n\nComparing with the QM scattering, we have to discard the \n  \n    \n      \n        (\n        2\n        m\n        \n          )\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (2m)^{2}}\n   as they arise due to differing normalizations of momentum eigenstate in QFT compared to QM and obtain:\n\nwhere Fourier transforming both sides, solving the integral and taking \n  \n    \n      \n        \u03b5\n        \u2192\n        0\n      \n    \n    {\\displaystyle \\varepsilon \\to 0}\n   at the end will yield\n\nas the Coulomb potential.However, the equivalent results of the classical Born derivations for the Coulomb problem are thought to be strictly accidental.The Coulomb potential, and its derivation, can be seen as a special case of the Yukawa potential, which is the case where the exchanged boson \u2013 the photon \u2013 has no rest mass.\n\n\n== Simple experiment to verify Coulomb's law ==\n\nIt is possible to verify Coulomb's law with a simple experiment. Consider two small spheres of mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   and same-sign charge \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  , hanging from two ropes of negligible mass of length \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  . The forces acting on each sphere are three: the weight \n  \n    \n      \n        m\n        g\n      \n    \n    {\\displaystyle mg}\n  , the rope tension \n  \n    \n      \n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbf {T} }\n   and the electric force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n  . In the equilibrium state: \n\nand\n\nDividing (1) by (2):\n\nLet \n  \n    \n      \n        \n          \n            L\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {L} _{1}}\n   be the distance between the charged spheres; the repulsion force between them \n  \n    \n      \n        \n          \n            F\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} _{1}}\n  , assuming Coulomb's law is correct, is equal to\n\nso:\n\nIf we now discharge one of the spheres, and we put it in contact with the charged sphere, each one of them acquires a charge \n  \n    \n      \n        \n          \n            q\n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {q}{2}}}\n  . In the equilibrium state, the distance between the charges will be \n  \n    \n      \n        \n          \n            L\n          \n          \n            2\n          \n        \n        <\n        \n          \n            L\n          \n          \n            1\n          \n        \n      \n    \n    {\\textstyle \\mathbf {L} _{2}<\\mathbf {L} _{1}}\n   and the repulsion force between them will be:\n\nWe know that \n  \n    \n      \n        \n          \n            F\n          \n          \n            2\n          \n        \n        =\n        m\n        g\n        tan\n        \u2061\n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} _{2}=mg\\tan \\theta _{2}}\n   and:\n\nDividing (4) by (5), we get: \n\nMeasuring the angles \n  \n    \n      \n        \n          \u03b8\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\theta _{1}}\n   and \n  \n    \n      \n        \n          \u03b8\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\theta _{2}}\n   and the distance between the charges \n  \n    \n      \n        \n          \n            L\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {L} _{1}}\n   and \n  \n    \n      \n        \n          \n            L\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {L} _{2}}\n   is sufficient to verify that the equality is true taking into account the experimental error. In practice, angles can be difficult to measure, so if the length of the ropes is sufficiently great, the angles will be small enough to make the following approximation:\n\nUsing this approximation, the relationship (6) becomes the much simpler expression:\n\nIn this way, the verification is limited to measuring the distance between the charges and checking that the division approximates the theoretical value.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Related reading ==\nCoulomb, Charles Augustin (1788) [1785]. \"Premier m\u00e9moire sur l'\u00e9lectricit\u00e9 et le magn\u00e9tisme\". Histoire de l'Acad\u00e9mie Royale des Sciences. Imprimerie Royale. pp. 569\u2013577.\nCoulomb, Charles Augustin (1788) [1785]. \"Second m\u00e9moire sur l'\u00e9lectricit\u00e9 et le magn\u00e9tisme\". Histoire de l'Acad\u00e9mie Royale des Sciences. Imprimerie Royale. pp. 578\u2013611.\nCoulomb, Charles Augustin (1788) [1785]. \"Troisi\u00e8me m\u00e9moire sur l'\u00e9lectricit\u00e9 et le magn\u00e9tisme\". Histoire de l'Acad\u00e9mie Royale des Sciences. Imprimerie Royale. pp. 612\u2013638.\nGriffiths, David J. (1999). Introduction to Electrodynamics (3rd ed.). Prentice Hall. ISBN 978-0-13-805326-0.\nTamm, Igor E. (1979) [1976]. Fundamentals of the Theory of Electricity (9th ed.). Moscow: Mir. pp. 23\u201327.\nTipler, Paul A.; Mosca, Gene (2008). Physics for Scientists and Engineers (6th ed.). New York: W. H. Freeman and Company. ISBN 978-0-7167-8964-2. LCCN 2007010418.\nYoung, Hugh D.; Freedman, Roger A. (2010). Sears and Zemansky's University Physics: With Modern Physics (13th ed.). Addison-Wesley (Pearson). ISBN 978-0-321-69686-1.\n\n\n== External links ==\n\nCoulomb's Law on Project PHYSNET\nElectricity and the Atom\u2014a chapter from an online textbook\nA maze game for teaching Coulomb's law\u2014a game created by the Molecular Workbench software\nElectric Charges, Polarization, Electric Force, Coulomb's Law Walter Lewin, 8.02 Electricity and Magnetism, Spring 2002: Lecture 1 (video). MIT OpenCourseWare. License: Creative Commons Attribution-Noncommercial-Share Alike.", "Collision": "In physics, a collision is any event in which two or more bodies exert forces on each other in a relatively short time. Although the most common use of the word collision refers to incidents in which two or more objects collide with great force, the scientific use of the term implies nothing about the magnitude of the force.Some examples of physical interactions that scientists would consider collisions are the following:\n\nWhen an insect lands on a plant's leaf, its legs are said to collide with the leaf.\nWhen a cat strides across a lawn, each contact that its paws make with the ground is considered a collision, as well as each brush of its fur against a blade of grass.\nWhen a boxer throws a punch, their fist is said to collide with the opponents  body.\nWhen an astronomical object merges with a black hole, they are considered to collide.Some colloquial uses of the word collision are the following:\n\nA traffic collision involves at least one automobile.\nA mid-air collision occurs between airplanes.\nA ship collision accurately involves at least two moving maritime vessels hitting each other; the related term, allision, describes when a moving ship strikes a stationary object (often, but not always, another ship).In physics, collisions can be classified by the change in the total kinetic energy of the system before and after the collision:\n\nIf most or all of the total kinetic energy is lost (dissipated as heat, sound, etc. or absorbed by the objects themselves), the collision is said to be inelastic; such collisions involve objects coming to a full stop. An example of such a collision is a car crash, as cars crumple inward when crashing, rather than bouncing off of each other. This is by design, for the safety of the occupants and bystanders should a crash occur - the frame of the car absorbs the energy of the crash instead.\nIf most of the kinetic energy is conserved (i.e. the objects continue moving afterwards), the collision is said to be elastic. An example of this is a baseball bat hitting a baseball - the kinetic energy of the bat is transferred to the ball, greatly increasing the ball's velocity. The sound of the bat hitting the ball represents the loss of energy.\nAnd if all of the total kinetic energy is conserved (i.e. no energy is released as sound, heat, etc.), the collision is said to be perfectly elastic. Such a system is an idealization and cannot occur in reality, due to the second law of thermodynamics.\n\n\n== Physics ==\n\nCollision is short-duration interaction between two bodies or more than two bodies simultaneously causing change in motion of bodies involved due to internal forces acted between them during this. Collisions involve forces (there is a change in velocity). The magnitude of the velocity difference just before impact is called the closing speed. All collisions conserve momentum.  What distinguishes different types of collisions is whether they also conserve kinetic energy. The line of impact is the line that is collinear to the common normal of the surfaces that are closest or in contact during impact.  This is the line along which internal force of collision acts during impact, and Newton's coefficient of restitution is defined only along this line.  Collisions are of three types:\n\nperfectly elastic collision\ninelastic collision\nperfectly inelastic collision.Specifically, collisions can either be elastic, meaning they conserve both momentum and kinetic energy, or inelastic, meaning they conserve momentum but not kinetic energy.\nAn inelastic collision is sometimes also called a plastic collision. A \"perfectly inelastic\" collision (also called a \"perfectly plastic\" collision) is a limiting case of inelastic collision in which the two bodies coalesce after impact.\nThe degree to which a collision is elastic or inelastic is quantified by the coefficient of restitution, a value that generally ranges between zero and one. A perfectly elastic collision has a coefficient of restitution of one; a perfectly inelastic collision has a coefficient of restitution of zero.\n\n\n== Types of collisions ==\nThere are two types of collisions between two bodies - 1) Head-on collisions or one-dimensional collisions - where the velocity of each body just before impact is along the line of impact, and 2) Non-head-on collisions, oblique collisions or two-dimensional collisions - where the velocity of each body just before impact is not along the line of impact.\nAccording to the coefficient of restitution, there are two special cases of any collision as written below:\n\nA perfectly elastic collision is defined as one in which there is no loss of kinetic energy in the collision. In reality, any macroscopic collision between objects will convert some kinetic energy to internal energy and other forms of energy, so no large-scale impacts are perfectly elastic. However, some problems are sufficiently close to perfectly elastic that they can be approximated as such. In this case, the coefficient of restitution equals one.\nAn inelastic collision is one in which part of the kinetic energy is changed to some other form of energy in the collision. Momentum is conserved in inelastic collisions (as it is for elastic collisions), but one cannot track the kinetic energy through the collision since some of it is converted to other forms of energy. In this case, coefficient of restitution is not equal to one.In any type of collision there is a phase when for a moment colliding bodies have the same velocity along the line of impact. Then the kinetic energy of bodies reduces to its minimum during this phase and may be called a maximum deformation phase for which momentarily the coefficient of restitution becomes one.\nCollisions in ideal gases approach perfectly elastic collisions, as do scattering interactions of sub-atomic particles which are deflected by the electromagnetic force. Some large-scale interactions like the slingshot type gravitational interactions between satellites and planets are almost perfectly elastic.\nCollisions between hard spheres may be nearly elastic, so it is useful to calculate the limiting case of an elastic collision. The assumption of conservation of momentum as well as the conservation of kinetic energy makes possible the calculation of the final velocities in two-body collisions.\n\n\n== Allision ==\nIn maritime law, it is occasionally desirable to distinguish between the situation of a vessel striking a moving object, and that of it striking a stationary object.  The word \"allision\" is then used to mean the striking of a stationary object, while \"collision\" is used to mean the striking of a moving object.  Thus, when two vessels run against each other, courts typically use the term collision whereas when one vessel runs against another, they typically use the term allision. The fixed object could also be a bridge or dock.  While there is no great difference between the two terms and often they are even used interchangeably, determining the difference helps clarify the circumstances of emergencies and adapt accordingly.  In the case of Vane Line Bunkering, Inc. v. Natalie D M/V, it was established that there was the presumption that the moving vessel is at fault, stating that \"presumption derives from the common-sense observation that moving vessels do not usually collide with stationary objects unless the [moving] vessel is mishandled in some way\".  This is also referred to as The Oregon Rule.\n\n\n== Analytical vs. numerical approaches towards resolving collisions ==\nRelatively few problems involving collisions can be solved analytically; the remainder require numerical methods. An important problem in simulating collisions is determining whether two objects have in fact collided. This problem is called collision detection.\n\n\n== Examples of collisions that can be solved analytically ==\n\n\n=== Billiards ===\nCollisions play an important role in cue sports. Because the collisions between billiard balls are nearly elastic, and the balls roll on a surface that produces low rolling friction, their behavior is often used to illustrate Newton's laws of motion. After a zero-friction collision of a moving ball with a stationary one of equal mass, the angle between the directions of the two balls is 90 degrees. This is an important fact that professional billiards players take into account, although it assumes the ball is moving without any impact of friction across the table rather than rolling with friction.\nConsider an elastic collision in two dimensions of any two masses m1 and m2, with respective initial velocities u1  and u2 where u2 = 0, and final velocities V1 and V2.\nConservation of momentum gives m1u1 = m1V1 + m2V2.\nConservation of energy for an elastic collision gives (1/2)m1|u1|2 = (1/2)m1|V1|2 + (1/2)m2|V2|2.\nNow consider the case m1 = m2: we obtain u1 = V1 + V2 and |u1|2 = |V1|2 + |V2|2.\nTaking the dot product of each side of the former equation with itself, |u1|2 = u1\u2022u1 = |V1|2 + |V2|2 + 2V1\u2022V2. Comparing this with the latter equation gives V1\u2022V2 = 0, so they are perpendicular unless V1 is the zero vector (which occurs if and only if the collision is head-on).\n\n\n=== Perfect inelastic collision ===\n\nIn a perfect inelastic collision, i.e., a zero coefficient of restitution, the colliding particles coalesce. It is necessary to consider conservation of momentum:\n\n  \n    \n      \n        \n          m\n          \n            a\n          \n        \n        \n          \n            u\n          \n          \n            a\n          \n        \n        +\n        \n          m\n          \n            b\n          \n        \n        \n          \n            u\n          \n          \n            b\n          \n        \n        =\n        \n          (\n          \n            \n              m\n              \n                a\n              \n            \n            +\n            \n              m\n              \n                b\n              \n            \n          \n          )\n        \n        \n          v\n        \n        \n      \n    \n    {\\displaystyle m_{a}\\mathbf {u} _{a}+m_{b}\\mathbf {u} _{b}=\\left(m_{a}+m_{b}\\right)\\mathbf {v} \\,}\n  where v is the final velocity, which is hence given by\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          \n            \n              \n                m\n                \n                  a\n                \n              \n              \n                \n                  u\n                \n                \n                  a\n                \n              \n              +\n              \n                m\n                \n                  b\n                \n              \n              \n                \n                  u\n                \n                \n                  b\n                \n              \n            \n            \n              \n                m\n                \n                  a\n                \n              \n              +\n              \n                m\n                \n                  b\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} ={\\frac {m_{a}\\mathbf {u} _{a}+m_{b}\\mathbf {u} _{b}}{m_{a}+m_{b}}}}\n  The reduction of total kinetic energy is equal to the total kinetic energy before the collision in a center of momentum frame with respect to the system of two particles, because in such a frame the kinetic energy after the collision is zero. In this frame most of the kinetic energy before the collision is that of the particle with the smaller mass. In another frame, in addition to the reduction of kinetic energy there may be a transfer of kinetic energy from one particle to the other; the fact that this depends on the frame shows how relative this is.\nWith time reversed we have the situation of two objects pushed away from each other, e.g. shooting a projectile, or a rocket applying thrust (compare the derivation of the Tsiolkovsky rocket equation).\n\n\n== Examples of collisions analyzed numerically ==\n\n\n=== Animal locomotion ===\nCollisions of an animal's foot or paw with the underlying substrate are generally termed ground reaction forces. These collisions are inelastic, as kinetic energy is not conserved. An important research topic in prosthetics is quantifying the forces generated during the foot-ground collisions associated with both disabled and non-disabled gait. This quantification typically requires subjects to walk across a force platform (sometimes called a \"force plate\") as well as detailed kinematic and dynamic (sometimes termed kinetic) analysis.\n\n\n== Collisions used as an experimental tool ==\nCollisions can be used as an experimental technique to study material properties of objects and other physical phenomena.\n\n\n=== Space exploration ===\nAn object may deliberately be made to crash-land on another celestial body, to do measurements and send them to Earth before being destroyed, or to allow instruments elsewhere to observe the effect. See e.g.:\n\nDuring Apollo 13, Apollo 14, Apollo 15, Apollo 16 and Apollo 17, the S-IVB (the rocket's third stage) was crashed into the Moon in order to perform seismic measurement used for characterizing the lunar core.\nDeep Impact\nSMART-1 - European Space Agency satellite\nMoon impact probe - ISRO probe and LCROSS with its spent Centaur Upper Stage - NASA Probe\nDouble Asteroid Redirection Test for planetary defence\n\n\n=== Mathematical description of molecular collisions ===\nLet the linear, angular and internal momenta of a molecule be given by the set of r variables { pi }. The state of a molecule may then be described by the range \u03b4wi = \u03b4p1\u03b4p2\u03b4p3 ... \u03b4pr. There are many such ranges corresponding to different states; a specific state may be denoted by the index i. Two molecules undergoing a collision can thus be denoted by (i, j) (Such an ordered pair is sometimes known as a constellation.)\nIt is convenient to suppose that two molecules exert a negligible effect on each other unless their center of gravity approach within a critical distance b. A collision therefore begins when the respective centers of gravity arrive at this critical distance, and is completed when they again reach this critical distance on their way apart. Under this model, a collision is completely described by the matrix \n  \n    \n      \n        \n          \n            (\n            \n              \n                \n                  i\n                \n                \n                  j\n                \n              \n              \n                \n                  k\n                \n                \n                  l\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\begin{pmatrix}i&j\\\\k&l\\end{pmatrix}}}\n  , which refers to the constellation (i, j) before the collision, and the (in general different) constellation (k, l) after the collision.\nThis notation is convenient in proving Boltzmann's H-theorem of statistical mechanics.\n\n\n== Attack by means of a deliberate collision ==\nTypes of attack by means of a deliberate collision include:\n\nstriking with the body: unarmed striking, punching, kicking\nstriking with a weapon, such as a sword, club or axe\nramming with an object or vehicle, e.g.:\nRam-raiding, the practice of driving a car into a building in order to break in\na battering ram, medieval weapon used for breaking down large doors, also a modern version is used by police forces during raidsAn attacking collision with a distant object can be achieved by throwing or launching a projectile.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\nTolman, R. C. (1938). The Principles of Statistical Mechanics. Oxford: Clarendon Press. Reissued (1979) New York: Dover ISBN 0-486-63896-0.\n\n\n== External links ==\nThree Dimensional Collision - Oblique inelastic collision between two homogeneous spheres.\nOne Dimensional Collision - One Dimensional Collision Flash Applet.\nTwo Dimensional Collision - Two Dimensional Collision Flash Applet.", "Scattering": "Scattering is a term used in physics to describe a wide range of physical processes where moving particles or radiation of some form, such as light or sound, are forced to deviate from a straight trajectory by localized non-uniformities (including particles and radiation) in the medium through which they pass. In conventional use, this also includes deviation of reflected radiation from the angle predicted by the law of reflection. Reflections of radiation that undergo scattering are often called diffuse reflections and unscattered reflections are called specular (mirror-like) reflections. Originally, the term was confined to light scattering (going back at least as far as Isaac Newton in the 17th century). As more \"ray\"-like phenomena were discovered, the idea of scattering was extended to them, so that William Herschel could refer to the scattering of \"heat rays\" (not then recognized as electromagnetic in nature) in 1800. John Tyndall, a pioneer in light scattering research, noted the connection between light scattering and acoustic scattering in the 1870s. Near the end of the 19th century, the scattering of cathode rays (electron beams) and X-rays was observed and discussed. With the discovery of subatomic particles (e.g. Ernest Rutherford in 1911) and the development of quantum theory in the 20th century, the sense of the term became broader as it was recognized that the same mathematical frameworks used in light scattering could be applied to many other phenomena.\nScattering can refer to the consequences of particle-particle collisions between molecules, atoms, electrons, photons and other particles. Examples include: cosmic ray scattering in the Earth's upper atmosphere; particle collisions inside particle accelerators; electron scattering by gas atoms in fluorescent lamps; and neutron scattering inside nuclear reactors.The types of non-uniformities which can cause scattering, sometimes known as scatterers or scattering centers, are too numerous to list, but a small sample includes particles, bubbles, droplets, density fluctuations in fluids, crystallites in polycrystalline solids, defects in monocrystalline solids, surface roughness, cells in organisms, and textile fibers in clothing. The effects of such features on the path of almost any type of propagating wave or moving particle can be described in the framework of scattering theory.\nSome areas where scattering and scattering theory are significant include radar sensing, medical ultrasound, semiconductor wafer inspection, polymerization process monitoring, acoustic tiling, free-space communications and computer-generated imagery. Particle-particle scattering theory is important in areas such as particle physics, atomic, molecular, and optical physics, nuclear physics and astrophysics. In Particle Physics the quantum interaction and scattering of fundamental particles is described by the Scattering Matrix or S-Matrix, introduced and developed by John Archibald Wheeler and Werner Heisenberg.Scattering is quantified using many different concepts, including scattering cross section (\u03c3), attenuation coefficients, the bidirectional scattering distribution function (BSDF), S-matrices, and mean free path.\n\n\n== Single and multiple scattering ==\n\nWhen radiation is only scattered by one localized scattering center, this is called single scattering. It is very common that scattering centers are grouped together; in such cases, radiation may scatter many times, in what is known as multiple scattering. The main difference between the effects of single and multiple scattering is that single scattering can usually be treated as a random phenomenon, whereas multiple scattering, somewhat counterintuitively, can be modeled as a more deterministic process because the combined results of a large number of scattering events tend to average out. Multiple scattering can thus often be modeled well with diffusion theory.Because the location of a single scattering center is not usually well known relative to the path of the radiation, the outcome, which tends to depend strongly on the exact incoming trajectory, appears random to an observer. This type of scattering would be exemplified by an electron being fired at an atomic nucleus. In this case, the atom's exact position relative to the path of the electron is unknown and would be unmeasurable, so the exact trajectory of the electron after the collision cannot be predicted. Single scattering is therefore often described by probability distributions.\nWith multiple scattering, the randomness of the interaction tends to be averaged out by a large number of scattering events, so that the final path of the radiation appears to be a deterministic distribution of intensity. This is exemplified by a light beam passing through thick fog. Multiple scattering is highly analogous to diffusion, and the terms multiple scattering and diffusion are interchangeable in many contexts. Optical elements designed to produce multiple scattering are thus known as diffusers. Coherent backscattering, an enhancement of backscattering that occurs when coherent radiation is multiply scattered by a random medium, is usually attributed to weak localization.\nNot all single scattering is random, however. A well-controlled laser beam can be exactly positioned to scatter off a microscopic particle with a deterministic outcome, for instance. Such situations are encountered in radar scattering as well, where the targets tend to be macroscopic objects such as people or aircraft.\nSimilarly, multiple scattering can sometimes have somewhat random outcomes, particularly with coherent radiation. The random fluctuations in the multiply scattered intensity of coherent radiation are called speckles. Speckle also occurs if multiple parts of a coherent wave scatter from different centers. In certain rare circumstances, multiple scattering may only involve a small number of interactions such that the randomness is not completely averaged out. These systems are considered to be some of the most difficult to model accurately.\nThe description of scattering and the distinction between single and multiple scattering are tightly related to wave\u2013particle duality.\n\n\n== Theory ==\nScattering theory is a framework for studying and understanding the scattering of waves and particles.  Prosaically, wave scattering corresponds to the collision and scattering of a wave with some material object, for instance (sunlight) scattered by rain drops to form a rainbow. Scattering also includes the interaction of billiard balls on a table, the Rutherford scattering (or angle change) of alpha particles by gold nuclei, the Bragg scattering (or diffraction) of electrons and X-rays by a cluster of atoms, and the inelastic scattering of a fission fragment as it traverses a thin foil. More precisely, scattering consists of the study of how solutions of partial differential equations, propagating freely \"in the distant past\", come together and interact with one another or with a boundary condition, and then propagate away \"to the distant future\".\nThe direct scattering problem is the problem of determining the distribution of scattered radiation/particle flux basing on the characteristics of the scatterer. The inverse scattering problem is the problem of determining the characteristics of an object (e.g., its shape, internal constitution) from measurement data of radiation or particles scattered from the object.\n\n\n=== Attenuation due to scattering ===\n\nWhen the target is a set of many scattering centers whose relative position varies unpredictably, it is customary to think of a range equation whose arguments take different forms in different application areas.  In the simplest case consider an interaction that removes particles from the \"unscattered beam\" at a uniform rate that is proportional to the incident number of particles per unit area per unit time (\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  ), i.e. that\n\n  \n    \n      \n        \n          \n            \n              d\n              I\n            \n            \n              d\n              x\n            \n          \n        \n        =\n        \u2212\n        Q\n        I\n        \n        \n      \n    \n    {\\displaystyle {\\frac {dI}{dx}}=-QI\\,\\!}\n  where Q is an interaction coefficient and x is the distance traveled in the target.\nThe above ordinary first-order differential equation has solutions of the form:\n\n  \n    \n      \n        I\n        =\n        \n          I\n          \n            o\n          \n        \n        \n          e\n          \n            \u2212\n            Q\n            \u0394\n            x\n          \n        \n        =\n        \n          I\n          \n            o\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \n                \n                  \u0394\n                  x\n                \n                \u03bb\n              \n            \n          \n        \n        =\n        \n          I\n          \n            o\n          \n        \n        \n          e\n          \n            \u2212\n            \u03c3\n            (\n            \u03b7\n            \u0394\n            x\n            )\n          \n        \n        =\n        \n          I\n          \n            o\n          \n        \n        \n          e\n          \n            \u2212\n            \n              \n                \n                  \u03c1\n                  \u0394\n                  x\n                \n                \u03c4\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle I=I_{o}e^{-Q\\Delta x}=I_{o}e^{-{\\frac {\\Delta x}{\\lambda }}}=I_{o}e^{-\\sigma (\\eta \\Delta x)}=I_{o}e^{-{\\frac {\\rho \\Delta x}{\\tau }}},}\n  where Io is the initial flux, path length \u0394x \u2261 x \u2212 xo, the second equality defines an interaction mean free path \u03bb, the third uses the number of targets per unit volume \u03b7 to define an area cross-section \u03c3, and the last uses the target mass density \u03c1 to define a density mean free path \u03c4.   Hence one converts between these quantities via Q = 1/\u03bb = \u03b7\u03c3 = \u03c1/\u03c4, as shown in the figure at left.\nIn electromagnetic absorption spectroscopy, for example, interaction coefficient (e.g. Q in cm\u22121) is variously called opacity, absorption coefficient, and attenuation coefficient.  In nuclear physics, area cross-sections (e.g. \u03c3 in barns or units of 10\u221224 cm2), density mean free path (e.g. \u03c4 in grams/cm2), and its reciprocal the mass attenuation coefficient (e.g. in cm2/gram) or area per nucleon are all popular, while in electron microscopy the inelastic mean free path (e.g. \u03bb in nanometers) is often discussed instead.\n\n\n=== Elastic and inelastic scattering ===\nThe term \"elastic scattering\" implies that the internal states of the scattering particles do not change, and hence they emerge unchanged from the scattering process.  In inelastic scattering, by contrast, the particles' internal state is changed, which may amount to exciting some of the electrons of a scattering atom, or the complete annihilation of a scattering particle and the creation of entirely new particles.\nThe example of scattering in quantum chemistry is particularly instructive, as the theory is reasonably complex while still having a good foundation on which to build an intuitive understanding. When two atoms are scattered off one another, one can understand them as being the bound state solutions of some differential equation.  Thus, for example, the hydrogen atom corresponds to a solution to the Schr\u00f6dinger equation with a negative inverse-power (i.e., attractive Coulombic) central potential.  The scattering of two hydrogen atoms will disturb the state of each atom, resulting in one or both becoming excited, or even ionized, representing an inelastic scattering process.\nThe term \"deep inelastic scattering\" refers to a special kind of scattering experiment in particle physics.\n\n\n=== Mathematical framework ===\nIn mathematics, scattering theory deals with a more abstract formulation of the same set of concepts. For example, if a differential equation is known to have some simple, localized solutions, and the solutions are a function of a single parameter, that parameter can take the conceptual role of time.  One then asks what might happen if two such solutions are set up far away from each other, in the \"distant past\", and are made  to move towards each other, interact (under the constraint of the differential equation) and then move apart in the \"future\".  The scattering matrix then pairs solutions in the \"distant past\" to those in the \"distant future\".\nSolutions to differential equations are often posed on manifolds. Frequently, the means to the solution requires the study of the spectrum of an operator on the manifold. As a result, the solutions often have a spectrum that can be identified with a Hilbert space, and scattering is described by a certain map, the S matrix, on Hilbert spaces.  Spaces with a discrete spectrum correspond to bound states in quantum mechanics, while a continuous spectrum is associated with scattering states.  The study of inelastic scattering then asks how discrete and continuous spectra are mixed together.\nAn important, notable development is the inverse scattering transform, central to the solution of many exactly solvable models.\n\n\n== Theoretical physics ==\n\nIn mathematical physics, scattering theory is a framework for studying and understanding the interaction or scattering of solutions to partial differential equations. In acoustics, the differential equation is the wave equation, and scattering studies how its solutions, the sound waves, scatter from solid objects or propagate through non-uniform media (such as sound waves, in sea water, coming from a submarine). In the case of classical electrodynamics, the differential equation is again the wave equation, and the scattering of light or radio waves is studied. In particle physics, the equations are those of Quantum electrodynamics, Quantum chromodynamics and the Standard Model, the solutions of which correspond to  fundamental particles.\nIn regular quantum mechanics, which includes quantum chemistry, the relevant equation is the Schr\u00f6dinger equation, although equivalent formulations, such as the Lippmann-Schwinger equation and the Faddeev equations, are also largely used. The solutions of interest describe the long-term motion of free atoms, molecules, photons, electrons, and protons. The scenario is that several particles come together from an infinite distance away. These reagents then collide, optionally reacting, getting destroyed or creating new particles. The products and unused reagents then fly away to infinity again. (The atoms and molecules are effectively particles for our purposes. Also, under everyday circumstances, only photons are being created and destroyed.) The solutions reveal which directions the products are most likely to fly off to and how quickly. They also reveal the probability of various reactions, creations, and decays occurring. There are two predominant techniques of finding solutions to scattering problems: partial wave analysis, and the Born approximation.\n\n\n== Electromagnetics ==\n\nElectromagnetic waves are one of the best known and most commonly encountered forms of radiation that undergo scattering. Scattering of light and radio waves (especially in radar) is particularly important. Several different aspects of electromagnetic scattering are distinct enough to have conventional names. Major forms of elastic light scattering (involving negligible energy transfer) are Rayleigh scattering and Mie scattering. Inelastic scattering includes Brillouin scattering, Raman scattering, inelastic X-ray scattering and Compton scattering.\nLight scattering is one of the two major physical processes that contribute to the visible appearance of most objects, the other being absorption. Surfaces described as white owe their appearance to multiple scattering of light by internal or surface inhomogeneities in the object, for example by the boundaries of transparent microscopic crystals that make up a stone or by the microscopic fibers in a sheet of paper. More generally, the gloss (or lustre or sheen) of the surface is determined by scattering. Highly scattering surfaces are described as being dull or having a matte finish, while the absence of surface scattering leads to a glossy appearance, as with polished metal or stone.\nSpectral absorption, the selective absorption of certain colors, determines the color of most objects with some modification by elastic scattering. The apparent blue color of veins in skin is a common example where both spectral absorption and scattering play important and complex roles in the coloration. Light scattering can also create color without absorption, often shades of blue, as with the sky (Rayleigh scattering), the human blue iris, and the feathers of some birds (Prum et al. 1998). However, resonant light scattering in nanoparticles can produce many different highly saturated and vibrant hues, especially when surface plasmon resonance is involved (Roqu\u00e9 et al. 2006).Models of light scattering can be divided into three domains based on a dimensionless size parameter, \u03b1 which is defined as:\n\nwhere \u03c0Dp is the circumference of a particle and \u03bb is the wavelength of incident radiation in the medium. Based on the value of \u03b1, these domains are:\n\n\u03b1 \u226a 1: Rayleigh scattering (small particle compared to wavelength of light);\n\u03b1 \u2248 1: Mie scattering (particle about the same size as wavelength of light, valid only for spheres);\n\u03b1 \u226b 1: geometric scattering (particle much larger than wavelength of light).Rayleigh scattering is a process in which electromagnetic radiation (including light) is scattered by a small spherical volume of variant refractive indexes, such as a particle, bubble, droplet, or even a density fluctuation. This effect was first modeled successfully by Lord Rayleigh, from whom it gets its name. In order for Rayleigh's model to apply, the sphere must be much smaller in diameter than the wavelength (\u03bb) of the scattered wave; typically the upper limit is taken to be about 1/10 the wavelength. In this size regime, the exact shape of the scattering center is usually not very significant and can often be treated as a sphere of equivalent volume. The inherent scattering that radiation undergoes passing through a pure gas is due to microscopic density fluctuations as the gas molecules move around, which are normally small enough in scale for Rayleigh's model to apply. This scattering mechanism is the primary cause of the blue color of the Earth's sky on a clear day, as the shorter blue wavelengths of sunlight passing overhead are more strongly scattered than the longer red wavelengths according to Rayleigh's famous 1/\u03bb4 relation. Along with absorption, such scattering is a major cause of the attenuation of radiation by the atmosphere. The degree of scattering varies as a function of the ratio of the particle diameter to the wavelength of the radiation, along with many other factors including polarization, angle, and coherence.For larger diameters, the problem of electromagnetic scattering by spheres was first solved by Gustav Mie, and scattering by spheres larger than the Rayleigh range is therefore usually known as Mie scattering. In the Mie regime, the shape of the scattering center becomes much more significant and the theory only applies well to spheres and, with some modification, spheroids and ellipsoids. Closed-form solutions for scattering by certain other simple shapes exist, but no general closed-form solution is known for arbitrary shapes.\nBoth Mie and Rayleigh scattering are considered elastic scattering processes, in which the energy (and thus wavelength and frequency) of the light is not substantially changed. However, electromagnetic radiation scattered by moving scattering centers does undergo a Doppler shift, which can be detected and used to measure the velocity of the scattering center/s in forms of techniques such as lidar and radar. This shift involves a slight change in energy.\nAt values of the ratio of particle diameter to wavelength more than about 10, the laws of geometric optics are mostly sufficient to describe the interaction of light with the particle. Mie theory can still be used for these larger spheres, but the solution often becomes numerically unwieldy.\nFor modeling of scattering in cases where the Rayleigh and Mie models do not apply such as larger, irregularly shaped particles, there are many numerical methods that can be used. The most common are finite-element methods which solve Maxwell's equations to find the distribution of the scattered electromagnetic field. Sophisticated software packages exist which allow the user to specify the refractive index or indices of the scattering feature in space, creating a 2- or sometimes 3-dimensional model of the structure. For relatively large and complex structures, these models usually require substantial execution times on a computer.\nElectrophoresis involves the migration of macromolecules under the influence of an electric field. Electrophoretic light scattering involves passing an electric field through a liquid which makes particles move. The bigger the charge is on the particles, the faster they are able to move.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nResearch group on light scattering and diffusion in complex systems\nMultiple light scattering from a photonic science point of view\nNeutron Scattering Web\nWorld directory of neutron scattering instruments\nScattering and diffraction\nOptics Classification and Indexing Scheme (OCIS), Optical Society of America, 1997\nLectures of the European school on theoretical methods for electron and positron induced chemistry, Prague, Feb. 2005\nE. Koelink, Lectures on scattering theory, Delft the Netherlands 2006", "Kinetic_energy": "In physics, the kinetic energy of an object is the form of energy that it possesses due to its motion.\nIt is defined as the work needed to accelerate a body of a given mass from rest to its stated velocity. Having gained this energy during its acceleration, the body maintains this kinetic energy unless its speed changes. The same amount of work is done by the body when decelerating from its current speed to a state of rest. Formally, a kinetic energy is any term in a system's Lagrangian which includes a derivative with respect to time and the second term in a Taylor expansion of a particle's relativistic energy. In classical mechanics, the kinetic energy of a non-rotating object of mass m traveling at a speed v is \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\textstyle {\\frac {1}{2}}mv^{2}}\n  . In relativistic mechanics, this is a good approximation only when v is much less than the speed of light.\nThe standard unit of kinetic energy is the joule, while the English unit of kinetic energy is the foot-pound.\n\n\n== History and etymology ==\nThe adjective kinetic has its roots in the Greek word \u03ba\u03af\u03bd\u03b7\u03c3\u03b9\u03c2 kinesis, meaning \"motion\". The dichotomy between kinetic energy and potential energy can be traced back to Aristotle's concepts of actuality and potentiality.The principle in classical mechanics that E \u221d mv2 was first developed by Gottfried Leibniz and Johann Bernoulli, who described kinetic energy as the living force, vis viva. Willem 's Gravesande of the Netherlands provided experimental evidence of this relationship. By dropping weights from different heights into a block of clay, Willem 's Gravesande determined that their penetration depth was proportional to the square of their impact speed. \u00c9milie du Ch\u00e2telet recognized the implications of the experiment and published an explanation.The terms kinetic energy and work in their present scientific meanings date back to the mid-19th century. Early understandings of these ideas can be attributed to Gaspard-Gustave Coriolis, who in 1829 published the paper titled Du Calcul de l'Effet des Machines outlining the mathematics of kinetic energy. William Thomson, later Lord Kelvin, is given the credit for coining the term \"kinetic energy\" c. 1849\u20131851. Rankine, who had introduced the term \"potential energy\" in 1853, and the phrase \"actual energy\" to complement it, later cites William Thomson and Peter Tait as substituting the word \"kinetic\" for \"actual\".\n\n\n== Overview ==\nEnergy occurs in many forms, including chemical energy, thermal energy, electromagnetic radiation, gravitational energy, electric energy, elastic energy, nuclear energy, and rest energy. These can be categorized in two main classes: potential energy and kinetic energy. Kinetic energy is the movement energy of an object. Kinetic energy can be transferred between objects and transformed into other kinds of energy.Kinetic energy may be best understood by examples that demonstrate how it is transformed to and from other forms of energy. For example, a cyclist uses chemical energy provided by food to accelerate a bicycle to a chosen speed. On a level surface, this speed can be maintained without further work, except to overcome air resistance and friction. The chemical energy has been converted into kinetic energy, the energy of motion, but the process is not completely efficient and produces heat within the cyclist.\nThe kinetic energy in the moving cyclist and the bicycle can be converted to other forms.  For example, the cyclist could encounter a hill just high enough to coast up, so that the bicycle comes to a complete halt at the top.  The kinetic energy has now largely been converted to gravitational potential energy that can be released by freewheeling down the other side of the hill.  Since the bicycle lost some of its energy to friction, it never regains all of its speed without additional pedaling. The energy is not destroyed; it has only been converted to another form by friction. Alternatively, the cyclist could connect a dynamo to one of the wheels and generate some electrical energy on the descent.  The bicycle would be traveling slower at the bottom of the hill than without the generator because some of the energy has been diverted into electrical energy.  Another possibility would be for the cyclist to apply the brakes, in which case the kinetic energy would be dissipated through friction as heat.\nLike any physical quantity that is a function of velocity, the kinetic energy of an object depends on the relationship between the object and the observer's frame of reference. Thus, the kinetic energy of an object is not invariant.\nSpacecraft use chemical energy to launch and gain considerable kinetic energy to reach orbital velocity.  In an entirely circular orbit, this kinetic energy remains constant because there is almost no friction in near-earth space. However, it becomes apparent at re-entry when some of the kinetic energy is converted to heat. If the orbit is elliptical or hyperbolic, then throughout the orbit kinetic and potential energy are exchanged; kinetic energy is greatest and potential energy lowest at closest approach to the earth or other massive body, while potential energy is greatest and kinetic energy the lowest at maximum distance. Disregarding loss or gain however, the sum of the kinetic and potential energy remains constant.\nKinetic energy can be passed from one object to another. In the game of billiards, the player imposes kinetic energy on the cue ball by striking it with the cue stick. If the cue ball collides with another ball, it slows down dramatically, and the ball it hit accelerates its speed as the kinetic energy is passed on to it. Collisions in billiards are effectively elastic collisions, in which kinetic energy is preserved. In inelastic collisions, kinetic energy is dissipated in various forms of energy, such as heat, sound and binding energy (breaking bound structures).\nFlywheels have been developed as a method of energy storage.  This illustrates that kinetic energy is also stored in rotational motion.\nSeveral mathematical descriptions of kinetic energy exist that describe it in the appropriate physical situation. For objects and processes in common human experience, the formula \u00bdmv\u00b2 given by Newtonian (classical) mechanics is suitable. However, if the speed of the object is comparable to the speed of light, relativistic effects become significant and the relativistic formula is used. If the object is on the atomic or sub-atomic scale, quantum mechanical effects are significant, and a quantum mechanical model must be employed.\n\n\n== Newtonian kinetic energy ==\n\n\n=== Kinetic energy of rigid bodies ===\nIn classical mechanics, the kinetic energy of a point object (an object so small that its mass can be assumed to exist at one point), or a non-rotating rigid body depends on the mass of the body as well as its speed. The kinetic energy is equal to 1/2 the product of the mass and the square of the speed. In formula form:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}={\\frac {1}{2}}mv^{2}}\n  where \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the mass and \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the speed (magnitude of the velocity) of the body. In SI units, mass is measured in kilograms, speed in metres per second, and the resulting kinetic energy is in joules.\nFor example, one would calculate the kinetic energy of an 80 kg mass (about 180 lbs) traveling at 18 metres per second (about 40 mph, or 65 km/h) as\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        \u22c5\n        80\n        \n        \n          kg\n        \n        \u22c5\n        \n          \n            (\n            \n              18\n              \n              \n                m/s\n              \n            \n            )\n          \n          \n            2\n          \n        \n        =\n        12\n        ,\n        960\n        \n        \n          J\n        \n        =\n        12.96\n        \n        \n          kJ\n        \n      \n    \n    {\\displaystyle E_{\\text{k}}={\\frac {1}{2}}\\cdot 80\\,{\\text{kg}}\\cdot \\left(18\\,{\\text{m/s}}\\right)^{2}=12,960\\,{\\text{J}}=12.96\\,{\\text{kJ}}}\n  When a person throws a ball, the person does work on it to give it speed as it leaves the hand. The moving ball can then hit something and push it, doing work on what it hits. The kinetic energy of a moving object is equal to the work required to bring it from rest to that speed, or the work the object can do while being brought to rest: net force \u00d7 displacement = kinetic energy, i.e.,\n\n  \n    \n      \n        F\n        s\n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle Fs={\\frac {1}{2}}mv^{2}}\n  Since the kinetic energy increases with the square of the speed, an object doubling its speed has four times as much kinetic energy. For example, a car traveling twice as fast as another requires four times as much distance to stop, assuming a constant braking force. As a consequence of this quadrupling, it takes four times the work to double the speed.\nThe kinetic energy of an object is related to its momentum by the equation:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            \n              p\n              \n                2\n              \n            \n            \n              2\n              m\n            \n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}={\\frac {p^{2}}{2m}}}\n  where:\n\n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   is momentum\n\n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is mass of the bodyFor the translational kinetic energy, that is the kinetic energy associated with rectilinear motion, of a rigid body with constant mass \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  , whose center of mass is moving in a straight line with speed \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  , as seen above is equal to\n\n  \n    \n      \n        \n          E\n          \n            t\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{t}}={\\frac {1}{2}}mv^{2}}\n  where:\n\n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n   is the mass of the body\n\n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the speed of the center of mass of the body.The kinetic energy of any entity depends on the reference frame in which it is measured. However, the total energy of an isolated system, i.e. one in which energy can neither enter nor leave, does not change over time in the reference frame in which it is measured. Thus, the chemical energy converted to kinetic energy by a rocket engine is divided differently between the rocket ship and its exhaust stream depending upon the chosen reference frame. This is called the Oberth effect. But the total energy of the system, including kinetic energy, fuel chemical energy, heat, etc., is conserved over time, regardless of the choice of reference frame. Different observers moving with different reference frames would however disagree on the value of this conserved energy.\nThe kinetic energy of such systems depends on the choice of reference frame: the reference frame that gives the minimum value of that energy is the center of momentum frame, i.e. the reference frame in which the total momentum of the system is zero. This minimum kinetic energy contributes to the invariant mass of the system as a whole.\n\n\n==== Derivation ====\n\n\n===== Without vectors and calculus =====\nThe work W done by a force F on an object over a distance s parallel to F equals \n\n  \n    \n      \n        W\n        =\n        F\n        \u22c5\n        s\n      \n    \n    {\\displaystyle W=F\\cdot s}\n  .Using Newton's Second Law \n\n  \n    \n      \n        F\n        =\n        m\n        a\n      \n    \n    {\\displaystyle F=ma}\n  with m the mass and a the acceleration of the object and \n\n  \n    \n      \n        s\n        =\n        \n          \n            \n              a\n              \n                t\n                \n                  2\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle s={\\frac {at^{2}}{2}}}\n  the distance traveled by the accelerated object in time t, we find with \n  \n    \n      \n        v\n        =\n        a\n        t\n      \n    \n    {\\displaystyle v=at}\n   for the velocity v of the object\n\n  \n    \n      \n        W\n        =\n        m\n        a\n        \n          \n            \n              a\n              \n                t\n                \n                  2\n                \n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              m\n              (\n              a\n              t\n              \n                )\n                \n                  2\n                \n              \n            \n            2\n          \n        \n        =\n        \n          \n            \n              m\n              \n                v\n                \n                  2\n                \n              \n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle W=ma{\\frac {at^{2}}{2}}={\\frac {m(at)^{2}}{2}}={\\frac {mv^{2}}{2}}.}\n  \n\n\n===== With vectors and calculus =====\nThe work done in accelerating a particle with mass m during the infinitesimal time interval dt is given by the dot product of force F and the infinitesimal displacement dx\n\n  \n    \n      \n        \n          F\n        \n        \u22c5\n        d\n        \n          x\n        \n        =\n        \n          F\n        \n        \u22c5\n        \n          v\n        \n        d\n        t\n        =\n        \n          \n            \n              d\n              \n                p\n              \n            \n            \n              d\n              t\n            \n          \n        \n        \u22c5\n        \n          v\n        \n        d\n        t\n        =\n        \n          v\n        \n        \u22c5\n        d\n        \n          p\n        \n        =\n        \n          v\n        \n        \u22c5\n        d\n        (\n        m\n        \n          v\n        \n        )\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} \\cdot d\\mathbf {x} =\\mathbf {F} \\cdot \\mathbf {v} dt={\\frac {d\\mathbf {p} }{dt}}\\cdot \\mathbf {v} dt=\\mathbf {v} \\cdot d\\mathbf {p} =\\mathbf {v} \\cdot d(m\\mathbf {v} )\\,,}\n  where we have assumed the relationship p = m v and the validity of Newton's Second Law. (However, also see the special relativistic derivation below.)\nApplying the product rule we see that:\n\n  \n    \n      \n        d\n        (\n        \n          v\n        \n        \u22c5\n        \n          v\n        \n        )\n        =\n        (\n        d\n        \n          v\n        \n        )\n        \u22c5\n        \n          v\n        \n        +\n        \n          v\n        \n        \u22c5\n        (\n        d\n        \n          v\n        \n        )\n        =\n        2\n        (\n        \n          v\n        \n        \u22c5\n        d\n        \n          v\n        \n        )\n        .\n      \n    \n    {\\displaystyle d(\\mathbf {v} \\cdot \\mathbf {v} )=(d\\mathbf {v} )\\cdot \\mathbf {v} +\\mathbf {v} \\cdot (d\\mathbf {v} )=2(\\mathbf {v} \\cdot d\\mathbf {v} ).}\n  Therefore, (assuming constant mass so that dm = 0), we have,\n\n  \n    \n      \n        \n          v\n        \n        \u22c5\n        d\n        (\n        m\n        \n          v\n        \n        )\n        =\n        \n          \n            m\n            2\n          \n        \n        d\n        (\n        \n          v\n        \n        \u22c5\n        \n          v\n        \n        )\n        =\n        \n          \n            m\n            2\n          \n        \n        d\n        \n          v\n          \n            2\n          \n        \n        =\n        d\n        \n          (\n          \n            \n              \n                m\n                \n                  v\n                  \n                    2\n                  \n                \n              \n              2\n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {v} \\cdot d(m\\mathbf {v} )={\\frac {m}{2}}d(\\mathbf {v} \\cdot \\mathbf {v} )={\\frac {m}{2}}dv^{2}=d\\left({\\frac {mv^{2}}{2}}\\right).}\n  Since this is a total differential (that is, it only depends on the final state, not how the particle got there), we can integrate it and call the result kinetic energy. Assuming the object was at rest at time 0, we integrate from time 0 to time t because the work done by the force to bring the object from rest to velocity v is equal to the work necessary to do the reverse:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \u222b\n          \n            0\n          \n          \n            t\n          \n        \n        \n          F\n        \n        \u22c5\n        d\n        \n          x\n        \n        =\n        \n          \u222b\n          \n            0\n          \n          \n            t\n          \n        \n        \n          v\n        \n        \u22c5\n        d\n        (\n        m\n        \n          v\n        \n        )\n        =\n        \n          \u222b\n          \n            0\n          \n          \n            t\n          \n        \n        d\n        \n          (\n          \n            \n              \n                m\n                \n                  v\n                  \n                    2\n                  \n                \n              \n              2\n            \n          \n          )\n        \n        =\n        \n          \n            \n              m\n              \n                v\n                \n                  2\n                \n              \n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}=\\int _{0}^{t}\\mathbf {F} \\cdot d\\mathbf {x} =\\int _{0}^{t}\\mathbf {v} \\cdot d(m\\mathbf {v} )=\\int _{0}^{t}d\\left({\\frac {mv^{2}}{2}}\\right)={\\frac {mv^{2}}{2}}.}\n  This equation states that the kinetic energy (Ek) is equal to the integral of the dot product of the velocity (v) of a body and the infinitesimal change of the body's momentum (p). It is assumed that the body starts with no kinetic energy when it is at rest (motionless).\n\n\n=== Rotating bodies ===\nIf a rigid body Q is rotating about any line through the center of mass then it has rotational kinetic energy (\n  \n    \n      \n        \n          E\n          \n            r\n          \n        \n        \n      \n    \n    {\\displaystyle E_{\\text{r}}\\,}\n  ) which is simply the sum of the kinetic energies of its moving parts, and is thus given by:\n\n  \n    \n      \n        \n          E\n          \n            r\n          \n        \n        =\n        \n          \u222b\n          \n            Q\n          \n        \n        \n          \n            \n              \n                v\n                \n                  2\n                \n              \n              d\n              m\n            \n            2\n          \n        \n        =\n        \n          \u222b\n          \n            Q\n          \n        \n        \n          \n            \n              (\n              r\n              \u03c9\n              \n                )\n                \n                  2\n                \n              \n              d\n              m\n            \n            2\n          \n        \n        =\n        \n          \n            \n              \u03c9\n              \n                2\n              \n            \n            2\n          \n        \n        \n          \u222b\n          \n            Q\n          \n        \n        \n          \n            r\n            \n              2\n            \n          \n        \n        d\n        m\n        =\n        \n          \n            \n              \u03c9\n              \n                2\n              \n            \n            2\n          \n        \n        I\n        =\n        \n          \n            1\n            2\n          \n        \n        I\n        \n          \u03c9\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{r}}=\\int _{Q}{\\frac {v^{2}dm}{2}}=\\int _{Q}{\\frac {(r\\omega )^{2}dm}{2}}={\\frac {\\omega ^{2}}{2}}\\int _{Q}{r^{2}}dm={\\frac {\\omega ^{2}}{2}}I={\\frac {1}{2}}I\\omega ^{2}}\n  where:\n\n\u03c9 is the body's angular velocity\nr is the distance of any mass dm from that line\n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the body's moment of inertia, equal to \n  \n    \n      \n        \n          \u222b\n          \n            Q\n          \n        \n        \n          \n            r\n            \n              2\n            \n          \n        \n        d\n        m\n      \n    \n    {\\textstyle \\int _{Q}{r^{2}}dm}\n  .(In this equation the moment of inertia must be taken about an axis through the center of mass and the rotation measured by \u03c9 must be around that axis; more general equations exist for systems where the object is subject to wobble due to its eccentric shape).\n\n\n=== Kinetic energy of systems ===\nA system of bodies may have internal kinetic energy due to the relative motion of the bodies in the system. For example, in the Solar System the planets and planetoids are orbiting the Sun. In a tank of gas, the molecules are moving in all directions. The kinetic energy of the system is the sum of the kinetic energies of the bodies it contains.\nA macroscopic body that is stationary (i.e. a reference frame has been chosen to correspond to the body's center of momentum) may have various kinds of internal energy at the molecular or atomic level, which may be regarded as kinetic energy, due to molecular translation, rotation, and vibration, electron translation and spin, and nuclear spin. These all contribute to the body's mass, as provided by the special theory of relativity. When discussing movements of a macroscopic body, the kinetic energy referred to is usually that of the macroscopic movement only. However, all internal energies of all types contribute to a body's mass, inertia, and total energy.\n\n\n=== Fluid dynamics ===\nIn fluid dynamics, the kinetic energy per unit volume at each point in an incompressible fluid flow field is called the dynamic pressure at that point.\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}={\\frac {1}{2}}mv^{2}}\n  Dividing by V, the unit of volume:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      E\n                      \n                        k\n                      \n                    \n                    V\n                  \n                \n              \n              \n                \n                =\n                \n                  \n                    1\n                    2\n                  \n                \n                \n                  \n                    m\n                    V\n                  \n                \n                \n                  v\n                  \n                    2\n                  \n                \n              \n            \n            \n              \n                q\n              \n              \n                \n                =\n                \n                  \n                    1\n                    2\n                  \n                \n                \u03c1\n                \n                  v\n                  \n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\frac {E_{\\text{k}}}{V}}&={\\frac {1}{2}}{\\frac {m}{V}}v^{2}\\\\q&={\\frac {1}{2}}\\rho v^{2}\\end{aligned}}}\n  where \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n   is the dynamic pressure, and \u03c1 is the density of the incompressible fluid.\n\n\n=== Frame of reference ===\nThe speed, and thus the kinetic energy of a single object is frame-dependent (relative): it can take any non-negative value, by choosing a suitable inertial frame of reference. For example, a bullet passing an observer has kinetic energy in the reference frame of this observer. The same bullet is stationary to an observer moving with the same velocity as the bullet, and so has zero kinetic energy. By contrast, the total kinetic energy of a system of objects cannot be reduced to zero by a suitable choice of the inertial reference frame, unless all the objects have the same velocity. In any other case, the total kinetic energy has a non-zero minimum, as no inertial reference frame can be chosen in which all the objects are stationary. This minimum kinetic energy contributes to the system's invariant mass, which is independent of the reference frame.\nThe total kinetic energy of a system depends on the inertial frame of reference: it is the sum of the total kinetic energy in a center of momentum frame and the kinetic energy the total mass would have if it were concentrated in the center of mass.\nThis may be simply shown: let \n  \n    \n      \n        \n          \n            V\n          \n        \n      \n    \n    {\\displaystyle \\textstyle \\mathbf {V} }\n   be the relative velocity of the center of mass frame i in the frame k. Since\n\n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        \n          \n            (\n            \n              \n                v\n                \n                  i\n                \n              \n              +\n              V\n            \n            )\n          \n          \n            2\n          \n        \n        =\n        \n          (\n          \n            \n              \n                v\n              \n              \n                i\n              \n            \n            +\n            \n              V\n            \n          \n          )\n        \n        \u22c5\n        \n          (\n          \n            \n              \n                v\n              \n              \n                i\n              \n            \n            +\n            \n              V\n            \n          \n          )\n        \n        =\n        \n          \n            v\n          \n          \n            i\n          \n        \n        \u22c5\n        \n          \n            v\n          \n          \n            i\n          \n        \n        +\n        2\n        \n          \n            v\n          \n          \n            i\n          \n        \n        \u22c5\n        \n          V\n        \n        +\n        \n          V\n        \n        \u22c5\n        \n          V\n        \n        =\n        \n          v\n          \n            i\n          \n          \n            2\n          \n        \n        +\n        2\n        \n          \n            v\n          \n          \n            i\n          \n        \n        \u22c5\n        \n          V\n        \n        +\n        \n          V\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle v^{2}=\\left(v_{i}+V\\right)^{2}=\\left(\\mathbf {v} _{i}+\\mathbf {V} \\right)\\cdot \\left(\\mathbf {v} _{i}+\\mathbf {V} \\right)=\\mathbf {v} _{i}\\cdot \\mathbf {v} _{i}+2\\mathbf {v} _{i}\\cdot \\mathbf {V} +\\mathbf {V} \\cdot \\mathbf {V} =v_{i}^{2}+2\\mathbf {v} _{i}\\cdot \\mathbf {V} +V^{2},}\n  Then,\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \u222b\n        \n          \n            \n              v\n              \n                2\n              \n            \n            2\n          \n        \n        d\n        m\n        =\n        \u222b\n        \n          \n            \n              v\n              \n                i\n              \n              \n                2\n              \n            \n            2\n          \n        \n        d\n        m\n        +\n        \n          V\n        \n        \u22c5\n        \u222b\n        \n          \n            v\n          \n          \n            i\n          \n        \n        d\n        m\n        +\n        \n          \n            \n              V\n              \n                2\n              \n            \n            2\n          \n        \n        \u222b\n        d\n        m\n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}=\\int {\\frac {v^{2}}{2}}dm=\\int {\\frac {v_{i}^{2}}{2}}dm+\\mathbf {V} \\cdot \\int \\mathbf {v} _{i}dm+{\\frac {V^{2}}{2}}\\int dm.}\n  However, let \n  \n    \n      \n        \u222b\n        \n          \n            \n              v\n              \n                i\n              \n              \n                2\n              \n            \n            2\n          \n        \n        d\n        m\n        =\n        \n          E\n          \n            i\n          \n        \n      \n    \n    {\\textstyle \\int {\\frac {v_{i}^{2}}{2}}dm=E_{i}}\n   the kinetic energy in the center of mass frame, \n  \n    \n      \n        \u222b\n        \n          \n            v\n          \n          \n            i\n          \n        \n        d\n        m\n      \n    \n    {\\textstyle \\int \\mathbf {v} _{i}dm}\n   would be simply the total momentum that is by definition zero in the center of mass frame, and let the total mass: \n  \n    \n      \n        \u222b\n        d\n        m\n        =\n        M\n      \n    \n    {\\textstyle \\int dm=M}\n  . Substituting, we get:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          E\n          \n            i\n          \n        \n        +\n        \n          \n            \n              M\n              \n                V\n                \n                  2\n                \n              \n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}=E_{i}+{\\frac {MV^{2}}{2}}.}\n  Thus the kinetic energy of a system is lowest to center of momentum reference frames, i.e., frames of reference in which the center of mass is stationary (either the center of mass frame or any other center of momentum frame). In any different frame of reference, there is additional kinetic energy corresponding to the total mass moving at the speed of the center of mass. The kinetic energy of the system in the center of momentum frame is a quantity that is invariant (all observers see it to be the same).\n\n\n=== Rotation in systems ===\nIt sometimes is convenient to split the total kinetic energy of a body into the sum of the body's center-of-mass translational kinetic energy and the energy of rotation around the center of mass (rotational energy):\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          E\n          \n            t\n          \n        \n        +\n        \n          E\n          \n            r\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}=E_{\\text{t}}+E_{\\text{r}}}\n  where:\n\nEk is the total kinetic energy\nEt is the translational kinetic energy\nEr is the rotational energy or angular kinetic energy in the rest frameThus the kinetic energy of a tennis ball in flight is the kinetic energy due to its rotation, plus the kinetic energy due to its translation.\n\n\n== Relativistic kinetic energy ==\n\nIf a body's speed is a significant fraction of the speed of light, it is necessary to use relativistic mechanics to calculate its kinetic energy. In special relativity theory, the expression for linear momentum is modified.\nWith m being an object's rest mass, v and v its velocity and speed, and c the speed of light in vacuum, we use the expression for linear momentum \n  \n    \n      \n        \n          p\n        \n        =\n        m\n        \u03b3\n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {p} =m\\gamma \\mathbf {v} }\n  , where \n  \n    \n      \n        \u03b3\n        =\n        1\n        \n          /\n        \n        \n          \n            1\n            \u2212\n            \n              v\n              \n                2\n              \n            \n            \n              /\n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\textstyle \\gamma =1/{\\sqrt {1-v^{2}/c^{2}}}}\n  .\nIntegrating by parts yields\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \u222b\n        \n          v\n        \n        \u22c5\n        d\n        \n          p\n        \n        =\n        \u222b\n        \n          v\n        \n        \u22c5\n        d\n        (\n        m\n        \u03b3\n        \n          v\n        \n        )\n        =\n        m\n        \u03b3\n        \n          v\n        \n        \u22c5\n        \n          v\n        \n        \u2212\n        \u222b\n        m\n        \u03b3\n        \n          v\n        \n        \u22c5\n        d\n        \n          v\n        \n        =\n        m\n        \u03b3\n        \n          v\n          \n            2\n          \n        \n        \u2212\n        \n          \n            m\n            2\n          \n        \n        \u222b\n        \u03b3\n        d\n        \n          (\n          \n            v\n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle E_{\\text{k}}=\\int \\mathbf {v} \\cdot d\\mathbf {p} =\\int \\mathbf {v} \\cdot d(m\\gamma \\mathbf {v} )=m\\gamma \\mathbf {v} \\cdot \\mathbf {v} -\\int m\\gamma \\mathbf {v} \\cdot d\\mathbf {v} =m\\gamma v^{2}-{\\frac {m}{2}}\\int \\gamma d\\left(v^{2}\\right)}\n  Since \n  \n    \n      \n        \u03b3\n        =\n        \n          \n            (\n            \n              1\n              \u2212\n              \n                v\n                \n                  2\n                \n              \n              \n                /\n              \n              \n                c\n                \n                  2\n                \n              \n            \n            )\n          \n          \n            \u2212\n            \n              \n                1\n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\gamma =\\left(1-v^{2}/c^{2}\\right)^{-{\\frac {1}{2}}}}\n  ,\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  E\n                  \n                    k\n                  \n                \n              \n              \n                \n                =\n                m\n                \u03b3\n                \n                  v\n                  \n                    2\n                  \n                \n                \u2212\n                \n                  \n                    \n                      \u2212\n                      m\n                      \n                        c\n                        \n                          2\n                        \n                      \n                    \n                    2\n                  \n                \n                \u222b\n                \u03b3\n                d\n                \n                  (\n                  \n                    1\n                    \u2212\n                    \n                      \n                        \n                          v\n                          \n                            2\n                          \n                        \n                        \n                          c\n                          \n                            2\n                          \n                        \n                      \n                    \n                  \n                  )\n                \n              \n            \n            \n              \n              \n                \n                =\n                m\n                \u03b3\n                \n                  v\n                  \n                    2\n                  \n                \n                +\n                m\n                \n                  c\n                  \n                    2\n                  \n                \n                \n                  \n                    (\n                    \n                      1\n                      \u2212\n                      \n                        \n                          \n                            v\n                            \n                              2\n                            \n                          \n                          \n                            c\n                            \n                              2\n                            \n                          \n                        \n                      \n                    \n                    )\n                  \n                  \n                    \n                      1\n                      2\n                    \n                  \n                \n                \u2212\n                \n                  E\n                  \n                    0\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}E_{\\text{k}}&=m\\gamma v^{2}-{\\frac {-mc^{2}}{2}}\\int \\gamma d\\left(1-{\\frac {v^{2}}{c^{2}}}\\right)\\\\&=m\\gamma v^{2}+mc^{2}\\left(1-{\\frac {v^{2}}{c^{2}}}\\right)^{\\frac {1}{2}}-E_{0}\\end{aligned}}}\n  \n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}}\n   is a constant of integration for the indefinite integral.\nSimplifying the expression we obtain\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  E\n                  \n                    k\n                  \n                \n              \n              \n                \n                =\n                m\n                \u03b3\n                \n                  (\n                  \n                    \n                      v\n                      \n                        2\n                      \n                    \n                    +\n                    \n                      c\n                      \n                        2\n                      \n                    \n                    \n                      (\n                      \n                        1\n                        \u2212\n                        \n                          \n                            \n                              v\n                              \n                                2\n                              \n                            \n                            \n                              c\n                              \n                                2\n                              \n                            \n                          \n                        \n                      \n                      )\n                    \n                  \n                  )\n                \n                \u2212\n                \n                  E\n                  \n                    0\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                m\n                \u03b3\n                \n                  (\n                  \n                    \n                      v\n                      \n                        2\n                      \n                    \n                    +\n                    \n                      c\n                      \n                        2\n                      \n                    \n                    \u2212\n                    \n                      v\n                      \n                        2\n                      \n                    \n                  \n                  )\n                \n                \u2212\n                \n                  E\n                  \n                    0\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                m\n                \u03b3\n                \n                  c\n                  \n                    2\n                  \n                \n                \u2212\n                \n                  E\n                  \n                    0\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}E_{\\text{k}}&=m\\gamma \\left(v^{2}+c^{2}\\left(1-{\\frac {v^{2}}{c^{2}}}\\right)\\right)-E_{0}\\\\&=m\\gamma \\left(v^{2}+c^{2}-v^{2}\\right)-E_{0}\\\\&=m\\gamma c^{2}-E_{0}\\end{aligned}}}\n  \n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle E_{0}}\n   is found by observing that when \n  \n    \n      \n        \n          v\n        \n        =\n        0\n        ,\n         \n        \u03b3\n        =\n        1\n      \n    \n    {\\displaystyle \\mathbf {v} =0,\\ \\gamma =1}\n   and \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle E_{\\text{k}}=0}\n  , giving\n\n  \n    \n      \n        \n          E\n          \n            0\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{0}=mc^{2}}\n  resulting in the formula\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        m\n        \u03b3\n        \n          c\n          \n            2\n          \n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n        =\n        \n          \n            \n              m\n              \n                c\n                \n                  2\n                \n              \n            \n            \n              1\n              \u2212\n              \n                \n                  \n                    v\n                    \n                      2\n                    \n                  \n                  \n                    c\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n        =\n        (\n        \u03b3\n        \u2212\n        1\n        )\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}=m\\gamma c^{2}-mc^{2}={\\frac {mc^{2}}{\\sqrt {1-{\\frac {v^{2}}{c^{2}}}}}}-mc^{2}=(\\gamma -1)mc^{2}}\n  This formula shows that the work expended accelerating an object from rest approaches infinity as the velocity approaches the speed of light. Thus it is impossible to accelerate an object across this boundary.\nThe mathematical by-product of this calculation is the mass-energy equivalence formula\u2014the body at rest must have energy content\n\n  \n    \n      \n        \n          E\n          \n            rest\n          \n        \n        =\n        \n          E\n          \n            0\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{rest}}=E_{0}=mc^{2}}\n  At a low speed (v \u226a c), the relativistic kinetic energy is approximated well by the classical kinetic energy. This is done by binomial approximation or by taking the first two terms of the Taylor expansion for the reciprocal square root:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        \u2248\n        m\n        \n          c\n          \n            2\n          \n        \n        \n          (\n          \n            1\n            +\n            \n              \n                1\n                2\n              \n            \n            \n              \n                \n                  v\n                  \n                    2\n                  \n                \n                \n                  c\n                  \n                    2\n                  \n                \n              \n            \n          \n          )\n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}\\approx mc^{2}\\left(1+{\\frac {1}{2}}{\\frac {v^{2}}{c^{2}}}\\right)-mc^{2}={\\frac {1}{2}}mv^{2}}\n  So, the total energy \n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle E_{k}}\n   can be partitioned into the rest mass energy plus the Newtonian kinetic energy at low speeds.\nWhen objects move at a speed much slower than light (e.g. in everyday phenomena on Earth), the first two terms of the series predominate. The next term in the Taylor series approximation\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        \u2248\n        m\n        \n          c\n          \n            2\n          \n        \n        \n          (\n          \n            1\n            +\n            \n              \n                1\n                2\n              \n            \n            \n              \n                \n                  v\n                  \n                    2\n                  \n                \n                \n                  c\n                  \n                    2\n                  \n                \n              \n            \n            +\n            \n              \n                3\n                8\n              \n            \n            \n              \n                \n                  v\n                  \n                    4\n                  \n                \n                \n                  c\n                  \n                    4\n                  \n                \n              \n            \n          \n          )\n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        m\n        \n          v\n          \n            2\n          \n        \n        +\n        \n          \n            3\n            8\n          \n        \n        m\n        \n          \n            \n              v\n              \n                4\n              \n            \n            \n              c\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}\\approx mc^{2}\\left(1+{\\frac {1}{2}}{\\frac {v^{2}}{c^{2}}}+{\\frac {3}{8}}{\\frac {v^{4}}{c^{4}}}\\right)-mc^{2}={\\frac {1}{2}}mv^{2}+{\\frac {3}{8}}m{\\frac {v^{4}}{c^{2}}}}\n  is small for low speeds. For example, for a speed of 10 km/s (22,000 mph) the correction to the Newtonian kinetic energy is 0.0417 J/kg (on a Newtonian kinetic energy of 50 MJ/kg) and for a speed of 100 km/s it is 417 J/kg (on a Newtonian kinetic energy of 5 GJ/kg).\nThe relativistic relation between kinetic energy and momentum is given by\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            \n              p\n              \n                2\n              \n            \n            \n              c\n              \n                2\n              \n            \n            +\n            \n              m\n              \n                2\n              \n            \n            \n              c\n              \n                4\n              \n            \n          \n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle E_{\\text{k}}={\\sqrt {p^{2}c^{2}+m^{2}c^{4}}}-mc^{2}}\n  This can also be expanded as a Taylor series, the first term of which is the simple expression from Newtonian mechanics:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        \u2248\n        \n          \n            \n              p\n              \n                2\n              \n            \n            \n              2\n              m\n            \n          \n        \n        \u2212\n        \n          \n            \n              p\n              \n                4\n              \n            \n            \n              8\n              \n                m\n                \n                  3\n                \n              \n              \n                c\n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}\\approx {\\frac {p^{2}}{2m}}-{\\frac {p^{4}}{8m^{3}c^{2}}}.}\n  This suggests that the formulae for energy and momentum are not special and axiomatic, but concepts emerging from the equivalence of mass and energy and the principles of relativity.\n\n\n=== General relativity ===\n\nUsing the convention that\n\n  \n    \n      \n        \n          g\n          \n            \u03b1\n            \u03b2\n          \n        \n        \n        \n          u\n          \n            \u03b1\n          \n        \n        \n        \n          u\n          \n            \u03b2\n          \n        \n        \n        =\n        \n        \u2212\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle g_{\\alpha \\beta }\\,u^{\\alpha }\\,u^{\\beta }\\,=\\,-c^{2}}\n  where the four-velocity of a particle is\n\n  \n    \n      \n        \n          u\n          \n            \u03b1\n          \n        \n        \n        =\n        \n        \n          \n            \n              d\n              \n                x\n                \n                  \u03b1\n                \n              \n            \n            \n              d\n              \u03c4\n            \n          \n        \n      \n    \n    {\\displaystyle u^{\\alpha }\\,=\\,{\\frac {dx^{\\alpha }}{d\\tau }}}\n  and \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   is the proper time of the particle, there is also an expression for the kinetic energy of the particle in general relativity.\nIf the particle has momentum\n\n  \n    \n      \n        \n          p\n          \n            \u03b2\n          \n        \n        \n        =\n        \n        m\n        \n        \n          g\n          \n            \u03b2\n            \u03b1\n          \n        \n        \n        \n          u\n          \n            \u03b1\n          \n        \n      \n    \n    {\\displaystyle p_{\\beta }\\,=\\,m\\,g_{\\beta \\alpha }\\,u^{\\alpha }}\n  as it passes by an observer with four-velocity uobs, then the expression for total energy of the particle as observed (measured in a local inertial frame) is\n\n  \n    \n      \n        E\n        \n        =\n        \n        \u2212\n        \n        \n          p\n          \n            \u03b2\n          \n        \n        \n        \n          u\n          \n            obs\n          \n          \n            \u03b2\n          \n        \n      \n    \n    {\\displaystyle E\\,=\\,-\\,p_{\\beta }\\,u_{\\text{obs}}^{\\beta }}\n  and the kinetic energy can be expressed as the total energy minus the rest energy:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        \n        =\n        \n        \u2212\n        \n        \n          p\n          \n            \u03b2\n          \n        \n        \n        \n          u\n          \n            obs\n          \n          \n            \u03b2\n          \n        \n        \n        \u2212\n        \n        m\n        \n        \n          c\n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle E_{k}\\,=\\,-\\,p_{\\beta }\\,u_{\\text{obs}}^{\\beta }\\,-\\,m\\,c^{2}\\,.}\n  Consider the case of a metric that is diagonal and spatially isotropic (gtt, gss, gss, gss). Since\n\n  \n    \n      \n        \n          u\n          \n            \u03b1\n          \n        \n        =\n        \n          \n            \n              d\n              \n                x\n                \n                  \u03b1\n                \n              \n            \n            \n              d\n              t\n            \n          \n        \n        \n          \n            \n              d\n              t\n            \n            \n              d\n              \u03c4\n            \n          \n        \n        =\n        \n          v\n          \n            \u03b1\n          \n        \n        \n          u\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle u^{\\alpha }={\\frac {dx^{\\alpha }}{dt}}{\\frac {dt}{d\\tau }}=v^{\\alpha }u^{t}}\n  where v\u03b1 is the ordinary velocity measured w.r.t. the coordinate system, we get\n\n  \n    \n      \n        \u2212\n        \n          c\n          \n            2\n          \n        \n        =\n        \n          g\n          \n            \u03b1\n            \u03b2\n          \n        \n        \n          u\n          \n            \u03b1\n          \n        \n        \n          u\n          \n            \u03b2\n          \n        \n        =\n        \n          g\n          \n            t\n            t\n          \n        \n        \n          \n            (\n            \n              u\n              \n                t\n              \n            \n            )\n          \n          \n            2\n          \n        \n        +\n        \n          g\n          \n            s\n            s\n          \n        \n        \n          v\n          \n            2\n          \n        \n        \n          \n            (\n            \n              u\n              \n                t\n              \n            \n            )\n          \n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle -c^{2}=g_{\\alpha \\beta }u^{\\alpha }u^{\\beta }=g_{tt}\\left(u^{t}\\right)^{2}+g_{ss}v^{2}\\left(u^{t}\\right)^{2}\\,.}\n  Solving for ut gives\n\n  \n    \n      \n        \n          u\n          \n            t\n          \n        \n        =\n        c\n        \n          \n            \n              \n                \u2212\n                1\n              \n              \n                \n                  g\n                  \n                    t\n                    t\n                  \n                \n                +\n                \n                  g\n                  \n                    s\n                    s\n                  \n                \n                \n                  v\n                  \n                    2\n                  \n                \n              \n            \n          \n        \n        \n        .\n      \n    \n    {\\displaystyle u^{t}=c{\\sqrt {\\frac {-1}{g_{tt}+g_{ss}v^{2}}}}\\,.}\n  Thus for a stationary observer (v = 0)\n\n  \n    \n      \n        \n          u\n          \n            obs\n          \n          \n            t\n          \n        \n        =\n        c\n        \n          \n            \n              \n                \u2212\n                1\n              \n              \n                g\n                \n                  t\n                  t\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle u_{\\text{obs}}^{t}=c{\\sqrt {\\frac {-1}{g_{tt}}}}}\n  and thus the kinetic energy takes the form\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \u2212\n        m\n        \n          g\n          \n            t\n            t\n          \n        \n        \n          u\n          \n            t\n          \n        \n        \n          u\n          \n            obs\n          \n          \n            t\n          \n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n        \n          \n            \n              \n                g\n                \n                  t\n                  t\n                \n              \n              \n                \n                  g\n                  \n                    t\n                    t\n                  \n                \n                +\n                \n                  g\n                  \n                    s\n                    s\n                  \n                \n                \n                  v\n                  \n                    2\n                  \n                \n              \n            \n          \n        \n        \u2212\n        m\n        \n          c\n          \n            2\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}=-mg_{tt}u^{t}u_{\\text{obs}}^{t}-mc^{2}=mc^{2}{\\sqrt {\\frac {g_{tt}}{g_{tt}+g_{ss}v^{2}}}}-mc^{2}\\,.}\n  Factoring out the rest energy gives:\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        m\n        \n          c\n          \n            2\n          \n        \n        \n          (\n          \n            \n              \n                \n                  \n                    g\n                    \n                      t\n                      t\n                    \n                  \n                  \n                    \n                      g\n                      \n                        t\n                        t\n                      \n                    \n                    +\n                    \n                      g\n                      \n                        s\n                        s\n                      \n                    \n                    \n                      v\n                      \n                        2\n                      \n                    \n                  \n                \n              \n            \n            \u2212\n            1\n          \n          )\n        \n        \n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}=mc^{2}\\left({\\sqrt {\\frac {g_{tt}}{g_{tt}+g_{ss}v^{2}}}}-1\\right)\\,.}\n  This expression reduces to the special relativistic case for the flat-space metric where\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  g\n                  \n                    t\n                    t\n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  c\n                  \n                    2\n                  \n                \n              \n            \n            \n              \n                \n                  g\n                  \n                    s\n                    s\n                  \n                \n              \n              \n                \n                =\n                1\n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}g_{tt}&=-c^{2}\\\\g_{ss}&=1\\,.\\end{aligned}}}\n  In the Newtonian approximation to general relativity\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  g\n                  \n                    t\n                    t\n                  \n                \n              \n              \n                \n                =\n                \u2212\n                \n                  (\n                  \n                    \n                      c\n                      \n                        2\n                      \n                    \n                    +\n                    2\n                    \u03a6\n                  \n                  )\n                \n              \n            \n            \n              \n                \n                  g\n                  \n                    s\n                    s\n                  \n                \n              \n              \n                \n                =\n                1\n                \u2212\n                \n                  \n                    \n                      2\n                      \u03a6\n                    \n                    \n                      c\n                      \n                        2\n                      \n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}g_{tt}&=-\\left(c^{2}+2\\Phi \\right)\\\\g_{ss}&=1-{\\frac {2\\Phi }{c^{2}}}\\end{aligned}}}\n  where \u03a6 is the Newtonian gravitational potential. This means clocks run slower and measuring rods are shorter near massive bodies.\n\n\n== Kinetic energy in quantum mechanics ==\n\nIn quantum mechanics, observables like kinetic energy are represented as operators. For one particle of mass m, the kinetic energy operator appears as a term in the Hamiltonian and is defined in terms of the more fundamental momentum operator \n  \n    \n      \n        \n          \n            \n              p\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {p}}}\n  . The kinetic energy operator in the non-relativistic case can be written as\n\n  \n    \n      \n        \n          \n            \n              T\n              ^\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    p\n                    ^\n                  \n                \n              \n              \n                2\n              \n            \n            \n              2\n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\hat {T}}={\\frac {{\\hat {p}}^{2}}{2m}}.}\n  Notice that this can be obtained by replacing \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   by \n  \n    \n      \n        \n          \n            \n              p\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {p}}}\n   in the classical expression for kinetic energy in terms of momentum,\n\n  \n    \n      \n        \n          E\n          \n            k\n          \n        \n        =\n        \n          \n            \n              p\n              \n                2\n              \n            \n            \n              2\n              m\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle E_{\\text{k}}={\\frac {p^{2}}{2m}}.}\n  In the Schr\u00f6dinger picture, \n  \n    \n      \n        \n          \n            \n              p\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {p}}}\n   takes the form \n  \n    \n      \n        \u2212\n        i\n        \u210f\n        \u2207\n      \n    \n    {\\displaystyle -i\\hbar \\nabla }\n   where the derivative is taken with respect to position coordinates and hence\n\n  \n    \n      \n        \n          \n            \n              T\n              ^\n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              \u210f\n              \n                2\n              \n            \n            \n              2\n              m\n            \n          \n        \n        \n          \u2207\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\hat {T}}=-{\\frac {\\hbar ^{2}}{2m}}\\nabla ^{2}.}\n  The expectation value of the electron kinetic energy, \n  \n    \n      \n        \n          \u27e8\n          \n            \n              \n                T\n                ^\n              \n            \n          \n          \u27e9\n        \n      \n    \n    {\\displaystyle \\left\\langle {\\hat {T}}\\right\\rangle }\n  , for a system of N electrons described by the wavefunction \n  \n    \n      \n        |\n        \u03c8\n        \u27e9\n      \n    \n    {\\displaystyle \\vert \\psi \\rangle }\n   is a sum of 1-electron operator expectation values:\n\n  \n    \n      \n        \n          \u27e8\n          \n            \n              \n                T\n                ^\n              \n            \n          \n          \u27e9\n        \n        =\n        \n          \u27e8\n          \n            \u03c8\n            \n              |\n              \n                \n                  \u2211\n                  \n                    i\n                    =\n                    1\n                  \n                  \n                    N\n                  \n                \n                \n                  \n                    \n                      \u2212\n                      \n                        \u210f\n                        \n                          2\n                        \n                      \n                    \n                    \n                      2\n                      \n                        m\n                        \n                          e\n                        \n                      \n                    \n                  \n                \n                \n                  \u2207\n                  \n                    i\n                  \n                  \n                    2\n                  \n                \n              \n              |\n            \n            \u03c8\n          \n          \u27e9\n        \n        =\n        \u2212\n        \n          \n            \n              \u210f\n              \n                2\n              \n            \n            \n              2\n              \n                m\n                \n                  e\n                \n              \n            \n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          \u27e8\n          \n            \u03c8\n            \n              |\n              \n                \u2207\n                \n                  i\n                \n                \n                  2\n                \n              \n              |\n            \n            \u03c8\n          \n          \u27e9\n        \n      \n    \n    {\\displaystyle \\left\\langle {\\hat {T}}\\right\\rangle =\\left\\langle \\psi \\left\\vert \\sum _{i=1}^{N}{\\frac {-\\hbar ^{2}}{2m_{\\text{e}}}}\\nabla _{i}^{2}\\right\\vert \\psi \\right\\rangle =-{\\frac {\\hbar ^{2}}{2m_{\\text{e}}}}\\sum _{i=1}^{N}\\left\\langle \\psi \\left\\vert \\nabla _{i}^{2}\\right\\vert \\psi \\right\\rangle }\n  where \n  \n    \n      \n        \n          m\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle m_{\\text{e}}}\n   is the mass of the electron and \n  \n    \n      \n        \n          \u2207\n          \n            i\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\nabla _{i}^{2}}\n   is the Laplacian operator acting upon the coordinates of the ith electron and the summation runs over all electrons.\nThe density functional formalism of quantum mechanics requires knowledge of the electron density only, i.e., it formally does not require knowledge of the wavefunction.  Given an electron density \n  \n    \n      \n        \u03c1\n        (\n        \n          r\n        \n        )\n      \n    \n    {\\displaystyle \\rho (\\mathbf {r} )}\n  , the exact N-electron kinetic energy functional is unknown; however, for the specific case of a 1-electron system, the kinetic energy can be written as\n\n  \n    \n      \n        T\n        [\n        \u03c1\n        ]\n        =\n        \n          \n            1\n            8\n          \n        \n        \u222b\n        \n          \n            \n              \u2207\n              \u03c1\n              (\n              \n                r\n              \n              )\n              \u22c5\n              \u2207\n              \u03c1\n              (\n              \n                r\n              \n              )\n            \n            \n              \u03c1\n              (\n              \n                r\n              \n              )\n            \n          \n        \n        \n          d\n          \n            3\n          \n        \n        r\n      \n    \n    {\\displaystyle T[\\rho ]={\\frac {1}{8}}\\int {\\frac {\\nabla \\rho (\\mathbf {r} )\\cdot \\nabla \\rho (\\mathbf {r} )}{\\rho (\\mathbf {r} )}}d^{3}r}\n  where \n  \n    \n      \n        T\n        [\n        \u03c1\n        ]\n      \n    \n    {\\displaystyle T[\\rho ]}\n   is known as the von Weizs\u00e4cker kinetic energy functional.\n\n\n== See also ==\nEscape velocity\nFoot-pound\nJoule\nKinetic energy penetrator\nKinetic energy per unit mass of projectiles\nKinetic projectile\nParallel axis theorem\nPotential energy\nRecoil\n\n\n== Notes ==\n\n\n== References ==\nPhysics Classroom (2000). \"Kinetic Energy\". Retrieved 2015-07-19.\nSchool of Mathematics and Statistics, University of St Andrews (2000). \"Biography of Gaspard-Gustave de Coriolis (1792-1843)\". Retrieved 2006-03-03.\nSerway, Raymond A.; Jewett, John W. (2004). Physics for Scientists and Engineers (6th ed.). Brooks/Cole. ISBN 0-534-40842-7.\nTipler, Paul (2004). Physics for Scientists and Engineers: Mechanics, Oscillations and Waves, Thermodynamics (5th ed.). W. H. Freeman. ISBN 0-7167-0809-4.\nTipler, Paul; Llewellyn, Ralph (2002). Modern Physics (4th ed.). W. H. Freeman. ISBN 0-7167-4345-0.\n\n\n== External links ==\n Media related to Kinetic energy at Wikimedia Commons", "Gravitational_field": "In physics, a gravitational field is a model used to explain the influences that a massive body extends into the space around itself, producing a force on another massive body. Thus, a gravitational field is used to explain gravitational phenomena, and is measured in newtons per kilogram (N/kg).  Equivalently, it is measured in meters per second squared (m/s2).\nIn its original concept, gravity was a force between point masses. Following Isaac Newton, Pierre-Simon Laplace attempted to model gravity as some kind of radiation field or fluid, and since the 19th century, explanations for gravity have usually been taught in terms of a field model, rather than a point attraction.\nIn a field model, rather than two particles attracting each other, the particles distort spacetime via their mass, and this distortion is what is perceived and measured as a \"force\".    In such a model one states that matter moves in certain ways in response to the curvature of spacetime, and that there is either no gravitational force, or that gravity is a fictitious force.Gravity is distinguished from other forces by its obedience to the equivalence principle.\n\n\n== Classical mechanics ==\nIn classical mechanics, a gravitational field is a physical quantity. A gravitational field can be defined using Newton's law of universal gravitation. Determined in this way, the gravitational field g around a single particle of mass M is a vector field consisting at every point of a vector pointing directly towards the particle. The magnitude of the field at every point is calculated by applying the universal law, and represents the force per unit mass on any object at that point in space. Because the force field is conservative, there is a scalar potential energy per unit mass, \u03a6, at each point in space associated with the force fields; this is called gravitational potential. The gravitational field equation is\nwhere F is the gravitational force, m is the mass of the test particle, R is the position of the test particle (or for Newton's second law of motion which is a time dependent function, a set of positions of test particles each occupying a particular point in space for the start of testing), R\u0302 is a unit vector in the radial direction of R, t is time, G is the gravitational constant, and \u2207 is the del operator.\nThis includes Newton's law of universal gravitation, and the relation between gravitational potential and field acceleration. Note that d2R/dt2 and F/m are both equal to the gravitational acceleration g (equivalent to the inertial acceleration, so same mathematical form, but also defined as gravitational force per unit mass). The negative signs are inserted since the force acts antiparallel to the displacement. The equivalent field equation in terms of mass density \u03c1 of the attracting mass is:\n\nwhich contains Gauss's law for gravity, and Poisson's equation for gravity. Newton's law implies Gauss's law, but not vice versa; see Relation between Gauss's and Newton's laws.\nThese classical equations are differential equations of motion for a test particle in the presence of a gravitational field, i.e. setting up and solving these equations allows the motion of a test mass to be determined and described.\nThe field around multiple particles is simply the vector sum of the fields around each individual particle. An object in such a field will experience a force that equals the vector sum of the forces it would experience in these individual fields. This is mathematically\ni.e. the gravitational field on mass mj is the sum of all gravitational fields due to all other masses mi, except the mass mj itself. The unit vector R\u0302ij is in the direction of Rj \u2212 Ri (pointing from particle i to particle j).\n\n\n== General relativity ==\n\nIn general relativity, the Christoffel symbols play the role of the gravitational force field and the metric tensor plays the role of the gravitational potential.\nIn general relativity, the gravitational field is determined by solving the Einstein field equations\nwhere T is the stress\u2013energy tensor, G is the Einstein tensor, and \u03ba is the Einstein gravitational constant.  The latter is defined as \u03ba = 8\u03c0G/c4, where G is the Newtonian constant of gravitation and c is the speed of light.\nThese equations are dependent on the distribution of matter and energy in a region of space, unlike Newtonian gravity, which is dependent only on the distribution of matter.  The fields themselves in general relativity represent the curvature of spacetime.  General relativity states that being in a region of curved space is equivalent to accelerating up the gradient of the field.  By Newton's second law, this will cause an object to experience a fictitious force if it is held still with respect to the field.  This is why a person will feel himself pulled down by the force of gravity while standing still on the Earth's surface.  In general the gravitational fields predicted by general relativity differ in their effects only slightly from those predicted by classical mechanics, but there are a number of easily verifiable differences, one of the most well known being the deflection of light in such fields.\n\n\n== See also ==\n\n\n== Notes ==", "Pitch_(music)": "Pitch is a perceptual property of sounds that allows their ordering on a frequency-related scale,\nor more commonly, pitch is the quality that makes it possible to judge sounds as \"higher\" and \"lower\" in the sense associated with musical melodies.  \nPitch is a major auditory attribute of musical tones, along with duration, loudness, and timbre.Pitch may be quantified as a frequency, but pitch is not a purely objective physical property; it is a subjective psychoacoustical attribute of sound. Historically, the study of pitch and pitch perception has been a central problem in psychoacoustics, and has been instrumental in forming and testing theories of sound representation, processing, and perception in the auditory system.\n\n\n== Perception ==\n\n\n=== Pitch and frequency ===\nPitch is an auditory sensation in which a listener assigns musical tones to relative positions on a musical scale based primarily on their perception of the frequency of vibration (audio frequency). Pitch is closely related to frequency, but the two are not equivalent. Frequency is an objective, scientific attribute that can be measured. Pitch is each person's subjective perception of a sound wave, which cannot be directly measured. However, this does not necessarily mean that most people won't agree on which notes are higher and lower.\nThe oscillations of sound waves can often be characterized in terms of frequency. Pitches are usually associated with, and thus quantified as, frequencies (in cycles per second, or hertz), by comparing the sounds being assessed against sounds with pure tones (ones with periodic, sinusoidal waveforms). Complex and aperiodic sound waves can often be assigned a pitch by this method.According to the American National Standards Institute, pitch is the auditory attribute of sound according to which sounds can be ordered on a scale from low to high. Since pitch is such a close proxy for frequency, it is almost entirely determined by how quickly the sound wave is making the air vibrate and has almost nothing to do with the intensity, or amplitude, of the wave. That is, \"high\" pitch means very rapid oscillation, and \"low\" pitch corresponds to slower oscillation. Despite that, the idiom relating vertical height to sound pitch is shared by most languages. At least in English, it is just one of many deep conceptual metaphors that involve up/down. The exact etymological history of the musical sense of high and low pitch is still unclear. There is evidence that humans do actually perceive that the source of a sound is slightly higher or lower in vertical space when the sound frequency is increased or reduced.In most cases, the pitch of complex sounds such as speech and musical notes corresponds very nearly to the repetition rate of periodic or nearly-periodic sounds, or to the reciprocal of the time interval between repeating similar events in the sound waveform.The pitch of complex tones can be ambiguous, meaning that two or more different pitches can be perceived, depending upon the observer. When the actual fundamental frequency can be precisely determined through physical measurement, it may differ from the perceived pitch because of overtones, also known as upper partials, harmonic or otherwise. A complex tone composed of two sine waves of 1000 and 1200 Hz may sometimes be heard as up to three pitches: two spectral pitches at 1000 and 1200 Hz, derived from the physical frequencies of the pure tones, and the combination tone at 200 Hz, corresponding to the repetition rate of the waveform. In a situation like this, the percept at 200 Hz is commonly referred to as the missing fundamental, which is often the greatest common divisor of the frequencies present.Pitch depends to a lesser degree on the sound pressure level (loudness, volume) of the tone, especially at frequencies below 1,000 Hz and above 2,000 Hz. The pitch of lower tones gets lower as sound pressure increases. For instance, a tone of 200 Hz that is very loud seems one semitone lower in pitch than if it is just barely audible. Above 2,000 Hz, the pitch gets higher as the sound gets louder. These results were obtained in the pioneering works by S. Stevens  and W. Snow. Later investigations, i.e. by A. Cohen, have shown that in most cases the apparent pitch shifts were not significantly different from pitch\u2010matching errors. When averaged, the remaining shifts followed the directions of Stevens's curves but were small (2% or less by frequency, i.e. not more than a semitone).\n\n\t\t\n\t\t\n\n\n=== Theories of pitch perception ===\nTheories of pitch perception try to explain how the physical sound and specific physiology of the auditory system work together to yield the experience of pitch. In general, pitch perception theories can be divided into place coding and temporal coding. Place theory holds that the perception of pitch is determined by the place of maximum excitation on the basilar membrane.\nA place code, taking advantage of the tonotopy in the auditory system, must be in effect for the perception of high frequencies, since neurons have an upper limit on how fast they can phase-lock their action potentials. However, a purely place-based theory cannot account for the accuracy of pitch perception in the low and middle frequency ranges. Moreover, there is some evidence that some non-human primates lack auditory cortex responses to pitch despite having clear tonotopic maps in auditory cortex, showing that tonotopic place codes are not sufficient for pitch responses.Temporal theories offer an alternative that appeals to the temporal structure of action potentials, mostly the phase-locking and mode-locking of action potentials to frequencies in a stimulus. The precise way this temporal structure helps code for pitch at higher levels is still debated, but the processing seems to be based on an autocorrelation of action potentials in the auditory nerve. However, it has long been noted that a neural mechanism that may accomplish a delay\u2014a necessary operation of a true autocorrelation\u2014has not been found. At least one model shows that a temporal delay is unnecessary to produce an autocorrelation model of pitch perception, appealing to phase shifts between cochlear filters; however, earlier work has shown that certain sounds with a prominent peak in their autocorrelation function do not elicit a corresponding pitch percept, and that certain sounds without a peak in their autocorrelation function nevertheless elicit a pitch. To be a more complete model, autocorrelation must therefore apply to signals that represent the output of the cochlea, as via auditory-nerve interspike-interval histograms. Some theories of pitch perception hold that pitch has inherent octave ambiguities, and therefore is best decomposed into a pitch chroma, a periodic value around the octave, like the note names in western music\u2014and a pitch height, which may be ambiguous, that indicates the octave the pitch is in.\n\n\n=== Just-noticeable difference ===\nThe just-noticeable difference (jnd) (the threshold at which a change is perceived) depends on the tone's frequency content.  Below 500 Hz, the jnd is about 3 Hz for sine waves, and 1 Hz for complex tones; above 1000 Hz, the jnd for sine waves is about 0.6% (about 10 cents).\nThe jnd is typically tested by playing two tones in quick succession with the listener asked if there was a difference in their pitches. The jnd becomes smaller if the two tones are played simultaneously as the listener is then able to discern beat frequencies. The total number of perceptible pitch steps in the range of human hearing is about 1,400; the total number of notes in the equal-tempered scale, from 16 to 16,000 Hz, is 120.\n\n\n=== Aural illusions ===\nThe relative perception of pitch can be fooled, resulting in aural illusions. There are several of these, such as the tritone paradox, but most notably the Shepard scale, where a continuous or discrete sequence of specially formed tones can be made to sound as if the sequence continues ascending or descending forever.\n\n\n== Definite and indefinite pitch ==\nNot all musical instruments make notes with a clear pitch. The unpitched percussion instrument (a class of percussion instrument) does not produce particular pitches. A sound or note of definite pitch is one where a listener can possibly (or relatively easily) discern the pitch. Sounds with definite pitch have harmonic frequency spectra or close to harmonic spectra.A sound generated on any instrument produces many modes of vibration that occur simultaneously. A listener hears numerous frequencies at once. The vibration with the lowest frequency is called the fundamental frequency; the other frequencies are overtones.Harmonics are an important class of overtones with frequencies that are integer multiples of the fundamental. Whether or not the higher frequencies are integer multiples, they are collectively called the partials, referring to the different parts that make up the total spectrum.\nA sound or note of indefinite pitch is one that a listener finds impossible or relatively difficult to identify as to pitch. Sounds with indefinite pitch do not have harmonic spectra or have altered harmonic spectra\u2014a characteristic known as inharmonicity.\nIt is still possible for two sounds of indefinite pitch to clearly be higher or lower than one another. For instance, a snare drum sounds higher pitched than a bass drum though both have indefinite pitch, because its sound contains higher frequencies. In other words, it is possible and often easy to roughly discern the relative pitches of two sounds of indefinite pitch, but sounds of indefinite pitch do not neatly correspond to any specific pitch.\n\n\n== Pitch standards and standard pitch ==\n\nA pitch standard (also concert pitch) is the conventional pitch reference a group of musical instruments are tuned to for a performance. Concert pitch may vary from ensemble to ensemble, and has varied widely over musical history.\n\nStandard pitch is a more widely accepted convention. The A above middle C is usually set at 440 Hz (often written as \"A = 440 Hz\" or sometimes \"A440\"), although other frequencies, such as 442 Hz, are also often used as variants. Another standard pitch, the so-called Baroque pitch, has been set in the 20th century as A = 415 Hz\u2014approximately an equal-tempered semitone lower than A440 to facilitate transposition.  The Classical pitch can be set to either 427 Hz (about halfway between A415 and A440) or 430 Hz (also between A415 and A440 but slightly sharper than the quarter tone).  And ensembles specializing in authentic performance set the A above middle C to 432 Hz or 435 Hz when performing repertoire from the Romantic era.\nTransposing instruments have their origin in the variety of pitch standards. In modern times, they conventionally have their parts transposed into different keys from voices and other instruments (and even from each other). As a result, musicians need a way to refer to a particular pitch in an unambiguous manner when talking to each other.\nFor example, the most common type of clarinet or trumpet, when playing a note written in their part as C, sounds a pitch that is called B\u266d on a non-transposing instrument like a violin (which indicates that at one time these wind instruments played at a standard pitch a tone lower than violin pitch). To refer to that pitch unambiguously, a musician calls it concert B\u266d, meaning, \"the pitch that someone playing a non-transposing instrument like a violin calls B\u266d.\"\n\n\n== Labeling pitches ==\n\nPitches are labeled using:\n\nLetters, as in Helmholtz pitch notation\nA combination of letters and numbers\u2014as in scientific pitch notation, where notes are labelled upwards from C0, the 16 Hz C\nNumbers that represent the frequency in hertz (Hz), the number of cycles per secondFor example, one might refer to the A above middle C as a\u2032, A4, or 440 Hz. In standard Western equal temperament, the notion of pitch is insensitive to \"spelling\": the description \"G4 double sharp\" refers to the same pitch as A4; in other temperaments, these may be distinct pitches.\nHuman perception of musical intervals is approximately logarithmic with respect to fundamental frequency: the perceived interval between the pitches \"A220\" and \"A440\" is the same as the perceived interval between the pitches A440 and A880.  Motivated by this logarithmic perception, music theorists sometimes represent pitches using a numerical scale based on the logarithm of fundamental frequency.  For example, one can adopt the widely used MIDI standard to map fundamental frequency, f, to a real number, p, as follows\n\n  \n    \n      \n        p\n        =\n        69\n        +\n        12\n        \u00d7\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        \n          \n            (\n            \n              \n                f\n                \n                  440\n                  \n                    \n                       Hz\n                    \n                  \n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle p=69+12\\times \\log _{2}{\\left({\\frac {f}{440{\\mbox{ Hz}}}}\\right)}}\n  This creates a linear pitch space in which octaves have size 12, semitones (the distance between adjacent keys on the piano keyboard) have size 1, and A440 is assigned the number 69. (See Frequencies of notes.) Distance in this space corresponds to musical intervals as understood by musicians. An equal-tempered semitone is subdivided into 100 cents. The system is flexible enough to include \"microtones\" not found on standard piano keyboards. For example, the pitch halfway between C (60) and C\u266f (61) can be labeled 60.5.\nThe following table shows frequencies in Hertz for notes in various octaves, named according to the \"German method\" of octave nomenclature:\n\n\n== Scales ==\nThe relative pitches of individual notes in a scale may be determined by one of a number of tuning systems. In the west, the twelve-note chromatic scale is the most common method of organization, with equal temperament now the most widely used method of tuning that scale. In it, the pitch ratio between any two successive notes of the scale is exactly the twelfth root of two (or about 1.05946). In well-tempered systems (as used in the time of Johann Sebastian Bach, for example), different methods of musical tuning were used.\nIn almost all of these systems interval of the octave doubles the frequency of a note; for example, an octave above A440 is 880 Hz. If however the first overtone is sharp due to inharmonicity, as in the extremes of the piano, tuners resort to octave stretching.\n\n\n== Other musical meanings of pitch ==\nIn atonal, twelve tone, or musical set theory a \"pitch\" is a specific frequency while a pitch class is all the octaves of a frequency. In many analytic discussions of atonal and post-tonal music, pitches are named with integers because of octave and enharmonic equivalency (for example, in a serial system, C\u266f and D\u266d are considered the same pitch, while C4 and C5 are functionally the same, one octave apart).\nDiscrete pitches, rather than continuously variable pitches, are virtually universal, with exceptions including \"tumbling strains\" and \"indeterminate-pitch chants\". Gliding pitches are used in most cultures, but are related to the discrete pitches they reference or embellish.\n\n\n== See also ==\n3rd bridge (harmonic resonance based on equal string divisions)\nAbsolute pitch\nDiplacusis\nEight foot pitch\nHarmonic pitch class profiles\nJust intonation\nMeantone temperament\nMusic and mathematics\nPiano key frequencies\nPitch circularity\nPitch class\nPitch detection algorithm\nPitch of brass instruments\nPitch shifter\nPitch pipe\nRelative pitch\nScale of vowels\nVocal and instrumental pitch ranges\n\n\n== References ==\n\n\n== Further reading ==\nMoore, B.C. & Glasberg, B.R. (1986) \"Thresholds for Hearing Mistuned Partials as Separate Tones in Harmonic Complexes\". Journal of the Acoustical Society of America, 80, 479\u201383.\nParncutt, R. (1989). Harmony: A Psychoacoustical Approach. Berlin: Springer-Verlag, 1989.\nSchneider, P.; Sluming, V.; Roberts, N.; Scherg, M.; Goebel, R.; Specht, H.-J.; Dosch, H.G.; Bleeck, S.; Stippich, C.; Rupp, A. (2005). \"Structural and Functional Asymmetry of Lateral Heschl's Gyrus Reflects Pitch Perception Preference\". Nat. Neurosci. 8, 1241\u201347.\nTerhardt, E., Stoll, G. and Seewann, M. (1982). \"Algorithm for Extraction of Pitch and Pitch Salience from Complex Tonal Signals\". Journal of the Acoustical Society of America, 71, 679\u201388.\n\n\n== External links ==", "Pigment": "A pigment is a colored substance that is completely or nearly insoluble in water. In contrast, dyes are typically soluble, at least at some stage in their use. Generally dyes are often organic compounds whereas pigments are often inorganic compounds. Pigments of prehistoric and historic value include ochre, charcoal, and lapis lazuli.\n\n\n== Economic impact ==\nIn 2006, around 7.4 million tons of inorganic, organic, and special pigments were marketed worldwide. According to an April 2018 report by Bloomberg Businessweek, the estimated value of the pigment industry globally is $30 billion. The value of titanium dioxide \u2013 used to enhance the white brightness of many products \u2013 was placed at $13.2 billion per year, while the color Ferrari red is valued at $300 million each year.\n\n\n== Physical principles ==\n\nLike all materials, the color of pigments arises because they absorb only certain wavelengths of visible light. The bonding properties of the material determine the wavelength and efficiency of light absorption. Light of other wavelengths are reflected or scattered. The reflected light spectrum defines the color that we observe.\nThe appearance of pigments is sensitive to the source light. Sunlight has a high color temperature and a fairly uniform spectrum. Sunlight is considered a standard for white light. Artificial light sources are less uniform.\nColor spaces used to represent colors numerically must specify their light source. Lab color measurements, unless otherwise noted, assume that the measurement was recorded under a D65 light source, or \"Daylight 6500 K\", which is roughly the color temperature of sunlight.\n\nOther properties of a color, such as its saturation or lightness, may be determined by the other substances that accompany pigments. Binders and fillers can affect the color.\n\n\n== History ==\nMinerals have been used as colorants since prehistoric times. Early humans used paint for aesthetic purposes such as body decoration. Pigments and paint grinding equipment believed to be between 350,000 and 400,000 years old have been reported in a cave at Twin Rivers, near Lusaka, Zambia. Ochre, iron oxide, was the first color of paint. A favored blue pigment was derived from lapis lazuli. Pigments based on minerals and clays often bear the name of the city or region where they were originally mined. Raw sienna and burnt sienna came from Siena, Italy, while raw umber and burnt umber came from Umbria. These pigments were among the easiest to synthesize, and chemists created modern colors based on the originals. These were more consistent than colors mined from the original ore bodies, but the place names remained. Also found in many Paleolithic and Neolithic cave paintings are Red Ochre, anhydrous Fe2O3, and the hydrated Yellow Ochre (Fe2O3.H2O). Charcoal\u2014or carbon black\u2014has also been used as a black pigment since prehistoric times.The first known synthetic pigment was Egyptian blue, which is first attested on an alabaster bowl in Egypt dated to Naqada III (circa 3250 BC). Egyptian blue (blue frit), calcium copper silicate CaCuSi4O10, made by heating a mixture of quartz sand, lime, a flux and a copper source, such as malachite. Already invented in the Predynastic Period of Egypt, its use became widespread by the 4th Dynasty. It was the blue pigment par excellence of Roman antiquity; its art technological traces vanished in the course of the Middle Ages until its rediscovery in the context of the Egyptian campaign and the excavations in Pompeii and Herculaneum. Later premodern synthetic pigments include white lead (basic lead carbonate, (PbCO3)2Pb(OH)2), vermilion, verdigris, and lead-tin yellow. Vermilion, a mercury sulfide, was originally made by grinding a powder of natural cinnabar. From the 17th century on, it was also synthesized from the elements. It was favored by old masters such as Titian. Indian yellow was once produced by collecting the urine of cattle that had been fed only mango leaves. Dutch and Flemish painters of the 17th and 18th centuries favored it for its luminescent qualities, and often used it to represent sunlight. Since mango leaves are nutritionally inadequate for cattle, the practice of harvesting Indian yellow was eventually declared to be inhumane. Modern hues of Indian yellow are made from synthetic pigments. Vermillion has been partially replaced in by cadmium reds.\nBecause of the cost of lapis lazuli, substitutes were often used. Prussian blue, the oldest modern synthetic pigment, was discovered by accident in 1704. By the early 19th century, synthetic and metallic blue pigments included French ultramarine, a synthetic form of lapis lazuli. Ultramarine was manufactured by treating aluminium silicate with sulfur. Various forms of cobalt blue and Cerulean blue were also introduced. In the early 20th century, Phthalo Blue, a synthetic metallo-organic pigment was prepared. At the same time, Royal Blue, another name once given to tints produced from lapis lazuli, has evolved to signify a much lighter and brighter color, and is usually mixed from Phthalo Blue and titanium dioxide, or from inexpensive synthetic blue dyes.\nThe discovery in 1856 of mauveine, the first aniline dyes, was a forerunner for the development of hundreds of synthetic dyes and pigments like azo and diazo compounds. These dyes ushered in the flourishing of organic chemistry, including systematic designs of colorants. The development of organic chemistry diminished the dependence on inorganic pigments.\nPaintings illustrating advances in pigments\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n== Manufacturing and industrial standards ==\n\nBefore the development of synthetic pigments, and the refinement of techniques for extracting mineral pigments, batches of color were often inconsistent. With the development of a modern color industry, manufacturers and professionals have cooperated to create international standards for identifying, producing, measuring, and testing colors.\nFirst published in 1905, the Munsell color system became the foundation for a series of color models, providing objective methods for the measurement of color. The Munsell system describes a color in three dimensions, hue, value (lightness), and chroma (color purity), where chroma is the difference from gray at a given hue and value.\nBy the middle 20th century, standardized methods for pigment chemistry were available, part of an international movement to create such standards in industry. The International Organization for Standardization (ISO) develops technical standards for the manufacture of pigments and dyes. ISO standards define various industrial and chemical properties, and how to test for them. The principal ISO standards that relate to all pigments are as follows:\n\nISO-787 General methods of test for pigments and extenders.\nISO-8780 Methods of dispersion for assessment of dispersion characteristics.Other ISO standards pertain to particular classes or categories of pigments, based on their chemical composition, such as ultramarine pigments, titanium dioxide, iron oxide pigments, and so forth.\nMany manufacturers of paints, inks, textiles, plastics, and colors have voluntarily adopted the Colour Index International (CII) as a standard for identifying the pigments that they use in manufacturing particular colors. First published in 1925\u2014and now published jointly on the web by the Society of Dyers and Colourists (United Kingdom) and the American Association of Textile Chemists and Colorists (USA)\u2014this index is recognized internationally as the authoritative reference on colorants. It encompasses more than 27,000 products under more than 13,000 generic color index names.\nIn the CII schema, each pigment has a generic index number that identifies it chemically, regardless of proprietary and historic names. For example, Phthalocyanine Blue BN has been known by a variety of generic and proprietary names since its discovery in the 1930s. In much of Europe, phthalocyanine blue is better known as Helio Blue, or by a proprietary name such as Winsor Blue. An American paint manufacturer, Grumbacher, registered an alternate spelling (Thanos Blue) as a trademark. Colour Index International resolves all these conflicting historic, generic, and proprietary names so that manufacturers and consumers can identify the pigment (or dye) used in a particular color product. In the CII, all phthalocyanine blue pigments are designated by a generic color index number as either PB15 or PB16, short for pigment blue 15 and pigment blue 16; these two numbers reflect slight variations in molecular structure, which produce a slightly more greenish or reddish blue.\n\n\n== Figures of merit ==\nThe following are some of the attributes of pigments that determine their suitability for particular manufacturing processes and applications:\n\nLightfastness and sensitivity for damage from ultraviolet light\nHeat stability\nToxicity\nTinting strength\nStaining\nDispersion (which can be measured with a Hegman gauge)\nOpacity or transparency\nResistance to alkalis and acids\nReactions and interactions between pigments\n\n\n== Swatches ==\nSwatches are used to communicate colors accurately. The types of swatches are dictated by the media, i.e., printing, computers, plastics, and textiles. Generally, the medium that offers the broadest gamut of color shades is widely used across diverse media.\n\n\n=== Printed swatches ===\nReference standards are provided by printed swatches of color shades. PANTONE, RAL, Munsell, etc. are widely used standards of color communication across diverse media like printing, plastics, and textiles.\n\n\n=== Plastic swatches ===\nCompanies manufacturing color masterbatches and pigments for plastics offer plastic swatches in injection molded color chips. These color chips are supplied to the designer or customer to choose and select the color for their specific plastic products.\nPlastic swatches are available in various special effects like pearl, metallic, fluorescent, sparkle, mosaic etc. However, these effects are difficult to replicate on other media like print and computer display. Plastic swatches have been created by 3D modelling to including various special effects.\n\n\n=== Computer swatches ===\nThe appearance of pigments in natural light is difficult to replicate on a computer display. Approximations are required. The Munsell Color System provides an objective measure of color in three dimensions: hue, value (or lightness), and chroma. Computer displays in general fail to show the true chroma of many pigments, but the hue and lightness can be reproduced with relative accuracy. However, when the gamma of a computer display deviates from the reference value, the hue is also systematically biased.\nThe following approximations assume a display device at gamma 2.2, using the sRGB color space. The further a display device deviates from these standards, the less accurate these swatches will be. Swatches are based on the average measurements of several lots of single-pigment watercolor paints, converted from Lab color space to sRGB color space for viewing on a computer display. The appearance of a pigment may depend on the brand and even the batch. Furthermore, pigments have inherently complex reflectance spectra that will render their color appearance greatly different depending on the spectrum of the source illumination, a property called metamerism. Averaged measurements of pigment samples will only yield approximations of their true appearance under a specific source of illumination. Computer display systems use a technique called chromatic adaptation transforms to emulate the correlated color temperature of illumination sources, and cannot perfectly reproduce the intricate spectral combinations originally seen. In many cases, the perceived color of a pigment falls outside of the gamut of computer displays and a method called gamut mapping is used to approximate the true appearance. Gamut mapping trades off any one of lightness, hue, or saturation accuracy to render the color on screen, depending on the priority chosen in the conversion's ICC rendering intent.\n\n\n== Biological pigments ==\n\nIn biology, a pigment is any colored material of plant or animal cells. Many biological structures, such as skin, eyes, fur, and hair contain pigments (such as melanin).\nAnimal skin coloration often comes about through specialized cells called chromatophores, which animals such as the octopus and chameleon can control to vary the animal's color. Many conditions affect the levels or nature of pigments in plant, animal, some protista, or fungus cells. For instance, the disorder called albinism affects the level of melanin production in animals.\nPigmentation in organisms serves many biological purposes, including camouflage, mimicry, aposematism (warning), sexual selection and other forms of signalling, photosynthesis (in plants), and basic physical purposes such as protection from sunburn.\nPigment color differs from structural color in that pigment color is the same for all viewing angles, whereas structural color is the result of selective reflection or iridescence, usually because of multilayer structures. For example, butterfly wings typically contain structural color, although many butterflies have cells that contain pigment as well.\n\n\n== Pigments by chemical composition ==\n\nAluminium pigment: aluminum powder\nBarium: barium white (lithopone)\nCadmium pigments: cadmium yellow, cadmium red, cadmium green, cadmium orange, cadmium sulfoselenide\nCarbon pigments: carbon black (including vine black, lamp black), ivory black (bone charcoal)\nChromium pigments: chrome yellow and chrome green (viridian)\nCobalt pigments: cobalt violet, cobalt blue, cerulean blue, aureolin (cobalt yellow)\nCopper pigments: azurite, Han purple, Han blue, Egyptian blue, malachite, Paris green, Phthalocyanine Blue BN, Phthalocyanine Green G, verdigris\nIron oxide pigments: sanguine, caput mortuum, oxide red, red ochre, yellow ochre, Venetian red, Prussian blue, raw sienna, burnt sienna, raw umber, burnt umber\nLead pigments: lead white, cremnitz white, Naples yellow, red lead, lead-tin yellow\nManganese pigments: manganese violet, YInMn blue\nMercury pigments: vermilion\nTitanium pigments: titanium yellow, titanium beige, titanium white, titanium black\nUltramarine pigments (based on sulfur): ultramarine, ultramarine green shade\nZinc pigments: zinc white, zinc ferrite, zinc yellow\n\n\n=== Biological and organic ===\nBiological origins: alizarin, gamboge, cochineal red, rose madder, indigo, Indian yellow, Tyrian purple\nNon-biological organic: quinacridone, magenta, phthalo green, phthalo blue, pigment red 170, diarylide yellow\n\n\n== See also ==\nBlue pigments\nLake pigment\nList of Stone Age art\nRed pigments\nRock art\nSubtractive color\n\n\n== Notes ==\n\n\n== References ==\nBall, Philip (2002). Bright Earth: Art and the Invention of Color. Farrar, Straus and Giroux. ISBN 0-374-11679-2.\nDoerner, Max (1984). The Materials of the Artist and Their Use in Painting: With Notes on the Techniques of the Old Masters, Revised Edition. Harcourt. ISBN 0-15-657716-X.\nFinlay, Victoria (2003). Color: A Natural History of the Palette. Random House. ISBN 0-8129-7142-6.\nGage, John (1999). Color and Culture: Practice and Meaning from Antiquity to Abstraction. University of California Press. ISBN 0-520-22225-3.\nMeyer, Ralph (1991). The Artist's Handbook of Materials and Techniques, Fifth Edition. Viking. ISBN 0-670-83701-6.\nFeller, R. L., ed. (1986). Artists' Pigments. A Handbook of Their History and Characteristics, Vol. 1. London: Cambridge University Press.\nRoy, A., ed. (1993). Artists' Pigments. A Handbook of Their History and Characteristics, Vol. 2. Oxford University Press.\nFitzhugh, E. W., ed. (1997). Artists' Pigments. A Handbook of Their History and Characteristics, Vol. 3. Oxford University Press.\nBerrie, B., ed. (2007). Artists' Pigments. A Handbook of Their History and Characteristics, Vol. 4. Archetype Books.\n\n\n== External links ==\n\nPigments through the ages\nColourLex Pigment Lexicon\nSarah Lowengard,The Creation of Color in Eighteenth-century Europe, Columbia University Press, 2006\nAlchemy's Rainbow: Pigment Science and the Art of Conservation on YouTube, Chemical Heritage Foundation\nPoisons and Pigments: A Talk with Art Historian Elisabeth Berry-Drago on YouTube, Chemical Heritage Foundation\nThe Quest for the Next Billion-Dollar Color", "Electrical_resistance_and_conductance": "The electrical resistance of an object is a measure of its opposition to the flow of electric current. Its reciprocal quantity is electrical conductance, measuring the ease with which an electric current passes. Electrical resistance shares some conceptual parallels with mechanical friction. The SI unit of electrical resistance is the ohm (\u03a9), while electrical conductance is measured in siemens (S) (formerly called the 'mho' and then represented by \u2127).\nThe resistance of an object depends in large part on the material it is made of. Objects made of electrical insulators like rubber tend to have very high resistance and low conductance, while objects made of electrical conductors like metals tend to have very low resistance and high conductance. This relationship is quantified by resistivity or conductivity. The nature of a material is not the only factor in resistance and conductance, however; it also depends on the size and shape of an object because these properties are extensive rather than intensive. For example, a wire's resistance is higher if it is long and thin, and lower if it is short and thick. All objects resist electrical current, except for superconductors, which have a resistance of zero.\nThe resistance R of an object is defined as the ratio of voltage V across it to current I through it, while the conductance G is the reciprocal:\n\nFor a wide variety of materials and conditions, V and I  are directly proportional to each other, and therefore R and G are constants (although they will depend on the size and shape of the object, the material it is made of, and other factors like temperature or strain). This proportionality is called Ohm's law, and materials that satisfy it are called ohmic materials.\nIn other cases, such as a transformer, diode or battery, V and I are not directly proportional. The ratio V/I is sometimes still useful, and is referred to as a chordal resistance or static resistance, since it corresponds to the inverse slope of a chord between the origin and an I\u2013V curve. In other situations, the derivative \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              V\n            \n            \n              \n                d\n              \n              I\n            \n          \n        \n      \n    \n    {\\textstyle {\\frac {\\mathrm {d} V}{\\mathrm {d} I}}}\n   may be most useful; this is called the differential resistance.\n\n\n== Introduction ==\n\nIn the hydraulic analogy, current flowing through a wire (or resistor) is like water flowing through a pipe, and the voltage drop across the wire is like the pressure drop that pushes water through the pipe. Conductance is proportional to how much flow occurs for a given pressure, and resistance is proportional to how much pressure is required to achieve a given flow. \nThe voltage drop (i.e., difference between voltages on one side of the resistor and the other), not the voltage itself, provides the driving force pushing current through a resistor. In hydraulics, it is similar: the pressure difference between two sides of a pipe, not the pressure itself, determines the flow through it. For example, there may be a large water pressure above the pipe, which tries to push water down through the pipe. But there may be an equally large water pressure below the pipe, which tries to push water back up through the pipe. If these pressures are equal, no water flows. (In the image at right, the water pressure below the pipe is zero.)\nThe resistance and conductance of a wire, resistor, or other element is mostly determined by two properties:\n\ngeometry (shape), and\nmaterialGeometry is important because it is more difficult to push water through a long, narrow pipe than a wide, short pipe. In the same way, a long, thin copper wire has higher resistance (lower conductance) than a short, thick copper wire.\nMaterials are important as well. A pipe filled with hair restricts the flow of water more than a clean pipe of the same shape and size. Similarly, electrons can flow freely and easily through a copper wire, but cannot flow as easily through a steel wire of the same shape and size, and they essentially cannot flow at all through an insulator like rubber, regardless of its shape. The difference between copper, steel, and rubber is related to their microscopic structure and electron configuration, and is quantified by a property called resistivity.\nIn addition to geometry and material, there are various other factors that influence resistance and conductance, such as temperature; see below.\n\n\n== Conductors and resistors ==\n\nSubstances in which electricity can flow are called conductors. A piece of conducting material of a particular resistance meant for use in a circuit is called a resistor. Conductors are made of high-conductivity materials such as metals, in particular copper and aluminium. Resistors, on the other hand, are made of a wide variety of materials depending on factors such as the desired resistance, amount of energy that it needs to dissipate, precision, and costs.\n\n\n== Ohm's law ==\n\nFor many materials, the current I through the material is proportional to the voltage V applied across it:\n\nover a wide range of voltages and currents.  Therefore, the resistance and conductance of objects or electronic components made of these materials is constant. This relationship is called Ohm's law, and materials which obey it are called ohmic materials.  Examples of ohmic components are wires and resistors. The current\u2013voltage graph of an ohmic device consists of a straight line through the origin with positive slope.\nOther components and materials used in electronics do not obey Ohm's law; the current is not proportional to the voltage, so the resistance varies with the voltage and current through them.  These are called nonlinear or non-ohmic. Examples include diodes and fluorescent lamps.  The current-voltage curve of a nonohmic device is a curved line.\n\n\n== Relation to resistivity and conductivity ==\n\nThe resistance of a given object depends primarily on two factors: what material it is made of, and its shape. For a given material, the resistance is inversely proportional to the cross-sectional area; for example, a thick copper wire has lower resistance than an otherwise-identical thin copper wire. Also, for a given material, the resistance is proportional to the length; for example, a long copper wire has higher resistance than an otherwise-identical short copper wire. The resistance R and conductance G of a conductor of uniform cross section, therefore, can be computed as\n\nwhere \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of the conductor, measured in metres (m), A is the cross-sectional area of the conductor measured in square metres (m2), \u03c3 (sigma) is the electrical conductivity measured in siemens per meter (S\u00b7m\u22121), and \u03c1 (rho) is the electrical resistivity (also called specific electrical resistance) of the material, measured in ohm-metres (\u03a9\u00b7m). The resistivity and conductivity are proportionality constants, and therefore depend only on the material the wire is made of, not the geometry of the wire. Resistivity and conductivity are reciprocals: \n  \n    \n      \n        \u03c1\n        =\n        1\n        \n          /\n        \n        \u03c3\n      \n    \n    {\\displaystyle \\rho =1/\\sigma }\n  . Resistivity is a measure of the material's ability to oppose electric current.\nThis formula is not exact, as it assumes the current density is totally uniform in the conductor, which is not always true in practical situations. However, this formula still provides a good approximation for long thin conductors such as wires.\nAnother situation for which this formula is not exact is with alternating current (AC), because the skin effect inhibits current flow near the center of the conductor. For this reason, the geometrical cross-section is different from the effective cross-section in which current actually flows, so resistance is higher than expected. Similarly, if two conductors near each other carry AC current, their resistances increase due to the proximity effect. At commercial power frequency, these effects are significant for large conductors carrying large currents, such as busbars in an electrical substation, or large power cables carrying more than a few hundred amperes.\nThe resistivity of different materials varies by an enormous amount: For example, the conductivity of teflon is about 1030 times lower than the conductivity of copper. Loosely speaking, this is because metals have large numbers of \"delocalized\" electrons that are not stuck in any one place, so they are free to move across large distances. In an insulator, such as Teflon, each electron is tightly bound to a single molecule so a great force is required to pull it away. Semiconductors lie between these two extremes. More details can be found in the article: Electrical resistivity and conductivity. For the case of electrolyte solutions, see the article: Conductivity (electrolytic).\nResistivity varies with temperature. In semiconductors, resistivity also changes when exposed to light. See below.\n\n\n== Measurement ==\n\nAn instrument for measuring resistance is called an ohmmeter.  Simple ohmmeters cannot measure low resistances accurately because the resistance of their measuring leads causes a voltage drop that interferes with the measurement, so more accurate devices use four-terminal sensing.\n\n\n== Typical values ==\n\n\n== Static and differential resistance ==\n\nMany electrical elements, such as diodes and batteries do not satisfy Ohm's law. These are called non-ohmic or non-linear, and their current\u2013voltage curves are not straight lines through the origin.\nResistance and conductance can still be defined for non-ohmic elements. However, unlike ohmic resistance, non-linear resistance is not constant but varies with the voltage or current through the device; i.e., its operating point. There are two types of resistance:\nStatic resistance\nAlso called chordal or DC resistance\nThis corresponds to the usual definition of resistance; the voltage divided by the current\n\nIt is the slope of the line (chord) from the origin through the point on the curve. Static resistance determines the power dissipation in an electrical component. Points on the current\u2013voltage curve located in the 2nd or 4th quadrants, for which the slope of the chordal line is negative, have negative static resistance. Passive devices, which have no source of energy, cannot have negative static resistance. However active devices such as transistors or op-amps can synthesize negative static resistance with feedback, and it is used in some circuits such as gyrators.\n\nDifferential resistance\nAlso called dynamic, incremental, or small-signal resistance\nDifferential resistance is the derivative of the voltage with respect to the current; the slope of the current\u2013voltage curve at a point\n\nIf the current\u2013voltage curve is nonmonotonic (with peaks and troughs), the curve has a negative slope in some regions\u2014so in these regions the device has negative differential resistance. Devices with negative differential resistance can amplify a signal applied to them, and are used to make amplifiers and oscillators. These include tunnel diodes, Gunn diodes, IMPATT diodes, magnetron tubes, and unijunction transistors.\n\n\n== AC circuits ==\n\n\n=== Impedance and admittance ===\n\nWhen an alternating current flows through a circuit, the relation between current and voltage across a circuit element is characterized not only by the ratio of their magnitudes, but also the difference in their phases. For example, in an ideal resistor, the moment when the voltage reaches its maximum, the current also reaches its maximum (current and voltage are oscillating in phase). But for a capacitor or inductor, the maximum current flow occurs as the voltage passes through zero and vice versa (current and voltage are oscillating 90\u00b0 out of phase, see image below). Complex numbers are used to keep track of both the phase and magnitude of current and voltage:\n\nwhere:\n\nt is time;\nu(t) and i(t) are the voltage and current as a function of time, respectively;\nU0 and I0 indicate the amplitude of the voltage and current, respectively;\n\n  \n    \n      \n        \u03c9\n      \n    \n    {\\displaystyle \\omega }\n   is the angular frequency of the AC current;\n\n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n   is the displacement angle;\nU and I are the complex-valued voltage and current, respectively;\nZ and Y are the complex impedance and admittance, respectively;\n\n  \n    \n      \n        \n          \n            \n              R\n              \n                e\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {R_{e}}}}\n   indicates the real part of a complex number; and\n\n  \n    \n      \n        j\n        \u2261\n        \n          \n            \u2212\n            1\n             \n          \n        \n      \n    \n    {\\displaystyle j\\equiv {\\sqrt {-1\\ }}}\n   is the imaginary unit.The impedance and admittance may be expressed as complex numbers that can be broken into real and imaginary parts:\n\nwhere R is resistance, G is conductance, X is reactance, and B is susceptance. These lead to the complex number identities\n\nwhich are true in all cases, whereas \n  \n    \n      \n         \n        R\n        =\n        1\n        \n          /\n        \n        G\n         \n      \n    \n    {\\displaystyle \\ R=1/G\\ }\n   is only true in the special cases of either DC or reactance-free current.\nThe complex angle \n  \n    \n      \n         \n        \u03b8\n        =\n        arg\n        \u2061\n        (\n        Z\n        )\n        =\n        \u2212\n        arg\n        \u2061\n        (\n        Y\n        )\n         \n      \n    \n    {\\displaystyle \\ \\theta =\\arg(Z)=-\\arg(Y)\\ }\n   is the phase difference between the voltage and current passing through a component with impedance Z. For capacitors and inductors, this angle is exactly -90\u00b0 or +90\u00b0, respectively, and X and B are nonzero. Ideal resistors have an angle of 0\u00b0, since X is zero (and hence B also), and Z and Y reduce to R and G respectively. In general, AC systems are designed to keep the phase angle close to 0\u00b0 as much as possible, since it reduces the reactive power, which does no useful work at a load. In a simple case with an inductive load (causing the phase to increase), a capacitor may be added for compensation at one frequency, since the capacitor's phase shift is negative, bringing the total impedance phase closer to 0\u00b0 again.\nY is the reciprocal of Z (\n  \n    \n      \n         \n        Z\n        =\n        1\n        \n          /\n        \n        Y\n         \n      \n    \n    {\\displaystyle \\ Z=1/Y\\ }\n  ) for all circuits, just as \n  \n    \n      \n        R\n        =\n        1\n        \n          /\n        \n        G\n      \n    \n    {\\displaystyle R=1/G}\n   for DC circuits containing only resistors, or AC circuits for which either the reactance or susceptance happens to be zero (X or B = 0, respectively) (if one is zero, then for realistic systems both must be zero).\n\n\n=== Frequency dependence ===\nA key feature of AC circuits is that the resistance and conductance can be frequency-dependent, a phenomenon known as the universal dielectric response. One reason, mentioned above is the skin effect (and the related proximity effect). Another reason is that the resistivity itself may depend on frequency (see Drude model, deep-level traps, resonant frequency, Kramers\u2013Kronig relations, etc.)\n\n\n== Energy dissipation and Joule heating ==\n\nResistors (and other elements with resistance) oppose the flow of electric current; therefore, electrical energy is required to push current through the resistance. This electrical energy is dissipated, heating the resistor in the process. This is called Joule heating (after James Prescott Joule), also called ohmic heating or resistive heating.\nThe dissipation of electrical energy is often undesired, particularly in the case of transmission losses in power lines. High voltage transmission helps reduce the losses by reducing the current for a given power.\nOn the other hand, Joule heating is sometimes useful, for example in electric stoves and other electric heaters (also called resistive heaters). As another example, incandescent lamps rely on Joule heating: the filament is heated to such a high temperature that it glows \"white hot\" with thermal radiation (also called incandescence).\nThe formula for Joule heating is:\n\nwhere P is the power (energy per unit time) converted from electrical energy to thermal energy, R is the resistance, and I is the current through the resistor.\n\n\n== Dependence on other conditions ==\n\n\n=== Temperature dependence ===\n\nNear room temperature, the resistivity of metals typically increases as temperature is increased, while the resistivity of semiconductors typically decreases as temperature is increased. The resistivity of insulators and electrolytes may increase or decrease depending on the system. For the detailed behavior and explanation, see Electrical resistivity and conductivity.\nAs a consequence, the resistance of wires, resistors, and other components often change with temperature. This effect may be undesired, causing an electronic circuit to malfunction at extreme temperatures. In some cases, however, the effect is put to good use. When temperature-dependent resistance of a component is used purposefully, the component is called a resistance thermometer or thermistor. (A resistance thermometer is made of metal, usually platinum, while a thermistor is made of ceramic or polymer.)\nResistance thermometers and thermistors are generally used in two ways. First, they can be used as thermometers: by measuring the resistance, the temperature of the environment can be inferred. Second, they can be used in conjunction with Joule heating (also called self-heating): if a large current is running through the resistor, the resistor's temperature rises and therefore its resistance changes. Therefore, these components can be used in a circuit-protection role similar to fuses, or for feedback in circuits, or for many other purposes. In general, self-heating can turn a resistor into a nonlinear and hysteretic circuit element. For more details see Thermistor#Self-heating effects.\nIf the temperature T does not vary too much, a linear approximation is typically used:\n\nwhere \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is called the temperature coefficient of resistance, \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n   is a fixed reference temperature (usually room temperature), and \n  \n    \n      \n        \n          R\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle R_{0}}\n   is the resistance at temperature \n  \n    \n      \n        \n          T\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle T_{0}}\n  . The parameter \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is an empirical parameter fitted from measurement data. Because the linear approximation is only an approximation, \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is different for different reference temperatures. For this reason it is usual to specify the temperature that \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   was measured at with a suffix, such as \n  \n    \n      \n        \n          \u03b1\n          \n            15\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{15}}\n  , and the relationship only holds in a range of temperatures around the reference.The temperature coefficient \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n   is typically +3\u00d710\u22123 K\u22121 to +6\u00d710\u22123 K\u22121 for metals near room temperature. It is usually negative for semiconductors and insulators, with highly variable magnitude.\n\n\n=== Strain dependence ===\n\nJust as the resistance of a conductor depends upon temperature, the resistance of a conductor depends upon strain. By placing a conductor under tension (a form of stress that leads to strain in the form of stretching of the conductor), the length of the section of conductor under tension increases and its cross-sectional area decreases. Both these effects contribute to increasing the resistance of the strained section of conductor. Under compression (strain in the opposite direction), the resistance of the strained section of conductor decreases. See the discussion on strain gauges for details about devices constructed to take advantage of this effect.\n\n\n=== Light illumination dependence ===\n\nSome resistors, particularly those made from semiconductors, exhibit photoconductivity, meaning that their resistance changes when light is shining on them. Therefore, they are called photoresistors (or light dependent resistors). These are a common type of light detector.\n\n\n== Superconductivity ==\n\nSuperconductors are materials that have exactly zero resistance and infinite conductance, because they can have V = 0 and I \u2260 0. This also means there is no joule heating, or in other words no dissipation of electrical energy. Therefore, if superconductive wire is made into a closed loop, current flows around the loop forever. Superconductors require cooling to temperatures near 4 K with liquid helium for most metallic superconductors like niobium\u2013tin alloys, or cooling to temperatures near 77 K with liquid nitrogen for the expensive, brittle and delicate ceramic high temperature superconductors.\nNevertheless, there are many technological applications of superconductivity, including superconducting magnets.\n\n\n== See also ==\nConductance quantum\nVon Klitzing constant (its reciprocal)\nElectrical measurements\nContact resistance\nElectrical resistivity and conductivity for more information about the physical mechanisms for conduction in materials.\nJohnson\u2013Nyquist noise\nQuantum Hall effect, a standard for high-accuracy resistance measurements.\nResistor\nRKM code\nSeries and parallel circuits\nSheet resistance\nSI electromagnetism units\nThermal resistance\nVoltage divider\nVoltage drop\n\n\n== Footnotes ==\n\n\n== References ==\n\n\n== External links ==\n\n\"Resistance calculator\". Vehicular Electronics Laboratory. Clemson University. Archived from the original on 11 July 2010.\n\"Electron conductance models using maximal entropy random walks\". wolfram.com. Wolfram Demonstrantions Project.", "Series_and_parallel_circuits": "Two-terminal components and electrical networks can be connected in series or parallel. The resulting electrical network will have two terminals, and itself can participate in a series or parallel topology. Whether a two-terminal \"object\" is an electrical component (e.g. a resistor) or an electrical network (e.g. resistors in series) is a matter of perspective. This article will use \"component\" to refer to a two-terminal \"object\" that participate in the series/parallel networks.\nComponents connected in series are connected along a single \"electrical path\", and each component has the same electric current through it, equal to the current through the network. The voltage across the network is equal to the sum of the voltages across each component.Components connected in parallel are connected along multiple paths, and each component has the same voltage across it, equal to the voltage across the network. The current through the network is equal to the sum of the currents through each component.\nThe two preceding statements are equivalent, except for exchanging the role of voltage and current.\nA circuit composed solely of components connected in series is known as a series circuit; likewise, one connected completely in parallel is known as a parallel circuit. Many circuits can be analyzed as a combination of series and parallel circuits, along with other configurations.\nIn a series circuit, the current that flows through each of the components is the same, and the voltage across the circuit is the sum of the individual voltage drops across each component. In a parallel circuit, the voltage across each of the components is the same, and the total current is the sum of the currents flowing through each component.Consider a very simple circuit consisting of four light bulbs and a 12-volt automotive battery. If a wire joins the battery to one bulb, to the next bulb, to the next bulb, to the next bulb, then back to the battery in one continuous loop, the bulbs are said to be in series. If each bulb is wired to the battery in a separate loop, the bulbs are said to be in parallel. If the four light bulbs are connected in series, the same current flows through all of them and the voltage drop is 3 volts across each bulb, which may not be sufficient to make them glow.  If the light bulbs are connected in parallel, the currents through the light bulbs combine to form the current in the battery, while the voltage drop is 12 volts across each bulb and they all glow.\nIn a series circuit, every device must function for the circuit to be complete. If one bulb burns out in a series circuit, the entire circuit is broken. In parallel circuits, each light bulb has its own circuit, so all but one light could be burned out, and the last one will still function.\n\n\n== Series circuits ==\nSeries circuits are sometimes referred to as current-coupled or daisy chain-coupled. The current in a series circuit goes through every component in the circuit. Therefore, all of the components in a series connection carry the same current.\nA series circuit has only one path through which its current can flow. Opening or breaking a series circuit at any point causes the entire circuit to \"open\" or stop operating. For example, if even one of the light bulbs in an older-style string of Christmas tree lights burns out or is removed, the entire string becomes inoperable until the faulty bulb is replaced.\n\n\n=== Current ===\n\nIn a series circuit, the current is the same for all of the elements.\n\n\n=== Voltage ===\nIn a series circuit, the voltage is the sum of the voltage drops of the individual components (resistance units).\n\n\n=== Resistance units ===\nThe total resistance of two or more resistors connected in series is equal to the sum of their individual resistances:\n\nHere, the subscript s in Rs denotes \"series\", and Rs denotes resistance in a series.\nElectrical conductance presents a reciprocal quantity to resistance. Total conductance of a series circuits of pure resistances, therefore, can be calculated from the following expression:\n\nFor a special case of two conductances in series, the total conductance is equal to:\n\n\n=== Inductors ===\nInductors follow the same law, in that the total inductance of non-coupled inductors in series is equal to the sum of their individual inductances:\n\nHowever, in some situations, it is difficult to prevent adjacent inductors from influencing each other as the magnetic field of one device couples with the windings of its neighbors. This influence is defined by the mutual inductance M. For example, if two inductors are in series, there are two possible equivalent inductances depending on how the magnetic fields of both inductors influence each other.\nWhen there are more than two inductors, the mutual inductance between each of them and the way the coils influence each other complicates the calculation. For a larger number of coils the total combined inductance is given by the sum of all mutual inductances between the various coils including the mutual inductance of each given coil with itself, which is termed self-inductance or simply inductance. For three coils, there are six mutual inductances \n  \n    \n      \n        \n          M\n          \n            12\n          \n        \n      \n    \n    {\\displaystyle M_{12}}\n  , \n  \n    \n      \n        \n          M\n          \n            13\n          \n        \n      \n    \n    {\\displaystyle M_{13}}\n  , \n  \n    \n      \n        \n          M\n          \n            23\n          \n        \n      \n    \n    {\\displaystyle M_{23}}\n   and \n  \n    \n      \n        \n          M\n          \n            21\n          \n        \n      \n    \n    {\\displaystyle M_{21}}\n  , \n  \n    \n      \n        \n          M\n          \n            31\n          \n        \n      \n    \n    {\\displaystyle M_{31}}\n   and \n  \n    \n      \n        \n          M\n          \n            32\n          \n        \n      \n    \n    {\\displaystyle M_{32}}\n  . There are also the three self-inductances of the three coils: \n  \n    \n      \n        \n          M\n          \n            11\n          \n        \n      \n    \n    {\\displaystyle M_{11}}\n  , \n  \n    \n      \n        \n          M\n          \n            22\n          \n        \n      \n    \n    {\\displaystyle M_{22}}\n   and \n  \n    \n      \n        \n          M\n          \n            33\n          \n        \n      \n    \n    {\\displaystyle M_{33}}\n  .\nTherefore\n\nBy reciprocity, \n  \n    \n      \n        \n          M\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle M_{ij}}\n   = \n  \n    \n      \n        \n          M\n          \n            j\n            i\n          \n        \n      \n    \n    {\\displaystyle M_{ji}}\n   so that the last two groups can be combined. The first three terms represent the sum of the self-inductances of the various coils. The formula is easily extended to any number of series coils with mutual coupling. The method can be used to find the self-inductance of large coils of wire of any cross-sectional shape by computing the sum of the mutual inductance of each turn of wire in the coil with every other turn since in such a coil all turns are in series.\n\n\n=== Capacitors ===\n\nCapacitors follow the same law using the reciprocals. The total capacitance of capacitors in series is equal to the reciprocal of the sum of the reciprocals of their individual capacitances:\n\nEquivalently using elastance (the reciprocal of capacitance), the total series elastance equals the sum of each capacitor's elastance.\n\n\n=== Switches ===\nTwo or more switches in series form a logical AND; the circuit only carries current if all switches are closed. See AND gate.\n\n\n=== Cells and batteries ===\nA battery is a collection of electrochemical cells. If the cells are connected in series, the voltage of the battery will be the sum of the cell voltages. For example, a 12 volt car battery contains six 2-volt cells connected in series. Some vehicles, such as trucks, have two 12 volt batteries in series to feed the 24-volt system.\n\n\n== Parallel circuits ==\n\nIf two or more components are connected in parallel, they have the same difference of potential (voltage) across their ends.  The potential differences across the components are the same in magnitude, and they also have identical polarities. The same voltage is applied to all circuit components connected in parallel. The total current is the sum of the currents through the individual components, in accordance with Kirchhoff's current law.\n\n\n=== Voltage ===\nIn a parallel circuit, the voltage is the same for all elements.\n\n\n=== Current ===\nThe current in each individual resistor is found by Ohm's law. Factoring out the voltage gives\n\n\n=== Resistance units ===\nTo find the total resistance of all components, add the reciprocals of the resistances \n  \n    \n      \n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle R_{i}}\n   of each component and take the reciprocal of the sum. Total resistance will always be less than the value of the smallest resistance:\n\nFor only two resistances, the unreciprocated expression is reasonably simple:\n\nThis sometimes goes by the mnemonic product over sum.\nFor N equal resistances in parallel, the reciprocal sum expression simplifies to:\n\nand therefore to:\n\nTo find the current in a component with resistance \n  \n    \n      \n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle R_{i}}\n  , use Ohm's law again:\n\nThe components divide the current according to their reciprocal resistances, so, in the case of two resistors,\n\nAn old term for devices connected in parallel is multiple, such as multiple connections for arc lamps.\nSince electrical conductance \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is reciprocal to resistance, the expression for total conductance of a parallel circuit of resistors reads:\n\nThe relations for total conductance and resistance stand in a complementary relationship: the expression for a series connection of resistances is the same as for parallel connection of conductances, and vice versa.\n\n\n=== Inductors ===\nInductors follow the same law, in that the total inductance of non-coupled inductors in parallel is equal to the reciprocal of the sum of the reciprocals of their individual inductances:\n\nIf the inductors are situated in each other's magnetic fields, this approach is invalid due to mutual inductance. If the mutual inductance between two coils in parallel is M, the equivalent inductor is:\n\nIf \n  \n    \n      \n        \n          L\n          \n            1\n          \n        \n        =\n        \n          L\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle L_{1}=L_{2}}\n  \n\nThe sign of \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   depends on how the magnetic fields influence each other. For two equal tightly coupled coils the total inductance is close to that of every single coil. If the polarity of one coil is reversed so that M is negative, then the parallel inductance is nearly zero or the combination is almost non-inductive. It is assumed in the \"tightly coupled\" case M is very nearly equal to L. However, if the inductances are not equal and the coils are tightly coupled there can be near short circuit conditions and high circulating currents for both positive and negative values of M, which can cause problems.\nMore than three inductors become more complex and the mutual inductance of each inductor on each other inductor and their influence on each other must be considered. For three coils, there are three mutual inductances \n  \n    \n      \n        \n          M\n          \n            12\n          \n        \n      \n    \n    {\\displaystyle M_{12}}\n  , \n  \n    \n      \n        \n          M\n          \n            13\n          \n        \n      \n    \n    {\\displaystyle M_{13}}\n   and \n  \n    \n      \n        \n          M\n          \n            23\n          \n        \n      \n    \n    {\\displaystyle M_{23}}\n  . This is best handled by matrix methods and summing the terms of the inverse of the \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   matrix (3\u00d73 in this case).\nThe pertinent equations are of the form:\n\n\n=== Capacitors ===\nThe total capacitance of capacitors in parallel is equal to the sum of their individual capacitances:\n\nThe working voltage of a parallel combination of capacitors is always limited by the smallest working voltage of an individual capacitor.\n\n\n=== Switches ===\nTwo or more switches in parallel form a logical OR; the circuit carries current if at least one switch is closed. See OR gate.\n\n\n=== Cells and batteries ===\nIf the cells of a battery are connected in parallel, the battery voltage will be the same as the cell voltage, but the current supplied by each cell will be a fraction of the total current. For example, if a battery comprises four identical cells connected in parallel and delivers a current of 1 ampere, the current supplied by each cell will be 0.25 ampere. If the cells are not identical in voltage, cells with higher voltages will attempt to charge those with lower ones, potentially damaging them.\nParallel-connected batteries were widely used to power the valve filaments in portable radios. Lithium-ion rechargeable batteries (particularly laptop batteries) are often connected in parallel to increase the ampere-hour rating. Some solar electric systems have batteries in parallel to increase the storage capacity; a close approximation of total amp-hours is the sum of all amp-hours of in-parallel batteries.\n\n\n== Combining conductances ==\nFrom Kirchhoff's circuit laws the rules for combining conductance can be deducted. For two conductances \n  \n    \n      \n        \n          G\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle G_{1}}\n   and \n  \n    \n      \n        \n          G\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle G_{2}}\n   in parallel, the voltage across them is the same and from Kirchhoff's current law (KCL) the total current is\n\nSubstituting Ohm's law for conductances gives\n\nand the equivalent conductance will be,\n\nFor two conductances \n  \n    \n      \n        \n          G\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle G_{1}}\n   and \n  \n    \n      \n        \n          G\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle G_{2}}\n   in series the current through them will be the same and Kirchhoff's Voltage Law says that the voltage across them is the sum of the voltages across each conductance, that is,\n\nSubstituting Ohm's law for conductance then gives,\n\nwhich in turn gives the formula for the equivalent conductance,\n\nThis equation can be rearranged slightly, though this is a special case that will only rearrange like this for two components.\n\nFor three conductances in series,\n\n\n== Notation ==\nThe value of two components in parallel is often represented in equations by the parallel operator, two vertical lines (\u2225), borrowing the parallel lines notation from geometry.\n\nThis simplifies expressions that would otherwise become complicated by expansion of the terms.  For instance:\n\nIf n components are in parallel, then\n\n\n== Applications ==\nA common application of series circuit in consumer electronics is in batteries, where several cells connected in series are used to obtain a convenient operating voltage. Two disposable zinc cells in series might power a flashlight or remote control at 3 volts; the battery pack for a hand-held power tool might contain a dozen lithium-ion cells wired in series to provide 48 volts.\nSeries circuits were formerly used for lighting in electric multiple units trains.  For example, if the supply voltage was 600 volts there might be eight 70-volt bulbs in series (total 560 volts) plus a resistor to drop the remaining 40 volts.  Series circuits for train lighting were superseded, first by motor-generators, then by solid state devices.\nSeries resistance can also be applied to the arrangement of blood vessels within a given organ.  Each organ is supplied by a large artery, smaller arteries, arterioles, capillaries, and veins arranged in series. The total resistance is the sum of the individual resistances, as expressed by the following equation: Rtotal = Rartery + Rarterioles + Rcapillaries. The largest proportion of resistance in this series is contributed by the arterioles.Parallel resistance is illustrated by the circulatory system. Each organ is supplied by an artery that branches off the aorta. The total resistance of this parallel arrangement is expressed by the following equation: 1/Rtotal = 1/Ra + 1/Rb + ... + 1/Rn. Ra, Rb, and Rn are the resistances of the renal, hepatic, and other arteries respectively. The total resistance is less than the resistance of any of the individual arteries.\n\n\n== See also ==\nAnti-parallel (electronics)\nCombining impedances\nCurrent divider\nEquivalent impedance transforms\nHydraulic analogy\nNetwork analysis (electrical circuits)\nResistance distance\nSeries-parallel duality\nSeries-parallel partial order\nSeries and parallel springs\nTopology (electrical circuits)\nVoltage divider\nWheatstone bridge\nY-\u0394 transform\n\n\n== References ==\n\n\n== Further reading ==\nWilliams, Tim (2005). The Circuit Designer's Companion. Butterworth-Heinemann. ISBN 0-7506-6370-7.\n\"Resistor combinations: How many values using 1K ohm resistors?\". EDN magazine.\nGrotz, Bernhard (2018-01-04). \"Str\u00f6mungswiderstand\". Mechanik der Fl\u00fcssigkeiten (in German).", "Creep_(deformation)": "In materials science, creep (sometimes called cold flow) is the tendency of a solid material to undergo slow deformation while subject to persistent mechanical stresses. It can occur as a result of long-term exposure to high levels of stress that are still below the yield strength of the material. Creep is more severe in materials that are subjected to heat for long periods and generally increases as they near their melting point.\nThe rate of deformation is a function of the material's properties, exposure time, exposure temperature and the applied structural load. Depending on the magnitude of the applied stress and its duration, the deformation may become so large that a component can no longer perform its function \u2013 for example creep of a turbine blade could cause the blade to contact the casing, resulting in the failure of the blade. Creep is usually of concern to engineers and metallurgists when evaluating components that operate under high stresses or high temperatures. Creep is a deformation mechanism that may or may not constitute a failure mode. For example, moderate creep in concrete is sometimes welcomed because it relieves tensile stresses that might otherwise lead to cracking.\nUnlike brittle fracture, creep deformation does not occur suddenly upon the application of stress. Instead, strain accumulates as a result of long-term stress. Therefore, creep is a \"time-dependent\" deformation.\n\n\n== Temperature dependence ==\nThe temperature range in which creep deformation may occur differs in various materials. Creep deformation generally occurs when a material is stressed at a temperature near its melting point. While tungsten requires a temperature in the thousands of degrees before creep deformation can occur, lead may creep at room temperature, and ice will creep at temperatures below 0 \u00b0C (32 \u00b0F). Plastics and low-melting-temperature metals, including many solders, can begin to creep at room temperature. Glacier flow is an example of creep processes in ice. The effects of creep deformation generally become noticeable at approximately 35% of the melting point (in Kelvin) for metals and at 45% of melting point for ceramics.\n\n\n== Stages ==\n\nCreep behavior can be split into three main stages.\nIn primary, or transient, creep, the strain rate is a function of time. In Class M materials, which include most pure materials, strain rate decreases over time. This can be due to increasing dislocation density, or it can be due to evolving grain size. In class A materials, which have large amounts of solid solution hardening, strain rate increases over time due to a thinning of solute drag atoms as dislocations move.In the secondary, or steady-state, creep, dislocation structure and grain size have reached equilibrium, and therefore strain rate is constant. Equations that yield a strain rate refer to the steady-state strain rate. Stress dependence of this rate depends on the creep mechanism.\nIn tertiary creep, the strain rate exponentially increases with stress. This can be due to necking  phenomena, internal cracks, or voids, which all decrease the cross-sectional area and increase the true stress on the region, further accelerating deformation and leading to fracture.\n\n\n== Mechanisms of deformation ==\nDepending on the temperature and stress, different deformation mechanisms are activated. Though there are generally many deformation mechanisms active at all times, usually one mechanism is dominant, accounting for almost all deformation.\nVarious mechanisms are:\n\nBulk diffusion (Nabarro\u2013Herring creep)\nGrain boundary diffusion (Coble creep)\nGlide-controlled dislocation creep: dislocations move via glide and climb, and the speed of glide is the dominant factor on strain rate\nClimb-controlled dislocation creep: dislocations move via glide and climb, and the speed of climb is the dominant factor on strain rate\nHarper\u2013Dorn creep: a low-stress creep mechanism in some pure materialsAt low temperatures and low stress, creep is essentially nonexistent and all strain is elastic. At low temperatures and high stress, materials experience plastic deformation rather than creep. At high temperatures and low stress, diffusional creep tends to be dominant, while at high temperatures and high stress, dislocation creep tends to be dominant.\n\n\n=== Deformation mechanism maps ===\n\nDeformation mechanism maps provide a visual tool categorizing the dominant deformation mechanism as a function of homologous temperature, shear modulus-normalized stress, and strain rate. Generally, two of these three properties (most commonly temperature and stress) are the axes of the map, while the third is drawn as contours on the map.\nTo populate the map, constitutive equations are found for each deformation mechanism. These are used to solve for the boundaries between each deformation mechanism, as well as the strain rate contours. \nDeformation mechanism maps can be used to compare different strengthening mechanisms, as well as compare different types of materials.\n\n\n== General equation ==\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b5\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              C\n              \n                \u03c3\n                \n                  m\n                \n              \n            \n            \n              d\n              \n                b\n              \n            \n          \n        \n        \n          e\n          \n            \n              \n                \u2212\n                Q\n              \n              \n                k\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\varepsilon }{\\mathrm {d} t}}={\\frac {C\\sigma ^{m}}{d^{b}}}e^{\\frac {-Q}{kT}}}\n  where \u03b5 is the creep strain, C is a constant dependent on the material and the particular creep mechanism, m and b are exponents dependent on the creep mechanism, Q is the activation energy of the creep mechanism, \u03c3 is the applied stress, d is the grain size of the material, k is Boltzmann's constant, and T is the absolute temperature.\n\n\n=== Dislocation creep ===\n\nAt high stresses (relative to the shear modulus), creep is controlled by the movement of dislocations. \nFor dislocation creep, Q = Q(self diffusion), 4 \u2264 m \u2264 6, and b < 1. Therefore, dislocation creep has a strong dependence on the applied stress and the intrinsic activation energy and a weaker dependence on grain size.  As grain size gets smaller, grain boundary area gets larger, so dislocation motion is impeded.\nSome alloys exhibit a very large stress exponent (m > 10), and this has typically been explained by introducing a \"threshold stress,\" \u03c3th, below which creep can't be measured. The modified power law equation then becomes:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b5\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        A\n        \n          \n            (\n            \n              \u03c3\n              \u2212\n              \n                \u03c3\n                \n                  \n                    t\n                    h\n                  \n                \n              \n            \n            )\n          \n          \n            m\n          \n        \n        \n          e\n          \n            \n              \n                \u2212\n                Q\n              \n              \n                \n                  \n                    \n                      R\n                      \u00af\n                    \n                  \n                \n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\varepsilon }{\\mathrm {d} t}}=A\\left(\\sigma -\\sigma _{\\rm {th}}\\right)^{m}e^{\\frac {-Q}{{\\bar {R}}T}}}\n  where A, Q and m can all be explained by conventional mechanisms (so 3 \u2264 m \u2264 10), and R is the gas constant. The creep increases with increasing applied stress, since the applied stress tends to drive the dislocation past the barrier, and make the dislocation get into a lower energy state after bypassing the obstacle, which means that the dislocation is inclined to pass the obstacle. In other words, part of the work required to overcome the energy barrier of passing an obstacle is provided by the applied stress and the remainder by thermal energy.\n\n\n=== Nabarro\u2013Herring creep ===\n\nNabarro\u2013Herring (NH) creep is a form of diffusion creep, while dislocation glide creep does not involve atomic diffusion. Nabarro\u2013Herring creep dominates at high temperatures and low stresses. As shown in the figure on the right, the lateral sides of the crystal are subjected to tensile stress and the horizontal sides to compressive stress. The atomic volume is altered by applied stress: it increases in regions under tension and decreases in regions under compression. So the activation energy for vacancy formation is changed by \u00b1\u03c3\u03a9, where \u03a9 is the atomic volume, the positive value is for compressive regions and negative value is for tensile regions. Since the fractional vacancy concentration is proportional to exp(\u2212Qf \u00b1 \u03c3\u03a9/RT), where Qf is the vacancy-formation energy, the vacancy concentration is higher in tensile regions than in compressive regions, leading to a net flow of vacancies from the regions under tension to the regions under compression, and this is equivalent to a net atom diffusion in the opposite direction, which causes the creep deformation: the grain elongates in the tensile stress axis and contracts in the compressive stress axis.\nIn Nabarro\u2013Herring creep, k is related to the diffusion coefficient of atoms through the lattice, Q = Q(self diffusion), m = 1, and b = 2. Therefore, Nabarro\u2013Herring creep has a weak stress dependence and a moderate grain size dependence, with the creep rate decreasing as the grain size is increased.\nNabarro\u2013Herring creep is strongly temperature dependent. For lattice diffusion of atoms to occur in a material, neighboring lattice sites or interstitial sites in the crystal structure must be free. A given atom must also overcome the energy barrier to move from its current site (it lies in an energetically favorable potential well) to the nearby vacant site (another potential well). The general form of the diffusion equation is\n\n  \n    \n      \n        D\n        =\n        \n          D\n          \n            0\n          \n        \n        \n          e\n          \n            \n              E\n              \n                K\n                T\n              \n            \n          \n        \n      \n    \n    {\\displaystyle D=D_{0}e^{\\frac {E}{KT}}}\n  where D0 has a dependence on both the attempted jump frequency and the number of nearest neighbor sites and the probability of the sites being vacant. Thus there is a double dependence upon temperature. At higher temperatures the diffusivity increases due to the direct temperature dependence of the equation, the increase in vacancies through Schottky defect formation, and an increase in the average energy of atoms in the material. Nabarro\u2013Herring creep dominates at very high temperatures relative to a material's melting temperature.\n\n\n=== Coble creep ===\n\nCoble creep is the second form of diffusion controlled creep. In Coble creep the atoms diffuse along grain boundaries to elongate the grains along the stress axis. This causes Coble creep to have a stronger grain size dependence than Nabarro\u2013Herring creep, thus, Coble creep will be more important in materials composed of very fine grains. For Coble creep k is related to the diffusion coefficient of atoms along the grain boundary, Q = Q(grain boundary diffusion), m = 1, and b = 3. Because Q(grain boundary diffusion) is less than Q(self diffusion), Coble creep occurs at lower temperatures than Nabarro\u2013Herring creep. Coble creep is still temperature dependent, as the temperature increases so does the grain boundary diffusion. However, since the number of nearest neighbors is effectively limited along the interface of the grains, and thermal generation of vacancies along the boundaries is less prevalent, the temperature dependence is not as strong as in Nabarro\u2013Herring creep. It also exhibits the same linear dependence on stress as Nabarro\u2013Herring creep. Generally, the diffusional creep rate should be the sum of Nabarro\u2013Herring creep rate and Coble creep rate. Diffusional creep leads to grain-boundary separation, that is, voids or cracks form between the grains. To heal this, grain-boundary sliding occurs. The diffusional creep rate and the grain boundary sliding rate must be balanced if there are no voids or cracks remaining. When grain-boundary sliding can not accommodate the incompatibility, grain-boundary voids are generated, which is related to the initiation of creep fracture.\n\n\n=== Solute drag creep ===\nSolute drag creep is one of the mechanisms for power-law creep (PLC), involving both dislocation and diffusional flow. Solute drag creep is observed in certain metallic alloys. In these alloys, the creep rate increases during the first stage of creep (Transient creep) before reaching a steady-state value. This phenomenon can be explained by a model associated with solid-solution strengthening. At low temperatures, the solute atoms are immobile and increase the flow stress required to move dislocations. However, at higher temperatures, the solute atoms are more mobile and may form atmospheres and clouds surrounding the dislocations. This is especially likely if the solute atom has a large misfit in the matrix. The solutes are attracted by the dislocation stress fields and are able to relieve the elastic stress fields of existing dislocations. Thus the solutes become bound to the dislocations. The concentration of solute, C, at a distance, r, from a dislocation is given by the Cottrell atmosphere defined as\n\n  \n    \n      \n        \n          C\n          \n            r\n          \n        \n        =\n        \n          C\n          \n            0\n          \n        \n        exp\n        \u2061\n        \n          (\n          \n            \u2212\n            \n              \n                \n                  \u03b2\n                  sin\n                  \u2061\n                  \u03b8\n                \n                \n                  r\n                  K\n                  T\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle C_{r}=C_{0}\\exp \\left(-{\\frac {\\beta \\sin \\theta }{rKT}}\\right)}\n  where C0 is the concentration at r = \u221e and \u03b2 is a constant which defines the extent of segregation of the solute. When surrounded by a solute atmosphere, dislocations that attempt to glide under an applied stress are subjected to a back stress exerted on them by the cloud of solute atoms. If the applied stress is sufficiently high, the dislocation may eventually break away from the atmosphere, allowing the dislocation to continue gliding under the action of the applied stress. The maximum force (per unit length) that the atmosphere of solute atoms can exert on the dislocation is given by Cottrell and Jaswon\n\n  \n    \n      \n        \n          \n            \n              F\n              \n                \n                  m\n                  a\n                  x\n                \n              \n            \n            L\n          \n        \n        =\n        \n          \n            \n              \n                C\n                \n                  0\n                \n              \n              \n                \u03b2\n                \n                  2\n                \n              \n            \n            \n              b\n              k\n              T\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {F_{\\rm {max}}}{L}}={\\frac {C_{0}\\beta ^{2}}{bkT}}}\n  When the diffusion of solute atoms is activated at higher temperatures, the solute atoms which are \"bound\" to the dislocations by the misfit can move along with edge dislocations as a \"drag\" on their motion if the dislocation motion or the creep rate is not too high. The amount of \"drag\" exerted by the solute atoms on the dislocation is related to the diffusivity of the solute atoms in the metal at that temperature, with a higher diffusivity leading to lower drag and vice versa. The velocity at which the dislocations glide can be approximated by a power law of the form\n\n  \n    \n      \n        v\n        =\n        B\n        \n          \n            \n              \u03c3\n              \n                \u2217\n              \n            \n          \n          \n            m\n          \n        \n        B\n        =\n        \n          B\n          \n            0\n          \n        \n        exp\n        \u2061\n        \n          (\n          \n            \n              \n                \u2212\n                \n                  Q\n                  \n                    \n                      g\n                    \n                  \n                \n              \n              \n                R\n                T\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle v=B{\\sigma ^{*}}^{m}B=B_{0}\\exp \\left({\\frac {-Q_{\\rm {g}}}{RT}}\\right)}\n  where m is the effective stress exponent, Q is the apparent activation energy for glide and B0 is a constant. The parameter B in the above equation was derived by Cottrell and Jaswon for interaction between solute atoms and dislocations on the basis of the relative atomic size misfit \u03b5a of solutes to be\n\n  \n    \n      \n        B\n        =\n        \n          \n            \n              9\n              k\n              T\n            \n            \n              M\n              \n                G\n                \n                  2\n                \n              \n              \n                b\n                \n                  4\n                \n              \n              ln\n              \u2061\n              \n                \n                  \n                    r\n                    2\n                  \n                  \n                    r\n                    1\n                  \n                \n              \n            \n          \n        \n        \u22c5\n        \n          \n            \n              D\n              \n                \n                  s\n                  o\n                  l\n                \n              \n            \n            \n              \n                \u03b5\n                \n                  \n                    a\n                  \n                \n                \n                  2\n                \n              \n              \n                c\n                \n                  0\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle B={\\frac {9kT}{MG^{2}b^{4}\\ln {\\frac {r2}{r1}}}}\\cdot {\\frac {D_{\\rm {sol}}}{\\varepsilon _{\\rm {a}}^{2}c_{0}}}}\n  where k is Boltzmann's constant, and r1 and r2 are the internal and external cut-off radii of dislocation stress field. c0 and Dsol are the atomic concentration of the solute and solute diffusivity respectively. Dsol also has a temperature dependence that makes a determining contribution to Qg.\nIf the cloud of solutes does not form or the dislocations are able to break away from their clouds, glide occurs in a jerky manner where fixed obstacles, formed by dislocations in combination with solutes, are overcome after a certain waiting time with support by thermal activation. The exponent m is greater than 1 in this case. The equations show that the hardening effect of solutes is strong if the factor B in the power-law equation is low so that the dislocations move slowly and the diffusivity Dsol is low. Also, solute atoms with both high concentration in the matrix and strong interaction with dislocations are strong gardeners. Since misfit strain of solute atoms is one of the ways they interact with dislocations, it follows that solute atoms with large atomic misfit are strong gardeners. A low diffusivity Dsol is an additional condition for strong hardening.Solute drag creep sometimes shows a special phenomenon, over a limited strain rate, which is called the Portevin\u2013Le Chatelier effect. When the applied stress becomes sufficiently large, the dislocations will break away from the solute atoms since dislocation velocity increases with the stress. After breakaway, the stress decreases and the dislocation velocity also decreases, which allows the solute atoms to approach and reach the previously departed dislocations again, leading to a stress increase. The process repeats itself when the next local stress maximum is obtained. So repetitive local stress maxima and minima could be detected during solute drag creep.\n\n\n=== Dislocation climb-glide creep ===\nDislocation climb-glide creep is observed in materials at high temperature. The initial creep rate is larger than the steady-state creep rate. Climb-glide creep could be illustrated as follows: when the applied stress is not enough for a moving dislocation to overcome the obstacle on its way via dislocation glide alone, the dislocation could climb to a parallel slip plane by diffusional processes, and the dislocation can glide on the new plane. This process repeats itself each time when the dislocation encounters an obstacle. The creep rate could be written as:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b5\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                A\n                \n                  \n                    C\n                    G\n                  \n                \n              \n              \n                D\n                \n                  \n                    L\n                  \n                \n              \n            \n            \n              M\n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  \u03c3\n                  \u03a9\n                \n                \n                  k\n                  T\n                \n              \n            \n            )\n          \n          \n            4.5\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\varepsilon }{\\mathrm {d} t}}={\\frac {A_{\\rm {CG}}D_{\\rm {L}}}{\\sqrt {M}}}\\left({\\frac {\\sigma \\Omega }{kT}}\\right)^{4.5}}\n  where ACG includes details of the dislocation loop geometry, DL is the lattice diffusivity, M is the number of dislocation sources per unit volume, \u03c3 is the applied stress, and \u03a9 is the atomic volume. The exponent m for dislocation climb-glide creep is 4.5 if M is independent of stress and this value of m is consistent with results from considerable experimental studies.\n\n\n=== Harper\u2013Dorn creep ===\nHarper\u2013Dorn creep is a climb-controlled dislocation mechanism at low stresses that has been observed in aluminum, lead, and tin systems, in addition to nonmetal systems such as ceramics and ice. It was first observed by Harper and Dorn in 1957. It is characterized by two principal phenomena: a power-law relationship between the steady-state strain rate and applied stress at a constant temperature which is weaker than the natural power-law of creep, and an independent relationship between the steady-state strain rate and grain size for a provided temperature and applied stress. The latter observation implies that Harper\u2013Dorn creep is controlled by dislocation movement; namely, since creep can occur by vacancy diffusion (Nabarro\u2013Herring creep, Coble creep), grain boundary sliding, and/or dislocation movement, and since the first two mechanisms are grain-size dependent, Harper\u2013Dorn creep must therefore be dislocation-motion dependent. The same was also confirmed in 1972 by Barrett and co-workers where FeAl3 precipitates lowered the creep rates by 2 orders of magnitude compared to highly pure Al, thus, indicating Harper\u2013Dorn creep to be a dislocation based mechanism.\n\n\n==== Equation ====\nHarper\u2013Dorn creep is typically overwhelmed by other creep mechanisms in most situations, and is therefore not observed in most systems. The phenomenological equation which describes Harper\u2013Dorn creep is\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \u03b5\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \u03c1\n          \n            0\n          \n        \n        \n          \n            \n              \n                D\n                \n                  \n                    v\n                  \n                \n              \n              G\n              \n                b\n                \n                  3\n                \n              \n            \n            \n              k\n              T\n            \n          \n        \n        \n          (\n          \n            \n              \n                \u03c3\n                \n                  \n                    s\n                  \n                \n                \n                  n\n                \n              \n              G\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} \\varepsilon }{\\mathrm {d} t}}=\\rho _{0}{\\frac {D_{\\rm {v}}Gb^{3}}{kT}}\\left({\\frac {\\sigma _{\\rm {s}}^{n}}{G}}\\right)}\n  where \u03c10 is dislocation density (constant for Harper\u2013Dorn creep), Dv is the diffusivity through the volume of the material, G is the shear modulus and b is the Burgers vector, \u03c3s, and n is the stress exponent which varies between 1 and 3.\n\n\n==== Later investigation of the creep region ====\nTwenty-five years after Harper and Dorn published their work, Mohamed and Ginter made an important contribution in 1982 by evaluating the potential for achieving Harper\u2013Dorn creep in samples of Al using different processing procedures. The experiments showed that Harper\u2013Dorn creep is achieved with stress exponent n = 1, and only when the internal dislocation density prior to testing is exceptionally low. By contrast, Harper\u2013Dorn creep was not observed in polycrystalline Al and single crystal Al when the initial dislocation density was high.\nHowever, various conflicting reports demonstrate the uncertainties at very low stress levels. One report by Blum and Maier, claimed that the experimental evidence for Harper\u2013Dorn creep is not fully convincing. They argued that the necessary condition for Harper\u2013Dorn creep is not fulfilled in Al with 99.99% purity and the steady-state stress exponent n of the creep rate is always much larger than 1.\nThe subsequent work conducted by Ginter et al. confirmed that Harper\u2013Dorn creep was attained in Al with 99.9995% purity but not in Al with 99.99% purity and, in addition, the creep curves obtained in the very high purity material exhibited regular and periodic accelerations. They also found that the creep behavior no longer follows a stress exponent of n = 1 when the tests are extended to very high strains of >0.1 but instead there is evidence for a stress exponent of n > 2.\n\nRequirements for the occurrenceHarper\u2013Dorn creep is usually regarded as a Newtonian viscous process with n = 1. Some very recent experimental evidence suggests that the stress exponent may be closer to \u223c2. Harper\u2013Dorn creep should be observed at a low-stress creep regime where the stress exponent is lower than in the conventional power-law regime where n \u2248 3\u20135.\nUnlike Nabarro\u2013Herring diffusion depending on grain size, the Harper\u2013Dorn flow process is independent of grain size. In the initial experiments of Harper and Dorn, identical creep rates are recorded either over a wide range of grain sizes in polycrystalline samples or in a combination of polycrystalline samples and single crystals.\nThe measured creep rates should be significantly faster, typically by more than two orders of magnitude, than the creep rates anticipated for Nabarro\u2013Herring diffusion creep. At very high testing temperatures, Coble diffusion creep will be of negligible significance under these conditions.\nThe volumetric activation energy indicates that the rate of Harper\u2013Dorn creep is controlled by vacancy diffusion to and from dislocations, resulting in climb-controlled dislocation motion. Unlike in other creep mechanisms, the dislocation density here is constant and independent of the applied stress.\nThe dislocation density must be low for Harper\u2013Dorn creep to dominate. The density has been proposed to increase as dislocations move via cross-slip from one slip-plane to another, thereby increasing the dislocation length per unit volume. Cross-slip can also result in jogs along the length of the dislocation, which, if large enough, can act as single-ended dislocation sources.\n\n\n==== Future expectation ====\nHarper\u2013Dorn creep is considered as a distinct mechanism under some conditions. But more definitive experiments are needed both to more fully establish the precise requirements for observing this process and to provide detailed information used to develop a more appropriate theoretical flow mechanism.\n\n\n=== Sintering ===\nAt high temperatures, it is energetically favorable for voids to shrink in a material. The application of tensile stress opposes the reduction in energy gained by void shrinkage. Thus, a certain magnitude of applied tensile stress is required to offset these shrinkage effects and cause void growth and creep fracture in materials at high temperature. This stress occurs at the sintering limit of the system.The stress tending to shrink voids that must be overcome is related to the surface energy and surface area-volume ratio of the voids. For a general void with surface energy \u03b3 and principle radii of curvature of r1 and r2, the sintering limit stress is\n\n  \n    \n      \n        \n          \u03c3\n          \n            \n              s\n              i\n              n\n              t\n            \n          \n        \n        =\n        \n          \n            \u03b3\n            \n              r\n              \n                1\n              \n            \n          \n        \n        +\n        \n          \n            \u03b3\n            \n              r\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\sigma _{\\rm {sint}}={\\frac {\\gamma }{r_{1}}}+{\\frac {\\gamma }{r_{2}}}}\n  Below this critical stress, voids will tend to shrink rather than grow. Additional void shrinkage effects will also result from the application of a compressive stress. For typical descriptions of creep, it is assumed that the applied tensile stress exceeds the sintering limit.\nCreep also explains one of several contributions to densification during metal powder sintering by hot pressing. A main aspect of densification is the shape change of the powder particles. Since this change involves permanent deformation of crystalline solids, it can be considered a plastic deformation process and thus sintering can be described as a high temperature creep process. The applied compressive stress during pressing accelerates void shrinkage rates and allows a relation between the steady-state creep power law and densification rate of the material. This phenomenon is observed to be one of the main densification mechanisms in the final stages of sintering, during which the densification rate (assuming gas-free pores) can be explained by:\n\n  \n    \n      \n        \n          \n            \n              \u03c1\n              \u02d9\n            \n          \n        \n        =\n        \n          \n            \n              3\n              A\n            \n            2\n          \n        \n        \n          \n            \n              \u03c1\n              (\n              1\n              \u2212\n              \u03c1\n              )\n            \n            \n              \n                (\n                \n                  1\n                  \u2212\n                  (\n                  1\n                  \u2212\n                  \u03c1\n                  \n                    )\n                    \n                      \n                        1\n                        n\n                      \n                    \n                  \n                \n                )\n              \n              \n                n\n              \n            \n          \n        \n        \n          \n            (\n            \n              \n                \n                  3\n                  2\n                \n              \n              \n                \n                  \n                    P\n                    \n                      \n                        e\n                      \n                    \n                  \n                  n\n                \n              \n            \n            )\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\dot {\\rho }}={\\frac {3A}{2}}{\\frac {\\rho (1-\\rho )}{\\left(1-(1-\\rho )^{\\frac {1}{n}}\\right)^{n}}}\\left({\\frac {3}{2}}{\\frac {P_{\\rm {e}}}{n}}\\right)^{n}}\n  in which \u03c1\u0307 is the densification rate, \u03c1 is the density, Pe is the pressure applied, n describes the exponent of strain rate behavior, and A is a mechanism-dependent constant. A and n are from the following form of the general steady-state creep equation,\n\n  \n    \n      \n        \n          \n            \n              \u03b5\n              \u02d9\n            \n          \n        \n        =\n        A\n        \n          \u03c3\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\dot {\\varepsilon }}=A\\sigma ^{n}}\n  where \u03b5\u0307 is the strain rate, and \u03c3 is the tensile stress. For the purposes of this mechanism, the constant A comes from the following expression, where A\u2032 is a dimensionless, experimental constant, \u03bc is the shear modulus, b is the Burgers vector, k is Boltzmann's constant, T is absolute temperature, D0 is the diffusion coefficient, and Q is the diffusion activation energy:\n\n  \n    \n      \n        A\n        =\n        \n          A\n          \u2032\n        \n        \n          \n            \n              \n                D\n                \n                  0\n                \n              \n              \u03bc\n              b\n            \n            \n              k\n              T\n            \n          \n        \n        exp\n        \u2061\n        \n          (\n          \n            \u2212\n            \n              \n                Q\n                \n                  k\n                  T\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle A=A'{\\frac {D_{0}\\mu b}{kT}}\\exp \\left(-{\\frac {Q}{kT}}\\right)}\n  \n\n\n== Examples ==\n\n\n=== Polymers ===\n\nCreep can occur in polymers and metals which are considered viscoelastic materials. When a polymeric material is subjected to an abrupt force, the response can be modeled using the Kelvin\u2013Voigt model. In this model, the material is represented by a Hookean spring and a Newtonian dashpot in parallel. The creep strain is given by the following convolution integral:\n\n  \n    \n      \n        \u03b5\n        (\n        t\n        )\n        =\n        \u03c3\n        \n          C\n          \n            0\n          \n        \n        +\n        \u03c3\n        C\n        \n          \u222b\n          \n            0\n          \n          \n            \u221e\n          \n        \n        f\n        (\n        \u03c4\n        )\n        \n          (\n          \n            1\n            \u2212\n            \n              e\n              \n                \u2212\n                t\n                \n                  /\n                \n                \u03c4\n              \n            \n          \n          )\n        \n        \n        \n          d\n        \n        \u03c4\n      \n    \n    {\\displaystyle \\varepsilon (t)=\\sigma C_{0}+\\sigma C\\int _{0}^{\\infty }f(\\tau )\\left(1-e^{-t/\\tau }\\right)\\,\\mathrm {d} \\tau }\n  where \u03c3 is applied stress, C0 is instantaneous creep compliance, C is creep compliance coefficient, \u03c4 is retardation time, and f(\u03c4) is the distribution of retardation times.\nWhen subjected to a step constant stress, viscoelastic materials experience a time-dependent increase in strain. This phenomenon is known as viscoelastic creep.\nAt a time t0, a viscoelastic material is loaded with a constant stress that is maintained for a sufficiently long time period. The material responds to the stress with a strain that increases until the material ultimately fails. When the stress is maintained for a shorter time period, the material undergoes an initial strain until a time t1 at which the stress is relieved, at which time the strain immediately decreases (discontinuity) then continues decreasing gradually to a residual strain.\nViscoelastic creep data can be presented in one of two ways. Total strain can be plotted as a function of time for a given temperature or temperatures. Below a critical value of applied stress, a material may exhibit linear viscoelasticity. Above this critical stress, the creep rate grows disproportionately faster. The second way of graphically presenting viscoelastic creep in a material is by plotting the creep modulus (constant applied stress divided by total strain at a particular time) as a function of time. Below its critical stress, the viscoelastic creep modulus is independent of the stress applied. A family of curves describing strain versus time response to various applied stress may be represented by a single viscoelastic creep modulus versus time curve if the applied stresses are below the material's critical stress value.\nAdditionally, the molecular weight of the polymer of interest is known to affect its creep behavior. The effect of increasing molecular weight tends to promote secondary bonding between polymer chains and thus make the polymer more creep resistant. Similarly, aromatic polymers are even more creep resistant due to the added stiffness from the rings. Both molecular weight and aromatic rings add to polymers' thermal stability, increasing the creep resistance of a polymer.Both polymers and metals can creep. Polymers experience significant creep at temperatures above around \u2212200 \u00b0C (\u2212330 \u00b0F); however, there are three main differences between polymeric and metallic creep. In metals, creep is not linearly viscoelastic, it is not recoverable, and it is only present at high temperatures.Polymers show creep basically in two different ways. At typical work loads (5% up to 50%) ultra-high-molecular-weight polyethylene (Spectra, Dyneema) will show time-linear creep, whereas polyester or aramids (Twaron, Kevlar) will show a time-logarithmic creep.\n\n\n=== Wood ===\nWood is considered as an orthotropic material, exhibiting different mechanical properties in three mutually perpendicular directions. Experiments show that the tangential direction in solid wood tend display a slightly higher creep compliance than in the radial direction. In the longitudinal direction, the creep compliance is relatively low and usually do not show any time-dependency in comparison to the other directions.\nIt has also been shown that there is a substantial difference in viscoelastic properties of wood depending on loading modality (creep in compression or tension). Studies have shown that certain Poisson's ratios gradually go from positive to negative values during the duration of the compression creep test, which does not occur in tension.\n\n\n=== Concrete ===\n\nThe creep of concrete, which originates from the calcium silicate hydrates (C-S-H) in the hardened Portland cement paste (which is the binder of mineral aggregates), is fundamentally different from the creep of metals as well as polymers. Unlike the creep of metals, it occurs at all stress levels and, within the service stress range, is linearly dependent on the stress if the pore water content is constant. Unlike the creep of polymers and metals, it exhibits multi-months aging, caused by chemical hardening due to hydration which stiffens the microstructure, and multi-year aging, caused by long-term relaxation of self-equilibrated microstresses in the nanoporous microstructure of the C-S-H. If concrete is fully dried it does not creep, though it is difficult to dry concrete fully without severe cracking.\n\n\n== Applications ==\n\nThough mostly due to the reduced yield strength at higher temperatures, the collapse of the World Trade Center was due in part to creep from increased temperature.The creep rate of hot pressure-loaded components in a nuclear reactor at power can be a significant design constraint, since the creep rate is enhanced by the flux of energetic particles.\nCreep in epoxy anchor adhesive was blamed for the Big Dig tunnel ceiling collapse in Boston, Massachusetts, that occurred in July 2006.The design of tungsten light bulb filaments attempts to reduce creep deformation. Sagging of the filament coil between its supports increases with time due to the weight of the filament itself. If too much deformation occurs, the adjacent turns of the coil touch one another, causing an electrical short and local overheating, which quickly leads to failure of the filament. The coil geometry and supports are therefore designed to limit the stresses caused by the weight of the filament, and a special tungsten alloy with small amounts of oxygen trapped in the crystallite grain boundaries is used to slow the rate of Coble creep.\nCreep can cause gradual cut-through of wire insulation, especially when stress is concentrated by pressing insulated wire against a sharp edge or corner. Special creep-resistant insulations such as Kynar (polyvinylidene fluoride) are used in wirewrap applications to resist cut-through due to the sharp corners of wire wrap terminals. Teflon insulation is resistant to elevated temperatures and has other desirable properties, but is notoriously vulnerable to cold-flow cut-through failures caused by creep.\nIn steam turbine power plants, pipes carry steam at high temperatures (566 \u00b0C, 1,051 \u00b0F) and pressures (above 24.1 MPa, 3,500 psi). In jet engines, temperatures can reach up to 1,400 \u00b0C (2,550 \u00b0F) and initiate creep deformation in even advanced-design coated turbine blades. Hence, it is crucial for correct functionality to understand the creep deformation behavior of materials.\nCreep deformation is important not only in systems where high temperatures are endured such as nuclear power plants, jet engines and heat exchangers, but also in the design of many everyday objects. For example, metal paper clips are stronger than plastic ones because plastics creep at room temperatures. Aging glass windows are often erroneously used as an example of this phenomenon: measurable creep would only occur at temperatures above the glass transition temperature around 500 \u00b0C (932 \u00b0F). While glass does exhibit creep under the right conditions, apparent sagging in old windows may instead be a consequence of obsolete manufacturing processes, such as that used to create crown glass, which resulted in inconsistent thickness.Fractal geometry, using a deterministic Cantor structure, is used to model the surface topography, where recent advancements in thermoviscoelastic creep contact of rough surfaces are introduced. Various viscoelastic idealizations are used to model the surface materials, including the Maxwell, Kelvin\u2013Voigt, standard linear solid and Jeffrey models.Nimonic 75 has been certified by the European Union as a standard creep reference material.The practice of tinning stranded wires to facilitate the process of connecting the wire to a screw terminal, though having been prevalent and considered standard practice for quite a while, has been discouraged by professional electricians, owing to the fact that the solder is likely to creep under the pressure exerted on the tinned wire end by the screw of the terminal, causing the joint to lose tension and hence create a loose contact over time. The accepted practice when connecting stranded wire to a screw terminal is to use a wire ferrule on the end of the wire.\n\n\n== Prevention ==\nGenerally, materials have better creep resistance if they have higher melting temperatures, lower diffusivity, and higher shear strength. Close-packed structures are usually more creep resistant as they tend to have lower diffusivity than non-close-packed structures. Common methods to reduce creep include:\n\nSolid solution strengthening: adding other elements in solid solution can slow diffusion, as well as slow dislocation motion via the mechanism of solute drag.\nParticle dispersion strengthening: adding particles, often incoherent oxide or carbide particles, block dislocation motion.\nPrecipitation hardening: precipitating a second phase out of the primary lattice blocks dislocation motion.\nGrain size: increasing grain size decreases the amount of grain boundaries, which results in slower creep due to the high diffusion rate along grain boundaries. This is opposite low-temperature applications, where increasing grain size decreases strength by blocking dislocation motion. In very high temperature applications such as jet engine turbines, single crystals are often used.\n\n\n=== Superalloys ===\n \n\nMaterials operating in high-performance systems, such as jet engines, often reach extreme temperatures surpassing 1,000 \u00b0C (1,830 \u00b0F), necessitating specialized material design. Superalloys based on cobalt, nickel, and iron have been engineered to be highly resistant to creep. The term \u2018superalloy\u2019 generally refers to austenitic nickel-, iron-, or cobalt-based alloys that use either \u03b3\u2032 or \u03b3\u2033 precipitation strengthening to maintain strength at high temperature.\nThe \u03b3\u2032 phase is a cubic L12-structure Ni3(Al,Ti,Ta,Nb) phase that produces cuboidal precipitates. Superalloys often have a high (60\u201375%) volume fraction of \u03b3\u2032 precipitates. \u03b3\u2032 precipitates are coherent with the parent \u03b3 phase, and are resistant to shearing due to the development of an anti-phase boundary when the precipitate is sheared. The \u03b3\u2033 phase is a tetragonal Ni3Nb or Ni3V structure. The \u03b3\u2033 phase, however, is unstable above 650 \u00b0C (1,202 \u00b0F), so \u03b3\u2033 is less commonly used as a strengthening phase in high temperature applications. Carbides are also used in polycrystalline superalloys to inhibit grain boundary sliding.Many other elements can be added to superalloys to tailor their properties. They can be used for solid solution strengthening, to reduce the formation of undesirable brittle precipitates, and to increase oxidation or corrosion resistance. Nickel-based superalloys have found widespread use in high-temperature, low stress applications. Iron-based superalloys are generally not used at high temperatures as the \u03b3\u2032 phase is not stable in the iron matrix, but are sometimes used at moderately high temperatures, as iron is significantly cheaper than nickel. Cobalt-based \u03b3\u2032 structure was found in 2006, allowing the development of cobalt-based superalloys, which are superior to nickel-based superalloys in corrosion resistance. However, in the base (cobalt\u2013tungsten\u2013aluminum) system, \u03b3\u2032 is only stable below 900 \u00b0C (1,650 \u00b0F), and cobalt-based superalloys tend to be weaker than their Ni counterparts.\n\n\n=== Contributing factors in creep resistivity ===\n\n\n==== 1. Stages of creep ====\nBased on the description of creep mechanisms and its three different stages mentioned earlier, creep resistance generally can be accomplished by using materials in which their tertiary stage is not active since, at this stage, the strain rate increases significantly by increasing stress. Therefore, a sound component design should satisfy the primary stage of creep, which has a relatively high initial creep rate that decreases with increasing exposure time, leading to the second stage of creep, in which the creep rate in the material is decelerated and reaches its minimum value via work hardening. The minimum value of creep rate is actually a constant creep rate, which plays a crucial role in designing a component, and its magnitude depends on temperature and stress. The minimum value of creep rate that is commonly applied to alloys is based on two norms: (1) the stress required to produce a creep rate of 0.1%/h\u00d710\u22123 and (2) the stress required to produce a creep rate of 0.1%/h\u00d710\u22124, which takes roughly about 11.5 years. The former standard has widely been used in the component design of turbine blades, while the latter is frequently used in designing steam turbines. One of the primary goals of creep tests is to determine the minimum value of the creep rate at the secondary stage and also to investigate the time required for an ultimate failure of a component. However, when it comes to ceramic applications, there are no such standards to determine their minimum creep rates, but it's safe to say that ceramics are usually picked up to operate at high-temperature applications under loads mainly because they possess a long lifetime. However, by acquiring information obtained from creep tests, proper ceramic material(s) can be selected for desired application to assure the safe service and evaluate the time period of secure service in high-temperature environments that the structural thermostability is essential. Therefore, by making the proper choice, suitable ceramic components may be selected, capable of operating at various conditions of high temperature and creep deformation.\n\n\n==== 2. Materials selection ====\nGenerally speaking, the structure of materials is different from one another. Metallic materials have different structures compared to polymer or ceramics, and even within the same class of materials, different structures might have existed at different temperatures. The difference in the structure includes the difference in grains (for example, their sizes, shapes, distributions), their crystalline or amorphous nature, and even dislocation and/or vacancy contents that are prone to change following a deformation. So, since creep is a time-dependent process and differs from one material to another, all these parameters must be considered in materials selection for a specific application. For instance, materials with low-dislocation content are among the suitable candidates for creep resistance. In other words, the dislocation glide and climb can be reduced if the proper material is selected (for example, ceramic materials are very popular in this case). In terms of vacancies, it's noteworthy to mention that the vacancy content not only depends on the chosen material but also on the component's service temperature. Vacancy-diffusion-controlled processes that promote creep can be categorized into grain boundary diffusion (Coble creep) and lattice diffusion (Nabarro\u2013Herring creep). Therefore, the properties of dislocations and vacancies, their distributions throughout the structure, and their potential change due to long-time exposure to stress and temperature must be considered seriously in materials selection for components design. Therefore, the role of dislocations, vacancies, wide range of obstacles that can retard the dislocation motion, including grain boundaries in polycrystalline materials, solute atoms, precipitates, impurities, and strain fields originating from other dislocations or their pile-ups which increase the lifetime of materials and make them more resistive with respect to creep are always at the top list of materials selection and component design. For instance, different types of vacancies in ceramic materials have different charges stemming from their dominant chemical boding. So, existing or newly-formed vacancies must be charge-balanced to maintain the overall neutrality of the final structure. Besides paying attention to individual dislocation and vacancy contents, the correlation between them is also worth exploring since dislocation's ability to climb depends heavily on how many vacancies are available in its vicinity. To recap, materials must be selected and developed that possess low dislocation and vacancy contents to have a practical creep resistance component.\n\n\n==== 3. Various working conditions ====\n\u25cf Temperature\nCreep is a phenomenon that is related to a material's melting point (Tm). Generally, a high lifetime is expected when we have a higher melting point, and the reason behind selecting materials with high melting points originates from the fact that diffusion processes are related to temperature-dependent vacancy concentrations. The diffusion rate is slower in high-temperature materials. Ceramic materials are well known for having high melting points, and that's the reason why ceramics gravitated considerable attention to creep resistance applications. Although it's widely known that creep starts at a temperature equal to 0.5Tm, the safe temperature to avoid the initiation of creep is 0.3Tm. Creep that starts below or at 0.5Tm is called \"low temperature creep\" because diffusion is not very progressive at such low temperatures, and the kind of creep that occurs is not diffusion-dominant and is related to other mechanisms.\n\u25cf Time\nAs mentioned previously, creep is a time-dependent deformation. Fortunately, creep doesn't occur suddenly in brittle materials as it does under tension and other forms of deformation, and it's an advantage for designers. Over time, creep strain develops in a material that is exposed to stress at the temperature of the application, and it depends on the duration of the exposure. Thus, besides temperature and stress, the creep rate is also a function of time, and it can be generalized as this function \u03b5 = F(t, T, \u03c3) that tells the designer all the three parameters, including time, temperature, and stress acting in concert, and all of them must be considered if a successful creep-resistance component is to be attained.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==", "Stiffness": "Stiffness is the extent to which an object resists deformation in response to an applied force.The complementary concept is flexibility or pliability: the more flexible an object is, the less stiff it is.\n\n\n== Calculations ==\nThe stiffness, \n  \n    \n      \n        k\n        ,\n      \n    \n    {\\displaystyle k,}\n   of a body is a measure of the resistance offered by an elastic body to deformation. For an elastic body with a single degree of freedom (DOF) (for example, stretching or compression of a rod), the stiffness is defined as\n\nwhere,\n\n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n   is the force on the body\n\n  \n    \n      \n        \u03b4\n      \n    \n    {\\displaystyle \\delta }\n   is the displacement produced by the force along the same degree of freedom (for instance,  the change in length of a stretched spring)In the International System of Units, stiffness is typically measured in newtons per meter (\n  \n    \n      \n        N\n        \n          /\n        \n        m\n      \n    \n    {\\displaystyle N/m}\n  ). In Imperial units, stiffness is typically measured in pounds (lbs) per inch.\nGenerally speaking, deflections (or motions) of an infinitesimal element (which is viewed as a point) in an elastic body can occur along multiple DOF (maximum of six DOF at a point). For example, a point on a horizontal beam can undergo both a vertical displacement and a rotation relative to its undeformed axis. When there are \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   degrees of freedom a \n  \n    \n      \n        M\n        \u00d7\n        M\n      \n    \n    {\\displaystyle M\\times M}\n   matrix must be used to describe the stiffness at the point. The diagonal terms in the matrix are the direct-related stiffnesses (or simply stiffnesses) along the same degree of freedom and the off-diagonal terms are the coupling stiffnesses between two different degrees of freedom (either at the same or different points) or the same degree of freedom at two different points. In industry, the term influence coefficient is sometimes used to refer to the coupling stiffness.\nIt is noted that for a body with multiple DOF, the equation above generally does not apply since the applied force generates not only the deflection along its direction (or degree of freedom) but also those along with other directions.\nFor a body with multiple DOF, to calculate a particular direct-related stiffness (the diagonal terms), the corresponding DOF is left free while the remaining should be constrained. Under such a condition, the above equation can obtain the direct-related stiffness for the degree of unconstrained freedom. The ratios between the reaction forces (or moments) and the produced deflection are the coupling stiffnesses.\nThe elasticity tensor is a generalization that describes all possible stretch and shear parameters.\n\n\n== Compliance ==\nThe inverse of stiffness is flexibility or compliance, typically measured in units of metres per newton. In rheology, it may be defined as the ratio of strain to stress, and so take the units of reciprocal stress, for example, 1/Pa.\n\n\n== Rotational stiffness ==\n\nA body may also have a rotational stiffness, \n  \n    \n      \n        k\n        ,\n      \n    \n    {\\displaystyle k,}\n   given by\n\nwhere\n\n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n   is the applied moment\n\n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the rotationIn the SI system, rotational stiffness is typically measured in newton-metres per radian.\nIn the SAE system, rotational stiffness is typically measured in inch-pounds per degree.\nFurther measures of stiffness are derived on a similar basis, including:\n\nshear stiffness - the ratio of applied shear force to shear deformation\ntorsional stiffness - the ratio of applied torsion moment to the angle of twist\n\n\n== Relationship to elasticity ==\nThe elastic modulus of a material is not the same as the stiffness of a component made from that material.  Elastic modulus is a property of the constituent material; stiffness is a property of a structure or component of a structure, and hence it is dependent upon various physical dimensions that describe that component.  That is, the modulus is an intensive property of the material; stiffness, on the other hand, is an extensive property of the solid body that is dependent on the material and its shape and boundary conditions.  For example, for an element in tension or compression, the axial stiffness is\n\nwhere\n\n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   is the (tensile) elastic modulus (or Young's modulus),\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is the cross-sectional area,\n\n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   is the length of the element.Similarly, the torsional stiffness of a straight section is\n\nwhere\n\n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n   is the rigidity modulus of the material,\n\n  \n    \n      \n        J\n      \n    \n    {\\displaystyle J}\n   is the torsion constant for the section.Note that the torsional stiffness has dimensions [force] * [length] / [angle], so that its SI units are N*m/rad.\nFor the special case of unconstrained uniaxial tension or compression, Young's modulus can be thought of as a measure of the stiffness of a structure.\n\n\n== Applications ==\nThe stiffness of a structure is of principal importance in many engineering applications, so the modulus of elasticity is often one of the primary properties considered when selecting a material. A high modulus of elasticity is sought when deflection is undesirable, while a low modulus of elasticity is required when flexibility is needed.\nIn biology, the stiffness of the extracellular matrix is important for guiding the migration of cells in a phenomenon called durotaxis.\nAnother application of stiffness finds itself in skin biology. The skin maintains its structure due to its intrinsic tension, contributed to by collagen, an extracellular protein that accounts for approximately 75% of its dry weight. The pliability of skin is a parameter of interest that represents its firmness and extensibility, encompassing characteristics such as elasticity, stiffness, and adherence. These factors are of functional significance to patients. This is of significance to patients with traumatic injuries to the skin, whereby the pliability can be reduced due to the formation and replacement of healthy skin tissue by a pathological scar. This can be evaluated both subjectively, or objectively using a device such as the Cutometer. The Cutometer applies a vacuum to the skin and measures the extent to which it can be vertically distended. These measurements are able to distinguish between healthy skin, normal scarring, and pathological scarring, and the method has been applied within clinical and industrial settings to monitor both pathophysiological sequelae, and the effects of treatments on skin.\n\n\n== See also ==\n\n\n== References ==", "Torque": "In physics and mechanics, torque is the rotational analogue of linear force. It is also referred to as the moment of force (also abbreviated to moment). It describes the rate of change of angular momentum that would be imparted to an isolated body. The concept originated with the studies by Archimedes of the usage of levers, which is reflected in his famous quote: \"Give me a lever and a place to stand and I will move the Earth\". Just as a linear force is a push or a pull applied to a body, a torque can be thought of as a twist applied to an object with respect to a chosen point. Torque is defined as the product of the magnitude of the perpendicular component of the force and the distance of the line of action of a force from the point around which it is being determined. The law of conservation of energy can also be used to understand torque. The symbol for torque is typically \n  \n    \n      \n        \n          \u03c4\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}}\n  , the lowercase Greek letter tau. When being referred to as moment of force, it is commonly denoted by M. \nIn three dimensions, the torque is a pseudovector; for point particles, it is given by the cross product of the displacement vector and the force vector. The magnitude of torque applied to a rigid body depends on three quantities: the force applied, the lever arm vector connecting the point about which the torque is being measured to the point of force application, and the angle between the force and lever arm vectors. In symbols:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} }\n  \n\n  \n    \n      \n        \u03c4\n        =\n        r\n        F\n        sin\n        \u2061\n        \u03b8\n        ,\n      \n    \n    {\\displaystyle \\tau =rF\\sin \\theta ,}\n  where\n\n  \n    \n      \n        \n          \u03c4\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}}\n   is the torque vector and \n  \n    \n      \n        \u03c4\n      \n    \n    {\\displaystyle \\tau }\n   is the magnitude of the torque,\n\n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   is the position vector (a vector from the point about which the torque is being measured to the point where the force is applied), and r is the magnitude of the position vector,\n\n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n   is the force vector, and F is the magnitude of the force vector,\n\n  \n    \n      \n        \u00d7\n      \n    \n    {\\displaystyle \\times }\n   denotes the cross product, which produces a vector that is perpendicular both to r and to F following the right-hand rule,\n\n  \n    \n      \n        \u03b8\n      \n    \n    {\\displaystyle \\theta }\n   is the angle between the force vector and the lever arm vector.The SI unit for torque is the newton-metre (N\u22c5m). For more on the units of torque, see \u00a7 Units.\n\n\n== History ==\n\nThe term torque (from Latin torqu\u0113re \"to twist\") is said to have been suggested by James Thomson and appeared in print in April, 1884. Usage is attested the same year by Silvanus P. Thompson in the first edition of Dynamo-Electric Machinery. Thompson motivates the term as follows:\nJust as the Newtonian definition of force is that which produces or tends to produce motion (along a line), so torque may be defined as that which produces or tends to produce torsion (around an axis). It is better to use a term which treats this action as a single definite entity than to use terms like \"couple\" and \"moment\", which suggest more complex ideas. The single notion of a twist applied to turn a shaft is better than the more complex notion of applying a linear force (or a pair of forces) with a certain leverage.\nToday, torque is referred to using different vocabulary depending on geographical location and field of study. This article follows the definition used in US physics in its usage of the word torque.In the UK and in US mechanical engineering, torque is referred to as moment of force, usually shortened to moment. This terminology can be traced back to at least 1811 in Sim\u00e9on Denis Poisson's Trait\u00e9 de m\u00e9canique. An English translation of Poisson's work appears in 1842.\n\n\n== Definition and relation to angular momentum ==\n\nA force applied perpendicularly to a lever multiplied by its distance from the lever's fulcrum (the length of the lever arm) is its torque. A force of three newtons applied two metres from the fulcrum, for example, exerts the same torque as a force of one newton applied six metres from the fulcrum. The direction of the torque can be determined by using the right hand grip rule: if the fingers of the right hand are curled from the direction of the lever arm to the direction of the force, then the thumb points in the direction of the torque.More generally, the torque on a point particle (which has the position r in some reference frame) can be defined as the cross product:\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} ,}\n  where  F is the force acting on the particle. The magnitude \u03c4 of the torque is given by\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        F\n        sin\n        \u2061\n        \u03b8\n        ,\n      \n    \n    {\\displaystyle \\tau =rF\\sin \\theta ,}\n  where F is the magnitude of the force applied, and \u03b8 is the angle between the position and force vectors. Alternatively,\n\n  \n    \n      \n        \u03c4\n        =\n        r\n        \n          F\n          \n            \u22a5\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\tau =rF_{\\perp },}\n  where F\u22a5 is the amount of force directed perpendicularly to the position of the particle. Any force directed parallel to the particle's position vector does not produce a torque.It follows from the properties of the cross product that the torque vector is perpendicular to both the position and force vectors. Conversely, the torque vector defines the plane in which the position and force vectors lie. The resulting torque vector direction is determined by the right-hand rule.The net torque on a body determines the rate of change of the body's angular momentum,\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}}\n  where L is the angular momentum vector and t is time.\nFor the motion of a point particle,\n\n  \n    \n      \n        \n          L\n        \n        =\n        I\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {L} =I{\\boldsymbol {\\omega }},}\n  where I is the moment of inertia and \u03c9 is the orbital angular velocity pseudovector. It follows that\n\n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            \n              n\n              e\n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                L\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              (\n              I\n              \n                \u03c9\n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        I\n        \n          \n            \n              \n                d\n              \n              \n                \u03c9\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        +\n        \n          \n            \n              \n                d\n              \n              I\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        \n          \n            \n              \n                d\n              \n              (\n              m\n              \n                r\n                \n                  2\n                \n              \n              )\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        \n          \u03c9\n        \n        =\n        I\n        \n          \u03b1\n        \n        +\n        2\n        r\n        \n          p\n          \n            \n              |\n            \n            \n              |\n            \n          \n        \n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{\\mathrm {net} }={\\frac {\\mathrm {d} \\mathbf {L} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} (I{\\boldsymbol {\\omega }})}{\\mathrm {d} t}}=I{\\frac {\\mathrm {d} {\\boldsymbol {\\omega }}}{\\mathrm {d} t}}+{\\frac {\\mathrm {d} I}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+{\\frac {\\mathrm {d} (mr^{2})}{\\mathrm {d} t}}{\\boldsymbol {\\omega }}=I{\\boldsymbol {\\alpha }}+2rp_{||}{\\boldsymbol {\\omega }},}\n  where \u03b1 is the angular acceleration of the particle, and p|| is the radial component of its linear momentum. This equation is the rotational analogue of Newton's second law for point particles, and is valid for any type of trajectory. Note that although force and acceleration are always parallel and directly proportional, the torque \u03c4 need not be parallel or directly proportional to the angular acceleration \u03b1. This arises from the fact that although mass is always conserved, the moment of inertia in general is not.\nIn some simple cases like a rotating disc, the moment of inertia is a constant, the rotational Newton's second law can be \nwhere   \n  \n    \n      \n        I\n        =\n        m\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\textstyle I=mr^{2}}\n   and \n  \n    \n      \n        \n          \u03b1\n        \n        =\n        \n          \n            \n              d\n              \n                \u03c9\n              \n            \n            \n              d\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\alpha }}={d{\\boldsymbol {\\omega }} \\over dt}}\n  .\n\n\n=== Proof of the equivalence of definitions ===\nThe definition of angular momentum for a single point particle is:\n\nwhere p is the particle's linear momentum and r is the position vector from the origin. The time-derivative of this is:\n\nThis result can easily be proven by splitting the vectors into components and applying the product rule. Now using the definition of force \n  \n    \n      \n        \n          F\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                p\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\textstyle \\mathbf {F} ={\\frac {\\mathrm {d} \\mathbf {p} }{\\mathrm {d} t}}}\n   (whether or not mass is constant) and the definition of velocity \n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          v\n        \n      \n    \n    {\\textstyle {\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}}=\\mathbf {v} }\n  \n\nThe cross product of momentum \n  \n    \n      \n        \n          p\n        \n      \n    \n    {\\displaystyle \\mathbf {p} }\n   with its associated velocity \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   is zero because velocity and momentum are parallel, so the second term vanishes.\nBy definition, torque \u03c4 = r \u00d7 F. Therefore, torque on a particle is equal to the\nfirst derivative of its angular momentum with respect to time.\nIf multiple forces are applied, Newton's second law instead reads Fnet = ma, and it follows that\n\nThis is a general proof for point particles.\nThe proof can be generalized to a system of point particles by applying the above proof to each of the point particles and then summing over all the point particles. Similarly, the proof can be generalized to a continuous mass by applying the above proof to each point within the mass, and then integrating over the entire mass.\n\n\n== Units ==\nTorque has the dimension of force times distance, symbolically T\u22122L2M. Although those fundamental dimensions are the same as that for energy or work, official SI literature suggests using the unit newton-metre (N\u22c5m) and never the joule. The unit newton-metre is properly denoted N\u22c5m.The traditional imperial and U.S. customary units for torque are the pound foot (lbf-ft), or for small values the pound inch (lbf-in). In the US, torque is most commonly referred to as the foot-pound (denoted as either lb-ft or ft-lb) and the inch-pound (denoted as in-lb). Practitioners depend on context and the hyphen in the abbreviation to know that these refer to torque and not to energy or moment of mass (as the symbolism ft-lb would properly imply).\n\n\n== Special cases and other facts ==\n\n\n=== Moment arm formula ===\n\nA very useful special case, often given as the definition of torque in fields other than physics, is as follows:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          moment arm\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{moment arm}})({\\text{force}}).}\n  The construction of the \"moment arm\" is shown in the figure to the right, along with the vectors r and F mentioned above. The problem with this definition is that it does not give the direction of the torque but only the magnitude, and hence it is difficult to use in three-dimensional cases. If the force is perpendicular to the displacement vector r, the moment arm will be equal to the distance to the centre, and torque will be a maximum for the given force. The equation for the magnitude of a torque, arising from a perpendicular force:\n\n  \n    \n      \n        \u03c4\n        =\n        (\n        \n          distance to centre\n        \n        )\n        (\n        \n          force\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\tau =({\\text{distance to centre}})({\\text{force}}).}\n  For example, if a person places a force of 10 N at the terminal end of a wrench that is 0.5 m long (or a force of 10 N acting 0.5 m from the twist point of a wrench of any length), the torque will be 5 N\u22c5m \u2013 assuming that the person moves the wrench by applying force in the plane of movement and perpendicular to the wrench.\n\n\n=== Static equilibrium ===\nFor an object to be in static equilibrium, not only must the sum of the forces be zero, but also the sum of the torques (moments) about any point. For a two-dimensional situation with horizontal and vertical forces, the sum of the forces requirement is two equations: \u03a3H = 0 and \u03a3V = 0, and the torque a third equation: \u03a3\u03c4 = 0. That is, to solve statically determinate equilibrium problems in two-dimensions, three equations are used.\n\n\n=== Net force versus torque ===\nWhen the net force on the system is zero, the torque measured from any point in space is the same. For example, the torque on a current-carrying loop in a uniform magnetic field is the same regardless of the point of reference. If the net force \n  \n    \n      \n        \n          F\n        \n      \n    \n    {\\displaystyle \\mathbf {F} }\n   is not zero, and \n  \n    \n      \n        \n          \n            \u03c4\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}_{1}}\n   is the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{1}}\n  , then the torque measured from \n  \n    \n      \n        \n          \n            r\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{2}}\n   is\n\n\n== Machine torque ==\n\nTorque forms part of the basic specification of an engine: the power output of an engine is expressed as its torque multiplied by the angular speed of the drive shaft. Internal-combustion engines produce useful torque only over a limited range of rotational speeds (typically from around 1,000\u20136,000 rpm for a small car). One can measure the varying torque output over that range with a dynamometer, and show it as a torque curve.\nSteam engines and electric motors tend to produce maximum torque close to zero rpm, with the torque diminishing as rotational speed rises (due to increasing friction and other constraints). Reciprocating steam-engines and electric motors can start heavy loads from zero rpm without a clutch.\n\n\n== Relationship between torque, power, and energy ==\nIf a force is allowed to act through a distance, it is doing mechanical work. Similarly, if torque is allowed to act through an angular displacement, it is doing work. Mathematically, for rotation about a fixed axis through the center of mass, the work W can be expressed as\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n         \n        \n          d\n        \n        \u03b8\n        ,\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\ \\mathrm {d} \\theta ,}\n  where \u03c4 is torque, and \u03b81 and \u03b82 represent (respectively) the initial and final angular positions of the body.\n\n\n=== Proof ===\nThe work done by a variable force acting over a finite linear displacement \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n   is given by integrating the force with respect to an elemental linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathrm {d} \\mathbf {s} }\n  \n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}\\mathbf {F} \\cdot \\mathrm {d} \\mathbf {s} }\n  However, the infinitesimal linear displacement \n  \n    \n      \n        \n          d\n        \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathrm {d} \\mathbf {s} }\n   is related to a corresponding angular displacement \n  \n    \n      \n        \n          d\n        \n        \n          \u03b8\n        \n      \n    \n    {\\displaystyle \\mathrm {d} {\\boldsymbol {\\theta }}}\n   and the radius vector \n  \n    \n      \n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {r} }\n   as \n\n  \n    \n      \n        \n          d\n        \n        \n          s\n        \n        =\n        \n          d\n        \n        \n          \u03b8\n        \n        \u00d7\n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathrm {d} \\mathbf {s} =\\mathrm {d} {\\boldsymbol {\\theta }}\\times \\mathbf {r} }\n  Substitution in the above expression for work gives\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          \u03b8\n        \n        \u00d7\n        \n          r\n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}\\mathbf {F} \\cdot \\mathrm {d} {\\boldsymbol {\\theta }}\\times \\mathbf {r} }\n  The expression \n  \n    \n      \n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          \u03b8\n        \n        \u00d7\n        \n          r\n        \n      \n    \n    {\\displaystyle \\mathbf {F} \\cdot \\mathrm {d} {\\boldsymbol {\\theta }}\\times \\mathbf {r} }\n   is a scalar triple product given by \n  \n    \n      \n        \n          [\n          \n            \n              F\n            \n            \n            \n              d\n            \n            \n              \u03b8\n            \n            \n            \n              r\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle \\left[\\mathbf {F} \\,\\mathrm {d} {\\boldsymbol {\\theta }}\\,\\mathbf {r} \\right]}\n  . An alternate expression for the same scalar triple product is\n\n  \n    \n      \n        \n          [\n          \n            \n              F\n            \n            \n            \n              d\n            \n            \n              \u03b8\n            \n            \n            \n              r\n            \n          \n          ]\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n        \u22c5\n        \n          d\n        \n        \n          \u03b8\n        \n      \n    \n    {\\displaystyle \\left[\\mathbf {F} \\,\\mathrm {d} {\\boldsymbol {\\theta }}\\,\\mathbf {r} \\right]=\\mathbf {r} \\times \\mathbf {F} \\cdot \\mathrm {d} {\\boldsymbol {\\theta }}}\n  But as per the definition of torque,\n\n  \n    \n      \n        \n          \u03c4\n        \n        =\n        \n          r\n        \n        \u00d7\n        \n          F\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}=\\mathbf {r} \\times \\mathbf {F} }\n  Corresponding substitution in the expression of work gives,\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              s\n              \n                1\n              \n            \n          \n          \n            \n              s\n              \n                2\n              \n            \n          \n        \n        \n          \u03c4\n        \n        \u22c5\n        \n          d\n        \n        \n          \u03b8\n        \n      \n    \n    {\\displaystyle W=\\int _{s_{1}}^{s_{2}}{\\boldsymbol {\\tau }}\\cdot \\mathrm {d} {\\boldsymbol {\\theta }}}\n  Since the parameter of integration has been changed from linear displacement to angular displacement, the limits of the integration also change correspondingly, giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \n          \u03c4\n        \n        \u22c5\n        \n          d\n        \n        \n          \u03b8\n        \n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}{\\boldsymbol {\\tau }}\\cdot \\mathrm {d} {\\boldsymbol {\\theta }}}\n  If the torque and the angular displacement are in the same direction, then the scalar product reduces to a product of magnitudes; i.e., \n  \n    \n      \n        \n          \u03c4\n        \n        \u22c5\n        \n          d\n        \n        \n          \u03b8\n        \n        =\n        \n          |\n          \n            \u03c4\n          \n          |\n        \n        \n          |\n          \n            \n              d\n            \n            \n              \u03b8\n            \n          \n          |\n        \n        cos\n        \u2061\n        0\n        =\n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle {\\boldsymbol {\\tau }}\\cdot \\mathrm {d} {\\boldsymbol {\\theta }}=\\left|{\\boldsymbol {\\tau }}\\right|\\left|\\mathrm {d} {\\boldsymbol {\\theta }}\\right|\\cos 0=\\tau \\,\\mathrm {d} \\theta }\n   giving\n\n  \n    \n      \n        W\n        =\n        \n          \u222b\n          \n            \n              \u03b8\n              \n                1\n              \n            \n          \n          \n            \n              \u03b8\n              \n                2\n              \n            \n          \n        \n        \u03c4\n        \n        \n          d\n        \n        \u03b8\n      \n    \n    {\\displaystyle W=\\int _{\\theta _{1}}^{\\theta _{2}}\\tau \\,\\mathrm {d} \\theta }\n  It follows from the work\u2013energy principle that W also represents the change in the rotational kinetic energy Er of the body, given by\n\n  \n    \n      \n        \n          E\n          \n            \n              r\n            \n          \n        \n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        I\n        \n          \u03c9\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle E_{\\mathrm {r} }={\\tfrac {1}{2}}I\\omega ^{2},}\n  where I is the moment of inertia of the body and \u03c9 is its angular speed.Power is the work per unit time, given by\n\n  \n    \n      \n        P\n        =\n        \n          \u03c4\n        \n        \u22c5\n        \n          \u03c9\n        \n        ,\n      \n    \n    {\\displaystyle P={\\boldsymbol {\\tau }}\\cdot {\\boldsymbol {\\omega }},}\n  where P is power, \u03c4 is torque, \u03c9 is the angular velocity, and \n  \n    \n      \n        \u22c5\n      \n    \n    {\\displaystyle \\cdot }\n   represents the scalar product.\nAlgebraically, the equation may be rearranged to compute torque for a given angular speed and power output. Note that the power injected by the torque depends only on the instantaneous angular speed \u2013 not on whether the angular speed increases, decreases, or remains constant while the torque is being applied (this is equivalent to the linear case where the power injected by a force depends only on the instantaneous speed \u2013 not on the resulting acceleration, if any).\nIn practice, this relationship can be observed in bicycles: Bicycles are typically composed of two road wheels, front and rear gears (referred to as sprockets) meshing with a chain, and a derailleur mechanism if the bicycle's transmission system allows multiple gear ratios to be used (i.e. multi-speed bicycle), all of which attached to the frame. A cyclist, the person who rides the bicycle, provides the input power by turning pedals, thereby cranking the front sprocket (commonly referred to as chainring). The input power provided by the cyclist is equal to the product of angular speed (i.e. the number of pedal revolutions per minute times 2\u03c0) and the torque at the spindle of the bicycle's crankset. The bicycle's drivetrain transmits the input power to the road wheel, which in turn conveys the received power to the road as the output power of the bicycle. Depending on the gear ratio of the bicycle, a (torque, angular speed)input pair is converted to a (torque, angular speed)output pair. By using a larger rear gear, or by switching to a lower gear in multi-speed bicycles, angular speed of the road wheels is decreased while the torque is increased, product of which (i.e. power) does not change.\nFor SI units, the unit of power is the watt, the unit of torque is the newton-metre and the unit of angular speed is the radian per second (not rpm and not revolutions per second).\nThe unit newton-metre is dimensionally equivalent to the joule, which is the unit of energy. In the case of torque, the unit is assigned to a vector, whereas for energy, it is assigned to a scalar. This means that the dimensional equivalence of the newton-metre and the joule may be applied in the former, but not in the latter case. This problem is addressed in orientational analysis, which treats the radian as a base unit rather than as a dimensionless unit.\n\n\n=== Conversion to other units ===\nA conversion factor may be necessary when using different units of power or torque.  For example, if rotational speed (unit: revolution per minute or second) is used in place of angular speed (unit: radian per second), we must multiply by 2\u03c0 radians per revolution. In the following formulas, P is power, \u03c4 is torque, and \u03bd (Greek letter nu) is rotational speed.\n\n  \n    \n      \n        P\n        =\n        \u03c4\n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \u03bd\n      \n    \n    {\\displaystyle P=\\tau \\cdot 2\\pi \\cdot \\nu }\n  Showing units:\n\n  \n    \n      \n        \n          P\n          \n            \n              W\n            \n          \n        \n        =\n        \n          \u03c4\n          \n            \n              N\n              \n                \u22c5\n              \n              m\n            \n          \n        \n        \u22c5\n        2\n        \n          \u03c0\n          \n            \n              r\n              a\n              d\n              \n                /\n              \n              r\n              e\n              v\n            \n          \n        \n        \u22c5\n        \n          \u03bd\n          \n            \n              r\n              e\n              v\n              \n                /\n              \n              s\n            \n          \n        \n      \n    \n    {\\displaystyle P_{\\rm {W}}=\\tau _{\\rm {N{\\cdot }m}}\\cdot 2\\pi _{\\rm {rad/rev}}\\cdot \\nu _{\\rm {rev/s}}}\n  Dividing by 60 seconds per minute gives us the following.\n\n  \n    \n      \n        \n          P\n          \n            \n              W\n            \n          \n        \n        =\n        \n          \n            \n              \n                \u03c4\n                \n                  \n                    N\n                    \n                      \u22c5\n                    \n                    m\n                  \n                \n              \n              \u22c5\n              2\n              \n                \u03c0\n                \n                  \n                    r\n                    a\n                    d\n                    \n                      /\n                    \n                    r\n                    e\n                    v\n                  \n                \n              \n              \u22c5\n              \n                \u03bd\n                \n                  \n                    r\n                    e\n                    v\n                    \n                      /\n                    \n                    m\n                    i\n                    n\n                  \n                \n              \n            \n            \n              60\n               \n              s\n              \n                /\n              \n              m\n              i\n              n\n            \n          \n        \n      \n    \n    {\\displaystyle P_{\\rm {W}}={\\frac {\\tau _{\\rm {N{\\cdot }m}}\\cdot 2\\pi _{\\rm {rad/rev}}\\cdot \\nu _{\\rm {rev/min}}}{\\rm {60~s/min}}}}\n  where rotational speed is in revolutions per minute (rpm, rev/min).\nSome people (e.g., American automotive engineers) use horsepower (mechanical) for power, foot-pounds (lbf\u22c5ft) for torque and rpm for rotational speed. This results in the formula changing to:\n\n  \n    \n      \n        \n          P\n          \n            \n              h\n              p\n            \n          \n        \n        =\n        \n          \n            \n              \n                \u03c4\n                \n                  \n                    l\n                    b\n                    f\n                    \n                      \u22c5\n                    \n                    f\n                    t\n                  \n                \n              \n              \u22c5\n              2\n              \n                \u03c0\n                \n                  \n                    r\n                    a\n                    d\n                    \n                      /\n                    \n                    r\n                    e\n                    v\n                  \n                \n              \n              \u22c5\n              \n                \u03bd\n                \n                  \n                    r\n                    e\n                    v\n                    \n                      /\n                    \n                    m\n                    i\n                    n\n                  \n                \n              \n            \n            \n              33\n              ,\n              000\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle P_{\\rm {hp}}={\\frac {\\tau _{\\rm {lbf{\\cdot }ft}}\\cdot 2\\pi _{\\rm {rad/rev}}\\cdot \\nu _{\\rm {rev/min}}}{33,000}}.}\n  The constant below (in foot-pounds per minute) changes with the definition of the horsepower; for example, using metric horsepower, it becomes approximately 32,550.\nThe use of other units (e.g., BTU per hour for power) would require a different custom conversion factor.\n\n\n=== Derivation ===\nFor a rotating object, the linear distance covered at the circumference of rotation is the product of the radius with the angle covered.  That is:  linear distance = radius \u00d7 angular distance. And by definition, linear distance = linear speed \u00d7 time = radius \u00d7 angular speed \u00d7 time.\nBy the definition of torque: torque = radius \u00d7 force. We can rearrange this to determine force = torque \u00f7 radius. These two values can be substituted into the definition of power:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        force\n                      \n                      \u22c5\n                      \n                        linear distance\n                      \n                    \n                    time\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      \n                        (\n                        \n                          \n                            \n                              torque\n                              r\n                            \n                          \n                        \n                        )\n                      \n                      \u22c5\n                      (\n                      r\n                      \u22c5\n                      \n                        angular speed\n                      \n                      \u22c5\n                      t\n                      )\n                    \n                    t\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                \n                  angular speed\n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\frac {{\\text{force}}\\cdot {\\text{linear distance}}}{\\text{time}}}\\\\[6pt]&={\\frac {\\left({\\dfrac {\\text{torque}}{r}}\\right)\\cdot (r\\cdot {\\text{angular speed}}\\cdot t)}{t}}\\\\[6pt]&={\\text{torque}}\\cdot {\\text{angular speed}}.\\end{aligned}}}\n  The radius r and time t have dropped out of the equation.  However, angular speed must be in radians per unit of time, by the assumed direct relationship between linear speed and angular speed at the beginning of the derivation.  If the rotational speed is measured in revolutions per unit of time, the linear speed and distance are increased proportionately by 2\u03c0 in the above derivation to give:\n\n  \n    \n      \n        \n          power\n        \n        =\n        \n          torque\n        \n        \u22c5\n        2\n        \u03c0\n        \u22c5\n        \n          rotational speed\n        \n        .\n        \n      \n    \n    {\\displaystyle {\\text{power}}={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}.\\,}\n  If torque is in newton-metres and rotational speed in revolutions per second, the above equation gives power in newton-metres per second or watts.  If Imperial units are used, and if torque is in pounds-force feet and rotational speed in revolutions per minute, the above equation gives power in foot pounds-force per minute.  The horsepower form of the equation is then derived by applying the conversion factor 33,000 ft\u22c5lbf/min per horsepower:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  power\n                \n              \n              \n                \n                =\n                \n                  torque\n                \n                \u22c5\n                2\n                \u03c0\n                \u22c5\n                \n                  rotational speed\n                \n                \u22c5\n                \n                  \n                    \n                      \n                        ft\n                      \n                      \n                        \u22c5\n                      \n                      \n                        lbf\n                      \n                    \n                    min\n                  \n                \n                \u22c5\n                \n                  \n                    horsepower\n                    \n                      33\n                      ,\n                      000\n                      \u22c5\n                      \n                        \n                          \n                            \n                              ft\n                            \n                            \u22c5\n                            \n                              lbf\n                            \n                          \n                          min\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2248\n                \n                  \n                    \n                      \n                        torque\n                      \n                      \u22c5\n                      \n                        RPM\n                      \n                    \n                    \n                      5\n                      ,\n                      252\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{power}}&={\\text{torque}}\\cdot 2\\pi \\cdot {\\text{rotational speed}}\\cdot {\\frac {{\\text{ft}}{\\cdot }{\\text{lbf}}}{\\text{min}}}\\cdot {\\frac {\\text{horsepower}}{33,000\\cdot {\\frac {{\\text{ft}}\\cdot {\\text{lbf}}}{\\text{min}}}}}\\\\[6pt]&\\approx {\\frac {{\\text{torque}}\\cdot {\\text{RPM}}}{5,252}}\\end{aligned}}}\n  because \n  \n    \n      \n        5252.113122\n        \u2248\n        \n          \n            \n              33\n              ,\n              000\n            \n            \n              2\n              \u03c0\n            \n          \n        \n        .\n        \n      \n    \n    {\\displaystyle 5252.113122\\approx {\\frac {33,000}{2\\pi }}.\\,}\n  \n\n\n== Principle of moments ==\nThe principle of moments, also known as Varignon's theorem (not to be confused with the geometrical theorem of the same name) states that the resultant torques due to several forces applied to about a point is equal to the sum of the contributing torques:\n\n  \n    \n      \n        \u03c4\n        =\n        \n          \n            r\n          \n          \n            1\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            1\n          \n        \n        +\n        \n          \n            r\n          \n          \n            2\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            2\n          \n        \n        +\n        \u2026\n        +\n        \n          \n            r\n          \n          \n            N\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            N\n          \n        \n        .\n      \n    \n    {\\displaystyle \\tau =\\mathbf {r} _{1}\\times \\mathbf {F} _{1}+\\mathbf {r} _{2}\\times \\mathbf {F} _{2}+\\ldots +\\mathbf {r} _{N}\\times \\mathbf {F} _{N}.}\n  From this it follows that the torques resulting from two forces acting around a pivot on an object are balanced when\n\n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            1\n          \n        \n        +\n        \n          \n            r\n          \n          \n            2\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            2\n          \n        \n        =\n        \n          0\n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {r} _{1}\\times \\mathbf {F} _{1}+\\mathbf {r} _{2}\\times \\mathbf {F} _{2}=\\mathbf {0} .}\n  \n\n\n== Torque multiplier ==\n\nTorque can be multiplied via three methods: by locating the fulcrum such that the length of a lever is increased; by using a longer lever; or by the use of a speed-reducing gearset or gear box.  Such a mechanism multiplies torque, as rotation rate is reduced.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\n\"Horsepower and Torque\" Archived 2007-03-28 at the Wayback Machine An article showing how power, torque, and gearing affect a vehicle's performance.\nTorque and Angular Momentum in Circular Motion  on Project PHYSNET.\nAn interactive simulation of torque\nTorque Unit Converter\nA feel for torque An order-of-magnitude interactive.", "Color": "Color (American English) or colour (Commonwealth English) is the visual perception based on the electromagnetic spectrum. Though color is not an inherent property of matter, color perception is related to an object's light absorption, reflection, emission spectra and interference. For most humans, color are perceived in the visible light spectrum with three types of cone cells (trichromacy). Other animals may have a different number of cone cell types or have eyes sensitive to different wavelength, such as bees that can distinguish ultraviolet, and thus has a different color sensitivity range. Animal perception of color originates from different light wavelength or spectral sensitivity in cone cell types, which is then processed by the brain.\nColors have perceived properties such as hue, colorfulness (saturation) and luminance. Colors can also be additively mixed (commonly used for actual light) or subtractively mixed (commonly used for materials). If the colors are mixed in the right proportions, because of metamerism, they may look the same as a single-wavelength light. For convenience, colors can be organized in a color space, which when being abstracted as a mathematical color model can assign each region of color with a corresponding set of numbers. As such, color spaces are an essential tool for color reproduction in print, photography, computer monitors and television. The most well-known color models are RGB, CMYK, YUV, HSL and HSV.\nBecause the perception of color is an important aspect of human life, different colors have been associated with emotions, activity, and nationality. Names of color regions in different cultures can have different, sometimes overlapping areas. In visual arts, color theory is used to govern the use of colors in an aesthetically pleasing and harmonious way. The theory of color includes the color complements; color balance; and classification of primary colors (traditionally red, yellow, blue), secondary colors (traditionally orange, green, purple) and tertiary colors. The study of colors in general is called color science.\n\n\n== Physical properties ==\n\nElectromagnetic radiation is characterized by its wavelength (or frequency) and its intensity. When the wavelength is within the visible spectrum (the range of wavelengths humans can perceive, approximately from 390 nm to 700 nm), it is known as \"visible light\".\nMost light sources emit light at many different wavelengths; a source's spectrum is a distribution giving its intensity at each wavelength. Although the spectrum of light arriving at the eye from a given direction determines the color sensation in that direction, there are many more possible spectral combinations than color sensations. In fact, one may formally define a color as a class of spectra that give rise to the same color sensation, although such classes would vary widely among different species, and to a lesser extent among individuals within the same species. In each such class, the members are called metamers of the color in question. This effect can be visualized by comparing the light sources' spectral power distributions and the resulting colors.\n\n\n=== Spectral colors ===\n\nThe familiar colors of the rainbow in the spectrum\u2014named using the Latin word for appearance or apparition by Isaac Newton in 1671\u2014include all those colors that can be produced by visible light of a single wavelength only, the pure spectral or monochromatic colors. The table at right shows approximate frequencies (in terahertz) and wavelengths (in nanometers) for spectral colors in the visible range. Spectral colors have 100% purity, and are fully saturated. A complex mixture of spectral colors can be used to describe any color, which is the definition of a light power spectrum.\nThe color table should not be interpreted as a definitive list; the spectral colors form a continuous spectrum, and how it is divided into distinct colors linguistically is a matter of culture and historical contingency. Despite the ubiquitous ROYGBIV mnemonic used to remember the spectral colors in English, the inclusion or exclusion of colors in this table is contentious, with disagreement often focused on indigo and cyan. Even if the subset of color terms is agreed, their wavelength ranges and borders between them may not be.\nThe intensity of a spectral color, relative to the context in which it is viewed, may alter its perception considerably according to the Bezold\u2013Br\u00fccke shift; for example, a low-intensity orange-yellow is brown, and a low-intensity yellow-green is olive green.\n\n\n=== Color of objects ===\nThe color of an object depends on how it absorbs and scatters light. Most objects scatters light to some degree and do not reflect or transmit light specularly like glasses or mirrors. A transparent object allows almost all light to transmit or pass through, thus transparent objects are perceived as colorless. Conversely, an opaque object does not allow light to transmit through and instead absorbing or reflecting the light it receives. Like transparent objects, translucent objects allow light to transmit through, but translucent objects are seen colored because they scatter or absorb certain wavelengths of light via internal scatterance. The absorbed light is often dissipated as heat.:\u200a5\u20139,\u200a12\u200a\n\n\n== Color vision ==\n\n\n=== Development of theories of color vision ===\n\nAlthough Aristotle and other ancient scientists had already written on the nature of light and color vision, it was not until Newton that light was identified as the source of the color sensation. In 1810, Goethe published his comprehensive Theory of Colors in which he provided a rational description of color experience, which 'tells us how it originates, not what it is'. (Schopenhauer)\nIn 1801 Thomas Young proposed his trichromatic theory, based on the observation that any color could be matched with a combination of three lights. This theory was later refined by James Clerk Maxwell and Hermann von Helmholtz. As Helmholtz puts it, \"the principles of Newton's law of mixture were experimentally confirmed by Maxwell in 1856. Young's theory of color sensations, like so much else that this marvelous investigator achieved in advance of his time, remained unnoticed until Maxwell directed attention to it.\"At the same time as Helmholtz, Ewald Hering developed the opponent process theory of color, noting that color blindness and afterimages typically come in opponent pairs (red-green, blue-orange, yellow-violet, and black-white). Ultimately these two theories were synthesized in 1957 by Hurvich and Jameson, who showed that retinal processing corresponds to the trichromatic theory, while processing at the level of the lateral geniculate nucleus corresponds to the opponent theory.In 1931, an international group of experts known as the Commission internationale de l'\u00e9clairage (CIE) developed a mathematical color model, which mapped out the space of observable colors and assigned a set of three numbers to each.\n\n\n=== Color in the eye ===\n\nThe ability of the human eye to distinguish colors is based upon the varying sensitivity of different cells in the retina to light of different wavelengths. Humans are trichromatic\u2014the retina contains three types of color receptor cells, or cones. One type, relatively distinct from the other two, is most responsive to light that is perceived as blue or blue-violet, with wavelengths around 450 nm; cones of this type are sometimes called short-wavelength cones or S cones (or misleadingly, blue cones). The other two types are closely related genetically and chemically: middle-wavelength cones, M cones, or green cones are most sensitive to light perceived as green, with wavelengths around 540 nm, while the long-wavelength cones, L cones, or red cones, are most sensitive to light that is perceived as greenish yellow, with wavelengths around 570 nm.\nLight, no matter how complex its composition of wavelengths, is reduced to three color components by the eye. Each cone type adheres to the principle of univariance, which is that each cone's output is determined by the amount of light that falls on it over all wavelengths. For each location in the visual field, the three types of cones yield three signals based on the extent to which each is stimulated. These amounts of stimulation are sometimes called tristimulus values.The response curve as a function of wavelength varies for each type of cone. Because the curves overlap, some tristimulus values do not occur for any incoming light combination. For example, it is not possible to stimulate only the mid-wavelength (so-called \"green\") cones; the other cones will inevitably be stimulated to some degree at the same time. The set of all possible tristimulus values determines the human color space. It has been estimated that humans can distinguish roughly 10 million different colors.The other type of light-sensitive cell in the eye, the rod, has a different response curve. In normal situations, when light is bright enough to strongly stimulate the cones, rods play virtually no role in vision at all. On the other hand, in dim light, the cones are understimulated leaving only the signal from the rods, resulting in a colorless response. (Furthermore, the rods are barely sensitive to light in the \"red\" range.) In certain conditions of intermediate illumination, the rod response and a weak cone response can together result in color discriminations not accounted for by cone responses alone. These effects, combined, are summarized also in the Kruithof curve, which describes the change of color perception and pleasingness of light as a function of temperature and intensity.\n\n\n=== Color in the brain ===\n\nWhile the mechanisms of color vision at the level of the retina are well-described in terms of tristimulus values, color processing after that point is organized differently. A dominant theory of color vision proposes that color information is transmitted out of the eye by three opponent processes, or opponent channels, each constructed from the raw output of the cones: a red\u2013green channel, a blue\u2013yellow channel, and a black\u2013white \"luminance\" channel. This theory has been supported by neurobiology, and accounts for the structure of our subjective color experience. Specifically, it explains why humans cannot perceive a \"reddish green\" or \"yellowish blue\", and it predicts the color wheel: it is the collection of colors for which at least one of the two color channels measures a value at one of its extremes.\nThe exact nature of color perception beyond the processing already described, and indeed the status of color as a feature of the perceived world or rather as a feature of our perception of the world\u2014a type of qualia\u2014is a matter of complex and continuing philosophical dispute.\n\n\n=== Nonstandard color perception ===\n\n\n==== Color vision deficiency ====\n\nA color vision deficiency causes an individual to perceive a smaller gamut of colors than the standard observer with normal color vision. The effect can be mild, having lower \"color resolution\" (i.e. anomalous trichromacy), moderate, lacking an entire dimension or channel of color (e.g. dichromacy), or complete, lacking all color perception (i.e. monochromacy). Most forms of color blindness derive from one or more of the three classes of cone cells either being missing, having a shifted spectral sensitivity or having lower responsiveness to incoming light. In addition, cerebral achromatopsia is caused by neural anomalies in those parts of the brain where visual processing takes place.\nSome colors that appear distinct to an individual with normal color vision will appear metameric to the color blind. The most common form of color blindness is congenital red\u2013green color blindness, affecting ~8% of males. Individuals with the strongest form of this condition (dichromacy) will experience blue and purple, green and yellow, teal and gray as colors of confusion, i.e. metamers.\n\n\n==== Tetrachromacy ====\n\nOutside of humans, which are mostly trichromatic (having three types of cones), most mammals are dichromatic, possessing only two cones. However, outside of mammals, most vertebrate are tetrachromatic, having four types of cones, and includes most, birds, reptiles, amphibians and bony fish. An extra dimension of color vision means these vertebrates can see two distinct colors that a normal human would view as metamers. Some invertebrates, such as the mantis shrimp, have an even higher number of cones (12) that could lead to a richer color gamut than even imaginable by humans.\nThe existence of human tetrachromats is a contentious notion. As many as half of all human females have 4 distinct cone classes, which could enable tetrachromacy.:\u200ap.256\u200a\nHowever, a distinction must be made between retinal (or weak) tetrachromats, which express four cone classes in the retina, and functional (or strong) tetrachromats, which are able to make the enhanced color discriminations expected of tetrachromats. In fact, there is only one peer-reviewed report of a functional tetrachromat. It is estimated that while the average person is able to see one million colors, someone with functional tetrachromacy could see a hundred million colors.\n\n\n==== Synesthesia ====\n\nIn certain forms of synesthesia, perceiving letters and numbers (grapheme\u2013color synesthesia) or hearing sounds (chromesthesia) will evoke a perception of color. Behavioral and functional neuroimaging experiments have demonstrated that these color experiences lead to changes in behavioral tasks and lead to increased activation of brain regions involved in color perception, thus demonstrating their reality, and similarity to real color percepts, albeit evoked through a non-standard route. Synesthesia can occur genetically, with 4% of the population having variants associated with the condition. Synesthesia has also been known to occur with brain damage, drugs, and sensory deprivation.The philosopher Pythagoras experienced synesthesia and provided one of the first written accounts of the condition in approximately 550 BCE. He created mathematical equations for musical notes that could form part of a scale, such as an octave.\n\n\n=== Afterimages ===\n\nAfter exposure to strong light in their sensitivity range, photoreceptors of a given type become desensitized. For a few seconds after the light ceases, they will continue to signal less strongly than they otherwise would. Colors observed during that period will appear to lack the color component detected by the desensitized photoreceptors. This effect is responsible for the phenomenon of afterimages, in which the eye may continue to see a bright figure after looking away from it, but in a complementary color.\nAfterimage effects have also been used by artists, including Vincent van Gogh.\n\n\n=== Color constancy ===\n\nWhen an artist uses a limited color palette, the human eye tends to compensate by seeing any gray or neutral color as the color which is missing from the color wheel. For example, in a limited palette consisting of red, yellow, black, and white, a mixture of yellow and black will appear as a variety of green, a mixture of red and black will appear as a variety of purple, and pure gray will appear bluish.The trichromatic theory is strictly true when the visual system is in a fixed state of adaptation. In reality, the visual system is constantly adapting to changes in the environment and compares the various colors in a scene to reduce the effects of the illumination. If a scene is illuminated with one light, and then with another, as long as the difference between the light sources stays within a reasonable range, the colors in the scene appear relatively constant to us. This was studied by Edwin H. Land in the 1970s and led to his retinex theory of color constancy.\nBoth phenomena are readily explained and mathematically modeled with modern theories of chromatic adaptation and color appearance (e.g. CIECAM02, iCAM). There is no need to dismiss the trichromatic theory of vision, but rather it can be enhanced with an understanding of how the visual system adapts to changes in the viewing environment.\n\n\n== Reproduction ==\n\nColor reproduction is the science of creating colors for the human eye that faithfully represent the desired color. It focuses on how to construct a spectrum of wavelengths that will best evoke a certain color in an observer. Most colors are not spectral colors, meaning they are mixtures of various wavelengths of light. However, these non-spectral colors are often described by their dominant wavelength, which identifies the single wavelength of light that produces a sensation most similar to the non-spectral color. Dominant wavelength is roughly akin to hue.\nThere are many color perceptions that by definition cannot be pure spectral colors due to desaturation or because they are purples (mixtures of red and violet light, from opposite ends of the spectrum). Some examples of necessarily non-spectral colors are the achromatic colors (black, gray, and white) and colors such as pink, tan, and magenta.\nTwo different light spectra that have the same effect on the three color receptors in the human eye will be perceived as the same color. They are metamers of that color. This is exemplified by the white light emitted by fluorescent lamps, which typically has a spectrum of a few narrow bands, while daylight has a continuous spectrum. The human eye cannot tell the difference between such light spectra just by looking into the light source, although the color rendering index of each light source may affect the color of objects illuminated by these metameric light sources.\nSimilarly, most human color perceptions can be generated by a mixture of three colors called primaries. This is used to reproduce color scenes in photography, printing, television, and other media. There are a number of methods or color spaces for specifying a color in terms of three particular primary colors. Each method has its advantages and disadvantages depending on the particular application.\nNo mixture of colors, however, can produce a response truly identical to that of a spectral color, although one can get close, especially for the longer wavelengths, where the CIE 1931 color space chromaticity diagram has a nearly straight edge. For example, mixing green light (530 nm) and blue light (460 nm) produces cyan light that is slightly desaturated, because response of the red color receptor would be greater to the green and blue light in the mixture than it would be to a pure cyan light at 485 nm that has the same intensity as the mixture of blue and green.\nBecause of this, and because the primaries in color printing systems generally are not pure themselves, the colors reproduced are never perfectly saturated spectral colors, and so spectral colors cannot be matched exactly. However, natural scenes rarely contain fully saturated colors, thus such scenes can usually be approximated well by these systems. The range of colors that can be reproduced with a given color reproduction system is called the gamut. The CIE chromaticity diagram can be used to describe the gamut.\nAnother problem with color reproduction systems is connected with the initial measurement of color, or colorimetry. The characteristics of the color sensors in measurement devices (e.g. cameras, scanners) are often very far from the characteristics of the receptors in the human eye.\nA color reproduction system \"tuned\" to a human with normal color vision may give very inaccurate results for other observers, according to color vision deviations to the standard observer.\nThe different color response of different devices can be problematic if not properly managed. For color information stored and transferred in digital form, color management techniques, such as those based on ICC profiles, can help to avoid distortions of the reproduced colors. Color management does not circumvent the gamut limitations of particular output devices, but can assist in finding good mapping of input colors into the gamut that can be reproduced.\n\n\n=== Additive coloring ===\n\nAdditive color is light created by mixing together light of two or more different colors. Red, green, and blue are the additive primary colors normally used in additive color systems such as projectors, televisions, and computer terminals.\n\n\n=== Subtractive coloring ===\n\nSubtractive coloring uses dyes, inks, pigments, or filters to absorb some wavelengths of light and not others. The color that a surface displays comes from the parts of the visible spectrum that are not absorbed and therefore remain visible. Without pigments or dye, fabric fibers, paint base and paper are usually made of particles that scatter white light (all colors) well in all directions. When a pigment or ink is added, wavelengths are absorbed or \"subtracted\" from white light, so light of another color reaches the eye.\nIf the light is not a pure white source (the case of nearly all forms of artificial lighting), the resulting spectrum will appear a slightly different color. Red paint, viewed under blue light, may appear black. Red paint is red because it scatters only the red components of the spectrum. If red paint is illuminated by blue light, it will be absorbed by the red paint, creating the appearance of a black object.\n\n\n=== Structural color ===\n\nStructural colors are colors caused by interference effects rather than by pigments. Color effects are produced when a material is scored with fine parallel lines, formed of one or more parallel thin layers, or otherwise composed of microstructures on the scale of the color's wavelength. If the microstructures are spaced randomly, light of shorter wavelengths will be scattered preferentially to produce Tyndall effect colors: the blue of the sky (Rayleigh scattering, caused by structures much smaller than the wavelength of light, in this case, air molecules), the luster of opals, and the blue of human irises. If the microstructures are aligned in arrays, for example, the array of pits in a CD, they behave as a diffraction grating: the grating reflects different wavelengths in different directions due to interference phenomena, separating mixed \"white\" light into light of different wavelengths. If the structure is one or more thin layers then it will reflect some wavelengths and transmit others, depending on the layers' thickness.\nStructural color is studied in the field of thin-film optics. The most ordered or the most changeable structural colors are iridescent. Structural color is responsible for the blues and greens of the feathers of many birds (the blue jay, for example), as well as certain butterfly wings and beetle shells. Variations in the pattern's spacing often give rise to an iridescent effect, as seen in peacock feathers, soap bubbles, films of oil, and mother of pearl, because the reflected color depends upon the viewing angle. Numerous scientists have carried out research in butterfly wings and beetle shells, including Isaac Newton and Robert Hooke. Since 1942, electron micrography has been used, advancing the development of products that exploit structural color, such as \"photonic\" cosmetics.\n\n\n== Cultural perspective ==\nColors, their meanings and associations can play a major role in works of art, including literature.\n\n\n=== Associations ===\nIndividual colors have a variety of cultural associations such as national colors (in general described in individual color articles and color symbolism). The field of color psychology attempts to identify the effects of color on human emotion and activity. Chromotherapy is a form of alternative medicine attributed to various Eastern traditions. Colors have different associations in different countries and cultures.Different colors have been demonstrated to have effects on cognition. For example, researchers at the University of Linz in Austria demonstrated that the color red significantly decreases cognitive functioning in men. The combination of the colors red and yellow together can induce hunger, which has been capitalized on by a number of chain restaurants.Color plays a role in memory development too. A photograph that is in black and white is slightly less memorable than one in color. Studies also show that wearing bright colors makes you more memorable to people you meet.\n\n\n=== Terminology ===\n\nColors vary in several different ways, including hue (shades of red, orange, yellow, green, blue, and violet), saturation, brightness, and gloss. Some color words are derived from the name of an object of that color, such as \"orange\" or \"salmon\", while others are abstract, like \"red\".\nIn the 1969 study Basic Color Terms: Their Universality and Evolution, Brent Berlin and Paul Kay describe a pattern in naming \"basic\" colors (like \"red\" but not \"red-orange\" or \"dark red\" or \"blood red\", which are \"shades\" of red). All languages that have two \"basic\" color names distinguish dark/cool colors from bright/warm colors. The next colors to be distinguished are usually red and then yellow or green. All languages with six \"basic\" colors include black, white, red, green, blue, and yellow. The pattern holds up to a set of twelve: black, gray, white, pink, red, orange, yellow, green, blue, purple, brown, and azure (distinct from blue in Russian and Italian, but not English).\n\n\n== See also ==\nChromophore\nColor analysis\nColor in Chinese culture\nColor mapping\nComplementary colors\nImpossible color\nInternational Color Consortium\nInternational Commission on Illumination\nLists of colors (compact version)\nNeutral color\nPearlescent coating including Metal effect pigments\nPseudocolor\nPrimary, secondary and tertiary colors\n\n\n== References ==\n\n\n== External links ==\nColor at the Encyclop\u00e6dia Britannica\nMaund, Barry. \"Color\".  In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\n\"Color\". Internet Encyclopedia of Philosophy.", "Gravitational_constant": "The gravitational constant (also known as the universal gravitational constant, the Newtonian constant of gravitation, or the Cavendish gravitational constant), denoted by the capital letter G, is an empirical physical constant involved in the calculation of gravitational effects in Sir Isaac Newton's law of universal gravitation and in Albert Einstein's theory of general relativity.\nIn Newton's law, it is the proportionality constant connecting the gravitational force between two bodies with the product of their masses and the inverse square of their distance. In the Einstein field equations, it quantifies the relation between the geometry of spacetime and the energy\u2013momentum tensor (also referred to as the stress\u2013energy tensor).\nThe measured value of the constant is known with some certainty to four significant digits. In SI units, its value is approximately 6.674\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122.The modern notation of Newton's law involving G was introduced in the 1890s by C. V. Boys. The first implicit measurement with an accuracy within about 1% is attributed to Henry Cavendish in a 1798 experiment.\n\n\n== Definition ==\nAccording to Newton's law of universal gravitation, the magnitude of the attractive force (F) between two point-like bodies is directly proportional to the product of their masses, m1 and m2, and inversely proportional to the square of the distance, r, between their centers of mass:\n\nThe constant of proportionality, G, is the gravitational constant. Colloquially, the gravitational constant is also called \"Big G\", distinct from \"small g\" (g), which is the local gravitational field of Earth (equivalent to the free-fall acceleration). Where \n  \n    \n      \n        \n          M\n          \n            \u2295\n          \n        \n      \n    \n    {\\displaystyle M_{\\oplus }}\n   is the mass of the Earth and \n  \n    \n      \n        \n          r\n          \n            \u2295\n          \n        \n      \n    \n    {\\displaystyle r_{\\oplus }}\n   is the radius of the Earth, the two quantities are related by:\n\nThe gravitational constant appears in the Einstein field equations of general relativity,\nwhere G\u03bc\u03bd is the Einstein tensor, \u039b is the cosmological constant, g\u03bc\u03bd is the metric tensor, T\u03bc\u03bd is the stress\u2013energy tensor,  and \u03ba is the Einstein gravitational constant, a constant originally introduced by Einstein that is directly related to the Newtonian constant of gravitation:\n\n\n== Value and uncertainty ==\nThe gravitational constant is a physical constant that is difficult to measure with high accuracy. This is because the gravitational force is an extremely weak force as compared to other fundamental forces at the laboratory scale.In SI units, the 2018 Committee on Data for Science and Technology (CODATA)-recommended value of the gravitational constant (with standard uncertainty in parentheses) is:\nThis corresponds to a relative standard uncertainty of 2.2\u00d710\u22125 (22 ppm).\n\n\n=== Natural units ===\nThe gravitational constant is a defining constant in some systems of natural units, particularly geometrized unit systems, such as Planck units and Stoney units.  When expressed in terms of such units, the value of the gravitational constant will generally have a numeric value of 1 or a value close to it. Due to the significant uncertainty in the measured value of G in terms of other known fundamental constants, a similar level of uncertainty will show up in the value of many quantities when expressed in such a unit system.\n\n\n=== Orbital mechanics ===\n\nIn astrophysics, it is convenient to measure distances in parsecs (pc), velocities in kilometres per second (km/s) and masses in solar units M\u2299. In these units, the gravitational constant is:\n\nFor situations where tides are important, the relevant length scales are solar radii rather than parsecs. In these units, the gravitational constant is:\n\nIn orbital mechanics, the period P of an object in circular orbit around a spherical object obeys\n\nwhere V is the volume inside the radius of the orbit. It follows that\n\n  \n    \n      \n        \n          P\n          \n            2\n          \n        \n        =\n        \n          \n            \n              3\n              \u03c0\n            \n            G\n          \n        \n        \n          \n            V\n            M\n          \n        \n        \u2248\n        10.896\n        \n        \n          \n            h\n            \n              2\n            \n          \n          \n            \u22c5\n          \n          g\n          \n            \u22c5\n          \n          c\n          \n            m\n            \n              \u2212\n              3\n            \n          \n          \n        \n        \n          \n            V\n            M\n          \n        \n        .\n      \n    \n    {\\displaystyle P^{2}={\\frac {3\\pi }{G}}{\\frac {V}{M}}\\approx 10.896\\,\\mathrm {h^{2}{\\cdot }g{\\cdot }cm^{-3}\\,} {\\frac {V}{M}}.}\n  This way of expressing G shows the relationship between the average density of a planet and the period of a satellite orbiting just above its surface.\nFor elliptical orbits, applying Kepler's 3rd law, expressed in units characteristic of Earth's orbit:\n\n  \n    \n      \n        G\n        =\n        4\n        \n          \u03c0\n          \n            2\n          \n        \n        \n           \n          A\n          \n            U\n            \n              3\n            \n          \n          \n            \u22c5\n          \n          y\n          \n            r\n            \n              \u2212\n              2\n            \n          \n        \n         \n        \n          M\n          \n            \u2212\n            1\n          \n        \n        \u2248\n        39.478\n        \n           \n          A\n          \n            U\n            \n              3\n            \n          \n          \n            \u22c5\n          \n          y\n          \n            r\n            \n              \u2212\n              2\n            \n          \n        \n         \n        \n          M\n          \n            \u2299\n          \n          \n            \u2212\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle G=4\\pi ^{2}\\mathrm {\\ AU^{3}{\\cdot }yr^{-2}} \\ M^{-1}\\approx 39.478\\mathrm {\\ AU^{3}{\\cdot }yr^{-2}} \\ M_{\\odot }^{-1},}\n  where distance is measured in terms of the semi-major axis of Earth's orbit (the astronomical unit, AU), time in years, and mass in the total mass of the orbiting system (M = M\u2609 + MEarth + M\u263e).\nThe above equation is exact only within the approximation of the Earth's orbit around the Sun as a two-body problem in Newtonian mechanics, the measured quantities contain corrections from the perturbations from other bodies in the solar system and from general relativity.\nFrom 1964 until 2012, however, it was used as the definition of the astronomical unit and thus held by definition: \n \nSince 2012, the AU is defined as 1.495978707\u00d71011 m exactly, and the equation can no longer be taken as holding precisely.\nThe quantity GM\u2014the product of the gravitational constant and the mass of a given astronomical body such as the Sun or Earth\u2014is known as the standard gravitational parameter (also denoted \u03bc). The standard gravitational parameter GM appears as above in Newton's law of universal gravitation, as well as in formulas for the deflection of light caused by gravitational lensing, in Kepler's laws of planetary motion, and in the formula for escape velocity.\nThis quantity gives a convenient simplification of various gravity-related formulas. The product GM is known much more accurately than either factor is.\n\nCalculations in celestial mechanics can also be carried out using the units of solar masses, mean solar days and astronomical units rather than standard SI units. For this purpose, the Gaussian gravitational constant was historically in widespread use, k = 0.01720209895, expressing the mean angular velocity of the Sun\u2013Earth system measured in radians per day. The use of this constant, and the implied definition of the astronomical unit discussed above, has been deprecated by the IAU since 2012.\n\n\n== History of measurement ==\n\n\n=== Early history ===\nThe existence of the constant is implied in Newton's law of universal gravitation as published in the 1680s (although its notation as G dates to the 1890s), but is not calculated in his Philosophi\u00e6 Naturalis Principia Mathematica where it postulates the inverse-square law of gravitation. In the Principia, Newton considered the possibility of measuring gravity's strength by measuring the deflection of a pendulum in the vicinity of a large hill, but thought that the effect would be too small to be measurable. Nevertheless, he had the opportunity to estimate the order of magnitude of the constant when he surmised that \"the mean density of the earth might be five or six times as great as the density of water\", which is equivalent to a gravitational constant of the order:\nG \u2248 (6.7\u00b10.6)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122A measurement was attempted in 1738 by Pierre Bouguer and Charles Marie de La Condamine in their \"Peruvian expedition\". Bouguer downplayed the significance of their results in 1740, suggesting that the experiment had at least proved that the Earth could not be a hollow shell, as some thinkers of the day, including Edmond Halley, had suggested.The Schiehallion experiment, proposed in 1772 and completed in 1776, was the first successful measurement of the mean density of the Earth, and thus indirectly of the gravitational constant. The result reported by Charles Hutton (1778) suggested a density of 4.5 g/cm3 (4+1/2 times the density of water), about 20% below the modern value. This immediately led to estimates on the densities and masses of the Sun, Moon and planets, sent by Hutton to J\u00e9r\u00f4me Lalande for inclusion in his planetary tables. As discussed above, establishing the average density of Earth is equivalent to measuring the gravitational constant, given Earth's mean radius and the mean gravitational acceleration at Earth's surface, by setting\nBased on this, Hutton's 1778 result is equivalent to G \u2248 8\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122.\n\nThe first direct measurement of gravitational attraction between two bodies in the laboratory was performed in 1798, seventy-one years after Newton's death, by Henry Cavendish. He determined a value for G implicitly, using a torsion balance invented by the geologist Rev. John Michell (1753). He used a horizontal torsion beam with lead balls whose inertia (in relation to the torsion constant) he could tell by timing the beam's oscillation. Their faint attraction to other balls placed alongside the beam was detectable by the deflection it caused. In spite of the experimental design being due to Michell, the experiment is now known as the Cavendish experiment for its first successful execution by Cavendish.\nCavendish's stated aim was the \"weighing of Earth\", that is, determining the average density of Earth and the Earth's mass. His result, \u03c1\ud83d\udf28 = 5.448(33) g\u00b7cm\u22123, corresponds to value of G = 6.74(4)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122. It is surprisingly accurate, about 1% above the modern value (comparable to the claimed standard uncertainty of 0.6%).\n\n\n=== 19th century ===\nThe accuracy of the measured value of G has increased only modestly since the original Cavendish experiment. G is quite difficult to measure because gravity is much weaker than other fundamental forces, and an experimental apparatus cannot be separated from the gravitational influence of other bodies.\nMeasurements with pendulums were made by Francesco Carlini (1821, 4.39 g/cm3), Edward Sabine (1827, 4.77 g/cm3), Carlo Ignazio Giulio (1841, 4.95 g/cm3) and George Biddell Airy (1854, 6.6 g/cm3).Cavendish's experiment was first repeated by Ferdinand Reich (1838, 1842, 1853), who found a value of 5.5832(149) g\u00b7cm\u22123, which is actually worse than Cavendish's result, differing from the modern value by 1.5%. Cornu and Baille (1873), found 5.56 g\u00b7cm\u22123.Cavendish's experiment proved to result in more reliable measurements than pendulum experiments of the \"Schiehallion\" (deflection) type or \"Peruvian\" (period as a function of altitude) type. Pendulum experiments still continued to be performed, by Robert von Sterneck (1883, results between 5.0 and 6.3 g/cm3) and Thomas Corwin Mendenhall (1880, 5.77 g/cm3).Cavendish's result was first improved upon by John Henry Poynting (1891), who published a value of 5.49(3) g\u00b7cm\u22123, differing from the modern value by 0.2%, but compatible with the modern value within the cited standard uncertainty of 0.55%. In addition to Poynting, measurements were made by C. V. Boys (1895) and Carl Braun (1897), with compatible results suggesting G = 6.66(1)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122. The modern notation involving the constant G was introduced by Boys in 1894 and becomes standard by the end of the 1890s, with values usually cited in the cgs system. Richarz and Krigar-Menzel (1898) attempted a repetition of the Cavendish experiment using 100,000 kg of lead for the attracting mass. The precision of their result of 6.683(11)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122 was, however, of the same order of magnitude as the other results at the time.Arthur Stanley Mackenzie in The Laws of Gravitation (1899) reviews the work done in the 19th century. Poynting is the author of the article \"Gravitation\" in the Encyclop\u00e6dia Britannica Eleventh Edition (1911). Here, he cites a value of G = 6.66\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122 with an uncertainty of 0.2%.\n\n\n=== Modern value ===\nPaul R. Heyl (1930) published the value of 6.670(5)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122 (relative uncertainty 0.1%), improved to 6.673(3)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122 (relative uncertainty 0.045% = 450 ppm) in 1942.Published values of G derived from high-precision measurements since the 1950s have remained compatible with Heyl (1930), but within the relative uncertainty of about 0.1% (or 1,000 ppm) have varied rather broadly, and it is not entirely clear if the uncertainty has been reduced at all since the 1942 measurement. Some measurements published in the 1980s to 2000s were, in fact, mutually exclusive. Establishing a standard value for G with a standard uncertainty better than 0.1% has therefore remained rather speculative.\nBy 1969, the value recommended by the National Institute of Standards and Technology (NIST) was cited with a standard uncertainty of 0.046% (460 ppm), lowered to 0.012% (120 ppm) by 1986. But the continued publication of conflicting measurements led NIST to considerably increase the standard uncertainty in the 1998 recommended value, by a factor of 12, to a standard uncertainty of 0.15%, larger than the one given by Heyl (1930).\nThe uncertainty was again lowered in 2002 and 2006, but once again raised, by a more conservative 20%, in 2010, matching the standard uncertainty of 120 ppm published in 1986. For the 2014 update, CODATA reduced the uncertainty to 46 ppm, less than half the 2010 value, and one order of magnitude below the 1969 recommendation.\nThe following table shows the NIST recommended values published since 1969:\n\nIn the January 2007 issue of Science, Fixler et al. described a measurement of the gravitational constant by a new technique, atom interferometry, reporting a value of G = 6.693(34)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122, 0.28% (2800 ppm) higher than the 2006 CODATA value. An improved cold atom measurement by Rosi et al. was published in 2014 of G = 6.67191(99)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122. Although much closer to the accepted value (suggesting that the Fixler et al. measurement was erroneous), this result was 325 ppm below the recommended 2014 CODATA value, with non-overlapping standard uncertainty intervals.\nAs of 2018, efforts to re-evaluate the conflicting results of measurements are underway, coordinated by NIST, notably a repetition of the experiments reported by Quinn et al. (2013).In August 2018, a Chinese research group announced new measurements based on torsion balances, 6.674184(78)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122 and 6.674484(78)\u00d710\u221211 m3\u22c5kg\u22121\u22c5s\u22122 based on two different methods. These are claimed as the most accurate measurements ever made, with a standard uncertainties cited as low as 12 ppm. The difference of 2.7\u03c3 between the two results suggests there could be sources of error unaccounted for.\n\n\n== Suggested time-variation ==\n\nA controversial 2015 study of some previous measurements of G, by Anderson et al., suggested that most of the mutually exclusive values in high-precision measurements of G can be explained by a periodic variation. The variation was measured as having a period of 5.9 years, similar to that observed in length-of-day (LOD) measurements, hinting at a common physical cause that is not necessarily a variation in G. A response was produced by some of the original authors of the G measurements used in Anderson et al. This response notes that Anderson et al. not only omitted measurements, but that they also used the time of publication rather than the time the experiments were performed. A plot with estimated time of measurement from contacting original authors seriously degrades the length of day correlation. Also, consideration of the data collected over a decade by Karagioz and Izmailov shows no correlation with length of day measurements. As such, the variations in G most likely arise from systematic measurement errors which have not properly been accounted for. Under the assumption that the physics of type Ia supernovae are universal, analysis of observations of 580 of them has shown that the gravitational constant has varied by less than one part in ten billion per year over the last nine billion years according to Mould et al. (2014).\n\n\n== See also ==\n\n\n== References ==\nFootnotes\n\nCitations\n\n\n=== Sources ===\n\n\n== External links ==\nNewtonian constant of gravitation G at the National Institute of Standards and Technology References on Constants, Units, and Uncertainty\nThe Controversy over Newton's Gravitational Constant \u2014 additional commentary on measurement problems", "Ray_(optics)": "In optics, a ray is an idealized geometrical model of light or other electromagnetic radiation, obtained by choosing a curve that is perpendicular to the wavefronts of the actual light, and that points in the direction of energy flow.  Rays are used to model the propagation of light through an optical system, by dividing the real light field up into discrete rays that can be computationally propagated through the system by the techniques of ray tracing. This allows even very complex optical systems to be analyzed mathematically or simulated by computer.  Ray tracing uses approximate solutions to Maxwell's equations that are valid as long as the light waves propagate through and around objects whose dimensions are much greater than the light's wavelength.  Ray optics or geometrical optics does not describe phenomena such as diffraction, which require wave optics theory. Some wave phenomena such as interference can be modeled in limited circumstances by adding phase to the ray model.\n\n\n== Definition ==\nA light ray is a line (straight or curved) that is perpendicular to the light's wavefronts; its tangent is collinear with the wave vector. Light rays in homogeneous media are straight. They bend at the interface between two dissimilar media and may be curved in a medium in which the refractive index changes. Geometric optics describes how rays propagate through an optical system. Objects to be imaged are treated as collections of independent point sources, each producing spherical wavefronts and corresponding outward rays. Rays from each object point can be mathematically propagated to locate the corresponding point on the image.\nA slightly more rigorous definition of a light ray follows from Fermat's principle, which states that the path taken between two points by a ray of light is the path that can be traversed in the least time.\n\n\n== Special rays ==\nThere are many special rays that are used in optical modelling to analyze an optical system. These are defined and described below, grouped by the type of system they are used to model.\n\n\n=== Interaction with surfaces ===\n\nAn incident ray is a ray of light that strikes a surface. The angle between this ray and the perpendicular or normal to the surface is the angle of incidence.\nThe reflected ray corresponding to a given incident ray, is the ray that represents the light reflected by the surface. The angle between the surface normal and the reflected ray is known as the angle of reflection. The Law of Reflection says that for a specular (non-scattering) surface, the angle of reflection is always equal to the angle of incidence.\nThe refracted ray or transmitted ray corresponding to a given incident ray represents the light that is transmitted through the surface. The angle between this ray and the normal is known as the angle of refraction, and it is given by Snell's Law. Conservation of energy requires that the power in the incident ray must equal the sum of the power in the refracted ray, the power in the reflected ray, and any power absorbed at the surface.\nIf the material is birefringent, the refracted ray may split into ordinary and extraordinary rays, which experience different indexes of refraction when passing through the birefringent material.\n\n\n=== Optical systems ===\n\nA meridional ray or tangential ray is a ray that is confined to the plane containing the system's optical axis and the object point from which the ray originated.\nA skew ray is a ray that does not propagate in a plane that contains both the object point and the optical axis. Such rays do not cross the optical axis anywhere, and are not parallel to it.\nThe marginal ray (sometimes known as an a ray or a marginal axial ray) in an optical system is the meridional ray that starts at the point where the object crosses the optical axis, and touches the edge of the aperture stop of the system. This ray is useful, because it crosses the optical axis again at the locations where an image will be formed. The distance of the marginal ray from the optical axis at the locations of the entrance pupil and exit pupil defines the sizes of each pupil (since the pupils are images of the aperture stop).\nThe principal ray or chief ray (sometimes known as the b ray) in an optical system is the meridional ray that starts at the edge of the object, and passes through the center of the aperture stop. This ray crosses the optical axis at the locations of the pupils. As such chief rays are equivalent to the rays in a pinhole camera. The distance between the chief ray and the optical axis at an image location defines the size of the image. The marginal and chief rays together define the Lagrange invariant, which characterizes the throughput or etendue of the optical system. Some authors define a \"principal ray\" for each object point. The principal ray starting at a point on the edge of the object may then be called the marginal principal ray.\nA sagittal ray or transverse ray from an off-axis object point is a ray that propagates in the plane that is perpendicular to the meridional plane and contains the principal ray. Sagittal rays intersect the pupil along a line that is perpendicular to the meridional plane for the ray's object point and passes through the optical axis. If the axis direction is defined to be the z axis, and the meridional plane is the y-z plane, sagittal rays intersect the pupil at yp=0. The principal ray is both sagittal and meridional. All other sagittal rays are skew rays.\nA paraxial ray is a ray that makes a small angle to the optical axis of the system, and lies close to the axis throughout the system. Such rays can be modeled reasonably well by using the paraxial approximation. When discussing ray tracing this definition is often reversed: a \"paraxial ray\" is then a ray that is modeled using the paraxial approximation, not necessarily a ray that remains close to the axis.\nA finite ray or real ray is a ray that is traced without making the paraxial approximation.\nA parabasal ray is a ray that propagates close to some defined \"base ray\" rather than the optical axis. This is more appropriate than the paraxial model in systems that lack symmetry about the optical axis. In computer modeling, parabasal rays are \"real rays\", that is rays that are treated without making the paraxial approximation. Parabasal rays about the optical axis are sometimes used to calculate first-order properties of optical systems.\n\n\n=== Fiber optics ===\nA meridional ray is a ray that passes through the axis of an optical fiber.\nA skew ray is a ray that travels in a non-planar zig-zag path and never crosses the axis of an optical fiber.\nA guided ray, bound ray, or trapped ray is a ray in a multi-mode optical fiber, which is confined by the core. For step index fiber, light entering the fiber will be guided if it makes an angle with the fiber axis that is less than the fiber's acceptance angle.\nA leaky ray or tunneling ray is a ray in an optical fiber that geometric optics predicts would totally reflect at the boundary between the core and the cladding, but which suffers loss due to the curved core boundary.\n\n\n== Geometrical optics ==\n\n\n== Ray tracing ==\n\n\n== See also ==\nCollimated beam\nOptical path\nOptical path length\nParaxial approximation\nPencil beam\nRay transfer matrix analysis\n\n\n== References ==", "Sound": "In physics, sound is a vibration that propagates as an acoustic wave, through a transmission medium such as a gas, liquid or solid.\nIn human physiology and psychology, sound is the reception of such waves and their perception by the brain. Only acoustic waves that have frequencies lying between about 20 Hz and 20 kHz, the audio frequency range, elicit an auditory percept in humans. In air at atmospheric pressure, these represent sound waves with wavelengths of 17 meters (56 ft) to 1.7 centimeters (0.67 in). Sound waves above 20 kHz are known as ultrasound and are not audible to humans. Sound waves below 20 Hz are known as infrasound. Different animal species have varying hearing ranges.\n\n\n== Acoustics ==\n\nAcoustics is the interdisciplinary science that deals with the study of mechanical waves in gasses, liquids, and solids including vibration, sound, ultrasound, and infrasound. A scientist who works in the field of acoustics is an acoustician, while someone working in the field of acoustical engineering may be called an acoustical engineer. An audio engineer, on the other hand, is concerned with the recording, manipulation, mixing, and reproduction of sound.\nApplications of acoustics are found in almost all aspects of modern society, subdisciplines include aeroacoustics, audio signal processing, architectural acoustics, bioacoustics, electro-acoustics, environmental noise, musical acoustics, noise control, psychoacoustics, speech, ultrasound,  underwater acoustics, and vibration.\n\n\n== Definition ==\nSound is defined as \"(a) Oscillation  in pressure, stress, particle displacement, particle velocity, etc., propagated in a medium with internal forces (e.g., elastic or viscous), or the superposition of such propagated oscillation. (b) Auditory sensation evoked by the oscillation described in (a).\" Sound can be viewed as a wave motion in  air or other elastic media. In this case, sound is a stimulus. Sound can also be viewed as an excitation of the hearing mechanism that results in the perception of sound. In this case, sound is a sensation.\n\n\n== Physics ==\n\nSound can propagate through a medium such as air, water and solids as longitudinal waves and also as a transverse wave in solids. The sound waves are generated by a sound source, such as the vibrating diaphragm of a stereo speaker. The sound source creates vibrations in the surrounding medium. As the source continues to vibrate the medium, the vibrations propagate away from the source at the speed of sound, thus forming the sound wave. At a fixed distance from the source, the pressure, velocity, and displacement of the medium vary in time. At an instant in time, the pressure, velocity, and displacement vary in space. Note that the particles of the medium do not travel with the sound wave. This is intuitively obvious for a solid, and the same is true for liquids and gases (that is, the vibrations of particles in the gas or liquid transport the vibrations, while the average position of the particles over time does not change).  During propagation, waves can be reflected, refracted, or attenuated by the medium.The behavior of sound propagation is generally affected by three things:\n\nA complex relationship between the density and pressure of the medium. This relationship, affected by temperature, determines the speed of sound within the medium.\nMotion of the medium itself. If the medium is moving, this movement may increase or decrease the absolute speed of the sound wave depending on the direction of the movement. For example, sound moving through wind will have its speed of propagation increased by the speed of the wind if the sound and wind are moving in the same direction. If the sound and wind are moving in opposite directions, the speed of the sound wave will be decreased by the speed of the wind.\nThe viscosity of the medium. Medium viscosity determines the rate at which sound is attenuated. For many media, such as air or water, attenuation due to viscosity is negligible.When sound is moving through a medium that does not have constant physical properties, it may be refracted (either dispersed or focused).\n\nThe mechanical vibrations that can be interpreted as sound can travel through all forms of matter: gases, liquids, solids, and plasmas. The matter that supports the sound is called the medium. Sound cannot travel through a vacuum.\n\n\n=== Waves ===\nSound is transmitted through gases, plasma, and liquids as longitudinal waves, also called compression waves. It requires a medium to propagate. Through solids, however, it can be transmitted as both longitudinal waves and transverse waves. Longitudinal sound waves are waves of alternating pressure deviations from the equilibrium pressure, causing local regions of compression and rarefaction, while transverse waves (in solids) are waves of alternating shear stress at right angle to the direction of propagation.\nSound waves may be viewed using parabolic mirrors and objects that produce sound.The energy carried by an oscillating sound wave converts back and forth between the potential energy of the extra compression (in case of longitudinal waves) or lateral displacement strain (in case of transverse waves) of the matter, and the kinetic energy of the displacement velocity of particles of the medium.\n\nAlthough there are many complexities relating to the transmission of sounds, at the point of reception (i.e. the ears), sound is readily dividable into two simple elements: pressure and time. These fundamental elements form the basis of all sound waves. They can be used to describe, in absolute terms, every sound we hear.\nIn order to understand the sound more fully, a complex wave such as the one shown in a blue background on the right of this text, is usually separated into its component parts, which are a combination of various sound wave frequencies (and noise).Sound waves are often simplified to a description in terms of sinusoidal plane waves, which are characterized by these generic properties:\n\nFrequency, or its inverse, wavelength\nAmplitude, sound pressure or Intensity\nSpeed of sound\nDirectionSound that is perceptible by humans has frequencies from about 20 Hz to 20,000 Hz. In air at standard temperature and pressure, the corresponding wavelengths of sound waves range from 17 m (56 ft) to 17 mm (0.67 in).  Sometimes speed and direction are combined as a velocity vector; wave number and direction are combined as a wave vector.\nTransverse waves, also known as shear waves, have the additional property, polarization, and are not a characteristic of sound waves.\n\n\n=== Speed ===\n\nThe speed of sound depends on the medium the waves pass through, and is a fundamental property of the material. The first significant effort towards measurement of the speed of sound was made by Isaac Newton. He believed the speed of sound in a particular substance was equal to the square root of the pressure acting on it divided by its density:\n\n  \n    \n      \n        c\n        =\n        \n          \n            \n              p\n              \u03c1\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle c={\\sqrt {\\frac {p}{\\rho }}}.}\n  This was later proven wrong and the French mathematician Laplace corrected the formula by deducing that the phenomenon of sound travelling is not isothermal, as believed by Newton, but adiabatic.  He added another factor to the equation\u2014gamma\u2014and multiplied\n\n  \n    \n      \n        \n          \n            \u03b3\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {\\gamma }}}\n  \nby\n\n  \n    \n      \n        \n          \n            p\n            \n              /\n            \n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {p/\\rho }}}\n  ,\nthus coming up with the equation\n\n  \n    \n      \n        c\n        =\n        \n          \n            \u03b3\n            \u22c5\n            p\n            \n              /\n            \n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle c={\\sqrt {\\gamma \\cdot p/\\rho }}}\n  .\nSince\n\n  \n    \n      \n        K\n        =\n        \u03b3\n        \u22c5\n        p\n      \n    \n    {\\displaystyle K=\\gamma \\cdot p}\n  ,\nthe final equation came up to be\n\n  \n    \n      \n        c\n        =\n        \n          \n            K\n            \n              /\n            \n            \u03c1\n          \n        \n      \n    \n    {\\displaystyle c={\\sqrt {K/\\rho }}}\n  ,\nwhich is also known as the Newton\u2013Laplace equation. In this equation, K is the elastic bulk modulus, c is the velocity of sound, and \n  \n    \n      \n        \u03c1\n      \n    \n    {\\displaystyle \\rho }\n   is the density.  Thus, the speed of sound is proportional to the square root of the ratio of the bulk modulus of the medium to its density.\nThose physical properties and the speed of sound change with ambient conditions.  For example, the speed of sound in gases depends on temperature.  In 20 \u00b0C (68 \u00b0F) air at sea level, the speed of sound is approximately 343 m/s (1,230 km/h; 767 mph) using the formula v\u202f[m/s] = 331 + 0.6\u202fT\u202f[\u00b0C].  The speed of sound is also slightly sensitive, being subject to a second-order anharmonic effect, to the sound amplitude, which means there are non-linear propagation effects, such as the production of harmonics and mixed tones not present in the original sound (see parametric array). If relativistic effects are important, the speed of sound is calculated from the relativistic Euler equations.\nIn fresh water the speed of sound is approximately 1,482 m/s (5,335 km/h; 3,315 mph). In steel, the speed of sound is about 5,960 m/s (21,460 km/h; 13,330 mph). Sound moves the fastest in solid atomic hydrogen at about 36,000 m/s (129,600 km/h; 80,530 mph).\n\n\n=== Sound pressure level ===\nSound pressure is the difference, in a given medium, between average local pressure and the pressure in the sound wave. A square of this difference (i.e., a square of the deviation from the equilibrium pressure) is usually averaged over time and/or space, and a square root of this average provides a root mean square (RMS) value. For example, 1 Pa RMS sound pressure (94 dBSPL) in atmospheric air implies that the actual pressure in the sound wave oscillates between (1 atm \n  \n    \n      \n        \u2212\n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle -{\\sqrt {2}}}\n   Pa) and (1 atm \n  \n    \n      \n        +\n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle +{\\sqrt {2}}}\n   Pa), that is between 101323.6 and 101326.4 Pa.\nAs the human ear can detect sounds with a wide range of amplitudes, sound pressure is often measured as a level on a logarithmic decibel scale. The sound pressure level (SPL) or Lp is defined as\n\n  \n    \n      \n        \n          L\n          \n            \n              p\n            \n          \n        \n        =\n        10\n        \n        \n          log\n          \n            10\n          \n        \n        \u2061\n        \n          (\n          \n            \n              \n                \n                  p\n                \n                \n                  2\n                \n              \n              \n                \n                  \n                    p\n                    \n                      \n                        r\n                        e\n                        f\n                      \n                    \n                  \n                \n                \n                  2\n                \n              \n            \n          \n          )\n        \n        =\n        20\n        \n        \n          log\n          \n            10\n          \n        \n        \u2061\n        \n          (\n          \n            \n              p\n              \n                p\n                \n                  \n                    r\n                    e\n                    f\n                  \n                \n              \n            \n          \n          )\n        \n        \n          \n             dB\n          \n        \n        \n      \n    \n    {\\displaystyle L_{\\mathrm {p} }=10\\,\\log _{10}\\left({\\frac {{p}^{2}}{{p_{\\mathrm {ref} }}^{2}}}\\right)=20\\,\\log _{10}\\left({\\frac {p}{p_{\\mathrm {ref} }}}\\right){\\mbox{ dB}}\\,}\n  where p is the root-mean-square sound pressure and \n  \n    \n      \n        \n          p\n          \n            \n              r\n              e\n              f\n            \n          \n        \n      \n    \n    {\\displaystyle p_{\\mathrm {ref} }}\n   is a reference sound pressure. Commonly used reference sound pressures, defined in the standard ANSI S1.1-1994, are 20 \u00b5Pa in air and 1 \u00b5Pa in water. Without a specified reference sound pressure, a value expressed in decibels cannot represent a sound pressure level.Since the human ear does not have a flat spectral response, sound pressures are often frequency weighted so that the measured level matches perceived levels more closely. The International Electrotechnical Commission (IEC) has defined several weighting schemes. A-weighting attempts to match the response of the human ear to noise and A-weighted sound pressure levels are labeled dBA. C-weighting is used to measure peak levels.\n\n\n== Perception ==\n\nA distinct use of the term sound from its use in physics is that in physiology and psychology, where the term refers to the subject of perception by the brain. The field of psychoacoustics is dedicated to such studies. Webster's 1936 dictionary defined sound as: \"1. The sensation of hearing, that which is heard; specif.: a. Psychophysics. Sensation due to stimulation of the auditory nerves and auditory centers of the brain, usually by vibrations transmitted in a material medium, commonly air, affecting the organ of hearing. b. Physics. Vibrational energy which occasions such a sensation. Sound is propagated by progressive longitudinal vibratory disturbances (sound waves).\" This means that the correct response to the question: \"if a tree falls in the forest with no one to hear it fall, does it make a sound?\" is \"yes\", and \"no\", dependent on whether being answered using the physical, or the psychophysical definition, respectively.\nThe physical reception of sound in any hearing organism is limited to a range of frequencies. Humans normally hear sound frequencies between approximately 20 Hz and 20,000 Hz (20 kHz),:\u200a382\u200a The upper limit decreases with age.:\u200a249\u200a Sometimes sound refers to only those vibrations with frequencies that are within the hearing range for humans or sometimes it relates to a particular animal. Other species have different ranges of hearing. For example, dogs can perceive vibrations higher than 20 kHz.\nAs a signal perceived by one of the major senses, sound is used by many species for detecting danger, navigation, predation, and communication. Earth's atmosphere, water, and virtually any physical phenomenon, such as fire, rain, wind, surf, or earthquake, produces (and is characterized by) its unique sounds. Many species, such as frogs, birds, marine and terrestrial mammals, have also developed special organs to produce sound. In some species, these produce song and speech. Furthermore, humans have developed culture and technology (such as music, telephone and radio) that allows them to generate, record, transmit, and broadcast sound.\nNoise is a term often used to refer to an unwanted sound. In science and engineering, noise is an undesirable component that obscures a wanted signal. However, in sound perception it can often be used to identify the source of a sound and is an important component of timbre perception (see above).\nSoundscape is the component of the acoustic environment that can be perceived by humans. The acoustic environment is the combination of all sounds (whether audible to humans or not) within a given area as modified by the environment and understood by people, in context of the surrounding environment.\nThere are, historically, six experimentally separable ways in which sound waves are analysed. They are:  pitch, duration, loudness, timbre, sonic texture and  spatial location. Some of these terms have a standardised definition (for instance in the ANSI Acoustical Terminology ANSI/ASA S1.1-2013). More recent approaches have also considered temporal envelope and temporal fine structure as perceptually relevant analyses.\n\n\n=== Pitch ===\n\nPitch is perceived as how \"low\" or \"high\" a sound is and represents the cyclic, repetitive nature of the vibrations that make up sound. For simple sounds, pitch relates to the frequency of the slowest vibration in the sound (called the fundamental harmonic). In the case of complex sounds, pitch perception can vary. Sometimes individuals identify different pitches for the same sound, based on their personal experience of particular sound patterns. Selection of a particular pitch is determined by pre-conscious examination of vibrations, including their frequencies and the balance between them. Specific attention is given to recognising potential harmonics.  Every sound is placed on a pitch continuum from low to high. For example: white noise (random noise spread evenly across all frequencies) sounds higher in pitch than pink noise (random noise spread evenly across octaves) as white noise has more high frequency content.  Figure 1 shows an example of pitch recognition. During the listening process, each sound is analysed for a repeating pattern (See Figure 1: orange arrows) and the results forwarded to the auditory cortex as a single pitch of a certain height (octave) and chroma (note name).\n\n\n=== Duration ===\n\nDuration is perceived as how \"long\" or \"short\" a sound is and relates to onset and offset signals created by nerve responses to sounds. The duration of a sound usually lasts from the time the sound is first noticed until the sound is identified as having changed or ceased. Sometimes this is not directly related to the physical duration of a sound. For example; in a noisy environment, gapped sounds (sounds that stop and start) can sound as if they are continuous because the offset messages are missed owing to disruptions from noises in the same general bandwidth. This can be of great benefit in understanding distorted messages such as radio signals that suffer from interference, as (owing to this effect) the message is heard as if it was continuous. Figure 2 gives an example of duration identification. When a new sound is noticed (see Figure 2, Green arrows), a sound onset message is sent to the auditory cortex. When the repeating pattern is missed, a sound offset messages is sent.\n\n\n=== Loudness ===\n\nLoudness is perceived as how \"loud\" or \"soft\" a sound is and relates to the totalled number of auditory nerve stimulations over short cyclic time periods, most likely over the duration of theta wave cycles. This means that at short durations, a very short sound can sound softer than a longer sound even though they are presented at the same intensity level. Past around 200 ms this is no longer the case and the duration of the sound no longer affects the apparent loudness of the sound. Figure 3 gives an impression of how loudness information is summed over a period of about 200 ms before being sent to the auditory cortex. Louder signals create a greater 'push' on the Basilar membrane and thus stimulate more nerves, creating a stronger loudness signal. A more complex signal also creates more nerve firings and so sounds louder (for the same wave amplitude) than a simpler sound, such as a sine wave.\n\n\n=== Timbre ===\n\nTimbre is perceived as the quality of different sounds (e.g. the thud of a fallen rock, the whir of a drill, the tone of a musical instrument or the quality of a voice) and represents the pre-conscious allocation of a sonic identity to a sound (e.g. \u201cit's an oboe!\"). This identity is based on information gained from frequency transients, noisiness, unsteadiness, perceived pitch and the spread and intensity of overtones in the sound over an extended time frame. The way a sound changes over time (see figure 4) provides most of the information for timbre identification. Even though a small section of the wave form from each instrument looks very similar (see the expanded sections indicated by the orange arrows in figure 4), differences in changes over time between the clarinet and the piano are evident in both loudness and harmonic content. Less noticeable are the different noises heard, such as air hisses for the clarinet and hammer strikes for the piano.\n\n\n=== Texture ===\nSonic texture relates to the number of sound sources and the interaction between them. The word texture, in this context, relates to the cognitive separation of auditory objects. In music, texture is often referred to as the difference between unison, polyphony and homophony, but it can also relate (for example) to a busy cafe; a sound which might be referred to as cacophony.\n\n\n=== Spatial location ===\n\nSpatial location represents the cognitive placement of a sound in an environmental context; including the placement of a sound on both the horizontal and vertical plane, the distance from the sound source and the characteristics of the sonic environment. In a thick texture, it is possible to identify multiple sound sources using a combination of spatial location and timbre identification.\n\n\n== Frequency ==\n\n\n=== Ultrasound ===\n\nUltrasound is sound waves with frequencies higher than 20,000 Hz. Ultrasound is not different from audible sound in its physical properties it just cannot be heard by humans. Ultrasound devices operate with frequencies from 20 kHz up to several gigahertz.\nMedical ultrasound is commonly used for diagnostics and treatment.\n\n\n=== Infrasound ===\n\nInfrasound is sound waves with frequencies lower than 20 Hz. Although sounds of such low frequency are too low for humans to hear, whales, elephants and other animals can detect infrasound and use it to communicate. It can be used to detect volcanic eruptions and is used in some types of music.\n\n\n== See also ==\n\n\n== References ==\n\n\n== External links ==\n\nEric Mack (20 May 2019). \"Stanford scientists created a sound so loud it instantly boils water\". CNET.\nSounds Amazing; a KS3/4 learning resource for sound and waves (uses Flash)\nHyperPhysics: Sound and Hearing\nIntroduction to the Physics of Sound\nHearing curves and on-line hearing test\nAudio for the 21st Century Archived 2009-01-23 at the Wayback Machine\nConversion of sound units and levels\nSound calculations\nAudio Check: a free collection of audio tests and test tones playable on-line\nMore Sounds Amazing; a sixth-form learning resource about sound waves", "Curved_mirror": "A curved mirror is a mirror with a curved reflecting surface. The surface may be either convex (bulging outward) or concave (recessed inward). Most curved mirrors have surfaces that are shaped like part of a sphere, but other shapes are sometimes used in optical devices. The most common non-spherical type are parabolic reflectors, found in optical devices such as reflecting telescopes that need to image distant objects, since spherical mirror systems, like spherical lenses, suffer from spherical aberration. Distorting mirrors are used for entertainment. They have convex and concave regions that produce deliberately distorted images. They also provide highly magnified or highly diminished (smaller) images when the object is placed at certain distances.\n\n\n== Convex mirrors ==\n\nA convex mirror or diverging mirror is a curved mirror in which the reflective surface bulges towards the light source. Convex mirrors reflect light outwards, therefore they are not used to focus light. Such mirrors always form a virtual image, since the focal point (F) and the centre of curvature (2F) are both imaginary points \"inside\" the mirror, that cannot be reached. As a result, images formed by these mirrors cannot be projected on a screen, since the image is inside the mirror. The image is smaller than the object, but gets larger as the object approaches the mirror.\nA collimated (parallel) beam of light diverges (spreads out) after reflection from a convex mirror, since the normal to the surface differs at each spot on the mirror.\n\n\n=== Uses of convex mirrors ===\n\nThe passenger-side mirror on a car is typically a convex mirror. In some countries, these are labeled with the safety warning \"Objects in mirror are closer than they appear\", to warn the driver of the convex mirror's distorting effects on distance perception. Convex mirrors are preferred in vehicles because they give an upright (not inverted), though diminished (smaller), image and because they provide a wider field of view as they are curved outwards. \nThese mirrors are often found in the hallways of various buildings (commonly known as \"hallway safety mirrors\"), including hospitals, hotels, schools, stores, and apartment buildings. They are usually mounted on a wall or ceiling where hallways intersect each other, or where they make sharp turns. They are useful for people to look at any obstruction they will face on the next hallway or after the next turn. They are also used on roads, driveways, and alleys to provide safety for road users where there is a lack of visibility, especially at curves and turns.Convex mirrors are used in some automated teller machines as a simple and handy security feature, allowing the users to see what is happening behind them. Similar devices are sold to be attached to ordinary computer monitors.\nConvex mirrors make everything seem smaller but cover a larger area of surveillance. \nRound convex mirrors called Oeil de Sorci\u00e8re (French for \"sorcerer's eye\") were a popular luxury item from the 15th century onwards, shown in many depictions of interiors from that time. With 15th century technology, it was easier to make a regular curved mirror (from blown glass) than a perfectly flat one. They were also known as \"bankers' eyes\" due to the fact that their wide field of vision was useful for security. Famous examples in art include the Arnolfini Portrait by Jan van Eyck and the left wing of the Werl Altarpiece by Robert Campin.\n\n\n=== Convex mirror image ===\n\nThe image on a convex mirror is always virtual (rays haven't actually passed through the image; their extensions do, like in a regular mirror), diminished (smaller), and upright (not inverted). As the object gets closer to the mirror, the image gets larger, until \napproximately the size of the object, when it touches the mirror. As the object moves away, the image diminishes in size and gets gradually closer to the focus, until it is reduced to a point in the focus when the object is at an infinite distance. These features make convex mirrors very useful: since everything appears smaller in the mirror, they cover a wider field of view than a normal plane mirror, so useful for looking at cars behind a driver's car on a road, watching a wider area for surveillance, etc.\n\n\n== Concave mirrors ==\n\nA concave mirror, or converging mirror, has a reflecting surface that is recessed inward (away from the incident light). Concave mirrors reflect light inward to one focal point. They are used to focus light. Unlike convex mirrors, concave mirrors show different image types depending on the distance between the object and the mirror.\nThe mirrors are called \"converging mirrors\" because they tend to collect light that falls on them, refocusing parallel incoming rays toward a focus. This is because the light is reflected at different angles at different spots on the mirror as the normal to the mirror surface differs at each spot.\n\n\n=== Uses of concave mirrors ===\nConcave mirrors are used in reflecting telescopes. They are also used to provide a magnified image of the face for applying make-up or shaving. In illumination applications, concave mirrors are used to gather light from a small source and direct it outward in a beam as in torches, headlamps and spotlights, or to collect light from a large area and focus it into a small spot, as in concentrated solar power. Concave mirrors are used to form optical cavities, which are important in laser construction. Some dental mirrors use a concave surface to provide a magnified image. The mirror landing aid system of modern aircraft carriers also uses a concave mirror.\n\n\n=== Concave mirror image ===\n\n\n== Mirror shape ==\nMost curved mirrors have a spherical profile. These are the simplest to make, and it is the best shape for general-purpose use. Spherical mirrors, however, suffer from spherical aberration\u2014parallel rays reflected from such mirrors do not focus to a single point. For parallel rays, such as those coming from a very distant object, a parabolic reflector can do a better job. Such a mirror can focus incoming parallel rays to a much smaller spot than a spherical mirror can. A toroidal reflector is a form of parabolic reflector which has a different focal distance depending on the angle of the mirror.\n\n\n== Analysis ==\n\n\n=== Mirror equation, magnification, and focal length ===\nThe Gaussian mirror equation, also known as the mirror and lens equation, relates the object distance \n  \n    \n      \n        \n          d\n          \n            \n              o\n            \n          \n        \n      \n    \n    {\\displaystyle d_{\\mathrm {o} }}\n   and image distance \n  \n    \n      \n        \n          d\n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle d_{\\mathrm {i} }}\n   to the focal length \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  :\n\n  \n    \n      \n        \n          \n            1\n            \n              d\n              \n                \n                  o\n                \n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              d\n              \n                \n                  i\n                \n              \n            \n          \n        \n        =\n        \n          \n            1\n            f\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{d_{\\mathrm {o} }}}+{\\frac {1}{d_{\\mathrm {i} }}}={\\frac {1}{f}}}\n  .The sign convention used here is that the focal length is positive for concave mirrors and negative for convex ones, and \n  \n    \n      \n        \n          d\n          \n            \n              o\n            \n          \n        \n      \n    \n    {\\displaystyle d_{\\mathrm {o} }}\n   and \n  \n    \n      \n        \n          d\n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle d_{\\mathrm {i} }}\n   are positive when the object and image are in front of the mirror, respectively. (They are positive when the object or image is real.)For convex mirrors, if one moves the \n  \n    \n      \n        1\n        \n          /\n        \n        \n          d\n          \n            \n              o\n            \n          \n        \n      \n    \n    {\\displaystyle 1/d_{\\mathrm {o} }}\n   term to the right side of the equation to solve for \n  \n    \n      \n        1\n        \n          /\n        \n        \n          d\n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle 1/d_{\\mathrm {i} }}\n  , then the result is always a negative number, meaning that the image distance is negative\u2014the image is virtual, located \"behind\" the mirror. This is consistent with the behavior described above.\nFor concave mirrors, whether the image is virtual or real depends on how large the object distance is compared to the focal length. If the \n  \n    \n      \n        1\n        \n          /\n        \n        f\n      \n    \n    {\\displaystyle 1/f}\n   term is larger than the \n  \n    \n      \n        1\n        \n          /\n        \n        \n          d\n          \n            \n              o\n            \n          \n        \n      \n    \n    {\\displaystyle 1/d_{\\mathrm {o} }}\n   term, then \n  \n    \n      \n        1\n        \n          /\n        \n        \n          d\n          \n            \n              i\n            \n          \n        \n      \n    \n    {\\displaystyle 1/d_{\\mathrm {i} }}\n   is positive and the image is real. Otherwise, the term is negative and the image is virtual. Again, this validates the behavior described above.\nThe magnification of a mirror is defined as the height of the image divided by the height of the object:\n\n  \n    \n      \n        m\n        \u2261\n        \n          \n            \n              h\n              \n                \n                  i\n                \n              \n            \n            \n              h\n              \n                \n                  o\n                \n              \n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              d\n              \n                \n                  i\n                \n              \n            \n            \n              d\n              \n                \n                  o\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle m\\equiv {\\frac {h_{\\mathrm {i} }}{h_{\\mathrm {o} }}}=-{\\frac {d_{\\mathrm {i} }}{d_{\\mathrm {o} }}}}\n  .By convention, if the resulting magnification is positive, the image is upright. If the magnification is negative, the image is inverted (upside down).\n\n\n=== Ray tracing ===\n\nThe image location and size can also be found by graphical ray tracing, as illustrated in the figures above.  A ray drawn from the top of the object to the mirror surface vertex (where the optical axis meets the mirror) will form an angle with the optical axis. The reflected ray has the same angle to the axis, but on the opposite side (See Specular reflection).\nA second ray can be drawn from the top of the object, parallel to the optical axis. This ray is reflected by the mirror and passes through its focal point. The point at which these two rays meet is the image point corresponding to the top of the object. Its distance from the optical axis defines the height of the image, and its location along the axis is the image location. The mirror equation and magnification equation can be derived geometrically by considering these two rays. A ray that goes from the top of the object through the focal point can be considered instead. Such a ray reflects parallel to the optical axis and also passes through the image point corresponding to the top of the object.\n\n\n=== Ray transfer matrix of spherical mirrors ===\n\nThe mathematical treatment is done under the paraxial approximation, meaning that under the first approximation a spherical mirror is a parabolic reflector.\nThe ray matrix of a concave spherical mirror is shown here. The \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n   element of the matrix is \n  \n    \n      \n        \u2212\n        \n          \n            1\n            f\n          \n        \n      \n    \n    {\\displaystyle -{\\frac {1}{f}}}\n  , where \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n   is the focal point of the optical device.\n\nBoxes 1 and 3 feature summing the angles of a triangle and comparing to \u03c0 radians (or 180\u00b0). Box 2 shows the Maclaurin series of \n  \n    \n      \n        arccos\n        \u2061\n        \n          (\n          \n            \u2212\n            \n              \n                r\n                R\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\arccos \\left(-{\\frac {r}{R}}\\right)}\n   up to order 1. The derivations of the ray matrices of a convex spherical mirror and a thin lens are very similar.\n\n\n== See also ==\nAlhazen's problem (reflection from a spherical mirror)\nAnamorphosis\nConcentrated solar power - a method of solar power generation using curved mirrors or arrays of mirrors\nList of telescope parts and construction\n\n\n== References ==\n\n\n== External links ==\nJava applets to explore ray tracing for curved mirrors\nConcave mirrors \u2014 real images, Molecular Expressions Optical Microscopy Primer\nSpherical mirrors, online physics lab\n\"Grinding the World's Largest Mirror\" Popular Science, December 1935", "Voltmeter": "A voltmeter is an instrument used for measuring electric potential difference between two points in an electric circuit. It is  connected in parallel. It usually has a high resistance so that it takes negligible current from the circuit.\nAnalog voltmeters move a pointer across a scale in proportion to the voltage measured and can be built from a galvanometer and series resistor. Meters using amplifiers can measure tiny voltages of microvolts or less. Digital voltmeters give a numerical display of voltage by use of an analog-to-digital converter.\nVoltmeters are made in a wide range of styles, some separately powered (e.g. by battery), and others powered by the measured voltage source itself. Instruments permanently mounted in a panel are used to monitor generators or other fixed apparatus. Portable instruments, usually equipped to also measure current and resistance in the form of a multimeter, are standard test instruments used in electrical and electronics work. Any measurement that can be converted to a voltage can be displayed on a meter that is suitably calibrated; for example, pressure, temperature, flow or level in a chemical process plant.\nGeneral-purpose analog voltmeters may have an accuracy of a few percent of full scale and are used with voltages from a fraction of a volt to several thousand volts. Digital meters can be made with high accuracy, typically better than 1%. Specially calibrated test instruments have higher accuracies, with laboratory instruments capable of measuring to accuracies of a few parts per million. Part of the problem of making an accurate voltmeter is that of calibration to check its accuracy. In laboratories, the Weston cell is used as a standard voltage for precision work. Precision voltage references are available based on electronic circuits.\n\n\n== Schematic symbol ==\n\nIn circuit diagrams, a voltmeter is represented by the letter V in a circle, with two emerging lines representing the two points of measurement.\n\n\n== Analog voltmeter ==\n\nA moving coil galvanometer can be used as a voltmeter by inserting a resistor in series with the instrument. The galvanometer has a coil of fine wire suspended in a strong magnetic field. When an electric current is applied, the interaction of the magnetic field of the coil and of the stationary magnet creates a torque, tending to make the coil rotate. The torque is proportional to the current through the coil. The coil rotates, compressing a spring that opposes the rotation. The deflection of the coil is thus proportional to the current, which in turn is proportional to the applied voltage, which is indicated by a pointer on a scale. \nOne of the design objectives of the instrument is to disturb the circuit as little as possible and so the instrument should draw a minimum of current to operate. This is achieved by using a sensitive galvanometer in series with a high resistance, and then the entire instrument is connected in parallel with the circuit examined.\nThe sensitivity of such a meter can be expressed as \"ohms per volt\", the number of ohms resistance in the meter circuit divided by the full scale measured value. For example, a meter with a sensitivity of 1000 ohms per volt would draw 1 milliampere at full scale voltage; if the full scale was 200 volts, the resistance at the instrument's terminals would be 200000 ohms and at full scale, the meter would draw 1 milliampere from the circuit under test. For multi-range instruments, the input resistance varies as the instrument is switched to different ranges.\nMoving-coil instruments with a permanent-magnet field respond only to direct current. Measurement of AC voltage requires a rectifier in the circuit so that the coil deflects in only one direction. Some moving-coil instruments are also made with the zero position in the middle of the scale instead of at one end; these are useful if the voltage reverses its polarity.\nVoltmeters operating on the electrostatic principle use the mutual repulsion between two charged plates to deflect a pointer attached to a spring. Meters of this type draw negligible current but are sensitive to voltages over about 100 volts and work with either alternating or direct current.\n\n\n== Amplified voltmeter ==\nThe sensitivity and input resistance of a voltmeter can be increased if the current required to deflect the meter pointer is supplied by an amplifier and power supply instead of by the circuit under test. The electronic amplifier between input and meter gives two benefits; a rugged moving coil instrument can be used, since its sensitivity need not be high, and the input resistance can be made high, reducing the current drawn from the circuit under test. Amplified voltmeters often have an input resistance of 1, 10, or 20 megohms which is independent of the range selected. A once-popular form of this instrument used a vacuum tube in the amplifier circuit and so was called the vacuum tube voltmeter (VTVM). These were almost always powered by the local AC line current and so were not particularly portable. Today these circuits use a solid-state amplifier using field-effect transistors, hence FET-VM, and appear in handheld digital multimeters as well as in bench and laboratory instruments. These largely replaced non-amplified multimeters except in the least expensive price ranges.\nMost VTVMs and FET-VMs handle DC voltage, AC voltage, and resistance measurements; modern FET-VMs add current measurements and often other functions as well. A specialized form of the VTVM or FET-VM is the AC voltmeter. These instruments are optimized for measuring AC voltage. They have much wider bandwidth and better sensitivity than a typical multifunction device.\n\n\n== Digital voltmeter ==\n\nA digital voltmeter (DVM) measures an unknown input voltage by converting the voltage to a digital value and then displays the voltage in numeric form. DVMs are usually designed around a special type of analog-to-digital converter called an integrating converter.\nDVM measurement accuracy is affected by many factors, including temperature, input impedance, and DVM power supply voltage variations. Less expensive DVMs often have input resistance on the order of 10 M\u03a9. Precision DVMs can have input resistances of 1 G\u03a9 or higher for the lower voltage ranges (e.g. less than 20 V). To ensure that a DVM's accuracy is within the manufacturer's specified tolerances, it must be periodically calibrated against a voltage standard such as the Weston cell.\nThe first digital voltmeter was invented and produced by Andrew Kay of Non-Linear Systems (and later founder of Kaypro) in 1954.Simple AC voltmeters use a rectifier connected to a DC measurement circuit, which responds to the average value of the waveform. The meter can be calibrated to display the root mean square value of the waveform, assuming a fixed relation between the average value of the rectified waveform and the RMS value. If the waveform departs significantly from the sinewave assumed in the calibration, the meter will be inaccurate, though for simple wave shapes the reading can be corrected by multiplying by a constant factor. Early \"true RMS\" circuits used a thermal converter that responded only to the RMS value of the waveform. Modern instruments calculate the RMS value by electronically calculating the square of the input value, taking the average, and then calculating the square root of the value. This allows accurate RMS measurements for a variety of waveforms.\n\n\n== See also ==\nAmmeter\nClass of accuracy in electrical measurements\nElectrical measurements\nElectrometer\nElectronic test equipment\nMetrology\nMultimeter\nOhmmeter\nPotentiometer (measuring instrument)\nSolenoid voltmeter\nVoltage divider\nMeasurement category\n\n\n== References ==\n\n\n== External links ==\n\nDC Metering Circuits chapter from Lessons In Electric Circuits Vol 1 DC free ebook and Lessons In Electric Circuits series.", "Transmission_medium": "A transmission medium is a system or substance that can mediate the propagation of signals for the purposes of telecommunication. Signals are typically imposed on a wave of some kind suitable for the chosen medium. For example, data can modulate sound, and a transmission medium for sounds may be air, but solids and liquids may also act as the transmission medium. Vacuum or air constitutes a good transmission medium for electromagnetic waves such as light and radio waves. While material substance is not required for electromagnetic waves to propagate, such waves are usually affected by the transmission media they pass through, for instance, by absorption or reflection or refraction at the interfaces between media. Technical devices can therefore be employed to transmit or guide waves. Thus, an optical fiber or a copper cable is used as transmission media.\nElectromagnetic radiation can be transmitted through an optical medium, such as optical fiber, or through twisted pair wires, coaxial cable, or dielectric-slab waveguides.  It may also pass through any physical material that is transparent to the specific wavelength, such as water, air, glass, or concrete. Sound is, by definition, the vibration of matter, so it requires a physical medium for transmission, as do other kinds of mechanical waves and heat energy. Historically, science incorporated various aether theories to explain the transmission medium. However, it is now known that electromagnetic waves do not require a physical transmission medium, and so can travel through the \"vacuum\" of free space. Regions of the insulative vacuum can become conductive for electrical conduction through the presence of free electrons, holes, or ions.\n\n\n== Optical medium ==\n\n\n== Telecommunications ==\nA physical medium in data communications is the transmission path over which a signal propagates. Many different types of transmission media are used as communications channel.\nIn many cases, communication is in the form of electromagnetic waves. With guided transmission media, the waves are guided along a physical path; examples of guided media include phone lines, twisted pair cables, coaxial cables, and optical fibers. Unguided transmission media are methods that allow the transmission of data without the use of physical means to define the path it takes. Examples of this include microwave, radio or infrared. Unguided media provide a means for transmitting electromagnetic waves but do not guide them; examples are propagation through air, vacuum and seawater.\nThe term direct link is used to refer to the transmission path between two devices in which signals propagate directly from transmitters to receivers with no intermediate devices, other than amplifiers or repeaters used to increase signal strength. This term can apply to both guided and unguided media.\n\n\n== Simplex versus duplex ==\nA transmission may be simplex, half-duplex, or full-duplex.\nIn simplex transmission, signals are transmitted in only one direction; one station is a transmitter and the other is the receiver. In the half-duplex operation, both stations may transmit, but only one at a time. In full-duplex operation, both stations may transmit simultaneously. In the latter case, the medium is carrying signals in both directions at the same time.\n\n\n== Types ==\nIn general, a transmission medium can be classified as\n\nlinear, if different waves at any particular point in the medium can be superposed;\nbounded, if it is finite in extent, otherwise unbounded;\nuniform or homogeneous, if its physical properties are unchanged at different points;\nisotropic, if its physical properties are the same in different directions.There are two main types of transmission media:\n\nguided media\u2014waves are guided along a solid medium such as a transmission line;\nunguided media\u2014transmission and reception are achieved by means of an antenna.One of the most common physical medias used in networking is copper wire. Copper wire to carry signals to long distances using relatively low amounts of power. The unshielded twisted pair (UTP) is eight strands of copper wire, organized into four pairs.\n\n\n=== Guided media ===\n\n\n==== Twisted pair ====\n\nTwisted pair cabling is a type of wiring in which two conductors of a single circuit are twisted together for the purposes of improving electromagnetic compatibility. Compared to a single conductor or an untwisted balanced pair, a twisted pair reduces electromagnetic radiation from the pair and crosstalk between neighboring pairs and improves rejection of external electromagnetic interference. It was invented by Alexander Graham Bell.\n\n\n==== Coaxial cable ====\n\nCoaxial cable, or coax (pronounced ) is a type of electrical cable that has an inner conductor surrounded by a tubular insulating layer, surrounded by a tubular conducting shield. Many coaxial cables also have an insulating outer sheath or jacket.  The term coaxial comes from the inner conductor and the outer shield sharing a geometric axis. Coaxial cable was invented by English physicist, engineer, and mathematician Oliver Heaviside, who patented the design in 1880.Coaxial cable is a type of transmission line, used to carry high frequency electrical signals with low losses.  It is used in such applications as telephone trunk lines, broadband internet networking cables,  high speed computer data busses, carrying cable television signals, and connecting radio transmitters and receivers to their antennas. It differs from other shielded cables because the dimensions of the cable and connectors are controlled to give a precise, constant conductor spacing, which is needed for it to function efficiently as a transmission line.\n\n\n==== Optical fiber ====\n\nOptical fiber, which has emerged as the most commonly used transmission medium for long-distance communications, is a thin strand of glass that guides light along its length. Four major factors favor optical fiber over copper: data rates, distance, installation, and costs. Optical fiber can carry huge amounts of data compared to copper. It can be run for hundreds of miles without the need for signal repeaters, in turn, reducing maintenance costs and improving the reliability of the communication system because repeaters are a common source of network failures. Glass is lighter than copper allowing for less need for specialized heavy-lifting equipment when installing long-distance optical fiber. Optical fiber for indoor applications cost approximately a dollar a foot, the same as copper.Multimode and single mode are two types of commonly used optical fiber. Multimode fiber uses LEDs as the light source and can carry signals over shorter distances, about 2 kilometers. Single mode can carry signals over distances of tens of miles.\nAn optical fiber is a flexible, transparent fiber made by drawing glass (silica) or plastic to a diameter slightly thicker than that of a human hair. Optical fibers are used most often as a means to transmit light between the two ends of the fiber and find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data rates) than electrical cables. Fibers are used instead of metal wires because signals travel along them with less loss; in addition, fibers are immune to electromagnetic interference, a problem from which metal wires suffer excessively. Fibers are also used for illumination and imaging, and are often wrapped in bundles so they may be used to carry light into, or images out of confined spaces, as in the case of a fiberscope. Specially designed fibers are also used for a variety of other applications, some of them being fiber optic sensors and fiber lasers.Optical fibers typically include a core surrounded by a transparent cladding material with a lower index of refraction. Light is kept in the core by the phenomenon of total internal reflection which causes the fiber to act as a waveguide. Fibers that support many propagation paths or transverse modes are called multi-mode fibers, while those that support a single mode are called single-mode fibers (SMF). Multi-mode fibers generally have a wider core diameter and are used for short-distance communication links and for applications where high power must be transmitted. Single-mode fibers are used for most communication links longer than 1,000 meters (3,300 ft).Being able to join optical fibers with low loss is important in fiber optic communication. This is more complex than joining electrical wire or cable and involves careful cleaving of the fibers, precise alignment of the fiber cores, and the coupling of these aligned cores. For applications that demand a permanent connection a fusion splice is common. In this technique, an electric arc is used to melt the ends of the fibers together. Another common technique is a mechanical splice, where the ends of the fibers are held in contact by mechanical force. Temporary or semi-permanent connections are made by means of specialized optical fiber connectors.The field of applied science and engineering concerned with the design and application of optical fibers is known as fiber optics. The term was coined by Indian physicist Narinder Singh Kapany, who is widely acknowledged as the father of fiber optics.\n\n\n=== Unguided media ===\n\n\n==== Radio ====\n\nRadio propagation is the behavior of radio waves as they travel, or are propagated, from one point to another, or into various parts of the atmosphere. As a form of electromagnetic radiation, like light waves, radio waves are affected by the phenomena of reflection, refraction, diffraction, absorption, polarization, and scattering.   Understanding the effects of varying conditions on radio propagation has many practical applications, from choosing frequencies for international shortwave broadcasters, to designing reliable mobile telephone systems, to radio navigation, to operation of radar systems.\nDifferent types of propagation are used in practical radio transmission systems. Line-of-sight propagation means radio waves which travel in a straight line from the transmitting antenna to the receiving antenna. Line of sight transmission is used to medium-range radio transmission such as cell phones, cordless phones, walkie-talkies, wireless networks, FM radio and television broadcasting and radar, and satellite communication, such as satellite television. Line-of-sight transmission on the surface of the Earth is limited to the distance to the visual horizon, which depends on the height of transmitting and receiving antennas. It is the only propagation method possible at microwave frequencies and above. At microwave frequencies, moisture in the atmosphere (rain fade) can degrade transmission.\nAt lower frequencies in the MF, LF, and VLF bands, due to diffraction radio waves can bend over obstacles like hills, and travel beyond the horizon as surface waves which follow the contour of the Earth. These are called ground waves.  AM broadcasting stations use ground waves to cover their listening areas. As the frequency gets lower, the attenuation with distance decreases, so very low frequency (VLF) and extremely low frequency (ELF) ground waves can be used to communicate worldwide. VLF and ELF waves can penetrate significant distances through water and earth, and these frequencies are used for mine communication and military communication with submerged submarines.\nAt medium wave and shortwave frequencies (MF and HF bands) radio waves can refract from a layer of charged particles (ions) high in the atmosphere, called the ionosphere. This means that radio waves transmitted at an angle into the sky can be reflected back to Earth beyond the horizon, at great distances, even transcontinental distances. This is called skywave propagation. It is used by amateur radio operators to talk to other countries and shortwave broadcasting stations that broadcast internationally. Skywave communication is variable, dependent on conditions in the upper atmosphere; it is most reliable at night and in the winter. Due to its unreliability, since the advent of communication satellites in the 1960s, many long range communication that previously used skywaves now use satellites.\nIn addition, there are several less common radio propagation mechanisms, such as tropospheric scattering (troposcatter) and near vertical incidence skywave (NVIS) which are used in specialized communication systems.\n\n\n== Digital encoding ==\nTransmission and reception of data is typically performed in four steps:\nAt the transmitting end, the data is encoded to a binary representation.\nA carrier signal is modulated as specified by the binary representation.\nAt the receiving end, the carrier signal is demodulated into a binary representation.\nThe data is decoded from the binary representation.\n\n\n== See also ==\nVacuum permittivity\nTransmission (telecommunications)\nExcitable medium\nDuplex (telecommunications)\nLuminiferous aether\n\n\n== References ==", "Insulator_(electricity)": "An electrical insulator is a material in which electric current does not flow freely. The atoms of the insulator have tightly bound electrons which cannot readily move. Other materials\u2014semiconductors and conductors\u2014conduct electric current more easily. The property that distinguishes an insulator is its resistivity; insulators have higher resistivity than semiconductors or conductors. The most common examples are non-metals.\nA perfect insulator does not exist because even insulators contain small numbers of mobile charges (charge carriers) which can carry current. In addition, all insulators become electrically conductive when a sufficiently large voltage is applied that the electric field tears electrons away from the atoms. This is known as the breakdown voltage of an insulator. Some materials such as glass, paper and PTFE, which have high resistivity, are very good electrical insulators. A much larger class of materials, even though they may have lower bulk resistivity, are still good enough to prevent significant current from flowing at normally used voltages, and thus are employed as insulation for electrical wiring and cables. Examples include rubber-like polymers and most plastics which can be thermoset or thermoplastic in nature.\nInsulators are used in electrical equipment to support and separate electrical conductors without allowing current through themselves. An insulating material used in bulk to wrap electrical cables or other equipment is called insulation. The term insulator is also used more specifically to refer to insulating supports used to attach electric power distribution or transmission lines to utility poles and transmission towers. They support the weight of the suspended wires without allowing the current to flow through the tower to ground.\n\n\n== Physics of conduction in solids ==\nElectrical insulation is the absence of electrical conduction. Electronic band theory (a branch of physics) explains that electric charge flows when quantum states of matter are available into which electrons can be excited. This allows electrons to gain energy and thereby move through a conductor, such as a metal, if an electric potential difference is applied to the material. If no such states are available, the material is an insulator.\nMost insulators have a large band gap. This occurs because the \"valence\" band containing the highest energy electrons is full, and a large energy gap separates this band from the next band above it. There is always some voltage (called the breakdown voltage) that gives electrons enough energy to be excited into this band. Once this voltage is exceeded, electrical breakdown occurs, and the material ceases being an insulator, passing charge. This is usually accompanied by physical or chemical changes that permanently degrade the material and its insulating properties.\nWhen the electric field applied across an insulating substance exceeds in any location the threshold breakdown field for that substance, the insulator suddenly becomes a conductor, causing a large increase in current, an electric arc through the substance. Electrical breakdown occurs when the electric field in the material is strong enough to accelerate free charge carriers (electrons and ions, which are always present at low concentrations) to a high enough velocity to knock electrons from atoms when they strike them, ionizing the atoms. These freed electrons and ions are in turn accelerated and strike other atoms, creating more charge carriers, in a chain reaction. Rapidly the insulator becomes filled with mobile charge carriers, and its resistance drops to a low level. In a solid, the breakdown voltage is proportional to the band gap energy. When corona discharge occurs, the air in a region around a high-voltage conductor can break down and ionise without a catastrophic increase in current. However, if the region of air breakdown extends to another conductor at a different voltage it creates a conductive path between them, and a large current flows through the air, creating an electric arc. Even a vacuum can suffer a sort of breakdown, but in this case the breakdown or vacuum arc involves charges ejected from the surface of metal electrodes rather than produced by the vacuum itself.\nIn addition, all insulators become conductors at very high temperatures as the thermal energy of the valence electrons is sufficient to put them in the conduction band.In certain capacitors, shorts between electrodes formed due to dielectric breakdown can disappear when the applied electric field is reduced.\n\n\n== Uses ==\nA flexible coating of an insulator is often applied to electric wire and cable; this assembly is called insulated wire. Wires sometimes don't use an insulating coating, just air, when a solid (e.g. plastic) coating may be impractical. Wires that touch each other produce cross connections, short circuits, and fire hazards. In coaxial cable the center conductor must be supported precisely in the middle of the hollow shield to prevent electro-magnetic wave reflections. Wires that expose high voltages can cause human shock and electrocution hazards.\nMost insulated wire and cable products have maximum ratings for voltage and conductor temperature. The product may not have an ampacity (current-carrying capacity) rating, since this is dependent on the surrounding environment (e.g. ambient temperature).\nIn electronic systems, printed circuit boards are made from epoxy plastic and fibreglass. The nonconductive boards support layers of copper foil conductors. In electronic devices, the tiny and delicate active components are embedded within nonconductive epoxy or phenolic plastics, or within baked glass or ceramic coatings.\nIn microelectronic components such as transistors and ICs, the silicon material is normally a conductor because of doping, but it can easily be selectively transformed into a good insulator by the application of heat and oxygen. Oxidised silicon is quartz, i.e. silicon dioxide, the primary component of glass.\nIn high voltage systems containing transformers and capacitors, liquid insulator oil is the typical method used for preventing arcs. The oil replaces air in spaces that must support significant voltage without electrical breakdown. Other high voltage system insulation materials include ceramic or glass wire holders, gas, vacuum, and simply placing wires far enough apart to use air as insulation.\n\n\n== Insulation in electrical apparatus ==\n\nThe most important insulation material is air. A variety of solid, liquid, and gaseous insulators are also used in electrical apparatus. In smaller transformers, generators, and electric motors, insulation on the wire coils consists of up to four thin layers of polymer varnish film. Film-insulated magnet wire permits a manufacturer to obtain the maximum number of turns within the available space. Windings that use thicker conductors are often wrapped with supplemental fiberglass insulating tape. Windings may also be impregnated with insulating varnishes to prevent electrical corona and reduce magnetically induced wire vibration. Large power transformer windings are still mostly insulated with paper, wood, varnish, and mineral oil; although these materials have been used for more than 100 years, they still provide a good balance of economy and adequate performance. Busbars and circuit breakers in switchgear may be insulated with glass-reinforced plastic insulation, treated to have low flame spread and to prevent tracking of current across the material.\nIn older apparatus made up to the early 1970s, boards made of compressed asbestos may be found; while this is an adequate insulator at power frequencies, handling or repairs to asbestos material can release dangerous fibers into the air and must be carried out cautiously. Wire insulated with felted asbestos was used in high-temperature and rugged applications from the 1920s. Wire of this type was sold by General Electric under the trade name \"Deltabeston.\"Live-front switchboards up to the early part of the 20th century were made of slate or marble. Some high voltage equipment is designed to operate within a high pressure insulating gas such as sulfur hexafluoride. Insulation materials that perform well at power and low frequencies may be unsatisfactory at radio frequency, due to heating from excessive dielectric dissipation.\nElectrical wires may be insulated with polyethylene, crosslinked polyethylene (either through electron beam processing or chemical crosslinking), PVC, Kapton, rubber-like polymers, oil impregnated paper, Teflon, silicone, or modified ethylene tetrafluoroethylene (ETFE). Larger power cables may use compressed inorganic powder, depending on the application.\nFlexible insulating materials such as PVC (polyvinyl chloride) are used to insulate the circuit and prevent human contact with a 'live' wire \u2013 one having voltage of 600 volts or less. Alternative materials are likely to become increasingly used due to EU safety and environmental legislation making PVC less economic.\nIn electrical apparatus such as motors, generators, and transformers, various insulation systems are used, classified by their maximum recommended working temperature to achieve acceptable operating life. Materials range from upgraded types of paper to inorganic compounds. \n\n\n=== Class I and Class II insulation ===\n\nAll portable or hand-held electrical devices are insulated to protect their user from harmful shock.\nClass I insulation requires that the metal body and other exposed metal parts of the device be connected to earth via a grounding wire that is earthed at the main service panel\u2014but only needs basic insulation on the conductors. This equipment needs an extra pin on the power plug for the grounding connection.\nClass II insulation means that the device is double insulated. This is used on some appliances such as electric shavers, hair dryers and portable power tools. Double insulation requires that the devices have both basic and supplementary insulation, each of which is sufficient to prevent electric shock. All internal electrically energized components are totally enclosed within an insulated body that prevents any contact with \"live\" parts. In the EU, double insulated appliances all are marked with a symbol of two squares, one inside the other.\n\n\n== Telegraph and power transmission insulators ==\n\nConductors for overhead high-voltage electric power transmission are bare, and are insulated by the surrounding air. Conductors for lower voltages in distribution may have some insulation but are often bare as well. Insulating supports are required at the points where they are supported by utility poles or transmission towers. Insulators are also required where wire enters buildings or electrical devices, such as transformers or circuit breakers, for insulation from the case. Often these are bushings, which are hollow insulators with the conductor inside them.\n\n\n=== Materials ===\nInsulators used for high-voltage power transmission are made from glass, porcelain or composite polymer materials. Porcelain insulators are made from clay, quartz or alumina and feldspar, and are covered with a smooth glaze to shed water. Insulators made from porcelain rich in alumina are used where high mechanical strength is a criterion. Porcelain has a dielectric strength of about 4\u201310 kV/mm. Glass has a higher dielectric strength, but it attracts condensation and the thick irregular shapes needed for insulators are difficult to cast without internal strains. Some insulator manufacturers stopped making glass insulators in the late 1960s, switching to ceramic materials.\nSome electric utilities use polymer composite materials for some types of insulators. These are typically composed of a central rod made of fibre reinforced plastic and an outer weathershed made of silicone rubber or ethylene propylene diene monomer rubber (EPDM). Composite insulators are less costly, lighter in weight, and have excellent hydrophobic properties. This combination makes them ideal for service in polluted areas. However, these materials do not yet have the long-term proven service life of glass and porcelain.\n\n\t\t\n\n\n=== Design ===\n\nThe electrical breakdown of an insulator due to excessive voltage can occur in one of two ways:\n\nA puncture arc is a breakdown and conduction of the material of the insulator, causing an electric arc through the interior of the insulator. The heat resulting from the arc usually damages the insulator irreparably. Puncture voltage is the voltage across the insulator (when installed in its normal manner) that causes a puncture arc.\nA flashover arc is a breakdown and conduction of the air around or along the surface of the insulator, causing an arc along the outside of the insulator. Insulators are usually designed to withstand flashover without damage. Flashover voltage is the voltage that causes a flash-over arc.Most high voltage insulators are designed with a lower flashover voltage than puncture voltage, so they flash over before they puncture, to avoid damage.\nDirt, pollution, salt, and particularly water on the surface of a high voltage insulator can create a conductive path across it, causing leakage currents and flashovers. The flashover voltage can be reduced by more than 50% when the insulator is wet. High voltage insulators for outdoor use are shaped to maximise the length of the leakage path along the surface from one end to the other, called the creepage length, to minimise these leakage currents. To accomplish this the surface is moulded into a series of corrugations or concentric disc shapes. These usually include one or more sheds; downward facing cup-shaped surfaces that act as umbrellas to ensure that the part of the surface leakage path under the 'cup' stays dry in wet weather. Minimum creepage distances are 20\u201325 mm/kV, but must be increased in high pollution or airborne sea-salt areas.\n\n\n=== Types ===\n\nInsulators are characterized in several common classes:\n\nPin insulator - The pin-type insulator is mounted on a pin affixed on the cross-arm of the pole. The insulator has a groove near the top just below the crown. The conductor passes through this groove and is tied to the insulator with annealed wire of the same material as the conductor. Pin-type insulators are used for transmission and distribution of communication signals, and electric power at voltages up to 33 kV. Insulators made for operating voltages between 33 kV and 69 kV tend to be bulky and have become uneconomical.\nPost insulator - A type of insulator in the 1930s that is more compact than traditional pin-type insulators and which has rapidly replaced many pin-type insulators on lines up to 69 kV and in some configurations, can be made for operation at up to 115 kV.\nSuspension insulator - For voltages greater than 33 kV, it is a usual practice to use suspension type insulators, consisting of a number of glass or porcelain discs connected in series by metal links in the form of a string. The conductor is suspended at the bottom end of this string while the top end is secured to the cross-arm of the tower. The number of disc units used depends on the voltage.\nStrain insulator - A dead end or anchor pole or tower is used where a straight section of line ends, or angles off in another direction. These poles must withstand the lateral (horizontal) tension of the long straight section of wire. To support this lateral load, strain insulators are used. For low voltage lines (less than 11 kV), shackle insulators are used as strain insulators. However, for high voltage transmission lines, strings of cap-and-pin (suspension) insulators are used, attached to the crossarm in a horizontal direction. When the tension load in lines is exceedingly high, such as at long river spans, two or more strings are used in parallel.\nShackle insulator - In early days, the shackle insulators were used as strain insulators. But nowaday, they are frequently used for low voltage distribution lines. Such insulators can be used either in a horizontal position or in a vertical position. They can be directly fixed to the pole with a bolt or to the cross arm.\nBushing - enables one or several conductors to pass through a partition such as a wall or a tank, and insulates the conductors from it.\nLine post insulator\nStation post insulator\nCut-out\n\n\n=== Sheath insulator ===\n\nAn insulator that protects a full length of bottom-contact third rail.\n\n\n=== Suspension insulators ===\nPin-type insulators are unsuitable for voltages greater than about 69 kV line-to-line. Higher transmission voltages use suspension insulator strings, which can be made for any practical transmission voltage by adding insulator elements to the string.Higher voltage transmission lines usually use modular suspension insulator designs. The wires are suspended from a 'string' of identical disc-shaped insulators that attach to each other with metal clevis pin or ball-and-socket links. The advantage of this design is that insulator strings with different breakdown voltages, for use with different line voltages, can be constructed by using different numbers of the basic units. Also, if one of the insulator units in the string breaks, it can be replaced without discarding the entire string.\nEach unit is constructed of a ceramic or glass disc with a metal cap and pin cemented to opposite sides. To make defective units obvious, glass units are designed so that an overvoltage causes a puncture arc through the glass instead of a flashover. The glass is heat-treated so it shatters, making the damaged unit visible. However the mechanical strength of the unit is unchanged, so the insulator string stays together.\nStandard suspension disc insulator units are 25 centimetres (9.8 in) in diameter and 15 cm (6 in) long, can support a load of 80\u2013120 kilonewtons (18,000\u201327,000 lbf), have a dry flashover voltage of about 72 kV, and are rated at an operating voltage of 10\u201312 kV. However, the flashover voltage of a string is less than the sum of its component discs, because the electric field is not distributed evenly across the string but is strongest at the disc nearest to the conductor, which flashes over first. Metal grading rings are sometimes added around the disc at the high voltage end, to reduce the electric field across that disc and improve flashover voltage.\nIn very high voltage lines the insulator may be surrounded by corona rings. These typically consist of toruses of aluminium (most commonly) or copper tubing attached to the line. They are designed to reduce the electric field at the point where the insulator is attached to the line, to prevent corona discharge, which results in power losses.\n\n\t\t\n\t\t\n\n\n=== History ===\n\nThe first electrical systems to make use of insulators were telegraph lines; direct attachment of wires to wooden poles was found to give very poor results, especially during damp weather.\nThe first glass insulators used in large quantities had an unthreaded pinhole. These pieces of glass were positioned on a tapered wooden pin, vertically extending upwards from the pole's crossarm (commonly only two insulators to a pole and maybe one on top of the pole itself). Natural contraction and expansion of the wires tied to these \"threadless insulators\" resulted in insulators unseating from their pins, requiring manual reseating.\nAmongst the first to produce ceramic insulators were companies in the United Kingdom, with Stiff and Doulton using stoneware from the mid-1840s, Joseph Bourne (later renamed Denby) producing them from around 1860 and Bullers from 1868. Utility patent number 48,906 was granted to Louis A. Cauvet on 25 July 1865 for a process to produce insulators with a threaded pinhole: pin-type insulators still have threaded pinholes.\nThe invention of suspension-type insulators made high-voltage power transmission possible. As transmission line voltages reached and passed 60,000 volts, the insulators required become very large and heavy, with insulators made for a safety margin of 88,000 volts being about the practical limit for manufacturing and installation. Suspension insulators, on the other hand, can be connected into strings as long as required for the line's voltage.\nA large variety of telephone, telegraph and power insulators have been made; some people collect them, both for their historic interest and for the aesthetic quality of many insulator designs and finishes. One collectors organisation is the US National Insulator Association, which has over 9,000 members.\n\n\n== Insulation of antennas ==\n\nOften a broadcasting radio antenna is built as a mast radiator, which means that the entire mast structure is energised with high voltage and must be insulated from the ground. Steatite mountings are used. They have to withstand not only the voltage of the mast radiator to ground, which can reach values up to 400 kV at some antennas, but also the weight of the mast construction and dynamic forces. Arcing horns and lightning arresters are necessary because lightning strikes to the mast are common.\nGuy wires supporting antenna masts usually have strain insulators inserted in the cable run, to keep the high voltages on the antenna from short circuiting to ground or creating a shock hazard. Often guy cables have several insulators, placed to break up the cable into lengths that prevent unwanted electrical resonances in the guy. These insulators are usually ceramic and cylindrical or egg-shaped (see picture). This construction has the advantage that the ceramic is under compression rather than tension, so it can withstand greater load, and that if the insulator breaks, the cable ends are still linked.\nThese insulators also have to be equipped with overvoltage protection equipment. For the dimensions of the guy insulation, static charges on guys have to be considered. For high masts, these can be much higher than the voltage caused by the transmitter, requiring guys divided by insulators in multiple sections on the highest masts. In this case, guys which are grounded at the anchor basements via a coil - or if possible, directly - are the better choice.\nFeedlines attaching antennas to radio equipment, particularly twin-lead type, often must be kept at a distance from metal structures. The insulated supports used for this purpose are called standoff insulators.\n\n\n== See also ==\nStephen Gray \u2013 English physicist\nElectrical conductor\nDielectric material\nElectrical conductivity\n\n\n== Notes ==\n\n\n== References ==\nTaylor, Sue (May 2003). Bullers of Milton. ISBN 978-1-897949-96-2.\nFunction of Grading rings to Composite Insulator", "Scalar_multiplication": "In mathematics, scalar multiplication is one of the basic operations defining a vector space in linear algebra (or more generally, a module in abstract algebra). In common geometrical contexts, scalar multiplication of a real Euclidean vector by a positive real number multiplies the magnitude of the vector\u2014without changing its direction. The term \"scalar\" itself derives from this usage: a scalar is that which scales vectors. Scalar multiplication is the multiplication of a vector by a scalar (where the product is a vector), and is to be distinguished from inner product of two vectors (where the product is a scalar).\n\n\n== Definition ==\nIn general, if K is a field and V is a vector space over K, then scalar multiplication is a function from K \u00d7 V to V.\nThe result of applying this function to k in K and v in V is denoted kv.\n\n\n=== Properties ===\nScalar multiplication obeys the following rules (vector in boldface):\n\nAdditivity in the scalar: (c + d)v = cv + dv;\nAdditivity in the vector: c(v + w) = cv + cw;\nCompatibility of product of scalars with scalar multiplication: (cd)v = c(dv);\nMultiplying by 1 does not change a vector: 1v = v;\nMultiplying by 0 gives the zero vector: 0v = 0;\nMultiplying by \u22121 gives the additive inverse: (\u22121)v = \u2212v.Here, + is addition either in the field or in the vector space, as appropriate; and 0 is the additive identity in either.\nJuxtaposition indicates either scalar multiplication or the multiplication operation in the field.\n\n\n== Interpretation ==\nScalar multiplication may be viewed as an external binary operation or as an action of the field on the vector space. A geometric interpretation of scalar multiplication is that it stretches or contracts vectors by a constant factor. As a result, it produces a vector in the same or opposite direction of the original vector but of a different length.As a special case, V may be taken to be K itself and scalar multiplication may then be taken to be simply the multiplication in the field.\nWhen V is Kn, scalar multiplication is equivalent to multiplication of each component with the scalar, and may be defined as such.\nThe same idea applies if K is a commutative ring and V is a module over K.\nK can even be a rig, but then there is no additive inverse.\nIf K is not commutative, the distinct operations left scalar multiplication cv and right scalar multiplication vc may be defined.\n\n\n== Scalar multiplication of matrices ==\n\nThe left scalar multiplication of a matrix A with a scalar \u03bb gives another matrix of the same size as A. It is denoted by \u03bbA, whose entries of \u03bbA are defined by\n\n  \n    \n      \n        (\n        \u03bb\n        \n          A\n        \n        \n          )\n          \n            i\n            j\n          \n        \n        =\n        \u03bb\n        \n          \n            (\n            \n              A\n            \n            )\n          \n          \n            i\n            j\n          \n        \n        \n        ,\n      \n    \n    {\\displaystyle (\\lambda \\mathbf {A} )_{ij}=\\lambda \\left(\\mathbf {A} \\right)_{ij}\\,,}\n  explicitly:\n\n  \n    \n      \n        \u03bb\n        \n          A\n        \n        =\n        \u03bb\n        \n          \n            (\n            \n              \n                \n                  \n                    A\n                    \n                      11\n                    \n                  \n                \n                \n                  \n                    A\n                    \n                      12\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      1\n                      m\n                    \n                  \n                \n              \n              \n                \n                  \n                    A\n                    \n                      21\n                    \n                  \n                \n                \n                  \n                    A\n                    \n                      22\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      2\n                      m\n                    \n                  \n                \n              \n              \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22f1\n                \n                \n                  \u22ee\n                \n              \n              \n                \n                  \n                    A\n                    \n                      n\n                      1\n                    \n                  \n                \n                \n                  \n                    A\n                    \n                      n\n                      2\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      n\n                      m\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \u03bb\n                  \n                    A\n                    \n                      11\n                    \n                  \n                \n                \n                  \u03bb\n                  \n                    A\n                    \n                      12\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \u03bb\n                  \n                    A\n                    \n                      1\n                      m\n                    \n                  \n                \n              \n              \n                \n                  \u03bb\n                  \n                    A\n                    \n                      21\n                    \n                  \n                \n                \n                  \u03bb\n                  \n                    A\n                    \n                      22\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \u03bb\n                  \n                    A\n                    \n                      2\n                      m\n                    \n                  \n                \n              \n              \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22f1\n                \n                \n                  \u22ee\n                \n              \n              \n                \n                  \u03bb\n                  \n                    A\n                    \n                      n\n                      1\n                    \n                  \n                \n                \n                  \u03bb\n                  \n                    A\n                    \n                      n\n                      2\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \u03bb\n                  \n                    A\n                    \n                      n\n                      m\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle \\lambda \\mathbf {A} =\\lambda {\\begin{pmatrix}A_{11}&A_{12}&\\cdots &A_{1m}\\\\A_{21}&A_{22}&\\cdots &A_{2m}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\A_{n1}&A_{n2}&\\cdots &A_{nm}\\\\\\end{pmatrix}}={\\begin{pmatrix}\\lambda A_{11}&\\lambda A_{12}&\\cdots &\\lambda A_{1m}\\\\\\lambda A_{21}&\\lambda A_{22}&\\cdots &\\lambda A_{2m}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\lambda A_{n1}&\\lambda A_{n2}&\\cdots &\\lambda A_{nm}\\\\\\end{pmatrix}}\\,.}\n  Similarly, even though there is no widely-accepted definition, the right scalar multiplication of a matrix A with a scalar \u03bb could be defined to be\n\n  \n    \n      \n        (\n        \n          A\n        \n        \u03bb\n        \n          )\n          \n            i\n            j\n          \n        \n        =\n        \n          \n            (\n            \n              A\n            \n            )\n          \n          \n            i\n            j\n          \n        \n        \u03bb\n        \n        ,\n      \n    \n    {\\displaystyle (\\mathbf {A} \\lambda )_{ij}=\\left(\\mathbf {A} \\right)_{ij}\\lambda \\,,}\n  explicitly:\n\n  \n    \n      \n        \n          A\n        \n        \u03bb\n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    A\n                    \n                      11\n                    \n                  \n                \n                \n                  \n                    A\n                    \n                      12\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      1\n                      m\n                    \n                  \n                \n              \n              \n                \n                  \n                    A\n                    \n                      21\n                    \n                  \n                \n                \n                  \n                    A\n                    \n                      22\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      2\n                      m\n                    \n                  \n                \n              \n              \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22f1\n                \n                \n                  \u22ee\n                \n              \n              \n                \n                  \n                    A\n                    \n                      n\n                      1\n                    \n                  \n                \n                \n                  \n                    A\n                    \n                      n\n                      2\n                    \n                  \n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      n\n                      m\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        \u03bb\n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    A\n                    \n                      11\n                    \n                  \n                  \u03bb\n                \n                \n                  \n                    A\n                    \n                      12\n                    \n                  \n                  \u03bb\n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      1\n                      m\n                    \n                  \n                  \u03bb\n                \n              \n              \n                \n                  \n                    A\n                    \n                      21\n                    \n                  \n                  \u03bb\n                \n                \n                  \n                    A\n                    \n                      22\n                    \n                  \n                  \u03bb\n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      2\n                      m\n                    \n                  \n                  \u03bb\n                \n              \n              \n                \n                  \u22ee\n                \n                \n                  \u22ee\n                \n                \n                  \u22f1\n                \n                \n                  \u22ee\n                \n              \n              \n                \n                  \n                    A\n                    \n                      n\n                      1\n                    \n                  \n                  \u03bb\n                \n                \n                  \n                    A\n                    \n                      n\n                      2\n                    \n                  \n                  \u03bb\n                \n                \n                  \u22ef\n                \n                \n                  \n                    A\n                    \n                      n\n                      m\n                    \n                  \n                  \u03bb\n                \n              \n            \n            )\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {A} \\lambda ={\\begin{pmatrix}A_{11}&A_{12}&\\cdots &A_{1m}\\\\A_{21}&A_{22}&\\cdots &A_{2m}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\A_{n1}&A_{n2}&\\cdots &A_{nm}\\\\\\end{pmatrix}}\\lambda ={\\begin{pmatrix}A_{11}\\lambda &A_{12}\\lambda &\\cdots &A_{1m}\\lambda \\\\A_{21}\\lambda &A_{22}\\lambda &\\cdots &A_{2m}\\lambda \\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\A_{n1}\\lambda &A_{n2}\\lambda &\\cdots &A_{nm}\\lambda \\\\\\end{pmatrix}}\\,.}\n  When the entries of the matrix and the scalars are from the same commutative field, for example, the real number field or the complex number field, these two multiplications are the same, and can be simply called scalar multiplication. For matrices over a more general field that is not commutative, they may not be equal.\nFor a real scalar and matrix:\n\n  \n    \n      \n        \u03bb\n        =\n        2\n        ,\n        \n        \n          A\n        \n        =\n        \n          \n            (\n            \n              \n                \n                  a\n                \n                \n                  b\n                \n              \n              \n                \n                  c\n                \n                \n                  d\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle \\lambda =2,\\quad \\mathbf {A} ={\\begin{pmatrix}a&b\\\\c&d\\\\\\end{pmatrix}}}\n  \n  \n    \n      \n        2\n        \n          A\n        \n        =\n        2\n        \n          \n            (\n            \n              \n                \n                  a\n                \n                \n                  b\n                \n              \n              \n                \n                  c\n                \n                \n                  d\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  2\n                  \n                  \u22c5\n                  \n                  a\n                \n                \n                  2\n                  \n                  \u22c5\n                  \n                  b\n                \n              \n              \n                \n                  2\n                  \n                  \u22c5\n                  \n                  c\n                \n                \n                  2\n                  \n                  \u22c5\n                  \n                  d\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  a\n                  \n                  \u22c5\n                  \n                  2\n                \n                \n                  b\n                  \n                  \u22c5\n                  \n                  2\n                \n              \n              \n                \n                  c\n                  \n                  \u22c5\n                  \n                  2\n                \n                \n                  d\n                  \n                  \u22c5\n                  \n                  2\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  a\n                \n                \n                  b\n                \n              \n              \n                \n                  c\n                \n                \n                  d\n                \n              \n            \n            )\n          \n        \n        2\n        =\n        \n          A\n        \n        2.\n      \n    \n    {\\displaystyle 2\\mathbf {A} =2{\\begin{pmatrix}a&b\\\\c&d\\\\\\end{pmatrix}}={\\begin{pmatrix}2\\!\\cdot \\!a&2\\!\\cdot \\!b\\\\2\\!\\cdot \\!c&2\\!\\cdot \\!d\\\\\\end{pmatrix}}={\\begin{pmatrix}a\\!\\cdot \\!2&b\\!\\cdot \\!2\\\\c\\!\\cdot \\!2&d\\!\\cdot \\!2\\\\\\end{pmatrix}}={\\begin{pmatrix}a&b\\\\c&d\\\\\\end{pmatrix}}2=\\mathbf {A} 2.}\n  For quaternion scalars and matrices:\n\n  \n    \n      \n        \u03bb\n        =\n        i\n        ,\n        \n        \n          A\n        \n        =\n        \n          \n            (\n            \n              \n                \n                  i\n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  j\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle \\lambda =i,\\quad \\mathbf {A} ={\\begin{pmatrix}i&0\\\\0&j\\\\\\end{pmatrix}}}\n  \n  \n    \n      \n        i\n        \n          \n            (\n            \n              \n                \n                  i\n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  j\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    i\n                    \n                      2\n                    \n                  \n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  i\n                  j\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \u2212\n                  1\n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  k\n                \n              \n            \n            )\n          \n        \n        \u2260\n        \n          \n            (\n            \n              \n                \n                  \u2212\n                  1\n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  \u2212\n                  k\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    i\n                    \n                      2\n                    \n                  \n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  j\n                  i\n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  i\n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  j\n                \n              \n            \n            )\n          \n        \n        i\n        \n        ,\n      \n    \n    {\\displaystyle i{\\begin{pmatrix}i&0\\\\0&j\\\\\\end{pmatrix}}={\\begin{pmatrix}i^{2}&0\\\\0&ij\\\\\\end{pmatrix}}={\\begin{pmatrix}-1&0\\\\0&k\\\\\\end{pmatrix}}\\neq {\\begin{pmatrix}-1&0\\\\0&-k\\\\\\end{pmatrix}}={\\begin{pmatrix}i^{2}&0\\\\0&ji\\\\\\end{pmatrix}}={\\begin{pmatrix}i&0\\\\0&j\\\\\\end{pmatrix}}i\\,,}\n  where i, j, k are the quaternion units. The non-commutativity of quaternion multiplication prevents the transition of changing ij = +k to ji = \u2212k.\n\n\n== See also ==\nDot product\nMatrix multiplication\nMultiplication of vectors\nProduct (mathematics)\n\n\n== References ==", "Refracting_telescope": "A refracting telescope (also called a refractor) is a type of optical telescope that uses a lens as its objective to form an image (also referred to a dioptric telescope). The refracting telescope design was originally used in spyglasses and astronomical telescopes but is also used for long-focus camera lenses. Although large refracting telescopes were very popular in the second half of the 19th century, for most research purposes, the refracting telescope has been superseded by the reflecting telescope, which allows larger apertures. A refractor's magnification is calculated by dividing the focal length of the objective lens by that of the eyepiece.Refracting telescopes typically have a lens at the front, then a long tube, then an eyepiece or instrumentation at the rear, where the telescope view comes to focus. Originally, telescopes had an objective of one element, but a century later, two and even three element lenses were made.\nRefracting telescope is a technology that has often been applied to other optical devices, such as binoculars and zoom lenses/telephoto lens/long-focus lens.\n\n\n== Invention ==\n\nRefractors were the earliest type of optical telescope. The first record of a refracting telescope appeared in the Netherlands about 1608, when a spectacle maker from Middelburg named Hans Lippershey unsuccessfully tried to patent one. News of the patent spread fast and Galileo Galilei, happening to be in Venice in the month of May 1609, heard of the invention, constructed a version of his own, and applied it to making astronomical discoveries.\n\n\n== Refracting telescope designs ==\n\nAll refracting telescopes use the same principles. The combination of an objective lens 1 and some type of eyepiece 2 is used to gather more light than the human eye is able to collect on its own, focus it 5, and present the viewer with a brighter, clearer, and magnified virtual image 6.\nThe objective in a refracting telescope refracts or bends light. This refraction causes parallel light rays to converge at a focal point; while those not parallel converge upon a focal plane. The telescope converts a bundle of parallel rays to make an angle \u03b1, with the optical axis to a second parallel bundle with angle \u03b2. The ratio \u03b2/\u03b1 is called the angular magnification. It equals the ratio between the retinal image sizes obtained with and without the telescope.Refracting telescopes can come in many different configurations to correct for image orientation and types of aberration. Because the image was formed by the bending of light, or refraction, these telescopes are called refracting telescopes or refractors.\n\n\n=== Galilean telescope ===\n\nThe design Galileo Galilei used c.\u20091609 is commonly called a Galilean telescope. It used a convergent (plano-convex) objective lens and a divergent (plano-concave) eyepiece lens (Galileo, 1610). A Galilean telescope, because the design has no intermediary focus, results in a non-inverted and, with the help of some devices, an upright image.Galileo's most powerful telescope, with a total length of 980 millimetres (3 ft 3 in), magnified objects about 30 times. Galileo had to work with the poor lens technology of the time, and found he had to use aperture stops to reduce the diameter of the objective lens (increase it focal ratio) to limit aberrations, so his telescope produced blurry and distorted images with a narrow field of view. Despite these flaws, the telescope was still good enough for Galileo to explore the sky. He used it to view craters on the Moon, the four largest moons of Jupiter, and the phases of Venus.Parallel rays of light from a distant object (y) would be brought to a focus in the focal plane of the objective lens (F\u2032 L1 / y\u2032). The (diverging) eyepiece (L2) lens intercepts these rays and renders them parallel once more. Non-parallel rays of light from the object traveling at an angle \u03b11 to the optical axis travel at a larger angle (\u03b12 > \u03b11)  after they passed through the eyepiece. This leads to an increase in the apparent angular size and is responsible for the perceived magnification.\nThe final image (y\u2033) is a virtual image, located at infinity and is the same way up as the object.\n\n\n=== Keplerian telescope ===\n\nThe Keplerian telescope, invented by Johannes Kepler in 1611, is an improvement on Galileo's design. It uses a convex lens as the eyepiece instead of Galileo's concave one. The advantage of this arrangement is that the rays of light emerging from the eyepiece are converging. This allows for a much wider field of view and greater eye relief, but the image for the viewer is inverted. Considerably higher magnifications can be reached with this design, but, like the Galilean telescope, it still uses simple single element objective lens so needs to have a very high focal ratio to reduce aberrations (Johannes Hevelius built an unwieldy f/225 telescope with a 200-millimetre (8 in) objective and a 46-metre (150 ft) focal length, and even longer tubeless \"aerial telescopes\" were constructed). The design also allows for use of a micrometer at the focal plane (to determine the angular size and/or distance between objects observed).\nHuygens built an aerial telescope for Royal Society of London with a 19 cm (7.5\u2033)  single-element lens.\n\n\n=== Achromatic refractors ===\n\nThe next major step in the evolution of refracting telescopes was the invention of the achromatic lens, a lens with multiple elements that helped solve problems with chromatic aberration and allowed shorter focal lengths. It was invented in 1733 by an English barrister named Chester Moore Hall, although it was independently invented and patented by John Dollond around 1758. The design overcame the need for very long focal lengths in refracting telescopes by using an objective made of two pieces of glass with different dispersion, 'crown' and 'flint glass', to reduce chromatic and spherical aberration. Each side of each piece is ground and polished, and then the two pieces are assembled together. Achromatic lenses are corrected to bring two wavelengths (typically red and blue) into focus in the same plane.\nChester More Hall is noted as having made the first twin color corrected lens in 1730.Dollond achromats were quite popular in the 18th century. A major appeal was they could be made shorter. However, problems with glass making meant that the glass objectives were not made more than about four inches in diameter.In the late 19th century, the Swiss optician Pierre-Louis Guinand developed a way to make higher quality glass blanks of greater than four inches. He passed this technology to his apprentice Joseph von Fraunhofer, who further developed this technology and also developed the Fraunhofer doublet lens design. The breakthrough in glass making techniques led to the great refractors of the 19th century, that became progressively larger through the decade, eventually reaching over 1 meter by the end of that century before being superseded by silvered-glass reflecting telescopes in astronomy.\nNoted lens makers of the 19th century include:\n\nAlvan Clark\nBrashear\nChance Brothers\nCauchoix\nFraunhofer\nGautier\nGrubb\nHenry Brothers\nLerebours\nTulleySome famous 19th century doublet refractors are the James Lick telescope (91 cm/36 in) and the Greenwich 28 inch refractor (71 cm). An example of an older refractor is the Shuckburgh telescope (dating to the late 1700s). A famous refractor was the \"Trophy Telescope\", presented at the 1851 Great Exhibition in London. The era of the 'great refractors' in the 19th century saw large achromatic lenses, culminating with the largest achromatic refractor ever built, the Great Paris Exhibition Telescope of 1900.\nIn the Royal Observatory, Greenwich an 1838 instrument named the Sheepshanks telescope includes an objective by Cauchoix. The Sheepshanks had a 6.7 inches (17 cm) wide lens, and was the biggest telescope at Greenwich for about twenty years.\nAn 1840 report from the Observatory noted of the then-new Sheepshanks telescope with the Cauchoix doublet:The power and general goodness of this telescope make it a most welcome addition to the instruments of the observatoryIn the 1900s a noted optics maker was Zeiss. An example of prime achievements of refractors, over 7 million people have been able to view through the 12-inch Zeiss refractor at Griffith Observatory since its opening in 1935; this is the most people to have viewed through any telescope.Achromats were popular in astronomy for making star catalogs, and they required less maintenance than metal mirrors. Some famous discoveries using achromats are the planet Neptune and the Moons of Mars.\nThe long achromats, despite having smaller aperture than the larger reflectors, were often favoured for \"prestige\" observatories. In the late 18th century, every few years, a larger and longer refractor would debut.\nFor example, the Nice Observatory debuted with 77-centimetre (30.31 in) refractor, the largest at the time, but was surpassed within only a couple of years.\n\n\n=== Apochromatic refractors ===\n\nApochromatic refractors have objectives built with special, extra-low dispersion materials. They are designed to bring three wavelengths (typically red, green, and blue) into focus in the same plane. The residual color error (tertiary spectrum) can be down to an order of magnitude less than that of an achromatic lens. Such telescopes contain elements of fluorite or special, extra-low dispersion (ED) glass in the objective and produce a very crisp image that is virtually free of chromatic aberration. Due to the special materials needed in the fabrication, apochromatic refractors are usually more expensive than telescopes of other types with a comparable aperture.\nIn the 18th century, Dollond, a popular maker of doublet telescopes, also made a triplet, although they were not really as popular as the two element telescopes.One of the famous triplet objectives is the Cooke triplet, noted for being able to correct the Seidal aberrations. It is recognized as one of the most important objective designs in the field of photography. The Cooke triplet can correct, with only three elements, for one wavelength, spherical aberration, coma, astigmatism, field curvature, and distortion.\n\n\n== Technical considerations ==\n\nRefractors suffer from residual chromatic and spherical aberration. This affects shorter focal ratios more than longer ones. A 100 mm (4 in) f/6 achromatic refractor is likely to show considerable color fringing (generally a purple halo around bright objects). A 100 mm (4 in) f/16 has little color fringing.\nIn very large apertures, there is also a problem of lens sagging, a result of gravity deforming glass. Since a lens can only be held in place by its edge, the center of a large lens sags due to gravity, distorting the images it produces. The largest practical lens size in a refracting telescope is around 1 meter (39 in).There is a further problem of glass defects, striae or small air bubbles trapped within the glass. In addition, glass is opaque to certain wavelengths, and even visible light is dimmed by reflection and absorption when it crosses the air-glass interfaces and passes through the glass itself. Most of these problems are avoided or diminished in reflecting telescopes, which can be made in far larger apertures and which have all but replaced refractors for astronomical research.\nThe ISS-WAC on the Voyager 1/2 used a 6 cm (2.36\u2033) lens, launched into space in the late 1970s, an example of the use of refractors in space.\n\n\n== Applications and achievements ==\n\nRefracting telescopes were noted for their use in astronomy as well as for terrestrial viewing. Many early discoveries of the Solar System were made with singlet refractors.\nThe use of refracting telescopic optics are ubiquitous in photography, and are also used in Earth orbit.\nOne of the more famous applications of the refracting telescope was when Galileo used it to discover the four largest moons of Jupiter in 1609. Furthermore, early refractors were also used several decades later to discover Titan, the largest moon of Saturn, along with three more of Saturn's moons.\nIn the 19th century, refracting telescopes were used for pioneering work on astrophotography and spectroscopy, and the related instrument, the heliometer, was used to calculate the distance to another star for the first time. Their modest apertures did not lead to as many discoveries and typically so small in aperture that many astronomical objects were simply not observeable until the advent of long-exposure photography, by which time the reputation and quirks of reflecting telescopes were beginning to exceed those of the refractors. Despite this, some discoveries include the Moons of Mars, a fifth Moon of Jupiter, and many double star discoveries including Sirius (the Dog star). Refactors were often used for positional astronomy, besides from the other uses in photography and terrestrial viewing.\n\nSinglets\nThe Galilean moons and many other moons of the solar system, were discovered with single-element objectives and aerial telescopes.\nGalileo Galilei's discovered the Galilean satellites of Jupiter in 1610 with a refracting telescope.The planet Saturn's moon, Titan, was discovered on March 25, 1655, by the Dutch astronomer Christiaan Huygens.Doublets\nIn 1861, the brightest star in the night sky, Sirius, was found to have smaller stellar companion using the 18 and half-inch Dearborn refracting telescope.\nBy the 18th century refractors began to have major competition from reflectors, which could be made quite large and did not normally suffer from the same inherent problem with chromatic aberration. Nevertheless, the astronomical community continued to use doublet refractors of modest aperture in comparison to modern instruments. Noted discoveries include the Moons of Mars and a fifth moon of Jupiter, Amalthea.\nAsaph Hall discovered Deimos on 12 August 1877 at about 07:48 UTC and Phobos on 18 August 1877, at the US Naval Observatory in Washington, D.C., at about 09:14 GMT (contemporary sources, using the pre-1925 astronomical convention that began the day at noon, give the time of discovery as 11 August 14:40 and 17 August 16:06 Washington mean time respectively).The telescope used for the discovery was the 26-inch (66 cm) refractor (telescope with a lens) then located at Foggy Bottom. In 1893 the lens was remounted and put in a new dome, where it remains into the 21st century.Jupiter's moon Amalthea was discovered on 9 September 1892, by Edward Emerson Barnard using the 36 inches (91 cm) refractor telescope at Lick Observatory. It was discovered by direct visual observation with the doublet-lens refractor.In 1904, one of the discoveries made using Great Refractor of Potsdam (a double telescope with two doublets) was of the interstellar medium. The astronomer Professor Hartmann determined from observations of the binary star Mintaka in Orion, that there was the element calcium in the intervening space.\nTripletsPlanet Pluto was discovered by looking at photographs (i.e. 'plates' in astronomy vernacular) in a blink comparator taken with a refracting telescope, an astrograph with a 3 element 13-inch lens.\n\n\n== List of the largest refracting telescopes ==\n\nExamples of some of the largest achromatic refracting telescopes, over 60 cm (24 in) diameter.\n\nGreat Paris Exhibition Telescope of 1900 (1.25 m or 49 in) \u2013 dismantled after exhibition\nYerkes Observatory (101.6 cm or 40 in)\nSwedish 1-m Solar Telescope (98 cm or 39 in)\nLick Observatory (91 cm or 36 in)\nParis Observatory Meudon Great Refractor (83 cm (33 in), + 62 cm (24 in))\nPotsdam Great Refractor (80 cm (31 in), + 50 cm (20 in))\nNice Observatory (77 cm or 30 in)\nJohn Wall (76.20 cm or 30 in) dialyte refracting telescope - the largest refractor built by an individual, at Hanwell Community Observatory\n28-inch Grubb Refractor at Royal Greenwich Observatory, (71 cm or 28 in) aperture lens\nGreat Refractor of Vienna Observatory, (69 cm or 27 in)\nArchenhold Observatory \u2013 the longest refracting telescope ever built (68 cm or 27 in \u00d7 21 m or 69 ft focal length)\nUnited States Naval Observatory refractor, (66 cm or 26 in)\nNewall refractor at the National Observatory of Athens (62.5 cm or 24.6 in)\nLowell Observatory (61 cm or 24 in)\n\n\n== See also ==\nAstrograph\nBaden-Powell's unilens\nCatadioptric telescopes\nList of largest optical refracting telescopes\nList of largest optical telescopes historically\nList of telescope types\nReflecting telescope\nStar diagonal\nHeliometer\n\n\n== Further reading ==\nThe optical work of Charles Tulley\n\n\n== References ==\n\n\n== External links ==\n\nnasa.gov \u2013 Build a Telescope\nMaking a Galilean Telescope\nAngular and Linear Fields of View of Galilean Telescopes and Telemicroscopes\nRefracting telescopes\nIntroduction to Galileo's Telescope", "Electric_current": "An electric current is a stream of charged particles, such as electrons or ions, moving through an electrical conductor or space. It is measured as the net rate of flow of electric charge through a surface or into a control volume.:\u200a2\u200a:\u200a622\u200a The moving particles are called charge carriers, which may be one of several types of particles, depending on the conductor.  In electric circuits the charge carriers are often electrons moving through a wire. In semiconductors they can be electrons or holes. In an electrolyte the charge carriers are ions, while in plasma, an ionized gas, they are ions and electrons.The SI unit of electric current is the ampere, or amp, which is the flow of electric charge across a surface at the rate of one coulomb per second. The ampere (symbol: A) is an SI base unit.:\u200a15\u200a Electric current is measured using a device called an ammeter.:\u200a788\u200aElectric currents create magnetic fields, which are used in motors, generators, inductors, and transformers. In ordinary conductors, they cause Joule heating, which creates light in incandescent light bulbs. Time-varying currents emit electromagnetic waves, which are used in telecommunications to broadcast information.\n\n\n== Symbol ==\nThe conventional symbol for current is I, which originates from the French phrase intensit\u00e9 du courant, (current intensity). Current intensity is often referred to simply as current.  The I symbol was used by Andr\u00e9-Marie Amp\u00e8re, after whom the unit of electric current is named, in formulating Amp\u00e8re's force law (1820).  The notation travelled from France to Great Britain, where it became standard, although at least one journal did not change from using C to I until 1896.\n\n\n== Conventions ==\n\nThe conventional direction of current, also known as conventional current,  is arbitrarily defined as the direction in which positive charges flow. In a conductive material, the moving charged particles that constitute the electric current are called charge carriers. In metals, which make up the wires and other conductors in most electrical circuits, the positively charged atomic nuclei of the atoms are held in a fixed position, and the negatively charged electrons are the charge carriers, free to move about in the metal. In other materials, notably the semiconductors, the charge carriers can be positive or negative, depending on the dopant used. Positive and negative charge carriers may even be present at the same time, as happens in an electrolyte in an electrochemical cell.\nA flow of positive charges gives the same electric current, and has the same effect in a circuit, as an equal flow of negative charges in the opposite direction. Since current can be the flow of either positive or negative charges, or both, a convention is needed for the direction of current that is independent of the type of charge carriers. Negatively charged carriers, such as the electrons (the charge carriers in metal wires and many other electronic circuit components), therefore flow in the opposite direction of conventional current flow in an electrical circuit.\n\n\n=== Reference direction ===\nA current in a wire or circuit element can flow in either of two directions.  When defining a variable \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   to represent the current, the direction representing positive current must be specified, usually by an arrow on the circuit schematic diagram.:\u200a13\u200a  This is called the reference direction of the current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  .  When analyzing electrical circuits, the actual direction of current through a specific circuit element is usually unknown until the analysis is completed. Consequently, the reference directions of currents are often assigned arbitrarily. When the circuit is solved, a negative value for the current implies the actual direction of current through that circuit element is opposite that of the chosen reference direction.:\u200a29\u200a\n\n\n== Ohm's law ==\n\nOhm's law states that the current through a conductor between two points is directly proportional to the potential difference across the two points.  Introducing the constant of proportionality, the resistance, one arrives at the usual mathematical equation that describes this relationship:\nwhere I is the current through the conductor in units of amperes, V is the potential difference measured across the conductor in units of volts,  and R is the resistance of the conductor in units of ohms.  More specifically, Ohm's law states that the R in this relation is constant, independent of the current.\n\n\n== Alternating and direct current ==\n\nIn alternating current (AC) systems, the movement of electric charge periodically reverses direction. AC is the form of electric power most commonly delivered to businesses and residences. The usual waveform of an AC power circuit is a sine wave, though certain applications use alternative waveforms, such as triangular or square waves. Audio and radio signals carried on electrical wires are also examples of alternating current. An important goal in these applications is recovery of information encoded (or modulated) onto the AC signal.\nIn contrast, direct current (DC) refers to a system in which the movement of electric charge in only one direction (sometimes called unidirectional flow). Direct current is produced by sources such as batteries, thermocouples, solar cells, and commutator-type electric machines of the dynamo type. Alternating current can also be converted to direct current through use of a rectifier. Direct current may flow in a conductor such as a wire, but can also flow through semiconductors, insulators, or even through a vacuum as in electron or ion beams. An old name for direct current was galvanic current.\n\n\n== Occurrences ==\nNatural observable examples of electric current include lightning, static electric discharge, and the solar wind, the source of the polar auroras.\nMan-made occurrences of electric current include the flow of conduction electrons in metal wires such as the overhead power lines that deliver electrical energy across long distances and the smaller wires within electrical and electronic equipment. Eddy currents are electric currents that occur in conductors exposed to changing magnetic fields. Similarly, electric currents occur, particularly in the surface, of conductors exposed to electromagnetic waves. When oscillating electric currents flow at the correct voltages within radio antennas, radio waves are generated.\nIn electronics, other forms of electric current include the flow of electrons through resistors or through the vacuum in a vacuum tube, the flow of ions inside a battery, and the flow of holes within metals and semiconductors.  \nA biological example of current is the flow of ions in neurons and nerves, responsible for both thought and sensory perception.\n\n\n== Measurement ==\nCurrent can be measured using an ammeter.\nElectric current can be directly measured with a galvanometer, but this method involves breaking the electrical circuit, which is sometimes inconvenient. \nCurrent can also be measured without breaking the circuit by detecting the magnetic field associated with the current. \nDevices, at the circuit level, use various techniques to measure current:\n\nShunt resistors\nHall effect current sensor transducers\nTransformers (however DC cannot be measured)\nMagnetoresistive field sensors\nRogowski coils\nCurrent clamps\n\n\n== Resistive heating ==\n\nJoule heating, also known as ohmic heating and resistive heating, is the process of power dissipation:\u200a36\u200a by which the passage of an electric current through a conductor increases the internal energy of the conductor,:\u200a846\u200a converting thermodynamic work into heat.:\u200a846,\u200afn. 5\u200a The phenomenon was first studied by James Prescott Joule in 1841. Joule immersed a length of wire in a fixed mass of water and measured the temperature rise due to a known current through the wire for a 30 minute period. By varying the current and the length of the wire he deduced that the heat produced was proportional to the square of the current multiplied by the electrical resistance of the wire.\n\nThis relationship is known as Joule's Law.:\u200a36\u200a The SI unit of energy was subsequently named the joule and given the symbol J.:\u200a20\u200a The commonly known SI unit of power, the watt (symbol: W), is equivalent to one joule per second.:\u200a20\u200a\n\n\n== Electromagnetism ==\n\n\n=== Electromagnet ===\n\nIn an electromagnet a coil of wires behaves like a magnet when an electric current flows through it. When the current is switched off, the coil loses its magnetism immediately.\nElectric current produces a magnetic field.  The magnetic field can be visualized as a pattern of circular field lines surrounding the wire that persists as long as there is current.\n\n\n=== Electromagnetic induction ===\n\nMagnetic fields can also be used to make electric currents. When a changing magnetic field is applied to a conductor, an electromotive force (EMF) is induced,:\u200a1004\u200a which starts an electric current, when there is a suitable path.\n\n\n=== Radio waves ===\n\nWhen an electric current flows in a suitably shaped conductor at radio frequencies, radio waves can be generated. These travel at the speed of light and can cause electric currents in distant conductors.\n\n\n== Conduction mechanisms in various media ==\n\nIn metallic solids, electric charge flows by means of electrons, from lower to higher electrical potential. In other media, any stream of charged objects (ions, for example) may constitute an electric current.  To provide a definition of current independent of the type of charge carriers, conventional current is defined as moving in the same direction as the positive charge flow. So, in metals where the charge carriers (electrons) are negative, conventional current is in the opposite direction to the overall electron movement.  In conductors where the charge carriers are positive, conventional current is in the same direction as the charge carriers.\nIn a vacuum, a beam of ions or electrons may be formed. In other conductive materials, the electric current is due to the flow of both positively and negatively charged particles at the same time. In still others, the current is entirely due to positive charge flow. For example, the electric currents in electrolytes are flows of positively and negatively charged ions. In a common lead-acid electrochemical cell, electric currents are composed of positive hydronium ions flowing in one direction, and negative sulfate ions flowing in the other. Electric currents in sparks or plasma are flows of electrons as well as positive and negative ions. In ice and in certain solid electrolytes, the electric current is entirely composed of flowing ions.\n\n\n=== Metals ===\nIn a metal, some of the outer electrons in each atom are not bound to the individual molecules as they are in molecular solids, or in full bands as they are in insulating materials, but are free to move within the metal lattice. These conduction electrons can serve as charge carriers, carrying a current. Metals are particularly conductive because there are many of these free electrons. With no external electric field applied, these electrons move about randomly due to thermal energy but, on average, there is zero net current within the metal. At room temperature, the average speed of these random motions is 106 metres per second. Given a surface through which a metal wire passes, electrons move in both directions across the surface at an equal rate. As George Gamow wrote in his popular science book, One, Two, Three...Infinity (1947), \"The metallic substances differ from all other materials by the fact that the outer shells of their atoms are bound rather loosely, and often let one of their electrons go free. Thus the interior of a metal is filled up with a large number of unattached electrons that travel aimlessly around like a crowd of displaced persons. When a metal wire is subjected to electric force applied on its opposite ends, these free electrons rush in the direction of the force, thus forming what we call an electric current.\"\nWhen a metal wire is connected across the two terminals of a DC voltage source such as a battery, the source places an electric field across the conductor. The moment contact is made, the free electrons of the conductor are forced to drift toward the positive terminal under the influence of this field. The free electrons are therefore the charge carrier in a typical solid conductor.\nFor a steady flow of charge through a surface, the current I (in amperes) can be calculated with the following equation:\n\nwhere Q is the electric charge transferred through the surface over a time t.  If Q and t are measured in coulombs and seconds respectively, I is in amperes.\nMore generally, electric current can be represented as the rate at which charge flows through a given surface as:\n\n\n=== Electrolytes ===\n\nElectric currents in electrolytes are flows of electrically charged particles (ions). For example, if an electric field is placed across a solution of Na+ and Cl\u2212 (and conditions are right) the sodium ions move towards the negative electrode (cathode), while the chloride ions move towards the positive electrode (anode). Reactions take place at both electrode surfaces, neutralizing each ion.\nWater-ice and certain solid electrolytes called proton conductors contain positive hydrogen ions (\"protons\") that are mobile. In these materials, electric currents are composed of moving protons, as opposed to the moving electrons in metals.\nIn certain electrolyte mixtures, brightly coloured ions are the moving electric charges. The slow progress of the colour makes the current visible.\n\n\n=== Gases and plasmas ===\nIn air and other ordinary gases below the breakdown field, the dominant source of electrical conduction is via relatively few mobile ions produced by radioactive gases, ultraviolet light, or cosmic rays. Since the electrical conductivity is low, gases are dielectrics or insulators. However, once the applied electric field approaches the breakdown value, free electrons become sufficiently accelerated by the electric field to create additional free electrons by colliding, and ionizing, neutral gas atoms or molecules in a process called avalanche breakdown. The breakdown process forms a plasma that contains enough mobile electrons and positive ions to make it an electrical conductor. In the process, it forms a light emitting conductive path, such as a spark, arc or lightning.\nPlasma is the state of matter where some of the electrons in a gas are stripped or \"ionized\" from their molecules or atoms. A plasma can be formed by high temperature, or by application of a high electric or alternating magnetic field as noted above. Due to their lower mass, the electrons in a plasma accelerate more quickly in response to an electric field than the heavier positive ions, and hence carry the bulk of the current. The free ions recombine to create new chemical compounds (for example, breaking atmospheric oxygen into single oxygen [O2 \u2192 2O], which then recombine creating ozone [O3]).\n\n\n=== Vacuum ===\nSince a \"perfect vacuum\" contains no charged particles, it normally behaves as a perfect insulator. However, metal electrode surfaces can cause a region of the vacuum to become conductive by injecting free electrons or ions through either field electron emission or thermionic emission. Thermionic emission occurs when the thermal energy exceeds the metal's work function, while field electron emission occurs when the electric field at the surface of the metal is high enough to cause tunneling, which results in the ejection of free electrons from the metal into the vacuum. Externally heated electrodes are often used to generate an electron cloud as in the filament or indirectly heated cathode of vacuum tubes. Cold electrodes can also spontaneously produce electron clouds via thermionic emission when small incandescent regions (called cathode spots or anode spots) are formed. These are incandescent regions of the electrode surface that are created by a localized high current. These regions may be initiated by field electron emission, but are then sustained by localized thermionic emission once a vacuum arc forms. These small electron-emitting regions can form quite rapidly, even explosively, on a metal surface subjected to a high electrical field. Vacuum tubes and sprytrons are some of the electronic switching and amplifying devices based on vacuum conductivity.\n\n\n=== Superconductivity ===\n\nSuperconductivity is a phenomenon of exactly zero electrical resistance and expulsion of magnetic fields occurring in certain materials when cooled below a characteristic critical temperature. It was discovered by Heike Kamerlingh Onnes on April 8, 1911 in Leiden. Like ferromagnetism and atomic spectral lines, superconductivity is a quantum mechanical phenomenon. It is characterized by the Meissner effect, the complete ejection of magnetic field lines from the interior of the superconductor as it transitions into the superconducting state. The occurrence of the Meissner effect indicates that superconductivity cannot be understood simply as the idealization of perfect conductivity in classical physics.\n\n\n=== Semiconductor ===\n\nIn a semiconductor it is sometimes useful to think of the current as due to the flow of positive \"holes\" (the mobile positive charge carriers that are places where the semiconductor crystal is missing a valence electron). This is the case in a p-type semiconductor. A semiconductor has electrical conductivity intermediate in magnitude between that of a conductor and an insulator. This means a conductivity roughly in the range of 10\u22122  to 104 siemens per centimeter (S\u22c5cm\u22121).\nIn the classic crystalline semiconductors, electrons can have energies only within certain bands (i.e. ranges of levels of energy). Energetically,  these bands are located between the energy of the ground state, the state in which electrons are tightly bound to the atomic nuclei of the material, and the free electron energy, the latter describing the energy required for an electron to escape entirely from the material. The energy bands each correspond to many discrete quantum states of the electrons, and most of the states with low energy (closer to the nucleus) are occupied, up to a particular band called the valence band. Semiconductors and insulators are distinguished from metals because the valence band in any given metal is nearly filled with electrons under usual operating conditions, while very few (semiconductor) or virtually none (insulator) of them are available in the conduction band, the band immediately above the valence band.\nThe ease of exciting electrons in the semiconductor from the valence band to the conduction band depends on the band gap between the bands. The size of this energy band gap serves as an arbitrary dividing line (roughly 4 eV) between semiconductors and insulators.\nWith covalent bonds, an electron moves by hopping to a neighboring bond. The Pauli exclusion principle requires that the electron be lifted into the higher anti-bonding state of that bond. For delocalized states, for example in one dimension \u2013 that is in a nanowire, for every energy there is a state with electrons flowing in one direction and another state with the electrons flowing in the other. For a net current to flow, more states for one direction than for the other direction must be occupied. For this to occur, energy is required, as in the semiconductor the next higher states lie above the band gap. Often this is stated as: full bands do not contribute to the electrical conductivity. However, as a semiconductor's temperature rises above absolute zero, there is more energy in the semiconductor to spend on lattice vibration and on exciting electrons into the conduction band. The current-carrying electrons in the conduction band are known as free electrons, though they are often simply called electrons if that is clear in context.\n\n\n== Current density and Ohm's law ==\n\nCurrent density is the rate at which charge passes through a chosen unit area.:\u200a31\u200a It is defined as a vector whose magnitude is the current per unit cross-sectional area.:\u200a749\u200a As discussed in Reference direction, the direction is arbitrary. Conventionally, if the moving charges are positive, then the current density has the same sign as the velocity of the charges.  For negative charges, the sign of the current density is opposite to the velocity of the charges.:\u200a749\u200a In SI units, current density (symbol: j) is expressed in the SI base units of amperes per square metre.:\u200a22\u200aIn linear materials such as metals, and under low frequencies, the current density across the conductor surface is uniform. In such conditions, Ohm's law states that the current is directly proportional to the potential difference between two ends (across) of that metal (ideal) resistor (or other ohmic device):\n\nwhere \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the current, measured in amperes; \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the potential difference, measured in volts; and \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   is the resistance, measured in ohms. For alternating currents, especially at higher frequencies, skin effect causes the current to spread unevenly across the conductor cross-section, with higher density near the surface, thus increasing the apparent resistance.\n\n\n== Drift speed ==\nThe mobile charged particles within a conductor move constantly in random directions, like the particles of a gas.  (More accurately, a Fermi gas.) To create a net flow of charge, the particles must also move together with an average drift rate. Electrons are the charge carriers in most metals and they follow an erratic path, bouncing from atom to atom, but generally drifting in the opposite direction of the electric field. The speed they drift at can be calculated from the equation:\n\nwhere\n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the electric current\n\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is number of charged particles per unit volume (or charge carrier density)\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is the cross-sectional area of the conductor\n\n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the drift velocity, and\n\n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   is the charge on each particle.Typically, electric charges in solids flow slowly.  For example, in a copper wire of cross-section 0.5 mm2, carrying a current of 5 A, the drift velocity of the electrons is on the order of a millimetre per second. To take a different example, in the near-vacuum inside a cathode-ray tube, the electrons travel in near-straight lines at about a tenth of the speed of light.\nAny accelerating electric charge, and therefore any changing electric current, gives rise to an electromagnetic wave that propagates at very high speed outside the surface of the conductor.  This speed is usually a significant fraction of the speed of light, as can be deduced from Maxwell's equations, and is therefore many times faster than the drift velocity of the electrons. For example, in AC power lines, the waves of electromagnetic energy propagate through the space between the wires, moving from a source to a distant load, even though the electrons in the wires only move back and forth over a tiny distance.\nThe ratio of the speed of the electromagnetic wave to the speed of light in free space is called the velocity factor, and depends on the electromagnetic properties of the conductor and the insulating materials surrounding it, and on their shape and size.\nThe magnitudes (not the natures) of these three velocities can be illustrated by an analogy with the three similar velocities associated with gases. (See also hydraulic analogy.)\n\nThe low drift velocity of charge carriers is analogous to air motion; in other words, winds.\nThe high speed of electromagnetic waves is roughly analogous to the speed of sound in a gas (sound waves move through air much faster than large-scale motions such as convection)\nThe random motion of charges is analogous to heat \u2013 the thermal velocity of randomly vibrating gas particles.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==", "Transverse_wave": "In physics, a transverse wave is a wave whose oscillations are perpendicular to the direction of the wave's advance. This is in contrast to a longitudinal wave which travels in the direction of its oscillations. Water waves are an example of transverse wave.\nA simple example is given by the waves that can be created on a horizontal length of string by anchoring one end and moving the other end up and down. Another example is the waves that are created on the membrane of a drum. The waves propagate in directions that are parallel to the membrane plane, but each point in the membrane itself gets displaced up and down, perpendicular to that plane. Light is another example of a transverse wave, where the oscillations are the electric and magnetic fields, which point at right angles to the ideal light rays that describe the direction of propagation. \nTransverse waves commonly occur in elastic solids due to the shear stress generated; the oscillations in this case are the displacement of the solid particles away from their relaxed position, in directions perpendicular to the propagation of the wave.  These displacements correspond to a local shear deformation of the material. Hence a transverse wave of this nature is called a shear wave. Since fluids cannot resist shear forces while at rest, propagation of transverse waves inside the bulk of fluids is not possible. In seismology, shear waves are also called secondary waves or S-waves.\nTransverse waves are contrasted with longitudinal waves, where the oscillations occur in the direction of the wave.  The standard example of a longitudinal wave is a sound wave or \"pressure wave\" in gases, liquids, or solids, whose oscillations cause compression and expansion of the material through which the wave is propagating.  Pressure waves are called \"primary waves\", or \"P-waves\" in geophysics.\n\n\n== Mathematical formulation ==\nMathematically, the simplest kind of transverse wave is a plane linearly polarized sinusoidal one.  \"Plane\" here means that the direction of propagation is unchanging and the same over the whole medium; \"linearly polarized\" means that the direction of displacement too is unchanging and the same over the whole medium; and the magnitude of the displacement is a sinusoidal function only of time and of position along the direction of propagation.\nThe motion of such a wave can be expressed mathematically as follows.  Let d be the direction of propagation (a vector with unit length), and o any reference point in the medium.  Let u be the direction of the oscillations (another unit-length vector perpendicular to d).  The displacement of a particle at any point p of the medium and any time t (seconds) will be\n\nwhere A is the wave's amplitude or strength, T is its period, v is the speed of propagation, and \u03c6 is its phase at o.  All these parameters are real numbers. The symbol \"\u2022\" denotes the inner product of two vectors.\nBy this equation, the wave travels in the direction d and the oscillations occur back and forth along the direction u.   The wave is said to be linearly polarized in the direction u.\nAn observer that looks at a fixed point p will see the particle there move in a simple harmonic (sinusoidal) motion with period T seconds, with maximum particle displacement A in each sense; that is, with a frequency of f = 1/T full oscillation cycles every second.  A snapshot of all particles at a fixed time t will show the same displacement for all particles on each plane perpendicular to d, with the displacements in successive planes forming a sinusoidal pattern, with each full cycle extending along d by the wavelength \u03bb = v T = v/f.  The whole pattern moves in the direction d with speed V.\nThe same equation describes a plane linearly polarized sinusoidal light wave, except that the \"displacement\" S(p, t) is the electric field at point p and time t.  (The magnetic field will be described by the same equation, but with a \"displacement\" direction that is perpendicular to both d and u, and a different amplitude.)\n\n\n=== Superposition principle ===\nIn a homogeneous linear medium, complex oscillations (vibrations in a material or light flows) can be described as the superposition of many simple sinusoidal waves, either transverse or longitudinal.\nThe vibrations of a violin string, for example, can be analyzed as the sum of many transverse waves of different frequencies, that displace the string either up or down or left to right.  The ripples in a pond can be analyzed as a combination of transverse and longitudinal waves (gravity waves) that propagate together.\n\n\n=== Circular polarization ===\nIf the medium is linear and allows multiple independent displacement directions for the same travel direction d, we can choose two mutually perpendicular directions of polarization, and express any wave linearly polarized in any other direction as a linear combination (mixing) of those two waves.\nBy combining two waves with same frequency, velocity, and direction of travel, but with different phases and independent displacement directions, one obtains a circularly or elliptically polarized wave.  In such a wave the particles describe circular or elliptical trajectories, instead of moving back and forth.\nIt may help understanding to revisit the thought experiment with a taut string mentioned above. Notice that you can also launch waves on the string by moving your hand to the right and left instead of up and down. This is an important point. There are two independent (orthogonal) directions that the waves can move. (This is true for any two directions at right angles, up and down and right and left are chosen for clarity.) Any waves launched by moving your hand in a straight line are linearly polarized waves. \nBut now imagine moving your hand in a circle. Your motion will launch a spiral wave on the string. You are moving your hand simultaneously both up and down and side to side. The maxima of the side to side motion occur a quarter wavelength (or a quarter of a way around the circle, that is 90 degrees or \u03c0/2 radians) from the maxima of the up and down motion. At any point along the string, the displacement of the string will describe the same circle as your hand, but delayed by the propagation speed of the wave. Notice also that you can choose to move your hand in a clockwise circle or a counter-clockwise circle. These alternate circular motions produce right and left circularly polarized waves. \nTo the extent your circle is imperfect, a regular motion will describe an ellipse, and produce elliptically polarized waves. At the extreme of eccentricity your ellipse will become a straight line, producing linear polarization along the major axis of the ellipse. An elliptical motion can always be decomposed into two orthogonal linear motions of unequal amplitude and 90 degrees out of phase, with circular polarization being the special case where the two linear motions have the same amplitude.\n\n\n=== Power in a transverse wave in string ===\n(Let the linear mass density of the string be \u03bc.)\nThe kinetic energy of a mass element in a transverse wave is given by:\n\nIn one wavelength, kinetic energy\n\nUsing Hooke's law the potential energy in mass element\n\nAnd the potential energy for one wavelength\n\nSo, total energy in one wavelength \n  \n    \n      \n        K\n        +\n        U\n        =\n        \n          \n            1\n            2\n          \n        \n        \u03bc\n        \n          A\n          \n            2\n          \n        \n        \n          \u03c9\n          \n            2\n          \n        \n        \u03bb\n      \n    \n    {\\textstyle K+U={\\frac {1}{2}}\\mu A^{2}\\omega ^{2}\\lambda }\n  \nTherefore average power is \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        \u03bc\n        \n          A\n          \n            2\n          \n        \n        \n          \u03c9\n          \n            2\n          \n        \n        \n          v\n          \n            x\n          \n        \n      \n    \n    {\\textstyle {\\frac {1}{2}}\\mu A^{2}\\omega ^{2}v_{x}}\n  \n\n\n== See also ==\nLongitudinal wave\nLuminiferous aether \u2013 the postulated medium for light waves; accepting that light was a transverse wave prompted a search for evidence of this physical medium\nShear wave splitting\nSinusoidal plane-wave solutions of the electromagnetic wave equation\nTransverse mode\nElastography\nShear-wave elasticity imaging\n\n\n== References ==\n\n\n== External links ==\nInteractive simulation of transverse wave\nWave types explained with high speed film and animations\nWeisstein, Eric Wolfgang (ed.). \"Transverse Wave\". ScienceWorld.\nTransverse and Longitudinal Waves Introductory module on these waves at Connexions", "Strength_of_materials": "The field of strength of materials (also called mechanics of materials) typically refers to various methods of calculating the stresses and strains in structural members, such as beams, columns, and shafts. The methods employed to predict the response of a structure under loading and its susceptibility to various failure modes takes into account the properties of the materials such as its yield strength, ultimate strength, Young's modulus, and Poisson's ratio. In addition, the mechanical element's macroscopic properties (geometric properties) such as its length, width, thickness, boundary constraints and abrupt changes in geometry such as holes are considered. \nThe theory began with the consideration of the behavior of one and two dimensional members of structures, whose states of stress can be approximated as two dimensional, and was then generalized to three dimensions to develop a more complete theory of the elastic and plastic behavior of materials. An important founding pioneer in mechanics of materials was Stephen Timoshenko.\n\n\n== Definition ==\nIn the mechanics of materials, the strength of a material is its ability to withstand an applied load without failure or plastic deformation. The field of strength of materials deals with forces and deformations that result from their acting on a material. A load applied to a mechanical member will induce internal forces within the member called stresses when those forces are expressed on a unit basis. The stresses acting on the material cause deformation of the material in various manners including breaking them completely. Deformation of the material is called strain when those deformations too are placed on a unit basis.\nThe stresses and strains that develop within a mechanical member must be calculated in order to assess the load capacity of that member. This requires a complete description of the geometry of the member, its constraints, the loads applied to the member and the properties of the material of which the member is composed. The applied loads may be axial (tensile or compressive), or rotational (strength shear). With a complete description of the loading and the geometry of the member, the state of stress and state of strain at any point within the member can be calculated. Once the state of stress and strain within the member is known, the strength (load carrying capacity) of that member, its deformations (stiffness qualities), and its stability (ability to maintain its original configuration) can be calculated.\nThe calculated stresses may then be compared to some measure of the strength of the member such as its material yield or ultimate strength. The calculated deflection of the member may be compared to deflection criteria that are based on the member's use. The calculated buckling load of the member may be compared to the applied load. The calculated stiffness and mass distribution of the member may be used to calculate the member's dynamic response and then compared to the acoustic environment in which it will be used.\nMaterial strength refers to the point on the engineering stress\u2013strain curve (yield stress) beyond which the material experiences deformations that will not be completely reversed upon removal of the loading and as a result, the member will have a permanent deflection. The ultimate strength of the material refers to the maximum value of stress reached. The fracture strength is the stress value at fracture (the last stress value recorded).\n\n\n=== Types of loadings ===\nTransverse loadings \u2013 Forces applied perpendicular to the longitudinal axis of a member. Transverse loading causes the member to bend and deflect from its original position, with internal tensile and compressive strains accompanying the change in curvature of the member. Transverse loading also induces shear forces that cause shear deformation of the material and increase the transverse deflection of the member.\nAxial loading \u2013 The applied forces are collinear with the longitudinal axis of the member. The forces cause the member to either stretch or shorten.\nTorsional loading \u2013 Twisting action caused by a pair of externally applied equal and oppositely directed force couples acting on parallel planes or by a single external couple applied to a member that has one end fixed against rotation.\n\n\n=== Stress terms ===\n\nUniaxial stress is expressed by\n\n  \n    \n      \n        \u03c3\n        =\n        \n          \n            F\n            A\n          \n        \n      \n    \n    {\\displaystyle \\sigma ={\\frac {F}{A}}}\n  where F is the force [N] acting on an area A [m2]. The area can be the undeformed area or the deformed area, depending on whether engineering stress or true stress is of interest.\n\nCompressive stress (or compression) is the stress state caused by an applied load that acts to reduce the length of the material (compression member) along the axis of the applied load, it is, in other words, a stress state that causes a squeezing of the material. A simple case of compression is the uniaxial compression induced by the action of opposite, pushing forces. Compressive strength for materials is generally higher than their tensile strength. However, structures loaded in compression are subject to additional failure modes, such as buckling, that are dependent on the member's geometry.\nTensile stress is the stress state caused by an applied load that tends to elongate the material along the axis of the applied load, in other words, the stress caused by pulling the material. The strength of structures of equal cross-sectional area loaded in tension is independent of shape of the cross-section. Materials loaded in tension are susceptible to stress concentrations such as material defects or abrupt changes in geometry. However, materials exhibiting ductile behaviour (most metals for example) can tolerate some defects while brittle materials (such as ceramics) can fail well below their ultimate material strength.\nShear stress is the stress state caused by the combined energy of a pair of opposing forces acting along parallel lines of action through the material, in other words, the stress caused by faces of the material sliding relative to one another. An example is cutting paper with scissors or stresses due to torsional loading.\n\n\n=== Stress parameters for resistance ===\nMaterial resistance can be expressed in several mechanical stress parameters. The term material strength is used when referring to mechanical stress parameters. These are physical quantities with dimension homogeneous to pressure and force per unit surface. The traditional measure unit for strength are therefore MPa in the International System of Units, and the psi between the United States customary units.\nStrength parameters include: yield strength, tensile strength, fatigue strength, crack resistance, and other parameters.\nYield strength is the lowest stress that produces a permanent deformation in a material. In some materials, like aluminium alloys, the point of yielding is difficult to identify, thus it is usually defined as the stress required to cause 0.2% plastic strain. This is called a 0.2% proof stress.Compressive strength is a limit state of compressive stress that leads to failure in a material in the manner of ductile failure (infinite theoretical yield) or brittle failure (rupture as the result of crack propagation, or sliding along a weak plane \u2013 see shear strength).\nTensile strength or ultimate tensile strength is a limit state of tensile stress that leads to tensile failure in the manner of ductile failure (yield as the first stage of that failure, some hardening in the second stage and breakage after a possible \"neck\" formation) or brittle failure (sudden breaking in two or more pieces at a low-stress state). The tensile strength can be quoted as either true stress or engineering stress, but engineering stress is the most commonly used.\nFatigue strength is a more complex measure of the strength of a material that considers several loading episodes in the service period of an object, and is usually more difficult to assess than the static strength measures. Fatigue strength is quoted here as a simple range (\n  \n    \n      \n        \u0394\n        \u03c3\n        =\n        \n          \u03c3\n          \n            \n              m\n              a\n              x\n            \n          \n        \n        \u2212\n        \n          \u03c3\n          \n            \n              m\n              i\n              n\n            \n          \n        \n      \n    \n    {\\displaystyle \\Delta \\sigma =\\sigma _{\\mathrm {max} }-\\sigma _{\\mathrm {min} }}\n  ). In the case of cyclic loading it can be appropriately expressed as an amplitude usually at zero mean stress, along with the number of cycles to failure under that condition of stress.Impact strength is the capability of the material to withstand a suddenly applied load and is expressed in terms of energy. Often measured with the Izod impact strength test or Charpy impact test, both of which measure the impact energy required to fracture a sample. Volume, modulus of elasticity, distribution of forces, and yield strength affect the impact strength of a material. In order for a material or object to have a high impact strength, the stresses must be distributed evenly throughout the object. It also must have a large volume with a low modulus of elasticity and a high material yield strength.\n\n\n=== Strain parameters for resistance ===\nDeformation of the material is the change in geometry created when stress is applied ( as a result of applied forces, gravitational fields, accelerations, thermal expansion, etc.). Deformation is expressed by the displacement field of the material.\nStrain or reduced deformation is a mathematical term that expresses the trend of the deformation change among the material field. Strain is the deformation per unit length. In the case of uniaxial loading the displacement of a specimen (for example a bar element) lead to a calculation of strain expressed as the quotient of the displacement and the original length of the specimen. For 3D displacement fields it is expressed as derivatives of displacement functions in terms of a second order tensor (with 6 independent elements).\nDeflection is a term to describe the magnitude to which a structural element is displaced when subject to an applied load.\n\n\n=== Stress\u2013strain relations ===\n\nElasticity is the ability of a material to return to its previous shape after stress is released. In many materials, the relation between applied stress is directly proportional to the resulting strain (up to a certain limit), and a graph representing those two quantities is a straight line.The slope of this line is known as Young's modulus, or the \"modulus of elasticity.\" The modulus of elasticity can be used to determine the stress\u2013strain relationship in the linear-elastic portion of the stress\u2013strain curve. The linear-elastic region is either below the yield point, or if a yield point is not easily identified on the stress\u2013strain plot it is defined to be between 0 and 0.2% strain, and is defined as the region of strain in which no yielding (permanent deformation) occurs.\nPlasticity or plastic deformation is the opposite of elastic deformation and is defined as unrecoverable strain. Plastic deformation is retained after the release of the applied stress. Most materials in the linear-elastic category are usually capable of plastic deformation. Brittle materials, like ceramics, do not experience any plastic deformation and will fracture under relatively low strain, while ductile materials such as metallics, lead, or polymers will plastically deform much more before a fracture initiation.Consider the difference between a carrot and chewed bubble gum. The carrot will stretch very little before breaking. The chewed bubble gum, on the other hand, will plastically deform enormously before finally breaking.\n\n\n== Design terms ==\nUltimate strength is an attribute related to a material, rather than just a specific specimen made of the material, and as such it is quoted as the force per unit of cross section area (N/m2). The ultimate strength is the maximum stress that a material can withstand before it breaks or weakens. For example, the ultimate tensile strength (UTS) of AISI 1018 Steel is 440 MPa. In Imperial units, the unit of stress is given as lbf/in\u00b2 or pounds-force per square inch. This unit is often abbreviated as psi. One thousand psi is abbreviated ksi.\nA factor of safety is a design criteria that an engineered component or structure must achieve. \n  \n    \n      \n        F\n        S\n        =\n        U\n        T\n        S\n        \n          /\n        \n        R\n      \n    \n    {\\displaystyle FS=UTS/R}\n  , where FS: the factor of safety, R: The applied stress, and UTS: ultimate stress (psi or N/m2)Margin of Safety is also sometimes used to as design criteria. It is defined MS = Failure Load/(Factor of Safety \u00d7 Predicted Load) \u2212 1.\nFor example, to achieve a factor of safety of 4, the allowable stress in an AISI 1018 steel component can be calculated to be \n  \n    \n      \n        R\n        =\n        U\n        T\n        S\n        \n          /\n        \n        F\n        S\n      \n    \n    {\\displaystyle R=UTS/FS}\n   = 440/4 = 110 MPa, or \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   = 110\u00d7106 N/m2. Such allowable stresses are also known as \"design stresses\" or \"working stresses.\"\nDesign stresses that have been determined from the ultimate or yield point values of the materials give safe and reliable results only for the case of static loading. Many machine parts fail when subjected to a non-steady and continuously varying loads even though the developed stresses are below the yield point. Such failures are called fatigue failure. The failure is by a fracture that appears to be brittle with little or no visible evidence of yielding. However, when the stress is kept below \"fatigue stress\" or \"endurance limit stress\", the part will endure indefinitely. A purely reversing or cyclic stress is one that alternates between equal positive and negative peak stresses during each cycle of operation. In a purely cyclic stress, the average stress is zero. When a part is subjected to a cyclic stress, also known as stress range (Sr), it has been observed that the failure of the part occurs after a number of stress reversals (N) even if the magnitude of the stress range is below the material's yield strength. Generally, higher the range stress, the fewer the number of reversals needed for failure.\n\n\n=== Failure theories ===\n\nThere are four failure theories: maximum shear stress theory, maximum normal stress theory, maximum strain energy theory, and maximum distortion energy theory. Out of these four theories of failure, the maximum normal stress theory is only applicable for brittle materials, and the remaining three theories are applicable for ductile materials.\nOf the latter three, the distortion energy theory provides most accurate results in a majority of the stress conditions. The strain energy theory needs the value of Poisson's ratio of the part material, which is often not readily available. The maximum shear stress theory is conservative. For simple unidirectional normal stresses all theories are equivalent, which means all theories will give the same result.\n\nMaximum Shear Stress Theory \u2013 This theory postulates that failure will occur if the magnitude of the maximum shear stress in the part exceeds the shear strength of the material determined from uniaxial testing.\nMaximum Normal Stress Theory \u2013 This theory postulates that failure will occur if the maximum normal stress in the part exceeds the ultimate tensile stress of the material as determined from uniaxial testing. This theory deals with brittle materials only. The maximum tensile stress should be less than or equal to ultimate tensile stress divided by factor of safety. The magnitude of the maximum compressive stress should be less than ultimate compressive stress divided by factor of safety.\nMaximum Strain Energy Theory \u2013 This theory postulates that failure will occur when the strain energy per unit volume due to the applied stresses in a part equals the strain energy per unit volume at the yield point in uniaxial testing.\nMaximum Distortion Energy Theory \u2013 This theory is also known as shear energy theory or von Mises-Hencky theory. This theory postulates that failure will occur when the distortion energy per unit volume due to the applied stresses in a part equals the distortion energy per unit volume at the yield point in uniaxial testing. The total elastic energy due to strain can be divided into two parts: one part causes change in volume, and the other part causes change in shape. Distortion energy is the amount of energy that is needed to change the shape.\nFracture mechanics was established by Alan Arnold Griffith and George Rankine Irwin. This important theory is also known as numeric conversion of toughness of material in the case of crack existence.A material's strength is dependent on its microstructure. The engineering processes to which a material is subjected can alter this microstructure. The variety of strengthening mechanisms that alter the strength of a material includes work hardening, solid solution strengthening, precipitation hardening, and grain boundary strengthening and can be quantitatively and qualitatively explained. Strengthening mechanisms are accompanied by the caveat that some other mechanical properties of the material may degenerate in an attempt to make the material stronger. For example, in grain boundary strengthening, although yield strength is maximized with decreasing grain size, ultimately, very small grain sizes make the material brittle. In general, the yield strength of a material is an adequate indicator of the material's mechanical strength. Considered in tandem with the fact that the yield strength is the parameter that predicts plastic deformation in the material, one can make informed decisions on how to increase the strength of a material depending its microstructural properties and the desired end effect. Strength is expressed in terms of the limiting values of the compressive stress, tensile stress, and shear stresses that would cause failure. The effects of dynamic loading are probably the most important practical consideration of the strength of materials, especially the problem of fatigue. Repeated loading often initiates brittle cracks, which grow until failure occurs. The cracks always start at stress concentrations, especially changes in cross-section of the product, near holes and corners at nominal stress levels far lower than those quoted for the strength of the material.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\n\n\n== External links ==\nFailure theories\nCase studies in structural failure", "Relative_velocity": "The relative velocity \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \u2223\n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\mid A}}\n   (also \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{BA}}\n   or \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            rel\n            \u2061\n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\operatorname {rel} A}}\n  ) is the velocity of an object or observer B in the rest frame of another object or observer A.\n\n\n== Classical mechanics ==\n\n\n=== In one dimension (non-relativistic) ===\n\nWe begin with relative motion in the classical, (or non-relativistic, or  the Newtonian approximation) that all speeds are much less than the speed of light.  This limit is associated with the Galilean transformation.  The figure shows a man on top of a train, at the back edge.  At 1:00 pm he begins to walk forward at a walking speed of 10 km/h (kilometers per hour).  The train is moving at 40 km/h.  The figure depicts the man and train at two different times: first, when the journey began, and also one hour later at 2:00 pm.  The figure suggests that the man is 50 km from the starting point after having traveled (by walking and by train) for one hour.  This, by definition, is 50 km/h, which suggests that the prescription for calculating relative velocity in this fashion is to add the two velocities.\nThe diagram displays clocks and rulers to remind the reader that while the logic behind this calculation seem flawless, it makes false assumptions about how clocks and rulers behave.  (See The train-and-platform thought experiment.) To recognize that this classical model of relative motion violates special relativity, we generalize the example into an equation:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      v\n                      \u2192\n                    \n                  \n                \n                \n                  M\n                  \u2223\n                  E\n                \n              \n              \u23df\n            \n          \n          \n            50 km/h\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    \n                      v\n                      \u2192\n                    \n                  \n                \n                \n                  M\n                  \u2223\n                  T\n                \n              \n              \u23df\n            \n          \n          \n            10 km/h\n          \n        \n        +\n        \n          \n            \n              \n                \n                  \n                    \n                      v\n                      \u2192\n                    \n                  \n                \n                \n                  T\n                  \u2223\n                  E\n                \n              \n              \u23df\n            \n          \n          \n            40 km/h\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\underbrace {{\\vec {v}}_{M\\mid E}} _{\\text{50 km/h}}=\\underbrace {{\\vec {v}}_{M\\mid T}} _{\\text{10 km/h}}+\\underbrace {{\\vec {v}}_{T\\mid E}} _{\\text{40 km/h}},}\n  where:\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            M\n            \u2223\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{M\\mid E}}\n   is the velocity of the Man relative to Earth,\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            M\n            \u2223\n            T\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{M\\mid T}}\n   is the velocity of the Man relative to the Train,\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            T\n            \u2223\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{T\\mid E}}\n   is the velocity of the Train relative to Earth.Fully legitimate expressions for \"the velocity of A relative to B\" include \"the velocity of A with respect to B\" and \"the velocity of A in the coordinate system where B is always at rest\".  The violation of special relativity occurs because this equation for relative velocity falsely predicts that different observers will measure different speeds when observing the motion of light.  \n\n\n=== In two dimensions (non-relativistic) ===\n\nThe figure shows two objects A and B moving at constant velocity.  The equations of motion are:\n\n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            A\n          \n        \n        =\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            A\n            i\n          \n        \n        +\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            A\n          \n        \n        t\n        ,\n      \n    \n    {\\displaystyle {\\vec {r}}_{A}={\\vec {r}}_{Ai}+{\\vec {v}}_{A}t,}\n  \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            B\n          \n        \n        =\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            B\n            i\n          \n        \n        +\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n          \n        \n        t\n        ,\n      \n    \n    {\\displaystyle {\\vec {r}}_{B}={\\vec {r}}_{Bi}+{\\vec {v}}_{B}t,}\n  where the subscript i refers to the initial displacement (at time t equal to zero).  The difference between the two displacement vectors, \n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            B\n          \n        \n        \u2212\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {r}}_{B}-{\\vec {r}}_{A}}\n  , represents the location of B as seen from A.\n\n  \n    \n      \n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            B\n          \n        \n        \u2212\n        \n          \n            \n              \n                r\n                \u2192\n              \n            \n          \n          \n            A\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        r\n                        \u2192\n                      \n                    \n                  \n                  \n                    B\n                    i\n                  \n                \n                \u2212\n                \n                  \n                    \n                      \n                        r\n                        \u2192\n                      \n                    \n                  \n                  \n                    A\n                    i\n                  \n                \n              \n              \u23df\n            \n          \n          \n            initial separation\n          \n        \n        +\n        \n          \n            \n              \n                (\n                \n                  \n                    \n                      \n                        v\n                        \u2192\n                      \n                    \n                  \n                  \n                    B\n                  \n                \n                \u2212\n                \n                  \n                    \n                      \n                        v\n                        \u2192\n                      \n                    \n                  \n                  \n                    A\n                  \n                \n                )\n                t\n              \n              \u23df\n            \n          \n          \n            relative velocity\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\vec {r}}_{B}-{\\vec {r}}_{A}=\\underbrace {{\\vec {r}}_{Bi}-{\\vec {r}}_{Ai}} _{\\text{initial separation}}+\\underbrace {({\\vec {v}}_{B}-{\\vec {v}}_{A})t} _{\\text{relative velocity}}.}\n  Hence:\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \u2223\n            A\n          \n        \n        =\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n          \n        \n        \u2212\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            A\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\mid A}={\\vec {v}}_{B}-{\\vec {v}}_{A}.}\n  After making the substitutions \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            A\n            \n              |\n            \n            C\n          \n        \n        =\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            A\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{A|C}={\\vec {v}}_{A}}\n   and \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \n              |\n            \n            C\n          \n        \n        =\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{B|C}={\\vec {v}}_{B}}\n  , we have:\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \u2223\n            A\n          \n        \n        =\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \u2223\n            C\n          \n        \n        \u2212\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            A\n            \u2223\n            C\n          \n        \n        \u21d2\n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\mid A}={\\vec {v}}_{B\\mid C}-{\\vec {v}}_{A\\mid C}\\Rightarrow }\n     \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \u2223\n            C\n          \n        \n        =\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            B\n            \u2223\n            A\n          \n        \n        +\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            A\n            \u2223\n            C\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\vec {v}}_{B\\mid C}={\\vec {v}}_{B\\mid A}+{\\vec {v}}_{A\\mid C}.}\n  \n\n\n=== Galilean transformation (non-relativistic) ===\nTo construct a theory of relative motion consistent with the theory of special relativity, we must adopt a different convention. Continuing to work in the (non-relativistic)  Newtonian limit we begin with a Galilean transformation in one dimension:\n\n  \n    \n      \n        \n          x\n          \u2032\n        \n        =\n        x\n        \u2212\n        v\n        t\n      \n    \n    {\\displaystyle x'=x-vt}\n  \n\n  \n    \n      \n        \n          t\n          \u2032\n        \n        =\n        t\n      \n    \n    {\\displaystyle t'=t}\n  where x' is the position as seen by a reference frame that is moving at speed, v, in the \"unprimed\" (x) reference frame.  Taking the differential of the first of the two equations above, we have, \n  \n    \n      \n        d\n        \n          x\n          \u2032\n        \n        =\n        d\n        x\n        \u2212\n        v\n        \n        d\n        t\n      \n    \n    {\\displaystyle dx'=dx-v\\,dt}\n  , and what may seem like the obvious statement that \n  \n    \n      \n        d\n        \n          t\n          \u2032\n        \n        =\n        d\n        t\n      \n    \n    {\\displaystyle dt'=dt}\n  , we have:\n\n  \n    \n      \n        \n          \n            \n              d\n              \n                x\n                \u2032\n              \n            \n            \n              d\n              \n                t\n                \u2032\n              \n            \n          \n        \n        =\n        \n          \n            \n              d\n              x\n            \n            \n              d\n              t\n            \n          \n        \n        \u2212\n        v\n      \n    \n    {\\displaystyle {\\frac {dx'}{dt'}}={\\frac {dx}{dt}}-v}\n  To recover the previous expressions for relative velocity, we assume that particle A is following the path defined by dx/dt in the unprimed reference (and hence dx\u2032/dt\u2032 in the primed frame).  Thus \n  \n    \n      \n        d\n        x\n        \n          /\n        \n        d\n        t\n        =\n        \n          v\n          \n            A\n            \u2223\n            O\n          \n        \n      \n    \n    {\\displaystyle dx/dt=v_{A\\mid O}}\n   and \n  \n    \n      \n        d\n        \n          x\n          \u2032\n        \n        \n          /\n        \n        d\n        t\n        =\n        \n          v\n          \n            A\n            \u2223\n            \n              O\n              \u2032\n            \n          \n        \n      \n    \n    {\\displaystyle dx'/dt=v_{A\\mid O'}}\n  , where \n  \n    \n      \n        O\n      \n    \n    {\\displaystyle O}\n   and \n  \n    \n      \n        \n          O\n          \u2032\n        \n      \n    \n    {\\displaystyle O'}\n   refer to motion of A as seen by an observer in the unprimed and primed frame, respectively.  Recall that v is the motion of a stationary object in the primed frame, as seen from the unprimed frame.  Thus we have \n  \n    \n      \n        v\n        =\n        \n          v\n          \n            \n              O\n              \u2032\n            \n            \u2223\n            O\n          \n        \n      \n    \n    {\\displaystyle v=v_{O'\\mid O}}\n  , and:\n\n  \n    \n      \n        \n          v\n          \n            A\n            \u2223\n            \n              O\n              \u2032\n            \n          \n        \n        =\n        \n          v\n          \n            A\n            \u2223\n            O\n          \n        \n        \u2212\n        \n          v\n          \n            \n              O\n              \u2032\n            \n            \u2223\n            O\n          \n        \n        \u21d2\n        \n          v\n          \n            A\n            \u2223\n            O\n          \n        \n        =\n        \n          v\n          \n            A\n            \u2223\n            \n              O\n              \u2032\n            \n          \n        \n        +\n        \n          v\n          \n            \n              O\n              \u2032\n            \n            \u2223\n            O\n          \n        \n        ,\n      \n    \n    {\\displaystyle v_{A\\mid O'}=v_{A\\mid O}-v_{O'\\mid O}\\Rightarrow v_{A\\mid O}=v_{A\\mid O'}+v_{O'\\mid O},}\n  where the latter form has the desired (easily learned) symmetry.\n\n\n== Special relativity ==\n\nAs in classical mechanics, in Special Relativity the relative velocity \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }}\n   is the velocity of an object or observer B in the rest frame of another object or observer A. However, unlike the case of classical mechanics, in Special Relativity, it is generally not the case that\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \u2212\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              A\n              \n                |\n              \n              B\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }=-{\\vec {v}}_{\\mathrm {A|B} }}\n  This peculiar lack of symmetry is related to Thomas precession and the fact that two successive Lorentz transformations rotate the coordinate system.  This rotation has no effect on the magnitude of a vector, and hence relative speed is symmetrical.\n\n  \n    \n      \n        \u2016\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        \u2016\n        =\n        \u2016\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              A\n              \n                |\n              \n              B\n            \n          \n        \n        \u2016\n        =\n        \n          v\n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          v\n          \n            \n              A\n              \n                |\n              \n              B\n            \n          \n        \n      \n    \n    {\\displaystyle \\|{\\vec {v}}_{\\mathrm {B|A} }\\|=\\|{\\vec {v}}_{\\mathrm {A|B} }\\|=v_{\\mathrm {B|A} }=v_{\\mathrm {A|B} }}\n  \n\n\n=== Parallel velocities ===\nIn the case where two objects are traveling in parallel directions, the relativistic formula for relative velocity is similar in form to the formula for addition of relativistic velocities.\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    \n                      v\n                      \u2192\n                    \n                  \n                \n                \n                  \n                    B\n                  \n                \n              \n              \u2212\n              \n                \n                  \n                    \n                      v\n                      \u2192\n                    \n                  \n                \n                \n                  \n                    A\n                  \n                \n              \n            \n            \n              1\n              \u2212\n              \n                \n                  \n                    \n                      \n                        \n                          \n                            v\n                            \u2192\n                          \n                        \n                      \n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \n                        \n                          \n                            v\n                            \u2192\n                          \n                        \n                      \n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                  \n                    c\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }={\\frac {{\\vec {v}}_{\\mathrm {B} }-{\\vec {v}}_{\\mathrm {A} }}{1-{\\frac {{\\vec {v}}_{\\mathrm {A} }{\\vec {v}}_{\\mathrm {B} }}{c^{2}}}}}}\n  The relative speed is given by the formula:\n\n  \n    \n      \n        \n          v\n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          \n            \n              |\n              \n                \n                  \n                    \n                      \n                        v\n                        \u2192\n                      \n                    \n                  \n                  \n                    \n                      B\n                    \n                  \n                \n                \u2212\n                \n                  \n                    \n                      \n                        v\n                        \u2192\n                      \n                    \n                  \n                  \n                    \n                      A\n                    \n                  \n                \n              \n              |\n            \n            \n              1\n              \u2212\n              \n                \n                  \n                    \n                      \n                        \n                          \n                            v\n                            \u2192\n                          \n                        \n                      \n                      \n                        \n                          A\n                        \n                      \n                    \n                    \n                      \n                        \n                          \n                            v\n                            \u2192\n                          \n                        \n                      \n                      \n                        \n                          B\n                        \n                      \n                    \n                  \n                  \n                    c\n                    \n                      2\n                    \n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle v_{\\mathrm {B|A} }={\\frac {\\left|{\\vec {v}}_{\\mathrm {B} }-{\\vec {v}}_{\\mathrm {A} }\\right|}{1-{\\frac {{\\vec {v}}_{\\mathrm {A} }{\\vec {v}}_{\\mathrm {B} }}{c^{2}}}}}}\n  \n\n\n=== Perpendicular velocities ===\nIn the case where two objects are traveling in perpendicular directions, the relativistic relative velocity \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }}\n   is given by the formula:\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    v\n                    \u2192\n                  \n                \n              \n              \n                \n                  B\n                \n              \n            \n            \n              \u03b3\n              \n                \n                  A\n                \n              \n            \n          \n        \n        \u2212\n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              A\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }={\\frac {{\\vec {v}}_{\\mathrm {B} }}{\\gamma _{\\mathrm {A} }}}-{\\vec {v}}_{\\mathrm {A} }}\n  where\n\n  \n    \n      \n        \n          \u03b3\n          \n            \n              A\n            \n          \n        \n        =\n        \n          \n            1\n            \n              1\n              \u2212\n              \n                \n                  (\n                  \n                    \n                      \n                        v\n                        \n                          \n                            A\n                          \n                        \n                      \n                      c\n                    \n                  \n                  )\n                \n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\gamma _{\\mathrm {A} }={\\frac {1}{\\sqrt {1-\\left({\\frac {v_{\\mathrm {A} }}{c}}\\right)^{2}}}}}\n  The relative speed is given by the formula\n\n  \n    \n      \n        \n          v\n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          \n            \n              \n                c\n                \n                  4\n                \n              \n              \u2212\n              \n                (\n                \n                  \n                    c\n                    \n                      2\n                    \n                  \n                  \u2212\n                  \n                    v\n                    \n                      \n                        A\n                      \n                    \n                    \n                      2\n                    \n                  \n                \n                )\n              \n              \n                (\n                \n                  \n                    c\n                    \n                      2\n                    \n                  \n                  \u2212\n                  \n                    v\n                    \n                      \n                        B\n                      \n                    \n                    \n                      2\n                    \n                  \n                \n                )\n              \n            \n            c\n          \n        \n      \n    \n    {\\displaystyle v_{\\mathrm {B|A} }={\\frac {\\sqrt {c^{4}-\\left(c^{2}-v_{\\mathrm {A} }^{2}\\right)\\left(c^{2}-v_{\\mathrm {B} }^{2}\\right)}}{c}}}\n  \n\n\n=== General case ===\nThe general formula for the relative velocity \n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }}\n   of an object or observer B in the rest frame of another object or observer A is given by the formula:\n\n  \n    \n      \n        \n          \n            \n              \n                v\n                \u2192\n              \n            \n          \n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          \n            1\n            \n              \n                \u03b3\n                \n                  \n                    A\n                  \n                \n              \n              \n                (\n                \n                  1\n                  \u2212\n                  \n                    \n                      \n                        \n                          \n                            \n                              \n                                v\n                                \u2192\n                              \n                            \n                          \n                          \n                            \n                              A\n                            \n                          \n                        \n                        \n                          \n                            \n                              \n                                v\n                                \u2192\n                              \n                            \n                          \n                          \n                            \n                              B\n                            \n                          \n                        \n                      \n                      \n                        c\n                        \n                          2\n                        \n                      \n                    \n                  \n                \n                )\n              \n            \n          \n        \n        \n          [\n          \n            \n              \n                \n                  \n                    v\n                    \u2192\n                  \n                \n              \n              \n                \n                  B\n                \n              \n            \n            \u2212\n            \n              \n                \n                  \n                    v\n                    \u2192\n                  \n                \n              \n              \n                \n                  A\n                \n              \n            \n            +\n            \n              \n                \n                  \n                    v\n                    \u2192\n                  \n                \n              \n              \n                \n                  A\n                \n              \n            \n            (\n            \n              \u03b3\n              \n                \n                  A\n                \n              \n            \n            \u2212\n            1\n            )\n            \n              (\n              \n                \n                  \n                    \n                      \n                        \n                          \n                            \n                              v\n                              \u2192\n                            \n                          \n                        \n                        \n                          \n                            A\n                          \n                        \n                      \n                      \u22c5\n                      \n                        \n                          \n                            \n                              v\n                              \u2192\n                            \n                          \n                        \n                        \n                          \n                            B\n                          \n                        \n                      \n                    \n                    \n                      v\n                      \n                        \n                          A\n                        \n                      \n                      \n                        2\n                      \n                    \n                  \n                \n                \u2212\n                1\n              \n              )\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle {\\vec {v}}_{\\mathrm {B|A} }={\\frac {1}{\\gamma _{\\mathrm {A} }\\left(1-{\\frac {{\\vec {v}}_{\\mathrm {A} }{\\vec {v}}_{\\mathrm {B} }}{c^{2}}}\\right)}}\\left[{\\vec {v}}_{\\mathrm {B} }-{\\vec {v}}_{\\mathrm {A} }+{\\vec {v}}_{\\mathrm {A} }(\\gamma _{\\mathrm {A} }-1)\\left({\\frac {{\\vec {v}}_{\\mathrm {A} }\\cdot {\\vec {v}}_{\\mathrm {B} }}{v_{\\mathrm {A} }^{2}}}-1\\right)\\right]}\n  where\n\n  \n    \n      \n        \n          \u03b3\n          \n            \n              A\n            \n          \n        \n        =\n        \n          \n            1\n            \n              1\n              \u2212\n              \n                \n                  (\n                  \n                    \n                      \n                        v\n                        \n                          \n                            A\n                          \n                        \n                      \n                      c\n                    \n                  \n                  )\n                \n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\gamma _{\\mathrm {A} }={\\frac {1}{\\sqrt {1-\\left({\\frac {v_{\\mathrm {A} }}{c}}\\right)^{2}}}}}\n  The relative speed is given by the formula\n\n  \n    \n      \n        \n          v\n          \n            \n              B\n              \n                |\n              \n              A\n            \n          \n        \n        =\n        \n          \n            1\n            \u2212\n            \n              \n                \n                  \n                    (\n                    \n                      \n                        c\n                        \n                          2\n                        \n                      \n                      \u2212\n                      \n                        v\n                        \n                          \n                            A\n                          \n                        \n                        \n                          2\n                        \n                      \n                    \n                    )\n                  \n                  \n                    (\n                    \n                      \n                        c\n                        \n                          2\n                        \n                      \n                      \u2212\n                      \n                        v\n                        \n                          \n                            B\n                          \n                        \n                        \n                          2\n                        \n                      \n                    \n                    )\n                  \n                \n                \n                  \n                    (\n                    \n                      \n                        c\n                        \n                          2\n                        \n                      \n                      \u2212\n                      \n                        \n                          \n                            \n                              v\n                              \u2192\n                            \n                          \n                        \n                        \n                          \n                            A\n                          \n                        \n                      \n                      \u22c5\n                      \n                        \n                          \n                            \n                              v\n                              \u2192\n                            \n                          \n                        \n                        \n                          \n                            B\n                          \n                        \n                      \n                    \n                    )\n                  \n                  \n                    2\n                  \n                \n              \n            \n          \n        \n        \u22c5\n        c\n      \n    \n    {\\displaystyle v_{\\mathrm {B|A} }={\\sqrt {1-{\\frac {\\left(c^{2}-v_{\\mathrm {A} }^{2}\\right)\\left(c^{2}-v_{\\mathrm {B} }^{2}\\right)}{\\left(c^{2}-{\\vec {v}}_{\\mathrm {A} }\\cdot {\\vec {v}}_{\\mathrm {B} }\\right)^{2}}}}}\\cdot c}\n  \n\n\n== See also ==\nDoppler effect\nNon-Euclidean geometry \u00a7 Kinematic geometries\nPeculiar velocity\nProper motion\nRange rate\nRadial velocity\nRapidity\nRelativistic speed\nSpace velocity (astronomy)\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nAlonso & Finn, Fundamental University Physics ISBN 0-201-56518-8\nGreenwood, Donald T, Principles of Dynamics.\nGoodman and Warner, Dynamics.\nBeer and Johnston, Statics and Dynamics.\nMcGraw Hill Dictionary of Physics and Mathematics.\nRindler, W., Essential Relativity.\nKHURMI R.S., Mechanics, Engineering Mechanics, Statics, Dynamics\n\n\n== External links ==\nRelative Motion at HyperPhysics\nA Java applet illustrating Relative Velocity, by Andrew Duffy\nRelat\u00edv mozg\u00e1s (1)...(3) Relative motion of two train (1)...(3). Videos on the portal FizKapu. (in Hungarian)\nSebess\u00e9gek \u00f6sszegz\u00e9se Relative tranquility of trout in creek. Video on the portal FizKapu. (in Hungarian)", "Resonance_(particle_physics)": "In particle physics, a resonance is the peak located around a certain energy found in differential cross sections of scattering experiments. These peaks are associated with subatomic particles, which include a variety of bosons, quarks and hadrons (such as nucleons, delta baryons or upsilon mesons) and their excitations. In common usage, \"resonance\" only describes particles with very short lifetimes, mostly high-energy hadrons existing for 10\u221223 seconds or less.The width of the resonance (\u0393) is related to the mean lifetime (\u03c4) of the particle (or its excited state) by the relation\n\n  \n    \n      \n        \u0393\n        =\n        \n          \n            \u210f\n            \u03c4\n          \n        \n      \n    \n    {\\displaystyle \\Gamma ={\\frac {\\hbar }{\\tau }}}\n  where h is the Planck constant and \n  \n    \n      \n        \n          \u210f\n        \n        =\n        \n          \n            h\n            \n              2\n              \u03c0\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hbar }={\\frac {h}{2\\pi }}}\n  .\nThus, the lifetime of a particle is the direct inverse of the particle's resonance width. For example, the charged pion has the second-longest lifetime of any meson, at 2.6033\u00d710\u22128 s. Therefore, its resonance width is very small, about 2.528\u00d710\u22128 eV or about 6.11 MHz. Pions are generally not considered as \"resonances\". The charged rho meson has a very short lifetime, about 4.41\u00d710\u221224 s. Correspondingly, its resonance width is very large, at 149.1 MeV or about 36 ZHz. This amounts to nearly one-fifth of the particle's rest mass.\n\n\n== See also ==\nBaryon resonance particles\nRoper resonance\nGiant resonance\nRelativistic Breit\u2013Wigner distribution\n\n\n== References ==", "Rarefaction": "Rarefaction is the reduction of an item's density, the opposite of compression. Like compression, which can travel in waves (sound waves, for instance), rarefaction waves also exist in nature. A common rarefaction wave is the area of low relative pressure following a shock wave (see picture).\nRarefaction waves expand with time (much like sea waves spread out as they reach a beach); in most cases rarefaction waves keep the same overall profile ('shape') at all times throughout the wave's movement: it is a self-similar expansion. Each part of the wave travels at the local speed of sound, in the local medium. This expansion behaviour contrasts with that of pressure increases, which gets narrower with time until they steepen into shock waves. When angle of incidence is greater than angle of refraction, then light travels from denser to rarer medium. When angle of incidence is smaller than angle of refraction then light travels from rarer to denser medium\n\n\n== Physical examples ==\nA natural example of rarefaction occurs in the layers of Earth's atmosphere. Because the atmosphere has mass, most atmospheric matter is nearer to the Earth due to the Earth's gravitation. Therefore, air at higher layers of the atmosphere is less dense, or rarefied, relative to air at lower layers. Thus rarefaction can refer either to a reduction in density over space at a single point of time, or a reduction of density over time for one particular area.\nRarefaction can be easily  observed by compressing a spring and releasing it. \n\n\n== In manufacturing ==\nModern construction of guitars is an example of using rarefaction in manufacturing. By forcing the reduction of density (loss of oils and other impurities) in the cellular structure of the soundboard, a rarefied guitar top produces a tonal decompression affecting the sound of the instrument, mimicking aged wood.\n\n\n== See also ==\nLongitudinal wave\nP-wave\nPrandtl\u2013Meyer expansion fan\n\n\n== Citations ==", "Tangential_and_normal_components": "In mathematics, given a vector at a point on a curve, that vector can be decomposed uniquely as a sum of two vectors, one tangent to the curve, called the tangential component of the vector, and another one perpendicular to the curve, called the normal component of the vector. Similarly, a vector at a point on a surface can be broken down the same way.\nMore generally, given a submanifold N of a manifold M, and a vector in the tangent space to M at a point of N, it can be decomposed into the component tangent to N and the component normal to N.\n\n\n== Formal definition ==\n\n\n=== Surface ===\nMore formally, let \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   be a surface, and \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   be a point on the surface. Let \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   be a vector at \n  \n    \n      \n        x\n        .\n      \n    \n    {\\displaystyle x.}\n   Then one can write uniquely \n  \n    \n      \n        \n          v\n        \n      \n    \n    {\\displaystyle \\mathbf {v} }\n   as a sum\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          \n            v\n          \n          \n            \u2225\n          \n        \n        +\n        \n          \n            v\n          \n          \n            \u22a5\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} =\\mathbf {v} _{\\parallel }+\\mathbf {v} _{\\perp }}\n  where the first vector in the sum is the tangential component and the second one is the normal component. It follows immediately that these two vectors are perpendicular to each other. \nTo calculate the tangential and normal components, consider a unit normal to the surface, that is, a unit vector \n  \n    \n      \n        \n          \n            \n              n\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {n}}}\n   perpendicular to \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n   at \n  \n    \n      \n        x\n        .\n      \n    \n    {\\displaystyle x.}\n   Then,\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            \u22a5\n          \n        \n        =\n        (\n        \n          v\n        \n        \u22c5\n        \n          \n            \n              n\n              ^\n            \n          \n        \n        )\n        \n          \n            \n              n\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{\\perp }=(\\mathbf {v} \\cdot {\\hat {n}}){\\hat {n}}}\n  and thus\n\n  \n    \n      \n        \n          \n            v\n          \n          \n            \u2225\n          \n        \n        =\n        \n          v\n        \n        \u2212\n        \n          \n            v\n          \n          \n            \u22a5\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{\\parallel }=\\mathbf {v} -\\mathbf {v} _{\\perp }}\n  where \"\n  \n    \n      \n        \u22c5\n      \n    \n    {\\displaystyle \\cdot }\n  \" denotes the dot product. Another formula for the tangential component is \n\n  \n    \n      \n        \n          \n            v\n          \n          \n            \u2225\n          \n        \n        =\n        \u2212\n        \n          \n            \n              n\n              ^\n            \n          \n        \n        \u00d7\n        (\n        \n          \n            \n              n\n              ^\n            \n          \n        \n        \u00d7\n        \n          v\n        \n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} _{\\parallel }=-{\\hat {n}}\\times ({\\hat {n}}\\times \\mathbf {v} ),}\n  where \"\n  \n    \n      \n        \u00d7\n      \n    \n    {\\displaystyle \\times }\n  \" denotes the cross product.\nNote that these formulas do not depend on the particular unit normal \n  \n    \n      \n        \n          \n            \n              n\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {n}}}\n   used (there exist two unit normals to any surface at a given point, pointing in opposite directions, so one of the unit normals is the negative of the other one).\n\n\n=== Submanifold ===\nMore generally, given a submanifold N of a manifold M and\na point \n  \n    \n      \n        p\n        \u2208\n        N\n      \n    \n    {\\displaystyle p\\in N}\n  , we get a short exact sequence\ninvolving the tangent spaces:\n\n  \n    \n      \n        \n          T\n          \n            p\n          \n        \n        N\n        \u2192\n        \n          T\n          \n            p\n          \n        \n        M\n        \u2192\n        \n          T\n          \n            p\n          \n        \n        M\n        \n          /\n        \n        \n          T\n          \n            p\n          \n        \n        N\n      \n    \n    {\\displaystyle T_{p}N\\to T_{p}M\\to T_{p}M/T_{p}N}\n  The quotient space \n  \n    \n      \n        \n          T\n          \n            p\n          \n        \n        M\n        \n          /\n        \n        \n          T\n          \n            p\n          \n        \n        N\n      \n    \n    {\\displaystyle T_{p}M/T_{p}N}\n   is a generalized space of normal vectors.\nIf M is a Riemannian manifold, the above sequence splits, and the tangent space of M at p decomposes as a direct sum of the component tangent to N and the component normal to N:\n\n  \n    \n      \n        \n          T\n          \n            p\n          \n        \n        M\n        =\n        \n          T\n          \n            p\n          \n        \n        N\n        \u2295\n        \n          N\n          \n            p\n          \n        \n        N\n        :=\n        (\n        \n          T\n          \n            p\n          \n        \n        N\n        \n          )\n          \n            \u22a5\n          \n        \n      \n    \n    {\\displaystyle T_{p}M=T_{p}N\\oplus N_{p}N:=(T_{p}N)^{\\perp }}\n  Thus every tangent vector \n  \n    \n      \n        v\n        \u2208\n        \n          T\n          \n            p\n          \n        \n        M\n      \n    \n    {\\displaystyle v\\in T_{p}M}\n   splits as\n\n  \n    \n      \n        v\n        =\n        \n          v\n          \n            \u2225\n          \n        \n        +\n        \n          v\n          \n            \u22a5\n          \n        \n      \n    \n    {\\displaystyle v=v_{\\parallel }+v_{\\perp }}\n  ,\nwhere \n  \n    \n      \n        \n          v\n          \n            \u2225\n          \n        \n        \u2208\n        \n          T\n          \n            p\n          \n        \n        N\n      \n    \n    {\\displaystyle v_{\\parallel }\\in T_{p}N}\n   and \n  \n    \n      \n        \n          v\n          \n            \u22a5\n          \n        \n        \u2208\n        \n          N\n          \n            p\n          \n        \n        N\n        :=\n        (\n        \n          T\n          \n            p\n          \n        \n        N\n        \n          )\n          \n            \u22a5\n          \n        \n      \n    \n    {\\displaystyle v_{\\perp }\\in N_{p}N:=(T_{p}N)^{\\perp }}\n  .\n\n\n== Computations ==\nSuppose N is given by non-degenerate equations.\nIf N is given explicitly, via parametric equations (such as a parametric curve), then the derivative gives a spanning set for the tangent bundle (it is a basis if and only if the parametrization is an immersion).\nIf N is given implicitly (as in the above description of a surface, (or more generally as) a hypersurface) as a level set or intersection of level surfaces for \n  \n    \n      \n        \n          g\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle g_{i}}\n  , then the gradients of \n  \n    \n      \n        \n          g\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle g_{i}}\n   span the normal space.\nIn both cases, we can again compute using the dot product; the cross product is special to 3 dimensions however.\n\n\n== Applications ==\nLagrange multipliers: constrained critical points are where the tangential component of the total derivative vanish.\nSurface normal\nFrenet\u2013Serret formulas\nDifferential geometry of surfaces#Tangent vectors and normal vectors\n\n\n== References ==\nRojansky, Vladimir (1979). Electromagnetic fields and waves. New York: Dover Publications. ISBN 0-486-63834-0.Benjamin Crowell (2003) Light and Matter. (online version).", "Scalar_(mathematics)": "A scalar is an element of a field which is used to define a vector space.\nIn linear algebra, real numbers or generally elements of a field are called scalars and relate to vectors in an associated vector space through the operation of scalar multiplication (defined in the vector space), in which a vector can be multiplied by a scalar in the defined way to produce another vector. Generally speaking, a vector space may be defined by using any field instead of real numbers (such as complex numbers). Then scalars of that vector space will be elements of the associated field (such as complex numbers).\nA scalar product operation \u2013 not to be confused with scalar multiplication \u2013 may be defined on a vector space, allowing two vectors to be multiplied in the defined way to produce a scalar. A vector space equipped with a scalar product is called an inner product space.\nA quantity described by multiple scalars, such as having both direction and magnitude, is called a vector.\nThe term scalar is also sometimes used informally to mean a vector, matrix, tensor, or other, usually, \"compound\" value that is actually reduced to a single component. Thus, for example, the product of a 1\u2009\u00d7\u2009n matrix and an n\u2009\u00d7\u20091 matrix, which is formally a 1\u2009\u00d7\u20091 matrix, is often said to be a scalar.\nThe real component of a quaternion is also called its scalar part.\nThe term scalar matrix is used to denote a matrix of the form kI where k is a scalar and I is the identity matrix.\n\n\n== Etymology ==\nThe word scalar derives from the Latin word scalaris, an adjectival form of scala (Latin for \"ladder\"), from which the English word scale also comes. The first recorded usage of the word \"scalar\" in mathematics occurs in Fran\u00e7ois Vi\u00e8te's Analytic Art (In artem analyticem isagoge) (1591):\nMagnitudes that ascend or descend proportionally in keeping with their nature from one kind to another may be called scalar terms.\n(Latin: Magnitudines quae ex genere ad genus sua vi proportionaliter adscendunt vel descendunt, vocentur Scalares.)According to a citation in the Oxford English Dictionary the first recorded usage of the term \"scalar\" in English came with W. R. Hamilton in 1846, referring to the real part of a quaternion:\n\nThe algebraically real part may receive, according to the question in which it occurs, all values contained on the one scale of progression of numbers from negative to positive infinity; we shall call it therefore the scalar part.\n\n\n== Definitions and properties ==\n\n\n=== Scalars of vector spaces ===\nA vector space is defined as a set of vectors (additive abelian group), a set of scalars (field), and a scalar multiplication operation that takes a scalar k and a vector v to form another vector kv. For example, in a coordinate space, the scalar multiplication \n  \n    \n      \n        k\n        (\n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n        \u2026\n        ,\n        \n          v\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle k(v_{1},v_{2},\\dots ,v_{n})}\n   yields \n  \n    \n      \n        (\n        k\n        \n          v\n          \n            1\n          \n        \n        ,\n        k\n        \n          v\n          \n            2\n          \n        \n        ,\n        \u2026\n        ,\n        k\n        \n          v\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle (kv_{1},kv_{2},\\dots ,kv_{n})}\n  . In a (linear) function space, kf is the function x \u21a6 k(f(x)).\nThe scalars can be taken from any field, including the rational, algebraic, real, and complex numbers, as well as finite fields.\n\n\n=== Scalars as vector components ===\nAccording to a fundamental theorem of linear algebra, every vector space has a basis. It follows that every vector space over a field K is isomorphic to the corresponding coordinate vector space where each coordinate consists of elements of K (E.g., coordinates (a1, a2, ..., an) where ai \u2208 K and n is the dimension of the vector space in consideration.). For example, every real vector space of dimension n is isomorphic to the n-dimensional real space Rn.\n\n\n=== Scalars in normed vector spaces ===\nAlternatively, a vector space V can be equipped with a norm function that assigns to every vector v in V a scalar ||v||. By definition, multiplying v by a scalar k also multiplies its norm by |k|. If ||v|| is interpreted as the length of v, this operation can be described as scaling the length of v by k.  A vector space equipped with a norm is called a normed vector space (or normed linear space).\nThe norm is usually defined to be an element of V's scalar field K, which restricts the latter to fields that support the notion of sign. Moreover, if V has dimension 2 or more, K must be closed under square root, as well as the four arithmetic operations; thus the rational numbers Q are excluded, but the surd field is acceptable. For this reason, not every scalar product space is a normed vector space.\n\n\n=== Scalars in modules ===\nWhen the requirement that the set of scalars form a field is relaxed so that it need only form a ring (so that, for example, the division of scalars need not be defined, or the scalars need not be commutative), the resulting more general algebraic structure is called a module.\nIn this case the \"scalars\" may be complicated objects.  For instance, if R is a ring, the vectors of the product space Rn can be made into a module with the n\u00d7n matrices with entries from R as the scalars. Another example comes from manifold theory, where the space of sections of the tangent bundle forms a module over the algebra of real functions on the manifold.\n\n\n=== Scaling transformation ===\nThe scalar multiplication of vector spaces and modules is a special case of scaling, a kind of linear transformation.\n\n\n== See also ==\nAlgebraic structure\nScalar (physics)\nLinear algebra\n\n\n== References ==\n\n\n== External links ==\n\"Scalar\", Encyclopedia of Mathematics, EMS Press, 2001 [1994]\nWeisstein, Eric W. \"Scalar\". MathWorld.\nMathwords.com \u2013 Scalar", "Electrical_polarity": "An electric current is a stream of charged particles, such as electrons or ions, moving through an electrical conductor or space. It is measured as the net rate of flow of electric charge through a surface or into a control volume.:\u200a2\u200a:\u200a622\u200a The moving particles are called charge carriers, which may be one of several types of particles, depending on the conductor.  In electric circuits the charge carriers are often electrons moving through a wire. In semiconductors they can be electrons or holes. In an electrolyte the charge carriers are ions, while in plasma, an ionized gas, they are ions and electrons.The SI unit of electric current is the ampere, or amp, which is the flow of electric charge across a surface at the rate of one coulomb per second. The ampere (symbol: A) is an SI base unit.:\u200a15\u200a Electric current is measured using a device called an ammeter.:\u200a788\u200aElectric currents create magnetic fields, which are used in motors, generators, inductors, and transformers. In ordinary conductors, they cause Joule heating, which creates light in incandescent light bulbs. Time-varying currents emit electromagnetic waves, which are used in telecommunications to broadcast information.\n\n\n== Symbol ==\nThe conventional symbol for current is I, which originates from the French phrase intensit\u00e9 du courant, (current intensity). Current intensity is often referred to simply as current.  The I symbol was used by Andr\u00e9-Marie Amp\u00e8re, after whom the unit of electric current is named, in formulating Amp\u00e8re's force law (1820).  The notation travelled from France to Great Britain, where it became standard, although at least one journal did not change from using C to I until 1896.\n\n\n== Conventions ==\n\nThe conventional direction of current, also known as conventional current,  is arbitrarily defined as the direction in which positive charges flow. In a conductive material, the moving charged particles that constitute the electric current are called charge carriers. In metals, which make up the wires and other conductors in most electrical circuits, the positively charged atomic nuclei of the atoms are held in a fixed position, and the negatively charged electrons are the charge carriers, free to move about in the metal. In other materials, notably the semiconductors, the charge carriers can be positive or negative, depending on the dopant used. Positive and negative charge carriers may even be present at the same time, as happens in an electrolyte in an electrochemical cell.\nA flow of positive charges gives the same electric current, and has the same effect in a circuit, as an equal flow of negative charges in the opposite direction. Since current can be the flow of either positive or negative charges, or both, a convention is needed for the direction of current that is independent of the type of charge carriers. Negatively charged carriers, such as the electrons (the charge carriers in metal wires and many other electronic circuit components), therefore flow in the opposite direction of conventional current flow in an electrical circuit.\n\n\n=== Reference direction ===\nA current in a wire or circuit element can flow in either of two directions.  When defining a variable \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   to represent the current, the direction representing positive current must be specified, usually by an arrow on the circuit schematic diagram.:\u200a13\u200a  This is called the reference direction of the current \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  .  When analyzing electrical circuits, the actual direction of current through a specific circuit element is usually unknown until the analysis is completed. Consequently, the reference directions of currents are often assigned arbitrarily. When the circuit is solved, a negative value for the current implies the actual direction of current through that circuit element is opposite that of the chosen reference direction.:\u200a29\u200a\n\n\n== Ohm's law ==\n\nOhm's law states that the current through a conductor between two points is directly proportional to the potential difference across the two points.  Introducing the constant of proportionality, the resistance, one arrives at the usual mathematical equation that describes this relationship:\nwhere I is the current through the conductor in units of amperes, V is the potential difference measured across the conductor in units of volts,  and R is the resistance of the conductor in units of ohms.  More specifically, Ohm's law states that the R in this relation is constant, independent of the current.\n\n\n== Alternating and direct current ==\n\nIn alternating current (AC) systems, the movement of electric charge periodically reverses direction. AC is the form of electric power most commonly delivered to businesses and residences. The usual waveform of an AC power circuit is a sine wave, though certain applications use alternative waveforms, such as triangular or square waves. Audio and radio signals carried on electrical wires are also examples of alternating current. An important goal in these applications is recovery of information encoded (or modulated) onto the AC signal.\nIn contrast, direct current (DC) refers to a system in which the movement of electric charge in only one direction (sometimes called unidirectional flow). Direct current is produced by sources such as batteries, thermocouples, solar cells, and commutator-type electric machines of the dynamo type. Alternating current can also be converted to direct current through use of a rectifier. Direct current may flow in a conductor such as a wire, but can also flow through semiconductors, insulators, or even through a vacuum as in electron or ion beams. An old name for direct current was galvanic current.\n\n\n== Occurrences ==\nNatural observable examples of electric current include lightning, static electric discharge, and the solar wind, the source of the polar auroras.\nMan-made occurrences of electric current include the flow of conduction electrons in metal wires such as the overhead power lines that deliver electrical energy across long distances and the smaller wires within electrical and electronic equipment. Eddy currents are electric currents that occur in conductors exposed to changing magnetic fields. Similarly, electric currents occur, particularly in the surface, of conductors exposed to electromagnetic waves. When oscillating electric currents flow at the correct voltages within radio antennas, radio waves are generated.\nIn electronics, other forms of electric current include the flow of electrons through resistors or through the vacuum in a vacuum tube, the flow of ions inside a battery, and the flow of holes within metals and semiconductors.  \nA biological example of current is the flow of ions in neurons and nerves, responsible for both thought and sensory perception.\n\n\n== Measurement ==\nCurrent can be measured using an ammeter.\nElectric current can be directly measured with a galvanometer, but this method involves breaking the electrical circuit, which is sometimes inconvenient. \nCurrent can also be measured without breaking the circuit by detecting the magnetic field associated with the current. \nDevices, at the circuit level, use various techniques to measure current:\n\nShunt resistors\nHall effect current sensor transducers\nTransformers (however DC cannot be measured)\nMagnetoresistive field sensors\nRogowski coils\nCurrent clamps\n\n\n== Resistive heating ==\n\nJoule heating, also known as ohmic heating and resistive heating, is the process of power dissipation:\u200a36\u200a by which the passage of an electric current through a conductor increases the internal energy of the conductor,:\u200a846\u200a converting thermodynamic work into heat.:\u200a846,\u200afn. 5\u200a The phenomenon was first studied by James Prescott Joule in 1841. Joule immersed a length of wire in a fixed mass of water and measured the temperature rise due to a known current through the wire for a 30 minute period. By varying the current and the length of the wire he deduced that the heat produced was proportional to the square of the current multiplied by the electrical resistance of the wire.\n\nThis relationship is known as Joule's Law.:\u200a36\u200a The SI unit of energy was subsequently named the joule and given the symbol J.:\u200a20\u200a The commonly known SI unit of power, the watt (symbol: W), is equivalent to one joule per second.:\u200a20\u200a\n\n\n== Electromagnetism ==\n\n\n=== Electromagnet ===\n\nIn an electromagnet a coil of wires behaves like a magnet when an electric current flows through it. When the current is switched off, the coil loses its magnetism immediately.\nElectric current produces a magnetic field.  The magnetic field can be visualized as a pattern of circular field lines surrounding the wire that persists as long as there is current.\n\n\n=== Electromagnetic induction ===\n\nMagnetic fields can also be used to make electric currents. When a changing magnetic field is applied to a conductor, an electromotive force (EMF) is induced,:\u200a1004\u200a which starts an electric current, when there is a suitable path.\n\n\n=== Radio waves ===\n\nWhen an electric current flows in a suitably shaped conductor at radio frequencies, radio waves can be generated. These travel at the speed of light and can cause electric currents in distant conductors.\n\n\n== Conduction mechanisms in various media ==\n\nIn metallic solids, electric charge flows by means of electrons, from lower to higher electrical potential. In other media, any stream of charged objects (ions, for example) may constitute an electric current.  To provide a definition of current independent of the type of charge carriers, conventional current is defined as moving in the same direction as the positive charge flow. So, in metals where the charge carriers (electrons) are negative, conventional current is in the opposite direction to the overall electron movement.  In conductors where the charge carriers are positive, conventional current is in the same direction as the charge carriers.\nIn a vacuum, a beam of ions or electrons may be formed. In other conductive materials, the electric current is due to the flow of both positively and negatively charged particles at the same time. In still others, the current is entirely due to positive charge flow. For example, the electric currents in electrolytes are flows of positively and negatively charged ions. In a common lead-acid electrochemical cell, electric currents are composed of positive hydronium ions flowing in one direction, and negative sulfate ions flowing in the other. Electric currents in sparks or plasma are flows of electrons as well as positive and negative ions. In ice and in certain solid electrolytes, the electric current is entirely composed of flowing ions.\n\n\n=== Metals ===\nIn a metal, some of the outer electrons in each atom are not bound to the individual molecules as they are in molecular solids, or in full bands as they are in insulating materials, but are free to move within the metal lattice. These conduction electrons can serve as charge carriers, carrying a current. Metals are particularly conductive because there are many of these free electrons. With no external electric field applied, these electrons move about randomly due to thermal energy but, on average, there is zero net current within the metal. At room temperature, the average speed of these random motions is 106 metres per second. Given a surface through which a metal wire passes, electrons move in both directions across the surface at an equal rate. As George Gamow wrote in his popular science book, One, Two, Three...Infinity (1947), \"The metallic substances differ from all other materials by the fact that the outer shells of their atoms are bound rather loosely, and often let one of their electrons go free. Thus the interior of a metal is filled up with a large number of unattached electrons that travel aimlessly around like a crowd of displaced persons. When a metal wire is subjected to electric force applied on its opposite ends, these free electrons rush in the direction of the force, thus forming what we call an electric current.\"\nWhen a metal wire is connected across the two terminals of a DC voltage source such as a battery, the source places an electric field across the conductor. The moment contact is made, the free electrons of the conductor are forced to drift toward the positive terminal under the influence of this field. The free electrons are therefore the charge carrier in a typical solid conductor.\nFor a steady flow of charge through a surface, the current I (in amperes) can be calculated with the following equation:\n\nwhere Q is the electric charge transferred through the surface over a time t.  If Q and t are measured in coulombs and seconds respectively, I is in amperes.\nMore generally, electric current can be represented as the rate at which charge flows through a given surface as:\n\n\n=== Electrolytes ===\n\nElectric currents in electrolytes are flows of electrically charged particles (ions). For example, if an electric field is placed across a solution of Na+ and Cl\u2212 (and conditions are right) the sodium ions move towards the negative electrode (cathode), while the chloride ions move towards the positive electrode (anode). Reactions take place at both electrode surfaces, neutralizing each ion.\nWater-ice and certain solid electrolytes called proton conductors contain positive hydrogen ions (\"protons\") that are mobile. In these materials, electric currents are composed of moving protons, as opposed to the moving electrons in metals.\nIn certain electrolyte mixtures, brightly coloured ions are the moving electric charges. The slow progress of the colour makes the current visible.\n\n\n=== Gases and plasmas ===\nIn air and other ordinary gases below the breakdown field, the dominant source of electrical conduction is via relatively few mobile ions produced by radioactive gases, ultraviolet light, or cosmic rays. Since the electrical conductivity is low, gases are dielectrics or insulators. However, once the applied electric field approaches the breakdown value, free electrons become sufficiently accelerated by the electric field to create additional free electrons by colliding, and ionizing, neutral gas atoms or molecules in a process called avalanche breakdown. The breakdown process forms a plasma that contains enough mobile electrons and positive ions to make it an electrical conductor. In the process, it forms a light emitting conductive path, such as a spark, arc or lightning.\nPlasma is the state of matter where some of the electrons in a gas are stripped or \"ionized\" from their molecules or atoms. A plasma can be formed by high temperature, or by application of a high electric or alternating magnetic field as noted above. Due to their lower mass, the electrons in a plasma accelerate more quickly in response to an electric field than the heavier positive ions, and hence carry the bulk of the current. The free ions recombine to create new chemical compounds (for example, breaking atmospheric oxygen into single oxygen [O2 \u2192 2O], which then recombine creating ozone [O3]).\n\n\n=== Vacuum ===\nSince a \"perfect vacuum\" contains no charged particles, it normally behaves as a perfect insulator. However, metal electrode surfaces can cause a region of the vacuum to become conductive by injecting free electrons or ions through either field electron emission or thermionic emission. Thermionic emission occurs when the thermal energy exceeds the metal's work function, while field electron emission occurs when the electric field at the surface of the metal is high enough to cause tunneling, which results in the ejection of free electrons from the metal into the vacuum. Externally heated electrodes are often used to generate an electron cloud as in the filament or indirectly heated cathode of vacuum tubes. Cold electrodes can also spontaneously produce electron clouds via thermionic emission when small incandescent regions (called cathode spots or anode spots) are formed. These are incandescent regions of the electrode surface that are created by a localized high current. These regions may be initiated by field electron emission, but are then sustained by localized thermionic emission once a vacuum arc forms. These small electron-emitting regions can form quite rapidly, even explosively, on a metal surface subjected to a high electrical field. Vacuum tubes and sprytrons are some of the electronic switching and amplifying devices based on vacuum conductivity.\n\n\n=== Superconductivity ===\n\nSuperconductivity is a phenomenon of exactly zero electrical resistance and expulsion of magnetic fields occurring in certain materials when cooled below a characteristic critical temperature. It was discovered by Heike Kamerlingh Onnes on April 8, 1911 in Leiden. Like ferromagnetism and atomic spectral lines, superconductivity is a quantum mechanical phenomenon. It is characterized by the Meissner effect, the complete ejection of magnetic field lines from the interior of the superconductor as it transitions into the superconducting state. The occurrence of the Meissner effect indicates that superconductivity cannot be understood simply as the idealization of perfect conductivity in classical physics.\n\n\n=== Semiconductor ===\n\nIn a semiconductor it is sometimes useful to think of the current as due to the flow of positive \"holes\" (the mobile positive charge carriers that are places where the semiconductor crystal is missing a valence electron). This is the case in a p-type semiconductor. A semiconductor has electrical conductivity intermediate in magnitude between that of a conductor and an insulator. This means a conductivity roughly in the range of 10\u22122  to 104 siemens per centimeter (S\u22c5cm\u22121).\nIn the classic crystalline semiconductors, electrons can have energies only within certain bands (i.e. ranges of levels of energy). Energetically,  these bands are located between the energy of the ground state, the state in which electrons are tightly bound to the atomic nuclei of the material, and the free electron energy, the latter describing the energy required for an electron to escape entirely from the material. The energy bands each correspond to many discrete quantum states of the electrons, and most of the states with low energy (closer to the nucleus) are occupied, up to a particular band called the valence band. Semiconductors and insulators are distinguished from metals because the valence band in any given metal is nearly filled with electrons under usual operating conditions, while very few (semiconductor) or virtually none (insulator) of them are available in the conduction band, the band immediately above the valence band.\nThe ease of exciting electrons in the semiconductor from the valence band to the conduction band depends on the band gap between the bands. The size of this energy band gap serves as an arbitrary dividing line (roughly 4 eV) between semiconductors and insulators.\nWith covalent bonds, an electron moves by hopping to a neighboring bond. The Pauli exclusion principle requires that the electron be lifted into the higher anti-bonding state of that bond. For delocalized states, for example in one dimension \u2013 that is in a nanowire, for every energy there is a state with electrons flowing in one direction and another state with the electrons flowing in the other. For a net current to flow, more states for one direction than for the other direction must be occupied. For this to occur, energy is required, as in the semiconductor the next higher states lie above the band gap. Often this is stated as: full bands do not contribute to the electrical conductivity. However, as a semiconductor's temperature rises above absolute zero, there is more energy in the semiconductor to spend on lattice vibration and on exciting electrons into the conduction band. The current-carrying electrons in the conduction band are known as free electrons, though they are often simply called electrons if that is clear in context.\n\n\n== Current density and Ohm's law ==\n\nCurrent density is the rate at which charge passes through a chosen unit area.:\u200a31\u200a It is defined as a vector whose magnitude is the current per unit cross-sectional area.:\u200a749\u200a As discussed in Reference direction, the direction is arbitrary. Conventionally, if the moving charges are positive, then the current density has the same sign as the velocity of the charges.  For negative charges, the sign of the current density is opposite to the velocity of the charges.:\u200a749\u200a In SI units, current density (symbol: j) is expressed in the SI base units of amperes per square metre.:\u200a22\u200aIn linear materials such as metals, and under low frequencies, the current density across the conductor surface is uniform. In such conditions, Ohm's law states that the current is directly proportional to the potential difference between two ends (across) of that metal (ideal) resistor (or other ohmic device):\n\nwhere \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the current, measured in amperes; \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n   is the potential difference, measured in volts; and \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n   is the resistance, measured in ohms. For alternating currents, especially at higher frequencies, skin effect causes the current to spread unevenly across the conductor cross-section, with higher density near the surface, thus increasing the apparent resistance.\n\n\n== Drift speed ==\nThe mobile charged particles within a conductor move constantly in random directions, like the particles of a gas.  (More accurately, a Fermi gas.) To create a net flow of charge, the particles must also move together with an average drift rate. Electrons are the charge carriers in most metals and they follow an erratic path, bouncing from atom to atom, but generally drifting in the opposite direction of the electric field. The speed they drift at can be calculated from the equation:\n\nwhere\n\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n   is the electric current\n\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is number of charged particles per unit volume (or charge carrier density)\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   is the cross-sectional area of the conductor\n\n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   is the drift velocity, and\n\n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n   is the charge on each particle.Typically, electric charges in solids flow slowly.  For example, in a copper wire of cross-section 0.5 mm2, carrying a current of 5 A, the drift velocity of the electrons is on the order of a millimetre per second. To take a different example, in the near-vacuum inside a cathode-ray tube, the electrons travel in near-straight lines at about a tenth of the speed of light.\nAny accelerating electric charge, and therefore any changing electric current, gives rise to an electromagnetic wave that propagates at very high speed outside the surface of the conductor.  This speed is usually a significant fraction of the speed of light, as can be deduced from Maxwell's equations, and is therefore many times faster than the drift velocity of the electrons. For example, in AC power lines, the waves of electromagnetic energy propagate through the space between the wires, moving from a source to a distant load, even though the electrons in the wires only move back and forth over a tiny distance.\nThe ratio of the speed of the electromagnetic wave to the speed of light in free space is called the velocity factor, and depends on the electromagnetic properties of the conductor and the insulating materials surrounding it, and on their shape and size.\nThe magnitudes (not the natures) of these three velocities can be illustrated by an analogy with the three similar velocities associated with gases. (See also hydraulic analogy.)\n\nThe low drift velocity of charge carriers is analogous to air motion; in other words, winds.\nThe high speed of electromagnetic waves is roughly analogous to the speed of sound in a gas (sound waves move through air much faster than large-scale motions such as convection)\nThe random motion of charges is analogous to heat \u2013 the thermal velocity of randomly vibrating gas particles.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==", "Direction_(geometry)": "In geometry, a position or position vector, also known as location vector or radius vector, is a Euclidean vector that represents the position of a point P in space in relation to an arbitrary reference origin O. Usually denoted x, r, or s, it corresponds to the straight line segment from O to P.\nIn other words, it is the displacement or translation that maps the origin to P:\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          \n            \n              O\n              P\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} ={\\overrightarrow {OP}}}\n  The term position vector is used mostly in the fields of differential geometry, mechanics and occasionally vector calculus.\nFrequently this is used in two-dimensional or three-dimensional space, but can be easily generalized to Euclidean spaces and affine spaces of any dimension.\n\n\n== Relative position ==\n\nThe relative position of a point Q with respect to point P is the Euclidean vector resulting from the subtraction of the two absolute position vectors (each with respect to the origin):\n\n  \n    \n      \n        \u0394\n        \n          r\n        \n        =\n        \n          s\n        \n        \u2212\n        \n          r\n        \n        =\n        \n          \n            \n              P\n              Q\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle \\Delta \\mathbf {r} =\\mathbf {s} -\\mathbf {r} ={\\overrightarrow {PQ}}}\n  where \n  \n    \n      \n        \n          s\n        \n        =\n        \n          \n            \n              O\n              Q\n            \n            \u2192\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {s} ={\\overrightarrow {OQ}}}\n  .\nThe relative direction between two points is their relative position normalized as a unit vector:\n\n  \n    \n      \n        \u0394\n        \n          \n            \n              r\n              ^\n            \n          \n        \n        =\n        \u0394\n        \n          r\n        \n        \n          /\n        \n        \u2016\n        \u0394\n        \n          r\n        \n        \u2016\n      \n    \n    {\\displaystyle \\Delta \\mathbf {\\hat {r}} =\\Delta \\mathbf {r} /\\|\\Delta \\mathbf {r} \\|}\n  where the denominator is the distance between the two points, \n  \n    \n      \n        \u2016\n        \u0394\n        \n          r\n        \n        \u2016\n      \n    \n    {\\displaystyle \\|\\Delta \\mathbf {r} \\|}\n  .\n\n\n== Definition ==\n\n\n=== Three dimensions ===\n\nIn three dimensions, any set of three-dimensional coordinates and their corresponding basis vectors can be used to define the location of a point in space\u2014whichever is the simplest for the task at hand may be used.\nCommonly, one uses the familiar Cartesian coordinate system, or sometimes spherical polar coordinates, or cylindrical coordinates:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  r\n                \n                (\n                t\n                )\n              \n              \n                \n                \u2261\n                \n                  r\n                \n                (\n                x\n                ,\n                y\n                ,\n                z\n                )\n                \u2261\n                x\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    x\n                  \n                \n                +\n                y\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    y\n                  \n                \n                +\n                z\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    z\n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2261\n                \n                  r\n                \n                (\n                r\n                ,\n                \u03b8\n                ,\n                \u03d5\n                )\n                \u2261\n                r\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    r\n                  \n                \n                \n                  \n                    (\n                  \n                \n                \u03b8\n                (\n                t\n                )\n                ,\n                \u03d5\n                (\n                t\n                )\n                \n                  \n                    )\n                  \n                \n              \n            \n            \n              \n              \n                \n                \u2261\n                \n                  r\n                \n                (\n                r\n                ,\n                \u03d5\n                ,\n                z\n                )\n                \u2261\n                r\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    r\n                  \n                \n                \n                  \n                    (\n                  \n                \n                \u03d5\n                (\n                t\n                )\n                \n                  \n                    )\n                  \n                \n                +\n                z\n                (\n                t\n                )\n                \n                  \n                    \n                      \n                        e\n                        ^\n                      \n                    \n                  \n                  \n                    z\n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {r} (t)&\\equiv \\mathbf {r} (x,y,z)\\equiv x(t)\\mathbf {\\hat {e}} _{x}+y(t)\\mathbf {\\hat {e}} _{y}+z(t)\\mathbf {\\hat {e}} _{z}\\\\&\\equiv \\mathbf {r} (r,\\theta ,\\phi )\\equiv r(t)\\mathbf {\\hat {e}} _{r}{\\big (}\\theta (t),\\phi (t){\\big )}\\\\&\\equiv \\mathbf {r} (r,\\phi ,z)\\equiv r(t)\\mathbf {\\hat {e}} _{r}{\\big (}\\phi (t){\\big )}+z(t)\\mathbf {\\hat {e}} _{z},\\\\\\end{aligned}}}\n  where t is a parameter, owing to their rectangular or circular symmetry. These different coordinates and corresponding basis vectors represent the same position vector. More general curvilinear coordinates could be used instead and are in contexts like continuum mechanics and general relativity (in the latter case one needs an additional time coordinate).\n\n\n=== n dimensions ===\nLinear algebra allows for the abstraction of an n-dimensional position vector. A position vector can be expressed as a linear combination of basis vectors:\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          x\n          \n            i\n          \n        \n        \n          \n            e\n          \n          \n            i\n          \n        \n        =\n        \n          x\n          \n            1\n          \n        \n        \n          \n            e\n          \n          \n            1\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          \n            e\n          \n          \n            2\n          \n        \n        +\n        \u22ef\n        +\n        \n          x\n          \n            n\n          \n        \n        \n          \n            e\n          \n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {r} =\\sum _{i=1}^{n}x_{i}\\mathbf {e} _{i}=x_{1}\\mathbf {e} _{1}+x_{2}\\mathbf {e} _{2}+\\dotsb +x_{n}\\mathbf {e} _{n}.}\n  The set of all position vectors forms position space (a vector space whose elements are the position vectors), since positions can be added (vector addition) and scaled in length (scalar multiplication) to obtain another position vector in the space. The notion of \"space\" is intuitive, since each xi (i = 1, 2, \u2026, n) can have any value, the collection of values defines a point in space.\nThe dimension of the position space is n (also denoted dim(R) = n). The coordinates of the vector r with respect to the basis vectors ei are xi. The vector of coordinates forms the coordinate vector or n-tuple (x1, x2, \u2026, xn).\nEach coordinate xi may be parameterized a number of parameters t. One parameter xi(t) would describe a curved 1D path, two parameters xi(t1, t2) describes a curved 2D surface, three xi(t1, t2, t3) describes a curved 3D volume of space, and so on.\nThe linear span of a basis set B = {e1, e2,  \u2026, en} equals the position space R, denoted span(B) = R.\n\n\n== Applications ==\n\n\n=== Differential geometry ===\n\nPosition vector fields are used to describe continuous and differentiable space curves, in which case the independent parameter needs not be time, but can be (e.g.) arc length of the curve.\n\n\n=== Mechanics ===\n\nIn any equation of motion, the position vector r(t) is usually the most sought-after quantity because this function defines the motion of a particle (i.e. a point mass) \u2013 its location relative to a given coordinate system at some time t.\nTo define motion in terms of position, each coordinate may be parametrized by time; since each successive value of time corresponds to a sequence of successive spatial locations given by the coordinates, the continuum limit of many successive locations is a path the particle traces.\nIn the case of one dimension, the position has only one component, so it effectively degenerates to a scalar coordinate. It could be, say, a vector in the x direction, or the radial r direction. Equivalent notations include\n\n  \n    \n      \n        \n          x\n        \n        \u2261\n        x\n        \u2261\n        x\n        (\n        t\n        )\n        ,\n        \n        r\n        \u2261\n        r\n        (\n        t\n        )\n        ,\n        \n        s\n        \u2261\n        s\n        (\n        t\n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {x} \\equiv x\\equiv x(t),\\quad r\\equiv r(t),\\quad s\\equiv s(t).}\n  \n\n\n== Derivatives of position ==\n\nFor a position vector r that is a function of time t, the time derivatives can be computed with respect to t. These derivatives have common utility in the study of kinematics, control theory, engineering and other sciences.\n\nVelocity\n\n  \n    \n      \n        \n          v\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} ={\\frac {\\mathrm {d} \\mathbf {r} }{\\mathrm {d} t}},}\n  \nwhere dr is an infinitesimally small displacement (vector).\nAcceleration\n\n  \n    \n      \n        \n          a\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                v\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n                \n                  2\n                \n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {a} ={\\frac {\\mathrm {d} \\mathbf {v} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} ^{2}\\mathbf {r} }{\\mathrm {d} t^{2}}}.}\n  \nJerk\n\n  \n    \n      \n        \n          j\n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                a\n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n                \n                  2\n                \n              \n              \n                v\n              \n            \n            \n              \n                d\n              \n              \n                t\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                \n                  d\n                \n                \n                  3\n                \n              \n              \n                r\n              \n            \n            \n              \n                d\n              \n              \n                t\n                \n                  3\n                \n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {j} ={\\frac {\\mathrm {d} \\mathbf {a} }{\\mathrm {d} t}}={\\frac {\\mathrm {d} ^{2}\\mathbf {v} }{\\mathrm {d} t^{2}}}={\\frac {\\mathrm {d} ^{3}\\mathbf {r} }{\\mathrm {d} t^{3}}}.}\n  These names for the first, second and third derivative of position are commonly used in basic kinematics. By extension, the higher-order derivatives can be computed in a similar fashion. Study of these higher-order derivatives can improve approximations of the original displacement function. Such higher-order terms are required in order to accurately represent the displacement function as a sum of an infinite sequence, enabling several analytical techniques in engineering and physics.\n\n\n== See also ==\nAffine space\nCoordinate system\nHorizontal position\nLine element\nParametric surface\nPosition fixing\nSix degrees of freedom\nVertical position\n\n\n== Notes ==\n\n\n== References ==\nKeller, F. J, Gettys, W. E. et al. (1993). \"Physics: Classical and modern\" 2nd ed. McGraw Hill Publishing.\n\n\n== External links ==\n Media related to Position (geometry) at Wikimedia Commons", "Huygens\u2013Fresnel_principle": "The Huygens\u2013Fresnel principle (named after Dutch physicist Christiaan Huygens and French physicist Augustin-Jean Fresnel) states that every point on a wavefront is itself the source of spherical wavelets, and the secondary wavelets emanating from different points mutually interfere. The sum of these spherical wavelets forms a new wavefront. As such, the Huygens-Fresnel principle is a method of analysis applied to problems of luminous wave propagation both in the far-field limit and in near-field diffraction as well as reflection.\n\n\n== History ==\n\nIn 1678, Huygens proposed that every point reached by a luminous disturbance becomes a source of a spherical wave; the sum of these secondary waves determines the form of the wave at any subsequent time. He assumed that the secondary waves travelled only in the \"forward\" direction and it is not explained in the theory why this is the case. He was able to provide a qualitative explanation of linear and spherical wave propagation, and to derive the laws of reflection and refraction using this principle, but could not explain the deviations from rectilinear propagation that occur when light encounters edges, apertures and screens, commonly known as diffraction effects. The resolution of this error was finally explained by David A. B. Miller in 1991. The resolution is that the source is a dipole (not the monopole assumed by Huygens), which cancels in the reflected direction.\nIn 1818, Fresnel showed that Huygens's principle, together with his own principle of interference could explain both the rectilinear propagation of light and also diffraction effects. To obtain agreement with experimental results, he had to include additional arbitrary assumptions about the phase and amplitude of the secondary waves, and also an obliquity factor. These assumptions have no obvious physical foundation but led to predictions that agreed with many experimental observations, including the Poisson spot.\nPoisson was a member of the French Academy, which reviewed Fresnel's work. He used Fresnel's theory to predict that a bright spot ought to appear in the center of the shadow of a small disc, and deduced from this that the theory was incorrect. However, Arago, another member of the committee, performed the experiment and showed that the prediction was correct. (Lisle had observed this fifty years earlier.) This was one of the investigations that led to the victory of the wave theory of light over then predominant corpuscular theory.\nIn antenna theory and engineering, the reformulation of the Huygens\u2013Fresnel principle for radiating current sources is known as surface equivalence principle.\n\n\n=== Huygens' principle as a microscopic model ===\nThe Huygens\u2013Fresnel principle provides a reasonable basis for understanding and predicting the classical wave propagation of light. However, there are limitations to the principle, namely the same approximations done for deriving the Kirchhoff's diffraction formula and the approximations of near field due to Fresnel. These can be summarized in the fact that the wavelength of light is much smaller than the dimensions of any optical components encountered.Kirchhoff's diffraction formula provides a rigorous mathematical foundation for diffraction, based on the wave equation. The arbitrary assumptions made by Fresnel to arrive at the Huygens\u2013Fresnel equation emerge automatically from the mathematics in this derivation.A simple example of the operation of the principle can be seen when an open doorway connects two rooms and a sound is produced in a remote corner of one of them. A person in the other room will hear the sound as if it originated at the doorway. As far as the second room is concerned, the vibrating air in the doorway is the source of the sound.\n\n\n=== Modern physics interpretations ===\nNot all experts agree that the Huygens' principle is an accurate microscopic representation of reality. For instance, Melvin Schwartz argued that \"Huygens' principle actually does give the right answer but for the wrong reasons\".This can be reflected in the following facts:\n\nThe microscopic mechanics to create photons and of emission, in general, is essentially acceleration of electrons.\nThe original analysis of Huygens included amplitudes only. It includes neither phases nor waves propagating at different speeds (due to diffraction within continuous media), and therefore does not take into account interference.\nThe Huygens analysis also does not include polarization for light which imply a vector potential, where instead sound waves can be described with a scalar potential and there is no unique and natural translation between the two.\nIn the Huygens description, there is no explanation of why we choose only the forward-going (retarded wave or forward envelope of wave fronts) versus the backward-propagating advanced wave (backward envelope).\nIn the Fresnel approximation there is a concept of non-local behavior due to the sum of spherical waves with different phases that comes from the different points of the wave front, and non local theories are subject of many debates (e.g., not being Lorentz covariant) and of active research.\nThe Fresnel approximation can be interpreted in a quantum probabilistic manner but is unclear how much this sum of states (i.e., wavelets on the wavefront) is a complete list of states that are meaningful physically or represents more of an approximation on a generic basis like in the linear combination of atomic orbitals (LCAO) method.The Huygens' principle is essentially compatible with quantum field theory in the far field approximation, considering effective fields in the center of scattering, considering small perturbations, and in the same sense that quantum optics is compatible with classical optics, other interpretations are subject of debates and active research.\nThe Feynman model where every point in an imaginary wave front as large as the room is generating a wavelet, shall also be interpreted in these approximations  and in a probabilistic context, in this context remote points can only contribute minimally to the overall probability amplitude.\nQuantum field theory does not include any microscopic model for photon creation and the concept of single photon is also put under scrutiny on a theoretical level.\n\n\n== Mathematical expression of the principle ==\n\nConsider the case of a point source located at a point P0, vibrating at a frequency f. The disturbance may be described by a complex variable U0 known as the complex amplitude. It produces a spherical wave with wavelength \u03bb, wavenumber k = 2\u03c0/\u03bb. Within a constant of proportionality, the complex amplitude of the primary wave at the point Q located at a distance r0 from P0 is:\n\n  \n    \n      \n        U\n        (\n        \n          r\n          \n            0\n          \n        \n        )\n        \u221d\n        \n          \n            \n              \n                U\n                \n                  0\n                \n              \n              \n                e\n                \n                  i\n                  k\n                  \n                    r\n                    \n                      0\n                    \n                  \n                \n              \n            \n            \n              r\n              \n                0\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle U(r_{0})\\propto {\\frac {U_{0}e^{ikr_{0}}}{r_{0}}}.}\n  Note that magnitude decreases in inverse proportion to the distance travelled, and the phase changes as k times the distance travelled.\nUsing Huygens's theory and the principle of superposition of waves, the complex amplitude at a further point P is found by summing the contributions from each point on the sphere of radius r0. In order to get agreement with experimental results, Fresnel found that the individual contributions from the secondary waves on the sphere had to be multiplied by a constant, \u2212i/\u03bb, and by an additional inclination factor, K(\u03c7). The first assumption means that the secondary waves oscillate at a quarter of a cycle out of phase with respect to the primary wave, and that the magnitude of the secondary waves are in a ratio of 1:\u03bb to the primary wave. He also assumed that K(\u03c7) had a maximum value when \u03c7 = 0, and was equal to zero when \u03c7 = \u03c0/2, where \u03c7 is the angle between the normal of the primary wave front and the normal of the secondary wave front. The complex amplitude at P, due to the contribution of secondary waves, is then given by:\n\n  \n    \n      \n        U\n        (\n        P\n        )\n        =\n        \u2212\n        \n          \n            i\n            \u03bb\n          \n        \n        U\n        (\n        \n          r\n          \n            0\n          \n        \n        )\n        \n          \u222b\n          \n            S\n          \n        \n        \n          \n            \n              e\n              \n                i\n                k\n                s\n              \n            \n            s\n          \n        \n        K\n        (\n        \u03c7\n        )\n        \n        d\n        S\n      \n    \n    {\\displaystyle U(P)=-{\\frac {i}{\\lambda }}U(r_{0})\\int _{S}{\\frac {e^{iks}}{s}}K(\\chi )\\,dS}\n  where S describes the surface of the sphere, and s is the distance between Q and P.\nFresnel used a zone construction method to find approximate values of K for the different zones, which enabled him to make predictions that were in agreement with experimental results. The integral theorem of Kirchhoff includes the basic idea of Huygens\u2013Fresnel principle. Kirchhoff showed that in many cases, the theorem can be approximated to a simpler form that is equivalent to the formation of Fresnel's formulation.For an aperture illumination consisting of a single expanding spherical wave, if the radius of the curvature of the wave is sufficiently large, Kirchhoff gave the following expression for K(\u03c7):\n\n  \n    \n      \n         \n        K\n        (\n        \u03c7\n        )\n        =\n        \n          \n            1\n            2\n          \n        \n        (\n        1\n        +\n        cos\n        \u2061\n        \u03c7\n        )\n      \n    \n    {\\displaystyle ~K(\\chi )={\\frac {1}{2}}(1+\\cos \\chi )}\n  K has a maximum value at \u03c7 = 0 as in the Huygens\u2013Fresnel principle; however, K is not equal to zero at \u03c7 = \u03c0/2, but at \u03c7 = \u03c0.\nAbove derivation of K(\u03c7) assumed that the diffracting aperture is illuminated by a single spherical wave with a sufficiently large radius of curvature. However, the principle holds for more general illuminations. An arbitrary illumination can be decomposed into a collection of point sources, and the linearity of the wave equation can be invoked to apply the principle to each point source individually. K(\u03c7) can be generally expressed as:\n\n  \n    \n      \n         \n        K\n        (\n        \u03c7\n        )\n        =\n        cos\n        \u2061\n        \u03c7\n      \n    \n    {\\displaystyle ~K(\\chi )=\\cos \\chi }\n  In this case, K satisfies the conditions stated above (maximum value at \u03c7 = 0 and zero at \u03c7 = \u03c0/2).\n\n\n== Generalized Huygens' principle ==\nMany books and references e.g. and  refer to the Generalized Huygens' Principle as the one referred by Feynman in this publication.Feynman defines the generalized principle in the following way:\n\n \"Actually Huygens\u2019 principle is not correct in optics. It is replaced by Kirchoff\u2019s [sic] modification which requires that both the amplitude and its derivative must be known on the adjacent surface. This is a consequence of the fact that the wave equation in optics is second order in the time. The wave equation of quantum mechanics is first order in the time; therefore, Huygens\u2019 principle is correct for matter waves, action replacing time.\"\nThis clarifies the fact that in this context the generalized principle reflects the linearity of quantum mechanics and the fact that the quantum mechanics equations are first order in time. Finally only in this case the superposition principle fully apply, i.e. the wave function in a point P can be expanded as a superposition of waves on a border surface enclosing P. Wave functions can be interpreted in the usual quantum mechanical sense as probability densities where the formalism of Green's functions and propagators apply. What is note-worthy is that this generalized principle is applicable for \"matter waves\" and not for light waves any more. The phase factor is now clarified as given by the action and there is no more confusion why the phases of the wavelets are different from the one of the original wave and modified by the additional Fresnel parameters.\nAs per Greiner  the generalized principle can be expressed for \n  \n    \n      \n        \n          t\n          \u2032\n        \n        >\n        t\n      \n    \n    {\\displaystyle t'>t}\n   in the form:\n\n  \n    \n      \n        \n          \u03c8\n          \u2032\n        \n        (\n        \n          \n            x\n          \n          \u2032\n        \n        ,\n        \n          t\n          \u2032\n        \n        )\n        =\n        i\n        \u222b\n        \n\n        \n        \n\n        \n        \n          d\n          \n            3\n          \n        \n        x\n        G\n        (\n        \n          \n            x\n          \n          \u2032\n        \n        ,\n        \n          t\n          \u2032\n        \n        ;\n        \n          x\n        \n        ,\n        t\n        )\n        \u03c8\n        (\n        \n          x\n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\psi '(\\mathbf {x} ',t')=i\\int {}{}d^{3}xG(\\mathbf {x} ',t';\\mathbf {x} ,t)\\psi (\\mathbf {x} ,t)}\n  Where G is the usual Green function that propagates in time the wave function \n  \n    \n      \n        \u03c8\n      \n    \n    {\\displaystyle \\psi }\n  . This description resembles and generalize the initial Fresnel's formula of the classical model.\n\n\n=== Huygens' theory, Feynman's path integral and the modern photon wave function ===\nHuygens' theory served as a fundamental explanation of the wave nature of light interference and was further developed by Fresnel and Young but did not fully resolve all observations such as the low-intensity double-slit experiment first performed by G. I. Taylor in 1909.  It was not until the early and mid-1900s that quantum theory discussions, particularly the early discussions at the 1927 Brussels Solvay Conference, where Louis de Broglie proposed his de Broglie hypothesis that the photon is guided by a wave function.The wave function presents a much different explanation of the observed light and dark bands in a double slit experiment. In this conception, the photon follows a path which is a probabilistic choice of one of many possible paths in the electromagnetic field.  These probable paths form the pattern: in dark areas, no photons are landing, and in bright areas, many photons are landing.  The set of possible photon paths is consistent with Richard Feynman's path integral theory, the paths determined by the surroundings: the photon's originating point (atom), the slit, and the screen and by tracking and summing phases. The wave function is a solution to this geometry.  The wave function approach was further supported by additional double-slit experiments in Italy and Japan in the 1970s and 1980s with electrons.\n\n\n=== Huygens' principle and quantum field theory ===\nHuygens' principle can be seen as a consequence of the homogeneity of space\u2014space is uniform in all locations. Any disturbance created in a sufficiently small region of homogeneous space (or in a homogeneous medium) propagates from that region in all geodesic directions. The waves produced by this disturbance, in turn, create disturbances in other regions, and so on. The superposition of all the waves results in the observed pattern of wave propagation.\nHomogeneity of space is fundamental to quantum field theory (QFT) where the wave function of any object propagates along all available unobstructed paths. When integrated along all possible paths, with a phase factor proportional to the action, the interference of the wave-functions correctly predicts observable phenomena. Every point on the wavefront acts as the source of secondary wavelets that spread out in the light cone with the same speed as the wave. The new wavefront is found by constructing the surface tangent to the secondary wavelets.\n\n\n== In other spatial dimensions ==\nIn 1900, Jacques Hadamard observed that Huygens' principle was broken when the number of spatial dimensions is even. From this, he developed a set of conjectures that remain an active topic of research. In particular, it has been discovered that Huygens' principle holds on a large class of homogeneous spaces derived from the Coxeter group (so, for example, the Weyl groups of simple Lie algebras).The traditional statement of Huygens' principle for the D'Alembertian gives rise to the KdV hierarchy; analogously, the Dirac operator gives rise to the AKNS hierarchy.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nStratton, Julius Adams: Electromagnetic Theory, McGraw-Hill, 1941. (Reissued by Wiley \u2013 IEEE Press, ISBN 978-0-470-13153-4).\nB.B. Baker and E.T. Copson, The Mathematical Theory of Huygens' Principle, Oxford, 1939, 1950; AMS Chelsea, 1987.", "Length": "Length is a measure of distance. In the International System of Quantities, length is a quantity with dimension distance. In most systems of measurement a base unit for length is chosen, from which all other units are derived. In the International System of Units (SI) system the base unit for length is the metre.\nLength is commonly understood to mean the most extended dimension of a fixed object. However, this is not always the case and may depend on the position the object is in.\nVarious terms for the length of a fixed object are used, and these include height, which is vertical length or vertical extent, and width, breadth or depth. Height is used when there is a base from which vertical measurements can be taken. Width or breadth usually refer to a shorter dimension when length is the longest one. Depth is used for the third dimension of a three dimensional object.Length is the measure of one spatial dimension, whereas area is a measure of two dimensions (length squared) and volume is a measure of three dimensions (length cubed).\n\n\n== History ==\nMeasurement has been important ever since humans settled from nomadic lifestyles and started using building materials, occupying land and trading with neighbours. As trade between different places increased, the need for standard units of length increased. And later, as society has become more technologically oriented, much higher accuracy of measurement is required in an increasingly diverse set of fields, from micro-electronics to interplanetary ranging.Under Einstein's special relativity, length can no longer be thought of as being constant in all reference frames. Thus a ruler that is one metre long in one frame of reference will not be one metre long in a reference frame that is moving relative to the first frame. This means the length of an object varies depending on the speed of the observer.\n\n\n== Use in mathematics ==\n\n\n=== Euclidean geometry ===\n\nIn Euclidean geometry, length is measured along straight lines unless otherwise specified and refers to segments on them. Pythagoras's theorem relating the length of the sides of a right triangle is one of many applications in Euclidean geometry. Length may also be measured along other types of curves and is referred to as arclength.\nIn a triangle, the length of an altitude, a line segment drawn from a vertex perpendicular to the side not passing through the vertex (referred to as a base of the triangle), is called the height of the triangle.\nThe area of a rectangle is defined to be length\u2009\u00d7\u2009width of the rectangle. If a long thin rectangle is stood up on its short side then its area could also be described as its height\u2009\u00d7\u2009width.\nThe volume of a solid rectangular box (such as a plank of wood) is often described as length\u2009\u00d7\u2009height\u2009\u00d7\u2009depth.\nThe perimeter of a polygon is the sum of the lengths of its sides.\nThe circumference of a circular disk is the length of the boundary (a circle) of that disk.\n\n\n=== Other geometries ===\n\nIn other geometries, length may be measured along possibly curved paths, called geodesics. The Riemannian geometry used in general relativity is an example of such a geometry. In spherical geometry, length is measured along the great circles on the sphere and the distance between two points on the sphere is the shorter of the two lengths on the great circle, which is determined by the plane through the two points and the center of the sphere.\n\n\n=== Graph theory ===\nIn an unweighted graph, the length of a cycle, path, or walk is the number of edges it uses. In a weighted graph, it may instead be the sum of the weights of the edges that it uses.Length is used to define the shortest path, girth (shortest cycle length), and longest path between two vertices in a graph.\n\n\n=== Measure theory ===\n\nIn measure theory, length is most often generalized to general sets of \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n   via the Lebesgue measure. In the one-dimensional case, the Lebesgue outer measure of a set is defined in terms of the lengths of open intervals. Concretely, the length of an open interval is first defined as\n\n  \n    \n      \n        \u2113\n        (\n        {\n        x\n        \u2208\n        \n          R\n        \n        \u2223\n        a\n        <\n        x\n        <\n        b\n        }\n        )\n        =\n        b\n        \u2212\n        a\n        .\n      \n    \n    {\\displaystyle \\ell (\\{x\\in \\mathbb {R} \\mid a<x<b\\})=b-a.}\n  so that the Lebesgue outer measure \n  \n    \n      \n        \n          \u03bc\n          \n            \u2217\n          \n        \n        (\n        E\n        )\n      \n    \n    {\\displaystyle \\mu ^{*}(E)}\n   of a general set \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n   may then be defined as\n\n  \n    \n      \n        \n          \u03bc\n          \n            \u2217\n          \n        \n        (\n        E\n        )\n        =\n        inf\n        \n          {\n          \n            \n              \u2211\n              \n                k\n              \n            \n            \u2113\n            (\n            \n              I\n              \n                k\n              \n            \n            )\n            :\n            \n              I\n              \n                k\n              \n            \n            \n               is a sequence of open intervals such that \n            \n            E\n            \u2286\n            \n              \u22c3\n              \n                k\n              \n            \n            \n              I\n              \n                k\n              \n            \n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle \\mu ^{*}(E)=\\inf \\left\\{\\sum _{k}\\ell (I_{k}):I_{k}{\\text{ is a sequence of open intervals such that }}E\\subseteq \\bigcup _{k}I_{k}\\right\\}.}\n  \n\n\n== Units ==\n\nIn the physical sciences and engineering, when one speaks of units of length, the word length is synonymous with distance. There are several units that are used to measure length. Historically, units of length may have been derived from the lengths of human body parts, the distance traveled in a number of paces, the distance between landmarks or places on the Earth, or arbitrarily on the length of some common object.\nIn the International System of Units (SI), the base unit of length is the metre (symbol, m) and is now defined in terms of the speed of light (about 300 million metres per second). The millimetre (mm), centimetre (cm) and the kilometre (km), derived from the metre, are also commonly used units. In U.S. customary units, English or Imperial system of units, commonly used units of length are the inch (in), the foot (ft), the yard (yd), and the mile (mi). A unit of length used in navigation is the nautical mile (nmi).Units used to denote distances in the vastness of space, as in astronomy, are much longer than those typically used on Earth (metre or centimetre) and include the astronomical unit (au), the light-year, and the parsec (pc).\nUnits used to denote sub-atomic distances, as in nuclear physics, are much smaller than the centimetre. Examples include the fermi.\n\n\n== See also ==\nArc length\nConversion of units\nHumorous units of length\nLength measurement\nMetric system\nMetric units\nOrders of magnitude (length)\nReciprocal length\n\n\n== References ==", "Optical_microscope": "The optical microscope, also referred to as a light microscope, is a type of microscope that commonly uses visible light and a system of lenses to generate magnified images of small objects. Optical microscopes are the oldest design of microscope and were possibly invented in their present compound form in the 17th century. Basic optical microscopes can be very simple, although many complex designs aim to improve resolution and sample contrast.\nThe object is placed on a stage and may be directly viewed through one or two eyepieces on the microscope. In high-power microscopes, both eyepieces typically show the same image, but with a stereo microscope, slightly different images are used to create a 3-D effect. A camera is typically used to capture the image (micrograph).\nThe sample can be lit in a variety of ways. Transparent objects can be lit from below and solid objects can be lit with light coming through (bright field) or around (dark field) the objective lens. Polarised light may be used to determine crystal orientation of metallic objects. Phase-contrast imaging can be used to increase image contrast by highlighting small details of differing refractive index.\nA range of objective lenses with different magnification are usually provided mounted on a turret, allowing them to be rotated into place and providing an ability to zoom-in. The maximum magnification power of optical microscopes is typically limited to around 1000x because of the limited resolving power of visible light. While larger magnifications are possible no additional details of the object are resolved.\nAlternatives to optical microscopy which do not use visible light include scanning electron microscopy and transmission electron microscopy and scanning probe microscopy and as a result, can achieve much greater magnifications.\n\n\n== Types ==\n\nThere are two basic types of optical microscopes: simple microscopes and compound microscopes. A simple microscope uses the optical power of single lens or group of lenses for magnification. A compound microscope uses a system of lenses (one set enlarging the image produced by another) to achieve much higher magnification of an object. The vast majority of modern research microscopes are compound microscopes while some cheaper commercial digital microscopes are simple single lens microscopes. Compound microscopes can be further divided into a variety of other types of microscopes which differ in their optical configurations, cost, and intended purposes.\n\n\n=== Simple microscope ===\nA simple microscope uses a lens or set of lenses to enlarge an object through angular magnification alone, giving the viewer an erect enlarged virtual image. The use of a single convex lens or groups of lenses are found in simple magnification devices such as the magnifying glass, loupes, and eyepieces for telescopes and microscopes.\n\n\n=== Compound microscope ===\n\nA compound microscope uses a lens close to the object being viewed to collect light (called the objective lens) which focuses a real image of the object inside the microscope (image 1). That image is then magnified by a second lens or group of lenses (called the eyepiece) that gives the viewer an enlarged inverted virtual image of the object (image 2). The use of a compound objective/eyepiece combination allows for much higher magnification. Common compound microscopes often feature exchangeable objective lenses, allowing the user to quickly adjust the magnification. A compound microscope also enables more advanced illumination setups, such as phase contrast.\n\n\n=== Other microscope variants ===\nThere are many variants of the compound optical microscope design for specialized purposes. Some of these are physical design differences allowing specialization for certain purposes:\n\nStereo microscope, a low-powered microscope which provides a stereoscopic view of the sample, commonly used for dissection.\nComparison microscope, which has two separate light paths allowing direct comparison of two samples via one image in each eye.\nInverted microscope, for studying samples from below; useful for cell cultures in liquid, or for metallography.\nFiber optic connector inspection microscope, designed for connector end-face inspection\nTraveling microscope, for studying samples of high optical resolution.Other microscope variants are designed for different illumination techniques:\n\nPetrographic microscope, whose design usually includes a polarizing filter, rotating stage and gypsum plate to facilitate the study of minerals or other crystalline materials whose optical properties can vary with orientation.\nPolarizing microscope, similar to the petrographic microscope.\nPhase-contrast microscope, which applies the phase contrast illumination method.\nEpifluorescence microscope, designed for analysis of samples which include fluorophores.\nConfocal microscope, a widely used variant of epifluorescent illumination which uses a scanning laser to illuminate a sample for fluorescence.\nTwo-photon microscope, used to image fluorescence deeper in scattering media and reduce photobleaching, especially in living samples.\nStudent microscope \u2013 an often low-power microscope with simplified controls and sometimes low quality optics designed for school use or as a starter instrument for children.\nUltramicroscope, an adapted light microscope that uses light scattering to allow viewing of tiny particles whose diameter is below or near the wavelength of visible light (around 500 nanometers); mostly obsolete since the advent of electron microscopes\nTip-enhanced Raman microscope, is a variant of optical microscope based on tip-enhanced Raman spectroscopy, without traditional wavelength-based resolution limits. This microscope primarily realized on the scanning-probe microscope platforms using all optical tools.\n\n\n=== Digital microscope ===\n\nA digital microscope is a microscope equipped with a digital camera allowing observation of a sample via a computer. Microscopes can also be partly or wholly computer-controlled with various levels of automation. Digital microscopy allows greater analysis of a microscope image, for example, measurements of distances and areas and quantitation of a fluorescent or histological stain.\nLow-powered digital microscopes, USB microscopes, are also commercially available. These are essentially webcams with a high-powered macro lens and generally do not use transillumination. The camera attached directly to the USB port of a computer so that the images are shown directly on the monitor. They offer modest magnifications (up to about 200\u00d7) without the need to use eyepieces, and at very low cost. High power illumination is usually provided by an LED source or sources adjacent to the camera lens.\nDigital microscopy with very low light levels to avoid damage to vulnerable biological samples is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band for efficient imaging by a photon-counting camera.\n\n\n== History ==\n\n\n=== Invention ===\nThe earliest microscopes were single lens magnifying glasses with limited magnification which date at least as far back as the widespread use of lenses in eyeglasses in the 13th century.Compound microscopes first appeared in Europe around 1620 including one demonstrated by Cornelis Drebbel in London (around 1621) and one exhibited in Rome in 1624.The actual inventor of the compound microscope is unknown although many claims have been made over the years. These include a claim 35 years after they appeared by Dutch spectacle-maker Johannes Zachariassen that his father, Zacharias Janssen, invented the compound microscope and/or the telescope as early as 1590. Johannes' testimony, which some claim is dubious, pushes the invention date so far back that Zacharias would have been a child at the time, leading to speculation that, for Johannes' claim to be true, the compound microscope would have to have been invented by Johannes' grandfather, Hans Martens. Another claim is that Janssen's competitor, Hans Lippershey (who applied for the first telescope patent in 1608) also invented the compound microscope. Other historians point to the Dutch innovator Cornelis Drebbel with his 1621 compound microscope.Galileo Galilei is also sometimes cited as a compound microscope inventor. After 1610, he found that he could close focus his telescope to view small objects, such as flies, close up and/or could look through the wrong end in reverse to magnify small objects. The only drawback was that his 2 foot long telescope had to be extended out to 6 feet to view objects that close. After seeing the compound microscope built by  Drebbel exhibited in Rome in 1624, Galileo built his own improved version. In 1625, Giovanni Faber coined the name microscope for the compound microscope Galileo submitted to the Accademia dei Lincei in 1624  (Galileo had called it the \"occhiolino\" or \"little eye\"). Faber coined the name from the Greek words \u03bc\u03b9\u03ba\u03c1\u03cc\u03bd (micron) meaning \"small\", and \u03c3\u03ba\u03bf\u03c0\u03b5\u1fd6\u03bd (skopein) meaning \"to look at\", a name meant to be analogous with \"telescope\", another word coined by the Linceans.Christiaan Huygens, another Dutchman, developed a simple 2-lens ocular system in the late 17th century that was achromatically corrected, and therefore a huge step forward in microscope development. The Huygens ocular is still being produced to this day, but suffers from a small field size, and other minor disadvantages.\n\n\n=== Popularization ===\n\nAntonie van Leeuwenhoek (1632\u20131724) is credited with bringing the microscope to the attention of biologists, even though simple magnifying lenses were already being produced in the 16th century. Van Leeuwenhoek's home-made microscopes were simple microscopes, with a single very small, yet strong lens. They were awkward in use, but enabled van Leeuwenhoek to see detailed images. It took about 150 years of optical development before the compound microscope was able to provide the same quality image as van Leeuwenhoek's simple microscopes, due to difficulties in configuring multiple lenses. In the 1850s, John Leonard Riddell, Professor of Chemistry at Tulane University, invented the first practical binocular microscope while carrying out one of the earliest and most extensive American microscopic investigations of cholera.\n\n\n=== Lighting techniques ===\nWhile basic microscope technology and optics have been available for over 400 years it is much more recently that techniques in sample illumination were developed to generate the high quality images seen today.\nIn August 1893, August K\u00f6hler developed K\u00f6hler illumination. This method of sample illumination gives rise to extremely even lighting and overcomes many limitations of older techniques of sample illumination. Before development of K\u00f6hler illumination the image of the light source, for example a lightbulb filament, was always visible in the image of the sample.\nThe Nobel Prize in physics was awarded to Dutch physicist Frits Zernike in 1953 for his development of phase contrast illumination which allows imaging of transparent samples. By using interference rather than absorption of light, extremely transparent samples, such as live mammalian cells, can be imaged without having to use staining techniques. Just two years later, in 1955, Georges Nomarski published the theory for differential interference contrast microscopy, another interference-based imaging technique.\n\n\n=== Fluorescence microscopy ===\nModern biological microscopy depends heavily on the development of fluorescent probes for specific structures within a cell. In contrast to normal transilluminated light microscopy, in fluorescence microscopy the sample is illuminated through the objective lens with a narrow set of wavelengths of light. This light interacts with fluorophores in the sample which then emit light of a longer wavelength. It is this emitted light which makes up the image.\nSince the mid-20th century chemical fluorescent stains, such as DAPI which binds to DNA, have been used to label specific structures within the cell. More recent developments include immunofluorescence, which uses fluorescently labelled antibodies to recognise specific proteins within a sample, and fluorescent proteins like GFP which a live cell can express making it fluorescent.\n\n\n== Components ==\n\nAll modern optical microscopes designed for viewing samples by transmitted light share the same basic components of the light path. In addition, the vast majority of microscopes have the same 'structural' components (numbered below according to the image on the right):\n\nEyepiece (ocular lens) (1)\nObjective turret, revolver, or revolving nose piece (to hold multiple objective lenses) (2)\nObjective lenses (3)\nFocus knobs (to move the stage)\nCoarse adjustment (4)\nFine adjustment (5)\nStage (to hold the specimen) (6)\nLight source (a light or a mirror) (7)\nDiaphragm and condenser (8)\nMechanical stage (9)\n\n\n=== Eyepiece (ocular lens) ===\n\nThe eyepiece, or ocular lens, is a cylinder containing two or more lenses; its function is to bring the image into focus for the eye. The eyepiece is inserted into the top end of the body tube. Eyepieces are interchangeable and many different eyepieces can be inserted with different degrees of magnification. Typical magnification values for eyepieces include 5\u00d7, 10\u00d7 (the most common), 15\u00d7 and 20\u00d7. In some high performance microscopes, the optical configuration of the objective lens and eyepiece are matched to give the best possible optical performance. This occurs most commonly with apochromatic objectives.\n\n\n=== Objective turret (revolver or revolving nose piece) ===\nObjective turret, revolver, or revolving nose piece is the part that holds the set of objective lenses. It allows the user to switch between objective lenses.\n\n\n=== Objective lens ===\n\nAt the lower end of a typical compound optical microscope, there are one or more objective lenses that collect light from the sample. The objective is usually in a cylinder housing containing a glass single or multi-element compound lens. Typically there will be around three objective lenses screwed into a circular nose piece which may be rotated to select the required objective lens. These arrangements are designed to be parfocal, which means that when one changes from one lens to another on a microscope, the sample stays in focus. Microscope objectives are characterized by two parameters, namely, magnification and numerical aperture. The former typically ranges from 5\u00d7 to 100\u00d7 while the latter ranges from 0.14 to 0.7, corresponding to focal lengths of about 40 to 2 mm, respectively. Objective lenses with higher magnifications normally have a higher numerical aperture and a shorter depth of field in the resulting image. Some high performance objective lenses may require matched eyepieces to deliver the best optical performance.\n\n\n==== Oil immersion objective ====\n\nSome microscopes make use of oil-immersion objectives or water-immersion objectives for greater resolution at high magnification. These are used with index-matching material such as immersion oil or water and a matched cover slip between the objective lens and the sample. The refractive index of the index-matching material is higher than air allowing the objective lens to have a larger numerical aperture (greater than 1) so that the light is transmitted from the specimen to the outer face of the objective lens with minimal refraction. Numerical apertures as high as 1.6 can be achieved. The larger numerical aperture allows collection of more light making detailed observation of smaller details possible. An oil immersion lens usually has a magnification of 40 to 100\u00d7.\n\n\n=== Focus knobs ===\nAdjustment knobs move the stage up and down with separate adjustment for coarse and fine focusing. The same controls enable the microscope to adjust to specimens of different thickness. In older designs of microscopes, the focus adjustment wheels move the microscope tube up or down relative to the stand and had a fixed stage.\n\n\n=== Frame ===\nThe whole of the optical assembly is traditionally attached to a rigid arm, which in turn is attached to a robust U-shaped foot to provide the necessary rigidity. The arm angle may be adjustable to allow the viewing angle to be adjusted.\nThe frame provides a mounting point for various microscope controls. Normally this will include controls for focusing, typically a large knurled wheel to adjust coarse focus, together with a smaller knurled wheel to control fine focus. Other features may be lamp controls and/or controls for adjusting the condenser.\n\n\n=== Stage ===\nThe stage is a platform below the objective lens which supports the specimen being viewed. In the center of the stage is a hole through which light passes to illuminate the specimen. The stage usually has arms to hold slides (rectangular glass plates with typical dimensions of 25\u00d775 mm, on which the specimen is mounted).\nAt magnifications higher than 100\u00d7 moving a slide by hand is not practical. A mechanical stage, typical of medium and higher priced microscopes, allows tiny movements of the slide via control knobs that reposition the sample/slide as desired. If a microscope did not originally have a mechanical stage it may be possible to add one.\nAll stages move up and down for focus. With a mechanical stage slides move on two horizontal axes for positioning the specimen to examine specimen details.\nFocusing starts at lower magnification in order to center the specimen by the user on the stage. Moving to a higher magnification requires the stage to be moved higher vertically for re-focus at the higher magnification and may also require slight horizontal specimen position adjustment. Horizontal specimen position adjustments are the reason for having a mechanical stage.\nDue to the difficulty in preparing specimens and mounting them on slides, for children it is best to begin with prepared slides that are centered and focus easily regardless of the focus level used.\n\n\n=== Light source ===\nMany sources of light can be used. At its simplest, daylight is directed via a mirror. Most microscopes, however, have their own adjustable and controllable light source \u2013 often a halogen lamp, although illumination using LEDs and lasers are becoming a more common provision. K\u00f6hler illumination is often provided on more expensive instruments.\n\n\n=== Condenser ===\nThe condenser is a lens designed to focus light from the illumination source onto the sample. The condenser may also include other features, such as a diaphragm and/or filters, to manage the quality and intensity of the illumination. For illumination techniques like dark field, phase contrast and differential interference contrast microscopy additional optical components must be precisely aligned in the light path.\n\n\n=== Magnification ===\nThe actual power or magnification of a compound optical microscope is the product of the powers of the eyepiece and the objective lens. For example a 10x eyepiece magnification and a 100x objective lens magnification gives a total magnification of 1,000\u00d7.  Modified environments such as the use of oil or ultraviolet light can increase the resolution and allow for resolved details at magnifications larger than 1,000x.\n\n\n== Operation ==\n\n\n=== Illumination techniques ===\n\nMany techniques are available which modify the light path to generate an improved contrast image from a sample. Major techniques for generating increased contrast from the sample include cross-polarized light, dark field, phase contrast and differential interference contrast illumination. A recent technique (Sarfus) combines cross-polarized light and specific contrast-enhanced slides for the visualization of nanometric samples.\n\nFour examples of transilumination techniques used to generate contrast in a sample of tissue paper. 1.559 \u03bcm/pixel.\n\t\t\n\t\t\n\t\t\n\t\t\n\n\n=== Other techniques ===\nModern microscopes allow more than just observation of transmitted light image of a sample; there are many techniques which can be used to extract other kinds of data. Most of these require additional equipment in addition to a basic compound microscope.\n\nReflected light, or incident, illumination (for analysis of surface structures)\nFluorescence microscopy, both:Epifluorescence microscopy\nConfocal microscopyMicrospectroscopy (where a UV-visible spectrophotometer is integrated with an optical microscope)\nUltraviolet microscopy\nNear-Infrared microscopy\nMultiple transmission microscopy for contrast enhancement and aberration reduction.\nAutomation (for automatic scanning of a large sample or image capture)\n\n\n== Applications ==\n\nOptical microscopy is used extensively in microelectronics, nanophysics, biotechnology, pharmaceutic research, mineralogy and microbiology.Optical microscopy is used for medical diagnosis, the field being termed histopathology when dealing with tissues, or in smear tests on free cells or tissue fragments.\nIn industrial use, binocular microscopes are common. Aside from applications needing true depth perception, the use of dual eyepieces reduces eye strain associated with long workdays at a microscopy station. In certain applications, long-working-distance or long-focus microscopes are beneficial.  An item may need to be examined behind a window, or industrial subjects may be a hazard to the objective.  Such optics resemble telescopes with close-focus capabilities.Measuring microscopes are used for precision measurement.  There are two basic types.\nOne has a reticle graduated to allow measuring distances in the focal plane.  The other (and older) type has simple crosshairs and a micrometer mechanism for moving the subject relative to the microscope.Very small, portable microscopes have found some usage in places where a laboratory microscope would be a burden.\n\n\n== Limitations ==\n\nAt very high magnifications with transmitted light, point objects are seen as fuzzy discs surrounded by diffraction rings. These are called Airy disks. The resolving power of a microscope is taken as the ability to distinguish between two closely spaced Airy disks (or, in other words the ability of the microscope to reveal adjacent structural detail as distinct and separate). It is these impacts of diffraction that limit the ability to resolve fine details. The extent and magnitude of the diffraction patterns are affected by both the wavelength of light (\u03bb), the refractive materials used to manufacture the objective lens and the numerical aperture (NA) of the objective lens. There is therefore a finite limit beyond which it is impossible to resolve separate points in the objective field, known as the diffraction limit. Assuming that optical aberrations in the whole optical set-up are negligible, the resolution d, can be stated as:\n\n  \n    \n      \n        d\n        =\n        \n          \n            \u03bb\n            \n              2\n              N\n              A\n            \n          \n        \n      \n    \n    {\\displaystyle d={\\frac {\\lambda }{2NA}}}\n  Usually a wavelength of 550 nm is assumed, which corresponds to green light. With air as the external medium, the highest practical NA is 0.95, and with oil, up to 1.5. In practice the lowest value of d obtainable with conventional lenses is about 200 nm. A new type of lens using multiple scattering of light allowed to improve the resolution to below 100 nm.\n\n\n=== Surpassing the resolution limit ===\nMultiple techniques are available for reaching resolutions higher than the transmitted light limit described above. Holographic techniques, as described by Courjon and Bulabois in 1979, are also capable of breaking this resolution limit, although resolution was restricted in their experimental analysis.Using fluorescent samples more techniques are available. Examples include Vertico SMI, near field scanning optical microscopy which uses evanescent waves, and stimulated emission depletion. In 2005, a microscope capable of detecting a single molecule was described as a teaching tool.Despite significant progress in the last decade, techniques for surpassing the diffraction limit remain limited and specialized.\nWhile most techniques focus on increases in lateral resolution there are also some techniques which aim to allow analysis of extremely thin samples. For example, sarfus methods place the thin sample on a contrast-enhancing surface and thereby allows to directly visualize films as thin as 0.3 nanometers.\nOn 8 October 2014, the Nobel Prize in Chemistry was awarded to Eric Betzig, William Moerner and Stefan Hell for the development of super-resolved fluorescence microscopy.\n\n\n==== Structured illumination SMI ====\nSMI (spatially modulated illumination microscopy) is a light optical process of the so-called point spread function (PSF) engineering. These are processes which modify the PSF of a microscope in a suitable manner to either increase the optical resolution, to maximize the precision of distance measurements of fluorescent objects that are small relative to the wavelength of the illuminating light, or to extract other structural parameters in the nanometer range.\n\n\n==== Localization microscopy SPDMphymod ====\n\nSPDM (spectral precision distance microscopy), the basic localization microscopy technology is a light optical process of fluorescence microscopy which allows position, distance and angle measurements on \"optically isolated\" particles (e.g. molecules) well below the theoretical limit of resolution for light microscopy. \"Optically isolated\" means that at a given point in time, only a single particle/molecule within a region of a size determined by conventional optical resolution (typically approx. 200\u2013250 nm diameter) is being registered. This is possible when molecules within such a region all carry different spectral markers (e.g. different colors or other usable differences in the light emission of different particles).Many standard fluorescent dyes like GFP, Alexa dyes, Atto dyes, Cy2/Cy3 and fluorescein molecules can be used for localization microscopy, provided certain photo-physical conditions are present. Using this so-called SPDMphymod (physically modifiable fluorophores) technology a single laser wavelength of suitable intensity is sufficient for nanoimaging.\n\n\n==== 3D super resolution microscopy ====\n3D super resolution microscopy with standard fluorescent dyes can be achieved by combination of localization microscopy for standard fluorescent dyes SPDMphymod and structured illumination SMI.\n\n\n==== STED ====\n\nStimulated emission depletion is a simple example of how higher resolution surpassing the diffraction limit is possible, but it has major limitations. STED is a fluorescence microscopy technique which uses a combination of light pulses to induce fluorescence in a small sub-population of fluorescent molecules in a sample. Each molecule produces a diffraction-limited spot of light in the image, and the centre of each of these spots corresponds to the location of the molecule. As the number of fluorescing molecules is low the spots of light are unlikely to overlap and therefore can be placed accurately. This process is then repeated many times to generate the image. Stefan Hell of the Max Planck Institute for Biophysical Chemistry was awarded the 10th German Future Prize in 2006 and Nobel Prize for Chemistry in 2014 for his development of the STED microscope and associated methodologies.\n\n\n== Alternatives ==\nIn order to overcome the limitations set by the diffraction limit of visible light other microscopes have been designed which use other waves.\n\nAtomic force microscope (AFM)\nScanning electron microscope (SEM)\nScanning ion-conductance microscopy (SICM)\nScanning tunneling microscope (STM)\nTransmission electron microscopy (TEM)\nUltraviolet microscope\nX-ray microscopeIt is important to note that higher frequency waves have limited interaction with matter, for example soft tissues are relatively transparent to X-rays resulting in distinct sources of contrast and different target applications.\nThe use of electrons and X-rays in place of light allows much higher resolution \u2013 the wavelength of the radiation is shorter so the diffraction limit is lower. To make the\nshort-wavelength probe non-destructive, the atomic beam imaging system (atomic nanoscope) has been proposed and widely discussed in the literature, but it is not yet competitive with conventional imaging systems.\nSTM and AFM are scanning probe techniques using a small probe which is scanned over the sample surface. Resolution in these cases is limited by the size of the probe; micromachining techniques can produce probes with tip radii of 5\u201310 nm.\nAdditionally, methods such as electron or X-ray microscopy use a vacuum or partial vacuum, which limits their use for live and biological samples (with the exception of an environmental scanning electron microscope). The specimen chambers needed for all such instruments also limits sample size, and sample manipulation is more difficult. Color cannot be seen in images made by these methods, so some information is lost. They are however, essential when investigating molecular or atomic effects, such as age hardening in aluminium alloys, or the microstructure of polymers.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Cited sources ==\nVan Helden, Albert; Dupre, Sven; Van Gent, Rob (2011). The Origins of the Telescope. Amsterdam University Press. ISBN 978-9069846156.\n\n\n== Further reading ==\n\"Metallographic and Materialographic Specimen Preparation, Light Microscopy, Image Analysis and Hardness Testing\", Kay Geels in collaboration with Struers A/S, ASTM International 2006.\n\"Light Microscopy: An ongoing contemporary revolution\", Siegfried Weisenburger and Vahid Sandoghdar, arXiv:1412.3255 2014.\n\n\n== External links ==\nAntique Microscopes & Scientific Instruments  A site about Antique Microscopes, their Accessories, and History\nAntique Microscopes.com A collection of early microscopes\nHistorical microscopes, an illustrated collection with more than 3000 photos of scientific microscopes by European makers (in German)\nThe Golub Collection, A collection of 17th through 19th century microscopes, including extensive descriptions\nMolecular Expressions, concepts in optical microscopy\nOnline tutorial of practical optical microscopy at University of Cambridge\nOpenWetWare\nCell Centered Database", "Coulomb": "The coulomb (symbol: C) is the unit of electric charge in the International System of Units (SI). In the present version of the SI it is equal to the electric charge delivered by a 1 ampere constant current in 1 second and to 5\u00d71027/801088317 elementary charges, e, (about 6.241509\u00d71018 e).\n\n\n== Name and history ==\nThe coulomb is named after Charles-Augustin de Coulomb. As with every SI unit named for a person, its symbol starts with an upper case letter (C), but when written in full it follows the rules for capitalisation of a common noun; i.e., \"coulomb\" becomes capitalised at the beginning of a sentence and in titles, but is otherwise in lower case.By 1878, the British Association for the Advancement of Science had defined the volt, ohm, and farad, but not the coulomb.  In 1881, the International Electrical Congress, now the International Electrotechnical Commission (IEC), approved the volt as the unit for electromotive force, the ampere as the unit for electric current, and the coulomb as the unit of electric charge.  \nAt that time, the volt was defined as the potential difference [i.e., what is nowadays called the \"voltage (difference)\"] across a conductor when a current of one ampere dissipates one watt of power.\nThe coulomb (later \"absolute coulomb\" or \"abcoulomb\" for disambiguation) was part of the EMU system of units. The \"international coulomb\" based on laboratory specifications for its measurement was introduced by the IEC in 1908. The entire set of \"reproducible units\" was abandoned in 1948 and the \"international coulomb\" became the modern coulomb.\n\n\n== Definition ==\nThe SI defines the coulomb in terms of the ampere and second: 1 C = 1 A \u00d7 1 s. \nThe ampere is defined by taking the fixed numerical value of the elementary charge e to be 1.602176634\u00d710\u221219 coulombs. \nThe 2019 redefinition of the ampere and other SI base units fixed the numerical value of the elementary charge when expressed in coulombs, and therefore fixed the value of the coulomb when expressed as a multiple of the fundamental charge (the numerical values of those quantities are the multiplicative inverses of each other). \nThe ampere was previously defined in terms of two wires of infinite extent.\nOne coulomb is the charge of approximately 6241509074460762607.776 elementary charges, where the number is the reciprocal of 1.602176634\u00d710\u221219 C. This is also 160.2176634 zC of charge. \nThe exact value of 1 coulomb is\n\nelementary charges where \n  \n    \n      \n        \n          \n            \n              \n                621\n                \n                837\n                \n                581\n              \n              \n                801\n                \n                088\n                \n                317\n              \n            \n          \n        \n        =\n        \n          \n            \n              \n                621\n                \n                837\n                \n                581\n              \n              \n                \n                  3\n                  \n                    2\n                  \n                \n                \u00d7\n                19\n                \u00d7\n                389\n                \u00d7\n                12\n                \n                043\n              \n            \n          \n        \n        \u2248\n        0.776\n        \n        24\n        \u2026\n      \n    \n    {\\displaystyle {\\tfrac {621\\,837\\,581}{801\\,088\\,317}}={\\tfrac {621\\,837\\,581}{3^{2}\\times 19\\times 389\\times 12\\,043}}\\approx 0.776\\,24\\ldots }\n   and the numerator \n  \n    \n      \n        621\n        \n        837\n        \n        581\n      \n    \n    {\\displaystyle 621\\,837\\,581}\n   is a prime number.\nIt is impossible to realize exactly 1 C of charge, since the number of elementary charges is not an integer. It is also impossible to realize charge at the yoctocoulomb scale.\n\n\n== SI prefixes ==\n\nLike other SI units, the coulomb can be modified by adding a prefix that multiplies it by a power of 10.\n\n\n== Conversions ==\nThe magnitude of the electrical charge of one mole of elementary charges (approximately 6.022\u00d71023, the Avogadro number) is known as a faraday unit of charge (closely related to the Faraday constant). One faraday equals 9.648533212...\u00d7104 coulombs. In terms of the Avogadro constant (NA), one coulomb is equal to approximately 1.036\u00d710\u22125 mol \u00d7 NA elementary charges.\nA capacitor of one farad can hold one coulomb at a drop of one volt.\nOne ampere hour equals 3600 C, hence 1 mA\u22c5h = 3.6 C.\nOne statcoulomb (statC), the obsolete CGS electrostatic unit of charge (esu), is approximately 3.3356\u00d710\u221210 C or about one-third of a nanocoulomb.\n\n\n== In everyday terms ==\nThe charges in static electricity from rubbing materials together are typically a few microcoulombs.\nThe amount of charge that travels through a lightning bolt is typically around 15 C, although for large bolts this can be up to 350 C.\nThe amount of charge that travels through a typical alkaline AA battery from being fully charged to discharged is about 5 kC = 5000 C \u2248 1400 mA\u22c5h.\nA typical smartphone battery can hold 10,800 C \u2248 3000 mA\u22c5h.\n\n\n== See also ==\nAbcoulomb, a cgs unit of charge\nAmp\u00e8re's circuital law\nCoulomb's law\nElectrostatics\nElementary charge\nFaraday constant, the number of coulombs per mole of elementary charges\n\n\n== Notes and references ==", "Ammeter": "An ammeter (abbreviation of Ampere meter) is an instrument used to measure the current in a circuit. Electric currents are measured in amperes (A), hence the name. For direct measurement, the ammeter is connected in series with the circuit in which the current is to be measured. An ammeter usually has low resistance so that it does not cause a significant voltage drop in the circuit being measured.\nInstruments used to measure smaller currents, in the milliampere or microampere range, are designated as milliammeters or microammeters. Early ammeters were laboratory instruments that relied on the Earth's magnetic field for operation. By the late 19th century, improved instruments were designed which could be mounted in any position and allowed accurate measurements in electric power systems. It is generally represented by letter 'A' in a circuit. \n\n\n== History ==\n\nThe relation between electric current, magnetic fields and physical forces was first noted by Hans Christian \u00d8rsted in 1820, who observed a compass needle was deflected from pointing North when a current flowed in an adjacent wire. The tangent galvanometer was used to measure currents using this effect, where the restoring force returning the pointer to the zero position was provided by the Earth's magnetic field. This made these instruments usable only when aligned with the Earth's field. Sensitivity of the instrument was increased by using additional turns of wire to multiply the effect \u2013 the instruments were called \"multipliers\".The word rheoscope as a detector of electrical currents was coined by Sir Charles Wheatstone about 1840 but is no longer used to describe electrical instruments.  The word makeup is similar to that of rheostat (also coined by Wheatstone) which was a device used to adjust the current in a circuit.  Rheostat is a historical term for a variable resistance, though unlike rheoscope may still be encountered.\n\n\n== Types ==\nSome instruments are panel meters, meant to be mounted on some sort of control panel. Of these, the flat, horizontal or vertical type is often called an edgewise meter.\n\n\n=== Moving-coil ===\n\nThe D'Arsonval galvanometer is a moving coil ammeter. It uses magnetic deflection, where current passing through a coil placed in the magnetic field of a permanent magnet causes the coil to move. The modern form of this instrument was developed by Edward Weston, and uses two spiral springs to provide the restoring force. The uniform air gap between the iron core and the permanent magnet poles make the deflection of the meter linearly proportional to current. These meters have linear scales.  Basic meter movements can have full-scale deflection for currents from about 25 microamperes to 10 milliamperes.Because the magnetic field is polarised, the meter needle acts in opposite directions for each direction of current. A DC ammeter is thus sensitive to which polarity it is connected in; most are marked with a positive terminal, but some have centre-zero mechanisms and can display currents in either direction. A moving coil meter indicates the average (mean) of a varying current through it, which is zero for AC. For this reason, moving-coil meters are only usable directly for DC, not AC.\nThis type of meter movement is extremely common for both ammeters and other meters derived from them, such as voltmeters and ohmmeters.\n\n\n=== Moving magnet ===\nMoving magnet ammeters operate on essentially the same principle as moving coil, except that the coil is mounted in the meter case, and a permanent magnet moves the needle. Moving magnet Ammeters are able to carry larger currents than moving coil instruments, often several tens of Amperes, because the coil can be made of thicker wire and the current does not have to be carried by the hairsprings. Indeed, some Ammeters of this type do not have hairsprings at all, instead using a fixed permanent magnet to provide the restoring force.\n\n\n=== Electrodynamic ===\nAn electrodynamic ammeter uses an electromagnet instead of the permanent magnet of the d'Arsonval movement. This instrument can respond to both alternating and direct current and also indicates true RMS for AC.  See Wattmeter for an alternative use for this instrument.\n\n\n=== Moving-iron ===\n\nMoving iron ammeters use a piece of iron which moves when acted upon by the electromagnetic force of a fixed coil of wire. The moving-iron meter was invented by Austrian engineer Friedrich Drexler in 1884. This type of meter responds to both direct and alternating currents (as opposed to the moving-coil ammeter, which works on direct current only). The iron element consists of a moving vane attached to a pointer, and a fixed vane, surrounded by a coil. As alternating or direct current flows through the coil and induces a magnetic field in both vanes, the vanes repel each other and the moving vane deflects against the restoring force provided by fine helical springs. The deflection of a moving iron meter is proportional to the square of the current.  Consequently, such meters would normally have a nonlinear scale, but the iron parts are usually modified in shape to make the scale fairly linear over most of its range.  Moving iron instruments indicate the RMS value of any AC waveform applied. Moving iron ammeters are commonly used to measure current in industrial frequency AC circuits.\n\n\n=== Hot-wire ===\n\nIn a hot-wire ammeter, a current passes through a wire which expands as it heats. Although these instruments have slow response time and low accuracy, they were sometimes used in measuring radio-frequency current.  These also measure true RMS for an applied AC.\n\n\n=== Digital ===\nIn much the same way as the analogue ammeter formed the basis for a wide variety of derived meters, including voltmeters, the basic mechanism for a digital meter is a digital voltmeter mechanism, and other types of meter are built around this.\nDigital ammeter designs use a shunt resistor to produce a calibrated voltage proportional to the current flowing. This voltage is then measured by a digital voltmeter, through use of an analog-to-digital converter (ADC); the digital display is calibrated to display the current through the shunt. Such instruments are often calibrated to indicate the RMS value for a sine wave only, but many designs will indicate true RMS within limitations of the wave crest factor.\n\n\n=== Integrating ===\n\nThere is also a range of devices referred to as integrating ammeters. In these ammeters the current is summed over time, giving as a result the product of current and time; which is proportional to the electrical charge transferred with that current. These can be used for metering energy (the charge needs to be multiplied by the voltage to give energy) or for estimating the charge of a battery or capacitor.\n\n\n== Picoammeter ==\nA picoammeter, or pico ammeter, measures very low electric current, usually from the picoampere range at the lower end to the milliampere range at the upper end. Picoammeters are used where the current being measured is below the limits of sensitivity of other devices, such as multimeters.\nMost picoammeters use a \"virtual short\" technique and have several different measurement ranges that must be switched between to cover multiple decades of measurement. Other modern picoammeters use log compression and a \"current sink\" method that eliminates range switching and associated voltage spikes. Special design and usage considerations must be observed in order to reduce leakage current which may swamp measurements such as special insulators and driven shields. Triaxial cable is often used for probe connections.\n\n\n== Application ==\nAmmeters must be connected in series with the circuit to be measured. For relatively small currents (up to a few amperes), an ammeter may pass the whole of the circuit current. For larger direct currents, a shunt resistor carries most of the circuit current and a small, accurately-known fraction of the current passes through the meter movement. For alternating current circuits, a current transformer may be used to provide a convenient small current to drive an instrument, such as 1 or 5 amperes, while the primary current to be measured is much larger (up to thousands of amperes). The use of a shunt or current transformer also allows convenient location of the indicating meter without the need to run heavy circuit conductors up to the point of observation. In the case of alternating current, the use of a current transformer also isolates the meter from the high voltage of the primary circuit. A shunt provides no such isolation for a direct-current ammeter, but where high voltages are used it may be possible to place the ammeter in the \"return\" side of the circuit which may be at low potential with respect to earth.\nAmmeters must not be connected directly across a voltage source since their internal resistance is very low and excess current would flow. Ammeters are designed for a low voltage drop across their terminals, much less than one volt; the extra circuit losses produced by the ammeter are called its \"burden\" on the measured circuit(I).\nOrdinary Weston-type meter movements can measure only milliamperes at most, because the springs and practical coils can carry only limited currents. To measure larger currents, a resistor called a shunt is placed in parallel with the meter. The resistances of shunts is in the integer to fractional milliohm range. Nearly all of the current flows through the shunt, and only a small fraction flows through the meter. This allows the meter to measure large currents. Traditionally, the meter used with a shunt has a full-scale deflection (FSD) of 50 mV, so shunts are typically designed to produce a voltage drop of 50 mV when carrying their full rated current.\n\nTo make a multi-range ammeter, a selector switch can be used to connect one of a number of shunts across the meter. It must be a make-before-break switch to avoid damaging current surges through the meter movement when switching ranges.\nA better arrangement is the Ayrton shunt or universal shunt, invented by William E. Ayrton, which does not require a make-before-break switch. It also avoids any inaccuracy because of contact resistance. In the figure, assuming for example, a movement with a full-scale voltage of 50 mV and desired current ranges of 10 mA, 100 mA, and 1 A, the resistance values would be: R1=4.5 ohms, R2=0.45 ohm, R3=0.05 ohm. And if the movement resistance is 1000 ohms, for example, R1 must be adjusted to 4.525 ohms.\nSwitched shunts are rarely used for currents above 10 amperes.\n\nZero-center ammeters are used for applications requiring current to be measured with both polarities, common in scientific and industrial equipment. Zero-center ammeters are also commonly placed in series with a battery. In this application, the charging of the battery deflects the needle to one side of the scale (commonly, the right side) and the discharging of the battery deflects the needle to the other side. A special type of zero-center ammeter for testing high currents in cars and trucks has a pivoted bar magnet that moves the pointer, and a fixed bar magnet to keep the pointer centered with no current. The magnetic field around the wire carrying current to be measured deflects the moving magnet.\nSince the ammeter shunt has a very low resistance, mistakenly wiring the ammeter in parallel with a voltage source will cause a short circuit, at best blowing a fuse, possibly damaging the instrument and wiring, and exposing an observer to injury.\nIn AC circuits, a current transformer can be used to convert the large current in the main circuit into a smaller current more suited to a meter. Some designs of transformer are able to directly convert the magnetic field around a conductor into a small AC current, typically either 1 A or 5 A at full rated current, that can be easily read by a meter. In a similar way, accurate AC/DC non-contact ammeters have been constructed using Hall effect magnetic field sensors. A portable hand-held clamp-on ammeter is a common tool for maintenance of industrial and commercial electrical equipment, which is temporarily clipped over a wire to measure current. Some recent types have a parallel pair of magnetically soft probes that are placed on either side of the conductor.\n\n\n== See also ==\nClamp meter\nClass of accuracy in electrical measurements\nElectric circuit\nElectrical measurements\nElectrical current#Measurement\nElectronics\nList of electronics topics\nMeasurement category\nMultimeter\nOhmmeter\nRheoscope\nVoltmeter\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\nDC Metering Circuits chapter from Lessons In Electric Circuits Vol 1 DC free ebook and Lessons In Electric Circuits series.", "Real_image": "In optics, an image is defined as the collection of focus points of light rays coming from an object. A real image is the collection of focus points actually made by converging/diverging rays, while a virtual image is the collection of focus points made by extensions of diverging or converging rays. In other words, it is an image which is located in the plane of convergence for the light rays that originate from a given object. Examples of real images include the image produced on a detector in the rear of a camera, and the image produced on an eyeball retina (the camera and eye focus light through an internal convex lens). \nIn ray diagrams (such as the images on the right), real rays of light are always represented by full, solid lines; perceived or extrapolated rays of light are represented by dashed lines. A real image occurs where rays converge, whereas a virtual image occurs where rays only appear to diverge.\nReal images can be produced by concave mirrors and converging lenses, only if the object is placed further away from the mirror/lens than the focal point, and this real image is inverted. As the object approaches the focal point the image approaches infinity, and when the object passes the focal point the image becomes virtual and is not inverted (upright image). The distance is not the same as from the object to the lenses.\nReal images may also be inspected by a second lens or lens system. This is the mechanism used by telescopes, binoculars and light microscopes. The objective lens gathers the light from the object and projects a real image within the structure of the optical instrument. A second lens or system of lenses, the eyepiece, then projects a second real image onto the retina of the eye.\n\n\n== See also ==\nFocal plane\nImage plane\nLens\nVirtual image", "Compass": "A compass is a device that shows the cardinal directions used for navigation and geographic orientation. It commonly consists of a magnetized needle or other element, such as a compass card or compass rose, which can pivot to align itself with magnetic north. Other methods may be used, including gyroscopes, magnetometers, and GPS receivers.\nCompasses often show angles in degrees: north corresponds to 0\u00b0, and the angles increase clockwise, so east is 90\u00b0, south is 180\u00b0, and west is 270\u00b0. These numbers allow the compass to show azimuths or bearings which are commonly stated in degrees. If local variation between magnetic north and true north is known, then direction of magnetic north also gives direction of true north.\nAmong the Four Great Inventions, the magnetic compass was first invented as a device for divination as early as the Chinese Han Dynasty (since c. 206 BC), and later adopted for navigation by the Song Dynasty Chinese during the 11th century. The first usage of a compass recorded in Western Europe and the Islamic world occurred around 1190.\n\n\n== Magnetic compass ==\n\nThe magnetic compass is the most familiar compass type. It functions as a pointer to \"magnetic north\", the local magnetic meridian, because the magnetized needle at its heart aligns itself with the horizontal component of the Earth's magnetic field. The magnetic field exerts a torque on the needle, pulling the North end or pole of the needle approximately toward the Earth's North magnetic pole, and pulling the other toward the Earth's South magnetic pole. The needle is mounted on a low-friction pivot point, in better compasses a jewel bearing, so it can turn easily. When the compass is held level, the needle turns until, after a few seconds to allow oscillations to die out, it settles into its equilibrium orientation.\nIn navigation, directions on maps are usually expressed with reference to geographical or true north, the direction toward the Geographical North Pole, the rotation axis of the Earth. Depending on where the compass is located on the surface of the Earth the angle between true north and magnetic north, called magnetic declination can vary widely with geographic location. The local magnetic declination is given on most maps, to allow the map to be oriented with a compass parallel to true north. The locations of the Earth's magnetic poles slowly change with time, which is referred to as geomagnetic secular variation. The effect of this means a map with the latest declination information should be used. Some magnetic compasses include means to manually compensate for the magnetic declination, so that the compass shows true directions.\n\n\n== Non-magnetic compasses ==\nThere are other ways to find north than the use of magnetism, and from a navigational point of view a total of seven possible ways exist (where magnetism is one of the seven). Two sensors that use two of the remaining six principles are often also called compasses, i.e. the gyrocompass and GPS-compass.\n\n\n=== Gyrocompass ===\n\nA gyrocompass is similar to a gyroscope. It is a non-magnetic compass that finds true north by using an (electrically powered) fast-spinning wheel and friction forces in order to exploit the rotation of the Earth. Gyrocompasses are widely used on ships. They have two main advantages over magnetic compasses:\n\nthey find true north, i.e., the direction of Earth's rotational axis, as opposed to magnetic north,\nthey are not affected by ferromagnetic metal (including iron, steel, cobalt, nickel, and various alloys) in a ship's hull. (No compass is affected by nonferromagnetic metal, although a magnetic compass will be affected by any kind of wires with electric current passing through them.)Large ships typically rely on a gyrocompass, using the magnetic compass only as a backup. Increasingly, electronic fluxgate compasses are used on smaller vessels. However, magnetic compasses are still widely in use as they can be small, use simple reliable technology, are comparatively cheap, are often easier to use than GPS, require no energy supply, and unlike GPS, are not affected by objects, e.g. trees, that can block the reception of electronic signals.\n\n\n=== GPS receivers used as compasses ===\nGPS receivers using two or more antennae mounted separately and blending the data with an inertial motion unit (IMU) can now achieve 0.02\u00b0 in heading accuracy and have startup times in seconds rather than hours for gyrocompass systems. The devices accurately determine the positions (latitudes, longitudes and altitude) of the antennae on the Earth, from which the cardinal directions can be calculated. Manufactured primarily for maritime and aviation applications, they can also detect pitch and roll of ships. Small, portable GPS receivers with only a single antenna can also determine directions if they are being moved, even if only at walking pace. By accurately determining its position on the Earth at times a few seconds apart, the device can calculate its speed and the true bearing (relative to true north) of its direction of motion. Frequently, it is preferable to measure the direction in which a vehicle is actually moving, rather than its heading, i.e. the direction in which its nose is pointing. These directions may be different if there is a crosswind or tidal current.\nGPS compasses share the main advantages of gyrocompasses. They determine true North, as opposed to magnetic North, and they are unaffected by perturbations of the Earth's magnetic field. Additionally, compared with gyrocompasses, they are much cheaper, they work better in polar regions, they are less prone to be affected by mechanical vibration, and they can be initialized far more quickly. However, they depend on the functioning of, and communication with, the GPS satellites, which might be disrupted by an electronic attack or by the effects of a severe solar storm. Gyrocompasses remain in use for military purposes (especially in submarines, where magnetic and GPS compasses are useless), but have been largely superseded by GPS compasses, with magnetic backups, in civilian contexts.\n\n\n== History ==\n\nThe first compasses in ancient Han dynasty China were made of lodestone, a naturally magnetized ore of iron. Later compasses were made of iron needles, magnetized by striking them with a lodestone, which appeared in China by 1088 during the Song Dynasty, as described by Shen Kuo. Dry compasses began to appear around 1300 in Medieval Europe and the Islamic world. This was supplanted in the early 20th century by the liquid-filled magnetic compass.\n\n\n== Modern compasses ==\n\n\n=== Magnetic compass ===\nModern compasses usually use a magnetized needle or dial inside a capsule completely filled with a liquid (lamp oil, mineral oil, white spirits, purified kerosene, or ethyl alcohol are common). While older designs commonly incorporated a flexible rubber diaphragm or airspace inside the capsule to allow for volume changes caused by temperature or altitude, some modern liquid compasses use smaller housings and/or flexible capsule materials to accomplish the same result. The liquid inside the capsule serves to damp the movement of the needle, reducing oscillation time and increasing stability. Key points on the compass, including the north end of the needle are often marked with phosphorescent, photoluminescent, or self-luminous materials to enable the compass to be read at night or in poor light. As the compass fill liquid is noncompressible under pressure, many ordinary liquid-filled compasses will operate accurately underwater to considerable depths.\nMany modern compasses incorporate a baseplate and protractor tool, and are referred to variously as \"orienteering\", \"baseplate\", \"map compass\" or \"protractor\" designs. This type of compass uses a separate magnetized needle inside a rotating capsule, an orienting \"box\" or gate for aligning the needle with magnetic north, a transparent base containing map orienting lines, and a bezel (outer dial) marked in degrees or other units of angular measurement. The capsule is mounted in a transparent baseplate containing a direction-of-travel (DOT) indicator for use in taking bearings directly from a map.\n\nOther features found on modern orienteering compasses are map and romer scales for measuring distances and plotting positions on maps, luminous markings on the face or bezels, various sighting mechanisms (mirror, prism, etc.) for taking bearings of distant objects with greater precision, gimbal-mounted, \"global\" needles for use in differing hemispheres, special rare-earth magnets to stabilize compass needles, adjustable declination for obtaining instant true bearings without resorting to arithmetic, and devices such as inclinometers for measuring gradients. The sport of orienteering has also resulted in the development of models with extremely fast-settling and stable needles utilizing rare-earth magnets for optimal use with a topographic map, a land navigation technique known as terrain association. Many marine compasses designed for use on boats with constantly shifting angles use dampening fluids such as isopar M or isopar L to limit the rapid fluctuation and direction of the needle.The military forces of a few nations, notably the United States Army, continue to issue field compasses with magnetized compass dials or cards instead of needles. A magnetic card compass is usually equipped with an optical, lensatic, or prismatic sight, which allows the user to read the bearing or azimuth off the compass card while simultaneously aligning the compass with the objective (see photo). Magnetic card compass designs normally require a separate protractor tool in order to take bearings directly from a map.The U.S. M-1950 military lensatic compass does not use a liquid-filled capsule as a damping mechanism, but rather electromagnetic induction to control oscillation of its magnetized card. A \"deep-well\" design is used to allow the compass to be used globally with a card tilt of up to 8 degrees without impairing accuracy. As induction forces provide less damping than fluid-filled designs, a needle lock is fitted to the compass to reduce wear, operated by the folding action of the rear sight/lens holder. The use of air-filled induction compasses has declined over the years, as they may become inoperative or inaccurate in freezing temperatures or extremely humid environments due to condensation or water ingress.Some military compasses, like the U.S. M-1950 (Cammenga 3H) military lensatic compass, the Silva 4b Militaire, and the Suunto M-5N(T) contain the radioactive material tritium (31H) and a combination of phosphors. The U.S. M-1950 equipped with self-luminous lighting contains 120 mCi (millicuries) of tritium. The purpose of the tritium and phosphors is to provide illumination for the compass, via radioluminescent tritium illumination, which does not require the compass to be \"recharged\" by sunlight or artificial light. However, tritium has a half-life of only about 12 years, so a compass that contains 120 mCi of tritium when new will contain only 60 when it is 12 years old, 30 when it is 24 years old, and so on. Consequently, the illumination of the display will fade.\nMariners' compasses can have two or more magnets permanently attached to a compass card, which moves freely on a pivot. A lubber line, which can be a marking on the compass bowl or a small fixed needle, indicates the ship's heading on the compass card. Traditionally the card is divided into thirty-two points (known as rhumbs), although modern compasses are marked in degrees rather than cardinal points. The glass-covered box (or bowl) contains a suspended gimbal within a binnacle. This preserves the horizontal position.\n\n\n==== Thumb compass ====\n\nA thumb compass is a type of compass commonly used in orienteering, a sport in which map reading and terrain association are paramount. Consequently, most thumb compasses have minimal or no degree markings at all, and are normally used only to orient the map to magnetic north. An oversized rectangular needle or north indicator aids visibility. Thumb compasses are also often transparent so that an orienteer can hold a map in the hand with the compass and see the map through the compass. The best models use rare-earth magnets to reduce needle settling time to 1 second or less.\n\n\n=== Solid state compasses ===\n\nSmall compasses found in clocks, mobile phones, and other electronic devices are solid-state microelectromechanical systems (MEMS) compasses, usually built out of two or three magnetic field sensors that provide data for a microprocessor. Often, the device is a discrete component which outputs either a digital or analog signal proportional to its orientation. This signal is interpreted by a controller or microprocessor and either used internally, or sent to a display unit. The sensor uses highly calibrated internal electronics to measure the response of the device to the Earth's magnetic field.\n\n\n=== Specialty compasses ===\n\nApart from navigational compasses, other specialty compasses have also been designed to accommodate specific uses. These include:\n\nQibla compass, which is used by Muslims to show the direction to Mecca for prayers.\nOptical or prismatic compass, most often used by surveyors, but also by cave explorers, foresters, and geologists. These compasses generally use a liquid-damped capsule and magnetized floating compass dial with an integral optical sight, often fitted with built-in photoluminescent or battery-powered illumination. Using the optical sight, such compasses can be read with extreme accuracy when taking bearings to an object, often to fractions of a degree. Most of these compasses are designed for heavy-duty use, with high-quality needles and jeweled bearings, and many are fitted for tripod mounting for additional accuracy.\nTrough compasses, mounted in a rectangular box whose length was often several times its width, date back several centuries. They were used for land surveying, particularly with plane tables.\n\n\n=== Limitations of the magnetic compass ===\n\nThe magnetic compass is very reliable at moderate latitudes, but in geographic regions near the Earth's magnetic poles it becomes unusable. As the compass is moved closer to one of the magnetic poles, the magnetic declination, the difference between the direction to geographical north and magnetic north, becomes greater and greater. At some point close to the magnetic pole the compass will not indicate any particular direction but will begin to drift. Also, the needle starts to point up or down when getting closer to the poles, because of the so-called magnetic inclination. Cheap compasses with bad bearings may get stuck because of this and therefore indicate a wrong direction.\nMagnetic compasses are influenced by any fields other than Earth's. Local environments may contain magnetic mineral deposits and artificial sources such as MRIs, large iron or steel bodies, electrical engines or strong permanent magnets. Any electrically conductive body produces its own magnetic field when it is carrying an electric current. Magnetic compasses are prone to errors in the neighborhood of such bodies. Some compasses include magnets which can be adjusted to compensate for external magnetic fields, making the compass more reliable and accurate.\nA compass is also subject to errors when the compass is accelerated or decelerated in an airplane or automobile. Depending on which of the Earth's hemispheres the compass is located and if the force is acceleration or deceleration the compass will increase or decrease the indicated heading. Compasses that include compensating magnets are especially prone to these errors, since accelerations tilt the needle, bringing it closer or further from the magnets.\nAnother error of the mechanical compass is turning error. When one turns from a heading of east or west the compass will lag behind the turn or lead ahead of the turn. Magnetometers, and substitutes such as gyrocompasses, are more stable in such situations.\n\n\n== Construction of a magnetic compass ==\n\n\n=== Magnetic needle ===\nA magnetic rod is required when constructing a compass. This can be created by aligning an iron or steel rod with Earth's magnetic field and then tempering or striking it. However, this method produces only a weak magnet so other methods are preferred. For example, a magnetised rod can be created by repeatedly rubbing an iron rod with a magnetic lodestone. This magnetised rod (or magnetic needle) is then placed on a low friction surface to allow it to freely pivot to align itself with the magnetic field. It is then labeled so the user can distinguish the north-pointing from the south-pointing end; in modern convention the north end is typically marked in some way.\n\n\n=== Needle-and-bowl device ===\nIf a needle is rubbed on a lodestone or other magnet, the needle becomes magnetized. When it is inserted in a cork or piece of wood, and placed in a bowl of water it becomes a compass. Such devices were universally used as compass until the invention of the box-like compass with a 'dry' pivoting needle sometime around 1300.\n\n\n=== Points of the compass ===\n\nOriginally, many compasses were marked only as to the direction of magnetic north, or to the four cardinal points (north, south, east, west). Later, these were divided, in China into 24, and in Europe into 32 equally spaced points around the compass card. For a table of the thirty-two points, see compass points.\nIn the modern era, the 360-degree system took hold. This system is still in use today for civilian navigators. The degree system spaces 360 equidistant points located clockwise around the compass dial. In the 19th century some European nations adopted the \"grad\" (also called grade or gon) system instead, where a right angle is 100 grads to give a circle of 400 grads. Dividing grads into tenths to give a circle of 4000 decigrades has also been used in armies.\nMost military forces have adopted the French \"millieme\" system. This is an approximation of a milli-radian (6283 per circle), in which the compass dial is spaced into 6400 units or \"mils\" for additional precision when measuring angles, laying artillery, etc. The value to the military is that one angular mil subtends approximately one metre at a distance of one kilometer. Imperial Russia used a system derived by dividing the circumference of a circle into chords of the same length as the radius. Each of these was divided into 100 spaces, giving a circle of 600. The Soviet Union divided these into tenths to give a circle of 6000 units, usually translated as \"mils\". This system was adopted by the former Warsaw Pact countries (e.g. Soviet Union, East Germany), often counterclockwise (see picture of wrist compass). This is still in use in Russia.\n\n\n=== Compass balancing (magnetic dip) ===\nBecause the Earth's magnetic field's inclination and intensity vary at different latitudes, compasses are often balanced during manufacture so that the dial or needle will be level, eliminating needle drag which can give inaccurate readings. Most manufacturers balance their compass needles for one of five zones, ranging from zone 1, covering most of the Northern Hemisphere, to zone 5 covering Australia and the southern oceans. This individual zone balancing prevents excessive dipping of one end of the needle which can cause the compass card to stick and give false readings.Some compasses feature a special needle balancing system that will accurately indicate magnetic north regardless of the particular magnetic zone. Other magnetic compasses have a small sliding counterweight installed on the needle itself. This sliding counterweight, called a 'rider', can be used for counterbalancing the needle against the dip caused by inclination if the compass is taken to a zone with a higher or lower dip.\n\n\n=== Compass correction ===\n\nLike any magnetic device, compasses are affected by nearby ferrous materials, as well as by strong local electromagnetic forces. Compasses used for wilderness land navigation should not be used in proximity to ferrous metal objects or electromagnetic fields (car electrical systems, automobile engines, steel pitons, etc.) as that can affect their accuracy. Compasses are particularly difficult to use accurately in or near trucks, cars or other mechanized vehicles even when corrected for deviation by the use of built-in magnets or other devices. Large amounts of ferrous metal combined with the on-and-off electrical fields caused by the vehicle's ignition and charging systems generally result in significant compass errors.\nAt sea, a ship's compass must also be corrected for errors, called deviation, caused by iron and steel in its structure and equipment. The ship is swung, that is rotated about a fixed point while its heading is noted by alignment with fixed points on the shore. A compass deviation card is prepared so that the navigator can convert between compass and magnetic headings. The compass can be corrected in three ways. First the lubber line can be adjusted so that it is aligned with the direction in which the ship travels, then the effects of permanent magnets can be corrected for by small magnets fitted within the case of the compass. The effect of ferromagnetic materials in the compass's environment can be corrected by two iron balls mounted on either side of the compass binnacle in concert with permanent magnets and a Flinders bar. The coefficient \n  \n    \n      \n        \n          a\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle a_{0}}\n   represents the error in the lubber line, while \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        ,\n        \n          b\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle a_{1},b_{1}}\n   the ferromagnetic effects and \n  \n    \n      \n        \n          a\n          \n            2\n          \n        \n        ,\n        \n          b\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle a_{2},b_{2}}\n   the non-ferromagnetic component.A similar process is used to calibrate the compass in light general aviation aircraft, with the compass deviation card often mounted permanently just above or below the magnetic compass on the instrument panel. Fluxgate electronic compasses can be calibrated automatically, and can also be programmed with the correct local compass variation so as to indicate the true heading.\n\n\n== Using a magnetic compass ==\n\nA magnetic compass points to magnetic north pole, which is approximately 1,000 miles from the true geographic North Pole. A magnetic compass's user can determine true North by finding the magnetic north and then correcting for variation and deviation. Variation is defined as the angle between the direction of true (geographic) north and the direction of the meridian between the magnetic poles. Variation values for most of the oceans had been calculated and published by 1914. Deviation refers to the response of the compass to local magnetic fields caused by the presence of iron and electric currents; one can partly compensate for these by careful location of the compass and the placement of compensating magnets under the compass itself. Mariners have long known that these measures do not completely cancel deviation; hence, they performed an additional step by measuring the compass bearing of a landmark with a known magnetic bearing. They then pointed their ship to the next compass point and measured again, graphing their results. In this way, correction tables could be created, which would be consulted when compasses were used when traveling in those locations.\nMariners are concerned about very accurate measurements; however, casual users need not be concerned with differences between magnetic and true North. Except in areas of extreme magnetic declination variance (20 degrees or more), this is enough to protect from walking in a substantially different direction than expected over short distances, provided the terrain is fairly flat and visibility is not impaired. By carefully recording distances (time or paces) and magnetic bearings traveled, one can plot a course and return to one's starting point using the compass alone.\n\nCompass navigation in conjunction with a map (terrain association) requires a different method. To take a map bearing or true bearing (a bearing taken in reference to true, not magnetic north) to a destination with a protractor compass, the edge of the compass is placed on the map so that it connects the current location with the desired destination (some sources recommend physically drawing a line). The orienting lines in the base of the compass dial are then rotated to align with actual or true north by aligning them with a marked line of longitude (or the vertical margin of the map), ignoring the compass needle entirely. The resulting true bearing or map bearing may then be read at the degree indicator or direction-of-travel (DOT) line, which may be followed as an azimuth (course) to the destination. If a magnetic north bearing or compass bearing is desired, the compass must be adjusted by the amount of magnetic declination before using the bearing so that both map and compass are in agreement. In the given example, the large mountain in the second photo was selected as the target destination on the map. Some compasses allow the scale to be adjusted to compensate for the local magnetic declination; if adjusted correctly, the compass will give the true bearing instead of the magnetic bearing.\nThe modern hand-held protractor compass always has an additional direction-of-travel (DOT) arrow or indicator inscribed on the baseplate. To check one's progress along a course or azimuth, or to ensure that the object in view is indeed the destination, a new compass reading may be taken to the target if visible (here, the large mountain). After pointing the DOT arrow on the baseplate at the target, the compass is oriented so that the needle is superimposed over the orienting arrow in the capsule. The resulting bearing indicated is the magnetic bearing to the target. Again, if one is using \"true\" or map bearings, and the compass does not have preset, pre-adjusted declination, one must additionally add or subtract magnetic declination to convert the magnetic bearing into a true bearing. The exact value of the magnetic declination is place-dependent and varies over time, though declination is frequently given on the map itself or obtainable on-line from various sites. If the hiker has been following the correct path, the compass' corrected (true) indicated bearing should closely correspond to the true bearing previously obtained from the map.\nA compass should be laid down on a level surface so that the needle only rests or hangs on the bearing fused to the compass casing \u2013 if used at a tilt, the needle might touch the casing on the compass and not move freely, hence not pointing to the magnetic north accurately, giving a faulty reading. To see if the needle is well leveled, look closely at the needle, and tilt it slightly to see if the needle is swaying side to side freely and the needle is not contacting the casing of the compass. If the needle tilts to one direction, tilt the compass slightly and gently to the opposing direction until the compass needle is horizontal, lengthwise. Items to avoid around compasses are magnets of any kind and any electronics. Magnetic fields from electronics can easily disrupt the needle, preventing it from aligning with the Earth's magnetic fields, causing inaccurate readings. The Earth's natural magnetic forces are considerably weak, measuring at 0.5 gauss and magnetic fields from household electronics can easily exceed it, overpowering the compass needle. Exposure to strong magnets, or magnetic interference can sometimes cause the magnetic poles of the compass needle to differ or even reverse. Avoid iron rich deposits when using a compass, for example, certain rocks which contain magnetic minerals, like Magnetite. This is often indicated by a rock with a surface which is dark and has a metallic luster, not all magnetic mineral bearing rocks have this indication. To see if a rock or an area is causing interference on a compass, get out of the area, and see if the needle on the compass moves. If it does, it means that the area or rock the compass was previously at is causing interference and should be avoided.\n\n\n== See also ==\n\n\n== Citations ==\n\n\n== Cited sources ==\nJohnson, G. Mark (2003). The Ultimate Desert Handbook. McGraw-Hill Professional. ISBN 978-0-07-139303-4.\nKreutz, Barbara M. (1973). \"Mediterranean Contributions to the Medieval Mariner's Compass\". Technology and Culture. 14 (3): 367\u2013383. doi:10.2307/3102323. JSTOR 3102323.\nLi Shu-hua (1954). \"Origine de la Boussole II. Aimant et Boussolee\". Isis. 45 (2): 175\u2013196. doi:10.1086/348315. JSTOR 227361. S2CID 143585290.\n\n\n== Further reading ==\nAdmiralty, Great Britain (1915) Admiralty manual of navigation, 1914, Chapter XXV: \"The Magnetic Compass (continued): the analysis and correction of the deviation\", London : HMSO, 525 p.\nAczel, Amir D. (2001) The Riddle of the Compass: The Invention that Changed the World, 1st Ed., New York : Harcourt, ISBN 0-15-600753-3\nCarlson, John B (1975). \"Multidisciplinary analysis of an Olmec hematite artifact from San Lorenzo, Veracruz, Mexico\". Science. 189 (4205): 753\u2013760. Bibcode:1975Sci...189..753C. doi:10.1126/science.189.4205.753. PMID 17777565. S2CID 33186517.\nGies, Frances and Gies, Joseph (1994) Cathedral, Forge, and Waterwheel: Technology and Invention in the Middle Age, New York : HarperCollins, ISBN 0-06-016590-1\nGubbins, David, Encyclopedia of Geomagnetism and Paleomagnetism, Springer Press (2007), ISBN 1-4020-3992-1, 978-1-4020-3992-8\nGurney, Alan (2004) Compass: A Story of Exploration and Innovation, London : Norton, ISBN 0-393-32713-2\nKing, David A. (1983). \"The Astronomy of the Mamluks\". Isis. 74 (4): 531\u2013555. doi:10.1086/353360. S2CID 144315162.\nLudwig, Karl-Heinz and Schmidtchen, Volker (1997) Metalle und Macht: 1000 bis 1600, Propyl\u00e4en Technikgeschichte, Berlin: Propyl\u00e4en Verlag, ISBN 3-549-05633-8\nMa, Huan (1997) Ying-yai sheng-lan [The overall survey of the ocean's shores (1433)], Feng, Ch'eng-ch\u00fcn (ed.) and Mills, J.V.G. (transl.), Bangkok : White Lotus Press, ISBN 974-8496-78-3\nSeidman, David, and Cleveland, Paul, The Essential Wilderness Navigator, Ragged Mountain Press (2001), ISBN 0-07-136110-3\nTaylor, E.G.R. (1951). \"The South-Pointing Needle\". Imago Mundi. 8: 1\u20137. doi:10.1080/03085695108591973.\nWilliams, J.E.D. (1992) From Sails to Satellites: the origin and development of navigational science, Oxford University Press, ISBN 0-19-856387-6\nWright, Monte Duane (1972) Most Probable Position: A History of Aerial Navigation to 1941, The University Press of Kansas, LCCN 72-79318\nZhou, Daguan (2007) The customs of Cambodia, translated into English from the French version by Paul Pelliot of Zhou's Chinese original by J. Gilman d'Arcy Paul, Phnom Penh : Indochina Books, prev publ. by Bangkok : Siam Society (1993), ISBN 974-8298-25-6\n\n\n== External links ==\n\nHandbook of Magnetic Compass Adjustment Archived 2019-05-29 at the Wayback Machine\nPaul J. Gans, The Medieval Technology Pages: Compass\nEvening Lecture To The British Association At The Southampton Meeting on Friday, August 25, 1882. Refers to compass correction by Fourier series.", "Planet": "A planet is a large, rounded astronomical body that is neither a star nor its remnant. The best available theory of planet formation is the nebular hypothesis, which posits that an interstellar cloud collapses out of a nebula to create a young protostar orbited by a protoplanetary disk. Planets grow in this disk by the gradual accumulation of material driven by gravity, a process called accretion. The Solar System has at least eight planets: the terrestrial planets Mercury, Venus, Earth and Mars, and the giant planets Jupiter, Saturn, Uranus and Neptune. These planets each rotate around an axis tilted with respect to its orbital pole. All planets of the Solar System other than Mercury possess a considerable atmosphere, and some share such features as ice caps, seasons, volcanism, hurricanes, tectonics, and even hydrology. Apart from Venus and Mars, the Solar System planets generate magnetic fields, and all except Venus and Mercury have natural satellites. The giant planets bear planetary rings, the most prominent being those of Saturn.\nThe word planet probably comes from the Greek plan\u1e17tai, meaning \"wanderers\". In antiquity, this word referred to the Sun, Moon, and five points of light visible by the naked eye that moved across the background of the stars\u2014namely, Mercury, Venus, Mars, Jupiter and Saturn. Planets have historically had religious associations: multiple cultures identified celestial bodies with gods, and these connections with mythology and folklore persist in the schemes for naming newly discovered Solar System bodies. Earth itself was recognized as a planet when heliocentrism supplanted geocentrism during the 16th and 17th centuries.\nWith the development of the telescope, the meaning of planet broadened to include objects only visible with assistance: the ice giants Uranus and Neptune; Ceres and other bodies later recognized to be part of the asteroid belt; and Pluto, later found to be the largest member of the collection of icy bodies known as the Kuiper belt. The discovery of other large objects in the Kuiper belt, particularly Eris, spurred debate about how exactly to define a planet. The International Astronomical Union (IAU) adopted a standard by which the four terrestrials and four giants qualify, placing Ceres, Pluto and Eris in the category of dwarf planet, although many planetary scientists have continued to apply the term planet more broadly.Further advances in astronomy led to the discovery of over five thousand planets outside the Solar System, termed exoplanets. These include hot Jupiters\u2014giant planets that orbit close to their parent stars\u2014like 51 Pegasi b, super-Earths like Gliese 581c that have masses in between that of Earth and Neptune; and planets smaller than Earth, like Kepler-20e. Multiple exoplanets have been found to orbit in the habitable zones of their stars, but Earth remains the only planet known to support life.\n\n\n== History ==\n\nThe idea of planets has evolved over its history, from the divine lights of antiquity to the earthly objects of the scientific age. The concept has expanded to include worlds not only in the Solar System, but in multitudes of other extrasolar systems. The consensus definition as to what counts as a planet vs. other objects orbiting the Sun has changed several times, previously encompassing asteroids, moons, and dwarf planets like Pluto, and there continues to be some disagreement today.The five classical planets of the Solar System, being visible to the naked eye, have been known since ancient times and have had a significant impact on mythology, religious cosmology, and ancient astronomy. In ancient times, astronomers noted how certain lights moved across the sky, as opposed to the \"fixed stars\", which maintained a constant relative position in the sky. Ancient Greeks called these lights \u03c0\u03bb\u03ac\u03bd\u03b7\u03c4\u03b5\u03c2 \u1f00\u03c3\u03c4\u03ad\u03c1\u03b5\u03c2 (plan\u0113tes asteres, \"wandering stars\") or simply \u03c0\u03bb\u03b1\u03bd\u1fc6\u03c4\u03b1\u03b9 (plan\u0113tai, \"wanderers\"), from which today's word \"planet\" was derived. In ancient Greece, China, Babylon, and indeed all pre-modern civilizations, it was almost universally believed that Earth was the center of the Universe and that all the \"planets\" circled Earth. The reasons for this perception were that stars and planets appeared to revolve around Earth each day and the apparently common-sense perceptions that Earth was solid and stable and that it was not moving but at rest.\n\n\n=== Babylon ===\n\nThe first civilization known to have a functional theory of the planets were the Babylonians, who lived in Mesopotamia in the first and second millennia BC. The oldest surviving planetary astronomical text is the Babylonian Venus tablet of Ammisaduqa, a 7th-century BC copy of a list of observations of the motions of the planet Venus, that probably dates as early as the second millennium BC. The MUL.APIN is a pair of cuneiform tablets dating from the 7th century BC that lays out the motions of the Sun, Moon, and planets over the course of the year. Late Babylonian astronomy is the origin of Western astronomy and indeed all Western efforts in the exact sciences. The Enuma anu enlil, written during the Neo-Assyrian period in the 7th century BC, comprises a list of omens and their relationships with various celestial phenomena including the motions of the planets. Venus, Mercury, and the outer planets Mars, Jupiter, and Saturn were all identified by Babylonian astronomers. These would remain the only known planets until the invention of the telescope in early modern times.\n\n\n=== Greco-Roman astronomy ===\n\nThe ancient Greeks initially did not attach as much significance to the planets as the Babylonians. In the 6th and 5th centuries BC, the Pythagoreans appear to have developed their own independent planetary theory, which consisted of the Earth, Sun, Moon, and planets revolving around a \"Central Fire\" at the center of the Universe. Pythagoras or Parmenides is said to have been the first to identify the evening star (Hesperos) and morning star (Phosphoros) as one and the same (Aphrodite, Greek corresponding to Latin Venus), though this had long been known in Mesopotamia. In the 3rd century BC, Aristarchus of Samos proposed a heliocentric system, according to which Earth and the planets revolved around the Sun. The geocentric system remained dominant until the Scientific Revolution.By the 1st century BC, during the Hellenistic period, the Greeks had begun to develop their own mathematical schemes for predicting the positions of the planets. These schemes, which were based on geometry rather than the arithmetic of the Babylonians, would eventually eclipse the Babylonians' theories in complexity and comprehensiveness, and account for most of the astronomical movements observed from Earth with the naked eye. These theories would reach their fullest expression in the Almagest written by Ptolemy in the 2nd century CE. So complete was the domination of Ptolemy's model that it superseded all previous works on astronomy and remained the definitive astronomical text in the Western world for 13 centuries. To the Greeks and Romans there were seven known planets, each presumed to be circling Earth according to the complex laws laid out by Ptolemy. They were, in increasing order from Earth (in Ptolemy's order and using modern names): the Moon, Mercury, Venus, the Sun, Mars, Jupiter, and Saturn.\n\n\n=== Medieval astronomy ===\n\nAfter the fall of the Western Roman Empire, astronomy developed further in India and the medieval Islamic world. In 499 CE, the Indian astronomer Aryabhata propounded a planetary model that explicitly incorporated Earth's rotation about its axis, which he explains as the cause of what appears to be an apparent westward motion of the stars. He also theorised that the orbits of planets were elliptical. Aryabhata's followers were particularly strong in South India, where his principles of the diurnal rotation of Earth, among others, were followed and a number of secondary works were based on them.The astronomy of the Islamic Golden Age mostly took place in the Middle East, Central Asia, Al-Andalus, and North Africa, and later in the Far East and India. These astronomers, like the polymath Ibn al-Haytham, generally accepted geocentrism, although they did dispute Ptolemy's system of epicycles and sought alternatives. The 10th-century astronomer Abu Sa'id al-Sijzi accepted that the Earth rotates around its axis. In the 11th century, the transit of Venus was observed by Avicenna. His contemporary Al-Biruni devised a method of determining the Earth's radius using trigonometry that, unlike the older method of Eratosthenes, only required observations at a single mountain.\n\n\n=== Scientific Revolution and new planets ===\n\nWith the advent of the Scientific Revolution and the heliocentric model of Copernicus, Galileo and Kepler, use of the term \"planet\" changed from something that moved around the sky relative to the fixed star to a body that orbited the Sun, directly (a primary planet) or indirectly (a secondary or satellite planet). Thus the Earth was added to the roster of planets and the Sun was removed. The Copernican count of primary planets stood until 1781, when William Herschel discovered Uranus.When four satellites of Jupiter (the Galilean moons) and five of Saturn were discovered in the 17th century, they were thought of as \"satellite planets\" or \"secondary planets\" orbiting the primary planets, though in the following decades they would come to be called simply \"satellites\" for short. Scientists generally considered planetary satellites to also be planets until about the 1920s, although this usage was not common among non-scientists.In the first decade of the 19th century, four new planets were discovered: Ceres (in 1801), Pallas (in 1802), Juno (in 1804), and Vesta (in 1807). It soon became apparent that they were rather different from previously known planets: they shared the same general region of space, between Mars and Jupiter (the asteroid belt), with sometimes overlapping orbits. This was an area where only one planet had been expected, and they were much much smaller than all other planets; indeed, it was suspected that they might be shards of a larger planet that had broken up. Herschel called them asteroids (from the Greek for \"starlike\") because even in the largest telescopes they resembled stars, without a resolvable disk.The situation was stable for four decades, but in the mid-1840s several additional asteroids were discovered (Astraea in 1845, Hebe in 1847,  Iris in 1847, Flora in 1848, Metis in 1848, and Hygiea in 1849), and soon new \"planets\" were discovered every year. As a result, astronomers began tabulating the asteroids (minor planets) separately from the major planets, and assigning them numbers instead of abstract planetary symbols, although they continued to be considered as small planets.Neptune was discovered in 1846, its position having been predicted thanks to its gravitational influence upon Uranus. Because the orbit of Mercury appeared to be affected in a similar way, it was believed in the late 19th century that there might be another planet even closer to the Sun. However, the discrepancy between Mercury's orbit and the predictions of Newtonian gravity was instead explained by an improved theory of gravity, Einstein's general relativity.\n\n\n=== 20th century ===\nPluto was discovered in 1930. After initial observations led to the belief that it was larger than Earth, the object was immediately accepted as the ninth major planet. Further monitoring found the body was actually much smaller: in 1936, Ray Lyttleton suggested that Pluto may be an escaped satellite of Neptune, and Fred Whipple suggested in 1964 that Pluto may be a comet. The discovery of its large moon Charon in 1978 showed that Pluto was only 0.2% the mass of Earth. As this was still substantially more massive than any known asteroid, and because no other trans-Neptunian objects had been discovered at that time, Pluto kept its planetary status, only officially losing it in 2006.In the 1950s, Gerard Kuiper published papers on the origin of the asteroids. He recognised that asteroids were typically not spherical, as had previously been thought, and that the asteroid families were remnants of collisions. Thus he differentiated between the largest asteroids as \"true planets\" versus the smaller ones as collisional fragments. From the 1960s onwards, the term \"minor planet\" was mostly displaced by the term \"asteroid\", and references to the asteroids as planets in the literature became scarce, except for the geologically evolved largest three: Ceres, and less often Pallas and Vesta.The beginning of Solar System exploration by space probes in the 1960s spurred a renewed interest in planetary science. A split in definitions regarding satellites occurred around then: planetary scientists began to reconsider the large moons as also being planets, but astronomers who were not planetary scientists generally did not.In 1992, astronomers Aleksander Wolszczan and Dale Frail announced the discovery of planets around a pulsar, PSR B1257+12. This discovery is generally considered to be the first definitive detection of a planetary system around another star. Then, on 6 October 1995, Michel Mayor and Didier Queloz of the Geneva Observatory announced the first definitive detection of an exoplanet orbiting an ordinary main-sequence star (51 Pegasi).The discovery of extrasolar planets led to another ambiguity in defining a planet: the point at which a planet becomes a star. Many known extrasolar planets are many times the mass of Jupiter, approaching that of stellar objects known as brown dwarfs. Brown dwarfs are generally considered stars due to their theoretical ability to fuse deuterium, a heavier isotope of hydrogen. Although objects more massive than 75 times that of Jupiter fuse simple hydrogen, objects of 13 Jupiter masses can fuse deuterium. Deuterium is quite rare, constituting less than 0.0026% of the hydrogen in the galaxy, and most brown dwarfs would have ceased fusing deuterium long before their discovery, making them effectively indistinguishable from supermassive planets.\n\n\n=== 21st century ===\nWith the discovery during the latter half of the 20th century of more objects within the Solar System and large objects around other stars, disputes arose over what should constitute a planet. There were particular disagreements over whether an object should be considered a planet if it was part of a distinct population such as a belt, or if it was large enough to generate energy by the thermonuclear fusion of deuterium. Complicating the matter even further, bodies too small to generate energy by fusing deuterium can form by gas-cloud collapse just like stars and brown dwarfs, even down to the mass of Jupiter: there was thus disagreement about whether how a body formed should be taken into account.A growing number of astronomers argued for Pluto to be declassified as a planet, because many similar objects approaching its size had been found in the same region of the Solar System (the Kuiper belt) during the 1990s and early 2000s. Pluto was found to be just one small body in a population of thousands. They often referred to the demotion of the asteroids as a precedent, although that had been done based on their geophysical differences from planets rather than their being in a belt. Some of the larger trans-Neptunian objects, such as Quaoar, Sedna, Eris, and Haumea were heralded in the popular press as the tenth planet.  The announcement of Eris in 2005, an object 27% more massive than Pluto, created the impetus for an official definition of a planet, as considering Pluto a planet would logically have demanded that Eris be considered a planet as well. Since different procedures were in place for naming planets versus non-planets, this created an urgent situation because under the rules Eris could not be named without defining what a planet was. At the time, it was also thought that the size required for a trans-Neptunian object to become round was about the same as that required for the moons of the giant planets (about 400 km diameter), a figure that would have suggested about 200 round objects in the Kuiper belt and thousands more beyond. Many astronomers argued that the public would not accept a definition creating a large number of planets.To acknowledge the problem, the IAU set about creating the definition of planet, and produced one in August 2006. Their definition dropped to the eight significantly larger bodies that had cleared their orbit (Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune), and a new class of dwarf planets was created, initially containing three objects (Ceres, Pluto and Eris).This definition has not been universally used or accepted. In planetary geology celestial objects have been assessed and defined as planets by geophysical characteristics. Planetary scientists are more interested in planetary geology than dynamics, so they classify planets based on their geological properties. A celestial body may acquire a dynamic (planetary) geology at approximately the mass required for its mantle to become plastic under its own weight. This leads to a state of hydrostatic equilibrium where the body acquires a stable, round shape, which is adopted as the hallmark of planethood by geophysical definitions. For example:\na substellar-mass body that has never undergone nuclear fusion and has enough gravitation to be round due to hydrostatic equilibrium, regardless of its orbital parameters.\nIn the Solar System, this mass is generally less than the mass required for a body to clear its orbit, and thus some objects that are considered \"planets\" under geophysical definitions are not considered as such under the IAU definition, such as Ceres and Pluto. Proponents of such definitions often argue that location should not matter and that planethood should be defined by the intrinsic properties of an object.\nDwarf planets had been proposed as a category of small planet (as opposed to planetoids as sub-planetary objects) and planetary geologists continue to treat them as planets despite the IAU definition.\n\nThe number of dwarf planets even among known objects is not certain. In 2019, Grundy et al. argued based on the low densities of some mid-sized trans-Neptunian objects that the limiting size required for a trans-Neptunian object to reach equilibrium was in fact much larger than it is for the icy moons of the giant planets, being about 900 km diameter. There is general consensus on Ceres in the asteroid belt and on the eight trans-Neptunians that probably cross this threshold: Quaoar, Sedna, Orcus, Pluto, Haumea, Eris, Makemake, and Gonggong. Planetary geologists may include the twenty known planetary-mass moons as \"satellite planets\", including Earth's Moon and Pluto's Charon, like the early modern astronomers. Some go even further and include as planets relatively large, geologically evolved bodies that are nonetheless not very round today, such as Pallas and Vesta, or rounded bodies that were completely disrupted by impacts and re-accreted like Hygiea.The 2006 IAU definition presents some challenges for exoplanets because the language is specific to the Solar System and the criteria of roundness and orbital zone clearance are not presently observable for exoplanets. There is no official definition of exoplanets, but the IAU's working group on the topic adopted a provisional statement in 2018.\nAstronomer Jean-Luc Margot proposed a mathematical criterion that determines whether an object can clear its orbit during the lifetime of its host star, based on the mass of the planet, its semimajor axis, and the mass of its host star. The formula produces a value called \u03c0 that is greater than 1 for planets. The eight known planets and all known exoplanets have \u03c0 values above 100, while Ceres, Pluto, and Eris have \u03c0 values of 0.1, or less. Objects with \u03c0 values of 1 or more are expected to be approximately spherical, so that objects that fulfill the orbital-zone clearance requirement around Sun-like stars will also fulfill the roundness requirement.\n\n\n== Definition and similar concepts ==\n\nAt the 2006 meeting of the IAU's General Assembly, after much debate and one failed proposal, \nthe following definition was passed in a resolution voted for by a large majority of those remaining at the meeting, addressing particularly the issue of the lower limits for a celestial object to be defined as a planet. The 2006 resolution defines planets within the Solar System as follows:\nA \"planet\" [1] is a celestial body inside the Solar System that (a) is in orbit around the Sun, (b) has sufficient mass for its self-gravity to overcome rigid body forces so that it assumes a hydrostatic equilibrium (nearly round) shape, and (c) has cleared the neighbourhood around its orbit.\n[1] The eight planets are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\nUnder this definition, the Solar System is considered to have eight planets. Bodies that fulfill the first two conditions but not the third are classified as dwarf planets, provided they are not natural satellites of other planets. Originally an IAU committee had proposed a definition that would have included a larger number of planets as it did not include (c) as a criterion. After much discussion, it was decided via a vote that those bodies should instead be classified as dwarf planets.This definition is based in modern theories of planetary formation, in which planetary embryos initially clear their orbital neighborhood of other smaller objects. As described below, planets form by material accreting together in a disk of matter surrounding a protostar. This process results in a collection of relatively substantial objects, each of which has either \"swept up\" or scattered away most of the material that had been orbiting near it. These objects do not collide with one another because they are too far apart, sometimes in orbital resonance.\n\n\n=== Exoplanet ===\n\nThe 2006 IAU definition presents some challenges for exoplanets because the language is specific to the Solar System and the criteria of roundness and orbital zone clearance are not presently observable for exoplanets. The IAU working group on extrasolar planets (WGESP) issued a working definition in 2001 and amended it in 2003. In 2018, this definition was reassessed and updated as knowledge of exoplanets increased. The current official working definition of an exoplanet is as follows:\n\nObjects with true masses below the limiting mass for thermonuclear fusion of deuterium (currently calculated to be 13 Jupiter masses for objects of solar metallicity) that orbit stars, brown dwarfs or stellar remnants and that have a mass ratio with the central object below the L4/L5 instability (M/Mcentral < 2/(25+\u221a621) are \"planets\" (no matter how they formed). The minimum mass/size required for an extrasolar object to be considered a planet should be the same as that used in our Solar System.\nSubstellar objects with true masses above the limiting mass for thermonuclear fusion of deuterium are \"brown dwarfs\", no matter how they formed nor where they are located.\nFree-floating objects in young star clusters with masses below the limiting mass for thermonuclear fusion of deuterium are not \"planets\", but are \"sub-brown dwarfs\" (or whatever name is most appropriate).\nThe IAU noted that this definition could be expected to evolve as knowledge improves. A 2022 review article discussing the history and rationale of this definition suggested that the words \"in young star clusters\" should be deleted in clause 3, as such objects have now been found elsewhere, and that the term \"sub-brown dwarfs\" should be replaced by the more current \"free-floating planetary mass objects\".\n\n\n=== Planetary-mass object ===\n\nGeoscientists often reject the IAU definition, preferring to consider round moons and dwarf planets as also being planets. Some scientists who accept the IAU definition of \"planet\" use other terms for bodies satisfying geophysical planet definitions, such as \"world\". The term \"planetary mass object\" has also been used to refer to ambiguous situations concerning exoplanets, such as objects with mass typical for a planet that are free-floating or orbit a brown dwarf instead of a star.\n\n\n== Mythology and naming ==\n\nNaming of planets differs between planets of the Solar System and Exoplanets (planets of other planetary systems). Latter are commonly named after their parent star and their order of discovery within its planetary system, such as Proxima Centauri b.\nThe names for the planets of the Solar System (other than Earth) in the English language are derived from naming practices developed consecutively by the Babylonians, Greeks and Romans of antiquity. The practice of grafting the names of gods onto the planets was almost certainly borrowed from the Babylonians by the ancient Greeks, and thereafter from the Greeks by the Romans. The Babylonians named Venus after the Sumerian goddess of love with the Akkadian name Ishtar; Mars after their god of war, Nergal; Mercury after their god of wisdom Nabu; and Jupiter after their chief god, Marduk. There are too many concordances between Greek and Babylonian naming conventions for them to have arisen separately. Given the differences in mythology, the correspondence was not perfect. For instance, the Babylonian Nergal was a god of war, and thus the Greeks identified him with Ares. Unlike Ares, Nergal was also a god of pestilence and ruler of the underworld.In ancient Greece, the two great luminaries, the Sun and the Moon, were called Helios and Selene, two ancient Titanic deities; the slowest planet, Saturn, was called Phainon, the shiner; followed by Phaethon, Jupiter, \"bright\"; the red planet, Mars was known as Pyroeis, the \"fiery\"; the brightest, Venus, was known as Phosphoros, the light bringer; and the fleeting final planet, Mercury, was called Stilbon, the gleamer. The Greeks assigned each planet to one among their pantheon of gods, the Olympians and the earlier Titans:\nHelios and Selene were the names of both planets and gods, both of them Titans (later supplanted by Olympians Apollo and Artemis);\nPhainon was sacred to Cronus, the Titan who fathered the Olympians;\nPhaethon was sacred to Zeus, Cronus's son who deposed him as king;\nPyroeis was given to Ares, son of Zeus and god of war;\nPhosphoros was ruled by Aphrodite, the goddess of love; and\nStilbon with its speedy motion, was ruled over by Hermes, messenger of the gods and god of learning and wit.\nAlthough modern Greeks still use their ancient names for the planets, other European languages, because of the influence of the Roman Empire and, later, the Catholic Church, use the Roman (Latin) names rather than the Greek ones. The Romans inherited Proto-Indo-European mythology as the Greeks did and shared with them a common pantheon under different names, but the Romans lacked the rich narrative traditions that Greek poetic culture had given their gods. During the later period of the Roman Republic, Roman writers borrowed much of the Greek narratives and applied them to their own pantheon, to the point where they became virtually indistinguishable. When the Romans studied Greek astronomy, they gave the planets their own gods' names: Mercurius (for Hermes), Venus (Aphrodite), Mars (Ares), Iuppiter (Zeus) and Saturnus (Cronus). Some Romans, following a belief possibly originating in Mesopotamia but developed in Hellenistic Egypt, believed that the seven gods after whom the planets were named took hourly shifts in looking after affairs on Earth. The order of shifts went Saturn, Jupiter, Mars, Sun, Venus, Mercury, Moon (from the farthest to the closest planet). Therefore, the first day was started by Saturn (1st hour), second day by Sun (25th hour), followed by Moon (49th hour), Mars, Mercury, Jupiter and Venus. Because each day was named by the god that started it, this became the order of the days of the week in the Roman calendar. In English, Saturday, Sunday, and Monday are straightforward translations of these Roman names. The other days were renamed after T\u012bw (Tuesday), W\u014dden (Wednesday), \u00deunor (Thursday), and Fr\u012b\u0121 (Friday), the Anglo-Saxon gods considered similar or equivalent to Mars, Mercury, Jupiter, and Venus, respectively.Earth's name in English is not derived from Greco-Roman mythology. Because it was only generally accepted as a planet in the 17th century, there is no tradition of naming it after a god. (The same is true, in English at least, of the Sun and the Moon, though they are no longer generally considered planets.) The name originates from the Old English word eor\u00fee, which was the word for \"ground\" and \"dirt\" as well as the world itself. As with its equivalents in the other Germanic languages, it derives ultimately from the Proto-Germanic word er\u00fe\u014d, as can be seen in the English earth, the German Erde, the Dutch aarde, and the Scandinavian jord. Many of the Romance languages retain the old Roman word terra (or some variation of it) that was used with the meaning of \"dry land\" as opposed to \"sea\". The non-Romance languages use their own native words. The Greeks retain their original name, \u0393\u03ae (Ge).Non-European cultures use other planetary-naming systems. India uses a system based on the Navagraha, which incorporates the seven traditional planets and the ascending and descending lunar nodes Rahu and Ketu. The planets are Surya 'Sun', Chandra 'Moon', Budha for Mercury, Shukra ('bright') for Venus, Mangala (the god of war) for Mars, B\u1e5bhaspati (councilor of the gods) for Jupiter, and Shani (symbolic of time) for Saturn.The native Persian names of most of the planets are based on identifications of the Mesopotamian gods with Iranian gods, analogous to the Greek and Latin names. Mercury is Tir (\u062a\u06cc\u0631) for the western Iranian god T\u012briya (patron of scribes), analogous to Nabu; Venus is N\u0101hid (\u0646\u0627\u0647\u06cc\u062f) for Anahita; Mars is Bahr\u0101m (\u0628\u0647\u0631\u0627\u0645) for Verethragna; and Jupiter is Hormoz (\u0647\u0631\u0645\u0632) for Ahura Mazda. The Persian name for Saturn, Keyv\u0101n (\u06a9\u06cc\u0648\u0627\u0646), is a borrowing from Akkadian kajam\u0101nu, meaning \"the permanent, steady\".China and the countries of eastern Asia historically subject to Chinese cultural influence (such as Japan, Korea and Vietnam) use a naming system based on the five Chinese elements: water (Mercury \u6c34\u661f \"water star\"), metal (Venus \u91d1\u661f \"metal star\"), fire (Mars \u706b\u661f \"fire star\"), wood (Jupiter \u6728\u661f \"wood star\") and earth (Saturn \u571f\u661f \"earth star\"). The names of Uranus (\u5929\u738b\u661f \"sky king star\"), Neptune (\u6d77\u738b\u661f \"sea king star\"), and Pluto (\u51a5\u738b\u661f \"underworld king star\") in Chinese, Korean, and Japanese are calques based on the roles of those gods in Roman and Greek mythology. Chinese uses calques for the dwarf planets and many asteroids as well, e.g. Eris (\u9b29\u795e\u661f \"quarrel goddess star\"), Ceres (\u7a40\u795e\u661f \"grain goddess star\"), and Pallas (\u667a\u795e\u661f \"wisdom goddess star\").In traditional Hebrew astronomy, the seven traditional planets have (for the most part) descriptive names \u2013 the Sun is \u05d7\u05de\u05d4 \u1e24ammah or \"the hot one\", the Moon is \u05dc\u05d1\u05e0\u05d4 Levanah or \"the white one\", Venus is \u05db\u05d5\u05db\u05d1 \u05e0\u05d5\u05d2\u05d4 Kokhav Nogah or \"the bright planet\", Mercury is \u05db\u05d5\u05db\u05d1 Kokhav or \"the planet\" (given its lack of distinguishing features), Mars is \u05de\u05d0\u05d3\u05d9\u05dd Ma'adim or \"the red one\", and Saturn is \u05e9\u05d1\u05ea\u05d0\u05d9 Shabbatai or \"the resting one\" (in reference to its slow movement compared to the other visible planets). The odd one out is Jupiter, called \u05e6\u05d3\u05e7 Tzedeq or \"justice\". Hebrew names were chosen for Uranus (\u05d0\u05d5\u05e8\u05d5\u05df Oron, \"small light\") and Neptune (\u05e8\u05d4\u05d1 Rahab, a Biblical sea monster) in 2009; prior to that the names \"Uranus\" and \"Neptune\" had simply been borrowed. The etymologies for the Arabic names of the planets are less well understood. Mostly agreed among scholars are Venus \u0627\u0644\u0632\u0647\u0631\u0629 (az-Zuhara, \"the bright one\"), Earth \u0627\u0644\u0623\u0631\u0636 (al-\u02beAr\u1e0d, from the same root as eretz), and Saturn \u0632\u064f\u062d\u064e\u0644 (Zu\u1e25al, \"withdrawer\"). Multiple suggested etymologies exist for Mercury \u0639\u064f\u0637\u064e\u0627\u0631\u0650\u062f (\u02bfU\u1e6d\u0101rid), Mars \u0627\u064e\u0644\u0652\u0645\u0650\u0631\u0650\u0651\u064a\u062e (al-Mirr\u012bkh), and Jupiter \u0627\u0644\u0645\u0634\u062a\u0631\u064a (al-Mu\u0161tar\u012b), but there is no agreement among scholars.When subsequent planets were discovered in the 18th and 19th centuries, Uranus was named for a Greek deity and Neptune for a Roman one (the counterpart of Poseidon). The asteroids were initially named from mythology as well \u2013 Ceres, Juno, and Vesta are major Roman goddesses, and Pallas is an epithet of the Greek goddess Athena \u2013 but as more and more were discovered, the mythological restriction was dropped starting from Massalia in 1852. Pluto was given a classical name, as it was considered a major planet when it was discovered. After more objects were discovered beyond Neptune, naming conventions depending on their orbits were put in place: those in the 2:3 resonance with Neptune (the plutinos) are given names from underworld myths, while others are given names from creation myths. Most of the trans-Neptunian dwarf planets are named after gods and goddesses from other cultures (e.g. Quaoar is named after a Tongva god), except for Orcus and Eris which continued the Roman and Greek scheme.The moons (including the planetary-mass ones) are generally given names with some association with their parent planet. The planetary-mass moons of Jupiter are named after four of Zeus' lovers (or other sexual partners); those of Saturn are named after Cronus' brothers and sisters, the Titans; those of Uranus are named after characters from Shakespeare and Pope (originally specifically from fairy mythology, but that ended with the naming of Miranda). Neptune's planetary-mass moon Triton is named after the god's son; Pluto's planetary-mass moon Charon is named after the ferryman of the dead, who carries the souls of the newly deceased to the underworld (Pluto's domain); and Eris' only known moon Dysnomia is named after one of Eris' daughters, the spirit of lawlessness.\n\n\n=== Symbols ===\n\nThe written symbols for Mercury, Venus, Jupiter, Saturn and possibly Mars have been traced to forms found in late Greek papyrus texts. The symbols for Jupiter and Saturn are identified as monograms of the corresponding Greek names, and the symbol for Mercury is a stylized caduceus.According to Annie Scott Dill Maunder, antecedents of the planetary symbols were used in art to represent the gods associated with the classical planets. Bianchini's planisphere, discovered by Francesco Bianchini in the 18th century but produced in the 2nd century, shows Greek personifications of planetary gods charged with early versions of the planetary symbols. Mercury has a caduceus; Venus has, attached to her necklace, a cord connected to another necklace; Mars, a spear; Jupiter, a staff; Saturn, a scythe; the Sun, a circlet with rays radiating from it; and the Moon, a headdress with a crescent attached. The modern shapes with the cross-marks first appeared around the 16th century. According to Maunder, the addition of crosses appears to be \"an attempt to give a savour of Christianity to the symbols of the old pagan gods.\" Earth itself was not considered a classical planet; its symbol descends from a pre-heliocentric symbol for the four corners of the world.When further planets were discovered orbiting the Sun, symbols were invented for them. The most common astronomical symbol for Uranus, \u26e2, was invented by Johann Gottfried K\u00f6hler, and was intended to represent the newly discovered metal platinum. An alternative symbol, \u2645, was invented by J\u00e9r\u00f4me Lalande, and represents a globe with a H on top, for Uranus' discoverer Herschel. Today, \u26e2 is mostly used by astronomers and \u2645 by astrologers, though it is possible to find each symbol in the other context. The first few asteroids were similarly given abstract symbols, but as their number rose further and further, this practice stopped in favour of numbering them instead. Neptune's symbol (\u2646) represents the god's trident. The astronomical symbol for Pluto is a P-L monogram (\u2647), though it has become less common since the IAU definition reclassified Pluto. Since Pluto's reclassification, NASA has used the traditional astrological symbol of Pluto (\u2bd3), a planetary orb over Pluto's bident.\nThe IAU discourages the use of planetary symbols in modern journal articles in favour of one-letter or (to disambiguate Mercury and Mars) two-letter abbreviations for the major planets. The symbols for the Sun and Earth are nonetheless common, as solar mass, Earth mass and similar units are common in astronomy. Other planetary symbols today are mostly encountered in astrology. Astrologers have started reusing the old astronomical symbols for the first few asteroids, and continue to invent symbols for other objects, though most proposed symbols are only used by their proposers. Unicode includes some relatively standard astrological symbols for some minor planets, including the dwarf planets discovered in the 21st century, though astronomical use of any of them is rare.\n\n\n== Formation ==\n\nIt is not known with certainty how planets are built. The prevailing theory is that they are formed during the collapse of a nebula into a thin disk of gas and dust. A protostar forms at the core, surrounded by a rotating protoplanetary disk. Through accretion (a process of sticky collision) dust particles in the disk steadily accumulate mass to form ever-larger bodies. Local concentrations of mass known as planetesimals form, and these accelerate the accretion process by drawing in additional material by their gravitational attraction. These concentrations become ever denser until they collapse inward under gravity to form protoplanets. After a planet reaches a mass somewhat larger than Mars' mass, it begins to accumulate an extended atmosphere, greatly increasing the capture rate of the planetesimals by means of atmospheric drag.  Depending on the accretion history of solids and gas, a giant planet, an ice giant, or a terrestrial planet may result. It is thought that the regular satellites of Jupiter, Saturn, and Uranus formed in a similar way; however, Triton was likely captured by Neptune, and Earth's Moon and Pluto's Charon might have formed in collisions.When the protostar has grown such that it ignites to form a star, the surviving disk is removed from the inside outward by photoevaporation, the solar wind, Poynting\u2013Robertson drag and other effects. Thereafter there still may be many protoplanets orbiting the star or each other, but over time many will collide, either to form a larger, combined protoplanet or release material for other protoplanets to absorb. Those objects that have become massive enough will capture most matter in their orbital neighbourhoods to become planets. Protoplanets that have avoided collisions may become natural satellites of planets through a process of gravitational capture, or remain in belts of other objects to become either dwarf planets or small bodies.\n\nThe energetic impacts of the smaller planetesimals (as well as radioactive decay) will heat up the growing planet, causing it to at least partially melt. The interior of the planet begins to differentiate by density, with higher density materials sinking toward the core. Smaller terrestrial planets lose most of their atmospheres because of this accretion, but the lost gases can be replaced by outgassing from the mantle and from the subsequent impact of comets. (Smaller planets will lose any atmosphere they gain through various escape mechanisms.)\nWith the discovery and observation of planetary systems around stars other than the Sun, it is becoming possible to elaborate, revise or even replace this account. The level of metallicity\u2014an astronomical term describing the abundance of chemical elements with an atomic number greater than 2 (helium)\u2014appears to determine the likelihood that a star will have planets. Hence, a metal-rich population I star is more likely to have a substantial planetary system than a metal-poor, population II star.\n\n\n== Solar System ==\n\nAccording to the IAU definition, there are eight planets in the Solar System, which are (in increasing distance from the Sun): Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus and Neptune. Jupiter is the largest, at 318 Earth masses, whereas Mercury is the smallest, at 0.055 Earth masses.The planets of the Solar System can be divided into categories based on their composition. Terrestrials are similar to Earth, with bodies largely composed of rock and metal: Mercury, Venus, Earth, and Mars. Earth is the largest terrestrial planet. Giant planets are significantly more massive than the terrestrials: Jupiter, Saturn, Uranus, and Neptune. They differ from the terrestrial planets in composition. The gas giants, Jupiter and Saturn, are primarily composed of hydrogen and helium and are the most massive planets in the Solar System. Saturn is one third as massive as Jupiter, at 95 Earth masses. The ice giants, Uranus and Neptune, are primarily composed of low-boiling-point materials such as water, methane, and ammonia, with thick atmospheres of hydrogen and helium. They have a significantly lower mass than the gas giants (only 14 and 17 Earth masses).Dwarf planets are gravitationally rounded, but have not cleared their orbits of other bodies. In increasing order of average distance from the Sun, the ones generally agreed among astronomers are Ceres, Orcus, Pluto, Haumea, Quaoar, Makemake, Gonggong, Eris and Sedna. Ceres is the largest object in the asteroid belt, located between the orbits of Mars and Jupiter. The other eight all orbit beyond Neptune. Orcus, Pluto, Haumea, Quaoar, and Makemake orbit in the Kuiper belt, which is a second belt of small Solar System bodies beyond the orbit of Neptune. Gonggong and Eris orbit in the scattered disc, which is somewhat further out and, unlike the Kuiper belt, is unstable towards interactions with Neptune. Sedna is the largest known detached object, a population that never comes close enough to the Sun to interact with any of the classical planets; the origins of their orbits are still being debated. All nine are similar to terrestrial planets in having a solid surface, but they are made of ice and rock, rather than rock and metal. Moreover, all of them are smaller than Mercury, with Pluto being the largest known dwarf planet, and Eris being the most massive known.There are at least twenty planetary-mass moons or satellite planets\u2014moons large enough to take on ellipsoidal shapes (though Dysnomia's shape has never been measured, it is massive and dense enough to be a solid body). The twenty generally agreed are as follows.\nOne satellite of Earth: the Moon\nFour satellites of Jupiter: Io, Europa, Ganymede, and Callisto\nSeven satellites of Saturn: Mimas, Enceladus, Tethys, Dione, Rhea, Titan, and Iapetus\nFive satellites of Uranus: Miranda, Ariel, Umbriel, Titania, and Oberon\nOne satellite of Neptune: Triton\nOne satellite of Pluto: Charon\nOne satellite of Eris: DysnomiaThe Moon, Io, and Europa have compositions similar to the terrestrial planets; the others are made of ice and rock like the dwarf planets, with Tethys being made of almost pure ice. (Europa is often considered an icy planet, though, because its surface ice layer makes it difficult to study its interior.) Ganymede and Titan are larger than Mercury by radius, and Callisto almost equals it, but all three are much less massive. Mimas is the smallest object generally agreed to be a geophysical planet, at about six millionths of Earth's mass, though there are many larger bodies that may not be geophysical planets (e.g. Salacia).\n\n\n=== Planetary attributes ===\nThe tables below summarise some properties of objects generally agreed to satisfy geophysical planet definitions. There are many smaller dwarf planet candidates, such as Salacia, that have not been included in the tables because astronomers disagree on whether or not they are dwarf planets. The diameters, masses, orbital periods, and rotation periods of the major planets are available from the Jet Propulsion Laboratory. JPL also provides their semi-major axes, inclinations, and eccentricities of planetary orbits, and the axial tilts are taken from their Horizons database. Other information is summarized by NASA. The data for the dwarf planets and planetary-mass moons is taken from list of gravitationally rounded objects of the Solar System, with sources listed there.\n\nAs all the planetary-mass moons exhibit synchronous rotation, their rotation periods equal their orbital periods.\n\n\n== Exoplanets ==\n\nAn exoplanet (extrasolar planet) is a planet outside the Solar System. As of 1 April 2023, there are 5,346 confirmed exoplanets in 3,943 planetary systems, with 855 systems having more than one planet. Known exoplanets range in size from gas giants about twice as large as Jupiter down to just over the size of the Moon. Analysis of gravitational microlensing data suggests a minimum average of 1.6 bound planets for every star in the Milky Way.In early 1992, radio astronomers Aleksander Wolszczan and Dale Frail announced the discovery of two planets orbiting the pulsar PSR 1257+12. This discovery was confirmed, and is generally considered to be the first definitive detection of exoplanets. Researchers suspect they formed from a disk remnant left over from the supernova that produced the pulsar.The first confirmed discovery of an extrasolar planet orbiting an ordinary main-sequence star occurred on 6 October 1995, when Michel Mayor and Didier Queloz of the University of Geneva announced the detection of 51 Pegasi b, an exoplanet around 51 Pegasi. From then until the Kepler mission most known extrasolar planets were gas giants comparable in mass to Jupiter or larger as they were more easily detected. The catalog of Kepler candidate planets consists mostly of planets the size of Neptune and smaller, down to smaller than Mercury.In 2011, the Kepler Space Telescope team reported the discovery of the first Earth-sized extrasolar planets orbiting a Sun-like star, Kepler-20e and Kepler-20f. Since that time, more than 100 planets have been identified that are approximately the same size as Earth, 20 of which orbit in the habitable zone of their star \u2013 the range of orbits where a terrestrial planet could sustain liquid water on its surface, given enough atmospheric pressure. One in five Sun-like stars is thought to have an Earth-sized planet in its habitable zone, which suggests that the nearest would be expected to be within 12 light-years distance from Earth. The frequency of occurrence of such terrestrial planets is one of the variables in the Drake equation, which estimates the number of intelligent, communicating civilizations that exist in the Milky Way.There are types of planets that do not exist in the Solar System: super-Earths and mini-Neptunes, which have masses between that of Earth and Neptune. Such planets could be rocky like Earth or a mixture of volatiles and gas like Neptune\u2014the dividing line between the two possibilities is currently thought to occur at about twice the mass of Earth. The planet Gliese 581c, with mass 5.5\u201310.4 times the mass of Earth, attracted attention upon its discovery for potentially being in the habitable zone, though later studies concluded that it is actually too close to its star to be habitable. Exoplanets have been found that are much closer to their parent star than any planet in the Solar System is to the Sun. Mercury, the closest planet to the Sun at 0.4 AU, takes 88 days for an orbit, but ultra-short period planets can orbit in less than a day. The Kepler-11 system has five of its planets in shorter orbits than Mercury's, all of them much more massive than Mercury. There are hot Jupiters, such as 51 Pegasi b, that orbit very close to their star and may evaporate to become chthonian planets, which are the leftover cores. There are also exoplanets that are much farther from their star. Neptune is 30 AU from the Sun and takes 165 years to orbit, but there are exoplanets that are thousands of AU from their star and take more than a million years to orbit. e.g. COCONUTS-2b.\n\n\n== Attributes ==\nAlthough each planet has unique physical characteristics, a number of broad commonalities do exist among them. Some of these characteristics, such as rings or natural satellites, have only as yet been observed in planets in the Solar System, whereas others are commonly observed in extrasolar planets.\n\n\n=== Dynamic characteristics ===\n\n\n==== Orbit ====\n\nIn the Solar System, all the planets orbit the Sun in the same direction as the Sun rotates: counter-clockwise as seen from above the Sun's north pole. At least one extrasolar planet, WASP-17b, has been found to orbit in the opposite direction to its star's rotation. The period of one revolution of a planet's orbit is known as its sidereal period or year. A planet's year depends on its distance from its star; the farther a planet is from its star, the longer the distance it must travel and the slower its speed, since it is less affected by its star's gravity.\nNo planet's orbit is perfectly circular, and hence the distance of each from the host star varies over the course of its year. The closest approach to its star is called its periastron, or perihelion in the Solar System, whereas its farthest separation from the star is called its apastron (aphelion). As a planet approaches periastron, its speed increases as it trades gravitational potential energy for kinetic energy, just as a falling object on Earth accelerates as it falls. As the planet nears apastron, its speed decreases, just as an object thrown upwards on Earth slows down as it reaches the apex of its trajectory.Each planet's orbit is delineated by a set of elements:\n\nThe eccentricity of an orbit describes the elongation of a planet's elliptical (oval) orbit. Planets with low eccentricities have more circular orbits, whereas planets with high eccentricities have more elliptical orbits. The planets and large moons in the Solar System have relatively low eccentricities, and thus nearly circular orbits. The comets and many Kuiper belt objects, as well as several extrasolar planets, have very high eccentricities, and thus exceedingly elliptical orbits.\nThe semi-major axis gives the size of the orbit. It is the distance from the midpoint to the longest diameter of its elliptical orbit. This distance is not the same as its apastron, because no planet's orbit has its star at its exact centre.\nThe inclination of a planet tells how far above or below an established reference plane its orbit is tilted. In the Solar System, the reference plane is the plane of Earth's orbit, called the ecliptic. For extrasolar planets, the plane, known as the sky plane or plane of the sky, is the plane perpendicular to the observer's line of sight from Earth. The eight planets of the Solar System all lie very close to the ecliptic; comets and Kuiper belt objects like Pluto are at far more extreme angles to it. The large moons are generally not very inclined to their parent planets' equators, but Earth's Moon, Saturn's Iapetus, and Neptune's Triton are exceptions. Triton is unique among the large moons in that it orbits retrograde, i.e. in the direction opposite to its parent planet's rotation.\nThe points at which a planet crosses above and below its reference plane are called its ascending and descending nodes. The longitude of the ascending node is the angle between the reference plane's 0 longitude and the planet's ascending node. The argument of periapsis (or perihelion in the Solar System) is the angle between a planet's ascending node and its closest approach to its star.\n\n\n==== Axial tilt ====\n\nPlanets have varying degrees of axial tilt; they spin at an angle to the plane of their stars' equators. This causes the amount of light received by each hemisphere to vary over the course of its year; when the northern hemisphere points away from its star, the southern hemisphere points towards it, and vice versa. Each planet therefore has seasons, resulting in changes to the climate over the course of its year. The time at which each hemisphere points farthest or nearest from its star is known as its solstice. Each planet has two in the course of its orbit; when one hemisphere has its summer solstice with its day being the longest, the other has its winter solstice when its day is shortest. The varying amount of light and heat received by each hemisphere creates annual changes in weather patterns for each half of the planet. Jupiter's axial tilt is very small, so its seasonal variation is minimal; Uranus, on the other hand, has an axial tilt so extreme it is virtually on its side, which means that its hemispheres are either continually in sunlight or continually in darkness around the time of its solstices. Among extrasolar planets, axial tilts are not known for certain, though most hot Jupiters are believed to have a negligible axial tilt as a result of their proximity to their stars. Similarly, the axial tilts of the planetary-mass moons are near zero, with Earth's Moon at 6.687\u00b0 as the biggest exception; additionally, Callisto's axial tilt varies between 0 and about 2 degrees on timescales of thousands of years.\n\n\n==== Rotation ====\n\nThe planets rotate around invisible axes through their centres. A planet's rotation period is known as a stellar day. Most of the planets in the Solar System rotate in the same direction as they orbit the Sun, which is counter-clockwise as seen from above the Sun's north pole. The exceptions are Venus and Uranus, which rotate clockwise, though Uranus's extreme axial tilt means there are differing conventions on which of its poles is \"north\", and therefore whether it is rotating clockwise or anti-clockwise. Regardless of which convention is used, Uranus has a retrograde rotation relative to its orbit.\n\nThe rotation of a planet can be induced by several factors during formation. A net angular momentum can be induced by the individual angular momentum contributions of accreted objects. The accretion of gas by the giant planets contributes to the angular momentum. Finally, during the last stages of planet building, a stochastic process of protoplanetary accretion can randomly alter the spin axis of the planet. There is great variation in the length of day between the planets, with Venus taking 243 days to rotate, and the giant planets only a few hours. The rotational periods of extrasolar planets are not known, but for hot Jupiters, their proximity to their stars means that they are tidally locked (that is, their orbits are in sync with their rotations). This means, they always show one face to their stars, with one side in perpetual day, the other in perpetual night. Mercury and Venus, the closest planets to the Sun, similarly exhibit very slow rotation: Mercury is tidally locked into a 3:2 spin\u2013orbit resonance (rotating three times for every two revolutions around the Sun), and Venus' rotation may be in equilibrium between tidal forces slowing it down and atmospheric tides created by solar heating speeding it up.All the large moons are tidally locked to their parent planets; Pluto and Charon are tidally locked to each other, as are Eris and Dysnomia. Orcus and its moon Vanth may be another example of mutual tidal locking, but the data is not conclusive. The other dwarf planets with known rotation periods rotate faster than Earth; Haumea rotates so fast that it has been distorted into a triaxial ellipsoid. The exoplanet Tau Bo\u00f6tis b and its parent star Tau Bo\u00f6tis appear to be mutually tidally locked.\n\n\n==== Orbital clearing ====\n\nThe defining dynamic characteristic of a planet, according to the IAU definition, is that it has cleared its neighborhood. A planet that has cleared its neighborhood has accumulated enough mass to gather up or sweep away all the planetesimals in its orbit. In effect, it orbits its star in isolation, as opposed to sharing its orbit with a multitude of similar-sized objects. As described above, this characteristic was mandated as part of the IAU's official definition of a planet in August 2006. Although to date this criterion only applies to the Solar System, a number of young extrasolar systems have been found in which evidence suggests orbital clearing is taking place within their circumstellar discs.\n\n\n=== Physical characteristics ===\n\n\n==== Size and shape ====\n\nGravity causes planets to be pulled into a roughly spherical shape, so a planet's size can be expressed roughly by an average radius (for example, Earth radius or Jupiter radius). However, planets are not perfectly spherical; for example, the Earth's rotation causes it to be slightly flattened at the poles with a bulge around the equator. Therefore, a better approximation of Earth's shape is an oblate spheroid, whose equatorial diameter is 43 kilometers (27 mi) larger than the pole-to-pole diameter. Generally, a planet's shape may be described by giving polar and equatorial radii of a spheroid or specifying a reference ellipsoid. From such a specification, the planet's flattening, surface area, and volume can be calculated; its normal gravity can be computed knowing its size, shape, rotation rate and mass.\n\n\n==== Mass ====\n\nA planet's defining physical characteristic is that it is massive enough for the force of its own gravity to dominate over the electromagnetic forces binding its physical structure, leading to a state of hydrostatic equilibrium. This effectively means that all planets are spherical or spheroidal. Up to a certain mass, an object can be irregular in shape, but beyond that point, which varies depending on the chemical makeup of the object, gravity begins to pull an object towards its own centre of mass until the object collapses into a sphere.Mass is the prime attribute by which planets are distinguished from stars. While the lower stellar mass limit is estimated to be around 75 times that of Jupiter (MJ), the upper planetary mass limit for planethood is only roughly 13 MJ for objects with solar-type isotopic abundance, beyond which it achieves conditions suitable for nuclear fusion of deuterium. Other than the Sun, no objects of such mass exist in the Solar System; but there are exoplanets of this size. The 13 MJ limit is not universally agreed upon and the Extrasolar Planets Encyclopaedia includes objects up to 60 MJ, and the Exoplanet Data Explorer up to 24 MJ.The smallest known exoplanet with an accurately known mass is PSR B1257+12A, one of the first extrasolar planets discovered, which was found in 1992 in orbit around a pulsar. Its mass is roughly half that of the planet Mercury. Even smaller is WD 1145+017 b, orbiting a white dwarf; its mass is roughly that of the dwarf planet Haumea, and it is typically termed a minor planet. The smallest known planet orbiting a main-sequence star other than the Sun is Kepler-37b, with a mass (and radius) that is probably slightly higher than that of the Moon.\n\n\n==== Internal differentiation ====\n\nEvery planet began its existence in an entirely fluid state; in early formation, the denser, heavier materials sank to the centre, leaving the lighter materials near the surface. Each therefore has a differentiated interior consisting of a dense planetary core surrounded by a mantle that either is or was a fluid. The terrestrial planets' mantles are sealed within hard crusts, but in the giant planets the mantle simply blends into the upper cloud layers. The terrestrial planets have cores of elements such as iron and nickel, and mantles of silicates. Jupiter and Saturn are believed to have cores of rock and metal surrounded by mantles of metallic hydrogen. Uranus and Neptune, which are smaller, have rocky cores surrounded by mantles of water, ammonia, methane and other ices. The fluid action within these planets' cores creates a geodynamo that generates a magnetic field. Similar differentiation processes are believed to have occurred on some of the large moons and dwarf planets, though the process may not always have been completed: Ceres, Callisto, and Titan appear to be incompletely differentiated.\n\n\n==== Atmosphere ====\n\nAll of the Solar System planets except Mercury have substantial atmospheres because their gravity is strong enough to keep gases close to the surface. Saturn's largest moon Titan also has a substantial atmosphere thicker than that of Earth; Neptune's largest moon Triton and the dwarf planet Pluto have more tenuous atmospheres. The larger giant planets are massive enough to keep large amounts of the light gases hydrogen and helium, whereas the smaller planets lose these gases into space. The composition of Earth's atmosphere is different from the other planets because the various life processes that have transpired on the planet have introduced free molecular oxygen.Planetary atmospheres are affected by the varying insolation or internal energy, leading to the formation of dynamic weather systems such as hurricanes (on Earth), planet-wide dust storms (on Mars), a greater-than-Earth-sized anticyclone on Jupiter (called the Great Red Spot), and holes in the atmosphere (on Neptune). Weather patterns detected on exoplanets include a hot region on HD 189733 b twice the size of the Great Red Spot, as well as clouds on the hot Jupiter Kepler-7b, the super-Earth Gliese 1214 b and others.Hot Jupiters, due to their extreme proximities to their host stars, have been shown to be losing their atmospheres into space due to stellar radiation, much like the tails of comets. These planets may have vast differences in temperature between their day and night sides that produce supersonic winds, although multiple factors are involved and the details of the atmospheric dynamics that affect the day-night temperature difference are complex.\n\n\n==== Magnetosphere ====\n\nOne important characteristic of the planets is their intrinsic magnetic moments, which in turn give rise to magnetospheres. The presence of a magnetic field indicates that the planet is still geologically alive. In other words, magnetized planets have flows of electrically conducting material in their interiors, which generate their magnetic fields. These fields significantly change the interaction of the planet and solar wind. A magnetized planet creates a cavity in the solar wind around itself called the magnetosphere, which the wind cannot penetrate. The magnetosphere can be much larger than the planet itself. In contrast, non-magnetized planets have only small magnetospheres induced by interaction of the ionosphere with the solar wind, which cannot effectively protect the planet.Of the eight planets in the Solar System, only Venus and Mars lack such a magnetic field.  Of the magnetized planets the magnetic field of Mercury is the weakest, and is barely able to deflect the solar wind. Jupiter's moon Ganymede has a magnetic field several times stronger, and Jupiter's is the strongest in the Solar System (so intense in fact that it poses a serious health risk to future crewed missions to all its moons inward of Callisto). The magnetic fields of the other giant planets, measured at their surfaces, are roughly similar in strength to that of Earth, but their magnetic moments are significantly larger. The magnetic fields of Uranus and Neptune are strongly tilted relative to the planets' rotational axes and displaced from the planets' centres.In 2003, a team of astronomers in Hawaii observing the star HD 179949 detected a bright spot on its surface, apparently created by the magnetosphere of an orbiting hot Jupiter.\n\n\n=== Secondary characteristics ===\n\nSeveral planets or dwarf planets in the Solar System (such as Neptune and Pluto) have orbital periods that are in resonance with each other or with smaller bodies. This is common in satellite systems (e.g. the resonance between Io, Europa, and Ganymede around Jupiter, or between Enceladus and Dione around Saturn). All except Mercury and Venus have natural satellites, often called \"moons\". Earth has one, Mars has two, and the giant planets have numerous moons in complex planetary-type systems. Except for Ceres and Sedna, all the consensus dwarf planets are known to have at least one moon as well. Many moons of the giant planets have features similar to those on the terrestrial planets and dwarf planets, and some have been studied as possible abodes of life (especially Europa and Enceladus).The four giant planets are orbited by planetary rings of varying size and complexity. The rings are composed primarily of dust or particulate matter, but can host tiny 'moonlets' whose gravity shapes and maintains their structure. Although the origins of planetary rings is not precisely known, they are believed to be the result of natural satellites that fell below their parent planet's Roche limit and were torn apart by tidal forces. The dwarf planets Haumea and Quaoar also have rings.No secondary characteristics have been observed around extrasolar planets. The sub-brown dwarf Cha 110913-773444, which has been described as a rogue planet, is believed to be orbited by a tiny protoplanetary disc and the sub-brown dwarf OTS 44 was shown to be surrounded by a substantial protoplanetary disk of at least 10 Earth masses.\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\nPhotojournal NASA\nPlanetary Science Research Discoveries (educational site with illustrated articles)", "Motion": "In physics, motion is the phenomenon in which an object changes its position with respect to time. Motion is mathematically described in terms of displacement, distance, velocity, acceleration, speed and frame of reference to an observer and measuring the change in position of the body relative to that frame with change in time. The branch of physics describing the motion of objects without reference to its cause is called kinematics, while the branch studying forces and their effect on motion is called dynamics.\nIf an object is not moving relative to a given frame of reference, the object is said to be at rest, motionless, immobile, stationary, or to have a constant or time-invariant position with reference to its surroundings. Modern physics holds that, as there is no absolute frame of reference, Newton's concept of absolute motion cannot be determined. As such, everything in the universe can be considered to be in motion.:\u200a20\u201321\u200aMotion applies to various physical systems: objects, bodies, matter particles, matter fields, radiation, radiation fields, radiation particles, curvature, and space-time. One can also speak on the motion of images, shapes, and boundaries. In general, the term motion signifies a continuous change in the positions or configuration of a physical system in space. For example, one can talk about the motion of a wave or the motion of a quantum particle, where the configuration consists of probabilities of the wave or particle occupying specific positions.\n\n\n== Equations of motion ==\n\n\n== Laws of motion ==\nIn physics, the motion of massive bodies is described through two related sets of laws of mechanics. Classical mechanics for super atomic (larger than an atom) objects (such as cars, projectiles, planets, cells, and humans) and quantum mechanics for atomic and sub-atomic objects (such as helium, protons, and electrons). Historically, Newton and Euler formulated three laws of classical mechanics:\n\n\n=== Classical mechanics ===\n\nClassical mechanics is used for describing the motion of macroscopic objects moving at speeds significantly slower than the speed of light, from projectiles to parts of machinery, as well as astronomical objects, such as spacecraft, planets, stars, and galaxies. It produces very accurate results within these domains and is one of the oldest and largest scientific descriptions in science, engineering, and technology.\nClassical mechanics is fundamentally based on Newton's laws of motion. These laws describe the relationship between the forces acting on a body and the motion of that body. They were first compiled by Sir Isaac Newton in his work Philosophi\u00e6 Naturalis Principia Mathematica, which was first published on July 5, 1687. Newton's three laws are:\n\nA body at rest will remain at rest, and a body in motion will remain in motion unless it is acted upon by an external force. (This is known as the law of inertia.)\nForce (\n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n  ) is equal to the change in momentum per change in time (\n  \n    \n      \n        \n          \n            \n              \u0394\n              m\n              \n                \n                  \n                    v\n                    \u2192\n                  \n                \n              \n            \n            \n              \u0394\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\Delta m{\\vec {v}}}{\\Delta t}}}\n  ). For a constant mass, force equals mass times acceleration (\n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n        =\n        m\n        \n          \n            \n              a\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}=m{\\vec {a}}}\n   ).\nFor every action, there is an equal and opposite reaction. (In other words, whenever one body exerts a force \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   onto a second body, (in some cases, which is standing still) the second body exerts the force \n  \n    \n      \n        \u2212\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle -{\\vec {F}}}\n   back onto the first body. \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   and \n  \n    \n      \n        \u2212\n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle -{\\vec {F}}}\n   are equal in magnitude and opposite in direction. So, the body which exerts \n  \n    \n      \n        \n          \n            \n              F\n              \u2192\n            \n          \n        \n      \n    \n    {\\displaystyle {\\vec {F}}}\n   will be pushed backward.)Newton's three laws of motion were the first to accurately provide a mathematical model for understanding orbiting bodies in outer space. This explanation unified the motion of celestial bodies and the motion of objects on Earth.\n\n\n=== Relativistic mechanics ===\nModern kinematics developed with study of electromagnetism and refers all velocities \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n   to their ratio to speed of light \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  . Velocity is then interpreted as rapidity, the hyperbolic angle \n  \n    \n      \n        \u03c6\n      \n    \n    {\\displaystyle \\varphi }\n   for which the hyperbolic tangent function \n  \n    \n      \n        tanh\n        \u2061\n        \u03c6\n        =\n        v\n        \u00f7\n        c\n      \n    \n    {\\displaystyle \\tanh \\varphi =v\\div c}\n  . Acceleration, the change of velocity over time, then changes rapidity according to Lorentz transformations. This part of mechanics is special relativity. Efforts to incorporate gravity into relativistic mechanics were made by W. K. Clifford and Albert Einstein. The development used differential geometry to describe a curved universe with gravity; the study is called general relativity.\n\n\n=== Quantum mechanics ===\nQuantum mechanics is a set of principles describing physical reality at the atomic level of matter (molecules and atoms) and the subatomic particles (electrons, protons, neutrons, and even smaller elementary particles such as quarks). These descriptions include the simultaneous wave-like and particle-like behavior of both matter and radiation energy as described in the wave\u2013particle duality.In classical mechanics, accurate measurements and predictions of the state of objects can be calculated, such as location and velocity. In quantum mechanics, due to the Heisenberg uncertainty principle, the complete state of a subatomic particle, such as its location and velocity, cannot be simultaneously determined.In addition to describing the motion of atomic level phenomena, quantum mechanics is useful in understanding some large-scale phenomena such as superfluidity, superconductivity, and biological systems, including the function of smell receptors and the structures of protein.\n\n\n== Orders of magnitude ==\nHumans, like all known things in the universe, are in constant motion;:\u200a8\u20139\u200a however, aside from obvious movements of the various external body parts and locomotion, humans are in motion in a variety of ways which are more difficult to perceive.  Many of these \"imperceptible motions\" are only perceivable with the help of special tools and careful observation. The larger scales of imperceptible motions are difficult for humans to perceive for two reasons: Newton's laws of motion (particularly the third) which prevents the feeling of motion on a mass to which the observer is connected, and the lack of an obvious frame of reference which would allow individuals to easily see that they are moving. The smaller scales of these motions are too small to be detected conventionally with human senses.\n\n\n=== Universe ===\nSpacetime (the fabric of the universe) is expanding, meaning everything in the universe is stretching, like a rubber band. This motion is the most obscure as it is not physical motion, but rather a change in the very nature of the universe. The primary source of verification of this expansion was provided by Edwin Hubble who demonstrated that all galaxies and distant astronomical objects were moving away from Earth, known as Hubble's law, predicted by a universal expansion.\n\n\n=== Galaxy ===\nThe Milky Way Galaxy is moving through space and many astronomers believe the velocity of this motion to be approximately 600 kilometres per second (1,340,000 mph) relative to the observed locations of other nearby galaxies. Another reference frame is provided by the Cosmic microwave background. This frame of reference indicates that the Milky Way is moving at around 582 kilometres per second (1,300,000 mph).\n\n\n=== Sun and Solar System ===\n\nThe Milky Way is rotating around its dense Galactic Center, thus the Sun is moving in a circle within the galaxy's gravity. Away from the central bulge, or outer rim, the typical stellar velocity is between 210 and 240 kilometres per second (470,000 and 540,000 mph). All planets and their moons move with the Sun. Thus, the Solar System is in motion.\n\n\n=== Earth ===\nThe Earth is rotating or spinning around its axis. This is evidenced by day and night, at the equator the earth has an eastward velocity of 0.4651 kilometres per second (1,040 mph). The Earth is also orbiting around the Sun in an orbital revolution. A complete orbit around the sun takes one year, or about 365 days; it averages a speed of about 30 kilometres per second (67,000 mph).\n\n\n=== Continents ===\nThe Theory of Plate tectonics tells us that the continents are drifting on convection currents within the mantle, causing them to move across the surface of the planet at the slow speed of approximately 2.54 centimetres (1 in) per year. However, the velocities of plates range widely. The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of 75 millimetres (3.0 in) per year and the Pacific Plate moving 52\u201369 millimetres (2.0\u20132.7 in) per year. At the other extreme, the slowest-moving plate is the Eurasian Plate, progressing at a typical rate of about 21 millimetres (0.83 in) per year.\n\n\n=== Internal body ===\nThe human heart is constantly contracting to move blood throughout the body. Through larger veins and arteries in the body, blood has been found to travel at approximately 0.33 m/s. Though considerable variation exists, and peak flows in the venae cavae have been found between 0.1 and 0.45 metres per second (0.33 and 1.48 ft/s). additionally, the smooth muscles of hollow internal organs are moving. The most familiar would be the occurrence of peristalsis which is where digested food is forced throughout the digestive tract. Though different foods travel through the body at different rates, an average speed through the human small intestine is 3.48 kilometres per hour (2.16 mph). The human lymphatic system is also constantly causing movements of excess fluids, lipids, and immune system related products around the body. The lymph fluid has been found to move through a lymph capillary of the skin at approximately 0.0000097 m/s.\n\n\n=== Cells ===\nThe cells of the human body have many structures and organelles which move throughout them. Cytoplasmic streaming is a way in which cells move molecular substances throughout the cytoplasm, various motor proteins work as molecular motors within a cell and move along the surface of various cellular substrates such as microtubules, and motor proteins are typically powered by the hydrolysis of adenosine triphosphate (ATP), and convert chemical energy into mechanical work. Vesicles propelled by motor proteins have been found to have a velocity of approximately 0.00000152 m/s.\n\n\n=== Particles ===\nAccording to the laws of thermodynamics, all particles of matter are in constant random motion as long as the temperature is above absolute zero. Thus the molecules and atoms which make up the human body are vibrating, colliding, and moving. This motion can be detected as temperature; higher temperatures, which represent greater kinetic energy in the particles, feel warm to humans who sense the thermal energy transferring from the object being touched to their nerves. Similarly, when lower temperature objects are touched, the senses perceive the transfer of heat away from the body as a feeling of cold.\n\n\n=== Subatomic particles ===\nWithin the standard atomic orbital model, electrons exist in a region around the nucleus of each atom.  This region is called the electron cloud.  According to Bohr's model of the atom, electrons have a high velocity, and the larger the nucleus they are orbiting the faster they would need to move.  If electrons were to move about the electron cloud in strict paths the same way planets orbit the sun, then electrons would be required to do so at speeds which would far exceed the speed of light.  However, there is no reason that one must confine oneself to this strict conceptualization (that electrons move in paths the same way macroscopic objects do), rather one can conceptualize electrons to be 'particles' that capriciously exist within the bounds of the electron cloud. Inside the atomic nucleus, the protons and neutrons are also probably moving around due to the electrical repulsion of the protons and the presence of angular momentum of both particles.\n\n\n== Light ==\n\nLight moves at a speed of 299,792,458 m/s, or 299,792.458 kilometres per second (186,282.397 mi/s), in a vacuum. The speed of light in vacuum (or \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  ) is also the speed of all massless particles and associated fields in a vacuum, and it is the upper limit on the speed at which energy, matter, information or causation can travel. The speed of light in vacuum is thus the upper limit for speed for all physical systems.\nIn addition, the speed of light is an invariant quantity: it has the same value, irrespective of the position or speed of the observer. This property makes the speed of light c a natural measurement unit for speed and a fundamental constant of nature.\nIn 2011, the speed of light was redefined alongside all seven SI base units using what it calls \"the explicit-constant formulation\", where each \"unit is defined indirectly by specifying explicitly an exact value for a well-recognized fundamental constant\", as was done for the speed of light. A new, but completely equivalent, wording of the metre's definition was proposed: \"The metre, symbol m, is the unit of length; its magnitude is set by fixing the numerical value of the speed of light in vacuum to be equal to exactly 299792458 when it is expressed in the SI unit m s\u22121.\"  This implicit change to the speed of light was one of the changes that was incorporated in the 2019 redefinition of the SI base units, also termed the New SI.\n\n\n=== Superluminal motion ===\nSome motion appears to an observer to exceed the speed of light. Bursts of energy moving out along the relativistic jets emitted from these objects can have a proper motion that appears greater than the speed of light. All of these sources are thought to contain a black hole, responsible for the ejection of mass at high velocities. Light echoes can also produce apparent superluminal motion. This occurs owing to how motion is often calculated at long distances; oftentimes calculations fail to account for the fact that the speed of light is finite. When measuring the movement of distant objects across the sky, there is a large time delay between what has been observed and what has occurred, due to the large distance the light from the distant object has to travel to reach us. The error in the above naive calculation comes from the fact that when an object has a component of velocity directed towards the Earth, as the object moves closer to the Earth that time delay becomes smaller. This means that the apparent speed as calculated above is greater than the actual speed. Correspondingly, if the object is moving away from the Earth, the above calculation underestimates the actual speed.\n\n\n== Types of motion ==\nSimple harmonic motion \u2013 motion in which the body oscillates in such a way that the restoring force acting on it is directly proportional to the body's displacement. Mathematically Force is directly proportional to the negative of displacement. Negative sign signifies the restoring nature of the force. (e.g., that of a pendulum).\nLinear motion \u2013 motion which follows a straight linear path, and whose displacement is exactly the same as its trajectory. [Also known as rectilinear motion]\nReciprocal motion\nBrownian motion (i.e. the random movement of particles)\nCircular motion\nRotatory motion \u2013 a motion about a fixed point. (e.g. Ferris wheel).\nCurvilinear motion \u2013 It is defined as the motion along a curved path that may be planar or in three dimensions.\nRolling motion \u2013 (as of the wheel of a bicycle)\nOscillatory \u2013 (swinging from side to side)\nVibratory motion\nCombination (or simultaneous) motions \u2013 Combination of two or more above listed motions\nProjectile motion \u2013  uniform horizontal motion + vertical accelerated motion\n\n\n== Fundamental motions ==\nLinear motion\nCircular motion\nOscillation\nWave\nRelative motion\nFundamental motions\n\n\n== See also ==\nDeflection (physics) \u2013 change in an object's velocity as a consequence of collision with a surfacePages displaying wikidata descriptions as a fallback\nKinematics \u2013 Branch of physics describing the motion of objects without considering forces\nSimple machines \u2013 Mechanical device that changes the direction or magnitude of a forcePages displaying short descriptions of redirect targets\nKinematic chain \u2013 Mathematical model for a mechanical system\nPower \u2013 Amount of energy transferred or converted per unit time\nMachine \u2013 Powered mechanical devicePages displaying short descriptions of redirect targets\nMicroswimmer \u2013 artificial or natural microorganisms that can move in a fluid environmentPages displaying wikidata descriptions as a fallback\nMotion (geometry) \u2013 Transformation of a geometric space preserving structure\nMotion capture \u2013 Process of recording the movement of objects or people\nDisplacement \u2013 Vector relating the initial and the final positions of a moving pointPages displaying short descriptions of redirect targets\nTranslatory motion \u2013 Type of motion in which the path of the moving object is a straight linePages displaying short descriptions of redirect targets\n\n\n== References ==\n\n\n== External links ==\n\nFeynman's lecture on motion\n Media related to Motion at Wikimedia Commons", "Kilogram": "The kilogram (also kilogramme) is the base unit of mass in the International System of Units (SI), having the unit symbol kg. It is a widely used measure in science, engineering and commerce worldwide, and is often simply called a kilo colloquially. It means 'one thousand grams'.\nThe kilogram is defined in terms of the second and the metre, both of which are based on fundamental physical constants. This allows a properly equipped metrology laboratory to calibrate a mass measurement instrument such as a Kibble balance as the primary standard to determine an exact kilogram mass.The kilogram was originally defined in 1795 during the French Revolution as the mass of one litre of water. The current definition of a kilogram agrees with this original definition to within 30 parts per million. In 1799, the platinum Kilogramme des Archives replaced it as the standard of mass. In 1889, a cylinder of platinum-iridium, the International Prototype of the Kilogram (IPK), became the standard of the unit of mass for the metric system and remained so for 130 years, before the current standard was adopted in 2019.\n\n\n== Definition ==\nThe kilogram is defined in terms of three fundamental physical constants:  \n\na specific atomic transition frequency \u0394\u03bdCs, which defines the duration of the second,\nthe speed of light c, which when combined with the second, defines the length of the metre,\nand the Planck constant h. which when combined with the metre and second, defines the mass of the kilogram.The formal definition according to the General Conference on Weights and Measures (CGPM) is:\n\nThe kilogram, symbol kg, is the SI unit of mass. It is defined by taking the fixed numerical value of the Planck constant h to be 6.62607015\u00d710\u221234 when expressed in the unit J\u22c5s, which is equal to kg\u22c5m2\u22c5s\u22121, where the metre and the second are defined in terms of c and \u0394\u03bdCs.\nDefined in term of those units, the kg is formulated as:\nkg = (299792458)2/(6.62607015\u00d710\u221234)(9192631770)h\u0394\u03bdCs/c2   = 917097121160018/621541050725904751042h\u0394\u03bdCs/c2 \u2248 (1.475521399735270\u00d71040)h\u0394\u03bdCs/c2 .This definition is generally consistent with previous definitions: the mass remains within 30 ppm of the mass of one litre of water.\n\n\n=== Timeline of previous definitions ===\n\n1793: The grave (the precursor of the kilogram) was defined as the mass of 1 litre (dm3) of water, which was determined to be 18841 grains.\n1795: the gram (1/1000 of a kilogram) was provisionally defined as the mass of one cubic centimetre of water at the melting point of ice.\n1799: The Kilogramme des Archives was manufactured as a prototype. It had a mass equal to the mass of 1 dm3 of water at the temperature of its maximum density, which is approximately 4 \u00b0C.\n1875\u20131889: The Metre Convention was signed in 1875, leading to the production of the International Prototype of the Kilogram (IPK) in 1879 and its adoption in 1889.\n2019: The kilogram was defined in terms of the Planck constant, the speed of light and hyperfine transition frequency of 133Cs as approved by the General Conference on Weights and Measures (CGPM) on November 16, 2018.\n\n\n== Name and terminology ==\nThe kilogram is the only base SI unit with an SI prefix (kilo) as part of its name. The word kilogramme or kilogram is derived from the French kilogramme, which itself was a learned coinage, prefixing the Greek stem of \u03c7\u03af\u03bb\u03b9\u03bf\u03b9 khilioi \"a thousand\" to gramma, a Late Latin term for \"a small weight\", itself from Greek \u03b3\u03c1\u03ac\u03bc\u03bc\u03b1. \nThe word kilogramme was written into French law in 1795, in the Decree of 18 Germinal,\nwhich revised the provisional system of units introduced by the French National Convention two years earlier, where the gravet had been defined as weight (poids) of a cubic centimetre of water, equal to 1/1000 of a grave. In the decree of 1795, the term gramme thus replaced gravet, and kilogramme replaced grave.\nThe French spelling was adopted in Great Britain when the word was used for the first time in English in 1795, with the spelling kilogram being adopted in the United States. In the United Kingdom both spellings are used, with \"kilogram\" having become by far the more common. UK law regulating the units to be used when trading by weight or measure does not prevent the use of either spelling.In the 19th century the French word kilo, a shortening of kilogramme, was imported into the English language where it has been used to mean both kilogram and kilometre. While kilo as an alternative is acceptable, to The Economist for example, the Canadian government's Termium Plus system states that \"SI (International System of Units) usage, followed in scientific and technical writing\" does not allow its usage and it is described as \"a common informal name\" on Russ Rowlett's Dictionary of Units of Measurement. When the United States Congress gave the metric system legal status in 1866, it permitted the use of the word kilo as an alternative to the word kilogram, but in 1990 revoked the status of the word kilo.The SI system was introduced in 1960 and in 1970 the BIPM started publishing the SI Brochure, which contains all relevant decisions and recommendations by the CGPM concerning units. The SI Brochure states that \"It is not permissible to use abbreviations for unit symbols or unit names ...\".\n\n\n== Kilogram becoming a base unit: the role of units for electromagnetism ==\nIt is primarily because of units for electromagnetism that the kilogram rather than the gram was eventually adopted as the base unit of mass in the SI. The relevant series of discussions and decisions started roughly in the 1850s and effectively concluded in 1946. By the end of the 19th century, the 'practical units' for electric and magnetic quantities such as the ampere and the volt were well established in practical use (e.g. for telegraphy). Unfortunately, they did not form a coherent system of units with the then-prevailing base units for length and mass, the centimetre, and the gram. However, the 'practical units' also included some purely mechanical units. In particular, the product of the ampere and the volt gives a purely mechanical unit of power, the watt. It was noticed that the purely mechanical practical units such as the watt would be coherent in a system in which the base unit of length was the metre and the base unit of mass was the kilogram. Because no one wanted to replace the second as the base unit of time, the metre and the kilogram are the only pair of base units of length and mass such that (1) the watt is a coherent unit of power, (2) the base units of length and time are integer-power-of-ten ratios to the metre and the gram (so that the system remains 'metric'), and (3) the sizes of the base units of length and mass are convenient for practical use. This would still leave out the purely electrical and magnetic units: while the purely mechanical practical units such as the watt are coherent in the metre-kilogram-second system, the explicitly electrical and magnetic units such as the volt, the ampere, etc. are not. The only way to also make those units coherent with the metre-kilogram-second system is to modify that system in a different way: the number of fundamental dimensions must be increased from three (length, mass, and time) to four (the previous three, plus one purely electrical one).\n\n\n=== The state of units for electromagnetism at the end of the 19th century ===\nDuring the second half of the 19th century, the centimetre\u2013gram\u2013second system of units was becoming widely accepted for scientific work, treating the gram as the fundamental unit of mass and the kilogram as a decimal multiple of the base unit formed by using a metric prefix. However, as the century drew to a close, there was widespread dissatisfaction with the units for electricity and magnetism in the CGS system: they were so small (or large) that realistic measurements involved very large (or small) numbers. There were two obvious choices for absolute units of electromagnetism: the \u2018electrostatic\u2019 (CGS-ESU) system and the \u2018electromagnetic\u2019 (CGS-EMU) system. But the sizes of coherent electric and magnetic units were not convenient in either of these systems; for example, the ESU unit of electrical resistance, which was later named the statohm, corresponds to about 9\u00d71011 ohm, while the EMU unit, which was later named the abohm, corresponds to 10\u22129 ohm.To circumvent this difficulty, a third set of units was introduced: the so-called practical units. The practical units were obtained as decimal multiples of coherent CGS-EMU units, chosen so that the resulting magnitudes were convenient for practical use and so that the practical units were, as far as possible, coherent with each other. The practical units included such units as the volt, the ampere, the ohm, etc., which were later incorporated in the SI system and which are used to this day. The reason the metre and the kilogram were later chosen to be the base units of length and mass was that they are the only combination of reasonably sized decimal multiples or submultiples of the metre and the gram that can be made coherent with the volt, the ampere, etc.\nThe reason is that electrical quantities cannot be isolated from mechanical and thermal ones: they are connected by relations such as current \u00d7 electric potential difference = power. For this reason, the practical system also included coherent units for certain mechanical quantities. For example, the previous equation implies that ampere \u00d7 volt is a coherent derived practical unit of power; this unit was named the watt. The coherent unit of energy is then the watt times the second, which was named the joule. The joule and the watt also have convenient magnitudes and are decimal multiples of CGS coherent units for energy (the erg) and power (the erg per second). The watt is not coherent in the centimetre-gram-second system, but it is coherent in the metre-kilogram-second system\u2014and in no other system whose base units of length and mass are reasonably sized decimal multiples or submultiples of the metre and the gram.\nHowever, unlike the watt and the joule, the explicitly electrical and magnetic units (the volt, the ampere...) are not coherent even in the (absolute three-dimensional) metre-kilogram-second system. Indeed, one can work out what the base units of length and mass have to be in order for all the practical units to be coherent (the watt and the joule as well as the volt, the ampere, etc.). The values are 107 metres (one half of a meridian of the Earth, called a quadrant) and 10\u221211 grams (called an eleventh-gram).Therefore, the full absolute system of units in which the practical electrical units are coherent is the quadrant\u2013eleventh-gram\u2013second (QES) system. However, the extremely inconvenient magnitudes of the base units for length and mass made it so that no one seriously considered adopting the QES system. Thus, people working on practical applications of electricity had to use units for electrical quantities and for energy and power that were not coherent with the units they were using for e.g. length, mass, and force.\nMeanwhile, scientists developed yet another fully coherent absolute system, which came to be called the Gaussian system, in which the units for purely electrical quantities are taken from CGE-ESU, while the units for magnetic quantities are taken from the CGS-EMU. This system proved very convenient for scientific work and is still widely used. However, the sizes of its units remained either too large or too small\u2014by many orders of magnitude\u2014for practical applications.\nFinally, in both CGS-ESU and CGS-EMU as well as in the Gaussian system, Maxwell's equations are 'unrationalized', meaning that they contain various factors of 4\u03c0 that many workers found awkward. So yet another system was developed to rectify that: the 'rationalized' Gaussian system, usually called the Heaviside\u2013Lorentz system. This system is still used in some subfields of physics. However, the units in that system are related to Gaussian units by factors of \u221a4\u03c0 \u2248 3.5, which means that their magnitudes remained, like those of the Gaussian units, either far too large or far too small for practical applications.\n\n\n=== The Giorgi proposal ===\nIn 1901, Giovanni Giorgi proposed a new system of units that would remedy this situation. He noted that the mechanical practical units such as the joule and the watt are coherent not only in the QES system, but also in the metre-kilogram-second (MKS) system. It was of course known that adopting the metre and the kilogram as base units\u2014obtaining the three dimensional MKS system\u2014would not solve the problem: while the watt and the joule would be coherent, this would not be so for the volt, the ampere, the ohm, and the rest of the practical units for electric and magnetic quantities (the only three-dimensional absolute system in which all practical units are coherent is the QES system).\nBut Giorgi pointed out that the volt and the rest could be made coherent if the idea that all physical quantities must be expressible in terms of dimensions of length, mass, and time, is relinquished and a fourth base dimension is added for electric quantities. Any practical electrical unit could be chosen as the new fundamental unit, independent from the metre, kilogram, and second. Likely candidates for the fourth independent unit included the coulomb, the ampere, the volt, and the ohm, but eventually, the ampere proved to be the most convenient for metrology. Moreover, the freedom gained by making an electric unit independent from the mechanical units could be used to rationalize Maxwell's equations.\nThe idea that one should give up on having a purely 'absolute' system (i.e. one where only length, mass, and time are the base dimensions) was a departure from a viewpoint that seemed to underlie the early breakthroughs by Gauss and Weber (especially their famous 'absolute measurements' of Earth's magnetic field:\u200a54\u201356\u200a), and it took some time for the scientific community to accept it\u2014not least because many scientists clung to the notion that the dimensions of a quantity in terms of length, mass, and time somehow specify its 'fundamental physical nature'.:24, 26\n\n\n=== Acceptance of the Giorgi system, leading to the MKSA system and the SI ===\nBy the 1920s, dimensional analysis had become much better understood and it was becoming widely accepted that the choice both of the number and of the identities of the \"fundamental\" dimensions should be dictated by convenience only and that there is nothing really fundamental about the dimensions of a quantity. In 1935, Giorgi's proposal was adopted by the IEC as the Giorgi system. It is this system that has since then been called the MKS system,\nalthough \u2018MKSA\u2019 appears in careful usage. In 1946 the CIPM approved a proposal to adopt the ampere as the electromagnetic unit of the \"MKSA system\".:\u200a109,\u200a110\u200a In 1948 the CGPM commissioned the CIPM \"to make recommendations for a single practical system of units of measurement, suitable for adoption by all countries adhering to the Metre Convention\". This led to the launch of SI in 1960.\nTo summarize, the ultimate reason that the kilogram was chosen over the gram as the base unit of mass was, in one word, the volt-ampere. Namely, the combination of the metre and the kilogram was the only choice of base units of length and mass such that 1. the volt-ampere\u2014which is also called the watt and which is the unit of power in the practical system of electrical units\u2014is coherent, 2. the base units of length and mass are decimal multiples or submultiples of the metre and the gram, and 3. the base units of length and mass have convenient sizes.\nThe CGS and MKS systems co-existed during much of the early-to-mid-20th century, but as a result of the decision to adopt the \"Giorgi system\" as the international system of units in 1960, the kilogram is now the SI base unit for mass, while the definition of the gram is derived.\n\n\n== Redefinition based on fundamental constants ==\n\nThe replacement of the International Prototype of the Kilogram (IPK) as the primary standard was motivated by evidence accumulated over a long period of time that the mass of the IPK and its replicas had been changing; the IPK had diverged from its replicas by approximately 50 micrograms since their manufacture late in the 19th century. This led to several competing efforts to develop measurement technology precise enough to warrant replacing the kilogram artefact with a definition based directly on physical fundamental constants. Physical standard masses such as the IPK and its replicas still serve as secondary standards.\nThe International Committee for Weights and Measures (CIPM) approved a redefinition of the SI base units in November 2018 that defines the kilogram by defining the Planck constant to be exactly 6.62607015\u00d710\u221234 kg\u22c5m2\u22c5s\u22121, effectively defining the kilogram in terms of the second and the metre. The new definition took effect on May 20, 2019.Prior to the redefinition, the kilogram and several other SI units based on the kilogram were defined by a man-made metal artifact: the Kilogramme des Archives from 1799 to 1889, and the IPK from 1889 to 2019.In 1960, the metre, previously similarly having been defined with reference to a single platinum-iridium bar with two marks on it, was redefined in terms of an invariant physical constant (the wavelength of a particular emission of light emitted by krypton, and later the speed of light) so that the standard can be independently reproduced in different laboratories by following a written specification.\nAt the 94th Meeting of the International Committee for Weights and Measures (CIPM) in 2005, it was recommended that the same be done with the kilogram.In October 2010, the CIPM voted to submit a resolution for consideration at the General Conference on Weights and Measures (CGPM), to \"take note of an intention\" that the kilogram be defined in terms of the Planck constant, h (which has dimensions of energy times time, thus mass \u00d7 length2 / time) together with other physical constants. This resolution was accepted by the 24th conference of the CGPM in October 2011 and further discussed at the 25th conference in 2014. Although the Committee recognised that significant progress had been made, they concluded that the data did not yet appear sufficiently robust to adopt the revised definition, and that work should continue to enable the adoption at the 26th meeting, scheduled for 2018. Such a definition would theoretically permit any apparatus that was capable of delineating the kilogram in terms of the Planck constant to be used as long as it possessed sufficient precision, accuracy and stability. The Kibble balance is one way to do this.\nAs part of this project, a variety of very different technologies and approaches were considered and explored over many years. Some of these approaches were based on equipment and procedures that would enable the reproducible production of new, kilogram-mass prototypes on demand (albeit with extraordinary effort) using measurement techniques and material properties that are ultimately based on, or traceable to, physical constants. Others were based on devices that measured either the acceleration or weight of hand-tuned kilogram test masses and which expressed their magnitudes in electrical terms via special components that permit traceability to physical constants. All approaches depend on converting a weight measurement to a mass and therefore require the precise measurement of the strength of gravity in laboratories. All approaches would have precisely fixed one or more constants of nature at a defined value.\n\n\n== SI multiples ==\n\nBecause an SI unit may not have multiple prefixes (see SI prefix), prefixes are added to gram, rather than the base unit kilogram, which already has a prefix as part of its name. For instance, one-millionth of a kilogram is 1 mg (one milligram), not 1 \u03bckg (one microkilogram).\n\nThe microgram is typically abbreviated \"mcg\" in pharmaceutical and nutritional supplement labelling, to avoid confusion, since the \"\u03bc\" prefix is not always well recognised outside of technical disciplines. (The expression \"mcg\" is also the symbol for an obsolete CGS unit of measure known as the \"millicentigram\", which is equal to 10 \u03bcg.)\nIn the United Kingdom, because serious medication errors have been made from the confusion between milligrams and micrograms when micrograms has been abbreviated, the recommendation given in the Scottish Palliative Care Guidelines is that doses of less than one milligram must be expressed in micrograms and that the word microgram must be written in full, and that it is never acceptable to use \"mcg\" or \"\u03bcg\".\nThe hectogram (100 g) (Italian: ettogrammo or etto) is a very commonly used unit in the retail food trade in Italy.\nThe former standard spelling and abbreviation \"deka-\" and \"dk\" produced abbreviations such as \"dkm\" (dekametre) and \"dkg\" (dekagram). As of 2020, the abbreviation \"dkg\" (10 g) is still used in parts of central Europe in retail for some foods such as cheese and meat.\nThe unit name megagram is rarely used, and even then typically only in technical fields in contexts where especially rigorous consistency with the SI standard is desired. For most purposes, the name tonne is instead used. The tonne and its symbol, \"t\", were adopted by the CIPM in 1879. It is a non-SI unit accepted by the BIPM for use with the SI. According to the BIPM, \"This unit is sometimes referred to as 'metric ton' in some English-speaking countries.\" The unit name megatonne or megaton (Mt) is often used in general-interest literature on greenhouse gas emissions and nuclear weapons yields, whereas the equivalent unit in scientific papers on the subject is often the teragram (Tg).\n\n\n== See also ==\n\n\n== Notes ==\n\n\n== References ==\n\n\n== External links ==\n\nNIST Improves Accuracy of 'Watt Balance' Method for Defining the Kilogram\nThe UK's National Physical Laboratory (NPL): Are any problems caused by having the kilogram defined in terms of a physical artefact? (FAQ \u2013 Mass & Density)\nNPL: NPL Kibble balance\nMetrology in France: Watt balance\nAustralian National Measurement Institute: Redefining the kilogram through the Avogadro constant\nInternational Bureau of Weights and Measures (BIPM): Home page\nNZZ Folio: What a kilogram really weighs\nNPL: What are the differences between mass, weight, force and load?\nBBC: Getting the measure of a kilogram\nNPR: This Kilogram Has A Weight-Loss Problem, an interview with National Institute of Standards and Technology physicist Richard Steiner\nAvogadro and molar Planck constants for the redefinition of the kilogram\nRealization of the awaited definition of the kilogram\nSample, Ian (November 9, 2018). \"In the balance: scientists vote on first change to kilogram in a century\". The Guardian. Retrieved November 9, 2018.\n\n\n=== Videos ===\nThe BIPM \u2013 YouTube channel\n\"The role of the Planck constant in physics\" \u2013 presentation at 26th CGPM meeting at Versailles, France, November 2018 when voting on superseding the IPK took place on YouTube", "Metre": "The metre (or meter in American spelling; symbol: m) is the base unit of length in the International System of Units (SI).\nThe metre was originally defined in 1793 as one ten-millionth of the distance from the equator to the North Pole along a great circle, so the Earth's circumference is approximately 40000 km. In 1799, the metre was redefined in terms of a prototype metre bar. The actual bar used was changed in 1889. In 1960, the metre was redefined in terms of a certain number of wavelengths of a certain emission line of krypton-86. \nThe current definition was adopted in 1983 and modified slightly in 2002 to clarify that the metre is a measure of proper length. From 1983 until 2019, the metre was formally defined as the length of the path travelled by light in a vacuum in 1/299792458 of a second. After the 2019 redefinition of the SI base units, this definition was rephrased to include the definition of a second in terms of the caesium frequency \u0394\u03bdCs.\n\n\n== Spelling ==\nMetre is the standard spelling of the metric unit for length in nearly all English-speaking nations but not the United States or the Philippines, which use meter. Other West Germanic languages, such as German and Dutch, and North Germanic languages, such as Danish, Norwegian, and Swedish, likewise spell the word Meter or meter.\nMeasuring devices (such as ammeter, speedometer) are spelled \"-meter\" in all variants of English. The suffix \"-meter\" has the same Greek origin as the unit of length.\n\n\n== Etymology ==\nThe etymological roots of metre can be traced to the Greek verb \u03bc\u03b5\u03c4\u03c1\u03ad\u03c9 (metreo) (to measure, count or compare) and noun \u03bc\u03ad\u03c4\u03c1\u03bf\u03bd (metron) (a measure), which were used for physical measurement, for poetic metre and by extension for moderation or avoiding extremism (as in \"be measured in your response\"). This range of uses is also found in Latin (metior, mensura), French (m\u00e8tre, mesure), English and other languages. The Greek word is derived from the Proto-Indo-European root *meh\u2081- 'to measure'. The motto \u039c\u0395\u03a4\u03a1\u03a9 \u03a7\u03a1\u03a9 (metro chro) in the seal of the International Bureau of Weights and Measures (BIPM), which was a saying of the Greek statesman and philosopher Pittacus of Mytilene and may be translated as \"Use measure!\", thus calls for both measurement and moderation. The use of the word metre (for the French unit m\u00e8tre) in English began at least as early as 1797.\n\n\n== History of definition ==\n\n\n=== Pendulum or meridian ===\nIn 1671, Jean Picard measured the length of a \"seconds pendulum\" and proposed a unit of measurement twice that length to be called the universal toise (French: Toise universelle). In 1675, Tito Livio Burattini suggested the term metre for a unit of length based on a pendulum length, but then it was discovered that the length of a seconds pendulum varies from place to place.Since Eratosthenes, geographers had used meridian arcs to assess the size of the Earth, which in 1669, Jean Picard determined to have a radius of 3269000 toises, treated as a simple sphere. In the 18th century, geodesy  grew in importance as a means of empirically demonstrating the theory of gravity, which \u00c9milie du Ch\u00e2telet promoted in France in combination with Leibniz mathematical work, and because the radius of the Earth was the unit to which all celestial distances were to be referred.\n\n\n=== Meridional definition ===\n\nAs a result of the Lumi\u00e8res and during the French Revolution, the French Academy of Sciences charged a commission with determining a single scale for all measures. On 7 October 1790 that commission advised the adoption of a decimal system, and on 19 March 1791 advised the adoption of the term m\u00e8tre (\"measure\"), a basic unit of length, which they defined as equal to one ten-millionth of the quarter meridian, the distance between the North Pole and the Equator along the meridian through Paris. On 26 March 1791, the French National Constituent Assembly adopted the proposal.The French Academy of Sciences commissioned an expedition led by Jean Baptiste Joseph Delambre and Pierre M\u00e9chain, lasting from 1792 to 1799, which attempted to accurately measure the distance between a belfry in Dunkirk and Montju\u00efc castle in Barcelona at the longitude of the Paris Panth\u00e9on (see meridian arc of Delambre and M\u00e9chain). The expedition was fictionalised in Denis Guedj, Le M\u00e8tre du Monde. Ken Alder wrote factually about the expedition in The Measure of All Things: the seven year odyssey and hidden error that transformed the world.This portion of the Paris meridian was to serve as the basis for the length of the half meridian connecting the North Pole with the Equator. From 1801 to 1812 France adopted this definition of the metre as its official unit of length based on results from this expedition combined with those of the Geodesic Mission to Peru. The latter was related by Larrie D. Ferreiro in Measure of the Earth: The Enlightenment Expedition That Reshaped Our World.In the 19th century, geodesy underwent a revolution through advances in mathematics as well as improvements in the instruments and methods of observation, for instance accounting for individual bias in terms of the personal equation. The application of the least squares method to meridian arc measurements demonstrated the importance of the scientific method in geodesy. On the other hand, the invention of the telegraph made it possible to measure parallel arcs, and the improvement of the reversible pendulum gave rise to the study of the Earth's gravitational field. A more accurate determination of the Figure of the Earth would soon result from the measurement of the Struve Geodetic Arc (1816\u20131855) and would have given another value for the definition of this standard of length. This did not invalidate the metre but highlighted that progress in science would allow better measurement of Earth's size and shape.In 1832, Carl Friedrich Gauss studied the Earth's magnetic field and proposed adding the second to the basic units of the metre and the kilogram in the form of the CGS system (centimetre, gram, second). In 1836, he founded the Magnetischer Verein, the first international scientific association, in collaboration with Alexander von Humboldt and Wilhelm Edouard Weber. The coordination of the observation of geophysical phenomena such as the Earth's magnetic field, lightning and gravity in different points of the globe stimulated the creation of the first international scientific associations. The foundation of the Magnetischer Verein was followed by that of the Central European Arc Measurement (German: Mitteleuropa\u00efsche Gradmessung) on the initiative of Johann Jacob Baeyer in 1863, and by that of the International Meteorological Organisation whose second president, the Swiss meteorologist and physicist, Heinrich von Wild represented Russia at the International Committee for Weights and Measures (CIPM).\n\n\n=== International prototype metre bar ===\nThe influence of the intellect transcends mountains and leaps across oceans. At the time when George Washington warned his fellow countrymen against entangling political alliances with European countries, there was started a movement of far reaching importance in a small country in the heart of the Alps which (as we shall see) exerted a silent, yet potent scientific influence upon the young republic on the eastern shores of North America. \n\nIn 1816, Ferdinand Rudolph Hassler was appointed first Superintendent of the Survey of the Coast. Trained in geodesy in Switzerland, France and Germany, Hassler had brought a standard metre made in Paris to the United States in 1805. He designed a baseline apparatus which instead of bringing different bars in actual contact during measurements, used only one bar calibrated on the metre and optical contact. Thus the metre became the unit of length for geodesy in the United States.Since 1830, Hassler was also head of the Bureau of Weights and Measures which became a part of the Coast Survey. He compared various units of length used in the United States at that time and measured coefficients of expansion to assess temperature effects on the measurements.In 1841, Friedrich Wilhelm Bessel, taking into account errors which had been recognized by Louis Puissant in the French meridian arc comprising the arc measurement of Delambre and M\u00e9chain which had been extended southward by Fran\u00e7ois Arago and Jean-Baptiste Biot, recalculated the flattening of the Earth ellipsoid making use of nine more arc measurements, namely Peruan, Prussian, first East-Indian, second East-Indian, English, Hannover, Danish, Russian and Swedish covering almost 50 degrees of latitude, and stated that the Earth quadrant used for determining the length of the metre was nothing more than a rather imprecise conversion factor between the toise and the metre.Regarding the precision of the conversion from the toise to the metre, both units of measurement were then defined by primary standards, and unique artifacts made of different alloys with distinct coefficients of expansion were the legal basis of units of length. A wrought iron ruler, the Toise of Peru, also called Toise de l'Acad\u00e9mie, was the French primary standard of the toise, and the metre was officially defined by the M\u00e8tre des Archives made of platinum. Besides the latter, another platinum and twelve iron standards of the metre were made in 1799.One of them became known as the Committee Meter in the United States and served as standard of length in the Coast Survey until 1890. According to geodesists, these standards were secondary standards deduced from the Toise of Peru. In Europe, surveyors continued to use measuring instruments calibrated on the Toise of Peru. Among these, the toise of Bessel and the apparatus of Borda were respectively the main references for geodesy in Prussia and in France. A French scientific instrument maker, Jean Nicolas Fortin, had made two direct copies of the Toise of Peru, the first for Friedrich Georg Wilhelm von Struve in 1821 and a second for Friedrich Bessel in 1823.On the subject of the theoretical definition of the metre, it had been inaccessible and misleading at the time of Delambre and Mechain arc measurement, as the geoid is a ball, which on the whole can be assimilated to an oblate spheroid, but which in detail differs from it so as to prohibit any generalization and any extrapolation. As early as 1861, after Friedrich von Schubert showed that the different meridians were not of equal length, Elie Ritter, a mathematician from Geneva, deduced from a computation based on eleven meridian arcs covering 86 degrees that the meridian equation differed from that of the ellipse: the meridian was swelled about the 45th degree of latitude by a layer whose thickness was difficult to estimate because of the uncertainty of the latitude of some stations, in particular that of Montju\u00efc in the French meridian arc. By measuring the latitude of two stations in Barcelona, M\u00e9chain had found that the difference between these latitudes was greater than predicted by direct measurement of distance by triangulation. We know now that, in addition to other errors in the survey of Delambre and M\u00e9chain, an unfavourable vertical deflection gave an inaccurate determination of Barcelona's latitude, a metre \"too short\" compared to a more general definition taken from the average of a large number of arcs.Nevertheless Ferdinand Rudolph Hassler's use of the metre in coastal survey contributed to the introduction of the Metric Act of 1866 allowing the use of the metre in the United States, and also played an important role in the choice of the metre as international scientific unit of length and the proposal by the European Arc Measurement (German: Europ\u00e4ische Gradmessung) to \u201cestablish a European international bureau for weights and measures\u201d. However, in 1866, the most important concern was that the Toise of Peru, the standard of the toise constructed in 1735 for the French Geodesic Mission to the Equator, might be so much damaged that comparison with it would be worthless, while Bessel had questioned the accuracy of copies of this standard belonging to Altona and Koenigsberg Observatories, which he had compared to each other about 1840. Indeed when the primary Imperial yard standard was partially destroyed in 1834, a new standard of reference had been constructed using copies of the \"Standard Yard, 1760\" instead of the pendulum's length as provided for in the Weights and Measures Act of 1824.In 1864, Urbain Le Verrier refused to join the first general conference of the Central European Arc Measurement because the French geodetic works had to be verified.\n\nIn 1866, at the meeting of the Permanent Commission of the association in Neuch\u00e2tel, Antoine Yvon Villarceau announced that he had checked eight points of the French arc. He confirmed that the metre was too short. It then became urgent to undertake a complete revision of the meridian arc. Moreover, while the extension of the French meridian arc to the Balearic Islands (1803\u20131807) had seemed to confirm the length of the metre, this survey had not been secured by any baseline in Spain. For that reason, Carlos Ib\u00e1\u00f1ez e Ib\u00e1\u00f1ez de Ibero's announcement, at this conference, of his 1858 measurement of a baseline in Madridejos was of particular importance. Indeed surveyors determined the size of triangulation networks by measuring baselines which concordance granted the accuracy of the whole survey.In 1867 at the second general conference of the International Association of Geodesy held in Berlin, the question of an international standard unit of length was discussed in order to combine the measurements made in different countries to determine the size and shape of the Earth. The conference recommended the adoption of the metre in replacement of the toise and the creation of an international metre commission, according to the proposal of Johann Jacob Baeyer, Adolphe Hirsch and Carlos Ib\u00e1\u00f1ez e Ib\u00e1\u00f1ez de Ibero who had devised two geodetic standards calibrated on the metre for the map of Spain.Ib\u00e1\u00f1ez adopted the system which Ferdinand Rudolph Hassler used for the United States Survey of the Coast, consisting of a single standard with lines marked on the bar and microscopic measurements. Regarding the two methods by which the effect of temperature was taken into account, Ib\u00e1\u00f1ez used both the bimetallic rulers, in platinum and brass, which he first employed for the central baseline of Spain, and the simple iron ruler with inlaid mercury thermometers which was utilized in Switzerland. These devices, the first of which is referred to as either Brunner apparatus or Spanish Standard, were constructed in France by Jean Brunner, then his sons. Measurement traceability between the toise and the metre was ensured by comparison of the Spanish Standard with the standard devised by Borda and Lavoisier for the survey of the meridian arc connecting Dunkirk with Barcelona.Hassler's metrological and geodetic work also had a favourable response in Russia. In 1869, the Saint Petersburg Academy of Sciences sent to the French Academy of Sciences a report drafted by Otto Wilhelm von Struve, Heinrich von Wild and Moritz von Jacobi inviting his French counterpart to undertake joint action to ensure the universal use of the metric system in all scientific work.\n\nIn the 1870s and in light of modern precision, a series of international conferences was held to devise new metric standards. When a conflict broke out regarding the presence of impurities in the metre-alloy of 1874, a member of the Preparatory Committee since 1870 and Spanish representative at the Paris Conference in 1875, Carlos Ib\u00e1\u00f1ez e Ib\u00e1\u00f1ez de Ibero intervened with the French Academy of Sciences to rally France to the project to create an International Bureau of Weights and Measures equipped with the scientific means necessary to redefine the units of the metric system according to the progress of sciences.The Metre Convention (Convention du M\u00e8tre) of 1875 mandated the establishment of a permanent International Bureau of Weights and Measures (BIPM: Bureau International des Poids et Mesures) to be located in S\u00e8vres, France. This new organisation was to construct and preserve a prototype metre bar, distribute national metric prototypes, and maintain comparisons between them and non-metric measurement standards. The organisation distributed such bars in 1889 at the first General Conference on Weights and Measures (CGPM: Conf\u00e9rence G\u00e9n\u00e9rale des Poids et Mesures), establishing the International Prototype Metre as the distance between two lines on a standard bar composed of an alloy of 90% platinum and 10% iridium, measured at the melting point of ice.\n\nThe comparison of the new prototypes of the metre with each other and with the Committee metre (French: M\u00e8tre des Archives) involved the development of special measuring equipment and the definition of a reproducible temperature scale. The BIPM's thermometry work led to the discovery of special alloys of iron-nickel, in particular invar, for which its director, the Swiss physicist Charles-Edouard Guillaume, was granted the Nobel Prize for physics in 1920.\n\nAs Carlos Ib\u00e1\u00f1ez e Ib\u00e1\u00f1ez de Ibero stated, the progress of metrology combined with those of gravimetry through improvement of Kater's pendulum led to a new era of geodesy. If precision metrology had needed the help of geodesy, the latter could not continue to prosper without the help of metrology. It was then necessary to define a single unit to express all the measurements of terrestrial arcs and all determinations of the force of gravity by the mean of pendulum. Metrology had to create a common unit, adopted and respected by all civilized nations.Moreover, at that time, statisticians knew that scientific observations are marred by two distinct types of errors, constant errors on the one hand, and fortuitous errors, on the other hand. The effects of the latters can be mitigated by the least-squares method. Constant or regular errors on the contrary must be carefully avoided, because they arise from one or more causes that constantly act in the same way and have the effect of always altering the result of the experiment in the same direction. They therefore deprive of any value the observations that they impinge. However, the distinction between systematic and random errors is far from being as sharp as one might think at first assessment. In reality, there are no or very few random errors. As science progresses, the causes of certain errors are sought out, studied, their laws discovered. These errors pass from the class of random errors into that of systematic errors. The ability of the observer consists in discovering the greatest possible number of systematic errors in order to be able, once he has become acquainted with their laws, to free his results from them using a method or appropriate corrections.For metrology the matter of expansibility was fundamental; as a matter of fact the temperature measuring error related to the length measurement in proportion to the expansibility of the standard and the constantly renewed efforts of metrologists to protect their measuring instruments against the interfering influence of temperature revealed clearly the importance they attached to the expansion-induced errors. It was thus crucial to compare at controlled temperatures with great precision and to the same unit all the standards for measuring geodetic baselines and all the pendulum rods. Only when this series of metrological comparisons would be finished with a probable error of a thousandth of a millimetre would geodesy be able to link the works of the different nations with one another, and then proclaim the result of the measurement of the Globe.As the figure of the Earth could be inferred from variations of the seconds pendulum length with latitude, the United States Coast Survey instructed Charles Sanders Peirce in the spring of 1875 to proceed to Europe for the purpose of making pendulum experiments to chief initial stations for operations of this sort, in order to bring the determinations of the forces of gravity in America into communication with those of other parts of the world; and also for the purpose of making a careful study of the methods of pursuing these researches in the different countries of Europe. In 1886 the association of geodesy changed name for the International Geodetic Association, which Carlos Ib\u00e1\u00f1ez e Ib\u00e1\u00f1ez de Ibero presided up to his death in 1891. During this period the International Geodetic Association (German: Internationale Erdmessung) gained worldwide importance with the joining of United States, Mexico, Chile, Argentina, and Japan.\n\nEfforts to supplement the various national surveying systems, which began in the 19th century with the foundation of the Mitteleurop\u00e4ische Gradmessung, resulted in a series of global ellipsoids of the Earth (e.g., Helmert 1906, Hayford 1910 and 1924) which would later lead to develop the World Geodetic System. Nowadays the practical realisation of the metre is possible everywhere thanks to the atomic clocks embedded in GPS satellites.\n\n\n=== Wavelength definition ===\nIn 1873, James Clerk Maxwell suggested that light emitted by an element be used as the standard both for the metre and for the second. These two quantities could then be used to define the unit of mass.In 1893, the standard metre was first measured with an interferometer by Albert A. Michelson, the inventor of the device and an advocate of using some particular wavelength of light as a standard of length. By 1925, interferometry was in regular use at the BIPM. However, the International Prototype Metre remained the standard until 1960, when the eleventh CGPM defined the metre in the new International System of Units (SI) as equal to 1650763.73 wavelengths of the orange-red emission line in the electromagnetic spectrum of the krypton-86 atom in a vacuum.\n\n\n=== Speed of light definition ===\nTo further reduce uncertainty, the 17th CGPM in 1983 replaced the definition of the metre with its current definition, thus fixing the length of the metre in terms of the second and the speed of light:\nThe metre is the length of the path travelled by light in vacuum during a time interval of 1/299792458 of a second.This definition fixed the speed of light in vacuum at exactly 299792458 metres per second (\u2248300000 km/s or \u22481.079 billion km/hour). An intended by-product of the 17th CGPM's definition was that it enabled scientists to compare lasers accurately using frequency, resulting in wavelengths with one-fifth the uncertainty involved in the direct comparison of wavelengths, because interferometer errors were eliminated. To further facilitate reproducibility from lab to lab, the 17th CGPM also made the iodine-stabilised helium\u2013neon laser \"a recommended radiation\" for realising the metre. For the purpose of delineating the metre, the BIPM currently considers the HeNe laser wavelength, \u03bbHeNe, to be 632.99121258 nm with an estimated relative standard uncertainty (U) of 2.1\u00d710\u221211.This uncertainty is currently one limiting factor in laboratory realisations of the metre, and it is several orders of magnitude poorer than that of the second, based upon the caesium fountain atomic clock (U = 5\u00d710\u221216). Consequently, a  realisation of the metre is usually delineated (not defined) today in labs as 1579800.762042(33) wavelengths of helium-neon laser light in a vacuum, the error stated being only that of frequency determination. This bracket notation expressing the error is explained in the article on measurement uncertainty.\nPractical realisation of the metre is subject to uncertainties in characterising the medium, to various uncertainties of interferometry, and to uncertainties in measuring the frequency of the source. A commonly used medium is air, and the National Institute of Standards and Technology (NIST) has set up an online calculator to convert wavelengths in vacuum to wavelengths in air. As described by NIST, in air, the uncertainties in characterising the medium are dominated by errors in measuring temperature and pressure. Errors in the theoretical formulas used are secondary.By implementing a refractive index correction such as this, an approximate realisation of the metre can be implemented in air, for example, using the formulation of the metre as 1579800.762042(33) wavelengths of helium\u2013neon laser light in a vacuum, and converting the wavelengths in a vacuum to wavelengths in air. Air is only one possible medium to use in a realisation of the metre, and any partial vacuum can be used, or some inert atmosphere like helium gas, provided the appropriate corrections for refractive index are implemented.The metre is defined as the path length travelled by light in a given time, and practical laboratory length measurements in metres are determined by counting the number of wavelengths of laser light of one of the standard types that fit into the length, and converting the selected unit of wavelength to metres. Three major factors limit the accuracy attainable with laser interferometers for a length measurement:\nuncertainty in vacuum wavelength of the source,\nuncertainty in the refractive index of the medium,\nleast count resolution of the interferometer.Of these, the last is peculiar to the interferometer itself. The conversion of a length in wavelengths to a length in metres is based upon the relation\n\n  \n    \n      \n        \u03bb\n        =\n        \n          \n            c\n            \n              n\n              f\n            \n          \n        \n      \n    \n    {\\displaystyle \\lambda ={\\frac {c}{nf}}}\n  which converts the unit of wavelength \u03bb to metres using c, the speed of light in vacuum in m/s. Here n is the refractive index of the medium in which the measurement is made, and f is the measured frequency of the source. Although conversion from wavelengths to metres introduces an additional error in the overall length due to measurement error in determining the refractive index and the frequency, the measurement of frequency is one of the most accurate measurements available.The CIPM issued a clarification in 2002:\n\nIts definition, therefore, applies only within a spatial extent sufficiently small that the effects of the non-uniformity of the gravitational field can be ignored (note that, at the surface of the Earth, this effect in the vertical direction is about 1 part in 1016 per metre). In this case, the effects to be taken into account are those of special relativity only.\n\n\n=== Timeline ===\n\n\n== Early adoptions of the metre internationally ==\nIn France, the metre was adopted as an exclusive measure in 1801 under the Consulate. This continued under the First French Empire until 1812, when Napoleon decreed the introduction of the non-decimal mesures usuelles, which remained in use in France up to 1840 in the reign of Louis Philippe. Meanwhile, the metre was adopted by the Republic of Geneva. After the joining of the canton of Geneva to Switzerland in 1815, Guillaume Henri Dufour published the first official Swiss map, for which the metre was adopted as the unit of length.Louis Napol\u00e9on Bonaparte, a Swiss\u2013French binational officer, was present when a baseline was measured near Z\u00fcrich for the Dufour map, which would win the gold medal for a national map at the Exposition Universelle of 1855. Among the scientific instruments calibrated on the metre that were displayed at the Exposition Universelle, was Brunner's apparatus, a geodetic instrument devised for measuring the central baseline of Spain, whose designer, Carlos Ib\u00e1\u00f1ez e Ib\u00e1\u00f1ez de Ibero would represent Spain at the International Statistical Institute. In 1885, in addition to the Exposition Universelle and the second Statistical Congress held in Paris, an International Association for Obtaining a Uniform Decimal System of Measures, Weights, and Coins was created there.Copies of the Spanish standard were made for Egypt, France and Germany. These standards were compared to each other and with the Borda apparatus, which was the main reference for measuring all geodetic bases in France. In 1869, Napoleon III convened the International Metre Commission, which met in Paris in 1870. The Franco-Prussian War broke out, the Second French Empire collapsed, but the metre survived.\n\n\n=== Metre adoption dates by country ===\nFrance: 1801 - 1812, then 1840,\nRepublic of Geneva, Switzerland: 1813,\nKingdom of the Netherlands: 1820,\nKingdom of Belgium: 1830,\nChile: 1848,\nKingdom of Sardinia, Italy: 1850,\nSpain: 1852,\nPortugal: 1852,\nColombia: 1853,\nEcuador: 1856,\nMexico: 1857,\nBrazil: 1862,\nArgentina: 1863,\nItaly: 1863,\nGerman Empire, Germany: 1872,\nAustria, 1875,\nSwitzerland: 1877.\n\n\n== SI prefixed forms of metre ==\n\nSI prefixes can be used to denote decimal multiples and submultiples of the metre, as shown in the table below. Long distances are usually expressed in km, astronomical units (149.6 Gm), light-years (10 Pm), or parsecs (31 Pm), rather than in Mm, Gm, Tm, Pm, Em, Zm or Ym; \"30 cm\", \"30 m\", and \"300 m\" are more common than \"3 dm\", \"3 dam\", and \"3 hm\", respectively.\nThe terms micron and millimicron can be used instead of micrometre (\u03bcm) and nanometre (nm), but this practice may be discouraged.\n\n\n== Equivalents in other units ==\nWithin this table, \"inch\" and \"yard\" mean \"international inch\" and \"international yard\" respectively, though approximate conversions in the left column hold for both international and survey units.\n\n\"\u2248\" means \"is approximately equal to\";\n\"=\" means \"is exactly equal to\".One metre is exactly equivalent to 5 000/127 inches and to 1 250/1 143 yards.\nA simple mnemonic aid exists to assist with conversion, as three \"3\"s:\n\n1 metre is nearly equivalent to 3 feet 3+3\u20448 inches. This gives an overestimate of 0.125 mm; however, the practice of memorising such conversion formulas has been discouraged in favour of practice and visualisation of metric units.The ancient Egyptian cubit was about 0.5 m (surviving rods are 523\u2013529 mm). Scottish and English definitions of the ell (two cubits) were 941 mm (0.941 m) and 1143 mm (1.143 m) respectively. The ancient Parisian toise (fathom) was slightly shorter than 2 m and was standardised at exactly 2 m in the mesures usuelles system, such that 1 m was exactly 1\u20442 toise. The Russian verst was 1.0668 km. The Swedish mil was 10.688 km, but was changed to 10 km when Sweden converted to metric units.\n\n\n== See also ==\n\nISO 1 \u2013 standard reference temperature for length measurements\nMetric prefix\nVertical position\n\n\n== Notes ==\n\n\n== References ==\nAlder, Ken (2002). The Measure of All Things : The Seven-Year Odyssey and Hidden Error That Transformed the World. New York: Free Press. ISBN 978-0-7432-1675-3.\nAstin, A. V. & Karo, H. Arnold, (1959), Refinement of values for the yard and the pound, Washington DC: National Bureau of Standards, republished on  National Geodetic Survey web site and the Federal Register (Doc. 59-5442, Filed, 30 June 1959)\nJudson, Lewis V. (1 October 1976) [1963].  Barbrow, Louis E. (ed.). Weights and Measures Standards of the United States, a brief history (PDF). Derived from a prior work by Louis A. Fisher (1905). USA: US Department of Commerce, National Bureau of Standards. LCCN 76-600055. NBS Special Publication 447; NIST SP 447; 003-003-01654-3. Retrieved 12 October 2015.\nBigourdan, Guillaume (1901). Le syst\u00e8me m\u00e9trique des poids et mesures ; son \u00e9tablissement et sa propagation graduelle, avec l'histoire des op\u00e9rations qui ont servi \u00e0 d\u00e9terminer le m\u00e8tre et le kilogramme [The metric system of weights and measures; its establishment and gradual propagation, with the history of the operations which served to determine the meter and the kilogram]. Paris: Gauthier-Villars.\nClarke, Alexander Ross; Helmert, Friedrich Robert (1911b). \"Earth, Figure of the\" .  In Chisholm, Hugh (ed.). Encyclop\u00e6dia Britannica. Vol. 8 (11th ed.). Cambridge University Press. pp. 801\u2013813.\nGuedj, Denis (2001). La Mesure du Monde [The Measure of the World]. Translated by Goldhammer, Art. Chicago: University of Chicago Press.\nCardarelli, Fran\u00e7ois (2003). \"Chapter 2: The International system of Units\" (PDF). Encydopaedia of scientific units, weights, and measures: their SI equivalences and origins. Springer-Verlag London Limited. Table 2.1, p. 5. ISBN 978-1-85233-682-0. Retrieved 26 January 2017. Data from Giacomo, P., Du platine \u00e0 la lumi\u00e8re [From platinum to light], Bull. Bur. Nat. Metrologie, 102 (1995) 5\u201314.\nCardarelli, F. (2004). Encyclopaedia of Scientific Units, Weights and Measures: Their SI Equivalences and Origins (2nd ed.). Springer. pp. 120\u2013124. ISBN 1-85233-682-X.\nHistorical context of the SI: Meter. Retrieved 26 May 2010.\nNational Institute of Standards and Technology. (27 June 2011). NIST-F1 Cesium Fountain Atomic Clock. Author.\nNational Physical Laboratory. (25 March 2010). Iodine-Stabilised Lasers. Author.\n\"Maintaining the SI unit of length\". National Research Council Canada. 5 February 2010. Archived from the original on 4 December 2011.\nRepublic of the Philippines. (2 December 1978). Batas Pambansa Blg. 8: An Act Defining the Metric System and its Units, Providing for its Implementation and for Other Purposes. Author.\nRepublic of the Philippines. (10 October 1991). Republic Act No. 7160: The Local Government Code of the Philippines. Author.\n Supreme Court of the Philippines (Second Division). (20 January 2010). G.R. No. 185240. Author.\nTaylor, B.N. and Thompson, A. (Eds.). (2008a). The International System of Units (SI). United States version of the English text of the eighth edition (2006) of the International Bureau of Weights and Measures publication Le Syst\u00e8me International d' Unit\u00e9s (SI) (Special Publication 330). Gaithersburg, MD: National Institute of Standards and Technology. Retrieved 18 August 2008.\nTaylor, B.N. and Thompson, A. (2008b). Guide for the Use of the International System of Units (Special Publication 811). Gaithersburg, MD: National Institute of Standards and Technology. Retrieved 23 August 2008.\nTurner, J. (Deputy Director of the National Institute of Standards and Technology). (16 May 2008).\"Interpretation of the International System of Units (the Metric System of Measurement) for the United States\". Federal Register Vol. 73, No. 96, p. 28432-3.\nZagar, B.G. (1999). Laser interferometer displacement sensors in J.G. Webster (ed.). The Measurement, Instrumentation, and Sensors Handbook. CRC Press. ISBN 0-8493-8347-1.", "Compression_(physics)": "In mechanics, compression is the application of balanced inward (\"pushing\") forces to different points on a material or structure, that is, forces with no net sum or torque directed so as to reduce its size in one or more directions. It is contrasted with tension or traction, the application of balanced outward (\"pulling\") forces; and with shearing forces, directed so as to displace layers of the material parallel to each other.  The compressive strength of materials and structures is an important engineering consideration.\nIn uniaxial compression, the forces are directed along one direction only, so that they act towards decreasing the object's length along that direction.  The compressive forces may also be applied in multiple directions; for example inwards along the edges of a plate or all over the side surface of a cylinder, so as to reduce its area (biaxial compression), or inwards over the entire surface of a body, so as to reduce its volume.\nTechnically, a material is under a state of compression, at some specific point and along a specific direction \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , if the normal component of the stress vector across a surface with normal direction \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n   is directed opposite to \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .  If the stress vector itself is opposite to \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , the material is said to be under normal compression or pure compressive stress along \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  .  In a solid, the amount of compression generally depends on the direction \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  , and the material may be under compression along some directions but under traction along others.  If the stress vector is purely compressive and has the same magnitude for all directions, the material is said to be under isotropic or hydrostatic compression at that point.  This is the only type of static compression that liquids and gases can bear.In a mechanical wave which is longitudinal, the medium is displaced in the wave's direction, resulting in areas of compression and rarefaction.\n\n\n== Effects ==\nWhen put under compression (or any other type of stress), every material will suffer some deformation, even if imperceptible, that causes the average relative positions of its atoms and molecules to change.  The deformation may be permanent, or may be reversed when the compression forces disappear. In the latter case, the deformation gives rise to reaction forces that oppose the compression forces, and may eventually balance them.Liquids and gases cannot bear steady uniaxial or biaxial compression, they will deform promptly and permanently and will not offer any permanent reaction force. However they can bear isotropic compression, and may be compressed in other ways momentarily, for instance in a sound wave.\n\nEvery ordinary material will contract in volume when put under isotropic compression, contract in cross-section area when put under uniform biaxial compression, and contract in length when put into uniaxial compression.  The deformation may not be uniform and may not be aligned with the compression forces. What happens in the directions where there is no compression depends on the material.  Most materials will expand in those directions, but some special materials will remain unchanged or even contract. In general, the relation between the stress applied to a material and the resulting deformation is a central topic of continuum mechanics.\n\n\n== Uses ==\n\nCompression of solids has many implications in materials science, physics and structural engineering, for compression yields noticeable amounts of stress and tension.\nBy inducing compression, mechanical properties such as compressive strength or modulus of elasticity, can be measured.Compression machines range from very small table top systems  to ones with over 53 MN capacity.\nGases are often stored and shipped in highly compressed form, to save space.  Slightly compressed air or other gases are also used to fill balloons, rubber boats, and other inflatable structures.  Compressed liquids are used in hydraulic equipment and in fracking.\n\n\n== In engines ==\n\n\n=== Internal combustion engines ===\nIn internal combustion engines the explosive mixture gets compressed before it is ignited; the compression improves the efficiency of the engine. In the Otto cycle, for instance, the second stroke of the piston effects the compression of the charge which has been drawn into the cylinder by the first forward stroke.\n\n\n=== Steam engines ===\nThe term is applied to the arrangement by which the exhaust valve of a steam engine is made to close, shutting a portion of the exhaust steam in the cylinder, before the stroke of the piston is quite complete. This steam being compressed as the stroke is completed, a cushion is formed against which the piston does work while its velocity is being rapidly reduced, and thus the stresses in the mechanism due to the inertia of the reciprocating parts are lessened. This compression, moreover, obviates the shock which would otherwise be caused by the admission of the fresh steam for the return stroke.\n\n\n== See also ==\nBuckling\nContainer compression test\nCompression member\nCompressive strength\nLongitudinal wave\nP-wave\nRarefaction\nStrength of materials\nResal effect\nPlane strain compression test\n\n\n== References ==", "Resultant_force": "In physics and engineering, a resultant force is the single force and associated torque obtained by combining a system of forces and torques acting on a rigid body via vector addition. The defining feature of a resultant force, or resultant force-torque, is that it has the same effect on the rigid body as the original system of forces. Calculating and visualizing the resultant force on a body is done through computational analysis, or (in the case of sufficiently simple systems) a free body diagram.\nThe point of application of the resultant force determines its associated torque. The term resultant force should be understood to refer to both the forces and torques acting on a rigid body, which is why some use the term resultant force\u2013torque.\n\n\n== Illustration ==\nThe diagram illustrates simple graphical methods for finding the line of application of the resultant force of simple planar systems.\n\nLines of application of the actual forces \n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    F\n                    \u2192\n                  \n                \n              \n              \n                1\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\scriptstyle {\\vec {F}}_{1}}}\n   and \n  \n    \n      \n        \n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\vec {F}}_{2}}\n   in the leftmost illustration intersect. After vector addition is performed \"at the location of \n  \n    \n      \n        \n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n              1\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\vec {F}}_{1}}\n  \", the net force obtained is translated so that its line of application passes through the common intersection point. With respect to that point all torques are zero, so the torque of the resultant force \n  \n    \n      \n        \n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n              R\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\vec {F}}_{R}}\n   is equal to the sum of the torques of the actual forces.\nIllustration in the middle of the diagram shows two parallel actual forces. After vector addition \"at the location of \n  \n    \n      \n        \n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\vec {F}}_{2}}\n  \", the net force is translated to the appropriate line of application, whereof it becomes the resultant force \n  \n    \n      \n        \n          \n            \n              \n                \n                  F\n                  \u2192\n                \n              \n            \n            \n              R\n            \n          \n        \n      \n    \n    {\\displaystyle \\scriptstyle {\\vec {F}}_{R}}\n  . The procedure is based on a decomposition of all forces into components for which the lines of application (pale dotted lines) intersect at one point (the so-called pole, arbitrarily set at the right side of the illustration). Then the arguments from the previous case are applied to the forces and their components to demonstrate the torque relationships.\nThe rightmost illustration shows a couple, two equal but opposite forces for which the amount of the net force is zero, but they produce the net torque \n  \n    \n      \n        \n          \u03c4\n          =\n          F\n          d\n        \n      \n    \n    {\\displaystyle \\scriptstyle \\tau =Fd}\n     where \n  \n    \n      \n        \n          d\n        \n      \n    \n    {\\displaystyle \\scriptstyle d}\n    is the distance between their lines of application. This is \"pure\" torque, since there is no resultant force.\n\n\n== Bound vector ==\nA force applied to a body has a point of application.  The effect of the force is different for different points of application.  For this reason a force is called a bound vector, which means that it is bound to its point of application.\nForces applied at the same point can be added together to obtain the same effect on the body.  However, forces with different points of application cannot be added together and maintain the same effect on the body.\nIt is a simple matter to change the point of application of a force by introducing equal and opposite forces at two different points of application that produce a pure torque on the body.  In this way, all of the forces acting on a body can be moved to the same point of application with associated torques.\nA system of forces on a rigid body is combined by moving the forces to the same point of application and computing the associated torques.  The sum of these forces and torques yields the resultant force-torque.\n\n\n== Associated torque ==\nIf a point R is selected as the point of application of the resultant force F of a system of n forces Fi then the associated torque T is determined from the formulas\n\n  \n    \n      \n        \n          F\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \n            F\n          \n          \n            i\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} =\\sum _{i=1}^{n}\\mathbf {F} _{i},}\n  and\n\n  \n    \n      \n        \n          T\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        (\n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u2212\n        \n          R\n        \n        )\n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {T} =\\sum _{i=1}^{n}(\\mathbf {R} _{i}-\\mathbf {R} )\\times \\mathbf {F} _{i}.}\n  It is useful to note that the point of application R of the resultant force may be anywhere along the line of action of F without changing the value of the associated torque.  To see this add the vector kF to the point of application R in the calculation of the associated torque,\n\n  \n    \n      \n        \n          T\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        (\n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u2212\n        (\n        \n          R\n        \n        +\n        k\n        \n          F\n        \n        )\n        )\n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {T} =\\sum _{i=1}^{n}(\\mathbf {R} _{i}-(\\mathbf {R} +k\\mathbf {F} ))\\times \\mathbf {F} _{i}.}\n  The right side of this equation can be separated into the original formula for T plus the additional term including kF,\n\n  \n    \n      \n        \n          T\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        (\n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u2212\n        \n          R\n        \n        )\n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        \u2212\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        k\n        \n          F\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        (\n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u2212\n        \n          R\n        \n        )\n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {T} =\\sum _{i=1}^{n}(\\mathbf {R} _{i}-\\mathbf {R} )\\times \\mathbf {F} _{i}-\\sum _{i=1}^{n}k\\mathbf {F} \\times \\mathbf {F} _{i}=\\sum _{i=1}^{n}(\\mathbf {R} _{i}-\\mathbf {R} )\\times \\mathbf {F} _{i},}\n  because the second term is zero.  To see this notice that F is the sum of the vectors Fi which yields\n\n  \n    \n      \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        k\n        \n          F\n        \n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        =\n        k\n        \n          F\n        \n        \u00d7\n        (\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \n            F\n          \n          \n            i\n          \n        \n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\sum _{i=1}^{n}k\\mathbf {F} \\times \\mathbf {F} _{i}=k\\mathbf {F} \\times (\\sum _{i=1}^{n}\\mathbf {F} _{i})=0,}\n  thus the value of the associated torque is unchanged.\n\n\n== Torque-free resultant ==\nIt is useful to consider whether there is a point of application R such that the associated torque is zero.  This point is defined by the property\n\n  \n    \n      \n        \n          R\n        \n        \u00d7\n        \n          F\n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {R} \\times \\mathbf {F} =\\sum _{i=1}^{n}\\mathbf {R} _{i}\\times \\mathbf {F} _{i},}\n  where F is resultant force and Fi form the system of forces.\nNotice that this equation for R has a solution only if the sum of the individual torques on the right side yield a vector that is perpendicular to F.  Thus, the condition that a system of forces has a torque-free resultant can be written as\n\n  \n    \n      \n        \n          F\n        \n        \u22c5\n        (\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        )\n        =\n        0.\n      \n    \n    {\\displaystyle \\mathbf {F} \\cdot (\\sum _{i=1}^{n}\\mathbf {R} _{i}\\times \\mathbf {F} _{i})=0.}\n  If this condition is satisfied then there is a point of application for the resultant which results in a pure force.  If this condition is not satisfied, then the system of forces includes a pure torque for every point of application.\n\n\n== Wrench ==\nThe forces and torques acting on a rigid body can be assembled into the pair of vectors called a wrench. If a system of forces and torques has a net resultant force F and a net resultant torque T, then the entire system can be replaced by a force F and an arbitrarily located couple that yields a torque of T. In general, if F and T are orthogonal, it is possible to derive a radial vector R such that \n  \n    \n      \n        \n          R\n        \n        \u00d7\n        \n          F\n        \n        =\n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbf {R} \\times \\mathbf {F} =\\mathbf {T} }\n  , meaning that the single force F, acting at displacement R, can replace the system.  If the system is zero-force (torque only), it is termed a screw and is mathematically formulated as screw theory.The resultant force and torque on a rigid body obtained from a system of forces Fi i=1,...,n, is simply the sum of the individual wrenches Wi, that is\n\n  \n    \n      \n        \n          \n            W\n          \n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \n            \n              W\n            \n          \n          \n            i\n          \n        \n        =\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        (\n        \n          \n            F\n          \n          \n            i\n          \n        \n        ,\n        \n          \n            R\n          \n          \n            i\n          \n        \n        \u00d7\n        \n          \n            F\n          \n          \n            i\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle {\\mathsf {W}}=\\sum _{i=1}^{n}{\\mathsf {W}}_{i}=\\sum _{i=1}^{n}(\\mathbf {F} _{i},\\mathbf {R} _{i}\\times \\mathbf {F} _{i}).}\n  Notice that the case of two equal but opposite forces F and -F acting at points A and B respectively, yields the resultant W=(F-F,  A\u00d7F - B\u00d7 F) = (0, (A-B)\u00d7F).  This shows that wrenches of the form W=(0, T) can be interpreted as pure torques.\n\n\n== References ==", "Physical_quantity": "A physical quantity is a physical property of a material or system that can be quantified by measurement. A physical quantity can be expressed as a value, which is the algebraic multiplication of a ' Numerical value ' and a ' Unit '. For example, the physical quantity of mass can be quantified as '32.3 kg ', where '32.3' is the numerical value and 'kg' is the Unit. \nA physical quantity possesses at least two characteristics in common. \n\nNumerical magnitude\nUnits\n\n\n== Symbols and nomenclature ==\nInternational recommendations for the use of symbols for quantities are set out in ISO/IEC 80000, the IUPAP red book and the IUPAC green book. For example, the recommended symbol for the physical quantity mass is m, and the recommended symbol for the quantity electric charge is Q.\n\n\n== Subscripts and indices ==\nSubscripts are used for two reasons, to simply attach a name to the quantity or associate it with another quantity, or index a specific component (e.g., row or column).\n\nName reference: The quantity has a subscripted or superscripted single letter, group of letters, or complete word, to label what concept or entity they refer to, often to distinguish it from other quantities with the same main symbol. These subscripts or superscripts tend to be written in upright roman typeface rather than italics while the main symbol representing the quantity is in italics. For instance, Ek or Ekinetic is usually used to denote kinetic energy and E p or E potential is usually used to denote potential energy.\nQuantity reference: The quantity has a subscripted or superscripted single letter, group of letters, or complete word, to parameterize what measurement/s they refer to. These subscripts or superscripts tend to be written in italic rather than in upright roman typeface; the main symbol representing the quantity is in italics. For example cp or cpressure is heat capacity at the pressure given by the quantity in the subscript.The type of subscript is expressed by its typeface:  'k' and 'p' are abbreviations of the words kinetic and potential, whereas p (italic) is the symbol for the physical quantity pressure rather than an abbreviation of the word.\n\nIndices: The use of indices is for mathematical formulation using index notation.\n\n\n== Size ==\nPhysical quantities can have different \"sizes\", such as a scalar, a vector, or a tensor.\n\n\n=== Scalars ===\nA scalar is a physical quantity that has magnitude but no direction. Symbols for physical quantities are usually chosen to be a single letter of the Latin or Greek alphabet, and are printed in italic type.\n\n\n=== Vectors ===\nVectors are physical quantities that possess both magnitude and direction and whose operations obey the axioms of a vector space. Symbols for physical quantities that are vectors are in bold type, underlined or with an arrow above. For example, if u is the speed of a particle, then the straightforward notations for its velocity are u, u, or \n  \n    \n      \n        \n          \n            \n              u\n              \u2192\n            \n          \n        \n        \n        \n      \n    \n    {\\displaystyle {\\vec {u}}\\,\\!}\n  .\n\n\n=== Tensors ===\nScalars and vectors are the simplest tensors, which can be used to describe more general physical quantities. For example, the Cauchy stress tensor possesses magnitude, direction, and orientation qualities.\n\n\n== Numbers and elementary functions ==\nNumerical quantities, even those denoted by letters, are usually printed in roman (upright) type, though sometimes in italics. Symbols for elementary functions (circular trigonometric, hyperbolic, logarithmic etc.), changes in a quantity like \u0394 in \u0394y or operators like d in dx, are also recommended to be printed in roman type.\nExamples:\n\nReal numbers, such as 1 or \u221a2,\ne, the base of natural logarithms,\ni, the imaginary unit,\n\u03c0 for the ratio of a circle's circumference to its diameter, 3.14159265358979323846264338327950288...\n\u03b4x, \u0394y, dz, representing differences (finite or otherwise) in the quantities x, y and z\nsin \u03b1, sinh \u03b3, log x 1 russ street\n\n\n== Units and dimensions ==\n\n\n=== Units ===\n There is often a choice of unit, though SI units (including submultiples and multiples of the basic unit) are usually used in scientific contexts due to their ease of use, international familiarity and prescription. For example, a quantity of mass might be represented by the symbol m, and could be expressed in the units kilograms (kg), pounds (lb), or daltons (Da).\n\n\n=== Dimensions ===\n\nThe notion of dimension of a physical quantity was introduced by Joseph Fourier in 1822. By convention, physical quantities are organized in a dimensional system built upon base quantities, each of which is regarded as having its own dimension.\n\n\n== Base quantities ==\n\nBase quantities are those quantities that are distinct in nature and in some cases have historically not been defined in terms of other quantities. Base quantities are those quantities on the basis of which other quantities can be expressed. The seven base quantities of the International System of Quantities (ISQ) and their corresponding SI units and dimensions are listed in the following table. Other conventions may have a different number of base units (e.g. the CGS and MKS systems of units).\n\nThe last two angular units, plane angle and solid angle, are subsidiary units used in the SI, but are treated as dimensionless. The subsidiary units are used for convenience to differentiate between a truly dimensionless quantity (pure number) and an angle, which are different measurements.\n\n\n== General derived quantities ==\nDerived quantities are those whose definitions are based on other physical quantities (base quantities).\n\n\n=== Space ===\nImportant applied base units for space and time are below. Area and volume are thus, of course, derived from the length, but included for completeness as they occur frequently in many derived quantities, in particular densities.\n\n\n=== Densities, flows, gradients, and moments ===\nImportant and convenient derived quantities such as densities, fluxes, flows, currents are associated with many quantities. Sometimes different terms such as current density and flux density, rate, frequency and current, are used interchangeably in the same context, sometimes they are used uniquely.\nTo clarify these effective template-derived quantities, we let q be any quantity within some scope of context (not necessarily base quantities) and present in the table below some of the most commonly used symbols where applicable, their definitions, usage, SI units and SI dimensions \u2013 where [q] denotes the dimension of q.\nFor time derivatives, specific, molar, and flux densities of quantities, there is no one symbol, nomenclature depends on the subject, though time derivatives can be generally written using overdot notation. For generality we use qm, qn, and F respectively. No symbol is necessarily required for the gradient of a scalar field, since only the nabla/del operator \u2207 or grad needs to be written. For spatial density, current, current density and flux, the notations are common from one context to another, differing only by a change in subscripts.\nFor current density, \n  \n    \n      \n        \n          \n            \n              t\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {t}} }\n   is a unit vector in the direction of flow, i.e. tangent to a flowline. Notice the dot product with the unit normal for a surface, since the amount of current passing through the surface is reduced when the current is not normal to the area. Only the current passing perpendicular to the surface contributes to the current passing through the surface, no current passes in the (tangential) plane of the surface.\nThe calculus notations below can be used synonymously.\nIf X is a n-variable function \n  \n    \n      \n        X\n        \u2261\n        X\n        \n          (\n          \n            \n              x\n              \n                1\n              \n            \n            ,\n            \n              x\n              \n                2\n              \n            \n            \u22ef\n            \n              x\n              \n                n\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle X\\equiv X\\left(x_{1},x_{2}\\cdots x_{n}\\right)}\n  , then\nDifferential The differential n-space volume element is \n  \n    \n      \n        \n          \n            d\n          \n          \n            n\n          \n        \n        x\n        \u2261\n        \n          d\n        \n        \n          V\n          \n            n\n          \n        \n        \u2261\n        \n          d\n        \n        \n          x\n          \n            1\n          \n        \n        \n          d\n        \n        \n          x\n          \n            2\n          \n        \n        \u22ef\n        \n          d\n        \n        \n          x\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {d} ^{n}x\\equiv \\mathrm {d} V_{n}\\equiv \\mathrm {d} x_{1}\\mathrm {d} x_{2}\\cdots \\mathrm {d} x_{n}}\n  ,\n\nIntegral: The multiple integral of X over the n-space volume is \n  \n    \n      \n        \u222b\n        X\n        \n          \n            d\n          \n          \n            n\n          \n        \n        x\n        \u2261\n        \u222b\n        X\n        \n          d\n        \n        \n          V\n          \n            n\n          \n        \n        \u2261\n        \u222b\n        \u22ef\n        \u222b\n        \u222b\n        X\n        \n          d\n        \n        \n          x\n          \n            1\n          \n        \n        \n          d\n        \n        \n          x\n          \n            2\n          \n        \n        \u22ef\n        \n          d\n        \n        \n          x\n          \n            n\n          \n        \n        \n        \n      \n    \n    {\\displaystyle \\int X\\mathrm {d} ^{n}x\\equiv \\int X\\mathrm {d} V_{n}\\equiv \\int \\cdots \\int \\int X\\mathrm {d} x_{1}\\mathrm {d} x_{2}\\cdots \\mathrm {d} x_{n}\\,\\!}\n  .The meaning of the term physical quantity is generally well understood (everyone understands what is meant by the frequency of a periodic phenomenon, or the resistance of an electric wire). The term physical quantity does not imply a physically invariant quantity. Length for example is a physical quantity, yet it is variant under coordinate change in special and general relativity. The notion of physical quantities is so basic and intuitive in the realm of science, that it does not need to be explicitly spelled out or even mentioned. It is universally understood that scientists will (more often than not) deal with quantitative data, as opposed to qualitative data. Explicit mention and discussion of physical quantities is not part of any standard science program, and is more suited for a philosophy of science or philosophy program.\nThe notion of physical quantities is seldom used in physics, nor is it part of the standard physics vernacular. The idea is often misleading, as its name implies \"a quantity that can be physically measured\", yet is often incorrectly used to mean a physical invariant. Due to the rich complexity of physics, many different fields possess different physical invariants. There is no known physical invariant sacred in all possible fields of physics. Energy, space, momentum, torque, position, and length (just to name a few) are all found to be experimentally variant in some particular scale and system. Additionally, the notion that it is possible to measure \"physical quantities\" comes into question, particularly in quantum field theory and normalization techniques. As infinities are produced by the theory, the actual \"measurements\" made are not really those of the physical universe (as we cannot measure infinities), they are those of the renormalization scheme which is expressly dependent on our measurement scheme, coordinate system and metric system.\n\n\n== See also ==\nList of physical quantities\nList of photometric quantities\nList of radiometric quantities\nPhilosophy of science\nQuantity\nObservable quantity\nSpecific quantity\n\n\n== References ==\n\n\n=== Computer implementations ===\nDEVLIB project in C# Language and Delphi Language\nPhysical Quantities project in C# Language at Code Plex\nPhysical Measure C# library project in C# Language at Code Plex\nEthical Measures project in C# Language at Code Plex\nEngineer JS online calculation and scripting tool supporting physical quantities.\n\n\n== Sources ==\nCook, Alan H. The observational foundations of physics, Cambridge, 1994. ISBN 0-521-45597-9\nEssential Principles of Physics, P.M. Whelan, M.J. Hodgson, 2nd Edition, 1978, John Murray, ISBN 0-7195-3382-1\nEncyclopedia of Physics, R.G. Lerner, G.L. Trigg, 2nd Edition, VHC Publishers, Hans Warlimont, Springer, 2005, pp 12\u201313\nPhysics for Scientists and Engineers: With Modern Physics (6th Edition), P.A. Tipler, G. Mosca, W.H. Freeman and Co, 2008, 9-781429-202657", "Subtractive_color": "Subtractive color or subtractive color mixing predicts the spectral power distribution of light after it passes through successive layers of partially absorbing media. This idealized model is the essential principle of how dyes and inks are used in color printing and photography where the perception of color is elicited after white light passes through microscopic \"stacks\" of partially absorbing media allowing some wavelengths of light to reach the eye and not others.\n\n\n== Process ==\nThe subtractive color mixing model predicts the resultant spectral power distribution of light filtered through overlaid partially absorbing materials on a reflecting or transparent surface. Each layer partially absorbs some wavelengths of light from the illumination spectrum while letting others pass through, resulting in a colored appearance. The resultant spectral power distribution is predicted by sequentially taking the product of the spectral power distributions of the incoming light and transmissivity at each filter.\n\n\n== RYB ==\n\nRYB (red, yellow, blue) is the traditional set of primary colors used for mixing pigments. It is used in art and art education, particularly in painting. It predated modern scientific color theory.\nRed, yellow, and blue are the primary colors of the RYB color \"wheel\".  The secondary colors, violet (or purple), orange, and green (VOG) make up another triad, conceptually formed by mixing equal amounts of red and blue, red and yellow, and blue and yellow, respectively.\n\nThe RYB primary colors became the foundation of 18th-century theories of color vision as the fundamental sensory qualities blended in the perception of all physical colors and equally in the physical mixture of pigments or dyes. These theories were enhanced by 18th-century investigations of a variety of purely psychological color effects, in particular, the contrast between \"complementary\" or opposing hues produced by color afterimages and in the contrasting shadows in colored light. These ideas and many personal color observations were summarized in two founding documents in color theory: the Theory of Colors (1810) by the German poet and government minister Johann Wolfgang von Goethe, and The Law of Simultaneous Color Contrast (1839) by the French industrial chemist Michel-Eug\u00e8ne Chevreul.\nIn late 19th and early to mid-20th-century commercial printing, use of the traditional RYB terminology persisted even though the more versatile CMY (cyan, magenta, yellow) triad had been adopted, with the cyan sometimes referred to as \"process blue\" and the magenta as \"process red\".\n\n\n== CMY and CMYK color models and printing processes ==\n\nIn color printing, the usual primary colors are cyan, magenta and yellow (CMY). Cyan is the complement of red, meaning that the cyan serves as a filter that absorbs red. The amount of cyan applied to a white sheet of paper controls how much of the red in white light will be reflected back from the paper. Ideally, the cyan is completely transparent to green and blue light and has no effect on those parts of the spectrum. Magenta is the complement of green, and yellow the complement of blue. Combinations of different amounts of the three can produce a wide range of colors with good saturation.\nIn inkjet color printing and typical mass production photomechanical printing processes, a black ink K (Key) component is included, resulting in the CMYK color model. The black ink serves to cover unwanted tints in dark areas of the printed image, which result from the imperfect transparency of commercially practical CMY inks; to improve image sharpness, which tends to be degraded by imperfect registration of the three color elements; and to reduce or eliminate consumption of the more expensive color inks where only black or gray is required.\nPurely photographic color processes almost never include a K component, because in all common processes the CMY dyes used are much more perfectly transparent, there are no registration errors to camouflage, and substituting a black dye for a saturated CMY combination, a trivial prospective cost-benefit at best, is technologically impractical in non-electronic analog photography.\n\n\n== See also ==\nAdditive color\nColor mixing\nColor motion picture film\nColor space\nColor theory\nPrimary color\n\n\n== References ==\n\n\n== Further reading ==\nBerns, Roy S. (2000). Billmeyer and Saltzman's Principles of Color Technology, 3rd edition. Wiley, New York. ISBN 0-471-19459-X.\nStroebel, Leslie, John Compton, Ira Current, and Richard Zakia (2000). Basic Photographic Materials and Processes, 2nd edition. Focal Press, Boston. ISBN 0-240-80405-8.{{cite book}}:  CS1 maint: multiple names: authors list (link)\nWyszecki, G\u00fcnther & W. S. Stiles (1982). Colour Science: Concept and Methods, Quantitative Data and Formulae. Wiley, New York. ISBN 0-471-02106-7.\n\n\n== External links ==\nStanford University CS 178 interactive Flash demo  comparing additive and subtractive color mixing.", "Free_body_diagram": "In physics and engineering, a free body diagram (FBD; also called a force diagram) is a graphical illustration used to visualize the applied forces, moments, and resulting reactions on a body in a given condition. It depicts a body or connected bodies with all the applied forces and moments, and reactions, which act on the body(ies). The body may consist of multiple internal members (such as a truss), or be a compact body (such as a beam). A series of free bodies and other diagrams may be necessary to solve complex problems.\n\n\n== Purpose ==\nFree body diagrams are used to visualize forces and moments applied to a body and to calculate reactions in mechanics problems. These diagrams are frequently used both to determine the loading of individual structural components and to calculate internal forces within a structure. They are used by most engineering disciplines from Biomechanics to Structural Engineering.\nIn the educational environment, a free body diagram is an important step in understanding certain topics, such as statics, dynamics and other forms of classical mechanics.\n\n\n== Features ==\nA free body diagram is not a scaled drawing, it is a diagram. The symbols used in a free body diagram depends upon how a body is modeled.Free body diagrams consist of:\n\nA simplified version of the body (often a dot or a box)\nForces shown as straight arrows pointing in the direction they act on the body\nMoments are shown as curves with an arrow head or a vector with two arrow heads pointing in the direction they act on the body\nOne or more reference coordinate systems\nBy convention, reactions to applied forces are shown with hash marks through the stem of the vectorThe number of forces and moments shown depends upon the specific problem and the assumptions made. Common assumptions are neglecting air resistance and friction and assuming rigid body action. \nIn statics all forces and moments must balance to zero; the physical interpretation is that if they do not, the body is accelerating and the principles of statics do not apply. In dynamics the resultant forces and moments can be non-zero.\nFree body diagrams may not represent an entire physical body. Portions of a body can be selected for analysis. This technique allows calculation of internal forces, making them appear external, allowing analysis. This can be used multiple times to calculate internal forces at different locations within a physical body.  \nFor example, a gymnast performing the iron cross: modeling the ropes and person allows calculation of overall forces (body weight, neglecting rope weight, breezes, buoyancy, electrostatics, relativity, rotation of the earth, etc.). Then remove the person and show only one rope; you get force direction. Then only looking at the person the forces on the hand can be calculated. Now only look at the arm to calculate the forces and moments at the shoulders, and so on until the component you need to analyze can be calculated.\n\n\n=== Modeling the body ===\nA body may be modeled in three ways:\n\na particle. This model may be used when any rotational effects are zero or have no interest even though the body itself may be extended. The body may be represented by a small symbolic blob and the diagram reduces to a set of concurrent arrows. A force on a particle is a bound vector.\nrigid extended. Stresses and strains are of no interest but rotational effects are. A force arrow should lie along the line of force, but where along the line is irrelevant. A force on an extended rigid body is a sliding vector.\nnon-rigid extended. The point of application of a force becomes crucial and has to be indicated on the diagram. A force on a non-rigid body is a bound vector. Some use the tail of the arrow to indicate the point of application. Others use the tip.\n\n\n==== Example: A body in free fall ====\n\nConsider a body in free fall in a uniform gravitational field. The body may be\n\na particle. It is enough to show a single vertically downward pointing arrow attached to a blob.\nrigid extended. A single arrow suffices to represent the weight W even though calm gravitational attraction acts on every particle of the body.\nnon-rigid extended. In non-rigid analysis, it would be an error to associate a single point of application with the gravitational force.\n\n\n=== What is included ===\nAn FBD represents the body of interest and the external forces acting on it.\n\nThe body: This is usually a schematic depending on the body\u2014particle/extended, rigid/non-rigid\u2014and on what questions are to be answered. Thus if rotation of the body and torque is in consideration, an indication of size and shape of the body is needed. For example, the brake dive of a motorcycle cannot be found from a single point, and a sketch with finite dimensions is required.\nThe external forces: These are indicated by labelled arrows. In a fully solved problem, a force arrow is capable of indicating\nthe direction and the line of action\nthe magnitude\nthe point of application\na reaction, as opposed to an applied force, if a hash is present through the stem of the arrowOften a provisional free body is drawn before everything is known. The purpose of the diagram is to help to determine magnitude, direction, and point of application of external loads. When a force is originally drawn, its length may not indicate the magnitude. Its line may not correspond to the exact line of action. Even its orientation may not be correct. \nExternal forces known to have negligible effect on the analysis may be omitted after careful consideration (e.g. buoyancy forces of the air in the analysis of a chair, or atmospheric pressure on the analysis of a frying pan).\nExternal forces acting on an object may include friction, gravity, normal force, drag, tension, or a human force due to pushing or pulling. When in a non-inertial reference frame (see coordinate system, below), fictitious forces, such as centrifugal pseudoforce are appropriate.\nAt least one coordinate system is always included, and chosen for convenience. Judicious selection of a coordinate system can make defining the vectors simpler when writing the equations of motion or statics. The x direction may be chosen to point down the ramp in an inclined plane problem, for example. In that case the friction force only has an x component, and the normal force only has a y component. The force of gravity would then have components in both the x and y directions: mgsin(\u03b8) in the x and mgcos(\u03b8) in the y, where \u03b8 is the angle between the ramp and the horizontal.\n\n\n=== Exclusions ===\nA free body diagram should not show:\n\nBodies other than the free body.\nConstraints.\n(The body is not free from constraints; the constraints have just been replaced by the forces and moments exerted on the body.)\nForces exerted by the free body.\n(A diagram showing the forces exerted both on and by a body is likely to be confusing since all the forces will cancel out. By Newton's 3rd law if body A exerts a force on body B then B exerts an equal and opposite force on A. This should not be confused with the equal and opposite forces that are necessary to hold a body in equilibrium.)\nInternal forces.\n(For example, if an entire truss is being analyzed, the forces between the individual truss members are not included.)\nVelocity or acceleration vectors.\n\n\n== Analysis ==\nIn an analysis, a free body diagram is used by summing all forces and moments (often accomplished along or about each of the axes). When the sum of all forces and moments is zero, the body is at rest or moving and/or rotating at a constant velocity, by Newton's first law. If the sum is not zero, then the body is accelerating in a direction or about an axis according to Newton's second law.\n\n\n=== Forces not aligned to an axis ===\n\nDetermining the sum of the forces and moments is straightforward if they are aligned with coordinate axes, but it is more complex if some are not. It is convenient to use the components of the forces, in which case the symbols \u03a3Fx and \u03a3Fy are used instead of \u03a3F (the variable M is used for moments). \nForces and moments that are at an angle to a coordinate axis can be rewritten as two vectors that are equivalent to the original (or three, for three dimensional problems)\u2014each vector directed along one of the axes (Fx) and (Fy).\n\n\n== Example: A block on an inclined plane ==\nA simple free-body diagram, shown above, of a block on a ramp, illustrates this.\n\nAll external supports and structures have been replaced by the forces they generate. These include:\nmg: the product of the mass of the block and the constant of gravitation acceleration: its weight.\nN: the normal force of the ramp.\nFf: the friction force of the ramp.\nThe force vectors show the direction and point of application and are labelled with their magnitude.\nIt contains a coordinate system that can be used when describing the vectors.Some care is needed in interpreting the diagram.\n\nThe normal force has been shown to act at the midpoint of the base, but if the block is in static equilibrium its true location is directly below the centre of mass, where the weight acts because that is necessary to compensate for the moment of the friction.\nUnlike the weight and normal force, which are expected to act at the tip of the arrow, the friction force is a sliding vector and thus the point of application is not relevant, and the friction acts along the whole base.\n\n\n== Kinetic diagram ==\n\nIn dynamics a kinetic diagram is a pictorial device used in analyzing mechanics problems when there is determined to be a net force and/or moment acting on a body. They are related to and often used with free body diagrams, but depict only the net force and moment rather than all of the forces being considered.\nKinetic diagrams are not required to solve dynamics problems; their use in teaching dynamics is argued against by some in favor of other methods that they view as simpler. They appear in some dynamics texts but are absent in others.\n\n\n== See also ==\n\nClassical mechanics\nForce field analysis \u2013 applications of force diagram in social science\nKinematic diagram\nPhysics\nShear and moment diagrams\n\n\n== References ==\n\n\n== Notes ==", "Crystallinity": "Crystallinity refers to the degree of structural order in a solid. In a crystal, the atoms or molecules are arranged in a regular, periodic manner. The degree of crystallinity has a big influence on hardness, density, transparency and diffusion. In an ideal gas, the relative positions of the atoms or molecules are completely random. Amorphous materials, such as liquids and glasses, represent an intermediate case, having order over short distances (a few atomic or molecular spacings) but not over longer distances.\nMany materials, such as glass-ceramics and some polymers, can be prepared in such a way as to produce a mixture of crystalline and amorphous regions. In such cases, crystallinity is usually specified as a percentage of the volume of the material that is crystalline. Even within materials that are completely crystalline, however, the degree of structural perfection can vary. For instance, most metallic alloys are crystalline, but they usually comprise many independent crystalline regions (grains or crystallites) in various orientations separated by grain boundaries; furthermore, they contain other crystallographic defects (notably dislocations) that reduce the degree of structural perfection. The most highly perfect crystals are silicon boules produced for semiconductor electronics; these are large single crystals (so they have no grain boundaries), are nearly free of dislocations, and have precisely controlled concentrations of defect atoms.\nCrystallinity can be measured using x-ray crystallography, but calorimetric techniques are also commonly used.\n\n\n== Rock crystallinity ==\nGeologists describe four qualitative levels of crystallinity:\n\nholocrystalline rocks are completely crystalline;\nhypocrystalline rocks are partially crystalline, with crystals embedded in an amorphous or glassy matrix;\nhypohyaline rocks are partially glassy;\nholohyaline rocks (such as obsidian) are completely glassy.\n\n\n== References ==\nOxford dictionary of science, 1999, ISBN 0-19-280098-1.", "Ohmmeter": "An ohmmeter is an electrical instrument that measures electrical resistance (the opposition offered by a circuit or component to the flow of electric current). Multimeters also function as ohmmeters when in resistance-measuring mode.  An ohmmeter applies current to the circuit or component whose resistance is to be measured. It then measures the resulting voltage and calculates the resistance using Ohm\u2019s law \n  \n    \n      \n        V\n        =\n        I\n        R\n      \n    \n    {\\displaystyle V=IR}\n  .\nAn ohmmeter should not be connected to a circuit or component that is carrying a current or is connected to a power source. Power should be disconnected before connecting the ohmmeter.  Ohmmeters can be either connected in series or parallel based on requirements (whether resistance being measured is part of circuit or is a shunt resistance.)\nMicro-ohmmeters (microhmmeter or micro ohmmeter) make measurements of low resistance. Megohmmeters (also a trademarked device Megger) measure large values of resistance. The unit of measurement for resistance is the ohm (\u03a9).\n\n\n== Design evolution ==\nThe first ohmmeters were based on a type of meter movement known as a 'ratiometer'.  These were similar to the galvanometer type movement encountered in later instruments, but instead of hairsprings to supply a restoring force they used conducting 'ligaments'.  These provided no net rotational force to the movement.  Also, the movement was wound with two coils.  One was connected via a series resistor to the battery supply.  The second was connected to the same battery supply via a second resistor and the resistor under test.  The indication on the meter was proportional to the ratio of the currents through the two coils.  This ratio was determined by the magnitude of the resistor under test.  The advantages of this arrangement were twofold.  First, the indication of the resistance was completely independent of the battery voltage (as long as it actually produced some voltage) and no zero adjustment was required.  Second, although the resistance scale was non linear, the scale remained correct over the full deflection range.  By interchanging the two coils a second range was provided.  This scale was reversed compared to the first.  A feature of this type of instrument was that it would continue to indicate a random resistance value once the test leads were disconnected (the action of which disconnected the battery from the movement).  Ohmmeters of this type only ever measured resistance as they could not easily be incorporated into a multimeter design.  Insulation testers that relied on a hand cranked generator operated on the same principle.  This ensured that the indication was wholly independent of the voltage actually produced.\nSubsequent designs of ohmmeter provided a small battery to apply a voltage to a resistance via a galvanometer to measure the current through the resistance (battery, galvanometer and resistance all connected in series). The scale of the galvanometer was marked in ohms, because the fixed voltage from the battery assured that as resistance is increased, the current through the meter (and hence deflection) would decrease. Ohmmeters form circuits by themselves, therefore they cannot be used within an assembled circuit.  This design is much simpler and cheaper than the former design, and was simple to integrate into a multimeter design and consequently was by far the most common form of analogue ohmmeter.  This type of ohmmeter suffers from two inherent disadvantages.  First, the meter needs to be zeroed by shorting the measurement points together and performing an adjustment for zero ohms indication prior to each measurement.  This is because as the battery voltage decreases with age, the series resistance in the meter needs to be reduced to maintain the zero indication at full deflection.  Second, and consequent on the first, the actual deflection for any given resistor under test changes as the internal resistance is altered.  It remains correct at the centre of the scale only, which is why such ohmmeter designs always quote the accuracy \"at centre scale only\".\nA more accurate type of ohmmeter has an electronic circuit that passes a constant current (I) through the resistance, and another circuit that measures the voltage (V) across the resistance. These measurements are then digitized with an analog digital converter (adc) after which a microcontroller or microprocessor make the division of the current and voltage according to Ohm's Law and then decode these to a display to offer the user a reading of the resistance value they're measuring at that instant. Since these type of meters already measure current, voltage and resistance all at once, these type of circuits are often used in digital multimeters.\n\n\n== Precision ohmmeters ==\nFor high-precision measurements of very small resistances, the above types of meter are inadequate. This is partly because the change in deflection itself is small when the resistance measured is too small in proportion to the intrinsic resistance of the ohmmeter (which can be dealt with through current division), but mostly because the meter's reading is the sum of the resistance of the measuring leads, the contact resistances and the resistance being measured. To reduce this effect, a precision ohmmeter has four terminals, called Kelvin contacts. Two terminals carry the current from and to the meter, while the other two allow the meter to measure the voltage across the resistor. In this arrangement, the power source is connected in series with the resistance to be measured through the external pair of terminals, while the second pair connects in parallel with the galvanometer which measures the voltage drop. With this type of meter, any voltage drop due to the resistance of the first pair of leads and their contact resistances is ignored by the meter. This four terminal measurement technique is called Kelvin sensing, after William Thomson, Lord Kelvin, who invented the Kelvin bridge in 1861 to measure very low resistances. The Four-terminal sensing method can also be utilized to conduct accurate measurements of low resistances.\n\n\n== References ==\nhttps://www.codrey.com/electrical/ohmmeter-working-and-types/\n\n\n== External links ==\n\nDC Metering Circuits chapter from Lessons In Electric Circuits Vol 1 DC free ebook and Lessons In Electric Circuits series.", "Musical_tone": "Traditionally in Western music, a musical tone is a steady periodic sound. A musical tone is characterized by its duration, pitch, intensity (or loudness), and timbre (or quality).  The notes used in music can be more complex than musical tones, as they may include aperiodic aspects, such as attack transients, vibrato, and envelope modulation.\nA simple tone, or pure tone, has a sinusoidal waveform.  A complex tone is a combination of two or more pure tones that have a periodic pattern of repetition, unless specified otherwise.\nThe Fourier theorem states that any periodic waveform can be approximated as closely as desired as the sum of a series of sine waves with frequencies in a harmonic series and at specific phase relationships to each other. The common denominator frequency, which is also often the lowest of these frequencies is the fundamental frequency, and is also the inverse of the period of the waveform. The fundamental frequency determines the pitch of the tone, which is perceived by the human hearing. In music, notes are assigned to tones with different fundamental frequencies, in order to describe the pitch of played tones.\n\n\n== History ==\nTones were recognised by Greek philosopher Aristoxenus (375-335 BCE), who called them \"tensions\".\n\n\n== See also ==\nMathematics of musical scales\nReference tone\nStandard test tone\nSignal tone\nWhite noise\n\n\n== References ==\nCitations\n\nWorks cited\n\nLuca de Samuele Cagnazzi (1841). La tonografia escogitata da Luca de Samuele Cagnazzi. Napoli: Stamperia della Societ\u00e0 Filomatica.\n\n\n== External links ==\nPure tones & complex sounds Media related to Tone (music) at Wikimedia Commons"}